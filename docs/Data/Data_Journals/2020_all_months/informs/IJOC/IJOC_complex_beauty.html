<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IJOC_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ijoc---106">IJOC - 106</h2>
<ul>
<li><details>
<summary>
(2020). Multiproduct newsvendor problem with customer-driven demand
substitution: A stochastic integer program perspective. <em>IJOC</em>,
<em>33</em>(3), 1229–1244. (<a
href="https://doi.org/10.1287/ijoc.2020.0996">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies a multiproduct newsvendor problem with customer-driven demand substitution, where each product, once run out of stock, can be proportionally substituted by the others. This problem has been widely studied in the literature; however, because of nonconvexity and intractability, only limited analytical properties have been reported and no efficient approaches have been proposed. This paper first completely characterizes the optimal order policy when the demand is known and reformulates this nonconvex problem as a binary quadratic program. When the demand is random, we formulate the problem as a two-stage stochastic integer program, derive several necessary optimality conditions, prove the submodularity of the profit function, and also develop polynomial-time approximation algorithms and show their performance guarantees. We further propose a tight upper bound via nonanticipativity dual, which is proven to be very close to the optimal value and can yield a good-quality feasible solution under a mild condition. Our numerical investigation demonstrates effectiveness of the proposed algorithms. Moreover, several useful findings and managerial insights are revealed from a series of sensitivity analyses.},
  archive      = {J_IJOC},
  author       = {Jie Zhang and Weijun Xie and Subhash C. Sarin},
  doi          = {10.1287/ijoc.2020.0996},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1229-1244},
  shortjournal = {INFORMS J. Comput.},
  title        = {Multiproduct newsvendor problem with customer-driven demand substitution: A stochastic integer program perspective},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Knowledge learning of insurance risks using dependence
models. <em>IJOC</em>, <em>33</em>(3), 1177–1196. (<a
href="https://doi.org/10.1287/ijoc.2020.1005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning the customers’ experience and behavior creates competitive advantages for any company over its rivals. The insurance industry is an essential sector in any developed economy and a better understanding of customers’ risk profile is critical to decision making in all aspects of insurance operations. In this paper, we explore the idea of using copula-based dependence models to learn the hidden risk of policyholders in property insurance. Specifically, we build a novel copula model to accommodate the dependence over time and over space among spatially clustered property risks. To tackle the computational challenge caused by the discreteness feature of large-scale insurance data, we propose an efficient multilevel composite likelihood approach for parameter estimation. Provided that latent risk induces correlation, the proposed customer learning method offers improved predictive analytics by allowing insurers to borrow strength from related risks in predicting new risks and also helps reveal the relative importance of the multiple sources of unobserved heterogeneity in updating policyholders’ risk profile. In the empirical study, we examine the loss cost of a portfolio of entities insured by a government property insurance program in Wisconsin. We find both significant temporal and spatial association among property risks. However, their effects on the predictive distribution of loss cost are different for the new and renewal policyholders. The two sources of dependence are complements for the former and substitutes for the latter. These findings are shown to have substantial managerial implications in key insurance operations such as experience rating, capital allocation, and reinsurance arrangement.},
  archive      = {J_IJOC},
  author       = {Zifeng Zhao and Peng Shi and Xiaoping Feng},
  doi          = {10.1287/ijoc.2020.1005},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1177-1196},
  shortjournal = {INFORMS J. Comput.},
  title        = {Knowledge learning of insurance risks using dependence models},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A branch-and-bound algorithm for team formation on social
networks. <em>IJOC</em>, <em>33</em>(3), 1162–1176. (<a
href="https://doi.org/10.1287/ijoc.2020.1000">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The team formation problem (TFP) aims to construct a capable team that can communicate and collaborate effectively. The cost of communication is quantified using the proximity of the potential members in a social network. We study a TFP with two measures for communication effectiveness; namely, we minimize the sum of communication costs, and we impose an upper bound on the largest communication cost. This problem can be formulated as a constrained quadratic set covering problem. Our experiments show that a general-purpose solver is capable of solving small and medium-sized instances to optimality. We propose a branch-and-bound algorithm to solve larger sizes: we reformulate the problem and relax it in such a way that it decomposes into a series of linear set covering problems, and we impose the relaxed constraints through branching. Our computational experiments show that the algorithm is capable of solving large-size instances, which are intractable for the solver.},
  archive      = {J_IJOC},
  author       = {Nihal Berktaş and Hande Yaman},
  doi          = {10.1287/ijoc.2020.1000},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1162-1176},
  shortjournal = {INFORMS J. Comput.},
  title        = {A branch-and-bound algorithm for team formation on social networks},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Linearized robust counterparts of two-stage robust
optimization problems with applications in operations management.
<em>IJOC</em>, <em>33</em>(3), 1138–1161. (<a
href="https://doi.org/10.1287/ijoc.2020.0959">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we discuss an alternative method for deriving conservative approximation models for two-stage robust optimization problems. The method mainly relies on a linearization scheme employed in bilinear programming; therefore, we will say that it gives rise to the linearized robust counterpart models. We identify a close relation between this linearized robust counterpart model and the popular affinely adjustable robust counterpart model. We also describe methods of modifying both types of models to make these approximations less conservative. These methods are heavily inspired by the use of valid linear and conic inequalities in the linearization process for bilinear models. We finally demonstrate how to employ this new scheme in location-transportation and multi-item newsvendor problems to improve the numerical efficiency and performance guarantees of robust optimization.},
  archive      = {J_IJOC},
  author       = {Amir Ardestani-Jaafari and Erick Delage},
  doi          = {10.1287/ijoc.2020.0959},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1138-1161},
  shortjournal = {INFORMS J. Comput.},
  title        = {Linearized robust counterparts of two-stage robust optimization problems with applications in operations management},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Data-driven optimization of reward-risk ratio measures.
<em>IJOC</em>, <em>33</em>(3), 1120–1137. (<a
href="https://doi.org/10.1287/ijoc.2020.1002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate a class of fractional distributionally robust optimization problems with uncertain probabilities. They consist in the maximization of ambiguous fractional functions representing reward-risk ratios and have a semi-infinite programming epigraphic formulation. We derive a new fully parameterized closed-form to compute a new bound on the size of the Wasserstein ambiguity ball. We design a data-driven reformulation and solution framework. The reformulation phase involves the derivation of the support function of the ambiguity set and the concave conjugate of the ratio function. We design modular bisection algorithms which enjoy the finite convergence property. This class of problems has wide applicability in finance, and we specify new ambiguous portfolio optimization models for the Sharpe and Omega ratios. The computational study shows the applicability and scalability of the framework to solve quickly large, industry-relevant-size problems, which cannot be solved in one day with state-of-the-art mixed-integer nonlinear programming (MINLP) solvers.},
  archive      = {J_IJOC},
  author       = {Ran Ji and Miguel A. Lejeune},
  doi          = {10.1287/ijoc.2020.1002},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1120-1137},
  shortjournal = {INFORMS J. Comput.},
  title        = {Data-driven optimization of reward-risk ratio measures},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mixed-integer convex nonlinear optimization with
gradient-boosted trees embedded. <em>IJOC</em>, <em>33</em>(3),
1103–1119. (<a href="https://doi.org/10.1287/ijoc.2020.0993">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision trees usefully represent sparse, high-dimensional, and noisy data. Having learned a function from these data, we may want to thereafter integrate the function into a larger decision-making problem, for example, for picking the best chemical process catalyst. We study a large-scale, industrially relevant mixed-integer nonlinear nonconvex optimization problem involving both gradient-boosted trees and penalty functions mitigating risk. This mixed-integer optimization problem with convex penalty terms broadly applies to optimizing pretrained regression tree models. Decision makers may wish to optimize discrete models to repurpose legacy predictive models or they may wish to optimize a discrete model that accurately represents a data set. We develop several heuristic methods to find feasible solutions and an exact branch-and-bound algorithm leveraging structural properties of the gradient-boosted trees and penalty functions. We computationally test our methods on a concrete mixture design instance and a chemical catalysis industrial instance.},
  archive      = {J_IJOC},
  author       = {Miten Mistry and Dimitrios Letsios and Gerhard Krennrich and Robert M. Lee and Ruth Misener},
  doi          = {10.1287/ijoc.2020.0993},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1103-1119},
  shortjournal = {INFORMS J. Comput.},
  title        = {Mixed-integer convex nonlinear optimization with gradient-boosted trees embedded},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An improved branch-and-bound algorithm for the one-machine
scheduling problem with delayed precedence constraints. <em>IJOC</em>,
<em>33</em>(3), 1091–1102. (<a
href="https://doi.org/10.1287/ijoc.2020.0988">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we discuss the one-machine scheduling problem with release and delivery times with the minimum makespan objective. Both heuristics and branch-and-bound algorithms have been formulated for the problem. One such branch-and-bound algorithm solves the problem and a variation that requires a delay between the completion of one job and the start of another (delayed precedence constraints). This paper analyzes key components of this branch-and-bound algorithm and proposes an improved heuristic to be used in conjunction with a different search strategy. Computational experiments demonstrate that the modifications lead to substantial improvements in running time and number of iterations on the one-machine problem instances both with and without delayed precedence constraints.},
  archive      = {J_IJOC},
  author       = {Wenda Zhang and Jason J. Sauppe and Sheldon H. Jacobson},
  doi          = {10.1287/ijoc.2020.0988},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1091-1102},
  shortjournal = {INFORMS J. Comput.},
  title        = {An improved branch-and-bound algorithm for the one-machine scheduling problem with delayed precedence constraints},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A branch-and-price framework for decomposing graphs into
relaxed cliques. <em>IJOC</em>, <em>33</em>(3), 1070–1090. (<a
href="https://doi.org/10.1287/ijoc.2020.0984">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the family of problems of partitioning and covering a graph into/with a minimum number of relaxed cliques. Relaxed cliques are subsets of vertices of a graph for which a clique-defining property—for example, the degree of the vertices, the distance between the vertices, the density of the edges, or the connectivity between the vertices—is relaxed. These graph partitioning and covering problems have important applications in many areas such as social network analysis, biology, and disease-spread prevention. We propose a unified framework based on branch-and-price techniques to compute optimal decompositions. For this purpose, new, effective pricing algorithms are developed, and new branching schemes are invented. In extensive computational studies, we compare several algorithmic designs, such as structure-preserving versus dichotomous branching, and their interplay with different pricing algorithms. The final chosen branch-and-price setup produces results that demonstrate the effectiveness of all components of the newly developed framework and the validity of our approach when applied to social network instances.},
  archive      = {J_IJOC},
  author       = {Timo Gschwind and Stefan Irnich and Fabio Furini and Roberto Wolfler Calvo},
  doi          = {10.1287/ijoc.2020.0984},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1070-1090},
  shortjournal = {INFORMS J. Comput.},
  title        = {A branch-and-price framework for decomposing graphs into relaxed cliques},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An augmented lagrangian decomposition method for
chance-constrained optimization problems. <em>IJOC</em>, <em>33</em>(3),
1056–1069. (<a href="https://doi.org/10.1287/ijoc.2020.1001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Joint chance-constrained optimization problems under discrete distributions arise frequently in financial management and business operations. These problems can be reformulated as mixed-integer programs. The size of reformulated integer programs is usually very large even though the original problem is of medium size. This paper studies an augmented Lagrangian decomposition method for finding high-quality feasible solutions of complex optimization problems, including nonconvex chance-constrained problems. Different from the current augmented Lagrangian approaches, the proposed method allows randomness to appear in both the left-hand-side matrix and the right-hand-side vector of the chance constraint. In addition, the proposed method only requires solving a convex subproblem and a 0-1 knapsack subproblem at each iteration. Based on the special structure of the chance constraint, the 0-1 knapsack problem can be computed in quasi-linear time, which keeps the computation for discrete optimization subproblems at a relatively low level. The convergence of the method to a first-order stationary point is established under certain mild conditions. Numerical results are presented in comparison with a set of existing methods in the literature for various real-world models. It is observed that the proposed method compares favorably in terms of the quality of the best feasible solution obtained within a certain time for large-size problems, particularly when the objective function of the problem is nonconvex or the left-hand-side matrix of the constraints is random.},
  archive      = {J_IJOC},
  author       = {Xiaodi Bai and Jie Sun and Xiaojin Zheng},
  doi          = {10.1287/ijoc.2020.1001},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1056-1069},
  shortjournal = {INFORMS J. Comput.},
  title        = {An augmented lagrangian decomposition method for chance-constrained optimization problems},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Extreme ray feasibility cuts for unit commitment with
uncertainty. <em>IJOC</em>, <em>33</em>(3), 1037–1055. (<a
href="https://doi.org/10.1287/ijoc.2020.0995">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The unit commitment problem with uncertainty is considered one of the most challenging power system scheduling problems. Different stochastic models have been proposed to solve the problem, but such approaches have yet to be applied in industry practice because of computational challenges. In practice, the problem is formulated as a deterministic model with reserve requirements to hedge against uncertainty. However, simply requiring a certain level of reserves cannot ensure power system reliability as the procured reserves may be nondispatchable because of transmission limitations. In this paper, we derive a set of feasibility cuts (constraints) for managing the unit commitment problem with uncertainty. These cuts eliminate unreliable scheduling solutions and reallocate reserves in the power system; they are induced by the extreme rays of a polyhedral dual cone. This paper shows that, with the proposed reformulation, the extreme rays of the dual cone can be characterized by combinatorial selections of transmission lines (arcs) and buses (nodes) of the power system. As a result, the cuts can then be characterized using engineering insights. The unit commitment problem with uncertainty is formulated as a deterministic model with the identified extreme ray feasibility cuts. Test results show that, with the proposed extreme ray feasibility cuts, the problem can be solved more efficiently, and the resulting scheduling decision is also more reliable.},
  archive      = {J_IJOC},
  author       = {Chao Li and Muhong Zhang and Kory Hedman},
  doi          = {10.1287/ijoc.2020.0995},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1037-1055},
  shortjournal = {INFORMS J. Comput.},
  title        = {Extreme ray feasibility cuts for unit commitment with uncertainty},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A framework for solving chance-constrained linear matrix
inequality programs. <em>IJOC</em>, <em>33</em>(3), 1015–1036. (<a
href="https://doi.org/10.1287/ijoc.2020.0982">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel partial sample average approximation (PSAA) framework to solve the two main types of chance-constrained linear matrix inequality (CCLMI) problems: CCLMI with random technology matrix and CCLMI with random right-hand side. We propose a series of computationally tractable PSAA-based approximations for CCLMI problems, analyze their properties, and derive sufficient conditions that ensure convexity for the two most popular—normal and uniform—continuous distributions. We derive several semidefinite programming PSAA reformulations efficiently solved by off-the-shelf solvers and design a sequential convex approximation method for the PSAA formulations containing bilinear matrix inequalities. The proposed methods can be generalized to other continuous random variables whose cumulative distribution function can be easily computed. We carry out a comprehensive numerical study on three practical CCLMI problems: robust truss topology design, calibration, and robust control. The tests attest to the superiority of the PSAA reformulation and algorithmic framework over the scenario and sample average approximation methods.},
  archive      = {J_IJOC},
  author       = {Roya Karimi and Jianqiang Cheng and Miguel A. Lejeune},
  doi          = {10.1287/ijoc.2020.0982},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1015-1036},
  shortjournal = {INFORMS J. Comput.},
  title        = {A framework for solving chance-constrained linear matrix inequality programs},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Time-dependent shortest path problems with penalties and
limits on waiting. <em>IJOC</em>, <em>33</em>(3), 997–1014. (<a
href="https://doi.org/10.1287/ijoc.2020.0985">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Waiting at the right location at the right time can be critically important in certain variants of time-dependent shortest path problems. We investigate the computational complexity of time-dependent shortest path problems in which there is either a penalty on waiting or a limit on the total time spent waiting at a given subset of the nodes. We show that some cases are nondeterministic polynomial-time hard, and others can be solved in polynomial time, depending on the choice of the subset of nodes, on whether waiting is penalized or constrained, and on the magnitude of the penalty/waiting limit parameter.},
  archive      = {J_IJOC},
  author       = {Edward He and Natashia Boland and George Nemhauser and Martin Savelsbergh},
  doi          = {10.1287/ijoc.2020.0985},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {997-1014},
  shortjournal = {INFORMS J. Comput.},
  title        = {Time-dependent shortest path problems with penalties and limits on waiting},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The rank-one quadratic assignment problem. <em>IJOC</em>,
<em>33</em>(3), 979–996. (<a
href="https://doi.org/10.1287/ijoc.2020.1003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the quadratic assignment problem with a rank-one cost matrix (QAP-R1). Four integer-programming formulations are introduced of which three are assumed to have partial integer data. Unlike the standard quadratic assignment problem, some of our formulations can solve reasonably large instances of QAP-R1 with impressive running times and are faster than some metaheuristics. Pairwise relative strength of the LP relaxations of these formulations are also analyzed from theoretical and experimental points of view. Finally, we present a new metaheuristic algorithm to solve QAP-R1 along with its computational analysis. Our study offers the first systematic experimental analysis of integer-programming models and heuristics for QAP-R1. The benchmark instances with various characteristics generated for our study are made available to the public for future research work. Some new polynomially solvable special cases are also introduced.},
  archive      = {J_IJOC},
  author       = {Yang Wang and Wei Yang and Abraham P. Punnen and Jingbo Tian and Aihua Yin and Zhipeng Lü},
  doi          = {10.1287/ijoc.2020.1003},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {979-996},
  shortjournal = {INFORMS J. Comput.},
  title        = {The rank-one quadratic assignment problem},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The quadratic multiknapsack problem with conflicts and
balance constraints. <em>IJOC</em>, <em>33</em>(3), 949–962. (<a
href="https://doi.org/10.1287/ijoc.2020.0983">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quadratic multiknapsack problem consists of packing a set of items of various weights into knapsacks of limited capacities with profits being associated with pairs of items packed into the same knapsack. This problem has been solved by various heuristics since its inception, and more recently it has also been solved with an exact method. We introduce a generalization of this problem that includes pairwise conflicts as well as balance constraints, among other particularities. We present and compare constraint programming and integer programming approaches for solving this generalized problem.},
  archive      = {J_IJOC},
  author       = {Philippe Olivier and Andrea Lodi and Gilles Pesant},
  doi          = {10.1287/ijoc.2020.0983},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {949-962},
  shortjournal = {INFORMS J. Comput.},
  title        = {The quadratic multiknapsack problem with conflicts and balance constraints},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The risk-averse static stochastic knapsack problem.
<em>IJOC</em>, <em>33</em>(3), 931–948. (<a
href="https://doi.org/10.1287/ijoc.2020.0972">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers a single-resource allocation problem for multiple items with random, independent resource consumption values, known as the static stochastic knapsack problem (SSKP). Whereas the existing SSKP literature generally assumes a risk-neutral objective using an expected value approach, such an approach can maximize expected profit while admitting the possibility of very high losses in some unfavorable scenarios. Because of this, we consider two popular risk measures, conditional value-at-risk (CVaR) and a mean-standard deviation trade-off, in order to address risk within this problem class. Optimizing the trade-offs associated with these risk measures presents significant modeling and computational challenges. To address these challenges, we first provide mixed-integer linear programming models using a scenario-based approach, which can be exploited to provide exact solutions for discrete distributions. For general distributions, a sample average approximation method provides approximate solutions. We then propose a general mixed integer nonlinear optimization modeling approach for the special case of normally distributed resource requirements. This modeling approach incorporates a new class of normalized penalty functions that account for both the expected costs and risks associated with uncertainty, and it can be specialized to a broad class of risk measures, including CVaR and mean-standard deviation. Our results characterize key optimality properties for the associated continuous relaxation of the proposed general model and provide insights on valuable rank-ordering mechanisms for items with uncertain resource needs under different risk measures. For this broadly applicable case, we present a class of efficient and high-performing asymptotically optimal heuristic methods based on these optimality conditions. An extensive numerical study evaluates the efficiency and quality of the proposed solution methods, identifies optimal item selection strategies, and examines the sensitivity of the solution to varying levels of risk, excess weight penalty values, and knapsack capacity values.},
  archive      = {J_IJOC},
  author       = {Yasemin Merzifonluoglu and Joseph Geunes},
  doi          = {10.1287/ijoc.2020.0972},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {931-948},
  shortjournal = {INFORMS J. Comput.},
  title        = {The risk-averse static stochastic knapsack problem},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Rapid discrete optimization via simulation with gaussian
markov random fields. <em>IJOC</em>, <em>33</em>(3), 915–930. (<a
href="https://doi.org/10.1287/ijoc.2020.0971">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inference-based optimization via simulation, which substitutes Gaussian process (GP) learning for the structural properties exploited in mathematical programming, is a powerful paradigm that has been shown to be remarkably effective in problems of modest feasible-region size and decision-variable dimension. The limitation to “modest” problems is a result of the computational overhead and numerical challenges encountered in computing the GP conditional (posterior) distribution on each iteration. In this paper, we substantially expand the size of discrete-decision-variable optimization-via-simulation problems that can be attacked in this way by exploiting a particular GP—discrete Gaussian Markov random fields—and carefully tailored computational methods. The result is the rapid Gaussian Markov Improvement Algorithm (rGMIA), an algorithm that delivers both a global convergence guarantee and finite-sample optimality-gap inference for significantly larger problems. Between infrequent evaluations of the global conditional distribution, rGMIA applies the full power of GP learning to rapidly search smaller sets of promising feasible solutions that need not be spatially close. We carefully document the computational savings via complexity analysis and an extensive empirical study.},
  archive      = {J_IJOC},
  author       = {Mark Semelhago and Barry L. Nelson and Eunhye Song and Andreas Wächter},
  doi          = {10.1287/ijoc.2020.0971},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {915-930},
  shortjournal = {INFORMS J. Comput.},
  title        = {Rapid discrete optimization via simulation with gaussian markov random fields},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multicomponent maintenance optimization: A stochastic
programming approach. <em>IJOC</em>, <em>33</em>(3), 898–914. (<a
href="https://doi.org/10.1287/ijoc.2020.0997">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maintenance optimization has been extensively studied in the past decades. However, most of the existing maintenance models focus on single-component systems and are not applicable to complex systems consisting of multiple components, due to various interactions among the components. The multicomponent maintenance optimization problem, which joins the stochastic processes regarding the failures of components with the combinatorial problems regarding the grouping of maintenance activities, is challenging in both modeling and solution techniques, and has remained an open issue in the literature. In this paper, we study the multicomponent maintenance problem over a finite planning horizon and formulate the problem as a multistage stochastic integer program with decision-dependent uncertainty. There is a lack of general efficient methods to solve this type of problem. To address this challenge, we use an alternative approach to model the underlying failure process and develop a novel two-stage model without decision-dependent uncertainty. Structural properties of the two-stage problem are investigated, and a progressive-hedging-based heuristic is developed based on the structural properties. Our heuristic algorithm demonstrates a significantly improved capacity to handle large-size two-stage problems comparing to three conventional methods for stochastic integer programming, and solving the two-stage model by our heuristic in a rolling horizon provides a good approximation of the multistage problem. The heuristic is further benchmarked with a dynamic programming approach and a structural policy, which are two commonly adopted approaches in the literature. Numerical results show that our heuristic can lead to significant cost savings compared with the benchmark approaches.},
  archive      = {J_IJOC},
  author       = {Zhicheng Zhu and Yisha Xiang and Bo Zeng},
  doi          = {10.1287/ijoc.2020.0997},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {898-914},
  shortjournal = {INFORMS J. Comput.},
  title        = {Multicomponent maintenance optimization: A stochastic programming approach},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust models for the kidney exchange problem.
<em>IJOC</em>, <em>33</em>(3), 861–881. (<a
href="https://doi.org/10.1287/ijoc.2020.0986">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kidney exchange programs aim at matching end-stage renal disease patients who have a willing but incompatible kidney donor with another donor. The programs comprise a pool of such incompatible patient-donor pairs and, whenever a donor from one pair is compatible with the patient of another pair, and vice versa, the pairs may be matched and exchange kidneys. This is typically a two-step process in which, first, a set of pairs is matched based on preliminary compatibility tests and, second, the matched pairs are notified and more accurate compatibility tests are performed to verify that actual transplantation can take place. These additional tests may reveal incompatibilities not previously detected. When that happens, the planned exchange will not proceed. Furthermore, pairs may drop out before the transplant, and thus the planned exchange is canceled. In this paper, we study the case in which a new set of pairs may be matched if incompatibilities are discovered or a pair withdraws from the program. The new set should be as close as possible to the initial set in order to minimize the material and emotional costs of the changes. Various recourse policies that determine the admissible second-stage actions are investigated. For each recourse policy, we propose a novel adjustable robust integer programming model. We also propose solution approaches to solve this model exactly. The approaches are validated through thorough computational experiments.},
  archive      = {J_IJOC},
  author       = {Margarida Carvalho and Xenia Klimentova and Kristiaan Glorie and Ana Viana and Miguel Constantino},
  doi          = {10.1287/ijoc.2020.0986},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {861-881},
  shortjournal = {INFORMS J. Comput.},
  title        = {Robust models for the kidney exchange problem},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Decision diagram decomposition for quadratically constrained
binary optimization. <em>IJOC</em>, <em>33</em>(1), 401–418. (<a
href="https://doi.org/10.1287/ijoc.2019.0938">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years the use of decision diagrams within the context of discrete optimization has proliferated. This paper continues this expansion by proposing the use of decision diagrams for modeling and solving binary optimization problems with quadratic constraints. The model proposes the use of multiple decision diagrams to decompose a quadratic matrix so that each individual diagram has provably limited size. The decision diagrams are then linked through channeling constraints to ensure that the solution represented is consistent across the decision diagrams and that the original quadratic constraints are satisfied. The resulting family of decision diagrams are optimized over by a dedicated cutting-plane algorithm akin to Benders decomposition. The approach is general, in that commercial integer programming solvers can readily apply the technique. A thorough experimental evaluation on both benchmark and synthetic instances exhibits that the proposed decision diagram reformulation provides significant improvements over current methods for quadratic constraints in state-of-the-art solvers.},
  archive      = {J_IJOC},
  author       = {David Bergman and Leonardo Lozano},
  doi          = {10.1287/ijoc.2019.0938},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {401-418},
  shortjournal = {INFORMS J. Comput.},
  title        = {Decision diagram decomposition for quadratically constrained binary optimization},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Piecewise constant decision rules via branch-and-bound based
scenario detection for integer adjustable robust optimization.
<em>IJOC</em>, <em>33</em>(1), 390–400. (<a
href="https://doi.org/10.1287/ijoc.2019.0934">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multistage problems with uncertain parameters and integer decisions variables are among the most difficult applications of robust optimization (RO). The challenge in these problems is to find optimal here-and-now decisions, taking into account that the wait-and-see decisions have to adapt to the revealed values of the uncertain parameters. An existing approach to solve these problems is to construct piecewise constant decision rules by adaptively partitioning the uncertainty set. The partitions of this set are iteratively updated by separating so-called criticial scenarios, and methods for identifying these critical scenarios are available. However, these methods are most suitable for problems with continuous decision variables and many uncertain constraints, providing no mathematically rigorous methodology for partitioning in case of integer decisions. In particular, they are not able to identify sets of critical scenarios for integer problems with uncertainty in the objective function only. In this paper, we address this shortcoming by introducing a general critical scenario detection method. The new method leverages the information embedded in the dual vectors of the LP relaxations at the nodes of the branch-and-bound tree used to solve the corresponding static problem. Numerical experiments on a route planning problem show that our general-purpose method outperforms a problem-specific approach from the literature.},
  archive      = {J_IJOC},
  author       = {Ward Romeijnders and Krzysztof Postek},
  doi          = {10.1287/ijoc.2019.0934},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {390-400},
  shortjournal = {INFORMS J. Comput.},
  title        = {Piecewise constant decision rules via branch-and-bound based scenario detection for integer adjustable robust optimization},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Worst-case expected shortfall with univariate and bivariate
marginals. <em>IJOC</em>, <em>33</em>(1), 370–389. (<a
href="https://doi.org/10.1287/ijoc.2019.0939">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computing and minimizing the worst-case bound on the expected shortfall risk of a portfolio given partial information on the distribution of the asset returns is an important problem in risk management. One such bound that been proposed is for the worst-case distribution that is “close” to a reference distribution where closeness in distance among distributions is measured using φ-divergence. In this paper, we advocate the use of such ambiguity sets with a tree structure on the univariate and bivariate marginal distributions. Such an approach has attractive modeling and computational properties. From a modeling perspective, this provides flexibility for risk management applications where there are many more choices for bivariate copulas in comparison with multivariate copulas. Bivariate copulas form the basis of the nested tree structure that is found in vine copulas. Because estimating a vine copula is fairly challenging, our approach provides robust bounds that are valid for the tree structure that is obtained by truncating the vine copula at the top level. The model also provides flexibility in tackling instances when the lower dimensional marginal information is inconsistent that might arise when multiple experts provide information. From a computational perspective, under the assumption of a tree structure on the bivariate marginals, we show that the worst-case expected shortfall is computable in polynomial time in the input size when the distributions are discrete. The corresponding distributionally robust portfolio optimization problem is also solvable in polynomial time. In contrast, under the assumption of independence, the expected shortfall is shown to be #P-hard to compute for discrete distributions. We provide numerical examples with simulated and real data to illustrate the quality of the worst-case bounds in risk management and portfolio optimization and compare it with alternate probabilistic models such as vine copulas and Markov tree distributions.},
  archive      = {J_IJOC},
  author       = {Anulekha Dhara and Bikramjit Das and Karthik Natarajan},
  doi          = {10.1287/ijoc.2019.0939},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {370-389},
  shortjournal = {INFORMS J. Comput.},
  title        = {Worst-case expected shortfall with univariate and bivariate marginals},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multistage stochastic power generation scheduling
co-optimizing energy and ancillary services. <em>IJOC</em>,
<em>33</em>(1), 352–369. (<a
href="https://doi.org/10.1287/ijoc.2019.0933">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing penetration of intermittent renewable energy and fluctuating electricity loads, power system operators are facing significant challenges in maintaining system load balance and reliability. In addition to traditional energy markets that are designed to balance power generation and load, ancillary service markets have been recently introduced to help manage the considerable uncertainty by reserving certain generation capacities against unexpected events. In this paper, we develop a multistage stochastic optimization model for system operators to efficiently schedule power-generation assets to co-optimize power generation and regulation reserve service (a critical ancillary service product) under uncertainty. In addition, to improve the computational efficiency of the proposed multistage stochastic integer program, we explore its polyhedral structure by investigating physical characteristics of individual generators, the system-wide requirements that couple all of the generators, and the scenario tree structure for our proposed multistage model. We start with the single-generator polytope and provide convex hull descriptions for the two-period case under different parameter settings. We then provide several families of multiperiod strong valid inequalities linking different scenarios and covering decision variables that represent both power generation and regulation reserve amounts. We further extend our study by exploring the multigenerator polytope and derive strong valid inequalities linking different generators and covering multiple periods. To enhance computational performance, polynomial-time separation algorithms are developed for the exponential number of inequalities. Finally, we verify the effectiveness of our proposed strong valid inequalities by applying them as user cuts under the branch-and-cut scheme to solve multistage stochastic network-constrained power generation scheduling problems.},
  archive      = {J_IJOC},
  author       = {Jianqiu Huang and Kai Pan and Yongpei Guan},
  doi          = {10.1287/ijoc.2019.0933},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {352-369},
  shortjournal = {INFORMS J. Comput.},
  title        = {Multistage stochastic power generation scheduling co-optimizing energy and ancillary services},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust optimization for electricity generation.
<em>IJOC</em>, <em>33</em>(1), 336–351. (<a
href="https://doi.org/10.1287/ijoc.2020.0956">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a robust optimization problem in an electric power system under uncertain demand and availability of renewable energy resources. Solving the deterministic alternating current (AC) optimal power flow (ACOPF) problem has been considered challenging since the 1960s due to its nonconvexity. Linear approximation of the AC power flow system sees pervasive use, but does not guarantee a physically feasible system configuration. In recent years, various convex relaxation schemes for the ACOPF problem have been investigated, and under some assumptions, a physically feasible solution can be recovered. Based on these convex relaxations, we construct a robust convex optimization problem with recourse to solve for optimal controllable injections (fossil fuel, nuclear, etc.) in electric power systems under uncertainty (renewable energy generation, demand fluctuation, etc.). We propose a cutting-plane method to solve this robust optimization problem, and we establish convergence and other desirable properties. Experimental results indicate that our robust convex relaxation of the ACOPF problem can provide a tight lower bound.},
  archive      = {J_IJOC},
  author       = {Haoxiang Yang and David P. Morton and Chaithanya Bandi and Krishnamurthy Dvijotham},
  doi          = {10.1287/ijoc.2020.0956},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {336-351},
  shortjournal = {INFORMS J. Comput.},
  title        = {Robust optimization for electricity generation},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The migratory beekeeping routing problem: Model and an exact
algorithm. <em>IJOC</em>, <em>33</em>(1), 319–335. (<a
href="https://doi.org/10.1287/ijoc.2020.0958">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Apiculture has gained worldwide interest because of its contributions to economic incomes and environmental conservation. In view of these, migratory beekeeping, as a high-yielding technique, is extensively adopted. However, because of the lack of an overall routing plan, beekeepers who follow the experiential migratory routes frequently encounter unexpected detours and suffer losses when faced with problems such as those related to nectar source capacities and the production of bee products. The migratory beekeeping routing problem (MBRP) is proposed based on the practical background of the commercial apiculture industry to optimize the global revenue for beekeepers by comprehensively considering nectar source allocation, migration, production and sales of bee products, and corresponding time decisions. The MBRP is a new variant of the vehicle routing problem but with significantly different production time decisions at the vertices (i.e., nectar sources). That is, only the overlaps between residence durations and flowering periods generate production benefits. Different sales visits cause different gains from the same products; in turn, these lead to different production time decisions at previously visited nectar source locations and even change the visits for production. To overcome the difficulty resulting from the complicated time decisions, we utilize the Dantzig–Wolfe decomposition method and propose a revised labeling algorithm for the pricing subproblems. The tests, performed on instances and a real-world case, demonstrate that the column generation method with the revised labeling algorithm is efficient for solving the MBRP. Compared with traditional routes, a more efficient overall routing schedule for migratory beekeepers is proposed.},
  archive      = {J_IJOC},
  author       = {Zu-Jun Ma and Fei Yang and Ying Dai and Zuo-Jun Max Shen},
  doi          = {10.1287/ijoc.2020.0958},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {319-335},
  shortjournal = {INFORMS J. Comput.},
  title        = {The migratory beekeeping routing problem: Model and an exact algorithm},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Integrating individual and aggregate diversity in top-n
recommendation. <em>IJOC</em>, <em>33</em>(1), 300–318. (<a
href="https://doi.org/10.1287/ijoc.2019.0952">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems have become one of the main components of web technologies that help people to cope with information overload. Based on the analysis of past user behavior, these systems filter items according to users’ likes and interests. Two of the most important metrics used to analyze the performance of these systems are the accuracy and diversity of the recommendation lists. Whereas all the efforts exerted in the prediction of the user interests aim at maximizing the former, the latter emerges in various forms, such as diversity in the lists across all user recommendation lists, referred to as aggregate diversity, and diversity in the lists of individuals, known as individual diversity. In this paper, we tackle the combination of these three objectives and justify this approach by showing through experiments that handling these objectives in pairs does not yield satisfactory results in the third one. To that end, we develop a mathematical model that is formulated using multiobjective optimization approaches. To cope with the intractability of this nonlinear integer programming model, its special structure is exploited by a decomposition technique. For the solution of the resulting formulation, we propose an iterative framework that is composed of a clique-generating genetic algorithm, a constructive heuristic, and an improvement heuristic. The former is designed to incorporate all objective functions into the generated cliques and specifically impose a certain level of individual diversity, whereas the latter chooses one clique for each user such that the desired aggregate diversity level is fulfilled. We conduct experiments on three data sets and show that the proposed modeling approach successfully handles all objectives according to the needs of the system and that the proposed methodology is capable of yielding good upper bounds.},
  archive      = {J_IJOC},
  author       = {Ethem Çanakoğlu and İbrahim Muter and Tevfik Aytekin},
  doi          = {10.1287/ijoc.2019.0952},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {300-318},
  shortjournal = {INFORMS J. Comput.},
  title        = {Integrating individual and aggregate diversity in top-N recommendation},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A review selection method for finding an informative subset
from online reviews. <em>IJOC</em>, <em>33</em>(1), 280–299. (<a
href="https://doi.org/10.1287/ijoc.2019.0950">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concerning the information overload of online reviews, this paper models a new review selection problem called the Informative Review Subset Selection problem (namely, IRSS) and demonstrates that it is NP-hard to solve and approximate. Furthermore, a novel heuristic method (namely, Combined Search-ComS) is proposed for seeking the solution to the problem and selecting a subset of reviews, which is consistent with the original review corpus in light of mutual information entropy. The proposed method is then comprehensively examined via extensive data experiments and a user study on Amazon data. Experimental results reveal the overall superiority of the proposed method in comparison with other extant methods of concern, showing that it is an effective way to select an informative subset of online reviews. The proposed method is deemed desirable and useful for online consumers and service providers.},
  archive      = {J_IJOC},
  author       = {Jin Zhang and Cong Wang and Guoqing Chen},
  doi          = {10.1287/ijoc.2019.0950},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {280-299},
  shortjournal = {INFORMS J. Comput.},
  title        = {A review selection method for finding an informative subset from online reviews},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sparse convex regression. <em>IJOC</em>, <em>33</em>(1),
262–279. (<a href="https://doi.org/10.1287/ijoc.2020.0954">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of best k-subset convex regression using n observations in d variables. For the case without sparsity, we develop a scalable algorithm for obtaining high quality solutions in practical times that compare favorably with other state of the art methods. We show that by using a cutting plane method, the least squares convex regression problem can be solved for sizes (n,d)=(104,10) in minutes and (n,d)=(105,102) in hours. Our algorithm can be adapted to solve variants such as finding the best convex or concave functions with coordinate-wise monotonicity, norm-bounded subgradients, and minimize the ℓ1 loss—all with similar scalability to the least squares convex regression problem. Under sparsity, we propose algorithms which iteratively solve for the best subset of features based on first order and cutting plane methods. We show that our methods scale for sizes (n,d,k=104,102,10) in minutes and (n,d,k=105,102,10) in hours. We demonstrate that these methods control for the false discovery rate effectively.},
  archive      = {J_IJOC},
  author       = {Dimitris Bertsimas and Nishanth Mundru},
  doi          = {10.1287/ijoc.2020.0954},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {262-279},
  shortjournal = {INFORMS J. Comput.},
  title        = {Sparse convex regression},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Calibration of voting-based helpfulness measurement for
online reviews: An iterative bayesian probability approach.
<em>IJOC</em>, <em>33</em>(1), 246–261. (<a
href="https://doi.org/10.1287/ijoc.2019.0951">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Voting mechanisms are widely adopted for evaluating the quality and credibility of user-generated content, such as online product reviews. For the reviews that do not receive sufficient votes, techniques and models are developed to automatically assess their helpfulness levels. Existing methods serving this purpose are mostly centered on feature analysis, ignoring the information conveyed in the frequencies and patterns of user votes. Consequently, the accuracy of helpfulness measurement is limited. Inspired by related findings from prediction theories and consumer behavior research, we propose a novel approach characterized by the technique of iterative Bayesian distribution estimation, aiming to more accurately measure the helpfulness levels of reviews used for training prediction models. Using synthetic data and a real-world data set involving 1.67 million reviews and 5.18 million votes from Amazon, a simulation experiment and a two-stage data experiment show that the proposed approach outperforms existing methods on accuracy measures. Moreover, an out-of-sample user study is conducted on Amazon Mechanical Turk. The results further illustrate the predictive power of the new approach. Practically, the research contributes to e-commerce by providing an enhanced method for exploiting the value of user-generated content. Academically, we contribute to the design science literature with a novel approach that may be adapted to a wide range of research topics, such as recommender systems and social media analytics.},
  archive      = {J_IJOC},
  author       = {Xunhua Guo and Guoqing Chen and Cong Wang and Qiang Wei and Zunqiang Zhang},
  doi          = {10.1287/ijoc.2019.0951},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {246-261},
  shortjournal = {INFORMS J. Comput.},
  title        = {Calibration of voting-based helpfulness measurement for online reviews: An iterative bayesian probability approach},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient sampling allocation procedures for optimal
quantile selection. <em>IJOC</em>, <em>33</em>(1), 230–245. (<a
href="https://doi.org/10.1287/ijoc.2019.0946">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a dynamic sampling allocation and selection paradigm for finding the alternative with the optimal quantile in a Bayesian framework. Myopic allocation policies (MAPs), analogous to existing methods in classic ranking and selection for selecting the alternative with the optimal mean, and computationally efficient selection policies are derived for selecting the alternative with the optimal quantile. Under certain conditions, we prove that the proposed MAPs and selection procedures are consistent, which means that the best quantile would be eventually correctly selected as the sample size goes to infinity. Numerical experiments demonstrate that the proposed schemes can significantly improve the performance.},
  archive      = {J_IJOC},
  author       = {Yijie Peng and Chun-Hung Chen and Michael C. Fu and Jian-Qiang Hu and Ilya O. Ryzhov},
  doi          = {10.1287/ijoc.2019.0946},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {230-245},
  shortjournal = {INFORMS J. Comput.},
  title        = {Efficient sampling allocation procedures for optimal quantile selection},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A computational approach to first passage problems of
reflected hyperexponential jump diffusion processes. <em>IJOC</em>,
<em>33</em>(1), 216–229. (<a
href="https://doi.org/10.1287/ijoc.2020.0980">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The extant literature on first passage problems of reflected hyperexponential jump diffusion processes (RHEPs) lacks efficiently computable formulae for the Laplace transform of the joint distribution of the RHEP and its first passage time, cumulative distribution function of the overshoot, expected cumulative value of the discounted increments of the local time up to the first passage time, expected cumulative discounted value of the RHEP up to the first passage time, and expectation of the first passage time. We combine numerical solutions to ordinary integro-differential equations and martingale methods in a novel manner to derive such expressions. For some of these quantities, our approach can deal with the subtle case in which both the RHEP’s overall drift and the discount rate equal zero. As a by-product, we obtain a formula for the Laplace transform of the RHEP transition density. We illustrate the numerical performance of our methodology through a few examples. We observe that, when the RHEP’s overall drift and the discount rate are very close to zero, rounding errors can make the evaluation of some of our formulae unreliable. In these situations our exact expression for the case in which the RHEP’s overall drift and discount rate are both zero can be an effective approximation for the quantities in question that is substantially more efficient than reliably calculating them using their exact expressions and “multiprecision computing.” Our research has applications in financial engineering, insurance, economics, and queueing.},
  archive      = {J_IJOC},
  author       = {Ning Cai and Xuewei Yang},
  doi          = {10.1287/ijoc.2020.0980},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {216-229},
  shortjournal = {INFORMS J. Comput.},
  title        = {A computational approach to first passage problems of reflected hyperexponential jump diffusion processes},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Computing feasible points of bilevel problems with a penalty
alternating direction method. <em>IJOC</em>, <em>33</em>(1), 198–215.
(<a href="https://doi.org/10.1287/ijoc.2019.0945">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bilevel problems are highly challenging optimization problems that appear in many applications of energy market design, critical infrastructure defense, transportation, pricing, and so on. Often these bilevel models are equipped with integer decisions, which makes the problems even harder to solve. Typically, in such a setting in mathematical optimization, one develops primal heuristics in order to obtain feasible points of good quality quickly or to enhance the search process of exact global methods. However, there are comparably few heuristics for bilevel problems. In this paper, we develop such a primal heuristic for bilevel problems with a mixed-integer linear or quadratic upper level and a linear or quadratic lower level. The heuristic is based on a penalty alternating direction method, which allows for a theoretical analysis. We derive a convergence theory stating that the method converges to a stationary point of an equivalent single-level reformulation of the bilevel problem and extensively test the method on a test set of more than 2,800 instances—which is one of the largest computational test sets ever used in bilevel programming. The study illustrates the very good performance of the proposed method in terms of both running times and solution quality. This renders the method a suitable subroutine in global bilevel solvers as well as a reasonable standalone approach.Summary of Contribution: Bilevel optimization problems form a very important class of optimization problems in the field of operations research, which is mainly due to their capability of modeling hierarchical decision processes. However, real-world bilevel problems are usually very hard to solve—especially in the case in which additional mixed-integer aspects are included in the modeling. Hence, the development of fast and reliable primal heuristics for this class of problems is very important. This paper presents such a method.},
  archive      = {J_IJOC},
  author       = {Thomas Kleinert and Martin Schmidt},
  doi          = {10.1287/ijoc.2019.0945},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {198-215},
  shortjournal = {INFORMS J. Comput.},
  title        = {Computing feasible points of bilevel problems with a penalty alternating direction method},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Complexity results and effective algorithms for worst-case
linear optimization under uncertainties. <em>IJOC</em>, <em>33</em>(1),
180–197. (<a href="https://doi.org/10.1287/ijoc.2019.0941">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the so-called worst-case linear optimization (WCLO) with uncertainties on the right-hand side of the constraints. Such a problem often arises in applications such as in systemic risk estimation in finance and stochastic optimization. We first show that the WCLO problem with the uncertainty set corresponding to the lp-norm ((WCLOp)) is NP-hard for p ɛ (1,∞). Second, we combine several simple optimization techniques, such as the successive convex optimization method, quadratic convex relaxation, initialization, and branch-and-bound (B&amp;amp;B), to develop an algorithm for (WCLO2) that can find a globally optimal solution to (WCLO2) within a prespecified ε-tolerance. We establish the global convergence of the algorithm and estimate its complexity. We also develop a finite B&amp;amp;B algorithm for (WCLO∞) to identify a global optimal solution to the underlying problem, and establish the finite convergence of the algorithm. Numerical experiments are reported to illustrate the effectiveness of our proposed algorithms in finding globally optimal solutions to medium and large-scale WCLO instances.},
  archive      = {J_IJOC},
  author       = {Hezhi Luo and Xiaodong Ding and Jiming Peng and Rujun Jiang and Duan Li},
  doi          = {10.1287/ijoc.2019.0941},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {180-197},
  shortjournal = {INFORMS J. Comput.},
  title        = {Complexity results and effective algorithms for worst-case linear optimization under uncertainties},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Perspective reformulations of semicontinuous quadratically
constrained quadratic programs. <em>IJOC</em>, <em>33</em>(1), 163–179.
(<a href="https://doi.org/10.1287/ijoc.2019.0925">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study perspective reformulations (PRs) of semicontinuous quadratically constrained quadratic programs (SQCQPs) in this paper. Based on perspective functions, we first propose a class of PRs for SQCQPs and discuss how to find the best PR in this class via strong duality and lifting techniques. We then study the properties of the PR class and relate them to alternative formulations that are used to derive lower bounds for SQCQPs. Finally, we embed the PR bounds in branch-and-bound algorithms and conduct computational experiments to illustrate the effectiveness of the proposed approach.},
  archive      = {J_IJOC},
  author       = {Xiaojin Zheng and Yutong Pan and Zhaolin Hu},
  doi          = {10.1287/ijoc.2019.0925},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {163-179},
  shortjournal = {INFORMS J. Comput.},
  title        = {Perspective reformulations of semicontinuous quadratically constrained quadratic programs},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Exploiting the structure of two-stage robust optimization
models with exponential scenarios. <em>IJOC</em>, <em>33</em>(1),
143–162. (<a href="https://doi.org/10.1287/ijoc.2019.0928">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses a class of two-stage robust optimization models with an exponential number of scenarios given implicitly. We apply Dantzig–Wolfe decomposition to exploit the structure of these models and show that the original problem reduces to a single-stage robust problem. We propose a Benders algorithm for the reformulated single-stage problem. We also develop a heuristic algorithm that dualizes the linear programming relaxation of the inner maximization problem in the reformulated model and iteratively generates cuts to shape the convex hull of the uncertainty set. We combine this heuristic with the Benders algorithm to create a more effective hybrid Benders algorithm. Because the master problem and subproblem in the Benders algorithm are mixed-integer programs, it is computationally demanding to solve them optimally at each iteration of the algorithm. Therefore, we develop novel stopping conditions for these mixed-integer programs and provide the relevant convergence proofs. Extensive computational experiments on a nurse planning problem and a two-echelon supply chain problem are performed to evaluate the efficiency of the proposed algorithms.},
  archive      = {J_IJOC},
  author       = {Hossein Hashemi Doulabi and Patrick Jaillet and Gilles Pesant and Louis-Martin Rousseau},
  doi          = {10.1287/ijoc.2019.0928},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {143-162},
  shortjournal = {INFORMS J. Comput.},
  title        = {Exploiting the structure of two-stage robust optimization models with exponential scenarios},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Optimization for l1-norm error fitting via data
aggregation. <em>IJOC</em>, <em>33</em>(1), 120–142. (<a
href="https://doi.org/10.1287/ijoc.2019.0908">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a data aggregation-based algorithm with monotonic convergence to a global optimum for a generalized version of the L1-norm error fitting model with an assumption of the fitting function. The proposed algorithm generalizes the recent algorithm in the literature, aggregate and iterative disaggregate (AID), which selectively solves three specific L1-norm error fitting problems. With the proposed algorithm, any L1-norm error fitting model can be solved optimally if it follows the form of the L1-norm error fitting problem and if the fitting function satisfies the assumption. The proposed algorithm can also solve multidimensional fitting problems with arbitrary constraints on the fitting coefficients matrix. The generalized problem includes popular models, such as regression and the orthogonal Procrustes problem. The results of the computational experiment show that the proposed algorithms are faster than the state-of-the-art benchmarks for L1-norm regression subset selection and L1-norm regression over a sphere. Furthermore, the relative performance of the proposed algorithm improves as data size increases.},
  archive      = {J_IJOC},
  author       = {Young Woong Park},
  doi          = {10.1287/ijoc.2019.0908},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {120-142},
  shortjournal = {INFORMS J. Comput.},
  title        = {Optimization for l1-norm error fitting via data aggregation},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Polyhedral results and branch-and-cut for the resource
loading problem. <em>IJOC</em>, <em>33</em>(1), 105–119. (<a
href="https://doi.org/10.1287/ijoc.2020.0957">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the resource loading problem, which arises in tactical capacity planning. In this problem, one has to plan the intensity of execution of a set of orders to minimize a cost function that penalizes the resource use above given capacity limits and the completion of the orders after their due dates. Our main contributions include a novel mixed-integer linear-programming (MIP)‐based formulation, the investigation of the polyhedra associated with the feasible intensity assignments of individual orders, and a comparison of our branch-and-cut algorithm based on the novel formulation and the related polyhedral results with other MIP formulations. The computational results demonstrate the superiority of our approach. In our formulation and in one of the proofs, we use fundamental results of Egon Balas on disjunctive programming.},
  archive      = {J_IJOC},
  author       = {Guopeng Song and Tamás Kis and Roel Leus},
  doi          = {10.1287/ijoc.2020.0957},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {105-119},
  shortjournal = {INFORMS J. Comput.},
  title        = {Polyhedral results and branch-and-cut for the resource loading problem},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A branch-and-price algorithm for facility location with
general facility cost functions. <em>IJOC</em>, <em>33</em>(1), 86–104.
(<a href="https://doi.org/10.1287/ijoc.2019.0921">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing facility location models assume that the facility cost is either a fixed setup cost or made up of a fixed setup and a problem-specific concave or submodular cost term. This structural property plays a critical role in developing fast branch-and-price, Lagrangian relaxation, constant ratio approximation, and conic integer programming reformulation approaches for these NP-hard problems. Many practical considerations and complicating factors, however, can make the facility cost no longer concave or submodular. By removing this restrictive assumption, we study a new location model that considers general nonlinear costs to operate facilities in the facility location framework. The general model does not even admit any approximation algorithms unless P = NP because it takes the unsplittable hard-capacitated metric facility location problem as a special case. We first reformulate this general model as a set-partitioning model and then propose a branch-and-price approach. Although the corresponding pricing problem is NP-hard, we effectively analyze its structural properties and design an algorithm to solve it efficiently. The numerical results obtained from two implementation examples of the general model demonstrate the effectiveness of the solution approach, reveal the managerial implications, and validate the importance to study the general framework.},
  archive      = {J_IJOC},
  author       = {Wenjun Ni and Jia Shu and Miao Song and Dachuan Xu and Kaike Zhang},
  doi          = {10.1287/ijoc.2019.0921},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {86-104},
  shortjournal = {INFORMS J. Comput.},
  title        = {A branch-and-price algorithm for facility location with general facility cost functions},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Enumeration of the nondominated set of multiobjective
discrete optimization problems. <em>IJOC</em>, <em>33</em>(1), 72–85.
(<a href="https://doi.org/10.1287/ijoc.2020.0953">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a generic algorithm to compute exactly the set of nondominated points for multiobjective discrete optimization problems. Our algorithm extends the ε-constraint method, originally designed for the biobjective case only, to solve problems with two or more objectives. For this purpose, our algorithm splits the search space into zones that can be investigated separately by solving an integer program. We also propose refinements, which provide extra information on several zones, allowing us to detect, and discard, empty parts of the search space without checking them by solving the associated integer programs. This results in a limited number of calls to the integer solver. Moreover, we can provide a feasible starting solution before solving every program, which significantly reduces the time spent for each resolution. The resulting algorithm is fast and simple to implement. It is compared with previous state-of-the-art algorithms and is seen to outperform them significantly on the experimented problem instances.},
  archive      = {J_IJOC},
  author       = {Satya Tamby and Daniel Vanderpooten},
  doi          = {10.1287/ijoc.2020.0953},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {72-85},
  shortjournal = {INFORMS J. Comput.},
  title        = {Enumeration of the nondominated set of multiobjective discrete optimization problems},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stochastic decomposition for two-stage stochastic linear
programs with random cost coefficients. <em>IJOC</em>, <em>33</em>(1),
51–71. (<a href="https://doi.org/10.1287/ijoc.2019.0929">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic decomposition (SD) has been a computationally effective approach to solve large-scale stochastic programming (SP) problems arising in practical applications. By using incremental sampling, this approach is designed to discover an appropriate sample size for a given SP instance, thus precluding the need for either scenario reduction or arbitrary sample sizes to create sample average approximations (SAA). When compared with the solutions obtained using the SAA procedure, SD provides solutions of similar quality in far less computational time using ordinarily available computational resources. However, previous versions of SD were not applicable to problems with randomness in second-stage cost coefficients. In this paper, we extend its capabilities by relaxing this assumption on cost coefficients in the second stage. In addition to the algorithmic enhancements necessary to achieve this, we also present the details of implementing these extensions, which preserve the computational edge of SD. Finally, we illustrate the computational results obtained from the latest implementation of SD on a variety of test instances generated for problems from the literature. We compare these results with those obtained from the regularized L-shaped method applied to the SAA function of these problems with different sample sizes.},
  archive      = {J_IJOC},
  author       = {Harsha Gangammanavar and Yifan Liu and Suvrajeet Sen},
  doi          = {10.1287/ijoc.2019.0929},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {51-71},
  shortjournal = {INFORMS J. Comput.},
  title        = {Stochastic decomposition for two-stage stochastic linear programs with random cost coefficients},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). High-performance prototyping of decomposition methods in
GAMS. <em>IJOC</em>, <em>33</em>(1), 34–50. (<a
href="https://doi.org/10.1287/ijoc.2019.0905">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prototyping algorithms in algebraic modeling languages has a long tradition. Despite the convenient prototyping platform that modeling languages offer, they are typically seen as rather inefficient with regard to repeatedly solving mathematical programming problems, a concept on which many algorithms are based. The most prominent examples of such algorithms are decomposition methods, such as the Benders decomposition, column generation, and the Dantzig–Wolfe decomposition. In this work, we discuss the underlying reasons for repeated solve deficiency with regard to speed in detail and provide an insider’s look into the algebraic modeling language GAMS. Further, we present recently added features in GAMS that mitigate some of the efficiency drawbacks inherent to the way modeling languages represent model data and ultimately solve a model. In particular, we demonstrate the grid-enabled gather-update-solve-scatter facility and the GAMS object-oriented application programming interface on a large-scale case study that involves a Benders decomposition–type algorithm for a power-expansion planning problem.},
  archive      = {J_IJOC},
  author       = {Timo Lohmann and Michael R. Bussieck and Lutz Westermann and Steffen Rebennack},
  doi          = {10.1287/ijoc.2019.0905},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {34-50},
  shortjournal = {INFORMS J. Comput.},
  title        = {High-performance prototyping of decomposition methods in GAMS},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). SDDP.jl: A julia package for stochastic dual dynamic
programming. <em>IJOC</em>, <em>33</em>(1), 27–33. (<a
href="https://doi.org/10.1287/ijoc.2020.0987">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present SDDP.jl, an open-source library for solving multistage stochastic programming problems using the stochastic dual dynamic programming algorithm. SDDP.jl is built on JuMP, an algebraic modeling language in Julia. JuMP provides SDDP.jl with a solver-agnostic, user-friendly interface. In addition, we leverage unique features of Julia, such as multiple dispatch, to provide an extensible framework for practitioners to build on our work. SDDP.jl is well tested, and accessible documentation is available at https://github.com/odow/SDDP.jl.},
  archive      = {J_IJOC},
  author       = {Oscar Dowson and Lea Kapelevich},
  doi          = {10.1287/ijoc.2020.0987},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {27-33},
  shortjournal = {INFORMS J. Comput.},
  title        = {SDDP.jl: A julia package for stochastic dual dynamic programming},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Approximate dynamic programming for military medical
evacuation dispatching policies. <em>IJOC</em>, <em>33</em>(1), 2–26.
(<a href="https://doi.org/10.1287/ijoc.2019.0930">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Military medical planners must consider how aerial medical evacuation (MEDEVAC) assets will be dispatched when preparing for and supporting high-intensity combat operations. The dispatching authority seeks to dispatch MEDEVAC assets to prioritized requests for service, such that battlefield casualties are effectively and efficiently transported to nearby medical-treatment facilities. We formulate and solve a discounted, infinite-horizon Markov decision process (MDP) model of the MEDEVAC dispatching problem. Because the high dimensionality and uncountable state space of our MDP model renders classical dynamic programming solution methods intractable, we instead apply approximate dynamic programming (ADP) solution methods to produce high-quality dispatching policies relative to the currently practiced closest-available dispatching policy. We develop, test, and compare two distinct ADP solution techniques, both of which utilize an approximate policy iteration (API) algorithmic framework. The first algorithm uses least-squares temporal differences (LSTD) learning for policy evaluation, whereas the second algorithm uses neural network (NN) learning. We construct a notional, yet representative planning scenario based on high-intensity combat operations in southern Azerbaijan to demonstrate the applicability of our MDP model and to compare the efficacies of our proposed ADP solution techniques. We generate 30 problem instances via a designed experiment to examine how selected problem features and algorithmic features affect the quality of solutions attained by our ADP policies. Results show that the respective policies determined by the NN-API and LSTD-API algorithms significantly outperform the closest-available benchmark policies in 27 (90\%) and 24 (80\%) of the problem instances examined. Moreover, the NN-API policies significantly outperform the LSTD-API policies in each of the problem instances examined. Compared with the closest-available policy for the baseline problem instance, the NN-API policy decreases the average response time of important urgent (i.e., life-threatening) requests by 39 minutes. These research models, methodologies, and results inform the implementation and modification of current and future MEDEVAC tactics, techniques, and procedures, as well as the design and purchase of future aerial MEDEVAC assets.},
  archive      = {J_IJOC},
  author       = {Phillip R. Jenkins and Matthew J. Robbins and Brian J. Lunday},
  doi          = {10.1287/ijoc.2019.0930},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {2-26},
  shortjournal = {INFORMS J. Comput.},
  title        = {Approximate dynamic programming for military medical evacuation dispatching policies},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Note from the editor. <em>IJOC</em>, <em>33</em>(1), 1. (<a
href="https://doi.org/10.1287/ijoc.2020.1043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJOC},
  author       = {Alice E. Smith},
  doi          = {10.1287/ijoc.2020.1043},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {1},
  shortjournal = {INFORMS J. Comput.},
  title        = {Note from the editor},
  volume       = {33},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Note from the editor. <em>IJOC</em>, <em>32</em>(4),
855–1186. (<a href="https://doi.org/10.1287/ijoc.2020.1024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.1024},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {855-1186},
  shortjournal = {INFORMS J. Comput.},
  title        = {Note from the editor},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On mixed-integer programming formulations for the unit
commitment problem. <em>IJOC</em>, <em>32</em>(4), 855–1186. (<a
href="https://doi.org/10.1287/ijoc.2019.0944">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide a comprehensive overview of mixed-integer programming formulations for the unit commitment (UC) problem. UC formulations have been an especially active area of research over the past 12 years due to their practical importance in power grid operations, and this paper serves as a capstone for this line of work. We additionally provide publicly available reference implementations of all formulations examined. We computationally test existing and novel UC formulations on a suite of instances drawn from both academic and real-world data sources. Driven by our computational experience from this and previous work, we contribute some additional formulations for both generator production upper bounds and piecewise linear production costs. By composing new UC formulations using existing components found in the literature and new components introduced in this paper, we demonstrate that performance can be significantly improved—and in the process, we identify a new state-of-the-art UC formulation.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2019.0944},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {855-1186},
  shortjournal = {INFORMS J. Comput.},
  title        = {On mixed-integer programming formulations for the unit commitment problem},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An approximation approach for response-adaptive clinical
trial design. <em>IJOC</em>, <em>32</em>(4), 855–1186. (<a
href="https://doi.org/10.1287/ijoc.2020.0969">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiarmed bandit (MAB) problems, typically modeled as Markov decision processes (MDPs), exemplify the learning versus earning trade-off. An area that has motivated theoretical research in MAB designs is the study of clinical trials, where the application of such designs has the potential to significantly improve patient outcomes. However, for many practical problems of interest, the state space is intractably large, rendering exact approaches to solving MDPs impractical. In particular, settings that require multiple simultaneous allocations lead to an expanded state and action-outcome space, necessitating the use of approximation approaches. We propose a novel approximation approach that combines the strengths of multiple methods: grid-based state discretization, value function approximation methods, and techniques for a computationally efficient implementation. The hallmark of our approach is the accurate approximation of the value function that combines linear interpolation with bounds on interpolated value and the addition of a learning component to the objective function. Computational analysis on relevant datasets shows that our approach outperforms existing heuristics (e.g., greedy and upper confidence bound family of algorithms) and a popular Lagrangian-based approximation method, where we find that the average regret improves by up to 58.3\%. A retrospective implementation on a recently conducted phase 3 clinical trial shows that our design could have reduced the number of failures by 17\% relative to the randomized control design used in that trial. Our proposed approach makes it practically feasible for trial administrators and regulators to implement Bayesian response-adaptive designs on large clinical trials with potential significant gains.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.0969},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {855-1186},
  shortjournal = {INFORMS J. Comput.},
  title        = {An approximation approach for response-adaptive clinical trial design},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal group testing: Structural properties and robust
solutions, with application to public health screening. <em>IJOC</em>,
<em>32</em>(4), 855–1186. (<a
href="https://doi.org/10.1287/ijoc.2019.0942">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide a novel regret-based robust formulation of the Dorfman group size problem considering the realistic setting where the prevalence rate is uncertain, establish key structural properties of the optimal solution, and provide an exact algorithm. Our analysis also leads to exact closed-form expressions for the optimal Dorfman group size under a deterministic prevalence rate, which is the problem studied in the extant literature. Thus, our structural results not only unify existing, and mostly empirical, results on the Dorfman group size problem under a deterministic prevalence rate, but, more importantly, enable us to efficiently solve the robust version of this problem to optimality. We demonstrate the value of robust testing schemes with a case study on disease screening using realistic data. Our case study indicates that robust testing schemes can significantly outperform their deterministic counterparts, by not only substantially reducing the maximum regret value, but, in the majority of the cases, reducing testing costs as well. Our findings have important implications on public health screening practices.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2019.0942},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {855-1186},
  shortjournal = {INFORMS J. Comput.},
  title        = {Optimal group testing: Structural properties and robust solutions, with application to public health screening},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evaluating a prediction-driven targeting strategy for
reducing the transmission of multidrug-resistant organisms.
<em>IJOC</em>, <em>32</em>(4), 855–1186. (<a
href="https://doi.org/10.1287/ijoc.2019.0916">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The transmission of multidrug-resistant organisms (MDROs) in the healthcare setting is an ongoing challenge affecting at least 2 million patients in the United States each year via infection and leading to over 20,000 deaths. Many mathematical models have been developed to approximate MDRO transmission dynamics, focusing most often on evaluating the impact of various infection-control strategies. However, although the insights derived from these studies are useful, the models do not typically have the ability to support decision making for infection-control practitioners in real time. In this study, we design a detailed agent-based model of MDRO transmission—focusing on methicillin-resistant Staphylococcus aureus in the intensive care unit setting—and validate its transmission dynamics using data collected during a multisite randomized, controlled trial. We leverage this model to develop and evaluate the effectiveness of a prediction-driven approach for targeting patients for contact precautions (i.e., requiring all visiting healthcare workers to wear personal protective equipment) in a simulated intensive care unit based on their daily likelihood of becoming colonized by the organism. We show that we can predict these outcomes with moderate to high accuracy across a broad range of scenarios and that these predictions can be used to efficiently target patients for intervention and, ultimately, to reduce the overall acquisition rate in the unit.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2019.0916},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {855-1186},
  shortjournal = {INFORMS J. Comput.},
  title        = {Evaluating a prediction-driven targeting strategy for reducing the transmission of multidrug-resistant organisms},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A theoretical framework for learning tumor dose-response
uncertainty in individualized spatiobiologically integrated
radiotherapy. <em>IJOC</em>, <em>32</em>(4), 855–1186. (<a
href="https://doi.org/10.1287/ijoc.2019.0896">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent theoretical research has employed the linear-quadratic model of dose-response in stochastic control formulations for spatiobiologically integrated radiotherapy. The goal is to maximize the expected tumor kill while limiting the biologically effective dose administered to nearby organs at risk under tolerable limits. This is attempted by adapting fluence maps to the uncertain evolution of tumor-cell densities observed in functional images acquired at the beginning of each treatment session. One limitation of this research is that the treatment planner is assumed to know the probability distribution of a crucial dose-response parameter in the linear-quadratic model. This paper proposes a Bayesian stochastic control framework to relax this assumption. An algorithm rooted in certainty-equivalent control is devised to simultaneously learn this probability distribution while adapting fluence maps based on dose-response data collected from functional images over the treatment course. This algorithm’s performance is compared via numerical simulations with two other solution procedures that are also rooted in certainty equivalent control. The first one is a clairvoyant method. This assumes that the treatment planner knows the probability distribution, and hence serves as an idealized gold standard. The other one uses a fixed value of the dose-response parameter as available from the literature, and hence provides a natural benchmark without learning. The tumor kill achieved by the learning algorithm is statistically indistinguishable from the clairvoyant approach, whereas it can be about 20\% higher than the no-learning benchmark. Both these conclusions bode well for individualized spatiobiologically integrated radiotherapy using functional images, at least in theory.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2019.0896},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {855-1186},
  shortjournal = {INFORMS J. Comput.},
  title        = {A theoretical framework for learning tumor dose-response uncertainty in individualized spatiobiologically integrated radiotherapy},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The optimal design of low-latency virtual backbones.
<em>IJOC</em>, <em>32</em>(4), 855–1186. (<a
href="https://doi.org/10.1287/ijoc.2019.0914">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two nodes of a wireless network may not be able to communicate with each other directly, perhaps because of obstacles or insufficient signal strength. This necessitates the use of intermediate nodes to relay information. Often, one designates a (preferably small) subset of them to relay these messages (i.e., to serve as a virtual backbone for the wireless network), which can be seen as a connected dominating set (CDS) of the associated graph. Ideally, these communication paths should be short, leading to the notion of a latency-constrained CDS. In this paper, we point out several shortcomings of a previously studied formalization of a latency-constrained CDS and propose an alternative one. We introduce an integer programming formulation for the problem that has a variable for each node and imposes the latency constraints via an exponential number of cut-like inequalities. Two nice properties of this formulation are that (1) it applies when distances are hop-based and when they are weighted and (2) it easily generalizes to ensure fault tolerance. We provide a branch-and-cut implementation of this formulation and compare it with a new polynomial-size formulation. Computational experiments demonstrate the superiority of the cut-like formulation. We also study related questions from computational complexity, such as approximation hardness, and answer an open problem regarding the fault diameter of graphs.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2019.0914},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {855-1186},
  shortjournal = {INFORMS J. Comput.},
  title        = {The optimal design of low-latency virtual backbones},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Communication-constrained expansion planning for resilient
distribution systems. <em>IJOC</em>, <em>32</em>(4), 855–1186. (<a
href="https://doi.org/10.1287/ijoc.2019.0899">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed generation and remotely controlled switches have emerged as important technologies to improve the resiliency of distribution grids against extreme weather-related disturbances. Therefore it becomes important to study how best to place them on the grid in order to meet a resiliency criteria, while minimizing costs and capturing their dependencies on the associated communication systems that sustain their distributed operations. This paper introduces the Optimal Resilient Design Problem for Distribution and Communication Systems (ORDPDC) to address this need. The ORDPDC is formulated as a two-stage stochastic mixed-integer program that captures the physical laws of distribution systems, the communication connectivity of the smart grid components, and a set of scenarios that specifies which components are affected by potential disasters. The paper proposes an exact branch-and-price algorithm for the ORDPDC that features a strong lower bound and a variety of acceleration schemes to address degeneracy. The ORDPDC model and branch-and-price algorithm were evaluated on a variety of test cases with varying disaster intensities and network topologies. The results demonstrate the significant impact of the network topologies on the expansion plans and costs, as well as the computational benefits of the proposed approach.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2019.0899},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {855-1186},
  shortjournal = {INFORMS J. Comput.},
  title        = {Communication-constrained expansion planning for resilient distribution systems},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sampling conditionally on a rare event via generalized
splitting. <em>IJOC</em>, <em>32</em>(4), 855–1186. (<a
href="https://doi.org/10.1287/ijoc.2019.0936">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose and analyze a generalized splitting method to sample approximately from a distribution conditional on the occurrence of a rare event. This has important applications in a variety of contexts in operations research, engineering, and computational statistics. The method uses independent trials starting from a single particle. We exploit this independence to obtain asymptotic and nonasymptotic bounds on the total variation error of the sampler. Our main finding is that the approximation error depends crucially on the relative variability of the number of points produced by the splitting algorithm in one run and that this relative variability can be readily estimated via simulation. We illustrate the relevance of the proposed method on an application in which one needs to sample (approximately) from an intractable posterior density in Bayesian inference.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2019.0936},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {855-1186},
  shortjournal = {INFORMS J. Comput.},
  title        = {Sampling conditionally on a rare event via generalized splitting},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Understanding and predicting users’ rating behavior: A
cognitive perspective. <em>IJOC</em>, <em>32</em>(4), 855–1186. (<a
href="https://doi.org/10.1287/ijoc.2019.0919">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online reviews are playing an increasingly important role in understanding and predicting users’ rating behavior, which brings great opportunities for users and organizations to make better decisions. In recent years, rating prediction has become a research hotspot. Existing research primarily focuses on generating content representation based on context information and using the overall rating score to optimize the semantics of the content, which largely ignores aspect ratings reflecting users’ feelings about more specific attributes of a product and semantic associations among aspect ratings, words, and sentences. Cognitive theory research has shown that users evaluate and rate products following the part–whole pattern; namely, they use aspect ratings to explicitly express sentiments toward aspect attributes of products and then describe those attributes in detail through the corresponding opinion words and sentences. In this paper, we develop a deep learning-based method for understanding and predicting users’ rating behavior, which adopts the hierarchical attention mechanism to unify the explicit aspect ratings and review contents. We conducted experiments using data collected from two real-world review sites and found that our proposed approach significantly outperforms existing methods. Experiments also show that the performance advantage of the proposed approach mainly comes from the high-quality representation of review content and the effective integration of aspect ratings. A user study empirically shows that aspect ratings influence users’ perceived review helpfulness and reduce users’ cognitive effort in understanding the overall score given for a product. The research contributes to the rating behavior analysis literature and has significant practical implications.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2019.0919},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {855-1186},
  shortjournal = {INFORMS J. Comput.},
  title        = {Understanding and predicting users’ rating behavior: A cognitive perspective},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Production and transportation integration for
commit-to-delivery mode with general shipping costs. <em>IJOC</em>,
<em>32</em>(4), 855–1186. (<a
href="https://doi.org/10.1287/ijoc.2019.0935">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study an integrated production and transportation problem for a make-to-order manufacturing company that operates under the commit-to-delivery mode and uses third-party logistics service providers to deliver products to customers on or before certain committed delivery dates. Such third-party logistics service providers often provide various shipping modes with quantity discounts and different guaranteed shipping times. As a result, the company’s shipping costs need to be represented by general shipping cost functions that are typically nondecreasing, subadditive, and piecewise linear with shipping quantities, and nonincreasing with guaranteed shipping times. To the best of our knowledge, this paper is the first attempt to solve such an integrated production and transportation problem for the commit-to-delivery mode with general shipping costs. We prove that with general shipping costs, the problem is strongly N P -hard when the planning horizon consists of an arbitrary number of days. For the two-day problem, we show that it is ordinarily N P -hard, but is unlikely to have a fully polynomial time approximation scheme (FPTAS) unless N P = P . Interestingly, we find that when the unit inventory holding cost is relatively small, which is often true in practice, there exists an FPTAS for the two-day problem, the development of which hinges on a newly discovered property for minimizing the sum of two general piecewise linear functions. For the multiday problem, we develop a heuristic algorithm based on column generation, which novelly uses a dynamic program for a variant of the problem with a single customer. Results from computational experiments demonstrate that the heuristic algorithm can find near-optimal solutions with optimality gaps less than 1\% in a short running time.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2019.0935},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {855-1186},
  shortjournal = {INFORMS J. Comput.},
  title        = {Production and transportation integration for commit-to-delivery mode with general shipping costs},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An adaptive heuristic approach to compute upper and lower
bounds for the close-enough traveling salesman problem. <em>IJOC</em>,
<em>32</em>(4), 855–1186. (<a
href="https://doi.org/10.1287/ijoc.2020.0962">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the close-enough traveling salesman problem, a variant of the Euclidean traveling salesman problem, in which the traveler visits a node if it passes through the neighborhood set of that node. We apply an effective strategy to discretize the neighborhoods of the nodes and the carousel greedy algorithm to appropriately select the neighborhoods that, step by step, are added to the partial solution until a feasible solution is generated. Our heuristic, based on these ingredients, is able to compute tight upper and lower bounds on the optimal solution relatively quickly. The computational results, carried out on benchmark instances, show that our heuristic often finds the optimal solution, on the instances where it is known, and in general, the upper bounds are more accurate than those from other algorithms available in the literature. Summary of Contribution: In this paper, we focus on the close-enough traveling salesman problem. This is a problem that has attracted research attention over the last 10 years; it has numerous real-world applications. For instance, consider the task of meter reading for utility companies. Homes and businesses have meters that measure the usage of gas, water, and electricity. Each meter transmits signals that can be read by a meter reader vehicle via radio-frequency identification (RFID) technology if the distance between the meter and the reader is less than r units. Each meter plays the role of a target point and the neighborhood is a disc of radius r centered at each target point. Now, suppose the meter reader vehicle is a drone and the goal is to visit each disc while minimizing the amount of energy expended by the drone. To solve this problem, we develop a metaheuristic approach, called ( lb/ub ) Alg , which computes both upper and lower bounds on the optimal solution value. This metaheuristic uses an innovative discretization scheme and the Carousel Greedy algorithm to obtain high-quality solutions. On benchmark instances where the optimal solution is known, ( lb/ub ) Alg obtains this solution 83\% of the time. Over the remaining 17\% of these instances, the deviation from the optimality is 0.05\%, on average. On the instances with the highest overlap ratio, ( lb/ub ) Alg does especially well.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.0962},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {855-1186},
  shortjournal = {INFORMS J. Comput.},
  title        = {An adaptive heuristic approach to compute upper and lower bounds for the close-enough traveling salesman problem},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Simple pattern minimality problems: Integer linear
programming formulations and covering-based heuristic solving
approaches. <em>IJOC</em>, <em>32</em>(4), 855–1186. (<a
href="https://doi.org/10.1287/ijoc.2019.0940">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The simple pattern minimality problem ( SPMP ) represents a central problem in the logical analysis of data and association rules mining, and it finds applications in several fields as logic synthesis, reliability analysis, and automated reasoning. It consists of determining the minimum number of patterns explaining all the observations of a data set, that is, a Boolean logic formula that is true for all the elements of the data set and false for all the unseen observations. We refer to this problem as covering SPMP ( C-SPMP ), because each observation can be explained (covered) by more than one pattern. Starting from a real industrial application, we also define a new version of the problem, and we refer to it as partitioning SPMP ( P-SPMP ), because each observation has to be covered just once. Given a propositional formula or a truth table, C-SPMP and P-SPMP coincide exactly with the problem of determining the minimum disjunctive and minimum exclusive disjunctive normal form, respectively. Both problems are known to be NP-hard and have been generally tackled by heuristic methods. In this context, the contribution of this work is twofold. On one side, it provides two original integer linear programming formulations for the two variants of the SPMP . These formulations exploit the concept of Boolean hypercube to build a graph representation of the problems and allow to exactly solve instances with more than 1,000 observations by using an MIP solver. On the other side, two effective and fast heuristics are proposed to solve relevant size instances taken from literature ( SeattleSNPs ) and from the industrial database. The proposed methods do not suffer from the same dimensional drawbacks of the methods present in the literature and outperform either existing commercial and freeware logic tools or the available industrial solutions in the number of generated patterns and/or in the computational burden.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2019.0940},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {855-1186},
  shortjournal = {INFORMS J. Comput.},
  title        = {Simple pattern minimality problems: Integer linear programming formulations and covering-based heuristic solving approaches},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A core-based exact algorithm for the multidimensional
multiple choice knapsack problem. <em>IJOC</em>, <em>32</em>(4),
855–1186. (<a href="https://doi.org/10.1287/ijoc.2019.0909">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the multidimensional multiple choice knapsack problem (MMKP), items with nonnegative profits are partitioned into groups. Each item consumes a predefined nonnegative amount of a set of resources with given availability. The problem looks for a subset of items consisting of exactly one item for each group that maximizes the overall profit without violating the resource constraints. The MMKP is among the most complex problems in the knapsack family. In the literature, although a plethora of heuristic approaches have been proposed, very few exact methods can be found, and all of them work only on limited size instances. In this paper, we propose a new exact approach for the problem. The method exactly solves subproblems of increasing size by means of a recursive variable-fixing process until an optimality condition is satisfied. The algorithm has several properties. Memory requirement remains almost constant during computation, and the method is general enough to be easily adapted to other knapsack problems. Finally, it can be converted at no cost into a heuristic approach. We close to optimality 10 open benchmark instances and improve the best-known values for many of the remaining ones. Interesting enough, our algorithm is able to find, within three minutes, better solutions than the ones found by Gurobi in one hour.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2019.0909},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {855-1186},
  shortjournal = {INFORMS J. Comput.},
  title        = {A core-based exact algorithm for the multidimensional multiple choice knapsack problem},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Biobjective simulation optimization on integer lattices
using the epsilon-constraint method in a retrospective approximation
framework. <em>IJOC</em>, <em>32</em>(4), 855–1186. (<a
href="https://doi.org/10.1287/ijoc.2019.0918">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider multiobjective simulation optimization (MOSO) problems on integer lattices, that is, nonlinear optimization problems in which multiple simultaneous objective functions can only be observed with stochastic error, for example, as output from a Monte Carlo simulation model. The solution to a MOSO problem is the efficient set, which is the set of all feasible decision points that map to nondominated points in the objective space. For problems with two objectives, we propose the retrospective partitioned epsilon-constraint with relaxed local enumeration (R-PERLE) algorithm. R-PERLE is designed for simulation efficiency and provably converges to a local efficient set under appropriate regularity conditions. It uses a retrospective approximation (RA) framework and solves each resulting biobjective sample-path problem only to an error tolerance commensurate with the sampling error. R-PERLE uses the subalgorithm RLE to certify it has found a sample-path approximate local efficient set. We also propose R-MinRLE, which is a provably convergent benchmark algorithm for problems with two or more objectives. R-PERLE performs favorably relative to R-MinRLE and the current state of the art, MO-COMPASS, in our numerical experiments. This work points to a family of RA algorithms for MOSO on integer lattices that employ RLE to certify sample-path approximate local efficient sets and for which we provide the convergence guarantees.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2019.0918},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {855-1186},
  shortjournal = {INFORMS J. Comput.},
  title        = {Biobjective simulation optimization on integer lattices using the epsilon-constraint method in a retrospective approximation framework},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). PyMOSO: Software for multiobjective simulation optimization
with r-PERLE and r-MinRLE. <em>IJOC</em>, <em>32</em>(4), 855–1186. (<a
href="https://doi.org/10.1287/ijoc.2019.0902">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present the PyMOSO software package for (1) solving multiobjective simulation optimization (MOSO) problems on integer lattices and (2) implementing and testing new simulation optimization (SO) algorithms. First, for solving MOSO problems on integer lattices, PyMOSO implements R-PERLE, a state-of-the-art algorithm for two objectives, and R-MinRLE, a competitive benchmark algorithm for three or more objectives. Both algorithms use pseudogradients, are designed for sampling efficiency, and return solutions that, under appropriate regularity conditions, provably converge to a local efficient set with probability 1 as the simulation budget increases. PyMOSO can interface with existing simulation software and can obtain simulation replications in parallel. Second, for implementing and testing new SO algorithms, PyMOSO includes pseudorandom number stream management, implements algorithm testing with independent pseudorandom number streams run in parallel, and computes the performance of algorithms with user-defined metrics. For convenience, we also include an implementation of R-SPLINE for problems with one objective. The PyMOSO source code is available under a permissive open-source license.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2019.0902},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {855-1186},
  shortjournal = {INFORMS J. Comput.},
  title        = {PyMOSO: Software for multiobjective simulation optimization with R-PERLE and R-MinRLE},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Reducing conservatism in robust optimization. <em>IJOC</em>,
<em>32</em>(4), 855–1186. (<a
href="https://doi.org/10.1287/ijoc.2019.0913">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although robust optimization is a powerful technique in dealing with uncertainty in optimization, its solutions can be too conservative. More specifically, it can lead to an objective value much worse than the nominal solution or even to infeasibility of the robust problem. In practice, this can lead to robust solutions being disregarded in favor of the nominal solution. This conservatism is caused by both the constraint-wise approach of robust optimization and its core assumption that all constraints are hard for all scenarios in the uncertainty set. This paper seeks to alleviate this conservatism by proposing an alternative robust formulation that condenses all uncertainty into a single constraint, binding the worst-case expected violation in the original constraints from above. Using recent results in distributionally robust optimization, the proposed formulation is shown to be tractable for both right- and left-hand side uncertainty. A computational study is performed with problems from the NETLIB library. For some problems, the percentage of uncertainty is magnified fourfold in terms of increase in objective value of the standard robust solution compared with the nominal solution, whereas we find solutions that safeguard against over half the violation at only a 10th of the cost in objective value. For problems with an infeasible standard robust counterpart, the suggested approach is still applicable and finds both solutions that safeguard against most of the uncertainty at a low price in terms of objective value.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2019.0913},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {855-1186},
  shortjournal = {INFORMS J. Comput.},
  title        = {Reducing conservatism in robust optimization},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A practical scheme to compute the pessimistic bilevel
optimization problem. <em>IJOC</em>, <em>32</em>(4), 855–1186. (<a
href="https://doi.org/10.1287/ijoc.2019.0927">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a new computation scheme for the pessimistic bilevel optimization problem, which so far does not have any computational methods generally applicable. We first develop a tight relaxation and then design a simple scheme to ensure a feasible and optimal solution. Then we discuss using this scheme to analyze and compute a linear pessimistic bilevel problem and several extensions. We also provide demonstrations on illustrative examples and a systematic numerical study on instances of two practical problems. Because of its simple structure and strong computational capacity, we believe that the developed scheme is of critical value in studying and solving pessimistic bilevel optimization problems arising from practice.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2019.0927},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {855-1186},
  shortjournal = {INFORMS J. Comput.},
  title        = {A practical scheme to compute the pessimistic bilevel optimization problem},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Predictive analytics with strategically missing data.
<em>IJOC</em>, <em>32</em>(4), 855–1186. (<a
href="https://doi.org/10.1287/ijoc.2019.0947">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study strategically missing data problems in predictive analytics with regression. In many real-world situations, such as financial reporting, college admission, job application, and marketing advertisement, data providers often conceal certain information on purpose in order to gain a favorable outcome. It is important for the decision-maker to have a mechanism to deal with such strategic behaviors. We propose a novel approach to handle strategically missing data in regression prediction. The proposed method derives imputation values of strategically missing data based on the Support Vector Regression models. It provides incentives for the data providers to disclose their true information. We show that with the proposed method imputation errors for the missing values are minimized under some reasonable conditions. An experimental study on real-world data demonstrates the effectiveness of the proposed approach.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2019.0947},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {855-1186},
  shortjournal = {INFORMS J. Comput.},
  title        = {Predictive analytics with strategically missing data},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Provably near-optimal approximation schemes for implicit
stochastic and sample-based dynamic programs. <em>IJOC</em>,
<em>32</em>(4), 855–1186. (<a
href="https://doi.org/10.1287/ijoc.2019.0926">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address two models of nondeterministic discrete time finite-horizon dynamic programs (DPs): implicit stochastic DPs (the information about the random events is given by value oracles to their cumulative distribution functions) and sample-based DPs (the information about the random events is deduced by drawing random samples). Such data-driven models frequently appear in practice, where the cumulative distribution functions of the underlying random variables are either unavailable or too complicated to work with. In both models, the single-period cost functions are accessed via value oracle calls and assumed to possess either monotone or convex structure. We develop the first near-optimal relative approximation schemes for each of the two models. Applications in stochastic inventory control (that is, several variants of the so-called newsvendor problem) are discussed in detail. Our results are achieved by a combination of Bellman equation calculations, density estimation results, and extensions of the technique of K -approximation sets and functions introduced by Halman et al. (2009) [Halman N, Klabjan D, Mostagir M, Orlin J, Simchi-Levi D (2009) A fully polynomial time approximation scheme for single-item stochastic inventory control with discrete demand. Math. Oper. Res. 34(3):674–685.].},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2019.0926},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {855-1186},
  shortjournal = {INFORMS J. Comput.},
  title        = {Provably near-optimal approximation schemes for implicit stochastic and sample-based dynamic programs},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Appreciation to reviewers. <em>IJOC</em>, <em>32</em>(4),
855–1186. (<a href="https://doi.org/10.1287/ijoc.2020.1029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.1029},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {855-1186},
  shortjournal = {INFORMS J. Comput.},
  title        = {Appreciation to reviewers},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Editorial board. <em>IJOC</em>, <em>32</em>(3), C2. (<a
href="https://doi.org/10.1287/ijoc.2020.eb.v3203">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.eb.v3203},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {C2},
  shortjournal = {INFORMS J. Comput.},
  title        = {Editorial board},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Assortment optimization under the multinomial logit model
with sequential offerings. <em>IJOC</em>, <em>32</em>(3), 835–853. (<a
href="https://doi.org/10.1287/ijoc.2019.0910">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider assortment optimization problems, where the choice process of a customer takes place in multiple stages. There is a finite number of stages. In each stage, we offer an assortment of products that does not overlap with the assortments offered in the earlier stages. If the customer makes a purchase within the offered assortment, then the customer leaves the system with the purchase. Otherwise, the customer proceeds to the next stage, where we offer another assortment. If the customer reaches the end of the last stage without a purchase, then the customer leaves the system without a purchase. The choice of the customer in each stage is governed by a multinomial logit model. The goal is to find an assortment to offer in each stage to maximize the expected revenue obtained from a customer. For this assortment optimization problem, it turns out that the union of the optimal assortments to offer in each stage is nested by revenue in the sense that this union includes a certain number of products with the largest revenues. However, it is still difficult to figure out the stage in which a certain product should be offered. In particular, the problem of finding an assortment to offer in each stage to maximize the expected revenue obtained from a customer is NP hard. We give a fully polynomial time approximation scheme for the problem when the number of stages is fixed.},
  archive      = {J_IJOC},
  author       = {Nan Liu and Yuhang Ma and Huseyin Topaloglu},
  doi          = {10.1287/ijoc.2019.0910},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {835-853},
  shortjournal = {INFORMS J. Comput.},
  title        = {Assortment optimization under the multinomial logit model with sequential offerings},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). When lift-and-project cuts are different. <em>IJOC</em>,
<em>32</em>(3), 822–834. (<a
href="https://doi.org/10.1287/ijoc.2019.0943">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a method to determine if a lift-and-project cut for a mixed-integer linear program is irregular, in which case the cut is not equivalent to any intersection cut from the bases of the linear relaxation. This is an important question due to the intense research activity for the past decade on cuts from multiple rows of simplex tableau as well as on lift-and-project cuts from nonsplit disjunctions. Although it has been known for a while that lift-and-project cuts from split disjunctions are always equivalent to intersection cuts and consequently to such multirow cuts, it has been recently shown that there is a necessary and sufficient condition in the case of arbitrary disjunctions: a lift-and-project cut is regular if, and only if, it corresponds to a regular basic solution of the Cut Generating Linear Program (CGLP). This paper has four contributions. First, we state a result that simplifies the verification of regularity for basic CGLP solutions. Second, we provide a mixed-integer formulation that checks whether there is a regular CGLP solution for a given cut that is regular in a broader sense, which also encompasses irregular cuts that are implied by the regular cut closure. Third, we describe a numerical procedure based on such formulation that identifies irregular lift-and-project cuts. Finally, we use this method to evaluate how often lift-and-project cuts from simple t-branch split disjunctions are irregular, and thus not equivalent to multirow cuts, on 74 instances of the Mixed Integer Programming Library (MIPLIB) benchmarks.},
  archive      = {J_IJOC},
  author       = {Egon Balas and Thiago Serra},
  doi          = {10.1287/ijoc.2019.0943},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {822-834},
  shortjournal = {INFORMS J. Comput.},
  title        = {When lift-and-project cuts are different},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimization-driven scenario grouping. <em>IJOC</em>,
<em>32</em>(3), 805–821. (<a
href="https://doi.org/10.1287/ijoc.2019.0924">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scenario decomposition algorithms for stochastic programs compute bounds by dualizing all nonanticipativity constraints and solving individual scenario problems independently. We develop an approach that improves on these bounds by reinforcing a carefully chosen subset of nonanticipativity constraints, effectively placing scenarios into groups. Specifically, we formulate an optimization problem for grouping scenarios that aims to improve the bound by optimizing a proxy metric based on information obtained from evaluating a subset of candidate feasible solutions. We show that the proposed grouping problem is NP-hard in general, identify a polynomially solvable case, and present two formulations for solving the problem: a matching formulation for a special case and a mixed-integer programming formulation for the general case. We use the proposed grouping scheme as a preprocessing step for a particular scenario decomposition algorithm and demonstrate its effectiveness in solving standard test instances of two-stage 0–1 stochastic programs. Using this approach, we are able to prove optimality for all previously unsolved instances of a standard test set. Additionally, we implement this scheme as a preprocessing step for PySP, a publicly available and widely used implementation of progressive hedging, and compare this grouping approach with standard grouping approaches on large-scale stochastic unit commitment instances. Finally, the idea is extended to propose a finitely convergent algorithm for two-stage stochastic programs with a finite feasible region.},
  archive      = {J_IJOC},
  author       = {Kevin Ryan and Shabbir Ahmed and Santanu S. Dey and Deepak Rajan and Amelia Musselman and Jean-Paul Watson},
  doi          = {10.1287/ijoc.2019.0924},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {805-821},
  shortjournal = {INFORMS J. Comput.},
  title        = {Optimization-driven scenario grouping},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Differentially private and budget-limited bandit learning
over matroids. <em>IJOC</em>, <em>32</em>(3), 790–804. (<a
href="https://doi.org/10.1287/ijoc.2019.0903">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose the first budget-limited multi-armed bandit (BMAB) algorithm subject to a union of matroid constraints in arm pulling, while at the same time achieving differential privacy. Our model generalizes the arm-pulling models studied in prior BMAB schemes, and it can be used to address many practical problems such as network backbone construction and dynamic pricing in crowdsourcing. We handle the exploitation versus exploration tradeoff in our BMAB problem by exploiting the combinatorial structures of matroids, and reduce the searching complexity of arm selection based on a divide-and-conquer approach. Our algorithm achieves a uniform logarithmic regret bound with respect to B and ɛ-differential privacy, where B is the budget for pulling the arms with random costs. Without differential privacy, our algorithm achieves a uniform logarithmic regret bound with respect to B, which advances the asymptotic regret bounds achieved by prior BMAB algorithms. We performed side-by-side comparisons with prior schemes in our experiments. Experimental results show that our purely-combinatorial algorithm not only achieves significantly better regret performance, but also is more than 20 times faster than prior BMAB schemes, which use time-consuming LP-solving techniques.},
  archive      = {J_IJOC},
  author       = {Kai Han and Yuntian He and Alex X. Liu and Shaojie Tang and He Huang},
  doi          = {10.1287/ijoc.2019.0903},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {790-804},
  shortjournal = {INFORMS J. Comput.},
  title        = {Differentially private and budget-limited bandit learning over matroids},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Differentially private distributed learning. <em>IJOC</em>,
<em>32</em>(3), 779–789. (<a
href="https://doi.org/10.1287/ijoc.2019.0912">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rich data used to train learning models increasingly tend to be distributed and private. It is important to efficiently perform learning tasks without compromising individual users’ privacy even considering untrusted learning applications and, furthermore, understand how privacy-preservation mechanisms impact the learning process. To address the problem, we design a differentially private distributed algorithm based on the stochastic variance reduced gradient (SVRG) algorithm, which prevents the learning server from accessing and inferring private training data with a theoretical guarantee. We quantify the impact of the adopted privacy-preservation measure on the learning process in terms of convergence rate, by which it indicates noises added at each gradient update results in a bounded deviation from the optimum. To further evaluate the impact on the trained models, we compare the proposed algorithm with SVRG and stochastic gradient descent using logistic regression and neural nets. The experimental results on benchmark data sets show that the proposed algorithm has minor impact on the accuracy of trained models under a moderate amount of privacy budget.},
  archive      = {J_IJOC},
  author       = {Yaqin Zhou and Shaojie Tang},
  doi          = {10.1287/ijoc.2019.0912},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {779-789},
  shortjournal = {INFORMS J. Comput.},
  title        = {Differentially private distributed learning},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An ellipsoidal bounding scheme for the quasi-clique number
of a graph. <em>IJOC</em>, <em>32</em>(3), 763–778. (<a
href="https://doi.org/10.1287/ijoc.2019.0922">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A γ-quasi-clique in a simple undirected graph refers to a subset of vertices that induces a subgraph with edge density at least γ. When γ equals one, this definition corresponds to a classical clique. When γ is less than one, it relaxes the requirement of all possible edges by the clique definition. Quasi-clique detection has been used in graph-based data mining to find dense clusters, especially in large-scale error-prone data sets in which the clique model can be overly restrictive. The maximum γ-quasi-clique problem, seeking a γ-quasi-clique of maximum cardinality in the given graph, can be formulated as an optimization problem with a linear objective function and a single quadratic constraint in binary variables. This article investigates the Lagrangian dual of this formulation and develops an upper-bounding technique using the geometry of ellipsoids to bound the Lagrangian dual. The tightness of the upper bound is compared with those obtained from multiple mixed-integer programming formulations of the problem via experiments on benchmark instances.},
  archive      = {J_IJOC},
  author       = {Zhuqi Miao and Balabhaskar Balasundaram},
  doi          = {10.1287/ijoc.2019.0922},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {763-778},
  shortjournal = {INFORMS J. Comput.},
  title        = {An ellipsoidal bounding scheme for the quasi-clique number of a graph},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A lagrangian bound on the clique number and an exact
algorithm for the maximum edge weight clique problem. <em>IJOC</em>,
<em>32</em>(3), 747–762. (<a
href="https://doi.org/10.1287/ijoc.2019.0898">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the connections between the classical maximum clique problem and its edge-weighted generalization, the maximum edge weight clique (MEWC) problem. As a result, a new analytic upper bound on the clique number of a graph is obtained and an exact algorithm for solving the MEWC problem is developed. The bound on the clique number is derived using a Lagrangian relaxation of an integer (linear) programming formulation of the MEWC problem. Furthermore, coloring-based bounds on the clique number are used in a novel upper-bounding scheme for the MEWC problem. This scheme is employed within a combinatorial branch-and-bound framework, yielding an exact algorithm for the MEWC problem. Results of computational experiments demonstrate a superior performance of the proposed algorithm compared with existing approaches.},
  archive      = {J_IJOC},
  author       = {Seyedmohammadhossein Hosseinian and Dalila B. M. M. Fontes and Sergiy Butenko},
  doi          = {10.1287/ijoc.2019.0898},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {747-762},
  shortjournal = {INFORMS J. Comput.},
  title        = {A lagrangian bound on the clique number and an exact algorithm for the maximum edge weight clique problem},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bilinear assignment problem: Large neighborhoods and
experimental analysis of algorithms. <em>IJOC</em>, <em>32</em>(3),
730–746. (<a href="https://doi.org/10.1287/ijoc.2019.0893">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The bilinear assignment problem (BAP) is a generalization of the well-known quadratic assignment problem. In this paper, we study the problem from the computational analysis point of view. Several classes of neighborhood structures are introduced for the problem along with some theoretical analysis. These neighborhoods are then explored within a local search and variable neighborhood search frameworks with multistart to generate robust heuristic algorithms. In addition, we present several very fast construction heuristics. Our systematic experimental analysis disclosed some interesting properties of the BAP, different from those of comparable models. We have also introduced benchmark test instances that can be used for future experiments on exact and heuristic algorithms for the problem.},
  archive      = {J_IJOC},
  author       = {Vladyslav Sokol and Ante Ćustić and Abraham P. Punnen and Binay Bhattacharya},
  doi          = {10.1287/ijoc.2019.0893},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {730-746},
  shortjournal = {INFORMS J. Comput.},
  title        = {Bilinear assignment problem: Large neighborhoods and experimental analysis of algorithms},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Learning to correlate accounts across online social
networks: An embedding-based approach. <em>IJOC</em>, <em>32</em>(3),
714–729. (<a href="https://doi.org/10.1287/ijoc.2019.0911">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-site account correlation correlates users who have multiple accounts but the same identity across online social networks (OSNs). Being able to identify cross-site users is important for a variety of applications in social networks, security, and electronic commerce, such as social link prediction and cross-domain recommendation. Because of either heterogeneous characteristics of platforms or some unobserved but intrinsic individual factors, the same individuals are likely to behave differently across OSNs, which accordingly causes many challenges for correlating accounts. Traditionally, account correlation is measured by analyzing user-generated content, such as writing style, rules of naming user accounts, or some existing metadata (e.g., account profile, account historical activities). Accounts can be correlated by de-anonymizing user behaviors, which is sometimes infeasible since such data are not often available. In this work, we propose a method, called ACCount eMbedding (ACCM), to go beyond text data and leverage semantics of network structures, a possibility that has not been well explored so far. ACCM aims to correlate accounts with high accuracy by exploiting the semantic information among accounts through random walks. It models and understands latent representations of accounts using an embedding framework similar to sequences of words in natural language models. It also learns a transformation matrix to project node representations into a common dimensional space for comparison. With evaluations on both real-world and synthetic data sets, we empirically demonstrate that ACCM provides performance improvement compared with several state-of-the-art baselines in correlating user accounts between OSNs.},
  archive      = {J_IJOC},
  author       = {Fan Zhou and Kunpeng Zhang and Shuying Xie and Xucheng Luo},
  doi          = {10.1287/ijoc.2019.0911},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {714-729},
  shortjournal = {INFORMS J. Comput.},
  title        = {Learning to correlate accounts across online social networks: An embedding-based approach},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Transient-state natural gas transmission in gunbarrel
pipeline networks. <em>IJOC</em>, <em>32</em>(3), 697–713. (<a
href="https://doi.org/10.1287/ijoc.2019.0904">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the energy consumption minimization problems of natural gas transmission in gunbarrel structured networks. In particular, we consider the transient-state dynamics of natural gas and the compressor’s nonlinear working domain and min-up-and-down constraints. We formulate the problem as a two-level dynamic program (DP), where the upper-level DP problem models each compressor station as a decision stage and each station’s optimization problem is further formulated as a lower-level DP by setting each time period as a stage. The upper-level DP faces the curse of high dimensionality. We propose an approximate dynamic programming (ADP) approach for the upper-level DP using appropriate basis functions and an exact approach for the lower-level DP by exploiting the structure of the problem. We validate the superior performance of the proposed ADP approach on both synthetic and real networks compared with the benchmark simulated annealing (SA) heuristic and the commonly used myopic policy and steady-state policy. On the synthetic networks (SNs), the ADP reduces the energy consumption by 5.8\%–6.7\% from the SA and 12\% from the myopic policy. On the test gunbarrel network with 21 compressor stations and 28 pipes calibrated from China National Petroleum Corporation, the ADP saves 4.8\%–5.1\% (with an average of 5.0\%) energy consumption compared with the SA and the currently deployed steady-state policy, which translates to cost savings of millions of dollars a year. Moreover, the proposed ADP algorithm requires 18.4\%–61.0\% less computation time than the SA. The advantages in both solution quality and computation time strongly support the proposed ADP algorithm in practice.},
  archive      = {J_IJOC},
  author       = {Shixuan Zhang and Sheng Liu and Tianhu Deng and Zuo-Jun Max Shen},
  doi          = {10.1287/ijoc.2019.0904},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {697-713},
  shortjournal = {INFORMS J. Comput.},
  title        = {Transient-state natural gas transmission in gunbarrel pipeline networks},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Convex relaxations for quadratic on/off constraints and
applications to optimal transmission switching. <em>IJOC</em>,
<em>32</em>(3), 682–696. (<a
href="https://doi.org/10.1287/ijoc.2019.0900">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies mixed-integer nonlinear programs featuring disjunctive constraints and trigonometric functions and presents a strengthened version of the convex quadratic relaxation of the optimal transmission switching problem. We first characterize the convex hull of univariate quadratic on/off constraints in the space of original variables using perspective functions. We then introduce new tight quadratic relaxations for trigonometric functions featuring variables with asymmetrical bounds. These results are used to further tighten recent convex relaxations introduced for the optimal transmission switching problem in power systems. Using the proposed improvements, along with bound propagation, on 23 medium-sized test cases in the PGLib benchmark library with a relaxation gap of more than 1\%, we reduce the gap to less than 1\% on five instances. The tightened model has promising computational results when compared with state-of-the-art formulations.},
  archive      = {J_IJOC},
  author       = {Ksenia Bestuzheva and Hassan Hijazi and Carleton Coffrin},
  doi          = {10.1287/ijoc.2019.0900},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {682-696},
  shortjournal = {INFORMS J. Comput.},
  title        = {Convex relaxations for quadratic On/Off constraints and applications to optimal transmission switching},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust optimization of a broad class of heterogeneous
vehicle routing problems under demand uncertainty. <em>IJOC</em>,
<em>32</em>(3), 661–681. (<a
href="https://doi.org/10.1287/ijoc.2019.0923">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies robust variants of an extended model of the classical heterogeneous vehicle routing problem (HVRP), where a mixed fleet of vehicles with different capacities, availabilities, fixed costs, and routing costs is used to serve customers with uncertain demand. This model includes, as special cases, all variants of the HVRP studied in the literature with fixed and unlimited fleet sizes, accessibility restrictions at customer locations, and multiple depots. Contrary to its deterministic counterpart, the goal of the robust HVRP is to determine a minimum cost set of routes and fleet composition that remains feasible for all demand realizations from a prespecified uncertainty set. To solve this problem, we develop robust versions of classical node and edge exchange neighborhoods that are commonly used in local search and establish that efficient evaluation of the local moves can be achieved for five popular classes of uncertainty sets. The proposed local search is then incorporated in a modular fashion within two metaheuristic algorithms to determine robust HVRP solutions. The quality of the metaheuristic solutions is quantified using an integer programming model that provides lower bounds on the optimal solution. An extensive computational study on literature benchmarks shows that the proposed methods allow us to obtain high-quality robust solutions for different uncertainty sets and with minor additional effort compared with deterministic solutions.},
  archive      = {J_IJOC},
  author       = {Anirudh Subramanyam and Panagiotis P. Repoussis and Chrysanthos E. Gounaris},
  doi          = {10.1287/ijoc.2019.0923},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {661-681},
  shortjournal = {INFORMS J. Comput.},
  title        = {Robust optimization of a broad class of heterogeneous vehicle routing problems under demand uncertainty},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimization-based mechanisms for the course allocation
problem. <em>IJOC</em>, <em>32</em>(3), 641–660. (<a
href="https://doi.org/10.1287/ijoc.2018.0849">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, several universities have adopted an algorithmic approach to the allocation of seats in courses, for which students place bids (typically by ordering or scoring desirable courses), and then seats are awarded according to a predetermined procedure or mechanism. Designing the appropriate mechanism for translating bids into student schedules has received attention in the literature, but there is currently no consensus on the best mechanism in practice. In this paper, we introduce five new algorithms for this course-allocation problem, using various combinations of matching algorithms, second-price concepts, and optimization, and compare our new methods with the natural benchmarks from the literature: the (proxy) draft mechanism and the (greedy) bidding-point mechanism. Using simulation, we compare the algorithms on metrics of fairness, efficiency, and incentive compatibility, measuring their ability to encourage truth telling among boundedly rational agents. We find good results for all of our methods and that a two-stage, full-market optimization performs best in measures of fairness and efficiency but with slightly worse incentives to act strategically compared with the best of the mechanisms. We also find generally negative results for the bidding-point mechanism, which performs poorly in all categories. These results can help guide the decision of selecting a mechanism for course allocation or for similar assignment problems, such as project team assignments or sports drafts, for example, in which efficiency and fairness are of utmost importance but incentives must also be considered. Additional robustness checks and comparisons are provided in the online supplement.},
  archive      = {J_IJOC},
  author       = {Hoda Atef Yekta and Robert Day},
  doi          = {10.1287/ijoc.2018.0849},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {641-660},
  shortjournal = {INFORMS J. Comput.},
  title        = {Optimization-based mechanisms for the course allocation problem},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Distributionally robust design for redundancy allocation.
<em>IJOC</em>, <em>32</em>(3), 620–640. (<a
href="https://doi.org/10.1287/ijoc.2019.0907">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider a redundancy allocation problem for a series parallel system with uncertain component lifetimes that minimizes system costs while safeguarding system reliability over a given threshold level. We consider mixed redundancy strategies of cold standby and active redundancy with multiple types of components. We address lifetime uncertainty in the framework of distributionally robust optimization. In particular, we assume the probability distributions of the component lifetimes are not exactly known with only limited distributional information (e.g., mean, dispersion, and support) being available. We protect the worst-case system reliability constraint over all the possible component lifetime distributions that are consistent with the given distributional characteristics. The proposed modeling framework enjoys computationally attractive structures. The evaluation of the worst-case system reliability in our redundancy allocation problem can be transformed into a linear program, and the resulting overall redundancy allocation optimization problem can be cast as a mixed integer linear program that does not induce any additional integer variables (other than original allocation variables). In addition, the extreme joint distribution of component lifetimes can be efficiently recovered by solving a linear program. Our modeling framework can also be extended to incorporate the startup failures and common-cause failures for cold standbys and active parallels, respectively, to cater to more computationally complex settings. Finally, the computational experiments positively demonstrate the performance of the proposed approach in protecting system reliability.},
  archive      = {J_IJOC},
  author       = {Shuming Wang and Yan-Fu Li},
  doi          = {10.1287/ijoc.2019.0907},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {620-640},
  shortjournal = {INFORMS J. Comput.},
  title        = {Distributionally robust design for redundancy allocation},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). MILP models for complex system reliability redundancy
allocation with mixed components. <em>IJOC</em>, <em>32</em>(3),
600–619. (<a href="https://doi.org/10.1287/ijoc.2019.0895">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The redundancy allocation problem (RAP) aims to find an optimal allocation of redundant components subject to resource constraints. In this paper, mixed integer linear programming (MILP) models and MILP-based algorithms are proposed for complex system reliability redundancy allocation problem with mixed components, where the system have bridges or interconnecting subsystems and each subsystem can have mixed types of components. Unlike the other algorithms in the literature, the proposed MILP models view the problem from a different point of view and approximate the nonconvex nonlinear system reliability function of a complex system using random samples. The solution to the MILP converges to the optimal solution of the original problem as sample size increases. In addition, data aggregation-based algorithms are proposed to improve the solution time and quality based on the proposed MILP models. A computational experiment shows that the proposed models and algorithms converge to the optimal or best-known solution as sample size increases. The proposed algorithms outperform popular metaheuristic algorithms in the literature.},
  archive      = {J_IJOC},
  author       = {Young Woong Park},
  doi          = {10.1287/ijoc.2019.0895},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {600-619},
  shortjournal = {INFORMS J. Comput.},
  title        = {MILP models for complex system reliability redundancy allocation with mixed components},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A branch-price-and-cut procedure for the discrete ordered
median problem. <em>IJOC</em>, <em>32</em>(3), 582–599. (<a
href="https://doi.org/10.1287/ijoc.2019.0915">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The discrete ordered median problem (DOMP) is formulated as a set-partitioning problem using an exponential number of variables. Each variable corresponds to a set of demand points allocated to the same facility with the information of the sorting position of their corresponding costs. We develop a column generation approach to solve the continuous relaxation of this model. Then we apply a branch-price-and-cut algorithm to solve small- to large-sized instances of DOMP in competitive computational time.},
  archive      = {J_IJOC},
  author       = {Samuel Deleplanque and Martine Labbé and Diego Ponce and Justo Puerto},
  doi          = {10.1287/ijoc.2019.0915},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {582-599},
  shortjournal = {INFORMS J. Comput.},
  title        = {A branch-price-and-cut procedure for the discrete ordered median problem},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Domination measure: A new metric for solving multiobjective
optimization. <em>IJOC</em>, <em>32</em>(3), 565–581. (<a
href="https://doi.org/10.1287/ijoc.2019.0920">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For general multiobjective optimization problems, the usual goal is finding the set of solutions not dominated by any other solutions, that is, a set of solutions as good as any other solution in all objectives and strictly better in at least one objective. In this paper, we propose a novel performance metric called the domination measure to measure the quality of a solution, which can be intuitively interpreted as the probability that an arbitrary solution in the solution space dominates that solution with respect to a predefined probability measure. We then reformulate the original problem as a stochastic and single-objective optimization problem. We further propose a model-based approach to solve it, which leads to an ideal version algorithm and an implementable version algorithm. We show that the ideal version algorithm converges to a set representation of the global optima of the reformulated problem; we demonstrate the numerical performance of the implementable version algorithm by comparing it with numerous existing multiobjective optimization methods on popular benchmark test functions. The numerical results show that the proposed approach is effective in generating a finite and uniformly spread approximation of the Pareto optimal set of the original multiobjective problem and is competitive with the tested existing methods. The concept of domination measure opens the door for potentially many new algorithms, and our proposed algorithm is an instance that benefits from domination measure.},
  archive      = {J_IJOC},
  author       = {Joshua Q. Hale and Helin Zhu and Enlu Zhou},
  doi          = {10.1287/ijoc.2019.0920},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {565-581},
  shortjournal = {INFORMS J. Comput.},
  title        = {Domination measure: A new metric for solving multiobjective optimization},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Branch and price for chance-constrained bin packing.
<em>IJOC</em>, <em>32</em>(3), 547–564. (<a
href="https://doi.org/10.1287/ijoc.2019.0894">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article describes two versions of the chance-constrained stochastic bin-packing (CCSBP) problem that consider item-to-bin allocation decisions in the context of chance constraints on the total item size within the bins. The first version is a stochastic CCSBP (SP-CCSBP) problem, which assumes that the distributions of item sizes are known. We present a two-stage stochastic mixed-integer program (SMIP) for this problem and a Dantzig–Wolfe formulation suited to a branch-and-price (B&amp;amp;P) algorithm. We further enhance the formulation using coefficient strengthening and reformulations based on probabilistic packs and covers. The second version is a distributionally robust CCSBP (DR-CCSBP) problem, which assumes that the distributions of item sizes are ambiguous. Based on a closed-form expression for the DR chance constraints, we approximate the DR-CCSBP problem as a mixed-integer program that has significantly fewer integer variables than the SMIP of the SP-CCSBP problem, and our proposed B&amp;amp;P algorithm can directly solve its Dantzig–Wolfe formulation. We also show that the approach for the DR-CCSBP problem, in addition to providing robust solutions, can obtain near-optimal solutions to the SP-CCSBP problem. We implement a series of numerical experiments based on real data in the context of surgery scheduling, and the results demonstrate that our proposed B&amp;amp;P algorithm is computationally more efficient than a standard branch-and-cut algorithm, and it significantly improves upon the performance of a well-known bin-packing heuristic.},
  archive      = {J_IJOC},
  author       = {Zheng Zhang and Brian T. Denton and Xiaolan Xie},
  doi          = {10.1287/ijoc.2019.0894},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {547-564},
  shortjournal = {INFORMS J. Comput.},
  title        = {Branch and price for chance-constrained bin packing},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the derivation of continuous piecewise linear
approximating functions. <em>IJOC</em>, <em>32</em>(3), 531–546. (<a
href="https://doi.org/10.1287/ijoc.2019.0949">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose mixed-integer programming models for fitting univariate discrete data points with continuous piecewise linear (PWL) functions. The number of approximating function segments and the locations of break points are optimized simultaneously. The proposed models include linear constraints and convex objective function and, thus, are computationally more efficient than previously proposed mixed-integer nonlinear programming models. We also show how the proposed models can be extended to approximate univariate functions with PWL functions with the minimum number of segments subject to bounds on the pointwise error.},
  archive      = {J_IJOC},
  author       = {Lingxun Kong and Christos T . Maravelias},
  doi          = {10.1287/ijoc.2019.0949},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {531-546},
  shortjournal = {INFORMS J. Comput.},
  title        = {On the derivation of continuous piecewise linear approximating functions},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Note from the editor. <em>IJOC</em>, <em>32</em>(2),
199–530. (<a href="https://doi.org/10.1287/ijoc.2020.0968">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.0968},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {199-530},
  shortjournal = {INFORMS J. Comput.},
  title        = {Note from the editor},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust quadratic programming with mixed-integer uncertainty.
<em>IJOC</em>, <em>32</em>(2), 199–530. (<a
href="https://doi.org/10.1287/ijoc.2019.0901">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study robust convex quadratic programs where the uncertain problem parameters can contain both continuous and integer components. Under the natural boundedness assumption on the uncertainty set, we show that the generic problems are amenable to exact copositive programming reformulations of polynomial size. These convex optimization problems are NP-hard but admit a conservative semidefinite programming (SDP) approximation that can be solved efficiently. We prove that the popular approximate S -lemma method—which is valid only in the case of continuous uncertainty—is weaker than our approximation. We also show that all results can be extended to the two-stage robust quadratic optimization setting if the problem has complete recourse. We assess the effectiveness of our proposed SDP reformulations and demonstrate their superiority over the state-of-the-art solution schemes on instances of least squares, project management, and multi-item newsvendor problems.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2019.0901},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {199-530},
  shortjournal = {INFORMS J. Comput.},
  title        = {Robust quadratic programming with mixed-integer uncertainty},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On solving the quadratic shortest path problem.
<em>IJOC</em>, <em>32</em>(2), 199–530. (<a
href="https://doi.org/10.1287/ijoc.2018.0861">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quadratic shortest path problem is the problem of finding a path in a directed graph such that the sum of interaction costs over all pairs of arcs on the path is minimized. We derive several semidefinite programming relaxations for the quadratic shortest path problem with a matrix variable of order m + 1, where m is the number of arcs in the graph. We use the alternating direction method of multipliers to solve the semidefinite programming relaxations. Numerical results show that our bounds are currently the strongest bounds for the quadratic shortest path problem. We also present computational results on solving the quadratic shortest path problem using a branch and bound algorithm. Our algorithm computes a semidefinite programming bound in each node of the search tree, and solves instances with up to 1,300 arcs in less than an hour.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2018.0861},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {199-530},
  shortjournal = {INFORMS J. Comput.},
  title        = {On solving the quadratic shortest path problem},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mitigating information asymmetry in liver allocation.
<em>IJOC</em>, <em>32</em>(2), 199–530. (<a
href="https://doi.org/10.1287/ijoc.2018.0874">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In accordance with the National Organ Transplant Act, which requires the efficient and equitable allocation of donated organs, the United Network for Organ Sharing (UNOS) prioritizes patients on the liver transplant waiting list within given geographic areas based mainly on their most recently reported health status. Accordingly, the UNOS requires patients to update their health status at a frequency that depends on their last reported health status. However, patients may elect to update any time within the required timeframe, which creates opportunities to game the system, leading to information asymmetries between the UNOS and the patients on the waiting list. This information asymmetry can be alleviated through more frequent updating requirements but at the price of an increased update burden (e.g., data collection costs and patient inconvenience). We propose a model that determines health reporting requirements that simultaneously minimize these two (possibly conflicting) criteria (i.e., inequity due to information asymmetry and update burden). Calibrating the model with clinical data, we examine (i) the degree to which an individual patient can benefit from the flexibility inherent to the current health reporting requirements and (ii) alternative recommendations that dominate the current requirements with respect to the two criteria of interest.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2018.0874},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {199-530},
  shortjournal = {INFORMS J. Comput.},
  title        = {Mitigating information asymmetry in liver allocation},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The mothership and drone routing problem. <em>IJOC</em>,
<em>32</em>(2), 199–530. (<a
href="https://doi.org/10.1287/ijoc.2018.0879">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The mothership and drone routing problem (MDRP) considers the routing of a two-vehicle tandem. The larger vehicle, which may be a ship or an airplane, is called the mothership ; the smaller vehicle, which may be a small boat or unmanned aerial vehicle, is called the drone . We assume that there exists a set of target locations T . For each t in T , the drone must launch from the mothership, visit t , and then return to the mothership to refuel. The drone has a limited range of R time units. In the MDRP, we assume that both mothership and drone operate in the “open seas” (i.e., using the Euclidean metric). We also introduce the mothership and infinite-capacity drone routing problem (MDRP-IC), where a drone launches from the mothership and visits one or more targets consecutively before returning to the mothership. Our exact approach uses branch and bound, where each node of the branch-and-bound tree corresponds to a potential subsequence of the order of target visits. A lower bound at each node is given by solving a second-order cone program, which optimally chooses a launch point and landing point for each target in the subsequence. A set of heuristics that also uses a second-order cone program as an embedded procedure is presented. We show that our schemes are flexible to accommodate a variety of additional constraints and/or objective functions. Computational results and interesting variants of the MDRP and MDRP-IC are also presented.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2018.0879},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {199-530},
  shortjournal = {INFORMS J. Comput.},
  title        = {The mothership and drone routing problem},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An MDD-based lagrangian approach to the multicommodity
pickup-and-delivery TSP. <em>IJOC</em>, <em>32</em>(2), 199–530. (<a
href="https://doi.org/10.1287/ijoc.2018.0881">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the one-to-one multicommodity pickup-and-delivery traveling salesman problem, a challenging variant of the traveling salesman problem that includes the transportation of commodities between locations. The goal is to find a minimum cost tour such that each commodity is delivered to its destination and the maximum capacity of the vehicle is never exceeded. We propose an exact approach that uses a discrete relaxation based on multivalued decision diagrams (MDDs) to better represent the combinatorial structure of the problem. We enhance our relaxation by using the MDDs as a subproblem to a Lagrangian relaxation technique, leading to significant improvements in both bound quality and run-time performance. Our work extends the use of MDDs for solving routing problems by presenting new construction methods and filtering rules based on capacity restrictions. Experimental results show that our approach outperforms state-of-the-art methodologies, closing 33 open instances from the literature, with 27 of those closed by our best variant.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2018.0881},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {199-530},
  shortjournal = {INFORMS J. Comput.},
  title        = {An MDD-based lagrangian approach to the multicommodity pickup-and-delivery TSP},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Solving the nearly symmetric all-pairs shortest-path
problem. <em>IJOC</em>, <em>32</em>(2), 199–530. (<a
href="https://doi.org/10.1287/ijoc.2018.0873">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a simple modification to the repeated shortest-path algorithm for the all-pairs shortest-path problem that adds a cumulative distance label update at each iteration based on the shortest-path tree from the prior iteration. We have implemented and tested our update using several shortest-path algorithms on a range of test networks of varying size, degree, and “skewness” (i.e., asymmetry) of costs on antisymmetric arcs, and we find that it provides a significant speedup to any such algorithm, except for cases either in which the underlying graph is extremely sparsely connected (or even disconnected) or when the arc costs are highly nonsymmetric. An added charm is that our best-modified method preserves the polynomial worst case runtime of its label-correcting antecedent. As with other repeated shortest-path algorithms, it is significantly faster than the Floyd–Warshall algorithm on sparsely connected networks and even some fairly densely connected networks.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2018.0873},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {199-530},
  shortjournal = {INFORMS J. Comput.},
  title        = {Solving the nearly symmetric all-pairs shortest-path problem},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Least-cost influence maximization on social networks.
<em>IJOC</em>, <em>32</em>(2), 199–530. (<a
href="https://doi.org/10.1287/ijoc.2019.0886">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Viral-marketing strategies are of significant interest in the online economy. Roughly, in these problems, one seeks to identify which individuals to strategically target in a social network so that a given proportion of the network is influenced at minimum cost. Earlier literature has focused primarily on problems where a fixed inducement is provided to those targeted. In contrast, resembling the practical viral-marketing setting, we consider this problem where one is allowed to “partially influence” (by the use of monetary inducements) those selected for targeting. We thus focus on the “least-cost influence problem (LCIP)”: an influence-maximization problem where the goal is to find the minimum total amount of inducements (individuals to target and associated tailored incentive) required to influence a given proportion of the population. Motivated by the desire to develop a better understanding of fundamental problems in social-network analytics, we seek to develop (exact) optimization approaches for the LCIP. Our paper makes several contributions, including (i) showing that the problem is NP-complete in general as well as under a wide variety of special conditions; (ii) providing an influence greedy algorithm to solve the problem polynomially on trees, where we require 100\% adoption and all neighbors exert equal influence on a node; and (iii) a totally unimodular formulation for this tree case.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2019.0886},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {199-530},
  shortjournal = {INFORMS J. Comput.},
  title        = {Least-cost influence maximization on social networks},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Understanding the impact of individual users’ rating
characteristics on the predictive accuracy of recommender systems.
<em>IJOC</em>, <em>32</em>(2), 199–530. (<a
href="https://doi.org/10.1287/ijoc.2018.0882">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we investigate how individual users’ rating characteristics affect the user-level performance of recommendation algorithms. We measure users’ rating characteristics from three perspectives: rating value, rating structure, and neighborhood network embeddedness. We study how these three categories of measures influence the predictive accuracy of popular recommendation algorithms for each user. Our experiments use five real-world data sets with varying characteristics. For each individual user, we estimate the predictive accuracy of three recommendation algorithms. We then apply regression-based models to uncover the relationships between rating characteristics and recommendation performance at the individual user level. Our experimental results show consistent and significant effects of several rating measures on recommendation accuracy. Understanding how rating characteristics affect the recommendation performance at the individual user level has practical implications for the design of recommender systems.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2018.0882},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {199-530},
  shortjournal = {INFORMS J. Comput.},
  title        = {Understanding the impact of individual users’ rating characteristics on the predictive accuracy of recommender systems},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Scalable, adaptable, and fast estimation of transient
downtime in virtual infrastructures using convex decomposition and
sample path randomization. <em>IJOC</em>, <em>32</em>(2), 199–530. (<a
href="https://doi.org/10.1287/ijoc.2019.0888">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network function virtualization enables efficient cloud-resource planning by virtualizing network services and applications into software running on commodity servers. A cloud-service provider needs to manage and ensure service availability of a network of concurrent virtualized network functions (VNFs). The downtime distribution of a network of VNFs can be estimated using sample-path randomization on the underlying birth–death process. An integrated modeling approach for this purpose is limited by its scalability and computational load because of the high dimensionality of the integrated birth–death process. We propose a generalized convex decomposition of the integrated birth–death process, which transforms the high-dimensional multi-VNF process into a series of interlinked, low-dimensional, single-VNF processes. We theoretically show the statistical equivalence between the transition probabilities of the integrated birth–death process and those resulting from interlinking the decomposed system of processes. We further develop a decomposition algorithm that yields scalable and fast estimation of the system downtime distribution. Our algorithmic framework can be easily adapted to any logical definition of overall system availability. It can also be easily extended to various realistic VNF network configurations and characteristics including heterogeneous VNF failure distributions, effects of both node and link failures on the overall system downtime of fully or partially connected networks, and resource sharing across multiple VNFs. Our extensive computational results demonstrate the computational efficiency of the proposed algorithms while ensuring statistical consistency with the integrated-network model and the superior performance of the decomposition strategy over the integrated modeling approach.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2019.0888},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {199-530},
  shortjournal = {INFORMS J. Comput.},
  title        = {Scalable, adaptable, and fast estimation of transient downtime in virtual infrastructures using convex decomposition and sample path randomization},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Successive quadratic upper-bounding for discrete mean-risk
minimization and network interdiction. <em>IJOC</em>, <em>32</em>(2),
199–530. (<a href="https://doi.org/10.1287/ijoc.2018.0870">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advances in conic optimization have led to its increased utilization for modeling data uncertainty. In particular, conic mean-risk optimization gained prominence in probabilistic and robust optimization. Whereas the corresponding conic models are solved efficiently over convex sets, their discrete counterparts are intractable. In this paper, we give a highly effective successive quadratic upper-bounding procedure for discrete mean-risk minimization problems. The procedure is based on a reformulation of the mean-risk problem through the perspective of its convex quadratic term. Computational experiments conducted on the network interdiction problem with stochastic capacities show that the proposed approach yields near-optimal solutions in a small fraction of the time required by exact-search algorithms. We demonstrate the value of the proposed approach for constructing efficient frontiers of flow at risk versus interdiction cost for varying confidence levels.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2018.0870},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {199-530},
  shortjournal = {INFORMS J. Comput.},
  title        = {Successive quadratic upper-bounding for discrete mean-risk minimization and network interdiction},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Online risk monitoring using offline simulation.
<em>IJOC</em>, <em>32</em>(2), 199–530. (<a
href="https://doi.org/10.1287/ijoc.2019.0892">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating portfolio risk measures and classifying portfolio risk levels in real time are important yet challenging tasks. In this paper, we propose to build a logistic regression model using data generated in past simulation experiments and to use the model to predict portfolio risk measures and classify risk levels at any time. We further explore regularization techniques, simulation model structure, and additional simulation budget to enhance the estimators of the logistic regression model to make its predictions more precise. Our numerical results show that the proposed methods work well. Our work may be viewed as an example of the recently proposed idea of simulation analytics, which treats a simulation model as a data generator and proposes to apply data analytics tools to the simulation outputs to uncover conditional statements. Our work shows that the simulation analytics idea is viable and promising in the field of financial risk management.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2019.0892},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {199-530},
  shortjournal = {INFORMS J. Comput.},
  title        = {Online risk monitoring using offline simulation},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Estimating the probability that a function observed with
noise is convex. <em>IJOC</em>, <em>32</em>(2), 199–530. (<a
href="https://doi.org/10.1287/ijoc.2018.0847">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider a real-valued function that can be only observed with stochastic noise at a finite set of design points within a Euclidean space. We wish to determine whether there exists a convex function that goes through the true function values at the design points. We develop an asymptotically consistent Bayesian sequential sampling procedure that estimates the posterior probability of this being true. In each iteration, the posterior probability is estimated using Monte Carlo simulation. We offer three variance reduction methods: change of measure, acceptance-rejection, and conditional Monte Carlo. Numerical experiments suggest that the conditional Monte Carlo method is preferred.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2018.0847},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {199-530},
  shortjournal = {INFORMS J. Comput.},
  title        = {Estimating the probability that a function observed with noise is convex},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the variance of single-run unbiased stochastic derivative
estimators. <em>IJOC</em>, <em>32</em>(2), 199–530. (<a
href="https://doi.org/10.1287/ijoc.2019.0897">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze the variance of single-run unbiased stochastic derivative estimators. The distribution of a specific conditional expectation characterizes an intrinsic distributional property of the derivative estimators in a given class, which, in turn, separates two of the most popular single-run unbiased derivative estimators, infinitesimal perturbation analysis and the likelihood ratio method, into disjoint classes. In addition, a necessary and sufficient condition for the estimators to achieve the lowest variance in a certain class is provided, as well as insights into finding an estimator with lower variance. We offer a sufficient condition to substantiate the rule of thumb that the infinitesimal perturbation analysis estimator has a smaller variance than does the likelihood ratio method estimator and to provide a counterexample when the sufficient condition is not satisfied.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2019.0897},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {199-530},
  shortjournal = {INFORMS J. Comput.},
  title        = {On the variance of single-run unbiased stochastic derivative estimators},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Relative robust and adaptive optimization. <em>IJOC</em>,
<em>32</em>(2), 199–530. (<a
href="https://doi.org/10.1287/ijoc.2018.0860">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust optimization has emerged in the operations research literature as a tractable and practical way to model uncertainty in optimization problems. Early approaches focused on relative worst-case objective functions, where the value of a solution is measured versus the best-possible solution over an uncertainty set of scenarios. However, over the past ten years the focus has primarily been on absolute worst-case objective functions, which have generally been considered to be more tractable. In this paper, we demonstrate that for many problems of interest, including some adaptive robust optimization problems, that considering relative objective functions does not significantly increase the computational cost over absolute objective functions. We use combinations of absolute and relative worst-case objective functions to find Pareto-efficient solutions that combine aspects of both, which suggests an approach to distinguish between otherwise very similar robust solutions. We provide reformulation and cutting plane approaches for these problems and demonstrate their efficacy with experiments on minimum-cost flow, inventory control, and facility location problems. These case studies show that solutions corresponding to relative objective functions may be a better match for a decision maker’s risk preferences than absolute.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2018.0860},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {199-530},
  shortjournal = {INFORMS J. Comput.},
  title        = {Relative robust and adaptive optimization},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new branch-and-price-and-cut algorithm for one-dimensional
bin-packing problems. <em>IJOC</em>, <em>32</em>(2), 199–530. (<a
href="https://doi.org/10.1287/ijoc.2018.0867">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new branch-and-price-and-cut algorithm is proposed to solve the one-dimensional bin-packing problem (1D-BPP). The 1D-BPP is one of the most fundamental problems in combinatorial optimization and has been extensively studied for decades. Recently, a set of new 500 test instances were proposed for the 1D-BPP, and the best exact algorithm proposed in the literature can optimally solve 167 of these new instances, with a time limit of 1 hour imposed on each execution of the algorithm. The exact algorithm proposed in this paper is based on the classical set-partitioning model for the 1DBPPs and the subset row inequalities. We describe an ad hoc label-setting algorithm to solve the pricing problem, dominance, and fathoming rules to speed up its computation and a new primal heuristic. The exact algorithm can easily handle some practical constraints, such as the incompatibility between the items, and therefore, we also apply it to solve the one-dimensional bin-packing problem with conflicts (1D-BPPC). The proposed method is tested on a large family of 1D-BPP and 1D-BPPC classes of instances. For the 1D-BPP, the proposed method can optimally solve 237 instances of the new set of difficult instances; the largest instance involves 1,003 items and bins of capacity 80,000. For the 1D-BPPC, the experiments show that the method is highly competitive with state-of-the-art methods and that it successfully closed several open 1D-BPPC instances.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2018.0867},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {199-530},
  shortjournal = {INFORMS J. Comput.},
  title        = {A new branch-and-price-and-cut algorithm for one-dimensional bin-packing problems},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mathematical models and search algorithms for the
capacitated p-center problem. <em>IJOC</em>, <em>32</em>(2), 199–530.
(<a href="https://doi.org/10.1287/ijoc.2019.0889">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The capacitated p -center problem requires one to select p facilities from a set of candidates to service a number of customers, subject to facility capacity constraints, with the aim of minimizing the maximum distance between a customer and its associated facility. The problem is well known in the field of facility location, because of the many applications that it can model. In this paper, we solve it by means of search algorithms that iteratively seek the optimal distance by solving tailored subproblems. We present different mathematical formulations for the subproblems and improve them by means of several valid inequalities, including an effective one based on a 0–1 disjunction and the solution of subset sum problems. We also develop an alternative search strategy that finds a balance between traditional sequential search and binary search. This strategy limits the number of feasible subproblems to be solved and, at the same time, avoids large overestimates of the solution value, which are detrimental for the search. We evaluate the proposed techniques by means of extensive computational experiments on benchmark instances from the literature and new larger test sets. All instances from the literature with up to 402 vertices and integer distances are solved to proven optimality, including 13 open cases, and feasible solutions are found in 10 minutes for instances with up to 3,038 vertices.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2019.0889},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {199-530},
  shortjournal = {INFORMS J. Comput.},
  title        = {Mathematical models and search algorithms for the capacitated p-center problem},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multiobjective integer programming: Synergistic parallel
approaches. <em>IJOC</em>, <em>32</em>(2), 199–530. (<a
href="https://doi.org/10.1287/ijoc.2018.0875">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exactly solving multiobjective integer programming (MOIP) problems is often a very time-consuming process, especially for large and complex problems. Parallel computing has the potential to significantly reduce the time taken to solve such problems but only if suitable algorithms are used. The first of our new algorithms follows a simple technique that demonstrates impressive performance for its design. We then go on to introduce new theory for developing more efficient parallel algorithms. The theory utilises elements of the symmetric group to apply a permutation to the objective functions to assign different workloads and applies to algorithms that order the objective functions lexicographically. As a result, information and updated bounds can be shared in real time, creating a synergy between threads. We design and implement two algorithms that take advantage of such a theory. To properly analyse the running time of our three algorithms, we compare them against two existing algorithms from the literature and against using multiple threads within our chosen integer programming solver, CPLEX. This survey of six different parallel algorithms, to our knowledge the first of its kind, demonstrates the advantages of parallel computing. Across all problem types tested, our new algorithms are on par with existing algorithms on smaller cases and massively outperform the competition on larger cases. These new algorithms, and freely available implementations, allow the investigation of complex MOIP problems with four or more objectives.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2018.0875},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {199-530},
  shortjournal = {INFORMS J. Comput.},
  title        = {Multiobjective integer programming: Synergistic parallel approaches},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Presolve reductions in mixed integer programming.
<em>IJOC</em>, <em>32</em>(2), 199–530. (<a
href="https://doi.org/10.1287/ijoc.2018.0857">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mixed integer programming has become a very powerful tool for modeling and solving real-world planning and scheduling problems, with the breadth of applications appearing to be almost unlimited. A critical component in the solution of these mixed integer programs is a set of routines commonly referred to as presolve. Presolve can be viewed as a collection of preprocessing techniques that reduce the size of and, more importantly, improve the “strength” of the given model formulation, that is, the degree to which the constraints of the formulation accurately describe the underlying polyhedron of integer-feasible solutions. As our computational results will show, presolve is a key factor in the speed with which we can solve mixed integer programs and is often the difference between a model being intractable and solvable, in some cases easily solvable. In this paper we describe the presolve functionality in the Gurobi commercial mixed integer programming code. This includes an overview, or taxonomy of the different methods that are employed, as well as more-detailed descriptions of several of the techniques, with some of them appearing, to our knowledge, for the first time in the literature.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2018.0857},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {199-530},
  shortjournal = {INFORMS J. Comput.},
  title        = {Presolve reductions in mixed integer programming},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Piecewise linear function fitting via mixed-integer linear
programming. <em>IJOC</em>, <em>32</em>(2), 199–530. (<a
href="https://doi.org/10.1287/ijoc.2019.0890">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Piecewise linear (PWL) functions are used in a variety of applications. Computing such continuous PWL functions, however, is a challenging task. Software packages and the literature on PWL function fitting are dominated by heuristic methods. This is true for both fitting discrete data points and continuous univariate functions. The only exact methods rely on nonconvex model formulations. Exact methods compute continuous PWL function for a fixed number of breakpoints minimizing some distance function between the original function and the PWL function. An optimal PWL function can only be computed if the breakpoints are allowed to be placed freely and are not fixed to a set of candidate breakpoints. In this paper, we propose the first convex model for optimal continuous univariate PWL function fitting. Dependent on the metrics chosen, the resulting formulations are either mixed-integer linear programming or mixed-integer quadratic programming problems. These models yield optimal continuous PWL functions for a set of discrete data. On the basis of these convex formulations, we further develop an exact algorithm to fit continuous univariate functions. Computational results for benchmark instances from the literature demonstrate the superiority of the proposed convex models compared with state-of-the-art nonconvex models.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2019.0890},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {199-530},
  shortjournal = {INFORMS J. Comput.},
  title        = {Piecewise linear function fitting via mixed-integer linear programming},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Editorial board. <em>IJOC</em>, <em>32</em>(1), C2. (<a
href="https://doi.org/10.1287/ijoc.2020.eb.v3201">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.eb.v3201},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {C2},
  shortjournal = {INFORMS J. Comput.},
  title        = {Editorial board},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Note from the editor. <em>IJOC</em>, <em>32</em>(1), 1–2.
(<a href="https://doi.org/10.1287/ijoc.2019.0948">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJOC},
  author       = {Alice E. Smith},
  doi          = {10.1287/ijoc.2019.0948},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {1-2},
  shortjournal = {INFORMS J. Comput.},
  title        = {Note from the editor},
  volume       = {32},
  year         = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
