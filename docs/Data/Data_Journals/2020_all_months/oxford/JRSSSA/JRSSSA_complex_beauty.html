<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>JRSSSA_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="jrsssa---96">JRSSSA - 96</h2>
<ul>
<li><details>
<summary>
(2020). Contents of volume 183, 2020. <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>183</em>(4), 1845–1848. (<a
href="https://doi.org/10.1111/rssa.12610">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  doi     = {10.1111/rssa.12610},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {4},
  pages   = {1845-1848},
  title   = {Contents of volume 183, 2020},
  volume  = {183},
  year    = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Referees. <em>Journal of the Royal Statistical Society:
Series A (Statistics in Society)</em>, <em>183</em>(4), 1831–1836. (<a
href="https://doi.org/10.1111/rssa.12597">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  doi     = {10.1111/rssa.12597},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {4},
  pages   = {1831-1836},
  title   = {Referees},
  volume  = {183},
  year    = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Statistical data analysis using SAS 2nd edn m. G. Marasinghe
k. J. Koehler 2018 london pp., £63.99 ISBN 978-3-319-69238-8.
<em>Journal of the Royal Statistical Society: Series A (Statistics in
Society)</em>, <em>183</em>(4), 1829. (<a
href="https://doi.org/10.1111/rssa.12606">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Sebastian Dietz},
  doi     = {10.1111/rssa.12606},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {4},
  pages   = {1829},
  title   = {Statistical data analysis using SAS 2nd edn m. g. marasinghe k. j. koehler 2018 london pp., £63.99 ISBN 978-3-319-69238-8},
  volume  = {183},
  year    = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>183</em>(4), 1829–1830. (<a
href="https://doi.org/10.1111/rssa.12607">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Gian Luca Di Tanna},
  doi     = {10.1111/rssa.12607},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {4},
  pages   = {1829-1830},
  title   = {Modern adaptive randomized clinical trials: Statistical and practical aspects o. sverdlov (ed.) 2016 boca raton pp., $80 ISBN 978-1-482-23988-1},
  volume  = {183},
  year    = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). An introduction to data, everything you need to know about
AI: Big data and data science f. Corea 2019 cham springer nature xvi +
132 pp., £58.99 ISBN 978-3-030-04468-8 (e-book). <em>Journal of the
Royal Statistical Society: Series A (Statistics in Society)</em>,
<em>183</em>(4), 1828. (<a
href="https://doi.org/10.1111/rssa.12604">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Morteza Aalabaf-Sabaghi},
  doi     = {10.1111/rssa.12604},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {4},
  pages   = {1828},
  title   = {An introduction to data, everything you need to know about AI: Big data and data science f. corea 2019 cham springer nature xvi + 132 pp., £58.99 ISBN 978-3-030-04468-8 (e-book)},
  volume  = {183},
  year    = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modelling spatial and spatial–temporal data: A bayesian
approach r. P. Haining g. Li 2020 boca raton chapman and hall–CRC 608
pp., £76.80 (hardbound), £62.40 (e-book) ISBN 978-1-482-23742-9.
<em>Journal of the Royal Statistical Society: Series A (Statistics in
Society)</em>, <em>183</em>(4), 1828–1829. (<a
href="https://doi.org/10.1111/rssa.12605">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Anoop Chaturvedi},
  doi     = {10.1111/rssa.12605},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {4},
  pages   = {1828-1829},
  title   = {Modelling spatial and Spatial–Temporal data: A bayesian approach r. p. haining g. li 2020 boca raton chapman and Hall–CRC 608 pp., £76.80 (hardbound), £62.40 (e-book) ISBN 978-1-482-23742-9},
  volume  = {183},
  year    = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Book reviews. <em>Journal of the Royal Statistical Society:
Series A (Statistics in Society)</em>, <em>183</em>(4), 1827. (<a
href="https://doi.org/10.1111/rssa.12603">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  doi     = {10.1111/rssa.12603},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {4},
  pages   = {1827},
  title   = {Book reviews},
  volume  = {183},
  year    = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Willem van zwet, 1934–2020. <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>183</em>(4), 1823–1825. (<a
href="https://doi.org/10.1111/rssa.12602">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {P. J. Bickel and N. I. Fisher},
  doi     = {10.1111/rssa.12602},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {4},
  pages   = {1823-1825},
  title   = {Willem van zwet, 1934–2020},
  volume  = {183},
  year    = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Gerald joseph goodhardt, 1930–2020. <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>183</em>(4), 1821–1823. (<a
href="https://doi.org/10.1111/rssa.12601">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Chris Chatfield},
  doi     = {10.1111/rssa.12601},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {4},
  pages   = {1821-1823},
  title   = {Gerald joseph goodhardt, 1930–2020},
  volume  = {183},
  year    = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Christopher john skinner, 1953–2020. <em>Journal of the
Royal Statistical Society: Series A (Statistics in Society)</em>,
<em>183</em>(4), 1819–1821. (<a
href="https://doi.org/10.1111/rssa.12600">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Ray Chambers and Ian Diamond and Tim Holt and Jouni Kuha and Danny Pfeffermann and Natalie Shlomo and Pedro Nascimento Silva and Paul Smith and David Steel and Fiona Steele},
  doi     = {10.1111/rssa.12600},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {4},
  pages   = {1819-1821},
  title   = {Christopher john skinner, 1953–2020},
  volume  = {183},
  year    = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A non-parametric projection-based estimator for the
probability of causation, with application to water sanitation in kenya.
<em>Journal of the Royal Statistical Society: Series A (Statistics in
Society)</em>, <em>183</em>(4), 1793–1818. (<a
href="https://doi.org/10.1111/rssa.12548">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Current estimation methods for the probability of causation ‘PC’ make strong parametric assumptions or are inefficient. We derive a non-parametric influence-function-based estimator for a projection of PC, which allows for simple interpretation and valid inference by making weak structural assumptions. We apply our estimator to real data from an experiment in Kenya. This experiment found, by estimating the average treatment effect, that protecting water springs reduces childhood disease. However, before scaling up this intervention, it is important to determine whether it was the exposure, and not something else, that caused the outcome. Indeed, we find that some children, who were exposed to a high concentration of bacteria in drinking water and had a diarrhoeal disease, would probably have contracted the disease absent the exposure since the estimated PC for an average child in this study is 0.12 with a 95\% confidence interval of (0.11, 0.13). Our non-parametric method offers researchers a way to estimate PC, which is essential if we wish to determine not only the average treatment effect, but also whether an exposure probably caused the observed outcome.},
  archive  = {J},
  author   = {Maria Cuellar and Edward H. Kennedy},
  doi      = {10.1111/rssa.12548},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {4},
  pages    = {1793-1818},
  title    = {A non-parametric projection-based estimator for the probability of causation, with application to water sanitation in kenya},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Causes of effects via a bayesian model selection procedure.
<em>Journal of the Royal Statistical Society: Series A (Statistics in
Society)</em>, <em>183</em>(4), 1777–1792. (<a
href="https://doi.org/10.1111/rssa.12560">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In causal inference, and specifically in the causes-of-effects problem, one is interested in how to use statistical evidence to understand causation in an individual case, and in particular how to assess the so-called probability of causation . The answer involves the use of potential responses, which describe what would have happened to the outcome if we had observed a different value for the exposure. However, even given the best possible statistical evidence for the association between exposure and outcome, we can typically only provide bounds for the probability of causation. Dawid and his colleagues highlighted some fundamental conditions, namely exogeneity, comparability and sufficiency, that are required to obtain such bounds from experimental data. The aim of the present paper is to provide methods to find, in specific cases, the best subsample of the reference data set to satisfy these requirements. For this, we introduce a new variable, expressing the preference whether or not to be exposed, and we set the question up as a model selection problem. The best model is selected by using the marginal probability of the responses and a suitable prior over the model space. An application in the educational field is presented.},
  archive  = {J},
  author   = {Fabio Corradi and Monica Musio},
  doi      = {10.1111/rssa.12560},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {4},
  pages    = {1777-1792},
  title    = {Causes of effects via a bayesian model selection procedure},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Causal discovery of gene regulation with incomplete data.
<em>Journal of the Royal Statistical Society: Series A (Statistics in
Society)</em>, <em>183</em>(4), 1747–1775. (<a
href="https://doi.org/10.1111/rssa.12565">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Causal discovery algorithms aim to identify causal relations from observational data and have become a popular tool for analysing genetic regulatory systems. In this work, we applied causal discovery to obtain novel insights into the genetic regulation underlying head-and-neck squamous cell carcinoma. Some methodological challenges needed to be resolved first. The available data contained missing values, but most approaches to causal discovery require complete data. Hence, we propose a new procedure combining constraint-based causal discovery with multiple imputation. This is based on using Rubin&#39;s rules for pooling tests of conditional independence.  A second challenge was that causal discovery relies on strong assumptions and can be rather unstable. To assess the robustness of our results, we supplemented our investigation with sensitivity analyses, including a non-parametric bootstrap to quantify the variability of the estimated causal structures. We applied these methods to investigate how the high mobility group AT-Hook 2 (HMGA2) gene is incorporated in the protein 53 signalling pathway playing an important role in head-and-neck squamous cell carcinoma. Our results were quite stable and found direct associations between HMGA2 and other relevant proteins, but they did not provide clear support for the claim that HMGA2 itself is a key regulator gene.},
  archive  = {J},
  author   = {Ronja Foraita and Juliane Friemel and Kathrin Günther and Thomas Behrens and Jörn Bullerdiek and Rolf Nimzyk and Wolfgang Ahrens and Vanessa Didelez},
  doi      = {10.1111/rssa.12565},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {4},
  pages    = {1747-1775},
  title    = {Causal discovery of gene regulation with incomplete data},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Discovering causal structures in bayesian gaussian directed
acyclic graph models. <em>Journal of the Royal Statistical Society:
Series A (Statistics in Society)</em>, <em>183</em>(4), 1727–1745. (<a
href="https://doi.org/10.1111/rssa.12550">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Causal directed acyclic graphs (DAGs) are naturally tailored to represent biological signalling pathways. However, a causal DAG is only identifiable up to Markov equivalence if only observational data are available. Interventional data, based on exogenous perturbations of the system, can greatly improve identifiability. Since the gain of an intervention crucially depends on the intervened variables, a natural issue is devising efficient strategies for optimal causal discovery. We present a Bayesian active learning procedure for Gaussian DAGs which requires no subjective specification on the side of the user, explicitly takes into account the uncertainty on the space of equivalence classes (through the posterior distribution) and sequentially proposes the choice of the optimal intervention variable. In simulation experiments our method, besides surpassing designs based on a random choice of intervention nodes, shows decisive improvements over currently available algorithms and is competitive with the best alternative benchmarks. An important reason behind this strong performance is that, unlike non-Bayesian algorithms, our utility function naturally incorporates graph estimation uncertainty through the posterior edge inclusion probability. We also reanalyse the Sachs data on protein signalling pathways from an active learning perspective and show that DAG identification can be achieved by using only a subset of the available intervention samples.},
  archive  = {J},
  author   = {Federico Castelletti and Guido Consonni},
  doi      = {10.1111/rssa.12550},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {4},
  pages    = {1727-1745},
  title    = {Discovering causal structures in bayesian gaussian directed acyclic graph models},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Examining the causal mediating role of brain pathology on
the relationship between diabetes and cognitive impairment: The
cardiovascular health study. <em>Journal of the Royal Statistical
Society: Series A (Statistics in Society)</em>, <em>183</em>(4),
1705–1726. (<a href="https://doi.org/10.1111/rssa.12570">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The paper examines whether diabetes mellitus leads to incident mild cognitive impairment and dementia through brain hypoperfusion and white matter disease. We performed inverse odds ratio weighted causal mediation analyses to decompose the effect of diabetes on cognitive impairment into direct and indirect effects, and we found that approximately a third of the total effect of diabetes is mediated through vascular-related brain pathology. Our findings lend support for a common aetiological hypothesis regarding incident cognitive impairment, which is that diabetes increases the risk of clinical cognitive impairment in part by impacting the vasculature of the brain.},
  archive  = {J},
  author   = {Ryan M. Andrews and Ilya Shpitser and Oscar Lopez and William T. Longstreth and Paulo H. M. Chaves and Lewis Kuller and Michelle C. Carlson},
  doi      = {10.1111/rssa.12570},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {4},
  pages    = {1705-1726},
  title    = {Examining the causal mediating role of brain pathology on the relationship between diabetes and cognitive impairment: The cardiovascular health study},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Health effects of power plant emissions through ambient air
quality. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>183</em>(4), 1677–1703. (<a
href="https://doi.org/10.1111/rssa.12547">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Coal burning power plants are a frequent target of regulatory programmes because of their emission of chemicals that are known precursors to the formation of ambient particulate air pollution. Health impact assessments of emissions from coal power plants typically rely on assumed causal relationships between emissions, ambient pollution and health, many of which have never been empirically verified. We offer a novel statistical evaluation of some of these presumed causal relationships, integrating the formality of causal inference methods with repurposed tools from atmospheric science to accommodate the central challenge of long-range pollution transport of emissions from power plants to exposed populations. The statistical approach follows recent work on Bayesian methods for deploying principal stratification and causal mediation analysis in tandem to characterize the extent to which decreased sulphur dioxide emissions from 410 power plants across the USA impact mortality and hospitalization outcomes across Medicare beneficiaries residing across 12370 locations in a manner that is mediated through reductions of ambient fine particulate pollution. The result is the first epidemiological investigation integrating causal inference methodology with direct measurements of coal emissions, pollution transport, ambient pollution and human health in a single analysis, indicating the potential for data science at the intersection of statistics, epidemiology and atmospheric science.},
  archive  = {J},
  author   = {Chanmin Kim and Lucas R. F. Henneman and Christine Choirat and Corwin M. Zigler},
  doi      = {10.1111/rssa.12547},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {4},
  pages    = {1677-1703},
  title    = {Health effects of power plant emissions through ambient air quality},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Causal inference, social networks and chain graphs.
<em>Journal of the Royal Statistical Society: Series A (Statistics in
Society)</em>, <em>183</em>(4), 1659–1676. (<a
href="https://doi.org/10.1111/rssa.12594">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Traditionally, statistical inference and causal inference on human subjects rely on the assumption that individuals are independently affected by treatments or exposures. However, recently there has been increasing interest in settings, such as social networks, where individuals may interact with one another such that treatments may spill over from the treated individual to their social contacts and outcomes may be contagious. Existing models proposed for causal inference using observational data from networks of interacting individuals have two major shortcomings. First, they often require a level of granularity in the data that is infeasible in practice to collect in most settings and, second, the models are high dimensional and often too big to fit to the available data. We illustrate and justify a parsimonious parameterization for network data with interference and contagion. Our parameterization corresponds to a particular family of graphical models known as chain graphs. We argue that, in some settings, chain graph models approximate the marginal distribution of a snapshot of a longitudinal data-generating process on interacting units. We illustrate the use of chain graphs for causal inference about collective decision making in social networks by using data from US Supreme Court decisions between 1994 and 2004 and in simulations.},
  archive  = {J},
  author   = {Elizabeth L. Ogburn and Ilya Shpitser and Youjin Lee},
  doi      = {10.1111/rssa.12594},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {4},
  pages    = {1659-1676},
  title    = {Causal inference, social networks and chain graphs},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Identification and sensitivity analysis of contagion effects
in randomized placebo-controlled trials. <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>183</em>(4), 1637–1657. (<a
href="https://doi.org/10.1111/rssa.12528">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In social science research, interference between units is the rule rather than the exception. Contagion represents one key causal mechanism of such spillover effects, where one&#39;s treatment affects the outcome of another individual indirectly by changing the treated unit&#39;s own outcome. Alternatively, the treatment of one individual can affect the outcome of another person through other mechanisms. We consider the identification and sensitivity analysis of contagion effects. We analyse a randomized placebo-controlled trial of the get out the vote campaign, in which canvassers were sent to randomly selected households with two registered voters but encouraged only one voter within each household to turn out in an upcoming election. To address the problem of non-compliance, the experiment includes a placebo arm, in which canvassers encourage voters to recycle. We show how to identify and estimate the average contagion and direct effects by decomposing the average spillover effect. Our analysis examines whether canvassing increases the turnout of a non-contacted voter by altering the vote intention of a contacted voter or through other mechanisms. To address the potential violation of key identification assumptions, we propose non-parametric and parametric sensitivity analyses. We find robust contagion effects among some households.},
  archive  = {J},
  author   = {Kosuke Imai and Zhichao Jiang},
  doi      = {10.1111/rssa.12528},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {4},
  pages    = {1637-1657},
  title    = {Identification and sensitivity analysis of contagion effects in randomized placebo-controlled trials},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Is being an only child harmful to psychological health?:
Evidence from an instrumental variable analysis of china’s one-child
policy. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>183</em>(4), 1615–1635. (<a
href="https://doi.org/10.1111/rssa.12595">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The paper evaluates the effects of being an only child in a family on psychological health, leveraging data on the one-child policy in China. We use an instrumental variable approach to address the potential unmeasured confounding between the fertility decision and psychological health, where the instrumental variable is an index of the intensity of the implementation of the policy. We establish an analytical link between the local instrumental variable approach and principal stratification to accommodate the continuous instrumental variable. Within the principal stratification framework, we postulate a Bayesian hierarchical model to infer various causal estimands of policy interest while adjusting for the clustering data structure. We apply the method to the data from the China Family Panel Studies and find small but statistically significant negative effects of being an only child on self-reported psychological health for some subpopulations. Our analysis reveals treatment effect heterogeneity with respect to both observed and unobserved characteristics. In particular, urban males suffer the most from being only children, and the negative effect has larger magnitude if the families were more resistant to the one-child policy. We also conduct a sensitivity analysis to assess the key instrumental variable assumption.},
  archive  = {J},
  author   = {Shuxi Zeng and Fan Li and Peng Ding},
  doi      = {10.1111/rssa.12595},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {4},
  pages    = {1615-1635},
  title    = {Is being an only child harmful to psychological health?: Evidence from an instrumental variable analysis of china&#39;s one-child policy},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Assessing causal effects of extra compulsory learning on
college students’ academic performances. <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>183</em>(4), 1595–1614. (<a
href="https://doi.org/10.1111/rssa.12599">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In Italian state universities candidate freshmen must take an entrance examination. Candidates who obtain a test score less than or equal to a pre-fixed threshold may enrol at the university but must comply with an additional compulsory educational obligation, called obblighi formativi aggiuntivi (OFA).  The OFA assignment rule appeals to a (sharp) regression discontinuity design with the entrance examination score acting as the forcing variable.  We assess causal effects of OFA status by using data from a school of engineering of a specific Italian state university. For subpopulations of units for which our regression discontinuity design can be described as a local randomized experiment, we draw inference on the causal effects of OFA on students’ academic performances measured by using two variables: the number of university credits awarded at the end of the first academic year and the corresponding average grade. These outcome variables suffer from the problem of truncation by ‘death’, because neither is defined for students who decide not to enrol. Moreover, nor is the average grade defined for students who enrol but do not either take or pass any examination in the first academic year.  We deal with these issues by using the framework of principal stratification and adopting a Bayesian approach to inference. We find some evidence that the receipt of OFA may negatively affect students’ academic performances, although the posterior distributions of the causal estimands have high variability.},
  archive  = {J},
  author   = {Federica Licari and Alessandra Mattei},
  doi      = {10.1111/rssa.12599},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {4},
  pages    = {1595-1614},
  title    = {Assessing causal effects of extra compulsory learning on college students’ academic performances},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bayesian econometric modelling of observational data for
cost-effectiveness analysis: Establishing the value of negative pressure
wound therapy in the healing of open surgical wounds. <em>Journal of the
Royal Statistical Society: Series A (Statistics in Society)</em>,
<em>183</em>(4), 1575–1593. (<a
href="https://doi.org/10.1111/rssa.12596">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In the absence of evidence from randomized controlled trials on the relative effectiveness of treatments, cost-effectiveness analyses increasingly use observational data instead. Treatment assignment is not, however, randomized, and naive estimates of the treatment effect may be biased. To deal with this bias, one may need to adjust for observed and unobserved confounders. In this work we explore and discuss the challenges of these adjustment strategies within a case-study of negative pressure wound therapy (NPWT) for the treatment of surgical wounds healing by secondary intention. We could not demonstrate that existing uncontrolled confounding affects NPWT effectiveness, and thus there was no evidence that NPWT was cost effective compared with standard dressings for the treatment of surgical wounds healing by secondary intention.},
  archive  = {J},
  author   = {Pedro Saramago and Karl Claxton and Nicky J. Welton and Marta Soares},
  doi      = {10.1111/rssa.12596},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {4},
  pages    = {1575-1593},
  title    = {Bayesian econometric modelling of observational data for cost-effectiveness analysis: Establishing the value of negative pressure wound therapy in the healing of open surgical wounds},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Flexible instrumental variable distributional regression.
<em>Journal of the Royal Statistical Society: Series A (Statistics in
Society)</em>, <em>183</em>(4), 1553–1574. (<a
href="https://doi.org/10.1111/rssa.12598">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {We tackle two limitations of standard instrumental variable regression in experimental and observational studies: restricted estimation to the conditional mean of the outcome and the assumption of a linear relationship between regressors and outcome. More flexible regression approaches that solve these limitations have already been developed but have not yet been adopted in causality analysis. The paper develops an instrumental variable estimation procedure building on the framework of generalized additive models for location, scale and shape. This enables modelling all distributional parameters of potentially complex response distributions and non-linear relationships between the explanatory variables, instrument and outcome. The approach shows good performance in simulations and is applied to a study that estimates the effect of rural electrification on the employment of females and males in the South African province of KwaZulu-Natal. We find positive marginal effects for the mean for employment of females rates, negative effects for employment of males and a reduced conditional standard deviation for both, indicating homogenization in employment rates due to the electrification programme. Although none of the effects are statistically significant, the application demonstrates the potentials of using generalized additive models for location, scale and shape in instrumental variable regression for both to account for endogeneity and to estimate treatment effects beyond the mean.},
  archive  = {J},
  author   = {Guillermo Briseño Sanchez and Maike Hohberg and Andreas Groll and Thomas Kneib},
  doi      = {10.1111/rssa.12598},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {4},
  pages    = {1553-1574},
  title    = {Flexible instrumental variable distributional regression},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Instrumental variable methods using dynamic interventions.
<em>Journal of the Royal Statistical Society: Series A (Statistics in
Society)</em>, <em>183</em>(4), 1523–1551. (<a
href="https://doi.org/10.1111/rssa.12563">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Recent work on dynamic interventions has greatly expanded the range of causal questions that researchers can study. Simultaneously, this work has weakened identifying assumptions, yielding effects that are more practically relevant. Most work in dynamic interventions to date has focused on settings where we directly alter some unconfounded treatment of interest. In policy analysis, decision makers rarely have this level of control over behaviours or access to experimental data. Instead, they are often faced with treatments that they can affect only indirectly and whose effects must be learned from observational data. We propose new estimands and estimators of causal effects based on dynamic interventions with instrumental variables. This method does not rely on parametric models and does not require an experiment. Instead, we estimate the effect of treatment induced by a dynamic intervention on an instrument. This robustness should reassure policy makers that these estimates can be used to inform policy effectively. We demonstrate the usefulness of this estimation strategy in a case-study examining the effect of visitation on recidivism.},
  archive  = {J},
  author   = {Jacqueline A. Mauro and Edward H. Kennedy and Daniel Nagin},
  doi      = {10.1111/rssa.12563},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {4},
  pages    = {1523-1551},
  title    = {Instrumental variable methods using dynamic interventions},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stronger instruments and refined covariate balance in an
observational study of the effectiveness of prompt admission to
intensive care units. <em>Journal of the Royal Statistical Society:
Series A (Statistics in Society)</em>, <em>183</em>(4), 1501–1521. (<a
href="https://doi.org/10.1111/rssa.12437">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Instrumental variable methods, subject to appropriate identification assumptions, enable consistent estimation of causal effects in the presence of unobserved confounding. Near–far matching has been proposed as one analytic method to improve inference by strengthening the effect of the instrument on the exposure and balancing observable characteristics between groups of subjects with low and high values of the instrument. However, in settings with hierarchical data (e.g. patients nested within hospitals), or where several covariate interactions must be balanced, conventional near–far matching algorithms may fail to achieve the requisite covariate balance. We develop a new matching algorithm, that combines near–far matching with refined covariate balance, to balance large numbers of nominal covariates while also strengthening the instrumental variable. This extension of near–far matching is motivated by a case-study that aims to identify the causal effect of prompt admission to an intensive care unit on 7-day and 28-day mortality.},
  archive  = {J},
  author   = {Luke Keele and Steve Harris and Samuel D. Pimentel and Richard Grieve},
  doi      = {10.1111/rssa.12437},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {4},
  pages    = {1501-1521},
  title    = {Stronger instruments and refined covariate balance in an observational study of the effectiveness of prompt admission to intensive care units},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Causal inference with multistate models—estimands and
estimators of the population attributable fraction. <em>Journal of the
Royal Statistical Society: Series A (Statistics in Society)</em>,
<em>183</em>(4), 1479–1500. (<a
href="https://doi.org/10.1111/rssa.12486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The population attributable fraction (PAF) is a popular epidemiological measure for the burden of a harmful exposure within a population. It is often interpreted causally as the proportion of preventable cases after an elimination of exposure. Originally, the PAF was defined for cohort studies of fixed length with a baseline exposure or cross-sectional studies. An extension of the definition to complex time-to-event data is not straightforward. We revise the proposed approaches in the literature and provide a clear concept of the PAF for these data situations. The conceptualization is achieved by a proper differentiation between estimands and estimators as well as causal effect measures and measures of association.},
  archive  = {J},
  author   = {Maja von Cube and Martin Schumacher and Martin Wolkewitz},
  doi      = {10.1111/rssa.12486},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {4},
  pages    = {1479-1500},
  title    = {Causal inference with multistate models—estimands and estimators of the population attributable fraction},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Brand versus generic: Addressing non-adherence, secular
trends and non-overlap. <em>Journal of the Royal Statistical Society:
Series A (Statistics in Society)</em>, <em>183</em>(4), 1461–1478. (<a
href="https://doi.org/10.1111/rssa.12573">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Whereas generic drugs offer a cost-effective alternative to brand name drugs, regulators need a method to assess therapeutic equivalence in a post-market setting. We develop such a method in the context of assessing the therapeutic equivalence of immediate release venlafaxine, based on a large insurance claims data set provided by OptumLabs \circledR . To address this question properly, our methodology must deal with issues of non-adherence, secular trends in health outcomes and lack of treatment overlap due to sharp uptake of the generic drug once it becomes available. We define, identify (under assumptions) and estimate (using G -computation) a causal effect for a time-to-event outcome by extending regression discontinuity to survival curves. We do not find evidence for a lack of therapeutic equivalence of brand and generic immediate release venlafaxine.},
  archive  = {J},
  author   = {Lamar Hunt and Irene B. Murimi and Jodi B. Segal and Marissa J. Seamans and Daniel O. Scharfstein and and Ravi Varadhan},
  doi      = {10.1111/rssa.12573},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {4},
  pages    = {1461-1478},
  title    = {Brand versus generic: Addressing non-adherence, secular trends and non-overlap},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A bayesian multivariate factor analysis model for evaluating
an intervention by using observational time series data on multiple
outcomes. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>183</em>(4), 1437–1459. (<a
href="https://doi.org/10.1111/rssa.12569">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {A problem that is frequently encountered in many areas of scientific research is that of estimating the effect of a non-randomized binary intervention on an outcome of interest by using time series data on units that received the intervention (‘treated’) and units that did not (‘controls’). One popular estimation method in this setting is based on the factor analysis (FA) model. The FA model is fitted to the preintervention outcome data on treated units and all the outcome data on control units, and the counterfactual treatment-free post-intervention outcomes of the former are predicted from the fitted model. Intervention effects are estimated as the observed outcomes minus these predicted counterfactual outcomes. We propose a model that extends the FA model for estimating intervention effects by jointly modelling the multiple outcomes to exploit shared variability, and assuming an auto-regressive structure on factors to account for temporal correlations in the outcome. Using simulation studies, we show that the method proposed can improve the precision of the intervention effect estimates and achieve better control of the type I error rate (compared with the FA model), especially when either the number of preintervention measurements or the number of control units is small. We apply our method to estimate the effect of stricter alcohol licensing policies on alcohol-related harms.},
  archive  = {J},
  author   = {Pantelis Samartsidis and Shaun R. Seaman and Silvia Montagna and André Charlett and Matthew Hickman and Daniela De Angelis},
  doi      = {10.1111/rssa.12569},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {4},
  pages    = {1437-1459},
  title    = {A bayesian multivariate factor analysis model for evaluating an intervention by using observational time series data on multiple outcomes},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal matching approaches in health policy evaluations
under rolling enrolment. <em>Journal of the Royal Statistical Society:
Series A (Statistics in Society)</em>, <em>183</em>(4), 1411–1435. (<a
href="https://doi.org/10.1111/rssa.12521">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Comparison group selection is paramount for health policy evaluations, where randomization is seldom practicable. Rolling enrolment is common in these evaluations, introducing challenges for comparison group selection and inference. We propose a novel framework, GroupMatch, for comparison group selection under rolling enrolment, founded on the notion of time agnosticism: two subjects with similar outcome trajectories but different enrolment periods may be more prognostically similar and produce better inference if matched, than two subjects with the same enrolment period but different pre-enrolment trajectories. We articulate the conceptual advantages of this framework and demonstrate its efficacy in a simulation study and in an application to a study of the effect of falls in Medicare Advantage patients.},
  archive  = {J},
  author   = {Samuel D. Pimentel and Lauren Vollmer Forrow and Jonathan Gellar and Jiaqi Li},
  doi      = {10.1111/rssa.12521},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {4},
  pages    = {1411-1435},
  title    = {Optimal matching approaches in health policy evaluations under rolling enrolment},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Direct and stable weight adjustment in non-experimental
studies with multivalued treatments: Analysis of the effect of an
earthquake on post-traumatic stress. <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>183</em>(4), 1387–1410. (<a
href="https://doi.org/10.1111/rssa.12561">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In February 2010, a massive earthquake struck Chile, causing devastation in certain parts of the country, affecting other areas, and leaving territories untouched. 2 months after the earthquake, Chile&#39;s Ministry of Social Development reinterviewed a representative subsample of its National Socioeconomic Characterization Survey, which had been completed 2 months before the earthquake, thereby creating a prospective longitudinal survey with detailed information of the same individuals before and after the earthquake. We use a new weighting method for non-experimental studies with multivalued treatments to estimate the effect of levels of exposure to the earthquake on post-traumatic stress. Unlike common weighting approaches for multivalued treatments, this new method does not require explicit modelling of the generalized propensity score and instead focuses on directly balancing the covariates across the multivalued treatments with weights that have minimum variance. As a result, the weighting estimator is stable and approximately unbiased. Furthermore, the weights are constrained to avoid model extrapolation. We illustrate this new method in a simulation study, with both categorical and continuous treatments. The results show that directly targeting balance instead of explicitly modelling the treatment assignment probabilities tends to provide the best results in terms of bias and root-mean-square error. Using this method, we estimate the effect of the intensity of the earthquake on post-traumatic stress. We implement this method in the new package msbw for R.},
  archive  = {J},
  author   = {María de los Angeles Resa and José R. Zubizarreta},
  doi      = {10.1111/rssa.12561},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {4},
  pages    = {1387-1410},
  title    = {Direct and stable weight adjustment in non-experimental studies with multivalued treatments: Analysis of the effect of an earthquake on post-traumatic stress},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Performance assessment as an application of causal
inference. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>183</em>(4), 1363–1385. (<a
href="https://doi.org/10.1111/rssa.12529">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Institutions in healthcare, education and other public services are under constant pressure to perform to high standards and with efficiency. Assessment of their performance is often problematic because it either ignores important background variables of their patients, students or clients (the casemix), or adjusts for them in a way that is not equitable or transparent. We apply a method of indirect standardization motivated by the potential outcomes framework, in which we consider the hypothetical scenario of an institution&#39;s case-load being dispersed for treatment throughout the domain of assessment (the country&#39;s institutions). The target of estimation is the difference of the means of the outcomes in the realized and hypothetical settings. The method is applied to estimating the prevalence of bronchopulmonary dysplasia in extremely preterm-born infants in the neonatal units and their networks in Great Britain in 2017. The prevalence of bronchopulmonary dysplasia is an audit measure in the UK National Neonatal Audit Programme.},
  archive  = {J},
  author   = {Nicholas T. Longford},
  doi      = {10.1111/rssa.12529},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {4},
  pages    = {1363-1385},
  title    = {Performance assessment as an application of causal inference},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Using hidden information and performance level boundaries to
study student–teacher assignments: Implications for estimating teacher
causal effects. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>183</em>(4), 1333–1362. (<a
href="https://doi.org/10.1111/rssa.12533">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {A common problem in educational evaluation is estimating causal effects of interventions from non-experimental data on students. Scores from standardized achievement tests often are used to adjust for differences in background characteristics of students in different non-experimental groups. An open question is whether, and how, these adjustments should account for the errors in test scores as measures of latent achievement. The answer depends on what information was used to assign students to non-experimental groups. Using a case-study of estimating teacher effects on student achievement, we develop two novel empirical tests about what information is used to assign students to teachers. We demonstrate that assignments are influenced by both information that is unobserved by the researcher, and error prone test scores. We develop a model that is appropriate for this complex selection mechanism and compare its results with common simpler estimators. We discuss implications for the broader problem of causal modelling with error prone confounders.},
  archive  = {J},
  author   = {J. R. Lockwood and D. McCaffrey},
  doi      = {10.1111/rssa.12533},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {4},
  pages    = {1333-1362},
  title    = {Using hidden information and performance level boundaries to study student–teacher assignments: Implications for estimating teacher causal effects},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Preface to the papers on “causal inference from
non-experimental studies: Challenges, developments and applications.”
<em>Journal of the Royal Statistical Society: Series A (Statistics in
Society)</em>, <em>183</em>(4), 1329–1332. (<a
href="https://doi.org/10.1111/rssa.12608">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Alessandra Mattei and Bianca L. De Stavola and Fabrizia Mealli},
  doi     = {10.1111/rssa.12608},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {4},
  pages   = {1329-1332},
  title   = {Preface to the papers on ‘Causal inference from non-experimental studies: Challenges, developments and applications’},
  volume  = {183},
  year    = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Book reviews. <em>Journal of the Royal Statistical Society:
Series A (Statistics in Society)</em>, <em>183</em>(3), 1323–1326. (<a
href="https://doi.org/10.1111/rssa.12585">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  doi     = {10.1111/rssa.12585},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {3},
  pages   = {1323-1326},
  title   = {Book reviews},
  volume  = {183},
  year    = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). T. M. F. Smith, 1934–2019; harvey goldstein, 1939–2020;
allan henry seheult, 1942–2019;john francis bithell, 1939–2020; m. H. A.
Davis, 1945–2020. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>183</em>(3), 1313–1322. (<a
href="https://doi.org/10.1111/rssa.12580">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  doi     = {10.1111/rssa.12580},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {3},
  pages   = {1313-1322},
  title   = {T. m. f. smith, 1934–2019; harvey goldstein, 1939–2020; allan henry seheult, 1942–2019;John francis bithell, 1939–2020; m. h. a. davis, 1945–2020},
  volume  = {183},
  year    = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improving external validity of epidemiologic cohort
analyses: A kernel weighting approach. <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>183</em>(3), 1293–1311. (<a
href="https://doi.org/10.1111/rssa.12564">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {For various reasons, cohort studies generally forgo probability sampling required to obtain population representative samples. However, such cohorts lack population representativeness, which invalidates estimates of population prevalences for novel health factors that are only available in cohorts. To improve external validity of estimates from cohorts, we propose a kernel weighting (KW) approach that uses survey data as a reference to create pseudoweights for cohorts. A jackknife variance is proposed for the KW estimates. In simulations, the KW method outperformed two existing propensity-score-based weighting methods in mean-squared error while maintaining confidence interval coverage. We applied all methods to estimating US population mortality and prevalences of various diseases from the non-representative US National Institutes of Health–American Association of Retired Persons cohort, using the sample from the US-representative National Health Interview Survey as the reference. Assuming that the survey estimates are correct, the KW approach yielded generally less biased estimates compared with the existing propensity-score-based weighting methods.},
  archive  = {J},
  author   = {Lingxiao Wang and Barry I. Graubard and Hormuzd A. Katki and and Yan Li},
  doi      = {10.1111/rssa.12564},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {3},
  pages    = {1293-1311},
  title    = {Improving external validity of epidemiologic cohort analyses: A kernel weighting approach},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A functional approach to small area estimation of the
relative median poverty gap. <em>Journal of the Royal Statistical
Society: Series A (Statistics in Society)</em>, <em>183</em>(3),
1273–1291. (<a href="https://doi.org/10.1111/rssa.12562">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {We consider the estimation of the relative median poverty gap (RMPG) at the level of Italian provinces by using data from the European Union Survey on Income and Living Conditions. The overall sample size does not allow reliable estimation of income-distribution-related parameters at the provincial level; therefore, small area estimation techniques must be used. The specific challenge in estimating the RMPG is that, as it summarizes the income distribution of the poor, samples for estimating it for small subpopulations are even smaller than those available in other parameters. We propose a Bayesian strategy where various parameters summarizing the distribution of income at the provincial level are modelled by means of a multivariate small area model. To estimate the RMPG, we relate these parameters to a distribution describing income, namely the generalized beta distribution of the second kind. Posterior draws from the multivariate model are then used to generate draws for the distribution&#39;s area-specific parameters and then of the RMPG defined as their functional.},
  archive  = {J},
  author   = {Enrico Fabrizi and Maria Rosaria Ferrante and Carlo Trivisano},
  doi      = {10.1111/rssa.12562},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {3},
  pages    = {1273-1291},
  title    = {A functional approach to small area estimation of the relative median poverty gap},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A causal inference framework for cancer cluster
investigations using publicly available data. <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>183</em>(3), 1253–1272. (<a
href="https://doi.org/10.1111/rssa.12567">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Often, a community becomes alarmed when high rates of cancer are noticed, and residents suspect that the cancer cases could be caused by a known source of hazard. In response, the US Centers for Disease Control and Prevention recommend that departments of health perform a standardized incidence ratio (SIR) analysis to determine whether the observed cancer incidence is higher than expected. This approach has several limitations that are well documented in the existing literature. We propose a novel causal inference framework for cancer cluster investigations, rooted in the potential outcomes framework. Assuming that a source of hazard representing a potential cause of increased cancer rates in the community is identified a priori , we focus our approach on a causal inference estimand which we call the causal SIR. The causal SIR is a ratio defined as the expected cancer incidence in the exposed population divided by the expected cancer incidence for the same population under the (counterfactual) scenario of no exposure. To estimate the causal SIR we need to overcome two main challenges: first, we must identify unexposed populations that are as similar as possible to the exposed population to inform estimation of the expected cancer incidence under the counterfactual scenario of no exposure, and, second, publicly available data on cancer incidence for these unexposed populations are often available at a much higher level of spatial aggregation (e.g. county) than what is desired (e.g. census block group). We overcome the first challenge by relying on matching. We overcome the second challenge by building a Bayesian hierarchical model that borrows information from other sources to impute cancer incidence at the desired level of spatial aggregation. In simulations, our statistical approach was shown to provide dramatically improved results, i.e. less bias and better coverage, than the current approach to SIR analyses. We apply our proposed approach to investigate whether trichloroethylene vapour exposure has caused increased cancer incidence in Endicott, New York.},
  archive  = {J},
  author   = {Rachel C. Nethery and Yue Yang and Anna J. Brown and Francesca Dominici},
  doi      = {10.1111/rssa.12567},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {3},
  pages    = {1253-1272},
  title    = {A causal inference framework for cancer cluster investigations using publicly available data},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Model-based clustering and analysis of life history data.
<em>Journal of the Royal Statistical Society: Series A (Statistics in
Society)</em>, <em>183</em>(3), 1231–1251. (<a
href="https://doi.org/10.1111/rssa.12575">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Methods and models for longitudinal data with categorical, multi-dimensional outcomes are quite limited, but they are essential to the study of life histories. For example, in the Swiss Household Panel, information on the co-residence and professional status of several thousand individuals is available through to age 45 years. Interest centres on the time and order of life course events such as having children and working full or part time and the duration of the phases that they delineate. With data of this type, optimal matching and clustering algorithms relying on a distance metric or parametric models of duration in a competing risks framework are used; the appropriateness of each derives from competing goals and orientation. We prefer model-based approaches when certain goals are paramount: simulation of individual trajectories; adjusting for time-dependent covariates; handling multistate trajectories and missing outcomes. Several of these goals are particularly challenging when the number of states is of moderate size, and many transitions are infrequent and/or time inhomogeneous. Using the Swiss Household Panel, we demonstrate the appropriateness of latent class growth curve models for analysing sequence data. In particular, models including heterogeneous dependence structure provide new techniques for assessing goodness of fit as well as yield insights into social processes.},
  archive  = {J},
  author   = {Marc A. Scott and Kaushik Mohan and Jacques-Antoine Gauthier},
  doi      = {10.1111/rssa.12575},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {3},
  pages    = {1231-1251},
  title    = {Model-based clustering and analysis of life history data},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Temporal disaggregation of overlapping noisy quarterly data:
Estimation of monthly output from UK value-added tax data. <em>Journal
of the Royal Statistical Society: Series A (Statistics in Society)</em>,
<em>183</em>(3), 1211–1230. (<a
href="https://doi.org/10.1111/rssa.12568">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The paper derives monthly estimates of business sector output in the UK from rolling quarterly value-added tax based turnover data. The administrative nature of the value-added tax data implies that their use could ultimately yield a more precise and granular picture of output across the economy. However, they show two particular features which complicate their exploitation: they are overlapping and subject to substantial noise. This motivates our choice of a multivariate unobserved components model for filtering and disaggregating temporally the aggregate figures. After illustrating our method by using one industry as a case-study, we estimate monthly seasonally adjusted gross output figures for the 75 industries for which the data are available. Our results show material differences from the existing output profile.},
  archive  = {J},
  author   = {Paul Labonne and Martin Weale},
  doi      = {10.1111/rssa.12568},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {3},
  pages    = {1211-1230},
  title    = {Temporal disaggregation of overlapping noisy quarterly data: Estimation of monthly output from UK value-added tax data},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multilevel network meta-regression for population-adjusted
treatment comparisons. <em>Journal of the Royal Statistical Society:
Series A (Statistics in Society)</em>, <em>183</em>(3), 1189–1210. (<a
href="https://doi.org/10.1111/rssa.12579">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Standard network meta-analysis (NMA) and indirect comparisons combine aggregate data from multiple studies on treatments of interest, assuming that any effect modifiers are balanced across populations. Population adjustment methods relax this assumption using individual patient data from one or more studies. However, current matching-adjusted indirect comparison and simulated treatment comparison methods are limited to pairwise indirect comparisons and cannot predict into a specified target population. Existing meta-regression approaches incur aggregation bias. We propose a new method extending the standard NMA framework. An individual level regression model is defined, and aggregate data are fitted by integrating over the covariate distribution to form the likelihood. Motivated by the complexity of the closed form integration, we propose a general numerical approach using quasi-Monte-Carlo integration. Covariate correlation structures are accounted for by using copulas. Crucially for decision making, comparisons may be provided in any target population with a given covariate distribution. We illustrate the method with a network of plaque psoriasis treatments. Estimated population-average treatment effects are similar across study populations, as differences in the distributions of effect modifiers are small. A better fit is achieved than a random effects NMA, uncertainty is substantially reduced by explaining within- and between-study variation, and estimates are more interpretable.},
  archive  = {J},
  author   = {David M. Phillippo and Sofia Dias and A. E. Ades and Mark Belger and Alan Brnabic and Alexander Schacht and Daniel Saure and Zbigniew Kadziola and Nicky J. Welton},
  doi      = {10.1111/rssa.12579},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {3},
  pages    = {1189-1210},
  title    = {Multilevel network meta-regression for population-adjusted treatment comparisons},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Longevity forecasting by socio-economic groups using
compositional data analysis. <em>Journal of the Royal Statistical
Society: Series A (Statistics in Society)</em>, <em>183</em>(3),
1167–1187. (<a href="https://doi.org/10.1111/rssa.12555">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Several Organisation for Economic Co-operation and Development countries have recently implemented an automatic link between the statutory retirement age and life expectancy for the total population to ensure sustainability in their pension systems due to increasing life expectancy. As significant mortality differentials are observed across socio-economic groups, future changes in these differentials will determine whether some socio-economic groups drive increases in the retirement age, leaving other groups with fewer pensionable years. We forecast life expectancy by socio-economic groups and compare the forecast performance of competing models by using Danish mortality data and find that the most accurate model assumes a common mortality trend. Life expectancy forecasts are used to analyse the consequences of a pension system where the statutory retirement age is increased when total life expectancy is increasing.},
  archive  = {J},
  author   = {S⊘ren Kjærgaard and Yunus Emre Ergemen and Marie-Pier Bergeron-Boucher and Jim Oeppen and Malene Kallestrup-Lamb},
  doi      = {10.1111/rssa.12555},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {3},
  pages    = {1167-1187},
  title    = {Longevity forecasting by socio-economic groups using compositional data analysis},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). New statistical metrics for multisite replication projects.
<em>Journal of the Royal Statistical Society: Series A (Statistics in
Society)</em>, <em>183</em>(3), 1145–1166. (<a
href="https://doi.org/10.1111/rssa.12572">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Increasingly, researchers are attempting to replicate published original studies by using large, multisite replication projects, at least 134 of which have been completed or are on going. These designs are promising to assess whether the original study is statistically consistent with the replications and to reassess the strength of evidence for the scientific effect of interest. However, existing analyses generally focus on single replications; when applied to multisite designs, they provide an incomplete view of aggregate evidence and can lead to misleading conclusions about replication success. We propose new statistical metrics representing firstly the probability that the original study&#39;s point estimate would be at least as extreme as it actually was, if in fact the original study were statistically consistent with the replications, and secondly the estimated proportion of population effects agreeing in direction with the original study. Generalized versions of the second metric enable consideration of only meaningfully strong population effects that agree in direction, or alternatively that disagree in direction, with the original study. These metrics apply when there are at least 10 replications (unless the heterogeneity estimate τ ^ = 0 , in which case the metrics apply regardless of the number of replications). The first metric assumes normal population effects but appears robust to violations in simulations; the second is distribution free. We provide R packages (Replicate and MetaUtility).},
  archive  = {J},
  author   = {Maya B. Mathur and Tyler J. VanderWeele},
  doi      = {10.1111/rssa.12572},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {3},
  pages    = {1145-1166},
  title    = {New statistical metrics for multisite replication projects},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Selecting a scale for spatial confounding adjustment.
<em>Journal of the Royal Statistical Society: Series A (Statistics in
Society)</em>, <em>183</em>(3), 1121–1143. (<a
href="https://doi.org/10.1111/rssa.12556">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Unmeasured, spatially structured factors can confound associations between spatial environmental exposures and health outcomes. Adding flexible splines to a regression model is a simple approach for spatial confounding adjustment, but the spline degrees of freedom do not provide an easily interpretable spatial scale. We describe a method for quantifying the extent of spatial confounding adjustment in terms of the Euclidean distance at which variation is removed. We develop this approach for confounding adjustment with splines and using Fourier and wavelet filtering. We demonstrate differences in the spatial scales that these bases can represent and provide a comparison of methods for selecting the amount of confounding adjustment. We find the best performance for selecting the amount of adjustment by using an information criterion evaluated on an outcome model without exposure. We apply this method to spatial adjustment in an analysis of fine particulate matter and blood pressure in a cohort of US women.},
  archive  = {J},
  author   = {Joshua P. Keller and Adam A. Szpiro},
  doi      = {10.1111/rssa.12556},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {3},
  pages    = {1121-1143},
  title    = {Selecting a scale for spatial confounding adjustment},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Freight rates in downside and upside markets: Pricing of own
and spillover risks from other shipping segments. <em>Journal of the
Royal Statistical Society: Series A (Statistics in Society)</em>,
<em>183</em>(3), 1097–1119. (<a
href="https://doi.org/10.1111/rssa.12553">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Shipping freight rates are notoriously volatile and shipping investors are perceived to be risk loving. The paper explores the stochastic properties of freight rates in the shipping industry and derives the analytical equations for their moments in downside and upside markets by using a two-piece extension of the generalized error distribution. Pricing equations developed across shipping segments show how conditional risk and conditional skewness are priced along with their risk spillover effects. Results reveal the existence of a positive skewness premium, suggesting that shipping investors are willing to accept lower expected returns for the opportunity to earn high pay-offs in the future.},
  archive  = {J},
  author   = {Panayiotis Theodossiou and Dimitris Tsouknidis and Christos Savva},
  doi      = {10.1111/rssa.12553},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {3},
  pages    = {1097-1119},
  title    = {Freight rates in downside and upside markets: Pricing of own and spillover risks from other shipping segments},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A placebo design to detect spillovers from an
education–entertainment experiment in uganda. <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>183</em>(3), 1075–1096. (<a
href="https://doi.org/10.1111/rssa.12571">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Education–entertainment refers to dramatizations designed to convey information and to change attitudes. Buoyed by observational studies suggesting that education–entertainment strongly influences beliefs, attitudes and behaviours, scholars have recently assessed education–entertainment by using rigorous experimental designs in field settings. Studies conducted in developing countries have repeatedly shown the effectiveness of radio and film dramatizations on outcomes ranging from health to group conflict. One important gap in the literature is estimation of social spillover effects from those exposed to the dramatizations to others in the audience members’ social network. In theory, the social diffusion of media effects could greatly amplify their policy impact. The current study uses a novel placebo-controlled design that gauges both the direct effects of the treatment on audience members as well as the indirect effects of the treatment on others in their family and in the community. We implement this design in two large cluster-randomized experiments set in rural Uganda using video dramatizations on the topics of violence against women, teacher absenteeism and abortion stigma. We find several instances of sizable and highly significant direct effects on the attitudes of audience members, but we find little evidence that these effects diffused to others in the villages where the videos were aired.},
  archive  = {J},
  author   = {Anna M. Wilke and Donald P. Green and Jasper Cooper},
  doi      = {10.1111/rssa.12571},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {3},
  pages    = {1075-1096},
  title    = {A placebo design to detect spillovers from an education–entertainment experiment in uganda},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Spatial confounding in hurdle multilevel beta models: The
case of the brazilian mathematical olympics for public schools.
<em>Journal of the Royal Statistical Society: Series A (Statistics in
Society)</em>, <em>183</em>(3), 1051–1073. (<a
href="https://doi.org/10.1111/rssa.12551">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Among the many disparities for which Brazil is known is the difference in performance across students who attend the three administrative levels of Brazilian public schools: federal, state and municipal. Our main goal is to investigate whether student performance in the Brazilian Mathematical Olympics for Public Schools is associated with school administrative level and student gender. For this, we propose a hurdle hierarchical beta model for the scores of students who took the examination in the second phase of these Olympics, in 2013. The mean of the beta model incorporates fixed and random effects at the student and school levels. We explore different distributions for the random school effect. As the posterior distributions of some fixed effects change in the presence, and distribution, of the random school effects, we also explore models that constrain random school effects to the orthogonal complement of the fixed effects. We conclude that male students perform slightly better than female students and that, on average, federal schools perform substantially better than state or municipal schools. However, some of the best municipal and state schools perform as well as some federal schools. We hypothesize that this is due to individual teachers who successfully motivate and prepare their students to perform well in the mathematical Olympics.},
  archive  = {J},
  author   = {João B. M. Pereira and Widemberg S. Nobre and Igor F. L. Silva and Alexandra M. Schmidt},
  doi      = {10.1111/rssa.12551},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {3},
  pages    = {1051-1073},
  title    = {Spatial confounding in hurdle multilevel beta models: The case of the brazilian mathematical olympics for public schools},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A multilevel structural equation model for the
interrelationships between multiple latent dimensions of childhood
socio-economic circumstances, partnership transitions and mid-life
health. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>183</em>(3), 1029–1050. (<a
href="https://doi.org/10.1111/rssa.12554">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {We propose a multilevel structural equation model to investigate the interrelationships between childhood socio-economic circumstances, partnership formation and stability, and mid-life health, using data from the 1958 British birth cohort. The structural equation model comprises latent class models that characterize the patterns of change in four dimensions of childhood socio-economic circumstances and a joint regression model that relates these categorical latent variables to partnership transitions in adulthood and mid-life health, while allowing for informative dropout. The model can be extended to handle multiple outcomes of mixed types and at different levels in a hierarchical data structure.},
  archive  = {J},
  author   = {Yajing Zhu and Fiona Steele and Irini Moustaki},
  doi      = {10.1111/rssa.12554},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {3},
  pages    = {1029-1050},
  title    = {A multilevel structural equation model for the interrelationships between multiple latent dimensions of childhood socio-economic circumstances, partnership transitions and mid-life health},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Quantifying the association between discrete event time
series with applications to digital forensics. <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>183</em>(3), 1005–1027. (<a
href="https://doi.org/10.1111/rssa.12549">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {We consider the problem of quantifying the degree of association between pairs of discrete event time series, with potential applications in forensic and cybersecurity settings. We focus in particular on the case where two associated event series exhibit temporal clustering such that the occurrence of one type of event at a particular time increases the likelihood that an event of the other type will also occur nearby in time. We pursue a non-parametric approach to the problem and investigate various score functions to quantify association, including characteristics of marked point processes and summary statistics of interevent times. Two techniques are proposed for assessing the significance of the measured degree of association: a population-based approach to calculating score-based likelihood ratios when a sample from a relevant population is available, and a resampling approach to computing coincidental match probabilities when only a single pair of event series is available. The methods are applied to simulated data and to two real world data sets consisting of logs of computer activity and achieve accurate results across all data sets.},
  archive  = {J},
  author   = {Christopher Galbraith and Padhraic Smyth and Hal S. Stern},
  doi      = {10.1111/rssa.12549},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {3},
  pages    = {1005-1027},
  title    = {Quantifying the association between discrete event time series with applications to digital forensics},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel approach to latent class modelling: Identifying the
various types of body mass index individuals. <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>183</em>(3), 983–1004. (<a
href="https://doi.org/10.1111/rssa.12552">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Given the increasing prevalence of adult obesity, furthering understanding of the determinants of measures such as the body mass index ( BMI ) remains high on the policy agenda. We contribute to existing literature on modelling the BMI by proposing an extension to latent class modelling, which serves to unveil a more detailed picture of the determinants of BMI. Interest here lies in latent class analysis with a regression model and predictor variables explaining class membership, a regression model and predictor variables explaining the outcome variable within BMI classes and instances where the BMI classes are naturally ordered and labelled by expected values within class. A simple and generic way of parameterizing both the class probabilities and the statistical representation of behaviours within each class is proposed, that simultaneously preserves the ranking according to class-specific expected values and yields a parsimonious representation of the class probabilities. Based on a wide range of metrics, the newly proposed approach is found to dominate the prevailing approach and, moreover, results are often quite different across the two.},
  archive  = {J},
  author   = {Sarah Brown and William Greene and Mark Harris},
  doi      = {10.1111/rssa.12552},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {3},
  pages    = {983-1004},
  title    = {A novel approach to latent class modelling: Identifying the various types of body mass index individuals},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On quantifying expert opinion about multinomial models that
contain covariates. <em>Journal of the Royal Statistical Society: Series
A (Statistics in Society)</em>, <em>183</em>(3), 959–981. (<a
href="https://doi.org/10.1111/rssa.12546">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The paper addresses the task of forming a prior distribution to represent expert opinion about a multinomial model that contains covariates. The task has not previously been addressed. We suppose that the sampling model is a multinomial logistic regression and represent expert opinion about the regression coefficients by a multivariate normal distribution. This logistic–normal model gives a flexible prior distribution that can capture a broad variety of expert opinion. The challenge is to find meaningful assessment tasks that an expert can perform and which should yield appropriate information to determine the values of parameters in the prior distribution, and to develop theory for determining the parameter values from the assessments. A method is proposed that meets this challenge. The method is implemented in interactive easy-to-use software that is freely available. It provides a graphical interface that the expert uses to assess quartiles of sets of proportions and the method determines a mean vector and a positive definite covariance matrix to represent the expert&#39;s opinions. The assessment tasks chosen yield parameter values that satisfy the usual laws of probability without the expert being aware of the constraints that this imposes. Special attention is given to feedback that encourages the expert to consider his or her opinions from a different perspective. The method is illustrated in an example that shows its viability and usefulness.},
  archive  = {J},
  author   = {Fadlalla G. Elfadaly and Paul H. Garthwaite},
  doi      = {10.1111/rssa.12546},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {3},
  pages    = {959-981},
  title    = {On quantifying expert opinion about multinomial models that contain covariates},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Finding the strength in a weak instrument in a study of
cognitive outcomes produced by catholic high schools. <em>Journal of the
Royal Statistical Society: Series A (Statistics in Society)</em>,
<em>183</em>(3), 935–958. (<a
href="https://doi.org/10.1111/rssa.12559">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {We show that the strength of an instrument is incompletely characterized by the proportion of compliers, and we propose and evaluate new methods that extract more information from certain settings with comparatively few compliers. Specifically, we demonstrate that, for a fixed small proportion of compliers, the presence of an equal number of always-takers and never-takers weakens an instrument, whereas the absence of always-takers or, equivalently, the absence of never-takers strengthens an instrument. In this statement, the strength of an instrument refers to its ability to recognize and reject a false hypothesis about a structural parameter. Equivalently, the strength of an instrument refers to its ability to exclude from a confidence interval a false value of a structural parameter. This ability is measured by the Bahadur efficiency of a test that assumes that the instrument is flawless, or the Bahadur efficiency of a sensitivity analysis that assumes that the instrument may be somewhat biased. When there are few compliers, the outcomes for most people are unaffected by fluctuations in the instrument, so most of the information about the treatment effect is contained in the tail of the distribution of the outcomes. Exploiting this fact, we propose new methods that emphasize the affected portion of the distribution of outcomes, thereby extracting more information from studies with few compliers. Studies of the effects of Catholic high schools on academic test performance have used ‘being Catholic’ as an instrument for ‘attending a Catholic high school’, and the application concerns such a comparison using the US National Educational Longitudinal Study. Most Catholics did not attend Catholic school, so there are few compliers, but it was rare for non-Catholics to attend Catholic school, so there are very few always-takers.},
  archive  = {J},
  author   = {Siyu Heng and Dylan S. Small and Paul R. Rosenbaum},
  doi      = {10.1111/rssa.12559},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {3},
  pages    = {935-958},
  title    = {Finding the strength in a weak instrument in a study of cognitive outcomes produced by catholic high schools},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Change point analysis of historical battle deaths.
<em>Journal of the Royal Statistical Society: Series A (Statistics in
Society)</em>, <em>183</em>(3), 909–933. (<a
href="https://doi.org/10.1111/rssa.12578">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {It has been claimed and disputed that World War II has been followed by a ‘long peace’: an unprecedented decline of war. We conduct a full change point analysis of well-documented, publicly available battle deaths data sets, using new techniques that enable the robust detection of changes in the statistical properties of such heavy-tailed data. We first test and calibrate these techniques. We then demonstrate the existence of changes, independent of data presentation, in the early to mid-19th century, as the Congress of Vienna system moved towards its collapse, in the early to mid-20th century, bracketing the World Wars, and in the late 20th century, as the world reconfigured around the end of the Cold War. Our analysis provides a methodology for future investigations and an empirical basis for political and historical discussions.},
  archive  = {J},
  author   = {Brennen T. Fagan and Marina I. Knight and Niall J. MacKay and A. Jamie Wood},
  doi      = {10.1111/rssa.12578},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {3},
  pages    = {909-933},
  title    = {Change point analysis of historical battle deaths},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). How does temperature vary over time?: Evidence on the
stationary and fractal nature of temperature fluctuations. <em>Journal
of the Royal Statistical Society: Series A (Statistics in Society)</em>,
<em>183</em>(3), 883–908. (<a
href="https://doi.org/10.1111/rssa.12557">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The paper analyses temperature data from 96 selected weather stations world wide, and from reconstructed northern hemisphere temperature data over the last two millennia. Using a non-parametric test, we find that the stationarity hypothesis is not rejected by the data. Subsequently, we investigate further properties of the data by means of a statistical model known as the fractional Gaussian noise (FGN) model. Under stationarity FGN follows from the fact that the observed data are obtained as temporal aggregates of data generated at a finer (basic) timescale where temporal aggregation is taken over a ‘large’ number of basic units. The FGN process exhibits long-range dependence. Several tests show that both the reconstructed and most of the observed data are consistent with the FGN model.},
  archive  = {J},
  author   = {John K. Dagsvik and Mariachiara Fortuna and Sigmund Hov Moen},
  doi      = {10.1111/rssa.12557},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {3},
  pages    = {883-908},
  title    = {How does temperature vary over time?: Evidence on the stationary and fractal nature of temperature fluctuations},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fulfilling the information need after an earthquake:
Statistical modelling of citizen science seismic reports for predicting
earthquake parameters in near realtime. <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>183</em>(3), 857–882. (<a
href="https://doi.org/10.1111/rssa.12577">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {When an earthquake affects an inhabited area, a need for information immediately arises among the population. In general, this need is not immediately fulfilled by official channels which usually release expert-validated information with delays of many minutes. Seismology is among the research fields where citizen science projects succeeded in collecting useful scientific information. More recently, the ubiquity of smartphones is giving the opportunity to involve even more citizens. This paper focuses on seismic intensity reports collected through smartphone applications while an earthquake is occurring. The aim is to provide a framework for predicting and updating in near realtime earthquake parameters that are useful for assessing the effect of the earthquake. This is done by using a multivariate space–time model based on time-varying coefficients and a spatial latent variable. As a case-study, the model is applied to more than 200000 seismic reports globally collected over a period of around 4 years by the Earthquake Network citizen science project. It is shown how the time-varying coefficients are needed to adapt the model to an information content that changes with time, and how the spatial latent variable can capture the local seismicity and the heterogeneity in the people&#39;s response across the globe.},
  archive  = {J},
  author   = {Francesco Finazzi},
  doi      = {10.1111/rssa.12577},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {3},
  pages    = {857-882},
  title    = {Fulfilling the information need after an earthquake: Statistical modelling of citizen science seismic reports for predicting earthquake parameters in near realtime},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Forecasting of cohort fertility under a hierarchical
bayesian approach. <em>Journal of the Royal Statistical Society: Series
A (Statistics in Society)</em>, <em>183</em>(3), 829–856. (<a
href="https://doi.org/10.1111/rssa.12566">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Fertility projections are a key determinant of population forecasts, which are widely used by government policy makers and planners. In keeping with the recent literature, we propose an intuitive and transparent hierarchical Bayesian model to forecast cohort fertility. Using Hamiltonian Monte Carlo methods and a data set from the human fertility database, we obtain fertility forecasts for 30 countries. We use scoring rules to assess the predictive accuracy of the forecasts quantitatively; these indicate that our model predicts with an accuracy comparable with that of the best-performing models in the current literature overall, with stronger performance for countries without a recent structural shift. Our findings support the position of hierarchical Bayesian modelling at the forefront of population forecasting methods.},
  archive  = {J},
  author   = {Joanne Ellison and Erengul Dodd and Jonathan J. Forster},
  doi      = {10.1111/rssa.12566},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {3},
  pages    = {829-856},
  title    = {Forecasting of cohort fertility under a hierarchical bayesian approach},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A similarity-based approach for macroeconomic forecasting.
<em>Journal of the Royal Statistical Society: Series A (Statistics in
Society)</em>, <em>183</em>(3), 801–827. (<a
href="https://doi.org/10.1111/rssa.12574">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In the aftermath of the recent financial crisis there has been considerable focus on methods for predicting macroeconomic variables when their behaviour is subject to abrupt changes, associated for example with crisis periods. We propose similarity-based approaches as a way to handle parameter instability and apply them to macroeconomic forecasting. The rationale is that clusters of past data that match the current economic conditions can be more informative for forecasting than the entire past behaviour of the variable of interest. We apply our methods to predict both simulated data in a set of Monte Carlo experiments, and a broad set of key US macroeconomic indicators. The forecast evaluation exercises indicate that similarity-based approaches perform well, in general, in comparison with other common time-varying forecasting methods, and particularly well during crisis episodes.},
  archive  = {J},
  author   = {Y. Dendramis and G. Kapetanios and M. Marcellino},
  doi      = {10.1111/rssa.12574},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {3},
  pages    = {801-827},
  title    = {A similarity-based approach for macroeconomic forecasting},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Simple rules to guide expert classifications. <em>Journal of
the Royal Statistical Society: Series A (Statistics in Society)</em>,
<em>183</em>(3), 771–800. (<a
href="https://doi.org/10.1111/rssa.12576">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Judges, doctors and managers are among those decision makers who must often choose a course of action under limited time, with limited knowledge and without the aid of a computer. Because data-driven methods typically outperform unaided judgements, resource-constrained practitioners can benefit from simple, statistically derived rules that can be applied mentally. In this work, we formalize long-standing observations about the efficacy of improper linear models to construct accurate yet easily applied rules. To test the performance of this approach, we conduct a large-scale evaluation in 22 domains and focus in detail on one: judicial decisions to release or detain defendants while they await trial. In these domains, we find that simple rules rival the accuracy of complex prediction models that base decisions on considerably more information. Further, comparing with unaided judicial decisions, we find that simple rules substantially outperform the human experts. To conclude, we present an analytical framework that sheds light on why simple rules perform as well as they do.},
  archive  = {J},
  author   = {Jongbin Jung and Connor Concannon and Ravi Shroff and Sharad Goel and Daniel G. Goldstein},
  doi      = {10.1111/rssa.12576},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {3},
  pages    = {771-800},
  title    = {Simple rules to guide expert classifications},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Gender differences in the perception of safety in public
transport. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>183</em>(3), 737–769. (<a
href="https://doi.org/10.1111/rssa.12558">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Concerns over women&#39;s safety on public transport systems are commonly reported in the media. We develop statistical models to test for gender differences in the perception of safety and satisfaction on urban metros and buses by using large-scale unique customer satisfaction data for 28 world cities over the period 2009–2018. Results indicate a significant gender gap in the perception of safety, with women being 10\% more likely than men to feel unsafe in metros (6\% for buses). This gender gap is larger for safety than for overall satisfaction (3\% in metros and 2.5\% in buses), which is consistent with safety being one dimension of overall satisfaction. Results are stable across specifications and robust to inclusion of city level and time controls. We find heterogeneous responses by sociodemographic characteristics. Data indicate that 45\% of women feel secure in trains and metro stations (and 55\% in buses). Thus the gender gap encompasses more differences in transport perception between men and women rather than an intrinsic network fear. Additional models test for the influence of metro characteristics on perceived safety levels and find that more acts of violence, larger carriages and emptier vehicles decrease women&#39;s feeling of safety.},
  archive  = {J},
  author   = {Laila Ait Bihi Ouali and Daniel J. Graham and Alexander Barron and Mark Trompet},
  doi      = {10.1111/rssa.12558},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {3},
  pages    = {737-769},
  title    = {Gender differences in the perception of safety in public transport},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multiple-systems analysis for the quantification of modern
slavery: Classical and bayesian approaches. <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>183</em>(3), 691–736. (<a
href="https://doi.org/10.1111/rssa.12505">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Multiple-systems estimation is a key approach for quantifying hidden populations such as the number of victims of modern slavery. The UK Government published an estimate of 10000–13000 victims, constructed by the present author, as part of the strategy leading to the Modern Slavery Act 2015. This estimate was obtained by a stepwise multiple-systems method based on six lists. Further investigation shows that a small proportion of the possible models give rather different answers, and that other model fitting approaches may choose one of these. Three data sets collected in the field of modern slavery, together with a data set about the death toll in the Kosovo conflict, are used to investigate the stability and robustness of various multiple-systems-estimate methods. The crucial aspect is the way that interactions between lists are modelled, because these can substantially affect the results. Model selection and Bayesian approaches are considered in detail, in particular to assess their stability and robustness when applied to real modern slavery data. A new Markov chain Monte Carlo Bayesian approach is developed; overall, this gives robust and stable results at least for the examples considered. The software and data sets are freely and publicly available to facilitate wider implementation and further research.},
  archive  = {J},
  author   = {Bernard W. Silverman},
  doi      = {10.1111/rssa.12505},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {3},
  pages    = {691-736},
  title    = {Multiple-systems analysis for the quantification of modern slavery: Classical and bayesian approaches},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Can genetics reveal the causes and consequences of
educational attainment? <em>Journal of the Royal Statistical Society:
Series A (Statistics in Society)</em>, <em>183</em>(2), 681–688. (<a
href="https://doi.org/10.1111/rssa.12543">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {There is an extensive literature on the causes of educational inequalities, and the life course consequences of educational attainment. Mendelian randomization, where genetic variants associated with exposures of interest are used as proxies for those exposures, often within an instrumental variables framework, has proven highly effective at elucidating the causal effects of several risk factors in the biomedical sciences. We discuss the potential for this approach to be used in the context of social and socio-economic exposures and outcomes, such as educational attainment.},
  archive  = {J},
  author   = {Marcus Munafò and Neil M. Davies and George Davey Smith},
  doi      = {10.1111/rssa.12543},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {2},
  pages    = {681-688},
  title    = {Can genetics reveal the causes and consequences of educational attainment?},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Crime against women in india: Unveiling spatial patterns and
temporal trends of dowry deaths in the districts of uttar pradesh.
<em>Journal of the Royal Statistical Society: Series A (Statistics in
Society)</em>, <em>183</em>(2), 655–679. (<a
href="https://doi.org/10.1111/rssa.12545">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Crimes against women in India have been continuously increasing lately as reported by the National Crime Records Bureau. Gender-based violence has become a serious issue to such an extent that it has been catalogued as a high impact health problem by the World Health Organization. However, there is a lack of spatiotemporal analyses to reveal a complete picture of the geographical and temporal patterns of crimes against women. We focus on analysing how the geographical pattern of ‘dowry deaths’ changes over time in the districts of Uttar Pradesh during the period 2001–2014. The study of the geographical distribution of dowry death incidence and its evolution over time aims to identify specific regions that exhibit high risks and to hypothesize on potential risk factors. We also look into different spatial priors and their effects on final risk estimates. Various priors for the hyperparameters are also reviewed. The risk estimates seem to be robust in terms of the spatial prior and hyperprior choices and final results highlight several districts with extreme risks of dowry death incidence. Statistically significant associations are also found between dowry deaths, sex ratio and some forms of overall crime.},
  archive  = {J},
  author   = {G. Vicente and T. Goicoa and P. Fernandez-Rasines and M. D. Ugarte},
  doi      = {10.1111/rssa.12545},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {2},
  pages    = {655-679},
  title    = {Crime against women in india: Unveiling spatial patterns and temporal trends of dowry deaths in the districts of uttar pradesh},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Inferring the outcomes of rejected loans: An application of
semisupervised clustering. <em>Journal of the Royal Statistical Society:
Series A (Statistics in Society)</em>, <em>183</em>(2), 631–654. (<a
href="https://doi.org/10.1111/rssa.12534">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Rejection inference aims to reduce sample bias and to improve model performance in credit scoring. We propose a semisupervised clustering approach as a new rejection inference technique. K -prototype clustering can deal with mixed types of numeric and categorical characteristics, which are common in consumer credit data. We identify homogeneous acceptances and rejections and assign labels to part of the rejections according to the label of acceptances. We test the performance of various rejection inference methods in logit, support vector machine and random-forests models based on data sets of real consumer loans. The predictions of clustering rejection inference show advantages over other traditional rejection inference methods. Inferring the label of the rejection from semisupervised clustering is found to help to mitigate the sample bias problem and to improve the predictive accuracy.},
  archive  = {J},
  author   = {Zhiyong Li and Xinyi Hu and Ke Li and Fanyin Zhou and Feng Shen},
  doi      = {10.1111/rssa.12534},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {2},
  pages    = {631-654},
  title    = {Inferring the outcomes of rejected loans: An application of semisupervised clustering},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A bayesian parametric approach to handle missing
longitudinal outcome data in trial-based health economic evaluations.
<em>Journal of the Royal Statistical Society: Series A (Statistics in
Society)</em>, <em>183</em>(2), 607–629. (<a
href="https://doi.org/10.1111/rssa.12522">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Trial-based economic evaluations are typically performed on cross-sectional variables, derived from the responses for only the completers in the study, using methods that ignore the complexities of utility and cost data (e.g. skewness and spikes). We present an alternative and more efficient Bayesian parametric approach to handle missing longitudinal outcomes in economic evaluations, while accounting for the complexities of the data. We specify a flexible parametric model for the observed data and partially identify the distribution of the missing data with partial identifying restrictions and sensitivity parameters. We explore alternative non-ignorable missingness scenarios through different priors for the sensitivity parameters, calibrated on the observed data. Our approach is motivated by, and applied to, data from a trial assessing the cost-effectiveness of a new treatment for intellectual disability and challenging behaviour.},
  archive  = {J},
  author   = {Andrea Gabrio and Michael J. Daniels and Gianluca Baio},
  doi      = {10.1111/rssa.12522},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {2},
  pages    = {607-629},
  title    = {A bayesian parametric approach to handle missing longitudinal outcome data in trial-based health economic evaluations},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Information asymmetry and leverage adjustments: A
semiparametric varying-coefficient approach. <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>183</em>(2), 581–605. (<a
href="https://doi.org/10.1111/rssa.12524">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Information asymmetry reflects the risk and uncertainty faced by investors and is a measure of a firm&#39;s transparency. High information asymmetry could increase the cost of external financing, which in turn impedes a firm&#39;s leverage (debt–asset ratio) adjustment. The paper studies the adjustment speed towards the target leverage in the presence of information asymmetry by using microlevel data from China. In contrast with previous studies, we allow heterogeneity in the adjustment speed coefficient by modelling it as a non-parametric function of information asymmetry and other firm characteristics. This refinement not only allows for more flexibility in the model, but it also facilitates further exploration into the differences and determinants of firms’ financing behaviour. We uniquely build the firm level measure of information asymmetry into the traditional partial leverage adjustment framework. Based on our firm level measure of the adjustment speed, our paper explores why the leverage adjustment speed matters by examining its association with corporate performance indicators. We find that China&#39;s firms do have leverage targets and they slowly adjust towards these targets. We also find that the adjustment speed decreases with an increase in information asymmetry. Overall, firms which converge towards their targets faster perform better in value, profitability, investment and costs.},
  archive  = {J},
  author   = {Man Jin and Shunan Zhao and Subal C. Kumbhakar},
  doi      = {10.1111/rssa.12524},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {2},
  pages    = {581-605},
  title    = {Information asymmetry and leverage adjustments: A semiparametric varying-coefficient approach},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The hot hand in professional darts. <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>183</em>(2), 565–580. (<a
href="https://doi.org/10.1111/rssa.12527">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {We investigate the hot hand hypothesis in professional darts in a nearly ideal setting with minimal to no interaction between players. Considering almost 1 year of tournament data, corresponding to 167492 dart throws in total, we use state space models to investigate serial dependence in throwing performance. In our models, a latent state process serves as a proxy for a player&#39;s underlying form, and we use auto-regressive processes to model how this process evolves over time. Our results regarding the persistence of the latent process indicate a weak hot hand effect, but the evidence is inconclusive.},
  archive  = {J},
  author   = {Marius Ötting and Roland Langrock and Christian Deutscher and Vianey Leos-Barajas},
  doi      = {10.1111/rssa.12527},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {2},
  pages    = {565-580},
  title    = {The hot hand in professional darts},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A bayesian spatial categorical model for prediction to
overlapping geographical areas in sample surveys. <em>Journal of the
Royal Statistical Society: Series A (Statistics in Society)</em>,
<em>183</em>(2), 535–563. (<a
href="https://doi.org/10.1111/rssa.12526">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Motivated by the Australian National University poll, we consider a situation where survey data have been collected from respondents for several categorical variables and a primary geographic classification, e.g. postcode. Here, a common and important problem is to obtain estimates for a second target geography that overlaps with the primary geography but has not been collected from the respondents. We examine this problem when areal level census information is available for both geographic classifications. Such a situation is challenging from a small area estimation perspective for several reasons: there is a misalignment between the census and survey information as well as the geographical classifications; the geographic areas are potentially small and so prediction can be difficult because of the sparse or spatially missing data issue; and there is the possibility of non-stationary spatial dependence. To address these problems we develop a Bayesian model using latent processes, underpinned by a non-stationary spatial basis that combines Moran&#39;s I and multiresolution basis functions with a small but representative set of knots. The study results based on simulated data demonstrate that the model can be highly effective and gives more accurate estimates for areas defined by the target geography than several existing models. The model also performs well for the Australian National University poll data to predict on a second geographic classification: statistical area level 2.},
  archive  = {J},
  author   = {K. Shuvo Bakar and Nicholas Biddle and Philip Kokic and Huidong Jin},
  doi      = {10.1111/rssa.12526},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {2},
  pages    = {535-563},
  title    = {A bayesian spatial categorical model for prediction to overlapping geographical areas in sample surveys},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A quantitative framework to inform extrapolation decisions
in children. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>183</em>(2), 515–534. (<a
href="https://doi.org/10.1111/rssa.12532">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {When developing a new medicine for children, the potential to extrapolate from adult efficacy data is well recognized. However, significant assumptions about the similarity of adults and children are needed for extrapolations to be biologically plausible. One such assumption is that of similar exposure–response ( E – R -) relationships. Motivated by applications to antiepileptic drug development, we consider how data that are available from existing trials of adults and adolescents can be used to quantify prior uncertainty about whether E – R -relationships are similar in adults and younger children. A Bayesian multivariate meta-analytic model is fitted to existing E – R -data and adjusted for external biases that arise because these data are not perfectly relevant to the comparison of interest. We propose a strategy for eliciting expert prior opinion on external biases. From the bias-adjusted meta-analysis, we derive prior distributions quantifying our uncertainty about the degree of similarity between E – R -relationships for adults and younger children. Using these we calculate the prior probability that average pharmacodynamic responses in adults and younger children, both on placebo and at an effective concentration, are sufficiently similar to justify a complete extrapolation of efficacy data. A simulation study is performed to evaluate the operating characteristics of the approach proposed.},
  archive  = {J},
  author   = {Ian Wadsworth and Lisa V. Hampson and Thomas Jaki and Graeme J. Sills and Anthony G. Marson and Richard Appleton},
  doi      = {10.1111/rssa.12532},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {2},
  pages    = {515-534},
  title    = {A quantitative framework to inform extrapolation decisions in children},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modelling the socio-economic determinants of fertility: A
mediation analysis using the parametric g-formula. <em>Journal of the
Royal Statistical Society: Series A (Statistics in Society)</em>,
<em>183</em>(2), 493–513. (<a
href="https://doi.org/10.1111/rssa.12520">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Theories predict that the timing of childbearing and number of children born are determined by multiple socio-economic factors. Despite this, many methods cannot investigate the interrelationships between these determinants, including the direct and indirect influence that they have on fertility over the life course. Here we use the parametric g -formula to examine the interdependent influences of time-varying socio-economic processes—education, employment status and partnership status—on fertility. To demonstrate this approach, we study a cohort of women who were born in the UK in 1970. Our results show that socio-economic processes play an important role in determining fertility, not only directly but also indirectly. We show that increasing attendance in higher education has a largely direct effect on early childbearing up to age 25 years, resulting in a substantial increase in childlessness. However, childbearing at later ages is dominated by an indirect effect of education on fertility, via partnership status and employment status, that is twice as large as the direct effect. We also use the g -formula to examine bias due to unobserved heterogeneity, and we demonstrate that our results appear to be robust. We conclude that the method provides a valuable tool for mediation analysis in studies of interdependent life course processes.},
  archive  = {J},
  author   = {Maarten J. Bijlsma and Ben Wilson},
  doi      = {10.1111/rssa.12520},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {2},
  pages    = {493-513},
  title    = {Modelling the socio-economic determinants of fertility: A mediation analysis using the parametric g-formula},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Identifying the effect of public holidays on daily demand
for gas. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>183</em>(2), 471–492. (<a
href="https://doi.org/10.1111/rssa.12504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {To reduce operational costs and to ensure security of supply, gas distribution networks require accurate forecasts of the demand for gas. Among domestic and commercial customers, demand relates primarily to the weather and patterns of life and work. Public holidays have a pronounced effect which often spreads into neighbouring days. We call this spread the ‘proximity effect’. Traditionally, the days over which the proximity effect is felt are prespecified in fixed windows around each holiday, allowing no uncertainty in their identification. We are motivated by an application to modelling daily gas demand in two large British regions. We introduce a novel model which does not fix the days on which the proximity effect is felt. Our approach uses a four-state, non-homogeneous hidden Markov model, with cyclic dynamics, where the classification of days as public holidays is observed, but the assignment of days as ‘pre-holiday’, ‘post-holiday’ or ‘normal’ days is unknown. The number of days to the preceding and succeeding holidays guide transitions between states. We apply Bayesian inference and illustrate the benefit of our modelling approach. A version of the model is now being used by one of the UK&#39;s regional distribution networks.},
  archive  = {J},
  author   = {Sarah E. Heaps and Malcolm Farrow and Kevin J. Wilson},
  doi      = {10.1111/rssa.12504},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {2},
  pages    = {471-492},
  title    = {Identifying the effect of public holidays on daily demand for gas},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Discussion on the meeting on “signs and sizes: Understanding
and replicating statistical findings.” <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>183</em>(2), 449–469. (<a
href="https://doi.org/10.1111/rssa.12544">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  doi     = {10.1111/rssa.12544},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {2},
  pages   = {449-469},
  title   = {Discussion on the meeting on ‘Signs and sizes: Understanding and replicating statistical findings’},
  volume  = {183},
  year    = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new standard for the analysis and design of replication
studies. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>183</em>(2), 431–448. (<a
href="https://doi.org/10.1111/rssa.12493">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {A new standard is proposed for the evidential assessment of replication studies. The approach combines a specific reverse Bayes technique with prior-predictive tail probabilities to define replication success. The method gives rise to a quantitative measure for replication success, called the sceptical p -value. The sceptical p -value integrates traditional significance of both the original and the replication study with a comparison of the respective effect sizes. It incorporates the uncertainty of both the original and the replication effect estimates and reduces to the ordinary p -value of the replication study if the uncertainty of the original effect estimate is ignored. The framework proposed can also be used to determine the power or the required replication sample size to achieve replication success. Numerical calculations highlight the difficulty of achieving replication success if the evidence from the original study is only suggestive. An application to data from the Open Science Collaboration project on the replicability of psychological science illustrates the methodology proposed.},
  archive  = {J},
  author   = {Leonhard Held},
  doi      = {10.1111/rssa.12493},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {2},
  pages    = {431-448},
  title    = {A new standard for the analysis and design of replication studies},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Knowing the signs: A direct and generalizable motivation of
two-sided tests. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>183</em>(2), 411–430. (<a
href="https://doi.org/10.1111/rssa.12496">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Many well-known problems with two-sided p -values are due to their use in hypothesis tests, with ‘reject–accept’ conclusions about point null hypotheses. We present an alternative motivation for p -value-based tests, viewing them as assessments of only the sign of an underlying parameter, where we can conclude that the parameter is positive or negative, or simply say nothing either way. Our approach is decision theoretic, but—unusually—we consider the whole set of possible utility functions available. Doing this we show how, in a specific sense, close analogues of familiar one- and two-sided tests are always the optimal decision. We argue that this simplicity could aid non-experts’ understanding and use of tests—and help them to think critically about whether or not tests are appropriate tools for answering their questions of interest. Several extensions are also considered, showing that the simple idea of determining the signs of parameters yields a rich framework for inference.},
  archive  = {J},
  author   = {Kenneth Rice and Tyler Bonnett and Chloe Krakauer},
  doi      = {10.1111/rssa.12496},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {2},
  pages    = {411-430},
  title    = {Knowing the signs: A direct and generalizable motivation of two-sided tests},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The beauty of mathematics in computer ScienceJ. Wu2018Boca
raton chapman and hall–CRC 268 pp., £115 (hardbound), £29.99
(paperbound), £26.99 (e-book) ISBN 978-1-138-04960-4. <em>Journal of the
Royal Statistical Society: Series A (Statistics in Society)</em>,
<em>183</em>(1), 407. (<a
href="https://doi.org/10.1111/rssa.12542">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Johnny Hopkins},
  doi     = {10.1111/rssa.12542},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {1},
  pages   = {407},
  title   = {The beauty of mathematics in computer ScienceJ. Wu2018Boca raton chapman and Hall–CRC 268 pp., £115 (hardbound), £29.99 (paperbound), £26.99 (e-book) ISBN 978-1-138-04960-4},
  volume  = {183},
  year    = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). A multivariate claim count model for applications in
InsuranceD. A. SelchM. Scherer2019Cham springer actuarial xii + 158 pp.,
£74.99 ISBN 978-3-319-92867-8. <em>Journal of the Royal Statistical
Society: Series A (Statistics in Society)</em>, <em>183</em>(1), 406.
(<a href="https://doi.org/10.1111/rssa.12540">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Morteza Aalabaf-Sabaghi},
  doi     = {10.1111/rssa.12540},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {1},
  pages   = {406},
  title   = {A multivariate claim count model for applications in InsuranceD. a. SelchM. Scherer2019Cham springer actuarial xii + 158 pp., £74.99 ISBN 978-3-319-92867-8},
  volume  = {183},
  year    = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Philogenetic inference, selection theory, and history of
ScienceR. G. Winther ed. 2018Cambridge cambridge university press 540
pp., £70.00 (hardbound), £66.50 (kindle) ISBN 978-1-107-11172-1.
<em>Journal of the Royal Statistical Society: Series A (Statistics in
Society)</em>, <em>183</em>(1), 406–407. (<a
href="https://doi.org/10.1111/rssa.12541">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {R Allan Reese},
  doi     = {10.1111/rssa.12541},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {1},
  pages   = {406-407},
  title   = {Philogenetic inference, selection theory, and history of ScienceR. g. winther ed. 2018Cambridge cambridge university press 540 pp., £70.00 (hardbound), £66.50 (Kindle) ISBN 978-1-107-11172-1},
  volume  = {183},
  year    = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Practical r for mass communication and JournalismS.
Machlis2018Boca raton chapman and hall–CRC 246 pp., £133 (<span
class="math inline">175)(<em>h</em><em>a</em><em>r</em><em>d</em><em>b</em><em>o</em><em>u</em><em>n</em><em>d</em>), £46.99(</span><!-- -->59.95)
(paperbound), £42.29 (e-book) ISBN 987-1-138-72691-8. <em>Journal of the
Royal Statistical Society: Series A (Statistics in Society)</em>,
<em>183</em>(1), 405. (<a
href="https://doi.org/10.1111/rssa.12538">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Thomas King},
  doi     = {10.1111/rssa.12538},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {1},
  pages   = {405},
  title   = {Practical r for mass communication and JournalismS. Machlis2018Boca raton chapman and Hall–CRC 246 pp., £133 ($175) (hardbound), £46.99 ($59.95) (paperbound), £42.29 (e-book) ISBN 987-1-138-72691-8},
  volume  = {183},
  year    = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Classification, (big) data analysis and statistical
LearningF. MolaC. ConversanoM. Vichi eds 2018Basel springer xvi + 242
pp., £89.99 ISBN 978-3-319-55707-6. <em>Journal of the Royal Statistical
Society: Series A (Statistics in Society)</em>, <em>183</em>(1),
405–406. (<a href="https://doi.org/10.1111/rssa.12539">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Kuldeep Kumar},
  doi     = {10.1111/rssa.12539},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {1},
  pages   = {405-406},
  title   = {Classification, (Big) data analysis and statistical LearningF. MolaC. ConversanoM. vichi eds 2018Basel springer xvi + 242 pp., £89.99 ISBN 978-3-319-55707-6},
  volume  = {183},
  year    = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Regression analysis in medical research for starters and
2nd LevelersT. J. CleophasA. H. Zwinderman2018Basel springer xii + 426
pp., £74.50 (hardbound), £74.99 (paperbound), £59.99 (e-book) ISBN
978-3-319-71936-8. <em>Journal of the Royal Statistical Society: Series
A (Statistics in Society)</em>, <em>183</em>(1), 404. (<a
href="https://doi.org/10.1111/rssa.12536">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Kuldeep Kumar},
  doi     = {10.1111/rssa.12536},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {1},
  pages   = {404},
  title   = {Regression analysis in medical research for starters and 2nd LevelersT. j. CleophasA. h. Zwinderman2018Basel springer xii + 426 pp., £74.50 (hardbound), £74.99 (paperbound), £59.99 (e-book) ISBN 978-3-319-71936-8},
  volume  = {183},
  year    = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Foundations of info-metrics: Modeling, inference, and
imperfect InformationA. Golan2018Oxford oxford university press 466 pp.,
£38.49 ISBN 978-0-199-34953-1. <em>Journal of the Royal Statistical
Society: Series A (Statistics in Society)</em>, <em>183</em>(1),
404–405. (<a href="https://doi.org/10.1111/rssa.12537">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Rosa Bernardini Papalia},
  doi     = {10.1111/rssa.12537},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {1},
  pages   = {404-405},
  title   = {Foundations of info-metrics: Modeling, inference, and imperfect InformationA. Golan2018Oxford oxford university press 466 pp., £38.49 ISBN 978-0-199-34953-1},
  volume  = {183},
  year    = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020c). Book reviews. <em>Journal of the Royal Statistical Society:
Series A (Statistics in Society)</em>, <em>183</em>(1), 403. (<a
href="https://doi.org/10.1111/rssa.12535">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  doi     = {10.1111/rssa.12535},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {1},
  pages   = {403},
  title   = {Book reviews},
  volume  = {183},
  year    = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Outcome-dependent sampling in cluster-correlated data
settings with application to hospital profiling. <em>Journal of the
Royal Statistical Society: Series A (Statistics in Society)</em>,
<em>183</em>(1), 379–402. (<a
href="https://doi.org/10.1111/rssa.12503">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Hospital readmission is a key marker of quality of healthcare and an important policy measure, used by the Centers for Medicare and Medicaid Services to determine, in part, reimbursement rates. Currently, analyses of readmissions are based on a logistic–normal generalized linear mixed model that permits estimation of hospital-specific measures while adjusting for case mix differences. Recent moves to identify and address healthcare disparities call for expanding case mix adjustment to include measures of socio-economic status while minimizing additional burden to hospitals associated with collecting data on such measures. Towards resolving this dilemma, we propose that detailed socio-economic data be collected on a subsample of patients via an outcome-dependent sampling scheme, specifically the cluster-stratified case–control design. Estimation and inference, for both the fixed and the random-effects components, are performed via pseudo-maximum-likelihood wherein inverse probability weights are incorporated in the usual integrated likelihood to account for the design. In comprehensive simulations, cluster-stratified case–control sampling proves to be an efficient design whenever interest lies in fixed or random effects of a generalized linear mixed model and covariates are unobserved or expensive to collect. The methods are motivated by and illustrated with an analysis of N = 889661 Medicare beneficiaries hospitalized between 2011 and 2013 with congestive heart failure at one of K = 3116 hospitals. Results highlight that the framework proposed provides a means of mitigating disparities in terms of which hospitals are indicated as being poor performers, relative to a naive analysis that fails to adjust for missing case mix variables.},
  archive  = {J},
  author   = {Glen McGee and Jonathan Schildcrout and Sharon-Lise Normand and Sebastien Haneuse},
  doi      = {10.1111/rssa.12503},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {1},
  pages    = {379-402},
  title    = {Outcome-dependent sampling in cluster-correlated data settings with application to hospital profiling},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimally balanced gaussian process propensity scores for
estimating treatment effects. <em>Journal of the Royal Statistical
Society: Series A (Statistics in Society)</em>, <em>183</em>(1),
355–377. (<a href="https://doi.org/10.1111/rssa.12502">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Propensity scores are commonly employed in observational study settings where the goal is to estimate average treatment effects. The paper introduces a flexible propensity score modelling approach, where the probability of treatment is modelled through a Gaussian process framework. To evaluate the effectiveness of the estimated propensity score, a metric of covariate imbalance is developed that quantifies the discrepancy between the distributions of covariates in the treated and control groups. It is demonstrated that this metric is ultimately a function of the hyperparameters of the covariance matrix of the Gaussian process and therefore it is possible to select the hyperparameters to optimize the metric and to minimize overall covariate imbalance. The effectiveness of the Gaussian process method is compared in a simulation against other methods of estimating the propensity score and the method is applied to data from a study of Dehejia and Wahba in 1999 to demonstrate benchmark performance within a relevant policy application.},
  archive  = {J},
  author   = {Brian G. Vegetabile and Daniel L. Gillen and Hal S. Stern},
  doi      = {10.1111/rssa.12502},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {1},
  pages    = {355-377},
  title    = {Optimally balanced gaussian process propensity scores for estimating treatment effects},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Inclusion of time-varying covariates in cure survival models
with an application in fertility studies. <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>183</em>(1), 333–354. (<a
href="https://doi.org/10.1111/rssa.12501">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Cure survival models are used when we desire to acknowledge explicitly that an unknown proportion of the population studied will never experience the event of interest. An extension of the promotion time cure model enabling the inclusion of time-varying covariates as regressors when modelling (simultaneously) the probability and the timing of the monitored event is presented. Our proposal enables us to handle non-monotone population hazard functions without a specific parametric assumption on the baseline hazard. This extension is motivated by and illustrated on data from the German Socio-Economic Panel by studying the transition to second and third births in West Germany.},
  archive  = {J},
  author   = {Philippe Lambert and Vincent Bremhorst},
  doi      = {10.1111/rssa.12501},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {1},
  pages    = {333-354},
  title    = {Inclusion of time-varying covariates in cure survival models with an application in fertility studies},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Regression-with-residuals estimation of marginal effects: A
method of adjusting for treatment-induced confounders that may also be
effect modifiers. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>183</em>(1), 311–332. (<a
href="https://doi.org/10.1111/rssa.12497">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {When making causal inferences, treatment-induced confounders complicate analyses of time-varying treatment effects. Conditioning on these variables naively to estimate marginal effects may inappropriately block causal pathways and may induce spurious associations between the treatment and the outcome, leading to bias. Although several methods for estimating marginal effects avoid these complications, including inverse probability of treatment weighted estimation of marginal structural models as well as g - and regression-with-residuals estimation of highly constrained structural nested mean models, each suffers from a set of non-trivial limitations, among them an inability to accommodate effect modification. In this study, we adapt the method of regression with residuals to estimate marginal effects with a set of moderately constrained structural nested mean models that easily accommodate several types of treatment-by-confounder interaction. With this approach, the confounders at each time point are first residualized with respect to the observed past, which involves centring them at their estimated means given prior treatments and confounders. The outcome is then regressed on all prior variables, including a set of treatment-by-confounder interaction terms, with these residuals substituted for the untransformed confounders both as ‘main effects’ and as part of any interaction terms. Through a series of simulation experiments and empirical examples, we show that this approach outperforms other methods for estimating the marginal effects of time-varying treatments.},
  archive  = {J},
  author   = {Geoffrey T. Wodtke and Zahide Alaca and Xiang Zhou},
  doi      = {10.1111/rssa.12497},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {1},
  pages    = {311-332},
  title    = {Regression-with-residuals estimation of marginal effects: A method of adjusting for treatment-induced confounders that may also be effect modifiers},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Estimation of proportions in small areas: Application to the
labour force using the swiss census structural survey. <em>Journal of
the Royal Statistical Society: Series A (Statistics in Society)</em>,
<em>183</em>(1), 281–310. (<a
href="https://doi.org/10.1111/rssa.12498">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The main objectives of this paper are to find efficient but computationally simple estimators for the proportions of people in the labour force (economic activity rates) in Swiss communes and to estimate their mean-squared error (MSE) over the sampling replication mechanism (the design MSE). This will be done by combining survey data with administrative data provided by the Swiss Federal Statistical Office. We find estimators with considerably greater efficiency than currently used direct estimators and that are easy to implement. We show that, under a generalized linear mixed model with logit link, the computationally expensive empirical best predictor does not perform appreciably better than a plug-in estimator. Moreover, for moderate proportions of active workers, the empirical best linear unbiased predictor (EBLUP) based on a much simpler linear mixed model performs similarly to the above estimators. We propose new bootstrap estimators of the design MSE of the EBLUPs, which ‘borrow strength’ similarly to EBLUPs. Realistic simulation studies carried out under both model- and design-based set-ups indicate great gains in efficiency of the selected small area estimators over the traditional direct estimators and acceptable performance of the proposed bootstrap MSE estimators. In the application using the Swiss data, coefficient-of-variation reductions of the estimates obtained for the communes are remarkable.},
  archive  = {J},
  author   = {Isabel Molina and Ewa Strzalkowska-Kominiak},
  doi      = {10.1111/rssa.12498},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {1},
  pages    = {281-310},
  title    = {Estimation of proportions in small areas: Application to the labour force using the swiss census structural survey},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). ‘What drives commuter behaviour?’: A bayesian clustering
approach for understanding opposing behaviours in social surveys.
<em>Journal of the Royal Statistical Society: Series A (Statistics in
Society)</em>, <em>183</em>(1), 251–280. (<a
href="https://doi.org/10.1111/rssa.12499">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The city of Exeter, UK, is experiencing unprecedented growth, putting pressure on traffic infrastructure. As well as traffic network management, understanding and influencing commuter behaviour is important for reducing congestion. Information about current commuter behaviour has been gathered through a large on-line survey, and similar individuals have been grouped to explore distinct behaviour profiles to inform intervention design to reduce commuter congestion. Statistical analysis within societal applications benefit from incorporating available social scientist expert knowledge. Current clustering approaches for the analysis of social surveys assume that the number of groups and the within-group narratives are unknown a priori . Here, however, informed by valuable expert knowledge, we develop a novel Bayesian approach for creating a clear opposing transport mode group narrative within survey respondents, simplifying communication with project partners and the general public. Our methodology establishes groups characterizing opposing behaviours based on a key multinomial survey question by constraining parts of our prior judgement within a Bayesian finite mixture model. Drivers of group membership and within-group behavioural differences are modelled hierarchically by using further information from the survey. In applying the methodology we demonstrate how it can be used to understand the key drivers of opposing behaviours in any wider application.},
  archive  = {J},
  author   = {Laura C. Dawkins and Daniel B. Williamson and Stewart W. Barr and Sally R. Lampkin},
  doi      = {10.1111/rssa.12499},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {1},
  pages    = {251-280},
  title    = {‘What drives commuter behaviour?&#39;: A bayesian clustering approach for understanding opposing behaviours in social surveys},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Parametric modelling of m-quantile regression coefficient
functions with application to small area estimation. <em>Journal of the
Royal Statistical Society: Series A (Statistics in Society)</em>,
<em>183</em>(1), 229–250. (<a
href="https://doi.org/10.1111/rssa.12495">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Small area estimation methods can be used to obtain reliable estimates of a parameter of interest within an unplanned domain or subgroup of the population for which only a limited sample size is available. A standard approach to small area estimation is to use a linear mixed model in which the heterogeneity between areas is accounted for by area level effects. An alternative solution, which has gained popularity in recent years, is to use M -quantile regression models. This approach requires much weaker assumptions than the standard linear mixed model and enables computing outlier robust estimators of the area means. We introduce a new framework for M -quantile regression, in which the model coefficients, β ( τ ), are described by (flexible) parametric functions of τ . We illustrate the advantages of this approach and its application to small area estimation. Using the European Union Survey on Income and Living Conditions data, we estimate the average equivalized household income in three Italian regions. The paper is accompanied by an R package Mqrcm that implements the necessary procedures for estimation, inference and prediction.},
  archive  = {J},
  author   = {Paolo Frumento and Nicola Salvati},
  doi      = {10.1111/rssa.12495},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {1},
  pages    = {229-250},
  title    = {Parametric modelling of M-quantile regression coefficient functions with application to small area estimation},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Productivity, infrastructure and urban density—an allometric
comparison of three european city regions across scales. <em>Journal of
the Royal Statistical Society: Series A (Statistics in Society)</em>,
<em>183</em>(1), 211–228. (<a
href="https://doi.org/10.1111/rssa.12490">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Agglomeration-based arguments citing Dutch and German city regions have been a primary driver in advocating intercity transport strategies in the north of England. We adopt an allometric urban model investigating the applicability and transferability of these transport-led agglomerative strategies promoted to address England&#39;s regional economic underperformance. This is undertaken through a comparative study of the size–cost performance balance of three city regions and the overall urban networks in the Netherlands and Germany, and England and Wales by using city units defined at different spatial scales. Although our results support a case for better mobility and transport comparing the three urban networks regardless of the spatial scales, comparisons of specific city regions indicate a more nuanced interplay of productivity, mobility infrastructure and urban density.},
  archive  = {J},
  author   = {Hadi Arbabi and Martin Mayfield and Philip McCann},
  doi      = {10.1111/rssa.12490},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {1},
  pages    = {211-228},
  title    = {Productivity, infrastructure and urban density—an allometric comparison of three european city regions across scales},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adjusting trial results for biases in meta-analysis:
Combining data-based evidence on bias with detailed trial assessment.
<em>Journal of the Royal Statistical Society: Series A (Statistics in
Society)</em>, <em>183</em>(1), 193–209. (<a
href="https://doi.org/10.1111/rssa.12485">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Flaws in the conduct of randomized trials can lead to biased estimation of the intervention effect. Methods for adjustment of within-trial biases in meta-analysis include the use of empirical evidence from an external collection of meta-analyses, and the use of expert opinion informed by the assessment of detailed trial information. Our aim is to present methods to combine these two approaches to gain the advantages of both. We make use of the risk of bias information that is routinely available in Cochrane reviews, by obtaining empirical distributions for the bias associated with particular bias profiles (combinations of risk of bias judgements). We propose three methods: a formal combination of empirical evidence and opinion in a Bayesian analysis; asking experts to give an opinion on bias informed by both summary trial information and a bias distribution from the empirical evidence, either numerically or by selecting areas of the empirical distribution. The methods are demonstrated through application to two example binary outcome meta-analyses. Bias distributions based on opinion informed by trial information alone were most dispersed on average, and those based on opinions obtained by selecting areas of the empirical distribution were narrowest. Although the three methods for combining empirical evidence with opinion vary in ease and speed of implementation, they yielded similar results in the two examples.},
  archive  = {J},
  author   = {K. M. Rhodes and J. Savović and R. Elbers and H. E. Jones and J. P. T. Higgins and J. A. C. Sterne and N. J. Welton and R. M. Turner},
  doi      = {10.1111/rssa.12485},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {1},
  pages    = {193-209},
  title    = {Adjusting trial results for biases in meta-analysis: Combining data-based evidence on bias with detailed trial assessment},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Spatial hedonic modelling adjusted for preferential
sampling. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>183</em>(1), 169–192. (<a
href="https://doi.org/10.1111/rssa.12489">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Hedonic models are widely used to predict selling prices of properties. Originally, they were proposed as simple spatial regressions, i.e. a spatially referenced response regressed on spatially referenced predictors. Subsequently, spatial random effects were introduced to serve as surrogates for unmeasured or unobservable predictors and were shown to provide better out-of-sample prediction. However, what has been ignored in the literature is the fact that the locations (and times) of the sales are random and, in fact, are an observation of a random point pattern. Here, we first consider whether there is stochastic dependence between the point pattern of locations and the set of responses. If so, a second question is whether incorporating a log-intensity for the point pattern of locations in the hedonic modelling enables improvement in the prediction of selling price. We connect this problem to what is referred to as preferential sampling. Through model comparison we illuminate the role of the point pattern data in the prediction of selling price. Using two different years of property sales from Zaragoza, Spain, we employ both the full database as well as an intentionally biased subset to elaborate this story.},
  archive  = {J},
  author   = {Lucia Paci and Alan E. Gelfand and and María Asunción Beamonte and Pilar Gargallo and Manuel Salvador},
  doi      = {10.1111/rssa.12489},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {1},
  pages    = {169-192},
  title    = {Spatial hedonic modelling adjusted for preferential sampling},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Tracking the evolution of literary style via
dirichlet–multinomial change point regression. <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>183</em>(1), 149–167. (<a
href="https://doi.org/10.1111/rssa.12492">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {It is typical in stylometry to assume that authors have a unique writing style which is common to all their published writings and is constant over time. Based on this assumption, statistical techniques can be used to answer literary questions, such as authorship attribution, in a quantitative manner. However, the claim that authors have a constant literary style has not received much investigation or validation. We propose a collection of statistical models based on Dirichlet–multinomial change point regression which can capture the evolution of writing style over time, including both gradual changes in style as the author matures, and abrupt changes which can be caused by extreme events in the author&#39;s life. To illustrate our framework, we study the literary output of the celebrated British author Sir Terry Pratchett, who was tragically diagnosed with Alzheimer&#39;s disease during the last years of his life. Contrary to the usual assumptions made in stylometry, we find evidence of both gradual changes in style over his lifetime, and an abrupt change which corresponds to his Alzheimer&#39;s diagnosis. We also investigate the published writings of Agatha Christie, who is also rumoured to have suffered from Alheizmer&#39;s disease towards the end of her life, and find evidence of gradual drift, but no corresponding abrupt change. The implications for stylometry and authorship attribution are discussed.},
  archive  = {J},
  author   = {Gordon J. Ross},
  doi      = {10.1111/rssa.12492},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {1},
  pages    = {149-167},
  title    = {Tracking the evolution of literary style via dirichlet–multinomial change point regression},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Data-driven transformations in small area estimation.
<em>Journal of the Royal Statistical Society: Series A (Statistics in
Society)</em>, <em>183</em>(1), 121–148. (<a
href="https://doi.org/10.1111/rssa.12488">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Small area models typically depend on the validity of model assumptions. For example, a commonly used version of the empirical best predictor relies on the Gaussian assumptions of the error terms of the linear mixed regression model: a feature rarely observed in applications with real data. The paper tackles the potential lack of validity of the model assumptions by using data-driven scaled transformations as opposed to ad hoc chosen transformations. Different types of transformations are explored, the estimation of the transformation parameters is studied in detail under the linear mixed regression model and transformations are used in small area prediction of linear and non-linear parameters. The use of scaled transformations is crucial as it enables fitting the linear mixed regression model with standard software and hence it simplifies the work of the data analyst. Mean-squared error estimation that accounts for the uncertainty due to the estimation of the transformation parameters is explored by using the parametric and semiparametric (wild) bootstrap. The methods proposed are illustrated by using real survey and census data for estimating income deprivation parameters for municipalities in the Mexican state of Guerrero. Simulation studies and the results from the application show that using carefully selected, data-driven transformations can improve small area estimation.},
  archive  = {J},
  author   = {Natalia Rojas-Perilla and Sören Pannier and Timo Schmid and Nikos Tzavidis},
  doi      = {10.1111/rssa.12488},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {1},
  pages    = {121-148},
  title    = {Data-driven transformations in small area estimation},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). UK regional nowcasting using a mixed frequency vector
auto-regressive model with entropic tilting. <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>183</em>(1), 91–119. (<a
href="https://doi.org/10.1111/rssa.12491">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Output growth data for the UK regions are available at only annual frequency and are released with significant delay. Regional policy makers would benefit from more frequent and timely data. We develop a stacked, mixed frequency vector auto-regression to provide, each quarter, nowcasts of annual output growth for the UK regions. The information that we use to update our regional nowcasts includes output growth data for the UK as a whole, as these aggregate data are released in a more timely and frequent (quarterly) fashion than the regional disaggregates which they comprise. We show how entropic tilting methods can be adapted to exploit the restriction that UK output growth is a weighted average of regional growth. In our realtime nowcasting application we find that the stacked mixed frequency vector-autoregressive model, with entropic tilting, provides an effective means of nowcasting the regional disaggregates exploiting known information on the aggregate.},
  archive  = {J},
  author   = {Gary Koop and Stuart McIntyre and James Mitchell},
  doi      = {10.1111/rssa.12491},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {1},
  pages    = {91-119},
  title    = {UK regional nowcasting using a mixed frequency vector auto-regressive model with entropic tilting},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A data-driven supply-side approach for estimating
cross-border internet purchases within the european union. <em>Journal
of the Royal Statistical Society: Series A (Statistics in Society)</em>,
<em>183</em>(1), 61–90. (<a
href="https://doi.org/10.1111/rssa.12487">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The digital economy is a highly relevant item on the European Union&#39;s policy agenda. We focus on cross-border Internet purchases, as part of the digital economy, the total value of which cannot be accurately estimated by using existing consumer survey approaches. In fact, they lead to a serious underestimation. To obtain an accurate estimate, we propose a three-step data-driven approach based on supply-side data. For the first step, we develop a data-driven generic method for firm level probabilistic record linkage of tax data and business registers. In the second step, we use machine learning to identify webshops based on website data. Then, in the third step, we implement recently developed bias correction techniques that have hitherto been overlooked by the machine learning community. Subsequently, we claim that our three-step approach can be applied to any European Union member state, leading to more accurate estimates of cross-border Internet purchases than those obtained by currently existing approaches. To justify the claim, we apply our approach to the Netherlands for the year 2016 and find an estimate that is six times as high as current estimates, having a standard deviation of 8\%. Hence, we may conclude that our new approach deserves more investigation and applications.},
  archive  = {J},
  author   = {Q. A. Meertens and C. G. H. Diks and H. J. van den Herik and F. W. Takes},
  doi      = {10.1111/rssa.12487},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {1},
  pages    = {61-90},
  title    = {A data-driven supply-side approach for estimating cross-border internet purchases within the european union},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improved secondary analysis of linked data: A framework and
an illustration. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>183</em>(1), 37–59. (<a
href="https://doi.org/10.1111/rssa.12477">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Applications that use linked data are now part of mainstream social science research, though they generally do not take linkage error into consideration. Solutions that correct for the bias caused by these errors have been proposed but are not yet embedded in the various analysis procedures in common use. Secondary analyses based on linked data can therefore be potentially misleading. We review some recent approaches to non-deterministic data linkage together with a framework for secondary analysis of the linked data which makes use of paradata produced by the linkage process to correct this bias. We also describe a new method for secondary analysis of linked data that builds on this framework and show how it can be used for estimation of a set of domain means based on linked data. We then illustrate this approach via an empirical study based on record linkage of agricultural producers in four states of Brazil aimed at producing estimates of agricultural output by industry. Our study considers register-to-register linkage as well as sample-to-register linkage, and we show results for the traditional Fellegi–Sunter approach to record linkage as well as for a newer linkage procedure based on the use of classification trees and bagging.},
  archive  = {J},
  author   = {Ray Chambers and Andrea Diniz da Silva},
  doi      = {10.1111/rssa.12477},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {1},
  pages    = {37-59},
  title    = {Improved secondary analysis of linked data: A framework and an illustration},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The effect of general health checks on healthcare
utilization: Accounting for self-selection bias. <em>Journal of the
Royal Statistical Society: Series A (Statistics in Society)</em>,
<em>183</em>(1), 3–36. (<a
href="https://doi.org/10.1111/rssa.12482">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The general health check is one of the most common preventive healthcare measures in many countries. In this study, we propose an empirical approach which jointly models the decision to obtain a general health check and healthcare utilization, tackling the self-selection problem by using eligibility to obtain a health check for free as an instrumental variable. Eligibility has some exogenous variations by design and this helps us to partial out the effect of general health checks from self-selection biases. We apply the model to a large 12-year panel data set provided by the Korean National Health Insurance Service. We find that participation in the general health check increases healthcare utilization and ignored self-selection generates substantial upward bias in the estimates. We also find that the health check effect shows noteworthy heterogeneity across gender and income groups. Before health checks, healthcare utilization of males and people in low income groups is lower than those of females and people in high income groups respectively. However, these become comparable across different groups after health checks. This finding implies that general health checks can be an effective vehicle for health equity.},
  archive  = {J},
  author   = {Sungwook Yoon and Duk Bin Jun and Sungho Park},
  doi      = {10.1111/rssa.12482},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {1},
  pages    = {3-36},
  title    = {The effect of general health checks on healthcare utilization: Accounting for self-selection bias},
  volume   = {183},
  year     = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
