<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IJAIT_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ijait---57">IJAIT - 57</h2>
<ul>
<li><details>
<summary>
(2020). Research on automatic vulnerability mining model based on
knowledge graph. <em>IJAIT</em>, <em>29</em>(07n08), 2040024. (<a
href="https://doi.org/10.1142/S0218213020400242">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the information extraction, information sources can be screened according to the characteristics of the target network at the present stage, and the knowledge graph generated thereby can play a role in assisting the security analysis of the general network or power grid control network, mobile Internet and other special networks. In the method proposed in this paper, knowledge reasoning is mainly based on the attack conditions and attack methods to reason about the success rate and return of the attack. Through the obtained quality information, map construction information extraction and reasoning are performed to realize the correlation analysis of the information, and the information processing results are stored in the graphic structure. When analyzing the alerts generated by IDS, it is necessary to solve the multi-source alarm format generated by various devices produced by different suppliers. The attack diagram constructs the attack mode to guide the defense side to take targeted defense measures, and the attack success rate is used to judge the defense priority of all network nodes. After completing the construction of the graph, the attack graph is generated for the specific network environment under the guidance of the knowledge graph. In the process of attack graph generation, attack method and attack condition of attack instance can be used to guide the match of pre-condition and post-condition, so as to find the attack path. Attack success rate and attack profit attribute can be used to assist subsequent risk analysis. After simulation tests, the timeliness and availability of the system are verified, and this makes a contribution to the grid network management.},
  archive      = {J_IJAIT},
  author       = {Ze Chen and Xiaojun Zuo and Botao Hou and Na Dong and Jie Chang},
  doi          = {10.1142/S0218213020400242},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {07n08},
  pages        = {2040024},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Research on automatic vulnerability mining model based on knowledge graph},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modeling method of tax management system based on artificial
intelligence. <em>IJAIT</em>, <em>29</em>(07n08), 2040023. (<a
href="https://doi.org/10.1142/S0218213020400230">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The transformation of taxation processes and the optimization and modeling of their management systems are hot topics in many disciplines such as public management and computer science. Therefore, the intelligent tax management is used to implement the tax process. Meanwhile, tax indicators are adopted as independent variables, and the Logistic regression model is applied to check the selected cases to determine corporate information, which further eliminates less relevant indicators based on the selection results to obtain a more accurate model. In addition, the system modularization design method is applied to design and plan the specific function process of system realization in detail, establishing the necessary business function which can be formed. Moreover, the test process is performed according to the simulation test of the function and the performance of the tax management module. It is proved that the application level of the design module in the paper can meet the current needs, and has the ability of intelligent data analysis and discrimination, which can be promoted within the scope of tax management.},
  archive      = {J_IJAIT},
  author       = {HongBiao Li},
  doi          = {10.1142/S0218213020400230},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {07n08},
  pages        = {2040023},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Modeling method of tax management system based on artificial intelligence},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improved multi-domain convolutional neural networks method
for vehicle tracking. <em>IJAIT</em>, <em>29</em>(07n08), 2040022. (<a
href="https://doi.org/10.1142/S0218213020400229">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of intelligent transportation, background complexity, lighting changes, occlusion, and scale transformation affect the tracking results of moving vehicles in the video. We propose an improved vehicle object tracking algorithm based on Multi-Domain Convolutional Neural Networks (MDNet), combining the instance segmentation method with the MDNet algorithm, adding two attention mechanisms to the algorithm. The module extracts better features, ensures that the vehicle object adapts to changes in appearance, and greatly improves tracking performance. Our improved algorithm has a tracking precision rate of 91.8% and a success rate of 67.8%. The Vehicle Tracking algorithm is evaluated on the Object Tracking Benchmark (OTB) data set. The tracking results are compared with eight mainstream object tracking algorithms, and the results show that our improved algorithm has excellent performance. The object tracking precision rate and tracking success rate of this algorithm have achieved excellent results in many cases.},
  archive      = {J_IJAIT},
  author       = {Jianwen Wang and Aimin Li and Y. Pang},
  doi          = {10.1142/S0218213020400229},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {07n08},
  pages        = {2040022},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Improved multi-domain convolutional neural networks method for vehicle tracking},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Language model pre-training method in machine translation
based on named entity recognition. <em>IJAIT</em>, <em>29</em>(07n08),
2040021. (<a href="https://doi.org/10.1142/S0218213020400217">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural Machine Translation (NMT) model has become the mainstream technology in machine translation. The supervised neural machine translation model trains with abundant of sentence-level parallel corpora. But for low-resources language or dialect with no such corpus available, it is difficult to achieve good performance. Researchers began to focus on unsupervised neural machine translation (UNMT) that monolingual corpus as training data. UNMT need to construct the language model (LM) which learns semantic information from the monolingual corpus. This paper focuses on the pre-training of LM in unsupervised machine translation and proposes a pre-training method, NER-MLM (named entity recognition masked language model). Through performing NER, the proposed method can obtain better semantic information and language model parameters with better training results. In the unsupervised machine translation task, the BLEU scores on the WMT’16 English–French, English–German, data sets are 35.30, 27.30 respectively. To the best of our knowledge, this is the highest results in the field of UNMT reported so far.},
  archive      = {J_IJAIT},
  author       = {Zhen Li and Dan Qu and Chaojie Xie and Wenlin Zhang and Yanxia Li},
  doi          = {10.1142/S0218213020400217},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {07n08},
  pages        = {2040021},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Language model pre-training method in machine translation based on named entity recognition},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Research on logistics distribution route based on
multi-objective sorting genetic algorithm. <em>IJAIT</em>,
<em>29</em>(07n08), 2040020. (<a
href="https://doi.org/10.1142/S0218213020400205">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous development of society, the social division of labor is further improved, and social production tends to be highly specialized and industrialized. Moreover, enterprise production is increasingly internationalized, and sales are gradually expanding. Therefore, the multi-objective sequencing in logistics distribution is incorporated into the path optimization of the logistics system, and a multi-objective bi-level programming model of time and cost is established. What is more, considering the limitations of the traditional algorithm in solving multi-objective problems, the low-dimensional multi-objective problem is selected, and according to the actual situation, the inheritance strategy of genetic factors is adopted to solve the more targeted rapid dominating sorting genetic problem. Besides, the specific conditions and characteristics of the model determine the encoding method, which is brought into the operation of the cross-mutation law and the interruption of individual populations, so that the building foundation of the model is improved. Based on the further theoretical research on the distribution efficiency of logistics system, the corresponding mathematical model is constructed by using the planning method, and the single cost target is transformed into the time and cost double objective, and the improved fast non dominated sorting genetic algorithm with elite strategy is used to solve the problem, which has certain theoretical innovation. Through simulation, the optimal or near optimal path of distribution vehicles in a certain area is given, which has certain practicality and reference value for the optimization of actual logistics distribution path.},
  archive      = {J_IJAIT},
  author       = {Jun Zhao and Hui Xiang and Jinbao Li and Jie Liu and Luyao Guo},
  doi          = {10.1142/S0218213020400205},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {07n08},
  pages        = {2040020},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Research on logistics distribution route based on multi-objective sorting genetic algorithm},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The internet of things based fault tolerant redundancy for
energy router in the interacted and interconnected micro grid.
<em>IJAIT</em>, <em>29</em>(07n08), 2040019. (<a
href="https://doi.org/10.1142/S0218213020400199">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The distribution energy router (DER) is the core of the interacted and interconnected micro grid in future distribution network, which fully meets the needs of the ubiquitous power internet of things (IOT) based future distribution network. The reliability of micro grid which applies the DER is highly related to its cascaded full-bridge converters. With the redundant full-bridge converters and IOT technology, the DER can stand the component failures, hence improve the robustness of the DER as well as the future interacted and interconnected micro grid. For a ubiquitous power IOT technology based DER, this paper proposes a redundancy design for fault tolerant strategy. Several redundancy designs are discussed in detail with operational principles and control strategies. The proposed redundancy design is implemented on the power circuit of one phase for DER consists of a nine-level cascaded full-bridge converter in Saber simulation platform, and the simulation results prove that the redundancy design can minimize the customer’s power interrupt time and the consequent damages to the system.},
  archive      = {J_IJAIT},
  author       = {Zixia Sang and Rengcun Fang and He Lei and Jiong Yan and Dongjun Yang and Yicong Wang},
  doi          = {10.1142/S0218213020400199},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {07n08},
  pages        = {2040019},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {The internet of things based fault tolerant redundancy for energy router in the interacted and interconnected micro grid},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A BERT fine-tuning model for targeted sentiment analysis of
chinese online course reviews. <em>IJAIT</em>, <em>29</em>(07n08),
2040018. (<a href="https://doi.org/10.1142/S0218213020400187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate analysis of targeted sentiment in online course reviews helps in understanding emotional changes of learners and improving the course quality. In this paper, we propose a fine-tuned bidirectional encoder representation from transformers (BERT) model for targeted sentiment analysis of course reviews. Specifically, it consists of two parts: binding corporate rules — conditional random field (BCR-CRF) target extraction model and a binding corporate rules — double attention (BCR-DA) target sentiment analysis model. Firstly, based on a large-scale Chinese review corpus, intra-domain unsupervised training of a BERT pre-trained model (BCR) is performed. Then, a Conditional Random Field (CRF) layer is introduced to add grammatical constraints to the output sequence of the semantic representation layer in the BCR model. Finally, a BCR-DA model containing double attention layers is constructed to express the sentiment polarity of the course review targets in a classified manner. Experiments are performed on Chinese online course review datasets of China MOOC. The experimental results show that the F1 score of the BCR-CRF model reaches above 92%, and the accuracy of the BCR-DA model reaches above 72%.},
  archive      = {J_IJAIT},
  author       = {Huibing Zhang and Junchao Dong and Liang Min and Peng Bi},
  doi          = {10.1142/S0218213020400187},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {07n08},
  pages        = {2040018},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {A BERT fine-tuning model for targeted sentiment analysis of chinese online course reviews},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fixed-frequency current control method of islanding
micro-grid based on improved neural network. <em>IJAIT</em>,
<em>29</em>(07n08), 2040017. (<a
href="https://doi.org/10.1142/S0218213020400175">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the islanding micro-grid operation mode, due to the lack of support from the large power grid, the voltage of the bus and each node in the network is completely supported by the cooperation of the micro-grid inverters in the grid. Therefore, the control performance of the micro-grid inverter determines the quality of the power supply voltage. This paper proposes an improved AC and DC islanding micro-grid fixed frequency current control method with variable topology. First, the neural network algorithm improved by particle swarm optimization is used as the basis to optimize the coordinated compensation control of the micro-grid to obtain the fitness value of the objective function under the positive and negative sequence potentials. Then, a control strategy for the improved AC/DC hybrid micro-grid is proposed, and the decoupling and coordinated control strategy for the output compensation of the dual filters in the islanding mode is designed. Finally, simulations and experiments verify the improved AC/DC hybrid microgrid with variable topology and achieve the goal of constant-frequency current control.},
  archive      = {J_IJAIT},
  author       = {Cuizhe Kuang and Meng Xiao and Zexing Chen and Zehuai Liu and Ziqi Wang and Baoqiang Lv and Guoxin Li},
  doi          = {10.1142/S0218213020400175},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {07n08},
  pages        = {2040017},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Fixed-frequency current control method of islanding micro-grid based on improved neural network},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A key node optimization scheme for public bicycles based on
wavefront theory. <em>IJAIT</em>, <em>29</em>(07n08), 2040016. (<a
href="https://doi.org/10.1142/S0218213020400163">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering the functional attributes of public bicycle outlets, users’ travel destinations and travel distances, this paper proposes a key node optimization scheme for urban public bicycle networks based on the combination of key nodes and wavefront theory. First analyze the net wave surface flow during peak hours to determine key nodes, then schedule or add nodes to achieve normal diversion in the area, and finally introduce betweenness indicators to evaluate the diversion effect. Through an example analysis of the operation data of a city’s public bicycle system, the research results show that the optimization scheme can better meet the dynamic needs of users of the public bicycle system, improve the user’s rental experience, increase user stickiness, and ensure maximum revenue and operating efficiency. It can provide a theoretical basis for the reasonable dispatch of public bicycles at the outlets.},
  archive      = {J_IJAIT},
  author       = {Yali Peng and Ting Liang and Yuxin Yang and Hong Yin and Ping Li and Jiangang Deng},
  doi          = {10.1142/S0218213020400163},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {07n08},
  pages        = {2040016},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {A key node optimization scheme for public bicycles based on wavefront theory},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A redundant manipulator joint torque estimation method based
on disturbance observer. <em>IJAIT</em>, <em>29</em>(07n08), 2040015.
(<a href="https://doi.org/10.1142/S0218213020400151">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous development of the robot industry, both industrial robots and collaborative robots are developing towards light type and intelligence. The core issue is that how to improve the dynamic control performance of robots and reduce costs. The accurate torque feedback control can be achieved by introducing a joint torque sensor. The disadvantages brought by it are higher cost and the limited performance of the torque sensor. Therefore, on the basis of the traditional current estimated torque, combined with the accurate joint torque data fed back by the torque sensor, a method to estimate the harmonic transmission torque in the joint based on the disturbance observer is proposed, and a joint torque model is constructed. At the same time, the compensation factor is introduced to improve the accuracy of torque estimation. In the method proposed in this paper, the theoretical position and actual position, speed difference and motor current of the dual encoder on the motor side and the link side are used to estimate the harmonic transmission torque through the disturbance observer, and the corresponding coefficient is identified. By calibrating the transmission error compensation term and friction force with the torque sensor, the joint torque estimation model is obtained, and the sensorless joint torque estimation can be realized. This method does not require additional torque error compensation caused by harmonic drive deformation in the controller. Therefore, the torque control method without torque sensor is adopted in batch, which is not affected by the configuration and dynamic parameters of the manipulator. In the experiment, the output data of the joint torque sensor is used for testing and comparison. Through the single joint and redundant robot manipulator integration testing, the effectiveness of the proposed joint torque estimation method is verified.},
  archive      = {J_IJAIT},
  author       = {Xun Liu and Yaqiu Liu and Hanchen Zhao},
  doi          = {10.1142/S0218213020400151},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {07n08},
  pages        = {2040015},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {A redundant manipulator joint torque estimation method based on disturbance observer},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Three dimensional measurement system for the dynamic
deformation of aero-engine blade profile. <em>IJAIT</em>,
<em>29</em>(07n08), 2040014. (<a
href="https://doi.org/10.1142/S021821302040014X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to solve the technical problem of three-dimensional profile measurement of aero-engine blades with high speed rotation, an optical dynamic measurement system for aero-engine blades was developed. Firstly, the system is calibrated by the algorithm of spatial truncation phase calibration to establish the index between truncation phase and spatial coordinates. During the measurement, the deformation map of the rotating measured blade is obtained by synchronous projection and snapshot. By using the fast Fourier algorithm, the truncation phase is obtained, and then the profile information of blade can be obtained through the truncation phase and spatial coordinate index. Through the design and construction of the blade simulation platform and dynamic measurement experiment system, the three-dimensional profile data of the blade at different rotating speeds are obtained, compared and analyzed, and then the overall profile deformation law is discovered, which verifies the effectiveness and feasibility of the algorithm. The system can obtain the dynamic profile information of the whole blade completely, and provide innovative technical means for blade design verification and performance analysis.},
  archive      = {J_IJAIT},
  author       = {Yongchao Wei and Chunyan Deng and Xingkun Wu and Liangzhong Ao},
  doi          = {10.1142/S021821302040014X},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {07n08},
  pages        = {2040014},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Three dimensional measurement system for the dynamic deformation of aero-engine blade profile},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Calibration algorithm for error screening based on line
structured light. <em>IJAIT</em>, <em>29</em>(07n08), 2040013. (<a
href="https://doi.org/10.1142/S0218213020400138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The 3D measurement system based on line-structured light uses a camera to capture laser stripes due to changing in the shape of an object, and uses the acquired pixel coordinates for 3D reconstruction. System calibration is an important step in 3D measurement. The current camera calibration algorithm research mainly focuses on improving the algorithm itself, and there is less research on the influence of external factors. This paper proposes a coplanar hybrid calibration algorithm based on the error screening model by combining the error screening model, mathematical model and neural network model. It is mainly divided into two steps. The first step is to use the radial array constraint calibration algorithm based on the error screening model to solve the camera’s internal and external parameters. The second step uses the camera internal and external parameters obtained in the first step to convert the pixel coordinates into real three-dimensional coordinates, and compares the calculated three-dimensional coordinates with the actual coordinates. Using machine learning to establish a compensation network, get a compensation function, and use the resulting 3D world coordinates to perform point cloud stitching. Experiments show that compared with the traditional calibration algorithm, the calibration algorithm has a small error and reduces the calibration error by about 6.5%.},
  archive      = {J_IJAIT},
  author       = {Baolong Liu and Ruixia Wu and Yu Liu},
  doi          = {10.1142/S0218213020400138},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {07n08},
  pages        = {2040013},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Calibration algorithm for error screening based on line structured light},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A seismic image denoising method based on kernel-prediction
CNN architecture. <em>IJAIT</em>, <em>29</em>(07n08), 2040012. (<a
href="https://doi.org/10.1142/S0218213020400126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To filter noises and preserve the details of seismic images, a denoising method based on kernel prediction convolution neural network (CNN) architecture is proposed. The method consists of two convolution layers and a residual connection, containing a source sensing encoder, a spatial feature extractor and a kernel predictor. The scalar kernel was normalized by the softmax function to obtain the denoised images. In addition, to avoid excessive blur at the expense of image details, the authors put forward the concept of asymmetric loss function, which would enable users to control the level of residual noise and make a trade-off between variance and deviation. The experimental results show the proposed method achieved good denoising effect. Compared with some other excellent methods, the proposed method increased the peak signal-to-noise ratio (PSNR) by about 1.0–3.2 dB for seismic images without discontinuity, and about 1.8–3.9 dB for seismic images with discontinuity.},
  archive      = {J_IJAIT},
  author       = {Li Lou and Yong Li},
  doi          = {10.1142/S0218213020400126},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {07n08},
  pages        = {2040012},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {A seismic image denoising method based on kernel-prediction CNN architecture},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Absolute depth measurement of objects based on monocular
vision. <em>IJAIT</em>, <em>29</em>(07n08), 2040011. (<a
href="https://doi.org/10.1142/S0218213020400114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous development of computer vision technology and the continuous upgrading of digital imaging equipment, image depth measurement method is widely used in the fields of intelligent robotics, traffic assistance, three-dimensional modeling and three dimensional video production. The following are the drawbacks of the traditional depth information measurement method: the operation is complex, the cost is high, and the measuring equipment occupies a large space and the load. In this paper, based on the Harris-SIFT corner detection algorithm, a technique is proposed to measure the absolute depth information of the object in the image using monocular vision. First of all, after the monocular camera is used to obtain the image of the target object, the image segmentation algorithm based on the LBF model is used to preprocess the image. Then, Harris algorithm in multi-scale space and SFIT algorithm to reconstruct feature descriptors are used to extract feature information in the image. Finally, by comparing the feature information between image groups, the depth information of target object is calculated by using the formula of convex hull principle and camera imaging principle. The test platform is applied to carry out measurement tests for different depth measurement methods, and the actual depth data and measurement data of the target object are compared, so as to evaluate the accuracy of the measurement method. The comparison results show that the error rate between the actual distance and the measured distance is less than 3.5%, which can accurately measure the absolute depth of the object in static and short distance, and is superior to other measurement methods.},
  archive      = {J_IJAIT},
  author       = {Zhongsheng Wang and Yufeng Lai and Sen Yang and Jiaqiong Gao},
  doi          = {10.1142/S0218213020400114},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {07n08},
  pages        = {2040011},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Absolute depth measurement of objects based on monocular vision},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). GRU-corr neural network optimized by improved PSO algorithm
for time series prediction. <em>IJAIT</em>, <em>29</em>(07n08), 2040010.
(<a href="https://doi.org/10.1142/S0218213020400102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series data from real problems have nonlinear, non-smooth, and multi-scale composite characteristics. This paper first proposes a gated recurrent unit-correction (GRU-corr) network model, which adds a correction layer to the GRU neural network. Then, a adaptive staged variation PSO (ASPSO) is proposed. Finally, to overcome the drawbacks of the imprecise selection of the GRU-corr network parameters and obtain the high-precision global optimization of network parameters, weight parameters and the hidden nodes number of GRU-corr is optimized by ASPSO, and a time series prediction model (ASPSO-GRU-corr) is proposed based on the GRU-corr optimized by ASPSO. In the experiment, a comparative analysis of the optimization performance of ASPSO on a benchmark function was performed to verify its validity, and then the ASPSO-GRU-corr model is used to predict the ship motion cross-sway angle data. The results show that, ASPSO has better optimization performance and convergence speed compared with other algorithms, while the ASPSO-GRU-corr has higher generalization performance and lower architecture complexity. The ASPSO-GRU-corr can reveal the intrinsic multi-scale composite features of the time series, which is a reliable nonlinear and non-steady time series prediction method.},
  archive      = {J_IJAIT},
  author       = {Shao-Pei Ji and Yu-Long Meng and Liang Yan and Gui-Shan Dong and Dong Liu},
  doi          = {10.1142/S0218213020400102},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {07n08},
  pages        = {2040010},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {GRU-corr neural network optimized by improved PSO algorithm for time series prediction},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Automatic RGBD object segmentation based on MSRM framework
integrating depth value. <em>IJAIT</em>, <em>29</em>(07n08), 2040009.
(<a href="https://doi.org/10.1142/S0218213020400096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an automatic RGBD object segmentation method is described. The method integrates depth feature with the cues from RGB images and then uses maximal similarity based region merging (MSRM) method to obtain the segmentation results. Firstly, the depth information is fused to the simple linear iterative clustering (SLIC) method so as to produce superpixels whose boundaries are well adhered to the edges of the natural image. Meanwhile, the depth prior is also incorporated into the saliency estimation, which helps a more accurate localization of representative object and background seeds. By introducing the depth cue into the region merging rule, the maximal geometry weighted similarity (MGWS) is considered, and the resulting segmentation framework has the ability to handle the complex image with similar colour appearance between object and background. Extensive experiments on public RGBD image datasets show that our proposed approach can reliably and automatically provide very promising segmentation results.},
  archive      = {J_IJAIT},
  author       = {Guoqing Li and Guoping Zhang and Chanchan Qin and Anqin Lu},
  doi          = {10.1142/S0218213020400096},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {07n08},
  pages        = {2040009},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Automatic RGBD object segmentation based on MSRM framework integrating depth value},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Network traffic classification using deep learning.
<em>IJAIT</em>, <em>29</em>(07n08), 2040008. (<a
href="https://doi.org/10.1142/S0218213020400084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The large amount of network traffic generated by Internet applications brings great challenges to Internet security. In order to facilitate network management and realize automatic classification of network traffic, this paper proposes a network traffic classification model NTCNET based on CNNs. Use open data set to do simulation verification experiment, then compare the test results with a variety of traditional classification methods. The experimental results shows that the constructed traffic classification model NTCNET has better precision, robustness and accuracy, with an accuracy of 99.66%.},
  archive      = {J_IJAIT},
  author       = {Lei Chen and Jian Liu and Ming Xian},
  doi          = {10.1142/S0218213020400084},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {07n08},
  pages        = {2040008},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Network traffic classification using deep learning},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A hybrid parameter estimation for multi-asset modeling and
dynamic allocation based on financial market microstructure model.
<em>IJAIT</em>, <em>29</em>(07n08), 2040007. (<a
href="https://doi.org/10.1142/S0218213020400072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the previous works, a discrete-time microstructure (DTMS) model for financial market was constructed by using identification technology and was successfully applied to dynamic asset allocation based on the identified excess demand. However, the initial value setting of the parameters has a great influence on the estimated results of the DTMS model, which may make the estimated model to describe the dynamic characteristics of the financial time series poor and also affect the investment results indirectly. To overcome the weakness, this paper proposes a global optimization method which combines particle swarm optimization (PSO) and genetic algorithm (GA) to estimate the initial parameters. In the paper, the multi-asset DTMS model is established, and a multi-asset dynamic allocation strategy based on excess demand obtained from the DTMS model is also designed. Furthermore, the paper also discusses the impact of mutual correlation of assets on portfolio. Case studies show that, when a portfolio is composed of several stocks which are weak correlation, its total return of the portfolio is more than the sum of two-asset allocation for each stock; while the correlation between stocks is high, the obtained total return is not better than those of two-asset allocation.},
  archive      = {J_IJAIT},
  author       = {Yemei Qin and Yangyu Zhong and Zhen Lei and Hui Peng and Feng Zhou and Ping Tan},
  doi          = {10.1142/S0218213020400072},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {07n08},
  pages        = {2040007},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {A hybrid parameter estimation for multi-asset modeling and dynamic allocation based on financial market microstructure model},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An initialization-free distributed algorithm for power
dispatch problem with multiple resources of future distribution network.
<em>IJAIT</em>, <em>29</em>(07n08), 2040006. (<a
href="https://doi.org/10.1142/S0218213020400060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the gradual development of bidirectional interacted future distribution network, it is necessary to enter distributed clean power sources with various characteristics, including wind turbine and solar panel. Traditional centralized control has difficulties to fulfill the demands of future distribution networks for safe, stable, and efficient operation. Aiming at the constrained power allocation problem widely studied in smart grid, with the cooperative control algorithm of continuous multi-agent system, this paper proposed a distributed optimization allocation strategy, which is free by the initial state. The proposed distributed algorithm implements parameterization by adding auxiliary variables. In the iterative process, the algorithm only needs to know the state of the distributed power supply of the neighbor, and finally solve the global optimal solution of the system. The simulations prove that the proposed scheme can effectively improve the economic dispatch performance. Furthermore, comparing to the existing algorithm, the proposed algorithm achieves faster optimal solution.},
  archive      = {J_IJAIT},
  author       = {Zixia Sang and Jiaqi Huang and Dongjun Yang and Jiong Yan and Zhi Du and Rengcun Fang},
  doi          = {10.1142/S0218213020400060},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {07n08},
  pages        = {2040006},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {An initialization-free distributed algorithm for power dispatch problem with multiple resources of future distribution network},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A position weighted information based word embedding model
for machine translation. <em>IJAIT</em>, <em>29</em>(07n08), 2040005.
(<a href="https://doi.org/10.1142/S0218213020400059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning technology promotes the development of neural network machine translation (NMT). End-to-End (E2E) has become the mainstream in NMT. It uses word vectors as the initial value of the input layer. The effect of word vector model directly affects the accuracy of E2E-NMT. Researchers have proposed many approaches to learn word representations and have achieved significant results. However, the drawbacks of these methods still limit the performance of E2E-NMT systems. This paper focuses on the word embedding technology and proposes the PW-CBOW word vector model which can present better semantic information. We apply these word vector models on IWSLT14 German-English, WMT14 English-German, WMT14 English-French corporas. The results evaluate the performance of the PW-CBOW model. In the latest E2E-NMT systems, the PW-CBOW word vector model can improve the performance.},
  archive      = {J_IJAIT},
  author       = {Zhen Li and Dan Qu and Yanxia Li and Chaojie Xie and Qi Chen},
  doi          = {10.1142/S0218213020400059},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {07n08},
  pages        = {2040005},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {A position weighted information based word embedding model for machine translation},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Analytical and simple form of shrinkage functions for
non-convex penalty functions in fused lasso algorithm. <em>IJAIT</em>,
<em>29</em>(6), 2050020. (<a
href="https://doi.org/10.1142/S0218213020500207">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In some circumstances, the performance of machine learning (ML) tasks are based on the quality of signal (data) that is processed in these tasks. Therefore, the pre-processing techniques, such as reconstruction and denoising methods, are important techniques in ML tasks. In reconstructed (estimated) method, the fused lasso algorithm with non-convex penalty function is an efficient method when the signal corrupted by additive white Gaussian noise (AWGN) is considered. Therefore, this paper proposes new shrinkage functions for non-convex penalty functions, modified arctangent and exponential models, in fused lasso formulation. A lot of works present the shrinkage function for arctangent penalty function. Unfortunately, there is no closed-form solution. The numerical solution is required for shrinkage function of this penalty function. However, the analytical solution is derived in this paper. Moreover, the shrinkage function of modified exponential penalty function is proposed. This shrinkage function obtains from simple iterative method, fixed-point algorithm. We demonstrate the proposed methods through simulations with standard one-dimensional signals contaminated by AWGN. The proposed techniques are compared with traditional estimation methods, such as total variation (TV) and wavelet denoising methods. In experimental results, our proposed methods outperform several exiting methods both visual quality and in terms of root mean square error (RMSE). In fact, the proposed methods can better preserve the feature of noise-free signal than the compared methods. The denoised signals produced by the proposed methods are less smooth than the denoised signals produced by the compared methods.},
  archive      = {J_IJAIT},
  author       = {Pichid Kittisuwan},
  doi          = {10.1142/S0218213020500207},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {6},
  pages        = {2050020},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Analytical and simple form of shrinkage functions for non-convex penalty functions in fused lasso algorithm},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A persian medical question answering system. <em>IJAIT</em>,
<em>29</em>(6), 2050019. (<a
href="https://doi.org/10.1142/S0218213020500190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A question answering system is a type of information retrieval that takes a question from a user in natural language as the input and returns the best answer to it as the output. In this paper, a medical question answering system in the Persian language is designed and implemented. During this research, a dataset of diseases and drugs is collected and structured. The proposed system includes three main modules: question processing, document retrieval, and answer extraction. For the question processing module, a sequential architecture is designed which retrieves the main concept of a question by using different components. In these components, rule-based methods, natural language processing, and dictionary-based techniques are used. In the document retrieval module, the documents are indexed and searched using the Lucene library. The retrieved documents are ranked using similarity detection algorithms and the highest-ranked document is selected to be used by the answer extraction module. This module is responsible for extracting the most relevant section of the text in the retrieved document. During this research, different customized language processing tools such as part of speech tagger and lemmatizer are also developed for Persian. Evaluation results show that this system performs well for answering different questions about diseases and drugs. The accuracy of the system for 500 sample questions is 83.6%.},
  archive      = {J_IJAIT},
  author       = {Hadi Veisi and Hamed Fakour Shandi},
  doi          = {10.1142/S0218213020500190},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {6},
  pages        = {2050019},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {A persian medical question answering system},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel online change point detection using an approximate
random blanket and the line process energy. <em>IJAIT</em>,
<em>29</em>(6), 2050018. (<a
href="https://doi.org/10.1142/S0218213020500189">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we focus on the problem of change point detection in piecewise constant signals. This problem is central to several applications such as human activity analysis, speech or image analysis and anomaly detection in genetics. We present a novel window-sliding algorithm for an online change point detection. The proposed approach considers a local blanket of a global Markov Random Field (MRF) representing the signal and its noisy observation. For each window, we define and solve the local energy minimization problem to deduce the gradient on each edge of the MRF graph. The gradient is then processed by an activation function to filter the weak features and produce the final jumps. We demonstrate the effectiveness of our method by comparing its running time and several detection metrics with state of the art algorithms.},
  archive      = {J_IJAIT},
  author       = {A. Belcaid and M. Douimi},
  doi          = {10.1142/S0218213020500189},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {6},
  pages        = {2050018},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {A novel online change point detection using an approximate random blanket and the line process energy},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal consensus recovery of multi-agent system subjected
to agent failure. <em>IJAIT</em>, <em>29</em>(6), 2050017. (<a
href="https://doi.org/10.1142/S0218213020500177">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Agent Systems are susceptible to external disturbances, sensor failures or collapse of communication channel/media. Such failures disconnect the agent network and thereby hamper the consensus of the system. Quick recovery of consensus is vital to continue the normal operation of an agent-based system. However, only limited works in the past have investigated the problem of recovering the consensus of an agent-based system in the event of a failure. This work proposes a novel algorithmic approach to recover the lost consensus, when an agent-based system is subject to the failure of an agent. The main focus of the algorithm is to reconnect the multi-agent network in a way so as to increase the connectivity of the network, post recovery. The proposed algorithm may be applied to both linear and non-linear continuous-time consensus protocols. To verify the efficiency of the proposed algorithm, it has been applied and tested on two multi-agent networks. The results, thus obtained, have been compared with other state-of-the-art recovery algorithms. Finally, it has been established that the proposed algorithm achieves better connectivity and therefore, faster consensus when compared to the other state-of-the-art.},
  archive      = {J_IJAIT},
  author       = {Deep Shekhar Acharya and Sudhansu Kumar Mishra},
  doi          = {10.1142/S0218213020500177},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {6},
  pages        = {2050017},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Optimal consensus recovery of multi-agent system subjected to agent failure},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A hybrid concession mechanism for negotiating software
agents in competitive environments. <em>IJAIT</em>, <em>29</em>(6),
2050016. (<a href="https://doi.org/10.1142/S0218213020500165">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new hybrid concession mechanism for negotiating agents. It considers both the current concession behavior of the proposing agent and the concession offered by its opponent in the last counteroffer to create a new offer. The proposed mechanism is a kind of imitating offer generation tactic. The difference is that it uses the first order difference between the two last counteroffers received from the opponent as its current reservation value which is one of the important inputs in generating a new offer. In this paper, a bilateral negotiation over a single issue is considered where agents have adverse interests over the issue such as price. Four negotiation environmental settings are used to test the proposed offer generating mechanism. The experimental results show that the proposed hybrid concession mechanism outperforms the time-dependent concession tactic in terms of utility rate while performing lower in one negotiation environment and similarly in most of negotiation environments.},
  archive      = {J_IJAIT},
  author       = {Khalid Mansour},
  doi          = {10.1142/S0218213020500165},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {6},
  pages        = {2050016},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {A hybrid concession mechanism for negotiating software agents in competitive environments},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A holistic approach for automatic deep understanding and
protection of technical documents. <em>IJAIT</em>, <em>29</em>(6),
2050007. (<a href="https://doi.org/10.1142/S0218213020500074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Technical Document (TD) is mainly composed by a set of modalities appropriately structured and associated. These modalities could be NL-text, block diagrams, formulas, tables, graphics, pictures etc. A deep understanding of a TD will be based on the synergistic understanding and associations of these modalities. This paper offers a novel methodology for the implementation of a holistic approach for deep understanding of technical documents by understanding and associating these modalities. This approach is based on the homogeneous expression (mapping) of the technical document modalities into the same medium, which in this case is the Stochastic Petri-nets (SPN). Then, these modalities are associated to each other generating new knowledge about the technical document topic and a SPN simulator is created to offer additional information about the functional behavior of the system described in the document. Some results from our studies are provided to prove the overall concept.},
  archive      = {J_IJAIT},
  author       = {Nikolaos Bourbakis and Sukarno Mertoguno},
  doi          = {10.1142/S0218213020500074},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {6},
  pages        = {2050007},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {A holistic approach for automatic deep understanding and protection of technical documents},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A two consequent multi-layers deep discriminative approach
for classifying fMRI images. <em>IJAIT</em>, <em>29</em>(6), 2030001.
(<a href="https://doi.org/10.1142/S021821302030001X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Functional Magnetic Resonance Imaging (fMRI), for many decades acts as a potential aiding method for diagnosing medical problems. Several successful machine learning algorithms have been proposed in literature to extract valuable knowledge from fMRI. One of these algorithms is the convolutional neural network (CNN) that competent with high capabilities for learning optimal abstractions of fMRI. This is because the CNN learns features similarly to human brain where it preserves local structure and avoids distortion of the global feature space. Focusing on the achievements of using the CNN for the fMRI, and accordingly, the Deep Convolutional Auto-Encoder (DCAE) benefits from the data-driven approach with CNN’s optimal features to strengthen the fMRI classification. In this paper, a new two consequent multi-layers DCAE deep discriminative approach for classifying fMRI Images is proposed. The first DCAE is unsupervised sub-model that is composed of four CNN. It focuses on learning weights to utilize discriminative characteristics of the extracted features for robust reconstruction of fMRI with lower dimensional considering tiny details and refining by its deep multiple layers. Then the second DCAE is a supervised sub-model that focuses on training labels to reach an outperformed results. The proposed approach proved its effectiveness and improved literately reported results on a large brain disorder fMRI dataset.},
  archive      = {J_IJAIT},
  author       = {Abeer M. Mahmoud and Hanen Karamti and Fadwa Alrowais},
  doi          = {10.1142/S021821302030001X},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {6},
  pages        = {2030001},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {A two consequent multi-layers deep discriminative approach for classifying fMRI images},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Auxiliary dictionary of diversity learning for face
recognition with a single sample per person. <em>IJAIT</em>,
<em>29</em>(5), 2050015. (<a
href="https://doi.org/10.1142/S0218213020500153">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face recognition for a single sample per person is challenging due to the lack of sufficient sample information. However, using generic training set to learn an auxiliary dictionary is an effective way to alleviate this problem. Considering generic training sample of diversity, we proposed an algorithm of auxiliary dictionary of diversity learning (ADDL). We first produced virtual face images by mirror images, square block occlusion and grey transform, and then learned an auxiliary dictionary of diversity using a designed objective function. Considering patch-based method can reduce the influence of variations, we seek extended sparse representation with l 2 -minimization for each probe patch. Experimental results in the CMUPIE, Extended Yale B and LFW datasets demonstrate that ADDL performs better than other related algorithms.},
  archive      = {J_IJAIT},
  author       = {Weifa Gan and Huixian Yang and Jinfang Zeng and Fan Chen},
  doi          = {10.1142/S0218213020500153},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {5},
  pages        = {2050015},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Auxiliary dictionary of diversity learning for face recognition with a single sample per person},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep learning based sentiment analysis in a code-mixed
english-hindi and english-bengali social media corpus. <em>IJAIT</em>,
<em>29</em>(5), 2050014. (<a
href="https://doi.org/10.1142/S0218213020500141">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis is a circumstantial analysis of text, identifying the social sentiment to better understand the source material. The article addresses sentiment analysis of an English-Hindi and English-Bengali code-mixed textual corpus collected from social media. Code-mixing is an amalgamation of multiple languages, which previously mainly was associated with spoken language. However, social media users also deploy it to communicate in ways that tend to be somewhat casual. The coarse nature of social media text poses challenges for many language processing applications. Here, the focus is on the low predictive nature of traditional machine learners when compared to Deep Learning counterparts, including the contextual language representation model BERT (Bidirectional Encoder Representations from Transformers), on the task of extracting user sentiment from code-mixed texts. Three deep learners (a BiLSTM CNN, a Double BiLSTM and an Attention-based model) attained accuracy 20–60% greater than traditional approaches on code-mixed data, and were for comparison also tested on monolingual English data.},
  archive      = {J_IJAIT},
  author       = {Anupam Jamatia and Steve Durairaj Swamy and Björn Gambäck and Amitava Das and Swapan Debbarma},
  doi          = {10.1142/S0218213020500141},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {5},
  pages        = {2050014},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Deep learning based sentiment analysis in a code-mixed english-hindi and english-bengali social media corpus},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Traffic sign recognition using a synthetic data training
approach. <em>IJAIT</em>, <em>29</em>(5), 2050013. (<a
href="https://doi.org/10.1142/S021821302050013X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic Sign Recognition (TSR) is a crucial component in many automotive applications, such as driver assistance, sign maintenance, and vehicle autonomy. In this paper, we present an efficient approach to training a machine learning-based TSR solution. In our choice of recognition method, we have opted for convolutional neural networks, which have demonstrated best-in-class performance in previous works on TSR. One of the challenges related to training deep neural networks is the requirement for a large amount of training data. To circumvent the tedious process of acquiring and manually labelling real data, we investigate the use of synthetically generated images. Our networks, trained on only synthetic data, are capable of recognising traffic signs in challenging real-world footage. The classification results achieved on the GTSRB benchmark are seen to outperform existing state-of-the-art solutions.},
  archive      = {J_IJAIT},
  author       = {Oualid Araar and Abdenour Amamra and Asma Abdeldaim and Ivan Vitanov},
  doi          = {10.1142/S021821302050013X},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {5},
  pages        = {2050013},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Traffic sign recognition using a synthetic data training approach},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Neural networks as classification mechanisms of complex
human activities. <em>IJAIT</em>, <em>29</em>(5), 2050011. (<a
href="https://doi.org/10.1142/S0218213020500116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Within this paper, we present two neural nets for view-independent complex human activity recognition (HAR) from video frames. For our study here, we reduce the number of frames produced by a video sequence given that we can identify activities from a sparsely sampled sequence of body poses, and, at the same time, we are able to reduce the processing complexity and response while hardly affecting the accuracy, precision, and recall. To do so, we use a formal framework to ensure the quality of data collection and data preprocessing. We utilize neural networks for the classification of single and complex body activities. More specifically, we consider the sequence of body poses as a time-series problem given that they can provide state-of-the-art results on challenging recognition tasks with little data engineering. Deep Learning in the form of Convolutional Neural Network (CNN), Long Short-Term Neural Network (LSTM), and a one-dimensional Convolutional Neural Network Long Short-Term Memory model (CNN-LSTM) are used as benchmarks to classify the activity.},
  archive      = {J_IJAIT},
  author       = {Anargyros Angeleas and Nikolaos Bourbakis},
  doi          = {10.1142/S0218213020500116},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {5},
  pages        = {2050011},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Neural networks as classification mechanisms of complex human activities},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Variance counterbalancing for stochastic large-scale
learning. <em>IJAIT</em>, <em>29</em>(5), 2050010. (<a
href="https://doi.org/10.1142/S0218213020500104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic Gradient Descent (SGD) is perhaps the most frequently used method for large scale training. A common example is training a neural network over a large data set, which amounts to minimizing the corresponding mean squared error (MSE). Since the convergence of SGD is rather slow, acceleration techniques based on the notion of “Mini-Batches” have been developed. All of them however, mimicking SGD, impose diminishing step-sizes as a means to inhibit large variations in the MSE objective. In this article, we introduce random sets of mini-batches instead of individual mini-batches. We employ an objective function that minimizes the average MSE and its variance over these sets, eliminating so the need for the systematic step size reduction. This approach permits the use of state-of-the-art optimization methods, far more efficient than the gradient descent, and yields a significant performance enhancement.},
  archive      = {J_IJAIT},
  author       = {Pola Lydia Lagari and Lefteri H. Tsoukalas and Isaac E. Lagaris},
  doi          = {10.1142/S0218213020500104},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {5},
  pages        = {2050010},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Variance counterbalancing for stochastic large-scale learning},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Systematic construction of neural forms for solving partial
differential equations inside rectangular domains, subject to initial,
boundary and interface conditions. <em>IJAIT</em>, <em>29</em>(5),
2050009. (<a href="https://doi.org/10.1142/S0218213020500098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A systematic approach is developed for constructing proper trial solutions to Partial Differential Equations (PDEs) of up to second order, using neural forms that satisfy prescribed initial, boundary and interface conditions. The spatial domain considered is of the rectangular hyper-box type. On each face either Dirichlet or Neumann conditions may apply. Robin conditions may be accommodated as well. Interface conditions that induce discontinuities, have not been treated to date in the relevant neural network literature. As an illustration a common problem of heat conduction through a system of two rods in thermal contact is considered.},
  archive      = {J_IJAIT},
  author       = {Pola Lydia Lagari and Lefteri H. Tsoukalas and Salar Safarkhani and Isaac E. Lagaris},
  doi          = {10.1142/S0218213020500098},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {5},
  pages        = {2050009},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Systematic construction of neural forms for solving partial differential equations inside rectangular domains, subject to initial, boundary and interface conditions},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Application of improved artificial intelligence with
runner-root meta-heuristic algorithm for dairy products industry: A case
study. <em>IJAIT</em>, <em>29</em>(5), 2050008. (<a
href="https://doi.org/10.1142/S0218213020500086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the dairy products have a short consumption period, the accurate prediction of their demand is very important for the dairy industry. Accordingly, this research specifically addresses the prediction of dairy product demand (DPD). The main contribution of this research is to provide an integrated framework based on statistical tests, time-series prediction and artificial intelligence with the runner-root algorithm (RRA) as a novel meta-heuristic algorithm to obtain the best prediction of DPD in Iran. First, a series of economic and social indicators that seemed to be effective in the demand for dairy products are identified and the ineffective indices are eliminated. Next, the artificial intelligence tools including MLP, ANFIS, and LSTM are implemented and improved with the help of RRA. The designed hybrid methods are implemented by using data from 2013 to 2017 of the Iran diary industry. This novel algorithm is compared to gray wolf optimization, invasive weed optimization, and particle swarm optimization. The results show that the proposed MLP-RRA has the most ability to improve by using meta-heuristic algorithms. The coefficient of determination is 98.19%. Moreover, in each artificial intelligence tools, RRA causes better results than the other tested algorithms. The highly accurate results confirm that the proposed hybrid methods based on the RRA algorithm are able to improve the prediction of demand for various products.},
  archive      = {J_IJAIT},
  author       = {Alireza Goli and Ehsan Moeini and Ahmad M. Shafiee and Mohammad Zamani and Elham Touti},
  doi          = {10.1142/S0218213020500086},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {5},
  pages        = {2050008},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Application of improved artificial intelligence with runner-root meta-heuristic algorithm for dairy products industry: A case study},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Smart cities — detecting humans in regions of disasters:
Synergy of drones, micro-robots in underground tunnels. <em>IJAIT</em>,
<em>29</em>(5), 2050006. (<a
href="https://doi.org/10.1142/S0218213020500062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pieces of information that are being collected from regions of disaster is critical as the rapid deployment of the first responders rely on them. Another critical part of that deployment is the acquisition of different types of information (visual, sounds, and others). Even with that information the rescuing teams still face the difficult task of rescuing humans under debris. Some of the constraints that make this task harder are the wrecked building’s unknown structure, time limitation, the difficulty to collect information under the debris and more. An important issue is the accurate collection of information beneath destroyed structures and the 3D representation of the space and the correct location of the human subject under the debris. This paper deals with the design and the capabilities of a ground bio-inspired micro-robot, called Tzitziki, capable to select visual and audio information beneath destroyed buildings and locate human subjects in areas (like deep underground cavities), the reconstruction of the underground cavities and the synergistic collaboration of drones, micro-robots and human first responders. Illustrative examples are provided proving the concept.},
  archive      = {J_IJAIT},
  author       = {Nikolaos Bourbakis and Iosif Papadakis Ktistakis and Tarek Seleem},
  doi          = {10.1142/S0218213020500062},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {5},
  pages        = {2050006},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Smart cities — detecting humans in regions of disasters: Synergy of drones, micro-robots in underground tunnels},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Estimation of personalized heterogeneous treatment effects
using concatenation and augmentation of feature vectors. <em>IJAIT</em>,
<em>29</em>(5), 2050005. (<a
href="https://doi.org/10.1142/S0218213020500050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new meta-algorithm for estimating the conditional average treatment effects is pro-posed in the paper. The basic idea behind the algorithm is to consider a new dataset consisting of feature vectors produced by means of concatenation of examples from control and treatment groups, which are close to each other. Outcomes of new data are defined as the difference between outcomes of the corresponding examples comprising new feature vectors. The second idea is based on the assumption that the number of controls is rather large and the control outcome function is precisely determined. This assumption allows us to augment treatments by generating feature vectors which are closed to available treatments. The outcome regression function constructed on the augmented set of concatenated feature vectors can be viewed as an estimator of the conditional average treatment effects. A simple modification of the Co-learner based on the random subspace method or the feature bagging is also proposed. Various numerical simulation experiments illustrate the proposed algorithm and show its outperformance in comparison with the well-known T-learner and X-learner for several types of the control and treatment outcome functions.},
  archive      = {J_IJAIT},
  author       = {Lev V. Utkin and Mikhail V. Kots and Viacheslav S. Chukanov and Andrei V. Konstantinov and Anna A. Meldo},
  doi          = {10.1142/S0218213020500050},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {5},
  pages        = {2050005},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Estimation of personalized heterogeneous treatment effects using concatenation and augmentation of feature vectors},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Enhanced unsatisfiable cores for QBF: Weakening universal to
existential quantifiers. <em>IJAIT</em>, <em>29</em>(03n04), 2060012.
(<a href="https://doi.org/10.1142/S021821302060012X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce an enhanced notion of unsatisfiable cores for QBF in prenex CNF that allows to weaken universal quantifiers to existential quantifiers in addition to the traditional removal of clauses. The resulting unsatisfiable cores can be different from those of the traditional notion in terms of syntax, standard semantics, and proof-based semantics. This not only gives rise to explanations of unsatisfiability but, via duality, also leads to diagnoses and repairs of unsatisfiability that are not obtained with traditional unsatisfiable cores. We use a source-to-source transformation on QBF in PCNF such that the weakening of universal quantifiers to existential quantifiers in the original formula corresponds to the removal of clauses in the transformed formula. This makes any tool or method for the computation of unsatisfiable cores of the traditional notion available for the computation of unsatisfiable cores of our enhanced notion. We implement our approach as an extension to the QBF solver DepQBF, and we perform an extensive experimental evaluation on a subset of QBFLIB. We illustrate with several case studies that helpful information can be provided by unsatisfiable cores of our enhanced notion.},
  archive      = {J_IJAIT},
  author       = {Viktor Schuppan},
  doi          = {10.1142/S021821302060012X},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {03n04},
  pages        = {2060012},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Enhanced unsatisfiable cores for QBF: Weakening universal to existential quantifiers},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Acoustic diversity classification using machine learning
techniques: Towards automated marine big data analysis. <em>IJAIT</em>,
<em>29</em>(03n04), 2060011. (<a
href="https://doi.org/10.1142/S0218213020600118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the last years, big data has become the new emerging trend that increasingly attracting the attention of the R&amp;D community in several fields (e.g., image processing, database engineering, data mining, artificial intelligence). Marine data is part of these fields which accommodates this growth, hence the appearance of marine big data paradigm that monitoring advocates the assessment of human impact on marine data. Nonetheless, supporting acoustic sounds classification is missing in such environment, with taking into account the diversity of such data (i.e., sounds of living undersea species, sounds of human activities, and sounds of environmental effects). To overcome this issue, we propose in this paper an approach that efficiently allowing acoustic diversity classification using machine learning techniques. The aim is to reach an automated support of marine big data analysis. We have conducted a set of experiments, using a real marine dataset, in order to validate our approach and show its effectiveness and efficiency. To do so, three machine learning techniques are employed: (i) classic machine learning models (i.e., k-nearest neighbor and support vector machine), (ii) deep learning based on convolutional neural networks, and (iii) transfer learning based on the reuse of pretrained models.},
  archive      = {J_IJAIT},
  author       = {Emna Hachicha Belghith and François Rioult and Medjber Bouzidi},
  doi          = {10.1142/S0218213020600118},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {03n04},
  pages        = {2060011},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Acoustic diversity classification using machine learning techniques: Towards automated marine big data analysis},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Heterogeneous island models and their application to
recommender systems and electric vehicle charging. <em>IJAIT</em>,
<em>29</em>(03n04), 2060010. (<a
href="https://doi.org/10.1142/S0218213020600106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we describe a general framework for parallel optimization based on the island model of evolutionary algorithms. The framework runs a number of optimization methods in parallel with periodic communication. In this way, it essentially creates a parallel ensemble of optimization methods. At the same time, the system contains a planner that decides which of the available optimization methods should be used to solve the given optimization problem and changes the distribution of such methods during the run of the optimization. Thus, the system effectively solves the problem of online parallel portfolio selection. The proposed system is evaluated in a number of common benchmarks with various problem encodings as well as in two real-life problems — the optimization in recommender systems and the training of neural networks for the control of electric vehicle charging.},
  archive      = {J_IJAIT},
  author       = {Štěpán Balcar and Martin Pilát},
  doi          = {10.1142/S0218213020600106},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {03n04},
  pages        = {2060010},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Heterogeneous island models and their application to recommender systems and electric vehicle charging},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Building high performance explainable machine learning
models for social media-based substance use prediction. <em>IJAIT</em>,
<em>29</em>(03n04), 2060009. (<a
href="https://doi.org/10.1142/S021821302060009X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media contain rich information that can be used to help understand human mind and behavior. Social media data, however, are mostly unstructured (e.g., text and image) and a large number of features may be needed to represent them (e.g., we may need millions of unigrams to represent social media texts). Moreover, accurately assessing human behavior is often difficult (e.g., assessing addiction may require medical diagnosis). As a result, the ground truth data needed to train a supervised human behavior model are often difficult to obtain at a large scale. To avoid overfitting, many state-of-the-art behavior models employ sophisticated unsupervised or self-supervised machine learning methods to leverage a large amount of unsupervised data for both feature learning and dimension reduction. Unfortunately, despite their high performance, these advanced machine learning models often rely on latent features that are hard to explain. Since understanding the knowledge captured in these models is important to behavior scientists and public health providers, we explore new methods to build machine learning models that are not only accurate but also interpretable. We evaluate the effectiveness of the proposed methods in predicting Substance Use Disorders (SUD). We believe the methods we proposed are general and applicable to a wide range of data-driven human trait and behavior analysis applications.},
  archive      = {J_IJAIT},
  author       = {Tao Ding and Fatema Hasan and Warren K. Bickel and Shimei Pan},
  doi          = {10.1142/S021821302060009X},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {03n04},
  pages        = {2060009},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Building high performance explainable machine learning models for social media-based substance use prediction},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evaluating the effects of modern storage devices on the
efficiency of parallel machine learning algorithms. <em>IJAIT</em>,
<em>29</em>(03n04), 2060008. (<a
href="https://doi.org/10.1142/S0218213020600088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Big Data analytics is presently one of the most emerging areas of research for both organizations and enterprises. The requirement for deployment of efficient machine learning algorithms over huge amounts of data led to the development of parallelization frameworks and of specialized libraries (like Mahout and MLlib) which implement the most important among these algorithms. Moreover, the recent advances in storage technology resulted in the introduction of high-performing devices, broadly known as Solid State Drives (SSDs). Compared to the traditional Hard Drives (HDDs), SSDs offer considerably higher performance and lower power consumption. Motivated by these appealing features and the growing necessity for efficient large-scale data processing, we compared the performance of several machine learning algorithms on MapReduce clusters whose nodes are equipped with HDDs, SSDs, and devices which implement the latest 3D XPoint technology. In particular, we evaluate several dataset preprocessing methods like vectorization and dimensionality reduction, two supervised classifiers, Naive Bayes and Linear Regression, and the popular k -Means clustering algorithm. We use an experimental cluster equipped with the three aforementioned storage devices under different configurations, and two large datasets, Wikipedia and HIGGS. The experiments showed that the benefits which derive from the usage of SSDs depend on the cluster setup and the nature of the applied algorithms.},
  archive      = {J_IJAIT},
  author       = {Leonidas Akritidis and Athanasios Fevgas and Panagiota Tsompanopoulou and Panayiotis Bozanis},
  doi          = {10.1142/S0218213020600088},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {03n04},
  pages        = {2060008},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Evaluating the effects of modern storage devices on the efficiency of parallel machine learning algorithms},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Assigning and scheduling service visits in a mixed
urban/rural setting. <em>IJAIT</em>, <em>29</em>(03n04), 2060007. (<a
href="https://doi.org/10.1142/S0218213020600076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper a describes a maintenance scheduling application, which was developed together with an industrial partner. This is a highly combinatorial decision process, to plan and schedule the work of a group of travelling repair technicians, which perform preventive and corrective maintenance tasks at customer locations. Customers are located both in urban areas, where many customers are in close proximity, and in sparsely populated rural areas, where the travel time between customer sites is significant. To balance the workload for the agents, we must consider both the productive working time, as well as the travel between locations. As the monolithic problem formulation is unmanageable, we introduce a problem decomposition into multiple sequential steps, that is compatible with current management practice. We present and compare different models for the solution steps, and discuss results on datasets provided by the industrial partner.},
  archive      = {J_IJAIT},
  author       = {Mark Antunes and Vincent Armant and Kenneth N. Brown and Daniel Desmond and Guillaume Escamocher and Anne-Marie George and Diarmuid Grimes and Mike O’Keeffe and Yiqing Lin and Barry O’Sullivan and Cemalettin Ozturk and Luis Quesada and Mohamed Siala and Helmut Simonis and Nic Wilson},
  doi          = {10.1142/S0218213020600076},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {03n04},
  pages        = {2060007},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Assigning and scheduling service visits in a mixed Urban/Rural setting},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). ITE: A lightweight implementation of stratified reasoning
for constructive logical operators. <em>IJAIT</em>, <em>29</em>(03n04),
2060006. (<a href="https://doi.org/10.1142/S0218213020600064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constraint Programming (CP) is a powerful declarative programming paradigm where inference and search are interleaved to find feasible and optimal solutions to various type of constraint systems. However, handling logical connectors with constructive information in CP is notoriously difficult. This paper presents I f T hen E lse (ITE), a lightweight implementation of stratified constructive reasoning for logical connectives. Stratification is introduced to cope with the risk of combinatorial explosion of constructing information from nested and combined logical operators. ITE is an open-source library built on top of SICStus Prolog clpfd, which proposes various operators, including constructive disjunction and negation, constructive implication and conditional. These operators can be used to express global constraints and to benefit from constructive reasoning for more domain pruning during constraint filtering. Even though ITE is not competitive with specialized filtering algorithms available in some global constraints implementations, its expressiveness allows users to easily define well-tuned constraints with powerful deduction capabilities. Our extended experimental results show that ITE is more efficient than available generic approaches that handle logical constraint systems over finite domains.},
  archive      = {J_IJAIT},
  author       = {Arnaud Gotlieb and Dusica Marijan and Helge Spieker},
  doi          = {10.1142/S0218213020600064},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {03n04},
  pages        = {2060006},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {ITE: A lightweight implementation of stratified reasoning for constructive logical operators},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Possibilistic networks: Computational analysis of MAP and
MPE inference. <em>IJAIT</em>, <em>29</em>(03n04), 2060005. (<a
href="https://doi.org/10.1142/S0218213020600052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Possibilistic graphical models are powerful modeling and reasoning tools for uncertain information based on possibility theory. In this paper, we provide an analysis of computational complexity of MAP and MPE queries for possibilistic networks. MAP queries stand for maximum a posteriori explanation while MPE ones stand for most plausible explanation. We show that the decision problems of answering MAP and MPE queries in both min-based and product-based possibilistic networks is NP -complete. Definitely, such results represent an advantage of possibilistic graphical models over probabilistic ones since MAP queries are NP PP -complete in Bayesian networks. Our proofs for querying min-based possibilistic networks make use of reductions from the 3SAT problem to querying possibilistic networks decision problem. Moreover, the provided reductions may be useful for the implementation of MAP and MPE inference engines based on the satisfiability problem solvers. As for product-based networks, the provided proofs are incremental and make use of reductions from SAT and its weighted variant WMAXSAT.},
  archive      = {J_IJAIT},
  author       = {Amélie Levray and Salem Benferhat and Karim Tabia},
  doi          = {10.1142/S0218213020600052},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {03n04},
  pages        = {2060005},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Possibilistic networks: Computational analysis of MAP and MPE inference},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Selecting and combining classifiers based on centrality
measures. <em>IJAIT</em>, <em>29</em>(03n04), 2060004. (<a
href="https://doi.org/10.1142/S0218213020600040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Centrality measures have been helping to explain the behavior of objects, given their relation, in a wide variety of problems, since sociology to chemistry. This work considers these measures to assess the importance of every classifier belonging to an ensemble of classifiers, aiming to improve a Multiple Classifier System (MCS). Assessing the classifier’s importance by employing centrality measures, inspired two different approaches: one for selecting classifiers and another for fusion. The selection approach, called Centrality Based Selection (CBS), adopts a trade-off between the classifier’s accuracy and their diversity. The sub-optimal selected subset presents good results against selection methods from the literature, being superior in 67.22% of the cases. The second approach, the integration, is named Centrality Based Fusion (CBF). This approach is a weighted combination method, which is superior to literature in 70% of the cases.},
  archive      = {J_IJAIT},
  author       = {Ronan Assumpção Silva and Alceu S. Britto Jr. and Fabricio Enembreck and Robert Sabourin and Luiz S. Oliveira},
  doi          = {10.1142/S0218213020600040},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {03n04},
  pages        = {2060004},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Selecting and combining classifiers based on centrality measures},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Logical encoding of argumentation frameworks with
higher-order attacks and evidential supports. <em>IJAIT</em>,
<em>29</em>(03n04), 2060003. (<a
href="https://doi.org/10.1142/S0218213020600039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a logical encoding of argumentation frameworks with higher-order interactions ( i.e . attacks/supports whose targets are arguments or other attacks/supports) with an evidential meaning for supports. Our purpose is to separate the logical expression of the meaning of an attack or an evidential support (simple or higher-order) from the logical expression of acceptability semantics. We consider semantics which specify the conditions under which the arguments (resp. the attacks/supports) are considered as accepted, directly on the extended framework, without translating the original framework into a Dung’s argumentation framework. We characterize the output of a given framework in logical terms (namely as particular models of a logical theory). Our proposal applies to the particular case of Dung’s frameworks, enabling to recover standard extensions.},
  archive      = {J_IJAIT},
  author       = {Claudette Cayrol and Marie-Christine Lagasquie-Schiex},
  doi          = {10.1142/S0218213020600039},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {03n04},
  pages        = {2060003},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Logical encoding of argumentation frameworks with higher-order attacks and evidential supports},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sparse deep neural network optimization for embedded
intelligence. <em>IJAIT</em>, <em>29</em>(03n04), 2060002. (<a
href="https://doi.org/10.1142/S0218213020600027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks become more popular as its ability to solve very complex pattern recognition problems. However, deep neural networks often need massive computational and memory resources, which is main reason resulting them to be difficult efficiently and entirely running on embedded platforms. This work addresses this problem by saving the computational and memory requirements of deep neural networks by proposing a variance reduced (VR)-based optimization with regularization techniques to compress the requirements of memory of models within fast training process. It is shown theoretically and experimentally that sparsity-inducing regularization can be effectively worked with the VR-based optimization whereby in the optimizer the behaviors of the stochastic element is controlled by a hyper-parameter to solve non-convex problems.},
  archive      = {J_IJAIT},
  author       = {Jia Bi and Steve R. Gunn},
  doi          = {10.1142/S0218213020600027},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {03n04},
  pages        = {2060002},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Sparse deep neural network optimization for embedded intelligence},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Interval tests and contractors based on optimality
conditions for bound-constrained global optimization. <em>IJAIT</em>,
<em>29</em>(03n04), 2060001. (<a
href="https://doi.org/10.1142/S0218213020600015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of finding the global optimum of a nonlinear real function over an interval box by means of complete search techniques, namely interval branch-and-bound algorithms. Such an algorithm typically generates a tree of boxes from the initial box by alternating branching steps and contraction steps in order to remove non optimal sub-boxes. In this paper, we introduce a new contraction method that is designed to handle the boundary of the initial box where a minimizer may not be a stationary point. This method exploits the first-order optimality conditions and we show that it subsumes the classical monotonicity test based on interval arithmetic. A new branch-and-bound algorithm has been implemented in the interval solver Realpaver. An extensive experimental study based on a set of standard benchmarks is presented.},
  archive      = {J_IJAIT},
  author       = {Laurent Granvilliers},
  doi          = {10.1142/S0218213020600015},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {03n04},
  pages        = {2060001},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Interval tests and contractors based on optimality conditions for bound-constrained global optimization},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sentiment analysis of teachers using social information in
educational platform environments. <em>IJAIT</em>, <em>29</em>(2),
2040004. (<a href="https://doi.org/10.1142/S0218213020400047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learners’ opinions constitute an important source of information that can be useful to teachers and educational instructors in order to improve learning procedures and training activities. By analyzing learners’ actions and extracting data related to their learning behavior, educators can specify proper learning approaches to stimulate learners’ interest and contribute to constructive monitoring of learning progress during the course or to improve future courses. Learners-generated content and their feedback and comments can provide indicative information about the educational procedures that they attended and the training activities that they participated in. Educational systems must possess mechanisms to analyze learners’ comments and automatically specify their opinions and attitude towards the courses and the learning activities that are offered to them. This paper describes a Greek language sentiment analysis system that analyzes texts written in Greek language and generates feature vectors which together with classification algorithms give us the opportunity to classify Greek texts based on the personal opinion and the degree of satisfaction expressed. The sentiment analysis module has been integrated into the hybrid educational systems of the Greek school network that offers life-long learning courses. The module offers a wide range of possibilities to lecturers, policymakers and educational institutes that participate in the training procedure and offers life-long learning courses, to understand how their learners perceive learning activities and specify what aspects of the learning activities they liked and disliked. The experimental study show quite interesting results regarding the performance of the sentiment analysis methodology and the specification of users’ opinions and satisfaction. The feature analysis demonstrates interesting findings regarding the characteristics that provide indicative information for opinion analysis and embeddings combined with deep learning approaches yield satisfactory results.},
  archive      = {J_IJAIT},
  author       = {Nikolaos Spatiotis and Isidoros Perikos and Iosif Mporas and Michael Paraskevas},
  doi          = {10.1142/S0218213020400047},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {2},
  pages        = {2040004},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Sentiment analysis of teachers using social information in educational platform environments},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fuzzy information diffusion in twitter by considering user’s
influence. <em>IJAIT</em>, <em>29</em>(2), 2040003. (<a
href="https://doi.org/10.1142/S0218213020400035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Does a post with specific emotional content that is posted on Twitter by an influential user have the capability to affect and even alter the opinions of those who read it? Accordingly, “influential” users affected by this post can then affect their followers so that eventually a large number of users may change their opinions about the subject the aforementioned post was made on? Social Influence can be described as the power or even the ability of a person to yet influence the thoughts and actions of other users. So, User Influence stands as a value that depends on the interest of the followers (via replies, mentions, retweets, favorites). Our study focuses on identifying such phenomena on the Twitter graph of posts and on determining which users’ posts can trigger them. Furthermore, we analyze the Influence Metrics of all users taking part in specific discussions and verify the differences among them. Finally the percentage of Graph cover when the diffusion starts from the “influential” users, is measured and corresponding results are extracted. Hence, results show that the proposed implementations and methodology can assist in identifying “influential” users, that play a dominant role in information diffusion.},
  archive      = {J_IJAIT},
  author       = {Andreas Kanavos and Ioannis E. Livieris},
  doi          = {10.1142/S0218213020400035},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {2},
  pages        = {2040003},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Fuzzy information diffusion in twitter by considering user’s influence},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Short semantic patterns: A linguistic pattern mining
approach for content analysis applied to hate speech. <em>IJAIT</em>,
<em>29</em>(2), 2040002. (<a
href="https://doi.org/10.1142/S0218213020400023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microblog posts such as tweets frequently contain users’ opinions and thoughts about events, products, people, institutions, etc. However, the usage of social media to prop-agate hate speech is not an uncommon occurrence. Analyzing hateful speech in social media is essential for understanding, fighting and discouraging such actions. We believe that by extracting fragments of text that are semantically similar it is possible to depict recurrent linguistic patterns in certain kinds of discourse. Therefore, we aim to use these patterns to encapsulate frequent statements textually expressed in microblog posts. In this paper, we propose to exploit such linguistic patterns in the context of hate speech. Through a technique that we call SSP (Short Semantic Pattern) mining, we are able to extract sequences of words that share a similar meaning in their word embedding representation. By analyzing the extracted patterns, we reveal some kinds of discourses that are replayed across a dataset, such as racist and sexist statements. Afterwards, we experiment using SSP as features to build classifiers that detect if a tweet contains hate speech (binary classification) and to distinguish between sexist, racist and clean tweets (ternary classification). The SSP instances encountered in tweets containing sexism have shown that a large number of sexist tweets began with the introduction ‘I’m not sexist but’ and ‘Call me sexist but’ . Meanwhile, SSP instances found in tweets reproducing racism revealed a prominence of contents against the Islamic religion, associated entities and organizations.},
  archive      = {J_IJAIT},
  author       = {Danielly Sorato and Fábio B. Goularte and Renato Fileto},
  doi          = {10.1142/S0218213020400023},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {2},
  pages        = {2040002},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Short semantic patterns: A linguistic pattern mining approach for content analysis applied to hate speech},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Anticipointment detection in event tweets. <em>IJAIT</em>,
<em>29</em>(2), 2040001. (<a
href="https://doi.org/10.1142/S0218213020400011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We developed a system to detect positive expectation, disappointment, and satisfaction in tweets that refer to events automatically discovered in the Twitter stream. The emotional content shared on Twitter when referring to public events can provide insights into the presumed and experienced quality of the event. We expected to find a connection between positive expectation and disappointment, a succession that is referred to as anticipointment . The application of computational approaches makes it possible to detect the presence and strength of this hypothetical relation for a large number of events. We extracted events from a longitudinal dataset of Dutch Twitter posts, and modeled classifiers to detect emotion in the tweets related to those events by means of hashtag-labeled training data. After classifying all tweets before and after the events in our dataset, we summarized the collective emotions for over 3000 events as the percentage of tweets classified as positive expectation (in anticipation), disappointment and satisfaction (in hindsight). Only a weak correlation of around 0.2 was found between positive expectation and disappointment, while a higher correlation of 0.6 was found between positive expectation and satisfaction. The most anticipointing events were events with a clear loss, such as a canceled event or when the favored sports team had lost. We conclude that senders of Twitter posts might be more inclined to share satisfaction than disappointment after a much anticipated event.},
  archive      = {J_IJAIT},
  author       = {F. Kunneman and M. van Mulken and A. van den Bosch},
  doi          = {10.1142/S0218213020400011},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {2},
  pages        = {2040001},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Anticipointment detection in event tweets},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Obituary. <em>IJAIT</em>, <em>29</em>(1), 2077001. (<a
href="https://doi.org/10.1142/S0218213020770011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJAIT},
  author       = {Nikolaos Bourbakis},
  doi          = {10.1142/S0218213020770011},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {1},
  pages        = {2077001},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Obituary},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dynamic hybrid graph matching for unsupervised video-based
person re-identification. <em>IJAIT</em>, <em>29</em>(1), 2050004. (<a
href="https://doi.org/10.1142/S0218213020500049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Taking videos as nodes in a graph, graph matching is an effective technique for unsupervised video-based person re-identification (re-ID). However, most of existing methods are sensitive to noisy training data and mainly only focus on visual content relations between query and gallery videos, which may introduce large amount of false positives. To enhance the robustness to training data and alleviate the visual ambiguity, a Dynamic Hybrid Graph Matching (DHGM) method is proposed, which jointly considers both content and context information for person re-ID in an iterative manner. The content relations between video nodes are obtained by metric learning, based on which the context relation is acquired by encoding the bidirectional feature of each probe node relative to its graph neighbors. The model is iteratively updated during the process of graph construction for promoted distance measurement and further better matching performance. Experimental results on the PRID 2011 and iLIDS-VID datasets demonstrate the superiority of the DHGM.},
  archive      = {J_IJAIT},
  author       = {Xiaoyue Xu and Ying Chen and Qiaoyuan Chen},
  doi          = {10.1142/S0218213020500049},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {1},
  pages        = {2050004},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Dynamic hybrid graph matching for unsupervised video-based person re-identification},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimization of many objective pickup and delivery problem
with delay time of vehicle using memetic decomposition based
evolutionary algorithm. <em>IJAIT</em>, <em>29</em>(1), 2050003. (<a
href="https://doi.org/10.1142/S0218213020500037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pickup and delivery problem (PDP) is a very common and important problem, which has a large number of real-world applications in logistics and transportation. In PDP, customers send transportation requests to pick up an object from one place and deliver it to another place. This problem is under the focus of researchers since the last two decades with multiple variations. In the literature, different variations of PDP with different number of objectives and constraints have been considered. Depending on the number of objectives, multi and many-objective evolutionary algorithms have been applied to solve the problem and to study the conflicts between objectives. In this paper, PDP is formulated as a many-objective pickup and delivery problem (MaOPDP) with delay time of vehicle having six criteria to be optimized. To the best of our knowledge, this variation of PDP has not been considered in the literature. To solve the problem, this paper proposes a memetic I-DBEA (Improved Decomposition Based Evolutionary Algorithm), which is basically the modification of an existing many-objective evolutionary algorithm called I-DBEA. To demonstrate the superiority of our approach, a set of experiments have been conducted on a variety of small, medium and large-scale problems. The quality of the results obtained by the proposed approach is compared with five existing multi and many-objective evolutionary algorithms using three different multi-objective evaluation measures such as hypervolume (HV), inverted generational distance (IGD) and generational distance (GD). The experimental results demonstrate that the proposed algorithm has significant advantages over several state-of-the-art algorithms in terms of the quality of the obtained solutions.},
  archive      = {J_IJAIT},
  author       = {Adeem Ali Anwar and Irfan Younas},
  doi          = {10.1142/S0218213020500037},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {1},
  pages        = {2050003},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Optimization of many objective pickup and delivery problem with delay time of vehicle using memetic decomposition based evolutionary algorithm},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Density-based approach with dual optimization for tracking
community structure of increasing social networks. <em>IJAIT</em>,
<em>29</em>(1), 2050002. (<a
href="https://doi.org/10.1142/S0218213020500025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid evolution of social networks in recent years has focused the attention of researchers to find adequate solutions for the management of these networks. For this purpose, several efficient algorithms dedicated to the tracking and the rapid detection of the community structure have been proposed. In this paper, we propose a novel density-based approach with dual optimization for tracking community structure of increasing social networks. These networks are part of dynamic networks evolving by adding nodes with their links. The local optimization of the density makes it possible to reduce the resolution limit problem generated by the optimization of the modularity. The presented algorithm is incremental with a relatively low algorithmic complexity, making it efficient and faster. To demonstrate the effectiveness of our method, we test it on social networks of the real world. The experimental results show the performance and efficiency of our algorithm measured in terms of modularity density, modularity, normalized mutual information, number of communities discovered, running time and stability of communities.},
  archive      = {J_IJAIT},
  author       = {Fariza Bouhatem and Ali Ait El Hadj and Fatiha Souam},
  doi          = {10.1142/S0218213020500025},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {1},
  pages        = {2050002},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Density-based approach with dual optimization for tracking community structure of increasing social networks},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Drug-target interaction prediction by metapath2vec node
embedding in heterogeneous network of interactions. <em>IJAIT</em>,
<em>29</em>(1), 2050001. (<a
href="https://doi.org/10.1142/S0218213020500013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug discovery is a complicated, time-consuming and expensive process. The cost for each new molecular entity (NME) is estimated at $1.8 billion. Furthermore, for a new drug to be FDA approved it often takes nearly a decade and approximately 20 new drugs being approved by the US Food and Drug Administration (FDA) each year. Accurately predicting drug-target interactions (DTIs) by computational methods is an important area of drug research, which brings about a broad prospect for fast and low-risk drug development. By accurate prediction of drugs and targets interactions scientists can scale-down huge experimental space and reduce the costs and help to faster drug development as well as predicting the side effects and potential function of new drugs. Many approaches have been taken by researchers to solve DTI problem and enhance the accuracy of methods. State-of-the-art approaches are based on various techniques, such as deep learning methods-like stacked auto-encoder-, matrix factorization, network inference, and ensemble methods. In this work, we have taken a new approach based on node embedding in a heterogeneous interaction network to obtain the representation of each node in the interaction network and then use a binary classifier such as logistic regression to solve this prominent problem in the pharmaceutical industry. Most introduced network-based methods use a homogeneous network of interactions as their input data whereas in the real word problem there exist other informative networks to help to enhance the prediction and by considering the homogeneous networks we lose some precious network information. Hence, in this work, we have tried to work on the heterogeneous network and have improved the accuracy of methods in comparison to baseline methods.},
  archive      = {J_IJAIT},
  author       = {Mina Samizadeh and Behrouz Minaei-Bidgoli},
  doi          = {10.1142/S0218213020500013},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {1},
  pages        = {2050001},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Drug-target interaction prediction by metapath2vec node embedding in heterogeneous network of interactions},
  volume       = {29},
  year         = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
