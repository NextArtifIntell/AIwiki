<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TCC_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tcc---104">TCC - 104</h2>
<ul>
<li><details>
<summary>
(2020). Comments on “secure data sharing in cloud computing using
revocable-storage identity-based encryption.” <em>TCC</em>,
<em>8</em>(4), 1299–1300. (<a
href="https://doi.org/10.1109/TCC.2020.2973623">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing can provide a flexible way to effectively share data among multiple users since it can overcome the time and location constraints of computing resource usage. However, the users of cloud computing are still reluctant to share sensitive data to a cloud server since the cloud server should be treated as an untrusted entity. In order to support secure and efficient data sharing in a cloud computing environment, Wei et al. recently extended the concept of identity-based encryption (IBE) to support key revocation and ciphertext update functionalities, and proposed a revocable-storage identity-based encryption (RS-IBE) scheme. In this article, we show that the RS-IBE scheme of Wei et al. does not satisfy the correctness property of RS-IBE. We also propose a method to modify the existing RS-IBE scheme.},
  archive      = {J_TCC},
  author       = {Kwangsu Lee},
  doi          = {10.1109/TCC.2020.2973623},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1299-1300},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Comments on “Secure data sharing in cloud computing using revocable-storage identity-based encryption”},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the privacy of matrix masking-based verifiable
(outsourced) computation. <em>TCC</em>, <em>8</em>(4), 1296–1298. (<a
href="https://doi.org/10.1109/TCC.2019.2922344">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Privacy-preserving verifiable (outsourced) computation (PPVC) is a useful technique for a resource-constrained client to outsource computationally heavy but sensitive tasks to a computationally powerful but untrusted worker and to obtain expected correct results from the worker. In this paper, we analyze the privacy property of three matrix masking-based PPVC protocols, which have recently been published in IEEE Transactions on Cloud Computing [2] , [3] . To do this, we present a formal definition of a privacy model for a PPVC protocol (see Definition 1 ), and then prove that neither of those three PPVC protocols holds privacy under this model. We also review the comments by Cao et al. [1] on two of the three protocols and show an issue in their comments.},
  archive      = {J_TCC},
  author       = {Liang Zhao and Liqun Chen},
  doi          = {10.1109/TCC.2019.2922344},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1296-1298},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {On the privacy of matrix masking-based verifiable (Outsourced) computation},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stochastic workload scheduling for uncoordinated datacenter
clouds with multiple QoS constraints. <em>TCC</em>, <em>8</em>(4),
1284–1295. (<a href="https://doi.org/10.1109/TCC.2016.2586048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing is now a well-adopted computing paradigm. With unprecedented scalability and flexibility, the computational cloud is able to carry out large scale computing tasks in parallel. The datacenter cloud is a new cloud computing model that uses multi-datacenter architectures for large scale massive data processing or computing. In datacenter cloud computing, the overall efficiency of the cloud depends largely on the workload scheduler, which allocates clients&#39; tasks to different Cloud datacenters. Developing high performance workload scheduling techniques in Cloud computing imposes a great challenge which has been extensively studied. Most previous works aim only at minimizing the completion time of all tasks. However, timeliness is not the only concern, reliability and security are also very important. In this work, a comprehensive Quality of Service (QoS) model is proposed to measure the overall performance of datacenter clouds. An advanced Cross-Entropy based stochastic scheduling (CESS) algorithm is developed to optimize the accumulative QoS and sojourn time of all tasks. Experimental results show that our algorithm improves accumulative QoS and sojourn time by up to 56.1 and 25.4 percent respectively compared to the baseline algorithm. The runtime of our algorithm grows only linearly with the number of Cloud datacenters and tasks. Given the same arrival rate and service rate ratio, our algorithm steadily generates scheduling solutions with satisfactory QoS without sacrificing sojourn time.},
  archive      = {J_TCC},
  author       = {Yunliang Chen and Lizhe Wang and Xiaodao Chen and Rajiv Ranjan and Albert Y. Zomaya and Yuchen Zhou and Shiyan Hu},
  doi          = {10.1109/TCC.2016.2586048},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1284-1295},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Stochastic workload scheduling for uncoordinated datacenter clouds with multiple QoS constraints},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Privacy protection and intrusion avoidance for
cloudlet-based medical data sharing. <em>TCC</em>, <em>8</em>(4),
1274–1283. (<a href="https://doi.org/10.1109/TCC.2016.2617382">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the popularity of wearable devices, along with the development of clouds and cloudlet technology, there has been increasing need to provide better medical care. The processing chain of medical data mainly includes data collection, data storage and data sharing, etc. Traditional healthcare system often requires the delivery of medical data to the cloud, which involves users&#39; sensitive information and causes communication energy consumption. Practically, medical data sharing is a critical and challenging issue. Thus in this paper, we build up a novel healthcare system by utilizing the flexibility of cloudlet. The functions of cloudlet include privacy protection, data sharing and intrusion detection. In the stage of data collection, we first utilize Number Theory Research Unit (NTRU) method to encrypt user&#39;s body data collected by wearable devices. Those data will be transmitted to nearby cloudlet in an energy efficient fashion. Second, we present a new trust model to help users to select trustable partners who want to share stored data in the cloudlet. The trust model also helps similar patients to communicate with each other about their diseases. Third, we divide users&#39; medical data stored in remote cloud of hospital into three parts, and give them proper protection. Finally, in order to protect the healthcare system from malicious attacks, we develop a novel collaborative intrusion detection system (IDS) method based on cloudlet mesh, which can effectively prevent the remote healthcare big data cloud from attacks. Our experiments demonstrate the effectiveness of the proposed scheme.},
  archive      = {J_TCC},
  author       = {Min Chen and Yongfeng Qian and Jing Chen and Kai Hwang and Shiwen Mao and Long Hu},
  doi          = {10.1109/TCC.2016.2617382},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1274-1283},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Privacy protection and intrusion avoidance for cloudlet-based medical data sharing},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multimedia processing pricing strategy in GPU-accelerated
cloud computing. <em>TCC</em>, <em>8</em>(4), 1264–1273. (<a
href="https://doi.org/10.1109/TCC.2017.2672554">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphics processing unit (GPU) accelerated processing performs significant efficiency in many multimedia applications. With the development of GPU cloud computing, more and more cloud providers focus on GPU-accelerated services. Since the high maintenance cost and different speedups for various applications, GPU-accelerated services still need a different pricing strategy. Thus, in this paper, we propose an optimal pricing strategy of GPU-accelerated multimedia processing services for maximizing the profits of both the cloud provider and users. We first analyze the revenues and costs of the cloud provider and users when users adopt GPU-accelerated multimedia processing services then state the profit functions of both the cloud provider and users. With a game theory based method, we find the optimal solutions of both the cloud provider&#39;s and users&#39; profit functions. Finally, through large scale simulations, our pricing strategy brings higher profit to the cloud provider and users compared to the original pricing strategy of GPU cloud services.},
  archive      = {J_TCC},
  author       = {He Li and Kaoru Ota and Mianxiong Dong and Athanasios V. Vasilakos and Koji Nagano},
  doi          = {10.1109/TCC.2017.2672554},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1264-1273},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Multimedia processing pricing strategy in GPU-accelerated cloud computing},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Integrating mobile display energy saving into cloud-based
video streaming via rate-distortion-display energy profiling.
<em>TCC</em>, <em>8</em>(4), 1250–1263. (<a
href="https://doi.org/10.1109/TCC.2016.2630684">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile displays have been recognized as the major contributors to the energy consumption of contemporary mobile video services. Existing display energy reduction (DER) algorithms focus on local video/image processing by utilizing the computation resources on the mobile devices. As such, a per-device DER strategy is highly inefficient from the systematic perspective since the same computation is repeated among millions of individual mobile devices. In this new era of cloud-based video streaming, a natural question to ask is can ubiquitous cloud resources be exploited to overcome these drawbacks. It is based on this motivation that we design a paradigm-shifting strategy to integrate the display energy saving engine into cloud-based video streaming in order to simultaneously benefit massive mobile devices with a one-time video processing in the cloud. By taking full advantage of the computational and storage resources in the cloud, a family of Rate-Distortion-Display Energy (R-D-DE) profiles can be created for a given video source and for different types of mobile devices. The preliminary experimental results with OLED displays prove that we can achieve the desired DER performance through jointly managing the display energy and user experience by implementing the proposed R-D-DE integrated video encoding engine in the cloud.},
  archive      = {J_TCC},
  author       = {Qian Liu and Zhisheng Yan and Chang Wen Chen},
  doi          = {10.1109/TCC.2016.2630684},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1250-1263},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Integrating mobile display energy saving into cloud-based video streaming via rate-distortion-display energy profiling},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hybrid tree-rule firewall for high speed data transmission.
<em>TCC</em>, <em>8</em>(4), 1237–1249. (<a
href="https://doi.org/10.1109/TCC.2016.2554548">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional firewalls employ listed rules in both configuration and process phases to regulate network traffic. However, configuring a firewall with listed rules may create rule conflicts, and slows down the firewall. To overcome this problem, we have proposed a Tree-rule firewall in our previous study. Although the Tree-rule firewall guarantees no conflicts within its rule set and operates faster than traditional firewalls, keeping track of the state of network connections using hashing functions incurs extra computational overhead. In order to reduce this overhead, we propose a hybrid Tree-rule firewall in this paper. This hybrid scheme takes advantages of both Tree-rule firewalls and traditional listed-rule firewalls. The GUIs of our Tree-rule firewalls are utilized to provide a means for users to create conflict-free firewall rules, which are organized in a tree structure and called `tree rules&#39;. These tree rules are later converted into listed rules that share the merit of being conflict-free. Finally, in decision making, the listed rules are used to verify against packet header information. The rules which have matched with most packets are moved up to the top positions by the core firewall. The mechanism applied in this hybrid scheme can significantly improve the functional speed of a firewall.},
  archive      = {J_TCC},
  author       = {Thawatchai Chomsiri and Xiangjian He and Priyadarsi Nanda and Zhiyuan Tan},
  doi          = {10.1109/TCC.2016.2554548},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1237-1249},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Hybrid tree-rule firewall for high speed data transmission},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Quantitative fault-tolerance for reliable workflows on
heterogeneous IaaS clouds. <em>TCC</em>, <em>8</em>(4), 1223–1236. (<a
href="https://doi.org/10.1109/TCC.2017.2780098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reliability requirement is one of the most important quality of services (QoS) and should be satisfied for a reliable workflow in cloud computing. Primary-backup replication is an important software fault-tolerant technique used to satisfy reliability requirement. Recent works studied quantitative fault-tolerant scheduling to reduce execution cost by minimizing the number of replicas while satisfying the reliability requirement of a workflow on heterogeneous infrastructure as a service (IaaS) clouds. However, a minimum number of replicas does not necessarily lead to the minimum execution cost and shortest schedule length in a heterogeneous IaaS cloud. In this study, we propose the quantitative fault-tolerant scheduling algorithms QFEC and QFEC+ with minimum execution costs and QFSL and QFSL+ with shortest schedule lengths while satisfing the reliability requirements of workflows. Extensive experimental results show that (1) compared with the state-of-the-art algorithms, the proposed algorithms achieve less execution cost and shorter schedule length, although the number of replicas are not minimum; (2) QFEC and QFEC+ are designed to reduce execution cost, and QFEC+ is better than QFEC for all low-parallelism and high-parallelism workflows; and (3) QFSL and QFSL+ are designed to decrease schedule length, and QFSL+ is better than QFSL for all low-parallelism and high-parallelism workflows.},
  archive      = {J_TCC},
  author       = {Guoqi Xie and Gang Zeng and Renfa Li and Keqin Li},
  doi          = {10.1109/TCC.2017.2780098},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1223-1236},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Quantitative fault-tolerance for reliable workflows on heterogeneous IaaS clouds},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cost-aware multimedia data allocation for heterogeneous
memory using genetic algorithm in cloud computing. <em>TCC</em>,
<em>8</em>(4), 1212–1222. (<a
href="https://doi.org/10.1109/TCC.2016.2594172">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent expansions of Internet-of-Things (IoT) applying cloud computing have been growing at a phenomenal rate. As one of the developments, heterogeneous cloud computing has enabled a variety of cloud-based infrastructure solutions, such as multimedia big data. Numerous prior researches have explored the optimizations of on-premise heterogeneous memories. However, the heterogeneous cloud memories are facing constraints due to the performance limitations and cost concerns caused by the hardware distributions and manipulative mechanisms. Assigning data tasks to distributed memories with various capacities is a combinatorial NP-hard problem. This paper focuses on this issue and proposes a novel approach, Cost-Aware Heterogeneous Cloud Memory Model (CAHCM), aiming to provision a high performance cloud-based heterogeneous memory service offerings. The main algorithm supporting CAHCM is Dynamic Data Allocation Advance (2DA) Algorithm that uses genetic programming to determine the data allocations on the cloud-based memories. In our proposed approach, we consider a set of crucial factors impacting the performance of the cloud memories, such as communication costs, data move operating costs, energy performance, and time constraints. Finally, we implement experimental evaluations to examine our proposed model. The experimental results have shown that our approach is adoptable and feasible for being a cost-aware cloud-based solution.},
  archive      = {J_TCC},
  author       = {Keke Gai and Longfei Qiu and Hui Zhao and Meikang Qiu},
  doi          = {10.1109/TCC.2016.2594172},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1212-1222},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Cost-aware multimedia data allocation for heterogeneous memory using genetic algorithm in cloud computing},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Boafft: Distributed deduplication for big data storage in
the cloud. <em>TCC</em>, <em>8</em>(4), 1199–1211. (<a
href="https://doi.org/10.1109/TCC.2015.2511752">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As data progressively grows within data centers, the cloud storage systems continuously facechallenges in saving storage capacity and providing capabilities necessary to move big data within an acceptable time frame. In this paper, we present the Boafft, a cloud storage system with distributed deduplication. The Boafft achieves scalable throughput and capacity usingmultiple data servers to deduplicate data in parallel, with a minimal loss of deduplication ratio. Firstly, the Boafft uses an efficient data routing algorithm based on data similarity that reduces the network overhead by quickly identifying the storage location. Secondly, the Boafft maintains an in-memory similarity indexing in each data server that helps avoid a large number of random disk reads and writes, which in turn accelerates local data deduplication. Thirdly, the Boafft constructs hot fingerprint cache in each data server based on access frequency, so as to improve the data deduplication ratio. Our comparative analysis with EMC&#39;s stateful routing algorithm reveals that the Boafft can provide a comparatively high deduplication ratio with a low network bandwidth overhead. Moreover, the Boafft makes better usage of the storage space, with higher read/write bandwidth and good load balance.},
  archive      = {J_TCC},
  author       = {Shengmei Luo and Guangyan Zhang and Chengwen Wu and Samee U. Khan and Keqin Li},
  doi          = {10.1109/TCC.2015.2511752},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1199-1211},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Boafft: Distributed deduplication for big data storage in the cloud},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bandwidth on-demand for multimedia big data transfer across
geo-distributed cloud data centers. <em>TCC</em>, <em>8</em>(4),
1189–1198. (<a href="https://doi.org/10.1109/TCC.2016.2617369">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimedia content is massively generated from various applications and devices, and processed in cloud data centers. Multimedia service providers prefer that their data are processed in data centers close to users in order to offer them high performance and reliable multimedia services that meet the requirements specified in the Service Level of Agreement (SLA). This requires transferring huge data sets of video streams, games content, images etc. across geographically distributed cloud data centers using underutilized bandwidth in backbone transport networks. As the amount of multimedia content increases, the demand to transfer big data sets across data centers increases as well. As such, the leftover bandwidth that appears at different times and for different durations in the backbone network becomes insufficient to satisfy the rapidly increasing demand for multimedia big data transfer. This challenge led to the creation of multi-rate Bandwidth on-Demand (BoD) service offerings for communication between geographically distributed cloud data centers. In this paper, we focus on BoD services which are offered by the Dense Wavelength Division Multiplexing (DWDM) layer because of its huge capacity. We propose a BoD broker which employs a scheduling algorithm that considers various deadlines of multimedia big data transfer requests. The broker in our model leverages the concept of standby wavelengths to minimize peak traffic and accommodate time requirements of delay-tolerant and delay-intolerant transfer requests. We also study strategies of routing and wavelength assignment using Mixed Integer Programming (MIP) optimization to rapidly handle volumes of multimedia big data transfer requests.},
  archive      = {J_TCC},
  author       = {Abdulsalam Yassine and Ali Asghar Nazari Shirehjini and Shervin Shirmohammadi},
  doi          = {10.1109/TCC.2016.2617369},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1189-1198},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Bandwidth on-demand for multimedia big data transfer across geo-distributed cloud data centers},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An ancillary services model for data centers and power
systems. <em>TCC</em>, <em>8</em>(4), 1176–1188. (<a
href="https://doi.org/10.1109/TCC.2017.2700838">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enormous energy consumption of data centers has a major impact on power systems by significantly increasing the electrical load. Due to the increase in electrical load, power systems are facing demand and supply miss-management problems. Therefore, power systems require efficient and intelligent ancillary services to maintain robustness, reliability, and stability. Data centers can provide the computational capabilities to manage power systems; however, data centers consume a tremendous amount of energy, and energy price accounts for a significant portion of their operational cost. Power system jobs will make this situation even more critical for data centers. In our work, we seek an Ancillary Services Model (ASM) to service data centers and power systems. In ASM, we find an optimal job scheduling technique for executing power systems’ jobs on data centers in terms of low power consumption, reduced makespan, and fewer preempted jobs. The power systems’ jobs include Optimal Power Flow (OPF) calculation, transmission line importance index, and bus importance index. Moreover, a Service Level Agreement (SLA) between data centers and power systems is shown to provide mutual benefits.},
  archive      = {J_TCC},
  author       = {Sahibzada Muhammad Ali and Muhammad Jawad and M. Usman S. Khan and Kashif Bilal and Jacob Glower and Scott C. Smith and Samee U. Khan and Keqin Li and Albert Y. Zomaya},
  doi          = {10.1109/TCC.2017.2700838},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1176-1188},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {An ancillary services model for data centers and power systems},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptive computing-plus-communication optimization framework
for multimedia processing in cloud systems. <em>TCC</em>, <em>8</em>(4),
1162–1175. (<a href="https://doi.org/10.1109/TCC.2016.2617367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A clear trend in the evolution of network-based services is the ever-increasing amount of multimedia data involved. This trend towards big-data multimedia processing finds its natural placement together with the adoption of the cloud computing paradigm, that seems the best solution to cope with the demands of a highly fluctuating workload that characterizes this type of services. However, as cloud data centers become more and more powerful, energy consumption becomes a major challenge both for environmental concerns and for economic reasons. An effective approach to improve energy efficiency in cloud data centers is to rely on traffic engineering techniques to dynamically adapt the number of active servers to the current workload. Towards this aim, we propose a joint computing-plus-communication optimization framework exploiting virtualization technologies, called MMGreen. Our proposal specifically addresses the typical scenario of multimedia data processing with computationally intensive tasks and exchange of a big volume of data. The proposed framework not only ensures users the Quality of Service (through Service Level Agreements), but also achieves maximum energy saving and attains green cloud computing goals in a fully distributed fashion by utilizing the DVFS-based CPU frequencies. To evaluate the actual effectiveness of the proposed framework, we conduct experiments with MMGreen under real-world and synthetic workload traces. The results of the experiments show that MMGreen may significantly reduce the energy cost for computing, communication and reconfiguration with respect to the previous resource provisioning strategies, respecting the SLA constraints.},
  archive      = {J_TCC},
  author       = {Mohammad Shojafar and Claudia Canali and Riccardo Lancellotti and Jemal Abawajy},
  doi          = {10.1109/TCC.2016.2617367},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1162-1175},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Adaptive computing-plus-communication optimization framework for multimedia processing in cloud systems},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A data skew oriented reduce placement algorithm based on
sampling. <em>TCC</em>, <em>8</em>(4), 1149–1161. (<a
href="https://doi.org/10.1109/TCC.2016.2607738">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For frequent disk I/O and large data transmissions among different racks and physical nodes, intermediate data communication has become the most important performance bottle-neck in most running Hadoop systems. This paper proposes a reduce placement algorithm called CORP to schedule related map and reduce tasks on the near nodes of clusters or racks for data locality. Because the number of keys cannot be counted until the input data are processed by map tasks, this paper applies a reservoir algorithm for sampling the input data, which can bring the distribution of keys/values closer to the overall situation of original data. Based on the distribution matrix of the intermediate results in each partition, by calculating the distance and cost matrices among the cross node communication, the related map and reduce tasks can be scheduled to relatively nearby physical nodes for data locality. We implement CORP in Hadoop 2.4.0 and evaluate its performance using three widely used benchmarks: Sort, Grep, and Join. In these experiments, an evaluation model is proposed for selecting the appropriate sample rates, which can comprehensively consider the importance of cost, effect, and variance in sampling. Experimental results show that CORP can not only improve the balance of reduces tasks effectively but also decreases the job execution time for the lower inner data communication. Compared with some other reduce scheduling algorithms, the average data transmission of the entire system on the core switch has been reduced substantially.},
  archive      = {J_TCC},
  author       = {Zhuo Tang and Wen Ma and Kenli Li and Keqin Li},
  doi          = {10.1109/TCC.2016.2607738},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1149-1161},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {A data skew oriented reduce placement algorithm based on sampling},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Quantitative modeling and analytical calculation of
elasticity in cloud computing. <em>TCC</em>, <em>8</em>(4), 1135–1148.
(<a href="https://doi.org/10.1109/TCC.2017.2665549">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Elasticity is a fundamental feature of cloud computing and can be considered as a great advantage and a key benefit of cloud computing. One key challenge in cloud elasticity is lack of consensus on a quantifiable, measurable, observable, and calculable definition of elasticity and systematic approaches to modeling, quantifying, analyzing, and predicting elasticity. Another key challenge in cloud computing is lack of effective ways for prediction and optimization of performance and cost in an elastic cloud platform. The present paper makes the following significant contributions. First, we present a new, quantitative, and formal definition of elasticity in cloud computing, i.e., the probability that the computing resources provided by a cloud platform match the current workload. Our definition is applicable to any cloud platform and can be easily measured and monitored. Furthermore, we develop an analytical model to study elasticity by treating a cloud platform as a queueing system, and use a continuous-time Markov chain (CTMC) model to precisely calculate the elasticity value of a cloud platform by using an analytical and numerical method based on just a few parameters, namely, the task arrival rate, the service rate, the virtual machine start-up and shut-down rates. In addition, we formally define auto-scaling schemes and point out that our model and method can be easily extended to handle arbitrarily sophisticated scaling schemes. Second, we apply our model and method to predict many other important properties of an elastic cloud computing system, such as average task response time, throughput, quality of service, average number of VMs, average number of busy VMs, utilization, cost, cost-performance ratio, productivity, and scalability. In fact, from a cloud consumer&#39;s point of view, these performance and cost metrics are even more important than the elasticity metric. Our study in this paper has two significance. On one hand, a cloud service provider can predict its performance and cost guarantee using the results developed in this paper. On the other hand, a cloud service provider can optimize its elastic scaling scheme to deliver the best cost-performance ratio. To the best of our knowledge, this is the first paper that analytically and comprehensively studies elasticity, performance, and cost in cloud computing. Our model and method significantly contribute to the understanding of cloud elasticity and management of elastic cloud computing systems.},
  archive      = {J_TCC},
  author       = {Keqin Li},
  doi          = {10.1109/TCC.2017.2665549},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1135-1148},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Quantitative modeling and analytical calculation of elasticity in cloud computing},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Towards network-aware service composition in the cloud.
<em>TCC</em>, <em>8</em>(4), 1122–1134. (<a
href="https://doi.org/10.1109/TCC.2016.2603504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Composing several API-defined services into one composite service per user requirements has become an important service creation approach in the cloud-enabled API economy. Various service selection approaches in support of service composition on demand have been proposed. They usually assume that networking resources are over-provisioned and their usage needs not be considered when making quality-aware service composition decisions. In practice, these approaches often lead to wasteful network resource consumption and impractical end-to-end QoS optimality for cloud-based services. This paper proposes a network-aware cloud service composition approach, named NetMIP, with comparative experimental evaluations for the clouds that adopt the widely deployed fat-tree network topology. By formalizing the service composition goal as a multi-objective constraint optimization problem, we have validated the proposed approach can be used to effectively reduce network resource consumption and deliver QoS optimality while satisfying the end-to-end QoS constraints for the candidate composite services in the cloud. The comparative experimental evaluations are done via a credible cloud infrastructure simulation system, named WebCloudSim. Extensive evaluation results show that NetMIP outperforms several representative cloud service composition approaches in terms of network resource consumption, QoS optimality, and computation time under various service selection workloads and fat-tree network topology settings.},
  archive      = {J_TCC},
  author       = {Shangguang Wang and Ao Zhou and Fangchun Yang and Rong N. Chang},
  doi          = {10.1109/TCC.2016.2603504},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1122-1134},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Towards network-aware service composition in the cloud},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Trustworthy enhancement for cloud proxy based on autonomic
computing. <em>TCC</em>, <em>8</em>(4), 1108–1121. (<a
href="https://doi.org/10.1109/TCC.2016.2603508">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming to improve Internet content accessing capacity of the system, cloud proxy platforms are used to improve the visiting performance in network export environment. Limited by complexity of cloud proxy system, trustworthy guarantee of cloud system becomes a difficult problem. Considering the self-government of autonomic computing, it could enhance cloud system trustworthy and avoids system management security and reliable problems brought by complex construction. Based on the idea of self-supervisory, a mechanism to enhance security of cloud system was proposed in this paper. First, a trustworthy autonomous enhancement framework for virtual machines was proposed. Second, a method to extract linear relationship of monitoring items in the virtual machine based on ARX model was put forward. According to the mapping relation between monitoring items and system modules, an abnormal module positioning technology based on Naive Bayes classifier was developed to realize self-sensing of abnormal system conditions. Finally, security threats of virtual machines including malicious dialogue and buffer memory of hot attacks were tested through experiments. Results showed that the proposed trustworthy enhancement mechanism of virtual machines based on autonomic computing could achieve trustworthy enhancement of virtual machines effectively and provide an effective safety protection for the cloud system.},
  archive      = {J_TCC},
  author       = {Hui He and Weizhe Zhang and Chuanyi Liu and Honglei Sun},
  doi          = {10.1109/TCC.2016.2603508},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1108-1121},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Trustworthy enhancement for cloud proxy based on autonomic computing},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dynamically partitioning workflow over federated clouds for
optimising the monetary cost and handling run-time failures.
<em>TCC</em>, <em>8</em>(4), 1093–1107. (<a
href="https://doi.org/10.1109/TCC.2016.2603477">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several real-world problems in domain of healthcare, large scale scientific simulations, and manufacturing are organised as workflow applications. Efficiently managing workflow applications on the Cloud computing data-centres is challenging due to the following problems: (i) they need to perform computation over sensitive data (e.g., Healthcare workflows) hence leading to additional security and legal risks especially considering public cloud environments and (ii) the dynamism of the cloud environment can lead to several run-time problems such as data loss and abnormal termination of workflow task due to failures of computing, storage, and network services. To tackle above challenges, this paper proposes a novel workflow management framework call Deploy on Federated Cloud Framework (DoFCF) that can dynamically partition scientific workflows across federated cloud (public/private) data-centres for minimising the financial cost, adhering to security requirements, while gracefully handling run-time failures. The framework is validated in cloud simulation tool (CloudSim) as well as in a realistic workflow-based cloud platform (e-Science Central). The results showed that our approach is practical and is successful in meeting users security requirements and reduces overall cost, and dynamically adapts to the run-time failures.},
  archive      = {J_TCC},
  author       = {Zhenyu Wen and Rawaa Qasha and Zequn Li and Rajiv Ranjan and Paul Watson and Alexander Romanovsky},
  doi          = {10.1109/TCC.2016.2603477},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1093-1107},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Dynamically partitioning workflow over federated clouds for optimising the monetary cost and handling run-time failures},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Performance-based pricing in multi-core geo-distributed
cloud computing. <em>TCC</em>, <em>8</em>(4), 1079–1092. (<a
href="https://doi.org/10.1109/TCC.2016.2628368">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {New pricing policies are emerging where cloud providers charge resource provisioning based on the allocated CPU frequencies. As a result, resources are offered to users as combinations of different performance levels and prices which can be configured at runtime. With such new pricing schemes and the increasing energy costs in data centres, balancing energy savings with performance and revenue losses is a challenging problem for cloud providers. CPU frequency scaling can be used to reduce power dissipation, but also impacts virtual machine (VM) performance and therefore revenue. In this paper, we first propose a non-linear power model that estimates power dissipation of a multi-core CPU physical machine (PM) and second a pricing model that adjusts the pricing based on the VM&#39;s CPU-boundedness characteristics. Finally, we present a cloud controller that uses these models to allocate VM and scale CPU frequencies of the physical machine (PM) to achieve energy cost savings that exceed service revenue losses. We evaluate the proposed approach using simulations with realistic VM workloads, electricity price and temperature traces and estimate energy savings of up to 14.57 percent.},
  archive      = {J_TCC},
  author       = {Dražen Lučanin and Ilia Pietri and Simon Holmbacka and Ivona Brandic and Johan Lilius and Rizos Sakellariou},
  doi          = {10.1109/TCC.2016.2628368},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1079-1092},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Performance-based pricing in multi-core geo-distributed cloud computing},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). DSARP: Dependable scheduling with active replica placement
for workflow applications in cloud computing. <em>TCC</em>,
<em>8</em>(4), 1069–1078. (<a
href="https://doi.org/10.1109/TCC.2016.2628374">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an efficient development for industrial and scientific applications, workflow technologies have received substantial attention in recent decades. To address the issue of workflow scheduling in a state-of-the-art cloud environment, based on analysis of a decentralized architecture for workflow scheduling, a dependable scheduling strategy with active replica placement (DS-ARP) is proposed in this paper. In this proposal, by analyzing control/data dependencies in a workflow, a game-theory-based active replica placement model is first developed to achieve reasonable replica placement; then, a dependable scheduling algorithm is proposed to enhance the system reliability and security. With five well-known workflow applications, CloudSim-based simulations are performed, and the analytical results are shown to demonstrate the performance of DS-ARP on an average number of initiated replicas, costs resulting from canceled replicas, makespans, deadline violation rates and resource utilization rates.},
  archive      = {J_TCC},
  author       = {Ming Tao and Kaoru Ota and Mianxiong Dong},
  doi          = {10.1109/TCC.2016.2628374},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1069-1078},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {DSARP: Dependable scheduling with active replica placement for workflow applications in cloud computing},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Online inter-datacenter service migrations. <em>TCC</em>,
<em>8</em>(4), 1054–1068. (<a
href="https://doi.org/10.1109/TCC.2017.2680439">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Service migration between datacenters can reduce the network overhead within a cloud infrastructure; thereby, also improving the quality of service for the clients. Most of the algorithms in the literature assume that the client access pattern remains stable for a sufficiently long period so as to amortize such migrations. However, if such an assumption does not hold, these algorithms can take arbitrarily poor migration decisions that can substantially degrade system performance. In this paper, we approach the issue of performing service migrations for an unknown and dynamically changing client access pattern. We propose an online algorithm that minimizes the inter-datacenter network, taking into account the network load of migrating a service between two datacenters, as well as the fact that the client request pattern may change “quickly”, before such a migration is amortized. We provide a rigorous mathematical proof showing that the algorithm is 3.8-competitive for a cloud network structured as a tree of multiple datacenters. We briefly discuss how the algorithm can be modified to work on general graph networks with an $O{\mathrm{(log\vert V\vert)}}$ probabilistic approximation of the optimal algorithm. Finally, we present an experimental evaluation of the algorithm based on extensive simulations.},
  archive      = {J_TCC},
  author       = {Nikos Tziritas and Samee U. Khan and Thanasis Loukopoulos and Spyros Lalis and Cheng-Zhong Xu and Keqin Li and Albert Y. Zomaya},
  doi          = {10.1109/TCC.2017.2680439},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1054-1068},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Online inter-datacenter service migrations},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). STAR: SLA-aware autonomic management of cloud resources.
<em>TCC</em>, <em>8</em>(4), 1040–1053. (<a
href="https://doi.org/10.1109/TCC.2017.2648788">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing has recently emerged as an important service to manage applications efficiently over the Internet. Various cloud providers offer pay per use cloud services that requires Quality of Service (QoS) management to efficiently monitor and measure the delivered services through Internet of Things (IoT) and thus needs to follow Service Level Agreements (SLAs). However, providing dedicated cloud services that ensure user&#39;s dynamic QoS requirements by avoiding SLA violations is a big challenge in cloud computing. As dynamism, heterogeneity and complexity of cloud environment is increasing rapidly, it makes cloud systems insecure and unmanageable. To overcome these problems, cloud systems require self-management of services. Therefore, there is a need to develop a resource management technique that automatically manages QoS requirements of cloud users thus helping the cloud providers in achieving the SLAs and avoiding SLA violations. In this paper, we present SLA-aware autonomic resource management technique called STAR which mainly focuses on reducing SLA violation rate for the efficient delivery of cloud services. The performance of the proposed technique has been evaluated through cloud environment. The experimental results demonstrate that STAR is efficient in reducing SLA violation rate and in optimizing other QoS parameters which effect efficient cloud service delivery.},
  archive      = {J_TCC},
  author       = {Sukhpal Singh and Inderveer Chana and Rajkumar Buyya},
  doi          = {10.1109/TCC.2017.2648788},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1040-1053},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {STAR: SLA-aware autonomic management of cloud resources},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A reinforcement learning-based mixed job scheduler scheme
for grid or IaaS cloud. <em>TCC</em>, <em>8</em>(4), 1030–1039. (<a
href="https://doi.org/10.1109/TCC.2017.2773078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Job scheduling is a necessary prerequisite for performance optimization and resource management in the cloud computing system. Focusing on accurate scaled cloud computing environment and efficient job scheduling under Virtual Machine (VM) resource and Server Level Agreement (SLA) constraints, we introduce the architecture of cloud computing platform and optimization job scheduling scheme in this study. The system model is comprised of clearly defined separate constituent parts, including portal, job scheduler, and resources pool. By analyzing the execution process of user jobs, we designed a novel job scheduling scheme based on reinforcement learning to minimize the makespan and Average Waiting Time (AWT) under the VM resource and deadline constraints, and employ parallel multi-age parallel technologies to balance the exploration and exploitation in learning process and accelerate the convergence of Q-learning algorithm. Both simulation and real cloud platform experiment results demonstrate the efficiency of the proposed job scheduling scheme.},
  archive      = {J_TCC},
  author       = {Delong Cui and Zhiping Peng and Jianbin Xiong and Bo Xu and Weiwei Lin},
  doi          = {10.1109/TCC.2017.2773078},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1030-1039},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {A reinforcement learning-based mixed job scheduler scheme for grid or IaaS cloud},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Towards pricing for sensor-cloud. <em>TCC</em>,
<em>8</em>(4), 1018–1029. (<a
href="https://doi.org/10.1109/TCC.2017.2649525">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by complementing the ubiquitous wireless sensor networks (WSNs) and powerful cloud computing (CC), a lot of attention from both industry and academia has been drawn to Sensor-Cloud (SC). However, SC pricing is barely investigated. Towards pricing for SC, this paper 1) introduces five SC Pricing Models (SCPMs) first. Specifically, to charge a SC user, each SCPM considers one of the following factors respectively: i) the lease period of the SC user; ii) the required working time of SC; iii) the SC resources utilized by the SC user; iv) the volume of sensory data obtained by the SC user; v) the SC path that transmits sensory data from the WSN to the SC user. Further, this paper 2) performs analysis to discuss and exhibit the characteristics of the proposed SCPMs. With that, this paper 3) presents the case studies regarding the application of SCPMs. Eventually, this paper 4) conducts a review about the user behavior study. This paper aims to serve as a very favorable guidance for future research about pricing in SC.},
  archive      = {J_TCC},
  author       = {Chunsheng Zhu and Xiuhua Li and Victor C. M. Leung and Laurence T. Yang and Edith C.-H. Ngai and Lei Shu},
  doi          = {10.1109/TCC.2017.2649525},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1018-1029},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Towards pricing for sensor-cloud},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Game theoretical analysis on acceptance of a cloud data
access control system based on reputation. <em>TCC</em>, <em>8</em>(4),
1003–1017. (<a href="https://doi.org/10.1109/TCC.2016.2632110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of the Internet, cloud storage has penetrated into every aspect of human society. However, cloud data disclosure happens more and more frequently, which makes cloud data security and privacy protection impact wide adoption of cloud storage. Control cloud data access based on reputation by introducing a Reputation Center (RC) was proposed and demonstrated to secure cloud data effectively in [9] . But the acceptance of such a system by cloud users and Cloud Service Providers (CSPs) is crucial for its practical deployment and final success. In this paper, we investigate the acceptance of a cloud data access control system based on reputation using Game Theory. Due to the existence of dishonest CSPs, there exists a social reputation dilemma among CSPs, which seriously impedes the popularity of cloud storage. To encourage users to use cloud storage and suppress collusion between CSPs and data requesters, a repeated public-goods game is built up by applying a compensation mechanism to improve the utilities of cloud users and a punishment mechanism based on reputation to incent honest behaviors. Theoretical analysis and simulation results show the effectiveness of the compensation and punishment mechanisms to increase cloud storage rate and restrain dishonest system entities.},
  archive      = {J_TCC},
  author       = {Lijun Gao and Zheng Yan and Laurence T. Yang},
  doi          = {10.1109/TCC.2016.2632110},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1003-1017},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Game theoretical analysis on acceptance of a cloud data access control system based on reputation},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Link-aware virtual machine placement for cloud services
based on service-oriented architecture. <em>TCC</em>, <em>8</em>(4),
989–1002. (<a href="https://doi.org/10.1109/TCC.2017.2662226">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data center benefits cloud applications in providing high scalability and ensuring service availability. However, virtual machine (VM) placement in data center poses new challenges for service provisioning. For many cloud services such as storage and video streaming, present placement approaches are unable to support network-demanding services due to overwhelming communication traffic and time. Therefore VM placement concerning link capacity is vital to cloud data centers. In this paper, we define the network-aware VM placement optimization (NAVMPO) problem based on integer linear programming. The objective function of NAVMPO problem aims to minimize communication time for VMs of the same service type. Then we propose the service-oriented physical machine (PM) selection (SOPMS) algorithm and link-aware VM placement (LAVMP) algorithm. The SOPMS algorithm selects the most appropriate PM based on service-oriented architecture, and then the LAVMP algorithm deploys the most suitable VM to target PM regarding to the link capacity between them. Simulation results show that the proposed placement approach significantly decreases communication time compared to existing non-service-oriented and service-oriented VM placement algorithms, and also improves the average utility rate of PMs with lower power consumption.},
  archive      = {J_TCC},
  author       = {Fan-Hsun Tseng and Yong-Ming Jheng and Li-Der Chou and Han-Chieh Chao and Victor C.M. Leung},
  doi          = {10.1109/TCC.2017.2662226},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {989-1002},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Link-aware virtual machine placement for cloud services based on service-oriented architecture},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimizing information leakage in multicloud storage
services. <em>TCC</em>, <em>8</em>(4), 975–988. (<a
href="https://doi.org/10.1109/TCC.2018.2808275">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many schemes have been recently advanced for storing data on multiple clouds. Distributing data over different cloud storage providers (CSPs) automatically provides users with a certain degree of information leakage control, for no single point of attack can leak all the information. However, unplanned distribution of data chunks can lead to high information disclosure even while using multiple clouds. In this paper, we study an important information leakage problem caused by unplanned data distribution in multicloud storage services. Then, we present StoreSim, an information leakage aware storage system in multicloud. StoreSim aims to store syntactically similar data on the same cloud, thus minimizing the user&#39;s information leakage across multiple clouds. We design an approximate algorithm to efficiently generate similarity-preserving signatures for data chunks based on MinHash and Bloom filter, and also design a function to compute the information leakage based on these signatures. Next, we present an effective storage plan generation algorithm based on clustering for distributing data chunks with minimal information leakage across multiple clouds. Finally, we evaluate our scheme using two real datasets from Wikipedia and GitHub. We show that our scheme can reduce the information leakage by up to 60 percent compared to unplanned placement. Furthermore, our analysis on system attackability demonstrates that our scheme makes attacks on information more complex.},
  archive      = {J_TCC},
  author       = {Hao Zhuang and Rameez Rahman and Pan Hui and Karl Aberer},
  doi          = {10.1109/TCC.2018.2808275},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {975-988},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Optimizing information leakage in multicloud storage services},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Guest editorial: Special section on advances of utility and
cloud computing technologies and services. <em>TCC</em>, <em>8</em>(4),
972–974. (<a href="https://doi.org/10.1109/TCC.2019.2936075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The articles in this special section focus on advancements of utility and cloud computing technologies and services. Computing is rapidly moving towards a model where it is provided as services that are delivered in a manner similar to traditional utilities such as water, electricity, gas, and telephony. In such a model, users access services according to their requirements, without regard to where the services are hosted or how they are delivered. Several computing architectures have evolved to realize this utility computing vision, including Grid computing, Service- Oriented Architecture (SOA) and Cloud computing,which has recently shifted into the center of attention in the ICT industry. Increasing numbers of IT vendors are promising to offer applications, storage and computation hosting services with conforming Service-Level Agreements},
  archive      = {J_TCC},
  author       = {Ching-Hsien Hsu and Manish Parashar and Omer Rana},
  doi          = {10.1109/TCC.2019.2936075},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {972-974},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Guest editorial: Special section on advances of utility and cloud computing technologies and services},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). VMGuard: A VMI-based security architecture for intrusion
detection in cloud environment. <em>TCC</em>, <em>8</em>(3), 957–971.
(<a href="https://doi.org/10.1109/TCC.2018.2829202">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud security is of paramount importance in the new era of computing. Advanced malware can hide their behavior on detection of the presence of a security tool at a tenant virtual machine (TVM). Hence, TVM-layer security solutions are not reliable. In this paper, we propose a Virtual Machine Introspection (VMI) based security architecture design for fine granular monitoring of the virtual machines to detect known attacks and their variants. We have developed techniques for monitoring the TVMs at the process level and system call level to detect attacks such as those based on malicious hidden processes, attacks that disable security tools in the virtual machines and attacks that alter the behavior of legitimate applications to access sensitive data. Our architecture, VMGuard, utilizes the introspection feature at the VMM-layer to analyze system call traces of programs running on TVM. VMGuard applies the software breakpoint injection technique which is OS agnostic and can be used to trap the execution of programs. Motivated by text mining approaches, VMGuard provides `Bag of n-grams (BonG)&#39; approach integrated with Term Frequency-Inverse Document Frequency (TF-IDF) method, to extract and select features of normal and attack traces. It then applies the Random Forest classifier to produce a generic behavior for different categories of intrusions of the monitored TVM. We have implemented a prototype and conducted a detailed analysis using University of New Mexico (UNM) datasets and a Windows malware dataset obtained from the University of California. The results obtained are promising and demonstrate the applicability of the VMGuard. We compare VMGuard with existing techniques and discuss its advantages.},
  archive      = {J_TCC},
  author       = {Preeti Mishra and Vijay Varadharajan and Emmanuel S. Pilli and Uday Tupakula},
  doi          = {10.1109/TCC.2018.2829202},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {957-971},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {VMGuard: A VMI-based security architecture for intrusion detection in cloud environment},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). VirtFlow: Guest independent execution flow analysis across
virtualized environments. <em>TCC</em>, <em>8</em>(3), 943–956. (<a
href="https://doi.org/10.1109/TCC.2018.2828846">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An agent-less technique to understand virtual machines (VMs) behavior and their changes during the VM life-cycle is essential for many performance analysis and debugging tasks in the cloud environment. Because of privacy and security issues, ease of deployment and execution overhead, the method preferably limits its data collection to the physical host level, without internal access to the VMs. We propose a host-based, precise method to recover execution flow of virtualized environments, regardless of the level of virtualization. Given a VM, the Any-Level VM Detection Algorithm (ADA) and Nested VM State Detection (NSD) Algorithm compute its execution path along with the state of virtual CPUs (vCPUs) from the host kernel trace. The state of vCPUs is displayed in an interactive trace viewer (TraceCompass) for further inspection. Then, a new approach for profiling threads and processes inside the VMs is proposed. Our proposed VM trace analysis algorithms have been open-sourced for further enhancements and to the benefit of other developers. Our new techniques are being evaluated with workloads generated by different benchmarking tools. These approaches are based on host hypervisor tracing, which brings a lower overhead (around 1 percent) as compared to other approaches.},
  archive      = {J_TCC},
  author       = {Hani Nemati and Michel Dagenais},
  doi          = {10.1109/TCC.2018.2828846},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {943-956},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {VirtFlow: Guest independent execution flow analysis across virtualized environments},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Towards security-based formation of cloud federations: A
game theoretical approach. <em>TCC</em>, <em>8</em>(3), 928–942. (<a
href="https://doi.org/10.1109/TCC.2018.2820715">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud federations allow Cloud Service Providers (CSPs) to deliver more efficient service performance by interconnecting their Cloud environments and sharing their resources. However, the security of the federated service could be compromised if the resources are shared with relatively insecure CSPs, and violations of the Security Service Level Agreement (Security-SLA) might occur. In this paper, we propose a Cloud federation formation model that considers the security level of CSPs. We start by applying the Goal-Question-Metric (GQM) method to develop a set of parameters that quantitatively describes the Security-SLA in the Cloud, and use it to evaluate the security levels of the CSPs and formed federations with respect to a defined Security-SLA baseline, while taking into account CSPs&#39; customers&#39; security satisfaction. Then, we model the Cloud federation formation process as a hedonic coalitional game with a preference relation that is based on the security level and reputation of CSPs. We propose a federation formation algorithm that enables CSPs to join a federation while minimizing their loss in security, and refrain from forming relatively insecure federations. Experimental results show that our model helps maintaining higher levels of security in the formed federations and reducing the rate and severity of Security-SLA violations.},
  archive      = {J_TCC},
  author       = {Talal Halabi and Martine Bellaiche},
  doi          = {10.1109/TCC.2018.2820715},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {928-942},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Towards security-based formation of cloud federations: A game theoretical approach},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). RRect: A novel server-centric data center network with high
power efficiency and availability. <em>TCC</em>, <em>8</em>(3), 914–927.
(<a href="https://doi.org/10.1109/TCC.2018.2816650">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel server-centric network for data centers, called RRect. Compared to existing server-centric networks, RRect provides a more graceful degradation performance in the presence of component failure. Meanwhile, RRect enjoys a linear diameter to the network order and multiple parallel paths. We present algorithms to find paths and to construct all parallel paths between any pair of servers in RRect. We also show that without using any power-aware routing algorithm, RRect behaves more power efficient in its interconnection network. To meet today&#39;s stringent high availability requirement, RRect can be configured into redundancy and failover scheme. In particular, RRect can be configured into both symmetric and asymmetric redundancy modes to cater different applications&#39; needs, which cannot be implemented in existing server-centric networks. Moreover, RRect gives more flexibility to adjust the network size. Given the same switches, by fine tuning the parameters, RRect provides numerous structures with different sizes, while preserving the properties of short diameter and multiple parallel paths. Our comprehensive simulations show that RRect gives much better graceful degradation performance in the presence of component failure, and RRect saves much energy in the interconnection network. Meanwhile, RRect can maintain the same performance on many critical metrics as BCube, including short diameter and excellent aggregate throughput. All these features make RRect a very empirical structure for enterprise dater center network products.},
  archive      = {J_TCC},
  author       = {Zhenhua Li and Yuanyuan Yang},
  doi          = {10.1109/TCC.2018.2816650},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {914-927},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {RRect: A novel server-centric data center network with high power efficiency and availability},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Revenue maximization for dynamic expansion of
geo-distributed cloud data centers. <em>TCC</em>, <em>8</em>(3),
899–913. (<a href="https://doi.org/10.1109/TCC.2018.2808351">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the cloud environment, it brings better reliability and robustness with geographically distributed datacenters. As the growth of large-scale applications in geo-distributed cloud systems, the resource demand from different areas increases violently, and researchers pay more attention to meet as many cloud users&#39; VM demands as possible by using limited cloud resources. However, there exist many issues for cloud users in existing works, such as the VM demands being refused and high response latency. In this paper, we present a cloud system model for the cloud provider to dynamically expand the scale of geo-distributed date centers. In our model, the cloud provider rents hardware resources from other resource owners (ROs), who have redundant resources and are willing to lease them. Since the ROs possess vast resources and spread all over the global, our system model can deploy more cloud users&#39; VMs and effectively reduce the bandwidth cost. We propose an optimization problem for the cloud provider to maximize the profit, and carefully solve it in different conditions. Our simulation results show that our system model and algorithms can effectively improve the user satisfaction and the total revenue and reduce the average latency of users&#39; requests.},
  archive      = {J_TCC},
  author       = {Hou Deng and Liusheng Huang and Hongli Xu and Xiangyan Liu and Pengzhan Wang and Xianjing Fang},
  doi          = {10.1109/TCC.2018.2808351},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {899-913},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Revenue maximization for dynamic expansion of geo-distributed cloud data centers},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Online VM auto-scaling algorithms for application hosting in
a cloud. <em>TCC</em>, <em>8</em>(3), 889–898. (<a
href="https://doi.org/10.1109/TCC.2018.2830793">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the auto-scaling problem for application hosting in a cloud, where applications are elastic and the number of requests changes over time. The application requests are serviced by Virtual Machines (VMs), which reside on Physical Machines (PMs) in a cloud. We aim to minimize the number of hosting PMs by intelligently packing VMs into PMs, while the VMs are auto-scaled, i.e., dynamically acquired and released, to accommodate varying application needs. We consider a shadow routing based approach for this problem. The proposed shadow algorithm employs a specially constructed virtual queueing system to dynamically produce an optimal solution that guides the VM auto-scaling and the VM-to-PM packing. The proposed algorithm runs continuously without the need to re-solve the underlying optimization problem “from scratch”, and adapts automatically to the changes in the application demands. We prove the asymptotic optimality of the shadow algorithm. The simulation experiments further demonstrate the algorithm&#39;s good performance and high adaptivity.},
  archive      = {J_TCC},
  author       = {Yang Guo and Alexander L. Stolyar and Anwar Walid},
  doi          = {10.1109/TCC.2018.2830793},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {889-898},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Online VM auto-scaling algorithms for application hosting in a cloud},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the feasibility of using current data centre
infrastructure for latency-sensitive applications. <em>TCC</em>,
<em>8</em>(3), 875–888. (<a
href="https://doi.org/10.1109/TCC.2018.2822271">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It has been claimed that the deployment of fog and edge computing infrastructure is a necessity to make high-performance cloud-based applications a possibility. However, there are a large number of middle-ground latency-sensitive applications such as online gaming, interactive photo editing and multimedia conferencing that require servers deployed closer to users than in globally centralised clouds but do not necessarily need the extreme low-latency provided by a new infrastructure of micro data centres located at the network edge, e.g., in base stations and ISP Points of Presence. In this paper we analyse a snapshot of today&#39;s data centres and the distribution of users around the globe and conclude that existing infrastructure provides a sufficiently distributed platform for middle-ground applications requiring a response time of 20-200 ms. However, while placement and selection of edge servers for extreme low-latency applications is a relatively straightforward matter of choosing the closest, providing a high quality of experience for middle-ground latency applications that use the more widespread distribution of today&#39;s data centres, as we advocate in this paper, raises new management challenges to develop algorithms for optimising the placement of and the per-request selection between replicated service instances.},
  archive      = {J_TCC},
  author       = {David Griffin and Truong Khoa Phan and Elisa Maini and Miguel Rio and Pieter Simoens},
  doi          = {10.1109/TCC.2018.2822271},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {875-888},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {On the feasibility of using current data centre infrastructure for latency-sensitive applications},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Intelligent health vessel ABC-DE: An electrocardiogram cloud
computing service. <em>TCC</em>, <em>8</em>(3), 861–874. (<a
href="https://doi.org/10.1109/TCC.2018.2825390">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The severe challenges of the fast aging population and the prevalence of cardiovascular diseases highlight the needs for effective solutions supporting more accurate and affordable medical diagnosis and treatment. Recent advances in cloud computing have inspired numerous designs of cloud-based health care services. In this paper, we developed a cloud-computing platform monitored by physicians, which can receive 12-lead ECG records and send back diagnostic reports to users. Aiming to lessen the physicians&#39; workload, we implemented an analysis algorithm that can identify abnormal heart rate, irregular heartbeat, abnormal amplitude, atrial fibrillation and abnormal ECG in it. A large number of testing samples were used to evaluate performance. Our algorithm achieved a TPR95 (specificity under the condition of negative predictive value being equal to 95 percent) of 68.5 percent and 0.9317 AUC (area under the ROC curve) for classification of normal and abnormal ECG records and a sensitivity of 98.51 percent and specificity of 98.26 percent for atrial fibrillation classification, comparable to the state-of-the-art results for each subject. The proposed ECG cloud computing service has been applied in Hunan Jinshengda Aerial Hospital Network and it now can receive and analyze ECG records in real time.},
  archive      = {J_TCC},
  author       = {Lin-peng Jin and Jun Dong},
  doi          = {10.1109/TCC.2018.2825390},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {861-874},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Intelligent health vessel ABC-DE: An electrocardiogram cloud computing service},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). From byzantine fault-tolerance to fault-avoidance: An
architectural transformation to attack and failure resiliency.
<em>TCC</em>, <em>8</em>(3), 847–860. (<a
href="https://doi.org/10.1109/TCC.2018.2814989">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present Byzantine Fault-Avoidance (BFA), a fault-resilient architecture designed for Byzantine Fault Tolerant (BFT) systems to withstand against attacks and failures. BFA allows replicas to short live on a given computing platform, i.e., hardware, hypervisors and OS, to thwart successful and in-progress attacks while simultaneously preserving the correctness condition of BFT properties; safety and liveness. BFA combines the cloud management software stack of OpenStack (nova) and the Software Defined Network (SDN) implementation (neutron) to control the replicas susceptibility window of attack in order to avoid Byzantine faults. The proposed fault-avoidance scheme illustrates the defensive security solutions enabled by the underlying cloud computing fabric are far superior than the ones implemented at the application/protocol level. Preliminary results of widely studied BFT system (BFT-SMaRT) deployed in a cloud infrastructure (OpenStack-Kilo) indicate that BFA achieves desired BFT reliability properties and throughput over contested environments.},
  archive      = {J_TCC},
  author       = {Noor O. Ahmed and Bharat Bhargava},
  doi          = {10.1109/TCC.2018.2814989},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {847-860},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {From byzantine fault-tolerance to fault-avoidance: An architectural transformation to attack and failure resiliency},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Energy efficient scheduling of servers with multi-sleep
modes for cloud data center. <em>TCC</em>, <em>8</em>(3), 833–846. (<a
href="https://doi.org/10.1109/TCC.2018.2834376">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a cloud data center, servers are always over-provisioned in an active state to meet the peak demand of requests, wasting a large amount of energy as a result. One of the options to reduce the power consumption of data centers is to reduce the number of idle servers, or to switch idle servers into low-power sleep states. However, the servers cannot process the requests immediately when transiting to an active state. There are delays and extra power consumption during the transition. In this paper, we consider using state-of-the-art servers with multi-sleep modes. The sleep modes with smaller transition delays usually consume more power when sleeping. Given the arrival of incoming requests, our goal is to minimize the energy consumption of a cloud data center by the scheduling of servers with multi-sleep modes. We formulate this problem as an integer linear programming (ILP) problem during the whole period of time with millions of decision variables. To solve this problem, we divide it into sub-problems with smaller periods while ensuring the feasibility and transition continuity for each sub-problem through a Backtrack-and-Update technique. We also consider using DVFS to adjust the frequency of active servers, so that the requests can be processed with the least power. Our simulations are based on traces from real world. Experiments show that our method can significantly reduce the power consumption for a cloud data center.},
  archive      = {J_TCC},
  author       = {Chonglin Gu and Zhenlong Li and Hejiao Huang and Xiaohua Jia},
  doi          = {10.1109/TCC.2018.2834376},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {833-846},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Energy efficient scheduling of servers with multi-sleep modes for cloud data center},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient traceable authorization search system for secure
cloud storage. <em>TCC</em>, <em>8</em>(3), 819–832. (<a
href="https://doi.org/10.1109/TCC.2018.2820714">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Secure search over encrypted remote data is crucial in cloud computing to guarantee the data privacy and usability. To prevent unauthorized data usage, fine-grained access control is necessary in multi-user system. However, authorized user may intentionally leak the secret key for financial benefit. Thus, tracing and revoking the malicious user who abuses secret key needs to be solved imminently. In this paper, we propose an escrow free traceable attribute based multiple keywords subset search system with verifiable outsourced decryption (EF-TAMKS-VOD). The key escrow free mechanism could effectively prevent the key generation centre (KGC) from unscrupulously searching and decrypting all encrypted files of users. Also, the decryption process only requires ultra lightweight computation, which is a desirable feature for energy-limited devices. In addition, efficient user revocation is enabled after the malicious user is figured out. Moreover, the proposed system is able to support flexible number of attributes rather than polynomial bounded. Flexible multiple keyword subset search pattern is realized, and the change of the query keywords order does not affect the search result. Security analysis indicates that EF-TAMKS-VOD is provably secure. Efficiency analysis and experimental results show that EF-TAMKS-VOD improves the efficiency and greatly reduces the computation overhead of users&#39; terminals.},
  archive      = {J_TCC},
  author       = {Yang Yang and Ximeng Liu and Xianghan Zheng and Chunming Rong and Wenzhong Guo},
  doi          = {10.1109/TCC.2018.2820714},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {819-832},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Efficient traceable authorization search system for secure cloud storage},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient regular language search for secure cloud storage.
<em>TCC</em>, <em>8</em>(3), 805–818. (<a
href="https://doi.org/10.1109/TCC.2018.2814594">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing provides flexible data management and ubiquitous data access. However, the storage service provided by cloud server is not fully trusted by customers. Searchable encryption could simultaneously provide the functions of confidentiality protection and privacy-preserving data retrieval, which is a vital tool for secure storage. In this paper, we propose an efficient large universe regular language searchable encryption scheme for the cloud, which is privacy-preserving and secure against the off-line keyword guessing attack (KGA). A notable highlight of the proposal over other existing schemes is that it supports the regular language encryption and deterministic finite automata (DFA) based data retrieval. The large universe construction ensures the extendability of the system, in which the symbol set does not need to be predefined. Multiple users are supported in the system, and the user could generate a DFA token using his own private key without interacting with the key generation center. Furthermore, the concrete scheme is efficient and formally proved secure in standard model. Extensive comparison and simulation show that this scheme has function and performance superior than other schemes.},
  archive      = {J_TCC},
  author       = {Yang Yang and Xianghan Zheng and Chunming Rong and Wenzhong Guo},
  doi          = {10.1109/TCC.2018.2814594},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {805-818},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Efficient regular language search for secure cloud storage},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). EDoS-ADS: An enhanced mitigation technique against economic
denial of sustainability (EDoS) attacks. <em>TCC</em>, <em>8</em>(3),
790–804. (<a href="https://doi.org/10.1109/TCC.2018.2805907">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing is an essential technology for the future of the Information Technology (IT) industry. However, the cloud security level is identified as the biggest challenge facing cloud providers and a major concern for cloud adopters. Economic Denial of Sustainability (EDoS) attack is one of the major threats targeting the cloud. The EDoS attack exploits the cloud elasticity and auto scaling features to charge a cloud adopter bill an excessive amount of cost leading to large-scale service withdrawal or bankruptcy. A novel reactive approach referred to as the EDoS Attack Defense Shell (EDoS-ADS) is proposed to mitigate EDoS attacks while taking into account most of the existing mitigation techniques drawbacks. Specifically, the EDoS-ADS has the ability to identify the legitimacy of clients even if they belong to a Network Address Translation (NAT) based network. Thus, EDoS-ADS is the first known technique that effectively prevents an EDoS attack from blocking an entire NAT-based network from accessing the cloud. The EDoS-ADS effectiveness in terms of response time, CPU utilization, throughput, and cost is evaluated using a CloudSim simulator. The simulation results show that EDoS-ADS outperforms other mitigation techniques, and successfully differentiates between legitimate and attacker clients even when they belong to the same NAT-based network.},
  archive      = {J_TCC},
  author       = {Ahmad Shawahna and Marwan Abu-Amara and Ashraf S. H. Mahmoud and Yahya Osais},
  doi          = {10.1109/TCC.2018.2805907},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {790-804},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {EDoS-ADS: An enhanced mitigation technique against economic denial of sustainability (EDoS) attacks},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Distributed resource allocation for data center networks: A
hierarchical game approach. <em>TCC</em>, <em>8</em>(3), 778–789. (<a
href="https://doi.org/10.1109/TCC.2018.2829744">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing demand of data computing and storage for cloud-based services motivates the development and deployment of large-scale data centers. This paper studies the resource allocation problem for the data center networking system when multiple data center operators (DCOs) simultaneously serve multiple service subscribers (SSs). We formulate a hierarchical game to analyze this system where the DCOs and the SSs are regarded as the leaders and followers, respectively. In the proposed game, each SS selects its serving DCO with preferred price and purchases the optimal amount of resources for the SS&#39;s computing requirements. Based on the responses of the SSs&#39; and the other DCOs&#39;, the DCOs decide their resource prices so as to receive the highest profit. When the coordination among DCOs is weak, we consider all DCOs are noncooperative with each other, and propose a sub-gradient algorithm for the DCOs to approach a sub-optimal solution of the game. When all DCOs are sufficiently coordinated, we formulate a coalition game among all DCOs and apply Kalai-Smorodinsky bargaining as a resource division approach to achieve high utilities. Both solutions constitute the Stackelberg Equilibrium. The simulation results verify the performance improvement provided by our proposed approaches.},
  archive      = {J_TCC},
  author       = {Huaqing Zhang and Yong Xiao and Shengrong Bu and F. Richard Yu and Dusit Niyato and Zhu Han},
  doi          = {10.1109/TCC.2018.2829744},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {778-789},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Distributed resource allocation for data center networks: A hierarchical game approach},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Detecting performance anomalies in cloud platform
applications. <em>TCC</em>, <em>8</em>(3), 764–777. (<a
href="https://doi.org/10.1109/TCC.2018.2808289">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present Roots, a full-stack monitoring and analysis system for performance anomaly detection and bottleneck identification in cloud platform-as-a-service (PaaS) systems. Roots facilitates application performance monitoring as a core capability of PaaS clouds, and relieves the developers from having to instrument application code. Roots tracks HTTP/S requests to hosted cloud applications and their use of PaaS services. To do so it employs lightweight monitoring of PaaS service interfaces. Roots processes this data in the background using multiple statistical techniques that in combination detect performance anomalies (i.e., violations of service-level objectives). For each anomaly, Roots determines whether the event was caused by a change in the request workload or by a performance bottleneck in a PaaS service. By correlating data collected across different layers of the PaaS, Roots is able to trace high-level performance anomalies to bottlenecks in specific components in the cloud platform. We implement Roots using the AppScale PaaS and evaluate its overhead and accuracy.},
  archive      = {J_TCC},
  author       = {Hiranya Jayathilaka and Chandra Krintz and Rich Wolski},
  doi          = {10.1109/TCC.2018.2808289},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {764-777},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Detecting performance anomalies in cloud platform applications},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adjusting packet size to mitigate TCP incast in data center
networks with COTS switches. <em>TCC</em>, <em>8</em>(3), 749–763. (<a
href="https://doi.org/10.1109/TCC.2018.2810870">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In data center networks, a large number of concurrent TCP connections suffer the TCP Incast throughput collapse due to packet drops in shallow-buffered Ethernet switches. In this work, we first reveal theoretically and empirically that controlling the IP packet size is much more effective in avoiding Incast than cutting congestion window under severe congestion. We further design a general supporting scheme Packet Slicing, which adjusts the IP packet on widely used commodity switches. The design uses standard ICMP signaling, which makes no modification on TCP protocols and can be transparently utilized by various TCP protocols. To alleviate the impact of micro-burst caused by high flow concurrency, we utilize the TCP Pacing scheme to disperse packets over the round trip time, helping Packet Slicing to support more concurrent TCP flows. We integrate Packet Slicing with three state-of-the-art data center TCP protocols on NS2 simulation and a physical testbed. The experimental results show that Packet Slicing broadly improves the goodput of different data center TCP protocols by average 26x, while having almost no effect on the I/O performance of switches and end hosts.},
  archive      = {J_TCC},
  author       = {Jiawei Huang and Yi Huang and Jianxin Wang and Tian He},
  doi          = {10.1109/TCC.2018.2810870},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {749-763},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Adjusting packet size to mitigate TCP incast in data center networks with COTS switches},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A truthful <span
class="math inline">(1 − <em>ϵ</em>)</span>(1-ε)-optimal mechanism for
on-demand cloud resource provisioning. <em>TCC</em>, <em>8</em>(3),
735–748. (<a href="https://doi.org/10.1109/TCC.2018.2822718">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {On-demand resource provisioning in cloud computing provides tailor-made resource packages (typically in the form of VMs) to meet users’ demands. Public clouds nowadays provide elaborated types of VMs, but have yet to offer the most flexible dynamic VM assembly, which is partly due to the lack of a mature mechanism for pricing tailor-made VMs. This work proposes an efficient randomized auction mechanism based on a novel application of smoothed analysis and randomized reduction, for dynamic VM provisioning and pricing in geo-distributed cloud data centers. To the best of our knowledge, it is the first one in literature that achieves (i) truthfulness in expectation, (ii) polynomial running time in expectation, and (iii) $(1-\epsilon)$ -optimal social welfare in expectation for resource allocation, where $\epsilon$ can be arbitrarily close to 0. Our mechanism consists of three modules: (1) an exact algorithm to solve the NP-hard social welfare maximization problem, which has polynomial run-time in expectation, (2) a perturbation-based randomized resource allocation scheme which produces an allocation solution that is $(1-\epsilon)$ -optimal and (3) an auction mechanism prices the customized VMs using a randomized VCG payment, with a guarantee in truthfulness in expectation. We validate the efficacy of the mechanism through theoretical analysis and trace-driven simulations.},
  archive      = {J_TCC},
  author       = {Xiaoxi Zhang and Chuan Wu and Zongpeng Li and Francis C. M. Lau},
  doi          = {10.1109/TCC.2018.2822718},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {735-748},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {A truthful $(1-\epsilon)$(1-ε)-optimal mechanism for on-demand cloud resource provisioning},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A tight estimate of job completion time in vehicular clouds.
<em>TCC</em>, <em>8</em>(3), 721–734. (<a
href="https://doi.org/10.1109/TCC.2018.2834352">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by the success of conventional cloud services and by the reality of present-day vehicles endowed with powerful on-board computers that can act as servers in a datacenter, researchers have recently introduced the concept of a vehicular cloud. Our main contribution is to offer a tight theoretical analysis of the expected job completion time in vehicular clouds characterized by short vehicular residency times, under a redundancy-based job assignment strategy. We also discuss various approximations of the expected completion time. A comprehensive set of simulations have confirmed the accuracy of our theoretical predictions.},
  archive      = {J_TCC},
  author       = {Ryan Florin and Puya Ghazizadeh and Aida Ghazi Zadeh and Ravi Mukkamala and Stephan Olariu},
  doi          = {10.1109/TCC.2018.2834352},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {721-734},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {A tight estimate of job completion time in vehicular clouds},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A robust formulation for efficient application offloading to
clouds. <em>TCC</em>, <em>8</em>(3), 710–720. (<a
href="https://doi.org/10.1109/TCC.2018.2827944">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Application offloading to clouds is the key enabler for compute-intensive applications running on mobile devices. An offloading algorithm employs estimated averages of the execution and communication costs of application modules to decide on a modules subset to be offloaded with the objective of minimizing a certain metric (e.g., execution time or energy). This decision is highly affected by the inherent uncertainty arising from the estimated cost averages due to natural fluctuations or measurement inaccuracies. In this article, we propose a novel offloading scheme that takes into consideration these uncertainties. The proposed work first formulates the offloading problem as a tractable robust optimization one where the uncertainty in k cost parameters is incorporated by allowing these parameters to fluctuate within intervals specified from profiling the application and the network. We then show that this problem can be transformed into k + 1 binary linear programs that are solved while preserving the complexity of the original problem. In contrast to existing approaches, the performance of the obtained decision is guaranteed as long as the behavior of the uncertain parameters remains within the given intervals. Performance evaluation results using a face detection and synthetically generated applications with a large number of modules demonstrate the robustness of the obtained offloading decisions.},
  archive      = {J_TCC},
  author       = {José Barrameda and Nancy Samaan},
  doi          = {10.1109/TCC.2018.2827944},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {710-720},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {A robust formulation for efficient application offloading to clouds},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A power-of-two choices based algorithm for fog computing.
<em>TCC</em>, <em>8</em>(3), 698–709. (<a
href="https://doi.org/10.1109/TCC.2018.2828809">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fog computing paradigm brings together storage, communication, and computation resources closer to users&#39; end-devices. Therefore, fog servers are deployed at the edge of the network, offering low latency access to users. With the expansion of such fog computing services, different providers will be able to deploy multiple resources within a restricted geographical proximity. In this paper, we investigate an incentive-based cooperation scheme across fog providers. We propose a distributed cooperative algorithm amongst fog computing providers where fully collaborative fog nodes are subject to different loads. The proposed algorithm leverages the power-of-two result and exploits a cooperation probability, namely the probability that a given provider collaborates by accepting a computation request from another provider, as a mean to achieve a fair cooperation. We adopt an analytical approach based on exploiting a simplified performance model to demonstrate numerically that a set of optimal accepting probabilities exits when the number of server nodes goes to infinity. This result then drives the design of our distributed algorithm. Second, in our experimental approach, we perform a set of simulation analysis to verify the validity of the proposed solution when the number of servers is limited.},
  archive      = {J_TCC},
  author       = {Roberto Beraldi and Hussein Alnuweiri and Abderrahmen Mtibaa},
  doi          = {10.1109/TCC.2018.2828809},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {698-709},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {A power-of-two choices based algorithm for fog computing},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A planning approach for reassigning virtual machines in IaaS
clouds. <em>TCC</em>, <em>8</em>(3), 685–697. (<a
href="https://doi.org/10.1109/TCC.2018.2826548">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reassignment of virtual machines into clusters is an important task for the good management of cloud resources since it decisively affects the performance of the Service Provider platform. Thus, for a successful reassignment, a clear and careful reassignment plan should be constructed in advance. In this paper, we propose a planning approach to the problem of reassigning virtual machines in IaaS Cloud platforms. First, we use the well-known A* algorithm to solve this planning problem. Then, we propose two algorithms, called Direct Move Heuristic (DMH) and Iterative Direct Move Heuristic (IDMH), to bridge the space limitation of the A* algorithm. Also, we suggest two experimental studies that have been conducted on randomly generated problem instances. The first experimental study considers small sized problem instances. It aims to show the applicability of the described modeling and assesses the efficiency of the proposed algorithms. The second experimental study focuses on large sized problem instances. It assesses the scalability performance of the IDMH heuristic. Our obtained results show a good scalability performance on problem instances with up to 800 virtual machines.},
  archive      = {J_TCC},
  author       = {Yacine Laalaoui and Jehad Al-Omari},
  doi          = {10.1109/TCC.2018.2826548},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {685-697},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {A planning approach for reassigning virtual machines in IaaS clouds},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new lightweight symmetric searchable encryption scheme for
string identification. <em>TCC</em>, <em>8</em>(3), 672–684. (<a
href="https://doi.org/10.1109/TCC.2018.2820014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we provide an efficient and easy-to-implement symmetric searchable encryption scheme (SSE) for string search, which takes one round of communication, O(n) times of computations over n documents. Unlike previous schemes, we use hash-chaining instead of chain of encryption operations for index generation, which makes it suitable for lightweight applications. Unlike the previous SSE schemes for string search, with our scheme, server learns nothing about the frequency and the relative positions of the words being searched except what it can learn from the history. We are the first to propose probabilistic trapdoors in SSE for string search. We provide concrete proof of non-adaptive security of our scheme against honest-but-curious server based on the definitions of [12]. We also introduce a new notion of search pattern privacy, which gives a measure of security against the leakage from trapdoor. We have shown that our scheme is secure under search pattern indistinguishability definition. We show why SSE scheme for string search cannot attain adaptive indistinguishability criteria as mentioned in [12]. We also propose modifications of our scheme so that the scheme can be used against active adversaries at the cost of more rounds of communications and memory space. We validate our scheme against two different commercial datasets (see [1], [2]).},
  archive      = {J_TCC},
  author       = {Indranil Ghosh Ray and Yogachandran Rahulamathavan and Muttukrishnan Rajarajan},
  doi          = {10.1109/TCC.2018.2820014},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {672-684},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {A new lightweight symmetric searchable encryption scheme for string identification},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A key-policy attribute-based temporary keyword search scheme
for secure cloud storage. <em>TCC</em>, <em>8</em>(3), 660–671. (<a
href="https://doi.org/10.1109/TCC.2018.2825983">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporary keyword search on confidential data in a cloud environment is the main focus of this research. The cloud providers are not fully trusted. So, it is necessary to outsource data in the encrypted form. In the attribute-based keyword search (ABKS) schemes, the authorized users can generate some search tokens and send them to the cloud for running the search operation. These search tokens can be used to extract all the ciphertexts which are produced at any time and contain the corresponding keyword. Since this may lead to some information leakage, it is more secure to propose a scheme in which the search tokens can only extract the ciphertexts generated in a specified time interval. To this end, in this paper, we introduce a new cryptographic primitive called key-policy attribute-based temporary keyword search (KP-ABTKS) which provide this property. To evaluate the security of our scheme, we formally prove that our proposed scheme achieves the keyword secrecy property and is secure against selectively chosen keyword attack (SCKA) both in the random oracle model and under the hardness of Decisional Bilinear Diffie-Hellman (DBDH) assumption. Furthermore, we show that the complexity of the encryption algorithm is linear with respect to the number of the involved attributes. Performance evaluation shows our scheme&#39;s practicality.},
  archive      = {J_TCC},
  author       = {Mohammad Hassan Ameri and Mahshid Delavar and Javad Mohajeri and Mahmoud Salmasizadeh},
  doi          = {10.1109/TCC.2018.2825983},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {660-671},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {A key-policy attribute-based temporary keyword search scheme for secure cloud storage},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A distributed auction-based framework for scalable IaaS
provisioning in geo-data centers. <em>TCC</em>, <em>8</em>(3), 647–659.
(<a href="https://doi.org/10.1109/TCC.2018.2808531">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a Cloud Infrastructure-as-a-Service (IaaS) framework that allows customers to have their high performance computing applications hosted efficiently and Cloud Service Providers (CSPs) to use their resources profitably. The solution introduces a distributed architecture that manages geographically distributed Data Centers (Geo-Data Centers) logically grouped in regions. This framework overcomes the challenges of traditional centralized provisioning approaches: (a) efficient provisioning of IaaS demand, (b) scale with respect to the growing number of IaaS requests, (c) guarantee of the stringent Quality of Service requirements of IaaS requests, and (d) efficient use of Cloud Geo-Data Center computing resources. Our architecture incorporates two decentralized approaches, hierarchical and distributed, that use auctions instead of a pay-as-you-go pricing scheme. The two approaches use a large-scale optimization technique for the allocation of Geo-Data Centers computing resources. The results of a simulation demonstrate an efficient use of computing resources and a significant reduction in computation time. This ensures adequate scalability to meet an exponential growth of IaaS demand. The auction-based approaches are also shown to provide monetary benefits to the participants.},
  archive      = {J_TCC},
  author       = {Khaled Metwally and Abdallah Jarray and Ahmed Karmouch},
  doi          = {10.1109/TCC.2018.2808531},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {647-659},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {A distributed auction-based framework for scalable IaaS provisioning in geo-data centers},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Locality-aware scheduling for containers in cloud computing.
<em>TCC</em>, <em>8</em>(2), 635–646. (<a
href="https://doi.org/10.1109/TCC.2018.2794344">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The state-of-the-art scheduler of containerized cloud services considers load balance as the only criterion; many other important properties, including application performance, are overlooked. In the era of Big Data, however, applications evolve to be increasingly more data-intensive thus perform poorly when deployed on containerized cloud services. To that end, this paper aims to improve today&#39;s cloud service by taking application performance into account for the next-generation container schedulers. More specifically, in this work we build and analyze a new model that respects both load balance and application performance. Unlike prior studies, our model abstracts the dilemma between load balance and application performance into a unified optimization problem and then employs a statistical method to efficiently solve it. The most challenging part is that some sub-problems are extremely complex (for example, NP-hard), and heuristic algorithms have to be devised. Last but not least, we implement a system prototype of the proposed scheduling strategy for containerized cloud services. Experimental results show that our system can significantly boost application performance while preserving high load balance.},
  archive      = {J_TCC},
  author       = {Dongfang Zhao and Mohamed Mohamed and Heiko Ludwig},
  doi          = {10.1109/TCC.2018.2794344},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {635-646},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Locality-aware scheduling for containers in cloud computing},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). QoS-aware cloudlet load balancing in wireless metropolitan
area networks. <em>TCC</em>, <em>8</em>(2), 623–634. (<a
href="https://doi.org/10.1109/TCC.2017.2786738">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With advances in wireless communication technology, more and more people depend heavily on portable mobile devices for business, entertainments and social interactions. This poses a great challenge of building a seamless application experience across different computing platforms. A key issue is the resource limitations of mobile devices due to their portable size, however this can be overcome by offloading computation-intensive tasks from the mobile devices to clusters of nearby computers called cloudlets through wireless access points. As increasing numbers of people access the Internet via mobile devices, it is reasonable to envision in the near future that cloudlet services will be available for the public through easily accessible public wireless metropolitan area networks (WMANs). However, the outdated notion of treating cloudlets as isolated data-centers-in-boxes must be discarded as there are clear benefits to connecting multiple cloudlets together to form a network. In this paper we investigate how to balance the workload among cloudlets in an WMAN to optimize mobile application performance. We first introduce a novel system model to capture the response time delays of offloaded tasks and formulate an optimization problem with the aim to minimize the maximum response time of all offloaded tasks. We then propose two algorithms for the problem: one is a fast heuristic, and another is a distributed genetic algorithm that is capable of delivering a more accurate solution compared with the first algorithm, but at the expense of a much longer running time. We finally evaluate the performance of the proposed algorithms in realistic simulation environments. The experimental results demonstrate the significant potential of the proposed algorithms in reducing the user task response time, maximizing user experience.},
  archive      = {J_TCC},
  author       = {Mike Jia and Weifa Liang and Zichuan Xu and Meitian Huang and Yu Ma},
  doi          = {10.1109/TCC.2017.2786738},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {623-634},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {QoS-aware cloudlet load balancing in wireless metropolitan area networks},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Privacy-preserving outsourced support vector machine design
for secure drug discovery. <em>TCC</em>, <em>8</em>(2), 610–622. (<a
href="https://doi.org/10.1109/TCC.2018.2799219">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a framework for privacy-preserving outsourced drug discovery in the cloud, which we refer to as POD. Specifically, POD is designed to allow the cloud to securely use multiple drug formula providers&#39; drug formulas to train Support Vector Machine (SVM) provided by the analytical model provider. In our approach, we design secure computation protocols to allow the cloud server to perform commonly used integer and fraction computations. To securely train the SVM, we design a secure SVM parameter selection protocol to select two SVM parameters and construct a secure sequential minimal optimization protocol to privately refresh both selected SVM parameters. The trained SVM classifier can be used to determine whether a drug chemical compound is active or not in a privacy-preserving way. Lastly, we prove that the proposed POD achieves the goal of SVM training and chemical compound classification without privacy leakage to unauthorized parties, as well as demonstrating its utility and efficiency using three real-world drug datasets.},
  archive      = {J_TCC},
  author       = {Ximeng Liu and Robert H. Deng and Kim-Kwang Raymond Choo and Yang Yang},
  doi          = {10.1109/TCC.2018.2799219},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {610-622},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Privacy-preserving outsourced support vector machine design for secure drug discovery},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Privacy aware data deduplication for side channel in cloud
storage. <em>TCC</em>, <em>8</em>(2), 597–609. (<a
href="https://doi.org/10.1109/TCC.2018.2794542">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud storage services enable individuals and organizations to outsource data storage to remote servers. Cloud storage providers generally adopt data deduplication, a technique for eliminating redundant data by keeping only a single copy of a file, thus saving a considerable amount of storage and bandwidth. However, an attacker can abuse deduplication protocols to steal information. For example, an attacker can perform the duplicate check to verify whether a file (e.g., a pay slip, with a specific name and salary amount) is already stored (by someone else), hence breaching the user privacy. In this paper, we propose ZEUS (zero-knowledge deduplication response) framework. We develop ZEUS and ZEUS+, two privacy-aware deduplication protocols: ZEUS provides weaker privacy guarantees while being more efficient in the communication cost, while ZEUSþ guarantees stronger privacy properties, at an increased communication cost. To the best of our knowledge, ZEUS is the first solution which addresses two-side privacy by neither using any extra hardware nor depending on heuristically chosen parameters used by the existing solutions, thus reducing both cost and complexity of the cloud storage. In summary, through the evaluation on real datasets and comparison to existing solutions, our proposed framework demonstrates its capability of eliminating data deduplication-based side channel and at the same time keeping the deduplication benefits.},
  archive      = {J_TCC},
  author       = {Chia-Mu Yu and Sarada Prasad Gochhayat and Mauro Conti and Chun-Shien Lu},
  doi          = {10.1109/TCC.2018.2794542},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {597-609},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Privacy aware data deduplication for side channel in cloud storage},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Near-optimal deployment of service chains by exploiting
correlations between network functions. <em>TCC</em>, <em>8</em>(2),
585–596. (<a href="https://doi.org/10.1109/TCC.2017.2780165">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A modern Network Function Virtualization (NFV) service is usually expressed in a service chain that contains a list of ordered network functions, each can run in one or multiple virtual machines. Although lots of efforts have been devoted to service chain deployment, the researchers normally consider a simple model of network functions where different service chains have their own network functions no matter whether some of the network function appliances are interdependent. In this paper, we study the service chain deployment by exploiting two types of correlations between network functions: the Coordination Effect due to information exchanges among multiple VMs running the same network function, and the Traffic-Change Effect where the volume of outgoing traffic is not necessarily equal to the volume of its incoming traffic at each network function because of packet manipulations such as compression and encryption. These two effects have not been studied simultaneously in the context of service chaining. With theobjective to maximize the profit measured by the admitted traffic minus the implementation cost, we first formulate a joint service-function deployment and traffic scheduling (SUPER) problem that is proved to be NP-hard. We then devise an approximation algorithm based on the Markov approximation technique and analyze its theoretical bound on the convergence time. Simulation results show that the proposed algorithm outperforms two existing benchmark algorithms significantly.},
  archive      = {J_TCC},
  author       = {Huawei Huang and Peng Li and Song Guo and Weifa Liang and Kun Wang},
  doi          = {10.1109/TCC.2017.2780165},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {585-596},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Near-optimal deployment of service chains by exploiting correlations between network functions},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Energy-efficient decision making for mobile cloud
offloading. <em>TCC</em>, <em>8</em>(2), 570–584. (<a
href="https://doi.org/10.1109/TCC.2018.2789446">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile cloud offloading migrates heavy computation from mobile devices to remote cloud resources or nearby cloudlets. It is a promising method to alleviate the struggle between resource-constrained mobile devices and resource-hungry mobile applications. Caused by frequently changing location mobile users often see dynamically changing network conditions which have a great impact on the perceived application performance. Therefore, making high-quality offloading decisions at run time is difficult in mobile environments. To balance the energy-delay tradeoff based on different offloading-decision criteria (e.g., minimum response time or energy consumption), an energy-efficient offloading-decision algorithm based on Lyapunov optimization is proposed. The algorithm determines when to run the application locally, when to forward it directly for remote execution to a cloud infrastructure and when to delegate it via a nearby cloudlet to the cloud. The algorithm is able to minimize the average energy consumption on the mobile device while ensuring that the average response time satisfies a given time constraint. Moreover, compared to local and remote execution, the Lyapunov-based algorithm can significantly reduce the energy consumption while only sacrificing a small portion of response time. Furthermore, it optimizes energy better and has less computational complexity than the Lagrange Relaxation based Aggregated Cost (LARAC-based) algorithm.},
  archive      = {J_TCC},
  author       = {Huaming Wu and Yi Sun and Katinka Wolter},
  doi          = {10.1109/TCC.2018.2789446},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {570-584},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Energy-efficient decision making for mobile cloud offloading},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A dynamic and failure-aware task scheduling framework for
hadoop. <em>TCC</em>, <em>8</em>(2), 553–569. (<a
href="https://doi.org/10.1109/TCC.2018.2805812">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hadoop has become a popular framework for processing data-intensive applications in cloud environments. A core constituent of Hadoop is the scheduler, which is responsible for scheduling and monitoring the jobs and tasks, and rescheduling them in case of failures. Although fault-tolerance mechanisms have been proposed for Hadoop, the performance of Hadoop can be significantly impacted by unforeseen events in the cloud environment. In this paper, we introduce a dynamic and failure-aware framework that can be integrated within Hadoop scheduler and adjust the scheduling decisions based on collected information about the cloud environment. Our framework relies on predictions made by machine learning algorithms and scheduling policies generated by a Markovian Decision Process (MDP), to adjust its scheduling decisions on the fly. Instead of the fixed heartbeat-based failure detection commonly used in Hadoop to track active TaskTrackers (i.e., nodes that process the scheduled tasks), our proposed framework implements an adaptive algorithm that can dynamically detect the failures of the TaskTracker. To deploy our proposed framework, we have built, ATLAS+, an AdapTive Failure-Aware Scheduler for Hadoop. To assess the performance of ATLAS+, we conduct a large empirical study on a 100-node Hadoop cluster deployed on Amazon Elastic MapReduce (EMR), comparing the performance of ATLAS+ with those of three Hadoop schedulers (FIFO, Fair, and Capacity). Results show that ATLAS+ outperforms FIFO, Fair, and Capacity schedulers. ATLAS+ can reduce the number of failed jobs by up to 43 percent and the number of failed tasks by up to 59 percent. On average, ATLAS+ could reduce the total execution time of jobs by 10 minutes, which represents 40 percent of the job execution times, and by up to 3 minutes for tasks, which represents 47 percent of the task execution time. ATLAS+ also reduced CPU and memory usage by 22 and 20 percent, respectively.},
  archive      = {J_TCC},
  author       = {Mbarka Soualhia and Foutse Khomh and Sofiène Tahar},
  doi          = {10.1109/TCC.2018.2805812},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {553-569},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {A dynamic and failure-aware task scheduling framework for hadoop},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Wisdom as a service for mental health care. <em>TCC</em>,
<em>8</em>(2), 539–552. (<a
href="https://doi.org/10.1109/TCC.2015.2464820">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain informatics adopts a systematic methodology to study clinical diagnosis and pathology of mental disorders from macro, meso and micro points of view. Systematic studies produce multi-level and multi-aspect health big data of mental disorders. Effectively integrating multi-level mental health big data and providing multi-level and content-oriented data services for different types of users by an open and extendable mode becomes new requirements on the acquisition and computing of mental health big data. The existing Data-Brain-based brain data center cannot meet these new requirements. This paper proposes a brain and health big data center and develops a content-oriented cloud service architecture, namely, wisdom as a service, for realizing the brain and health big data center. The illustrative example demonstrates significance and usefulness of the proposed approach.},
  archive      = {J_TCC},
  author       = {Jianhui Chen and Ningning Wang and Yue Deng and Han Zhong and Jian Han and Youjun Li and Zhijiang Wan and Taihei Kotake and Dongsheng Wang and Ning Zhong},
  doi          = {10.1109/TCC.2015.2464820},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {539-552},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Wisdom as a service for mental health care},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Parallel RMCLP classification algorithm and its application
on the medical data. <em>TCC</em>, <em>8</em>(2), 532–538. (<a
href="https://doi.org/10.1109/TCC.2015.2481381">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To make better use of the cloud computing technology, and to overcome the computing and storage requirements which increase rapidly with the number of training samples, in this paper, a new parallel algorithm is proposed-Parallel Regularized Multiple-Criteria Linear Programming (PRMCLP) algorithm-The RMCLP model is converted into a unconstrained optimization problem, and then, in the parallel version, it is split into several tasks, where each part is mapped and computed on a separate processor. This approach enables us to obtain efficiently the final optimization solution of the whole classification problem. At last, we apply this algorithm to Medical data classification. All experiments show that our method and approach greatly increases the training speed of RMCLP in the parallel case.},
  archive      = {J_TCC},
  author       = {Zhiquan Qi and Yingjie Tian and Yong Shi and Vassil Alexandrov},
  doi          = {10.1109/TCC.2015.2481381},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {532-538},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Parallel RMCLP classification algorithm and its application on the medical data},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Splitting large medical data sets based on normal
distribution in cloud environment. <em>TCC</em>, <em>8</em>(2), 518–531.
(<a href="https://doi.org/10.1109/TCC.2015.2462361">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The surge of medical and e-commerce applications has generated tremendous amount of data, which brings people to a so-called “Big Data” era. Different from traditional large data sets, the term “Big Data” not only means the large size of data volume but also indicates the high velocity of data generation. However, current data mining and analytical techniques are facing the challenge of dealing with large volume data in a short period of time. This paper explores the efficiency of utilizing the Normal Distribution (ND) method for splitting and processing large volume medical data in cloud environment, which can provide representative information in the split data sets. The ND-based new model consists of two stages. The first stage adopts the ND method for large data sets splitting and processing, which can reduce the volume of data sets. The second stage implements the ND-based model in a cloud computing infrastructure for allocating the split data sets. The experimental results show substantial efficiency gains of the proposed method over the conventional methods without splitting data into small partitions. The ND-based method can generate representative data sets, which can offer efficient solution for large data processing. The split data sets can be processed in parallel in Cloud computing environment.},
  archive      = {J_TCC},
  author       = {Hao Lan Zhang and Yali Zhao and Chaoyi Pang and Jinyuan He},
  doi          = {10.1109/TCC.2015.2462361},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {518-531},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Splitting large medical data sets based on normal distribution in cloud environment},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficiently translating complex SQL query to MapReduce
jobflow on cloud. <em>TCC</em>, <em>8</em>(2), 508–517. (<a
href="https://doi.org/10.1109/TCC.2017.2700842">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {MapReduce is a widely-used programming model in cloud environment for parallel processing large-scale data sets. The combination of the high-level language with a SQL-to-MapReduce translator allows programmers to code using SQL-like declarative language, so that each program can afterwards be complied into a MapReduce jobflow automatically. This way is helpful to narrow the gap between non-professional users and cloud platforms, and thus significantly improve the usability of the cloud. Although a number of translators have been developed, the auto-generated MapReduce programs still suffered from extremely inefficiency. In this paper, we present an efficient Cost-Aware SQL-to-MapReduce Translator (CAT). CAT has two notable features. First, it defines two intra-SQL correlations: Generalized Job Flow Correlation (GJFC) and Input Correlation (IC), based on which a set of looser merging rules are introduced. Thus, both Top-Down (TD) and Bottom-Up (BU) merging strategies are proposed and integrated into CAT simultaneously. Second, it adopts a cost estimation model for MapReduce jobflows to guide the selection of a more efficient MapReduce jobflows auto-generated by TD and BU merging strategies. Finally, comparative experiments on TPC-H benchmark demonstrate the effectiveness and scalability of CAT.},
  archive      = {J_TCC},
  author       = {Zhiang Wu and Aibo Song and Jie Cao and Junzhou Luo and Lu Zhang},
  doi          = {10.1109/TCC.2017.2700842},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {508-517},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Efficiently translating complex SQL query to MapReduce jobflow on cloud},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cloud colonography: Distributed medical testbed over cloud.
<em>TCC</em>, <em>8</em>(2), 495–507. (<a
href="https://doi.org/10.1109/TCC.2015.2481414">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud Colonography is proposed in this paper, using different types of cloud computing environments. Databases from the Computed Tomographic Colonography (CTC) screening tests among several hospitals are explored. These networked databases are going to be available in the near future via cloud computing technologies. Associated Multiple Databases (AMD) was developed in this study to handle multiple CTC databases. When AMD is used for assembling databases, it can achieve very high classification accuracy. The proposed AMD has the potential to play a role of the core classifier in the cloud computing framework. AMD for multiple institutions databases yields high detection performance of polyps using Kernel principal component analysis (KPCA). Two cases in the proposed cloud platform are private and public. We adapted a university cluster as a private platform, and Amazon Elastic Compute Cloud (EC2) as a public. The computation time, memory usage, and running costs were compared using three representative databases between private and public cloud environments. The proposed parallel processing modules improved the computation time, especially in the public cloud environments. The successful development of a cloud computing environment that handles large amounts of data will make Cloud Colonography feasible for a new health care service.},
  archive      = {J_TCC},
  author       = {Yuichi Motai and Eric Henderson and Nahian Alam Siddique and Hiroyuki Yoshida},
  doi          = {10.1109/TCC.2015.2481414},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {495-507},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Cloud colonography: Distributed medical testbed over cloud},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Achieving secure and efficient dynamic searchable symmetric
encryption over medical cloud data. <em>TCC</em>, <em>8</em>(2),
484–494. (<a href="https://doi.org/10.1109/TCC.2017.2769645">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In medical cloud computing, a patient can remotely outsource her medical data to the cloud server. In this case, only authorized doctors are allowed to access the data since the medical data is highly sensitive. Before outsourcing, the data is commonly encrypted, where the corresponding secret key is sent to authorized doctors. However, performing searches on encrypted medical data is difficult without decryption. In this paper, we propose two Secure and Efficient Dynamic Searchable Symmetric Encryption (SEDSSE) schemes over medical cloud data. First, we utilize the secure k-Nearest Neighbor (kNN) and Attribute-Based Encryption (ABE) techniques to construct a dynamic searchable symmetric encryption scheme, which can achieve forward privacy and backward privacy simultaneously. These tow security properties are vital and very challenging in the area of dynamic searchable symmetric encryption. Then, we propose an enhanced scheme to solve the key sharing problem which widely exists in the kNN based searchable encryption scheme. Compared with existing proposals, our schemes are better in terms of storage, search and updating complexity. Extensive experiments demonstrate the efficiency of our schemes on storage overhead, index building, trapdoor generating and query.},
  archive      = {J_TCC},
  author       = {Hongwei Li and Yi Yang and Yuanshun Dai and Shui Yu and Yong Xiang},
  doi          = {10.1109/TCC.2017.2769645},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {484-494},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Achieving secure and efficient dynamic searchable symmetric encryption over medical cloud data},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A clustering-based multi-layer distributed ensemble for
neurological diagnostics in cloud services. <em>TCC</em>, <em>8</em>(2),
473–483. (<a href="https://doi.org/10.1109/TCC.2016.2567389">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the problem of minimizing data transfer between different data centers of the cloud during the neurological diagnostics of cardiac autonomic neuropathy (CAN). This problem has never been considered in the literature before. All classifiers considered for the diagnostics of CAN previously assume complete access to all data, which would lead to enormous burden of data transfer during training if such classifiers were deployed in the cloud. We introduce a new model of clustering-based multi-layer distributed ensembles (CBMLDE). It is designed to eliminate the need to transfer data between different data centers for training of the classifiers. We conducted experiments utilizing a dataset derived from an extensive DiScRi database. Our comprehensive tests have determined the best combinations of options for setting up CBMLDE classifiers. The results demonstrate that CBMLDE classifiers not only completely eliminate the need in patient data transfer, but also have significantly outperformed all base classifiers and simpler counterpart models in all cloud frameworks.},
  archive      = {J_TCC},
  author       = {Morshed U. Chowdhury and Jemal H. Abawajy and Andrei Kelarev and Herbert F. Jelinek},
  doi          = {10.1109/TCC.2016.2567389},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {473-483},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {A clustering-based multi-layer distributed ensemble for neurological diagnostics in cloud services},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stochastic load balancing for virtual resource management in
datacenters. <em>TCC</em>, <em>8</em>(2), 459–472. (<a
href="https://doi.org/10.1109/TCC.2016.2525984">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing offers a cost-effective and elastic computing paradigm that facilitates large scale data storage and analytics. By deploying virtualization technologies in the datacenter, cloud enables efficient resource management and isolation for various big data applications. Since the hotspots (i.e., overloaded machines) can degrade the performance of these applications, virtual machine migration has been utilized to perform load balancing in the datacenters to eliminate hotspots and guarantee Service Level Agreements (SLAs). However, the previous load balancing schemes make migration decisions based on deterministic resource demand estimation and workload characterization, without considering their stochastic properties. By studying real world traces, we show that the resource demand and workload of virtual machines are highly dynamic and bursty, which can cause these schemes to make inefficient migrations for load balancing. To address this problem, in this paper we propose a stochastic load balancing scheme which aims to provide probabilistic guarantee against the resource overloading with virtual machine migration, while minimizing the total migration overhead. Our scheme effectively addresses the prediction of the distribution of resource demand and the multidimensional resource requirements with stochastic characterization. Moreover, as opposed to the previous works that measure the migration cost without considering the network topology, our scheme explicitly takes into account the distance between the source physical machine and the destination physical machine for a virtual machine migration. The trace-driven experiments show that our scheme outperforms the previous schemes in terms of SLA violation and the migration cost.},
  archive      = {J_TCC},
  author       = {Lei Yu and Liuhua Chen and Zhipeng Cai and Haiying Shen and Yi Liang and Yi Pan},
  doi          = {10.1109/TCC.2016.2525984},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {459-472},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Stochastic load balancing for virtual resource management in datacenters},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Statistical model checking-based evaluation and optimization
for cloud workflow resource allocation. <em>TCC</em>, <em>8</em>(2),
443–458. (<a href="https://doi.org/10.1109/TCC.2016.2586067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the existence of resource variations, it is very challenging for Cloud workflow resource allocation strategies to guarantee a reliable Quality of Service (QoS). Although dozens of resource allocation heuristics have been developed to improve the QoS of Cloud workflow, it is hard to predict their performance under variations because of the lack of accurate modeling and evaluation methods. So far, there is no comprehensive approach that can quantitatively reason the capability of resource allocation strategies or enable the tuning of parameters to optimize resource allocation solutions under variations. To address the above problems, this paper proposes a novel framework that can evaluate and optimize resource allocation strategies effectively and quantitatively. By using the statistical model checker UPPAAL-SMC and supervised learning approaches, our framework can: i) conduct complex QoS queries on resource allocation instances considering resource variations; ii) make quantitative and qualitative comparisons among resource allocation strategies; iii) enable the tuning of parameters to improve the overall QoS; and iv) support the quick optimization of overall workflow QoS under customer requirements and resource variations. The experimental results demonstrate that our automated framework can support both the Service Level Agreement (SLA) negotiation and workflow resource allocation optimization efficiently.},
  archive      = {J_TCC},
  author       = {Mingsong Chen and Saijie Huang and Xin Fu and Xiao Liu and Jifeng He},
  doi          = {10.1109/TCC.2016.2586067},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {443-458},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Statistical model checking-based evaluation and optimization for cloud workflow resource allocation},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Segmented in-advance data analytics for fast scientific
discovery. <em>TCC</em>, <em>8</em>(2), 432–442. (<a
href="https://doi.org/10.1109/TCC.2016.2541142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scientific discovery usually involves data generation, data preprocessing, data storage and data analysis. As the data volume exceeds a few terabytes (TB) in a single simulation run, the data movement, which happens during each cycle of the scientific discovery, continues to be the bottleneck in most scientific big data applications. A lot of research works have been conducted on reducing the data movement. Among the existing efforts and based on our previous research, reusing the analysis results shows a significant potential in optimizing the data movement between analysis operations. In this work, we propose the Segmented In-Advance (SIA) data analytics approach for optimizing the data movement and we also provide a cloud-based elastic distributed in-memory database to manage the intermediate analysis results. The fundamental idea of this Segmented In-Advance approach is to analyze the history operations and to predict the future interesting analytics operations. The predicted analysis operation is in-advance performed on the finer segmented dataset and the segmented results are distributed in an in-memory key-value store for future reuse. The evaluation shows that the segmented in-advance data analytics approach achieves 1.2X-6.1X speedup. The evaluation also shows a good scalability of the in-memory distributed data store. The proposed Segmented In-Advance data analytics approach is a promising data movement reduction solution for scientific big data applications and fast scientific discovery.},
  archive      = {J_TCC},
  author       = {Jialin Liu and Yong Chen},
  doi          = {10.1109/TCC.2016.2541142},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {432-442},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Segmented in-advance data analytics for fast scientific discovery},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Phase-reconfigurable shuffle optimization for hadoop
MapReduce. <em>TCC</em>, <em>8</em>(2), 418–431. (<a
href="https://doi.org/10.1109/TCC.2015.2459707">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hadoop MapReduce is a leading open source framework that supports the realization of the Big Data revolution and serves as a pioneering platform in ultra large amount of information storing and processing. However, tuning a MapReduce system has become a difficult task because a large number of parameters restrict its performance, many of which are related with shuffle, a complicated phase between map and reduce functions, including sorting, grouping, and HTTP transferring. During shuffle phase, a large mount of time is spent on disk I/O due to the low speed of data throughput. In this paper, we build a mathematical model to judge the computing complexity of different operating orders within map-side shuffle, so that a faster execution can be achieved through reconfiguring the order of sorting and grouping. Furthermore, a three-dimensional exploring space of the performance is expanded, with which, some sampled features during shuffle stage, such as key number, spilling file number, and the variances of intermediate results, are collected to support the evaluation of computing complexity of each operating order. Thus, an optimized reconfiguration of map-side shuffle architecture can be achieved within Hadoop without extra disk I/O induced. Comparing with the original Hadoop implementation, the results show that our reconfigurable architecture gains up to 2.37χ speedup to finish the map-side shuffle work.},
  archive      = {J_TCC},
  author       = {Jihe Wang and Meikang Qiu and Bing Guo and Ziliang Zong},
  doi          = {10.1109/TCC.2015.2459707},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {418-431},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Phase-reconfigurable shuffle optimization for hadoop MapReduce},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Microaggregation sorting framework for k-anonymity
statistical disclosure control in cloud computing. <em>TCC</em>,
<em>8</em>(2), 408–417. (<a
href="https://doi.org/10.1109/TCC.2015.2469649">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In cloud computing, there have led to an increase in the capability to store and record personal data (microdata) in the cloud. In most cases, data providers have no/little control that has led to concern that the personal data may be beached. Microaggregation techniques seek to protect microdata in such a way that data can be published and mined without providing any private information that can be linked to specific individuals. An optimal microaggregation method must minimize the information loss resulting from this replacement process. The challenge is how to minimize the information loss during the microaggregation process. This paper presents a sorting framework for Statistical Disclosure Control (SDC) to protect microdata in cloud computing. It consists of two stages. In the first stage, an algorithm sorts all records in a data set in a particular way to ensure that during microaggregation very dissimilar observations are never entered into the same cluster. In the second stage a microaggregation method is used to create k-anonymous clusters while minimizing the information loss. The performance of the proposed techniques is compared against the most recent microaggregation methods. Experimental results using benchmark datasets show that the proposed algorithms perform significantly better than existing associate techniques in the literature.},
  archive      = {J_TCC},
  author       = {Md Enamul Kabir and Abdun Naser Mahmood and Hua Wang and Abdul K. Mustafa},
  doi          = {10.1109/TCC.2015.2469649},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {408-417},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Microaggregation sorting framework for K-anonymity statistical disclosure control in cloud computing},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hybrid consensus pruning of ensemble classifiers for big
data malware detection. <em>TCC</em>, <em>8</em>(2), 398–407. (<a
href="https://doi.org/10.1109/TCC.2015.2481378">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the major challenges for safeguarding the security of big data in the cloud is how to detect and prevent malicious software (malware). Despite of the fact that security and privacy are critical issues in big data, more research needs to be done in this area. As malware can affect the reliability of the data and subsequently the reputation of the system, it is critical to detect and remove malware from a system as early as possible. Recently, ensembles that combine a set of classifiers have been proposed as an efficient approach for malware detection. Unfortunately, the size, meHA85-C0002-A008mory and processing requirements as well as the high cost of data transfer during training and operation make large ensemble classifiers unsuitable for big data in the cloud. To address this problem, we propose a new advanced ensemble pruning method, Hybrid Consensus Pruning (HCP), which is the first pruning algorithm that employs a fast consensus function to combine several classifier classes into one scheme. To test the effectiveness of the HCP method, we conducted experiments comparing its performance with Ensemble Pruning via Individual Contribution ordering (EPIC), Directed Hill Climbing Ensemble Pruning (DHCEP) and K-Means Pruning approaches for pruning very large ensemble classifiers for malware detection. The results of the experiments show that HCP achieved better results by producing better ensemble classifiers as compared to those created by EPIC, DHCEP and K-Means Pruning.},
  archive      = {J_TCC},
  author       = {Jemal H. Abawajy and Morshed Chowdhury and Andrei Kelarev},
  doi          = {10.1109/TCC.2015.2481378},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {398-407},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Hybrid consensus pruning of ensemble classifiers for big data malware detection},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Crowdsourcing based description of urban emergency events
using social media big data. <em>TCC</em>, <em>8</em>(2), 387–397. (<a
href="https://doi.org/10.1109/TCC.2016.2517638">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowdsourcing is a process of acquisition, integration, and analysis of big and heterogeneous data generated by a diversity of sources in urban spaces, such as sensors, devices, vehicles, buildings, and human. Especially, nowadays, no countries, no communities, and no person are immune to urban emergency events. Detection about urban emergency events, e.g., fires, storms, traffic jams is of great importance to protect the security of humans. Recently, social media feeds are rapidly emerging as a novel platform for providing and dissemination of information that is often geographic. The content from social media usually includes references to urban emergency events occurring at, or affecting specific locations. In this paper, in order to detect and describe the real time urban emergency event, the 5W (What, Where, When, Who, and Why) model is proposed. Firstly, users of social media are set as the target of crowd sourcing. Secondly, the spatial and temporal information from the social media are extracted to detect the real time event. Thirdly, a GIS based annotation of the detected urban emergency event is shown. The proposed method is evaluated with extensive case studies based on real urban emergency events. The results show the accuracy and efficiency of the proposed method.},
  archive      = {J_TCC},
  author       = {Zheng Xu and Yunhuai Liu and Neil Y. Yen and Lin Mei and Xiangfeng Luo and Xiao Wei and Chuanping Hu},
  doi          = {10.1109/TCC.2016.2517638},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {387-397},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Crowdsourcing based description of urban emergency events using social media big data},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cross-cloud MapReduce for big data. <em>TCC</em>,
<em>8</em>(2), 375–386. (<a
href="https://doi.org/10.1109/TCC.2015.2474385">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {MapReduce plays a critical role as a leading framework for big data analytics. In this paper, we consider a geo-distributed cloud architecture that provides MapReduce services based on the big data collected from end users all over the world. Existing work handles MapReduce jobs by a traditional computation-centric approach that all input data distributed in multiple clouds are aggregated to a virtual cluster that resides in a single cloud. Its poor efficiency and high cost for big data support motivate us to propose a novel data-centric architecture with three key techniques, namely, cross-cloud virtual cluster, data-centric job placement, and network coding based traffic routing. Our design leads to an optimization framework with the objective of minimizing both computation and transmission cost for running a set of MapReduce jobs in geo-distributed clouds. We further design a parallel algorithm by decomposing the original large-scale problem into several distributively solvable subproblems that are coordinated by a high-level master problem. Finally, we conduct real-world experiments and extensive simulations to show that our proposal significantly outperforms the existing works.},
  archive      = {J_TCC},
  author       = {Peng Li and Song Guo and Shui Yu and Weihua Zhuang},
  doi          = {10.1109/TCC.2015.2474385},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {375-386},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Cross-cloud MapReduce for big data},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An integration framework on cloud for cyber-physical-social
systems big data. <em>TCC</em>, <em>8</em>(2), 363–374. (<a
href="https://doi.org/10.1109/TCC.2015.2511766">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A tremendous challenge in the development of Cyber-Physical-Social Systems (CPSS) is to integrate the growing volume and wide variety of data generated from multiple sources. To address the challenge, this paper presents an integration framework on cloud consisting of five functionally complementary processes, namely data representation, dimensionality reduction, relation establishment, data rank and data retrieval. The unstructured, semi-structured and structured data in the cyber, physical and social space are first represented as low-order data tensors, and then transformed to a three-order feature tensor for relation establishment. A similarity-based multi-linear data rank approach is proposed to measure the importance of the CPSS big data, and an incremental method is explored to rapidly and accurately update the rank vector. This paper, through a smart home case study, illustrates a practical application of the proposed integration framework, and evaluates the performance of the multi-linear data rank approach as well as the incremental rank update method. The results reveal that the proposed framework is feasible and competitive to integrate the CPSS big data on cloud.},
  archive      = {J_TCC},
  author       = {Liwei Kuang and Laurence T. Yang and Yang Liao},
  doi          = {10.1109/TCC.2015.2511766},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {363-374},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {An integration framework on cloud for cyber-physical-social systems big data},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A data and task co-scheduling algorithm for scientific cloud
workflows. <em>TCC</em>, <em>8</em>(2), 349–362. (<a
href="https://doi.org/10.1109/TCC.2015.2511745">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing has emerged as a promising computational infrastructure for cost-efficient workflow execution by provisioning on-demand resources in a pay-as-you-go manner. While scientific workflows require accessing community-wide resources, they usually need to be performed in collaborative cloud environments composed of multiple datacenters. Although such environments facilitate scientific collaboration, the movements of input and intermediate datasets across geographically distributed datacenters may cause intolerable latency that would hinder efficient execution of large-scale data-intensive scientific workflows. To address the problem, in this article we propose a novel multi-level K-cut graph partitioning algorithm to minimize the volume of data transfer across datacenters while satisfying load balancing and fixed data constraints. The algorithm first contracts the fixed input datasets in the same datacenter and their consuming tasks, and coarsens the contracted graph to a predefined scale in a level-by-level manner. Then, a K-cut algorithm is used to partition the resulted graph into K parts such that the cut size is minimized. After that, the partitioned graph is projected back to the original workflow graph, during which the load balancing constraint is maintained. We evaluate our algorithm using three real-world workflow applications and the results demonstrate that the proposed algorithm outperforms other state-of-the-art algorithms.},
  archive      = {J_TCC},
  author       = {Kefeng Deng and Kaijun Ren and Min Zhu and Junqiang Song},
  doi          = {10.1109/TCC.2015.2511745},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {349-362},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {A data and task co-scheduling algorithm for scientific cloud workflows},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A context-aware service evaluation approach over big data
for cloud applications. <em>TCC</em>, <em>8</em>(2), 338–348. (<a
href="https://doi.org/10.1109/TCC.2015.2511764">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing has promoted the success of big data applications such as medical data analyses. With the abundant resources provisioned by cloud platforms, the quality of service (QoS) of services that process big data could be boosted significantly. However, due to unstable network or fake advertisement, the QoS published by service providers is not always trusted. Therefore, it becomes a necessity to evaluate the service quality in a trustable way, based on the services&#39; historical QoS records. However, the evaluation efficiency would be low and cannot meet users&#39; quick response requirement, if all the records of a service are recruited for quality evaluation. Moreover, it may lead to `Lagging Effect&#39; or low evaluation accuracy, if all the records are treated equally, as the invocation contexts of different records are not exactly the same. In view of these challenges, a novel approach named Partial Historical Records-based service evaluation approach (Partial-HR) is put forward in this paper. In Partial-HR, each historical QoS record is weighted based on its service invocation context. Afterwards, only partial important records are employed for quality evaluation. Finally, a group of experiments are deployed to validate the feasibility of our proposal, in terms of evaluation accuracy and efficiency.},
  archive      = {J_TCC},
  author       = {Lianyong Qi and Wanchun Dou and Chunhua Hu and Yuming Zhou and Jiguo Yu},
  doi          = {10.1109/TCC.2015.2511764},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {338-348},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {A context-aware service evaluation approach over big data for cloud applications},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A 3D image quality assessment method based on vector
information and SVD of quaternion matrix under cloud computing
environment. <em>TCC</em>, <em>8</em>(2), 326–337. (<a
href="https://doi.org/10.1109/TCC.2015.2513397">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing demands of end-users to the visual perception in three-dimension (3D) image, quality assessment for 3D imageis dominantly required as the feedback information for multimedia transmission systems. In this paper, a novel full-reference quality assessment method by considering the depth and integral color information of 3D image under cloud computing environment is proposed. Based on the property of the depth information in 3D image, the depth map is firstly separated into different planes according to the perception of human visual system (HVS). Then, after express the image pixels of every separated plane through quaternions, the structural and energy information are separated by quaternion singular value decomposition (QSVD). The distortion of structural and energy in every plane are calculated in various formulas respectively. The final result is calculated in terms of the global score, which synthesizes the structural and energy distortion scores in every individual depth plane. It should be pointed out that the chrominance information is employed in our mechanism to evaluate the color image quality because of its useful characteristic for 3D color image quality assessment, and its spatial correlation is used for calculating structural distortion through vector cross-product. Our experimental results confirm that the proposed method has achieves better performance under cloud computing environments compared with other existing 3D image quality assessment methods.},
  archive      = {J_TCC},
  author       = {Xingang Liu and Lan Zhang and Kaixuan Lu},
  doi          = {10.1109/TCC.2015.2513397},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {326-337},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {A 3D image quality assessment method based on vector information and SVD of quaternion matrix under cloud computing environment},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Editorial: A message from the incoming editor-in-chief.
<em>TCC</em>, <em>8</em>(2), 324–325. (<a
href="https://doi.org/10.1109/TCC.2020.2975868">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Presents the introductory editorial for this issue of the publication.},
  archive      = {J_TCC},
  author       = {YuanYuan Yang},
  doi          = {10.1109/TCC.2020.2975868},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {324-325},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Editorial: A message from the incoming editor-in-chief},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Toward practical privacy-preserving frequent itemset mining
on encrypted cloud data. <em>TCC</em>, <em>8</em>(1), 312–323. (<a
href="https://doi.org/10.1109/TCC.2017.2739146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Frequent itemset mining, which is the essential operation in association rule mining, is one of the most widely used data mining techniques on massive datasets nowadays. With the dramatic increase on the scale of datasets collected and stored with cloud services in recent years, it is promising to carry this computation-intensive mining process in the cloud. Amount of work also transferred the approximate mining computation into the exact computation, where such methods not only improve the accuracy also aim to enhance the efficiency. However, while mining data stored on public clouds, it inevitably introduces privacy concerns on sensitive datasets. In this paper, we propose a new framework for enforcing privacy in frequent itemset mining, where data are both collected and mined in an encrypted form in a public cloud service. We specifically design three secure frequent itemset mining protocols on top of this framework. Our first protocol achieves more efficient mining performance while our second protocol provides a stronger privacy guarantee. In order to further optimize the performance of the second protocol, we leverage a minor trade-off of privacy to get our third protocol. Finally, we evaluate the performance of our protocols with extensive experiments, and the results demonstrate that our protocols obviously outperform previous solutions in performance with the same security level.},
  archive      = {J_TCC},
  author       = {Shuo Qiu and Boyang Wang and Ming Li and Jiqiang Liu and Yanfeng Shi},
  doi          = {10.1109/TCC.2017.2739146},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {312-323},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Toward practical privacy-preserving frequent itemset mining on encrypted cloud data},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). TIMER-cloud: Time-sensitive VM provisioning in
resource-constrained clouds. <em>TCC</em>, <em>8</em>(1), 297–311. (<a
href="https://doi.org/10.1109/TCC.2017.2777992">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Resource management is a vital factor for better performance in cloud systems and many resource allocation algorithms have been studied. In this work, focusing on applications with timing constraints (i.e., deadlines) running on resource-constrained clouds that have multiple heterogeneous nodes of computing resources (e.g., CPU cores and memory), we propose TIMER-Cloud, a time-sensitive resource allocation and virtual machine (VM) provisioning framework. As a key component of the framework, user requests (of running certain applications) are prioritized according to their deadlines and resource demands (in the form of VM and its operation time). Specifically, in addition to the intuitive Earliest Deadline First (EDF) ordering of requests, we propose three prioritization heuristics: a) one based on the Time-Sensitive Resource Factor (TSRF) that incorporates a request&#39;s deadline and usage efficiency of all its resources; b) the Dominant Share (DS) extension of TSRF that emphasizes the most demanded resource of a request aiming at obtaining balanced resource usage among the nodes; and c) a unified k-EDFscheme that integrates the ideas of EDF and TSRF/DS to balance the needs of meeting imminent deadlines of requests and improving resource usage efficiency. Then, for the mapping of the prioritized user requests to the heterogeneous nodes, we propose a novel request-to-node mapping algorithm based on the idea of euclidean Distance that finds the node with the best match of its resource requirements for each request. TIMER-Cloud has been implemented and validated on a cloud testbed powered by OpenStack with a few heterogeneous nodes. The proposed VM provisioning schemes are further evaluated through extensive simulations using the execution data of benchmark applications. The results show that the proposed schemes can outperform the state-of-the-art deadline oblivious scheme by serving up to 12 percent more user requests and achieving up to 8 percent more system rewards for the over-loaded scenario with 140 percent system load.},
  archive      = {J_TCC},
  author       = {Rehana Begam and Wei Wang and Dakai Zhu},
  doi          = {10.1109/TCC.2017.2777992},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {297-311},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {TIMER-cloud: Time-sensitive VM provisioning in resource-constrained clouds},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Scheduling live migration of virtual machines. <em>TCC</em>,
<em>8</em>(1), 282–296. (<a
href="https://doi.org/10.1109/TCC.2017.2754279">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Every day, numerous VMs are migrated inside a datacenter to balance the load, save energy or prepare production servers for maintenance. Although VM placement problems are carefully studied, the underlying migration schedulers rely on vague adhoc models. This leads to unnecessarily long and energy-intensive migrations. We present mVM, a new and extensible migration scheduler. To provide schedules with minimal completion times, mVM parallelizes and sequentializes the migrations with regards to the memory workload and the network topology. mVM is implemented as a plugin of BtrPlace and its current library allows administrators to address temporal and energy concerns. Experiments on a real testbed shows mVM outperforms state-of-the-art migration schedulers. Compared to schedulers that cap the migration parallelism, mVM reduces the individual migration duration by 20.4 percent on average and the schedule completion time by 28.1 percent. In a maintenance operation involving 96 VMs migrated between 72 servers, mVM saves 21.5 percent Joules against BtrPlace. Compared to the migration model inside the cloud simulator CloudSim, the prediction error of the migrations duration is about 5 times lower with mVM. By computing schedules involving thousands of migrations performed over various fat-tree network topologies, we observed that the mVM solving time accounts for about 1 percent of the schedule execution time.},
  archive      = {J_TCC},
  author       = {Vincent Kherbache and Éric Madelaine and Fabien Hermenier},
  doi          = {10.1109/TCC.2017.2754279},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {282-296},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Scheduling live migration of virtual machines},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Providing performance guarantees for cloud-deployed
applications. <em>TCC</em>, <em>8</em>(1), 269–281. (<a
href="https://doi.org/10.1109/TCC.2017.2771402">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applications with a dynamic workload demand need access to a flexible infrastructure to meet performance guarantees and minimize resource costs. While cloud computing provides the elasticity to scale the infrastructure on demand, cloud service providers lack control and visibility of user space applications, making it difficult to accurately scale the infrastructure. Thus, the burden of scaling falls on the user. That is, the user must determine when to trigger scaling and how much to scale. Scaling becomes even more challenging when applications exhibit dynamic changes in their behavior. In this paper, we propose a new cloud service, Dependable Compute Cloud (DC2), that automatically scales the infrastructure to meet the user-specified performance requirements, even when multiple user requests execute concurrently. DC2 employs Kalman filtering to automatically learn the (possibly changing) system parameters for each application, allowing it to proactively scale the infrastructure to meet performance guarantees. Importantly, DC2 is designed for the cloud - it is application-agnostic and does not require any offline application profiling or benchmarking, training data, or expert knowledge about the application. We evaluate DC2 via implementation on OpenStack using a multi-tier application under a range of workload mixes and arrival traces. Our experimental results demonstrate the robustness and superiority of DC2 over existing rule-based approaches with respect to avoiding SLA violations and minimizing resource consumption.},
  archive      = {J_TCC},
  author       = {Anshul Gandhi and Parijat Dube and Alexei Karve and Andrzej Kochut and Li Zhang},
  doi          = {10.1109/TCC.2017.2771402},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {269-281},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Providing performance guarantees for cloud-deployed applications},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Predicting workflow task execution time in the cloud using a
two-stage machine learning approach. <em>TCC</em>, <em>8</em>(1),
256–268. (<a href="https://doi.org/10.1109/TCC.2017.2732344">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many techniques such as scheduling and resource provisioning rely on performance prediction of workflow tasks for varying input data. However, such estimates are difficult to generate in the cloud. This paper introduces a novel two-stage machine learning approach for predicting workflow task execution times for varying input data in the cloud. In order to achieve high accuracy predictions, our approach relies on parameters reflecting runtime information and two stages of predictions. Empirical results for four real world workflow applications and several commercial cloud providers demonstrate that our approach outperforms existing prediction methods. In our experiments, our approach respectively achieves a best-case and worst-case estimation error of 1.6 and 12.2 percent, while existing methods achieved errors beyond 20 percent (for some cases even over 50 percent) in more than 75 percent of the evaluated workflow tasks. In addition, we show that the models predicted by our approach for a specific cloud can be ported with low effort to new clouds with low errors by requiring only a small number of executions.},
  archive      = {J_TCC},
  author       = {Thanh-Phuong Pham and Juan J. Durillo and Thomas Fahringer},
  doi          = {10.1109/TCC.2017.2732344},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {256-268},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Predicting workflow task execution time in the cloud using a two-stage machine learning approach},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Predicted affinity based virtual machine placement in cloud
computing environments. <em>TCC</em>, <em>8</em>(1), 246–255. (<a
href="https://doi.org/10.1109/TCC.2017.2737624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In cloud data centers, an appropriate Virtual Machine (VM) placement has become an effective method to improve the resource utilization and reduce the energy consumption. However, most current solutions regard the VM placement as a bin-packing problem and each VM is seen as a single object. None of them have taken the relationships between VMs into consideration, which supplies us with a kind of new perspective. In this paper, we provide a model which explores the relationships for every two VMs based on the resource requirement provided by ARIMA prediction. This model evaluates the volatility of resource utilization after putting the two VMs on the same host and we call this model as affinity model. Based on the affinity model, VMs will be placed on those hosts that have the highest affinity with them. Therefore, we call it as Predicted Affinity based Virtual Machine Placement Algorithm (PAVMP). The advantages of PAVMP are showed by comparing it with other VM placement algorithms on CloudSim simulation platform with the PlanetLab and Google workload trace.},
  archive      = {J_TCC},
  author       = {Xiong Fu and Chen Zhou},
  doi          = {10.1109/TCC.2017.2737624},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {246-255},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Predicted affinity based virtual machine placement in cloud computing environments},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimizing timeliness and cost in geo-distributed streaming
analytics. <em>TCC</em>, <em>8</em>(1), 232–245. (<a
href="https://doi.org/10.1109/TCC.2017.2750678">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rapid data streams are generated continuously from diverse sources including users, devices, and sensors located around the globe. This results in the need for efficient geo-distributed streaming analytics to extract timely information. A typical geo-distributed analytics service uses a hub-and-spoke model, comprising multiple edges connected by a wide-area-network (WAN) to a central data warehouse. In this paper, we focus on the widely used primitive of windowed grouped aggregation, and examine the question of how much computation should be performed at the edges versus the center. We develop algorithms to optimize two key metrics: WAN traffic and staleness(delay in getting results). We present a family of optimal offline algorithms that jointly minimize these metrics, and we use these to guide our design of practical online algorithms based on the insight that windowed grouped aggregation can be modeled as a caching problem where the cache size varies overtime. We evaluate our algorithms through an implementation in Apache Storm deployed on PlanetLab. Using workloads derived from anonymized traces of a popular analytics service from a large commercial CDN, our experiments show that our online algorithms achieve near-optimal traffic and staleness for a variety of system configurations, stream arrival rates, and queries.},
  archive      = {J_TCC},
  author       = {Benjamin Heintz and Abhishek Chandra and Ramesh K. Sitaraman},
  doi          = {10.1109/TCC.2017.2750678},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {232-245},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Optimizing timeliness and cost in geo-distributed streaming analytics},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). ODDS: Optimizing data-locality access for scientific data
analysis. <em>TCC</em>, <em>8</em>(1), 220–231. (<a
href="https://doi.org/10.1109/TCC.2017.2754484">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Whereas traditional scientific applications are computationally intensive, recent applications require more data-intensive analysis and visualization to extract knowledge from the explosive growth of scientific information and simulation data. As the computational power and size of compute clusters continue to increase, the I/O read rates and associated network for these data-intensive applications have been unable to keep pace. These applications suffer from long I/O latency due to the movement of “big data” from the network/parallel file system, which results in a serious performance bottleneck. To address this problem, we proposed a novel approach called “ODDS” to optimize data-locality access in scientific data analysis and visualization. ODDS leverages a distributed file system (DFS) to provide scalable data access for scientific analysis. Through exploiting the information of underlying data distribution in DFS, ODDS employs a novel data-locality scheduler to transform a compute-centric mapping into a data-centric one and enables each computational process to access the needed data from a local or nearby storage node. ODDS is suitable for parallel applications with dynamic process-to-data scheduling and for applications with static process-to-data assignment. To demonstrate the efficacy of our methods, we present and evaluate ODDS in the context of two state-of-the-art, scientific-analysis applications-mpiBLAST and ParaView-along with the Hadoop distributed file system (HDFS) across a wide variety of computing platform settings. In comparison to existing deployments using NFS, PVFS, or Lustre as the underlying storage systems, ODDS can greatly reduce the I/O cost and double overall performance.},
  archive      = {J_TCC},
  author       = {Jun Wang and Dezhi Han and Jiangling Yin and Xiaobo Zhou and ChangJun Jiang},
  doi          = {10.1109/TCC.2017.2754484},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {220-231},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {ODDS: Optimizing data-locality access for scientific data analysis},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). How to extract image features based on co-occurrence matrix
securely and efficiently in cloud computing. <em>TCC</em>,
<em>8</em>(1), 207–219. (<a
href="https://doi.org/10.1109/TCC.2017.2737980">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional feature extraction based on co-occurrence matrix improves the detection performance of steganalysis, but it is difficult to be realized for massive image data by an analyzer with limited computational ability. We solve this problem by verifiable outsourcing computation, which allows a computationally weak client to outsource the evaluation of a function to a powerful but untrusted server. In this paper, we propose a verifiable outsourcing scheme of feature extraction based on co-occurrence matrix with single untrusted cloud server. The original images are protected from the server by using a projection of one to many with trapdoor, which can be realized by a symmetric probabilistic encryption scheme we present. The analyzer can obtain true results of feature extraction and detect any failure with a probability of 1 if the server misbehaves. Finally, we provide the simulations on the outsourcing of extracting ccJRM features in cloud computing. The theory analysis and experiment result also show that the proposed outsourcing scheme could greatly decrease the computation cost of the analyzer without exposure of the original images and extraction results.},
  archive      = {J_TCC},
  author       = {Yanli Ren and Xinpeng Zhang and Guorui Feng and Zhenxing Qian and Fengyong Li},
  doi          = {10.1109/TCC.2017.2737980},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {207-219},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {How to extract image features based on co-occurrence matrix securely and efficiently in cloud computing},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Heterogeneous job allocation scheduler for hadoop MapReduce
using dynamic grouping integrated neighboring search. <em>TCC</em>,
<em>8</em>(1), 193–206. (<a
href="https://doi.org/10.1109/TCC.2017.2748586">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {MapReduce is a crucial framework in the cloud computing architecture, and is implemented by Apache Hadoop and other cloud computing platforms. The resources required for executing jobs in a large data center vary according to the job types. In general, there are two types of jobs, CPU-bound and I/O-bound, which require different resources but run simultaneously in the same cluster. The default job scheduling policy of Hadoop is first-come-first-served and therefore, may cause unbalanced resource utilization. Considering various job workloads, numerous job allocation schedulers were proposed in the literature. However, those schedulers encountered the data locality problem or unreasonable job execution performance. This study proposes a job scheduler based on a dynamic grouping integrated neighboring search strategy, which can balance the resource utilization and improve the performance and data locality in heterogeneous computing environments.},
  archive      = {J_TCC},
  author       = {Chi-Ting Chen and Ling-Ju Hung and Sun-Yuan Hsieh and Rajkumar Buyya and Albert Y. Zomaya},
  doi          = {10.1109/TCC.2017.2748586},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {193-206},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Heterogeneous job allocation scheduler for hadoop MapReduce using dynamic grouping integrated neighboring search},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Green cloudlet network: A sustainable platform for mobile
cloud computing. <em>TCC</em>, <em>8</em>(1), 180–192. (<a
href="https://doi.org/10.1109/TCC.2017.2764463">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Green Cloudlet Network (GCN) architecture, each User Equipment (UE) is associated with an Avatar (a private virtual machine for executing its UE&#39;s offloaded tasks) in a cloudlet located at the network edge. In order to reduce the operational expenditure for maintaining the distributed cloudlets, each cloudlet is powered by green energy and uses on-grid power as a backup. Owing to the spatial dynamics of energy demands and green energy generations, the energy gap (i.e., energy demand minus green energy generation) among different cloudlets in the network is unbalanced, i.e., some cloudlets&#39; energy demands can be fully provisioned by their green energy generations but others need to utilize on-grid power to meet their energy demands. The unbalanced energy gap increases the on-grid power consumption of the cloudlets. In this paper, we propose the Green-energy aware Avatar Placement (GAP) strategy to minimize the total on-grid power consumption of the cloudlets by migrating Avatars among the cloudlets according to the cloudlets&#39; residual green energy, while guaranteeing the service level agreement (the End-to-End (E2E) delay requirement between a UE and its Avatar). Simulation results show that GAP can save 57.1 and 57.6 percent of on-grid power consumption as compared to the two other Avatar placement strategies, i.e., Static Avatar Placement and Follow me AvataR, respectively.},
  archive      = {J_TCC},
  author       = {Xiang Sun and Nirwan Ansari},
  doi          = {10.1109/TCC.2017.2764463},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {180-192},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Green cloudlet network: A sustainable platform for mobile cloud computing},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Google users as sequences: A robust hierarchical cluster
analysis study. <em>TCC</em>, <em>8</em>(1), 167–179. (<a
href="https://doi.org/10.1109/TCC.2017.2766227">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this era of cloud computing, users encounter the challenging task of effectively composing and running their applications on the cloud. By understanding user behavior in constructing applications and interacting with typical cloud infrastructures, cloud managers can develop better systems that improve the users&#39; experience. In this paper, we analyze a large dataset of a Google cluster to characterize the users into distinct groups of similar usage behavior. We used a wide range of measured metrics to model user behavior in composing applications from the perspective of actions around application architecting, capacity planning, and workload type planning and to model user interaction behavior around the session view. The trajectories of users&#39; actions are represented as sequences using categorical and proportional encoding schemes. We used techniques from the sequence analysis paradigm to quantify dissimilarity among users. We employed a robust cluster analysis procedure based on the agglomerative hierarchical methods to optimally classify users into 12 classes. We used a variety of formal indices and visual aids to confirm the quality and stability of the outcomes. By visual inspection, we regrouped the obtained clusters into 5 main groups that reveal interesting insights about the characteristics which underline different groups&#39; utilization behavior.},
  archive      = {J_TCC},
  author       = {Omar Arif Abdul-Rahman and Kento Aida},
  doi          = {10.1109/TCC.2017.2766227},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {167-179},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Google users as sequences: A robust hierarchical cluster analysis study},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fair online power capping for emergency handling in
multi-tenant cloud data centers. <em>TCC</em>, <em>8</em>(1), 152–166.
(<a href="https://doi.org/10.1109/TCC.2017.2762311">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In view of the high capital expense for scaling up power capacity to meet the escalating demand, maximizing the utilization of built capacity has become a top priority for multi-tenant data center operators, where many cloud providers house their physical servers. The traditional power provisioning guarantees a high availability, but is very costly and results in a significant capacity under-utilization. On the other hand, power oversubscription (i.e., deploying more servers than what the capacity allows) improves utilization but offers no availability guarantees due to the necessity of power reduction to handle the resulting power emergencies. Given these limitations, we propose a novel hybrid power provisioning approach, called HyPP, which provides a combination of two different power availabilities to tenants: capacity with a very high availability (100 percent or nearly 100 percent), plus additional capacity with a medium availability that may be unavailable for up to a certain amount during each billing period. For HyPP, we design an online algorithm for the operator to coordinate tenants&#39; power reduction at runtime when the tenants&#39; aggregate power demand exceeds the power capacities. Our algorithm aims at achieving long-term fairness in tenants&#39; power reduction (defined as the ratio of total actual power reduction by a tenant to its contracted reduction budget over a billing period). We analyze the theoretical performance of our online algorithm and derive a good competitive ratio in terms of fairness compared to the offline optimum. We also validate our algorithm through simulations under realistic settings.},
  archive      = {J_TCC},
  author       = {Qihang Sun and Shaolei Ren and Chuan Wu},
  doi          = {10.1109/TCC.2017.2762311},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {152-166},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Fair online power capping for emergency handling in multi-tenant cloud data centers},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient proofs of retrievability with public verifiability
for dynamic cloud storage. <em>TCC</em>, <em>8</em>(1), 138–151. (<a
href="https://doi.org/10.1109/TCC.2017.2767584">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud service providers offer various facilities to their clients. The clients with limited resources opt for some of these facilities. They can outsource their bulk data to the cloud server. The cloud server maintains these data in lieu of monetary benefits. However, a malicious cloud server might delete some of these data to save some space and offer this extra amount of storage to another client. Therefore, the client might not retrieve her file (or some portions of it) as often as needed. Proofs of retrievability (POR) provide an assurance to the client that the server is actually storing all of her data appropriately and they can be retrieved at any point of time. In a dynamic POR scheme, the client can update her data after she uploads them to the cloud server. Moreover, in publicly verifiable POR schemes, the client can delegate her auditing task to some third party specialized for this purpose. In this work, we exploit the homomorphic hashing technique to design a publicly verifiable dynamic POR scheme that is more efficient (in terms of bandwidth required between the client and the server) than the “state-of-the-art” publicly verifiable dynamic POR scheme. We also analyze security and performance of our scheme.},
  archive      = {J_TCC},
  author       = {Binanda Sengupta and Sushmita Ruj},
  doi          = {10.1109/TCC.2017.2767584},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {138-151},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Efficient proofs of retrievability with public verifiability for dynamic cloud storage},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient decentralized attribute based access control for
mobile clouds. <em>TCC</em>, <em>8</em>(1), 124–137. (<a
href="https://doi.org/10.1109/TCC.2017.2754255">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine grained access control is a requirement for data stored in untrusted servers like clouds. Owing to the large volume of data, decentralized key management schemes are preferred over centralized ones. Often encryption and decryption are quite expensive and not practical when users access data from resource constrained devices. We propose a decentralized attribute based encryption (ABE) scheme with fast encryption, outsourced decryption and user revocation. Our scheme is very specific to the context of mobile cloud as the storage of encrypted data and the partial decryption of ciphertexts are dependent on the cloud and users with mobile devices can upload data to the cloud or access data from it by incurring very little cost for encryption and decryption respectively. The main idea is to divide the encryption into two phases, offline preprocessing phase which is done when the device is otherwise not in use and an online phase when the data is actually encrypted with the policy. This makes encryption faster and more efficient than existing decentralized ABE schemes. For decryption outsourcing, data users need to generate a transformed version of the decryption key allowing an untrusted proxy server to partially decrypt the ciphertext without gaining any information about the plaintext. Data users can then fully decrypt the partially decrypted ciphertext without performing any costly pairing operations. We also introduce user revocation in this scheme without incurring too much additional cost in the online phase. Comparison with other ABE schemes shows that our scheme significantly reduces computation times for both data owners and data users and highly suitable for use in mobile devices.},
  archive      = {J_TCC},
  author       = {Sourya Joyee De and Sushmita Ruj},
  doi          = {10.1109/TCC.2017.2754255},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {124-137},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Efficient decentralized attribute based access control for mobile clouds},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Disaster recovery layer for distributed OpenStack
deployments. <em>TCC</em>, <em>8</em>(1), 112–123. (<a
href="https://doi.org/10.1109/TCC.2017.2745560">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present the Disaster Recovery Layer (DRL) that enables OpenStack-managed datacenter workloads, Virtual Machines (VMs) and Volumes, to be protected and recovered in another datacenter, in case of a disaster. This work has been carried out in the context of the EU FP7 ORBIT project that develops technologies for enabling business continuity as a service. The DRL framework is based on a number of autonomous components and extensions of OpenStack modules, while its functionalities are available through OpenStack&#39;s Horizon UI and command line interface. Also, the DRL&#39;s architecture is extensible, allowing for the easy and dynamic integration of protection, restoration and orchestration plug-ins that adopt new approaches. A distributed disaster detection mechanism was also developed for identifying datacenter disasters and alerting the DRL. For the evaluation of the DRL, a two (active and backup) datacenters testbed has been setup in respective sites in Umea and Lulea, 265km apart and connected through the Swedish national research and education network. In case of a disaster, traffic is redirected between the datacenters utilizing the BGP anycast scheme. The experiments performed, show that DRL can efficiently protect VMs and Volumes, with minimum service disruption in case of failures and low overhead, even when the available bandwidth is limited.},
  archive      = {J_TCC},
  author       = {Luis Tomás and Panagiotis Kokkinos and Vasilis Anagnostopoulos and Oshrit Feder and Dimosthenis Kyriazis and Kalman Meth and Emmanouel Varvarigos and Theodora Varvarigou},
  doi          = {10.1109/TCC.2017.2745560},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {112-123},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Disaster recovery layer for distributed OpenStack deployments},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Design and implementation of an overlay file system for
cloud-assisted mobile apps. <em>TCC</em>, <em>8</em>(1), 97–111. (<a
href="https://doi.org/10.1109/TCC.2017.2763158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With cloud assistance, mobile apps can offload their resource-demanding computation tasks to the cloud. This leads to a scenario where computation tasks in the same program run concurrently on both the mobile device and the cloud. An important challenge is to ensure that the tasks are able to access and share the files on both the mobile and the cloud in a manner that is efficient, consistent, and transparent to locations. Existing distributed file systems and network file systems do not satisfy these requirements. Current systems for offloading tasks either do not support file access for offloaded tasks or do not offload tasks with file access. The paper addresses this issue by designing and implementing an application-level file system called Overlay File System (OFS). To improve efficiency, OFS maintains and buffers local copies of data sets on both the cloud and the mobile device. OFS ensures consistency and guarantees that all the reads get the latest data. It combines write-invalidate and write-update policies to effectively reduce the network traffic incurred by invalidating/updating stale data copies and to reduce the execution delay when the latest data cannot be accessed locally. To guarantee location transparency, OFS creates a unified view of the data that is location independent and is accessible as local storage. We overcome the challenges caused by the special features of mobile systems on an application-level file system, like the lack of root privilege and state loss when application is killed due to the shortage of resource and implement an easy to deploy prototype of OFS. The paper tests the OFS prototype on Android OS with a real mobile app and real mobile user traces. Extensive experiments show that OFS can effectively support consistent file accesses from computation tasks, no matter whether they are on a mobile device or offloaded to the cloud. In addition, OFS reduce both file access latency and network traffic incurred by file accesses.},
  archive      = {J_TCC},
  author       = {Nafize Rabbani Paiker and Jianchen Shan and Cristian Borcea and Narain Gehani and Reza Curtmola and Xiaoning Ding},
  doi          = {10.1109/TCC.2017.2763158},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {97-111},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Design and implementation of an overlay file system for cloud-assisted mobile apps},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Delay-sensitive multicast in inter-datacenter WAN using
compressive latency monitoring. <em>TCC</em>, <em>8</em>(1), 86–96. (<a
href="https://doi.org/10.1109/TCC.2017.2769080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multicast routing in inter-datacenter wide area networks is to compute a multicast tree from a source datacenter to multiple destination datacenters. Software-defined networking enables optimal delay-sensitive routing for multicast sessions in inter-datacenter WANs. Delay-sensitive routing requires the controller to obtain the up-to-date latency of every link. However, the communication overhead and time for collecting the latency information of all links can be prohibitively high for the controller to perform real-time scheduling in a WAN. Inspired by the sparsity of link load information in WANs, we propose compressive latency monitoring, a real-time method for collecting a near-accurate latency information of all links. The controller only needs to collect the latency information of a small subset of significant links and then estimates the latency information of insignificant links. We use real-world network topologies to simulate multicast routing both under the compressive latency monitoring and global latency monitoring. Simulation results show that the compressive latency monitoring can achieve nearly good network throughput performance as the global monitoring with much less communication overhead and in a more timely fashion.},
  archive      = {J_TCC},
  author       = {Tracy Yingying Cheng and Xiaohua Jia},
  doi          = {10.1109/TCC.2017.2769080},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {86-96},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Delay-sensitive multicast in inter-datacenter WAN using compressive latency monitoring},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bulk savings for bulk transfers: Minimizing the energy-cost
for geo-distributed data centers. <em>TCC</em>, <em>8</em>(1), 73–85.
(<a href="https://doi.org/10.1109/TCC.2017.2739160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the fast proliferation of cloud computing, major cloud service providers, e.g., Amazon, Google, Facebook, etc., have been deploying more and more geographically distributed data centers to provide customers with better reliability and quality of services. A basic demand in such a geo-distributed data center system is to transfer bulk volumes of data from one data center to another. Geographic distribution and large delay-tolerance of such inter-data-center bulk data transfers provide cloud service providers opportunities to optimize the operating cost. Most existing studies on inter-data-center bulk data transfers focus on minimizing the network bandwidth cost. However, the energy-cost of the bulk data transfers, which also accounts for a large proportion of operating cost in the data centers, still remains unexplored. This is an important problem, especially in the multi-electricity-market environment, where the electricity price exhibits both spatial and temporal diversities. In this paper, we systematically study the problem of how to route and schedule inter-data-center bulk data transfers to minimize the energy-cost for geo-distributed data centers. We model this problem as a min-cost multi-commodity flow problem and develop an efficient two-stage optimization method to solve it. Extensive evaluations with real-life inter-data-center network and electricity prices show that our method brings significant energy-cost savings over existing bulk data transfer methods.},
  archive      = {J_TCC},
  author       = {Xingjian Lu and Fanxin Kong and Xue Liu and Jianwei Yin and Qiao Xiang and Huiqun Yu},
  doi          = {10.1109/TCC.2017.2739160},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {73-85},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Bulk savings for bulk transfers: Minimizing the energy-cost for geo-distributed data centers},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Amazon EC2 spot price prediction using regression random
forests. <em>TCC</em>, <em>8</em>(1), 59–72. (<a
href="https://doi.org/10.1109/TCC.2017.2780159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spot instances were introduced by Amazon EC2 in December 2009 to sell its spare capacity through auction based market mechanism. Despite its extremely low prices, cloud spot market has low utilization. Spot pricing being dynamic, spot instances are prone to out-of bid failure. Bidding complexity is another reason why users today still fear using spot instances. This work aims to present Regression Random Forests (RRFs) model to predict one-week-ahead and one-day-ahead spot prices. The prediction would assist cloud users to plan in advance when to acquire spot instances, estimate execution costs, and also assist them in bid decision making to minimize execution costs and out-of-bid failure probability. Simulations with 12 months real Amazon EC2 spot history traces to forecast future spot prices show the effectiveness of the proposed technique. Comparison of RRFs based spot price forecasts with existing non-parametric machine learning models reveal that RRFs based forecast accuracy outperforms other models. We measure predictive accuracy using MAPE, MCPE, OOB Error and speed. Evaluation results show that MAPE &lt;; = 10\% for 66 to 92 percent and MCPE &lt;; = 15\% for 35 to 81 percent of one-day-ahead predictions with prediction time less than one second. MAPE &lt;; = 15\% for 71 to 96 percent of one-week-ahead predictions.},
  archive      = {J_TCC},
  author       = {Veena Khandelwal and Anand Kishore Chaturvedi and Chandra Prakash Gupta},
  doi          = {10.1109/TCC.2017.2780159},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {59-72},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Amazon EC2 spot price prediction using regression random forests},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Achieving multi-hop PRE via branching program. <em>TCC</em>,
<em>8</em>(1), 45–58. (<a
href="https://doi.org/10.1109/TCC.2017.2764082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Proxy re-encryption (PRE) is a fundamental cryptographic primitive in secure data sharing and e-mail forwarding, etc. To our knowledge, most existing efficient lattice-based PRE schemes focus on the construction of single-hop, key-private, multi-bit and chosen-ciphertext attack (CCA), etc. Few works of literature discussed the detailed multi-hop construction over lattices. Very recently, Chandran et al. (PKC&#39;14) proposed a lattice-based PRE scheme that builds upon the key switching mechanism of Brakerski (CRYPTO&#39;12), and pointed out that their scheme can achieve multi-hop PRE scheme by the ideal circuit family for a directed graph G. In this paper, we are still working along this line and achieving multi-hop PRE via the branching program (BP), which is one type of NC1 circuit and can be used to compute encrypted data. To our knowledge, we proposed the first multi-hop PRE scheme via BP which supports homomorphic evaluation. We also analyze the security of our scheme under decisional learning with errors (LWE) assumption.},
  archive      = {J_TCC},
  author       = {Zengpeng Li and Chunguang Ma and Ding Wang},
  doi          = {10.1109/TCC.2017.2764082},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {45-58},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Achieving multi-hop PRE via branching program},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A scalable attribute-based access control scheme with
flexible delegation cum sharing of access privileges for cloud storage.
<em>TCC</em>, <em>8</em>(1), 32–44. (<a
href="https://doi.org/10.1109/TCC.2017.2751471">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays cloud servers have become the primary choice to store and share data with multiple users across the globe. The major challenge in sharing data using cloud servers is to protect data against untrusted cloud service provider and illegitimate users. Attribute-Based Encryption (ABE) has emerged as a useful cryptographic technique to securely share data with legitimate recipients in fine-grained manner. Several solutions employing ABE have been proposed to securely share data using cloud servers. However, most of the solutions are data owner-centric and focus on providing data owner complete control on his outsourced data. The existing solutions in cloud computing fail to provide shared access privileges among users and to enable cloud users to delegate their access privileges in a flexible manner. In order to simultaneously achieve the notion of fine-grained access control, scalability and to provide cloud users shared access privileges and flexibility on delegation of their access privileges, we propose a scalable attribute-based access control scheme for cloud storage. The scheme extends the ciphertext policy attribute-based encryption to achieve flexible delegation of access privileges and shared access privileges along with scalability and fine-grained access control. The scheme achieves scalability by employing hierarchical structure of users. Furthermore, we formally prove the security of our proposed scheme based on security of the ciphertext-policy attribute-based encryption. We also implement the algorithm to show its scalability and efficiency.},
  archive      = {J_TCC},
  author       = {Rohit Ahuja and Sraban Kumar Mohanty},
  doi          = {10.1109/TCC.2017.2751471},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {32-44},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {A scalable attribute-based access control scheme with flexible delegation cum sharing of access privileges for cloud storage},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A resource usage intensity aware load balancing method for
virtual machine migration in cloud datacenters. <em>TCC</em>,
<em>8</em>(1), 17–31. (<a
href="https://doi.org/10.1109/TCC.2017.2737628">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To provide robust infrastructure as a service (IaaS), clouds currently perform load balancing by migrating virtual machines (VMs) from heavily loaded physical machines (PMs) to lightly loaded PMs. The unique features of clouds pose formidable challenges to achieving effective and efficient load balancing. First, VMs in clouds use different resources (e.g., CPU, bandwidth, memory) to serve a variety of services (e.g., high performance computing, web services, file services), resulting in different over utilized resources in different PMs. Also, the over utilized resources in a PM may vary over time due to the time-varying heterogeneous service requests. Second, there is intensive network communication between VMs. However, previous load balancing methods statically assign equal or predefined weights to different resources, which lead to degraded performance in terms of speed and cost to achieve load balance. Also, they do not strive to minimize the VM communications between PMs. We propose a Resource Intensity Aware Load balancing method (RIAL). For each PM, RIAL dynamically assigns different weights to different resources according to their usage intensity in the PM, which significantly reduces the time and cost to achieve load balance and avoids future load imbalance. It also tries to keep frequently communicating VMs in the same PM to reduce bandwidth cost, and migrates VMs to PMs with minimum VM performance degradation. We also propose an extended version of RIAL with three additional algorithms. First, it optimally determines the weights for considering communication cost and performance degradation due to VM migrations. Second, it has a more strict migration triggering algorithm to avoid unnecessary migrations while still satisfying Service Level Objects (SLOs). Third, it conducts destination PM selection in a decentralized manner to improve scalability. Our extensive trace-driven simulation results and real-world experimental results show the superior performance of RIAL compared to other load balancing methods.},
  archive      = {J_TCC},
  author       = {Haiying Shen and Liuhua Chen},
  doi          = {10.1109/TCC.2017.2737628},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {17-31},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {A resource usage intensity aware load balancing method for virtual machine migration in cloud datacenters},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A carbon-aware incentive mechanism for greening colocation
data centers. <em>TCC</em>, <em>8</em>(1), 4–16. (<a
href="https://doi.org/10.1109/TCC.2017.2767043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The massive energy consumption of data centers worldwide has resulted in a large carbon footprint, raising serious concerns to sustainable IT initiatives and attracting a great amount of research attention. Nonetheless, the current efforts to date, despite encouraging, have been primarily centered around owner-operated data centers (e.g., Google data center), leaving out another major segment of data center industry-colocation data centers-much less explored. As a major hindrance to carbon efficiency desired by the operator, colocation suffers from “split incentive”: tenants may not be willing to manage their servers for carbon efficiency. In this paper, we aim at minimizing the carbon footprint of geo-distributed colocation data centers, while ensuring that the operator&#39;s cost meets a long-term budget constraint. We overcome the “split incentive” hurdle by devising a novel online carbon-aware incentive mechanism, called GreenColo, in which tenants voluntarily bid for energy reduction at self-determined prices and will receive financial rewards if their bids are accepted at runtime. Using trace based simulation we show that GreenColo results in a carbon footprint fairly close (23 versus 18 percent) to the optimal offline solution with future information, while being able to satisfy the colocation operator&#39;s long-term budget constraint. We demonstrate the effectiveness of GreenColo in practical scenarios via both simulation studies and scaled-down prototype experiments. Our results show that GreenColo can reduce the carbon footprint by up to 24 percent without incurring any additional cost for the colocation operator (compared to the no-incentive baseline case), while tenants receive financial rewards for “free” without violating service level agreement.},
  archive      = {J_TCC},
  author       = {Mohammad A. Islam and Hasan Mahmud and Shaolei Ren and Xiaorui Wang},
  doi          = {10.1109/TCC.2017.2767043},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {4-16},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {A carbon-aware incentive mechanism for greening colocation data centers},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Farewell editorial. <em>TCC</em>, <em>8</em>(1), 1–3. (<a
href="https://doi.org/10.1109/TCC.2020.2966754">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Presents the farewell editorial from the editor for this issue of the publication.},
  archive      = {J_TCC},
  author       = {Hui Lei},
  doi          = {10.1109/TCC.2020.2966754},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {1-3},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Farewell editorial},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
