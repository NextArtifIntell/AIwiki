<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TEVC_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tevc---96">TEVC - 96</h2>
<ul>
<li><details>
<summary>
(2020a). IEEE transactions on evolutionary computation society
information. <em>TEVC</em>, <em>24</em>(6), C3. (<a
href="https://doi.org/10.1109/TEVC.2020.3035223">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Presents a listing of the editorial board, board of governors, current staff, committee members, and/or society editors for this issue of the publication.},
  archive      = {J_TEVC},
  doi          = {10.1109/TEVC.2020.3035223},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {C3},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {IEEE transactions on evolutionary computation society information},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Introducing IEEE collabratec. <em>TEVC</em>,
<em>24</em>(6), 1179. (<a
href="https://doi.org/10.1109/TEVC.2020.3036177">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advertisement, IEEE. IEEE Collabratec is a new, integrated online community where IEEE members, researchers, authors, and technology professionals with similar fields of interest can network and collaborate, as well as create and manage content. Featuring a suite of powerful online networking and collaboration tools, IEEE Collabratec allows you to connect according to geographic location, technical interests, or career pursuits. You can also create and share a professional identity that showcases key accomplishments and participate in groups focused around mutual interests, actively learning from and contributing to knowledgeable communities. All in one place! Learn about IEEE Collabratec at ieeecollabratec.org.},
  archive      = {J_TEVC},
  doi          = {10.1109/TEVC.2020.3036177},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1179},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Introducing IEEE collabratec},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Characterizing genetic programming error through extended
bias and variance decomposition. <em>TEVC</em>, <em>24</em>(6),
1164–1176. (<a href="https://doi.org/10.1109/TEVC.2020.2990626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An error function can be used to select between candidate models but it does not provide a thorough understanding of the behavior of a model. A greater understanding of an algorithm can be obtained by performing a bias-variance decomposition. Splitting the error into bias and variance is effective for understanding a deterministic algorithm such as k-nearest neighbor, which provides the same predictions when performed multiple times using the same data. However, simply splitting the error into bias and variance is not sufficient for nondeterministic algorithms, such as genetic programming (GP), which potentially produces a different model each time it is run, even when using the same data. This article presents an extended bias-variance decomposition that decomposes error into bias, external variance (error attributable to limited sampling of the problem), and internal variance (error due to random actions performed in the algorithm itself). This decomposition is applied to GP to expose the three components of error, providing a unique insight into the role of maximum tree depth, number of generations, size/complexity of function set, and data standardization in influencing predictive performance. The proposed tool can be used to inform targeted improvements for reducing specific components of model error.},
  archive      = {J_TEVC},
  author       = {Caitlin A. Owen and Grant Dick and Peter A. Whigham},
  doi          = {10.1109/TEVC.2020.2990626},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1164-1176},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Characterizing genetic programming error through extended bias and variance decomposition},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A framework for scalable bilevel optimization: Identifying
and utilizing the interactions between upper-level and lower-level
variables. <em>TEVC</em>, <em>24</em>(6), 1150–1163. (<a
href="https://doi.org/10.1109/TEVC.2020.2987804">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When solving bilevel optimization problems (BOPs) by evolutionary algorithms (EAs), it is necessary to obtain the lower-level optimal solution for each upper-level solution, which gives rise to a large number of lower-level fitness evaluations, especially for large-scale BOPs. It is interesting to note that some upper-level variables may not interact with some lower-level variables. Under this condition, if the value(s) of one/several upper-level variables change(s), we only need to focus on the optimization of the interacting lower-level variables, thus reducing the dimension of the search space and saving the number of lower-level fitness evaluations. This article proposes a new framework (called GO) to identify and utilize the interactions between upper-level and lower-level variables for scalable BOPs. GO includes two phases: 1) the grouping phase and 2) the optimization phase. In the grouping phase, after identifying the interactions between upper-level and lower-level variables, they are divided into three types of subgroups (denoted as types I-III), which contain only upper-level variables, only lower-level variables, and both upper-level and lower-level variables, respectively. In the optimization phase, if type-I and type-II subgroups only include one variable, a multistart sequential quadratic programming is designed; otherwise, a single-level EA is applied. In addition, a criterion is proposed to judge whether a type-II subgroup has multiple optima. If multiple optima exist, by incorporating the information of the upper level, we design new objective function and degree of constraint violation to locate the optimistic solution. As for type-III subgroups, they are optimized by a bilevel EA (BLEA). The effectiveness of GO is demonstrated on a set of scalable test problems by applying it to five representative BLEAs. Moreover, GO is applied to the resource pricing in mobile edge computing.},
  archive      = {J_TEVC},
  author       = {Pei-Qiu Huang and Yong Wang},
  doi          = {10.1109/TEVC.2020.2987804},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1150-1163},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A framework for scalable bilevel optimization: Identifying and utilizing the interactions between upper-level and lower-level variables},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sharp bounds for genetic drift in estimation of distribution
algorithms. <em>TEVC</em>, <em>24</em>(6), 1140–1149. (<a
href="https://doi.org/10.1109/TEVC.2020.2987361">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimation of distribution algorithms (EDAs) are a successful branch of evolutionary algorithms (EAs) that evolve a probabilistic model instead of a population. Analogous to genetic drift in EAs, EDAs also encounter the phenomenon that the random sampling in the model update can move the sampling frequencies to boundary values not justified by the fitness. This can result in a considerable performance loss. This article gives the first tight quantification of this effect for three EDAs and one ant colony optimizer, namely, for the univariate marginal distribution algorithm, the compact genetic algorithm, population-based incremental learning, and the max-min ant system with iteration-best update. Our results allow to choose the parameters of these algorithms in such a way that within a desired runtime, no sampling frequency approaches the boundary values without a clear indication from the objective function.},
  archive      = {J_TEVC},
  author       = {Benjamin Doerr and Weijie Zheng},
  doi          = {10.1109/TEVC.2020.2987361},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1140-1149},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Sharp bounds for genetic drift in estimation of distribution algorithms},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Binary relation learning and classifying for preselection in
evolutionary algorithms. <em>TEVC</em>, <em>24</em>(6), 1125–1139. (<a
href="https://doi.org/10.1109/TEVC.2020.2986348">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary algorithms (EAs) are a kind of population-based heuristic optimization method by using trial-and-error. Therefore, the search efficiency is a major concern in both of the algorithm design and applications. The preselection, which estimates the quality of candidate solutions and discards unpromising ones before fitness evaluation, is a widely used component for reducing the number of fitness evaluations in EAs. The surrogate models, such as regression and classification, are usually applied for quality estimation. In some EA frameworks, the relationship between a pair of solutions helps to distinguish “good” and “bad” solutions. In such cases, it is not necessary to estimate the specific quality of each candidate solution but the binary relationship of a pair of solutions. Following this idea, this article proposes a new preselection strategy, called relationship classification-based preselection (RCPS). In RCPS, a classification model is built to learn the relationship between a pair of solutions based on a given training data set, and promising candidate solutions are prescreened by this relation. The mechanism of RCPS is visualized and analyzed. The advantages of RCPS over traditional surrogate model-based preselection strategies are illustrated through a comprehensive empirical study. The experimental results suggest that on two sets of test suits, RCPS outperforms the comparison preselection strategies. To achieve a same accuracy, an EA with RCPS needs a smaller number of fitness evaluations than the one without RCPS.},
  archive      = {J_TEVC},
  author       = {Hao Hao and Jinyuan Zhang and Xiaofen Lu and Aimin Zhou},
  doi          = {10.1109/TEVC.2020.2986348},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1125-1139},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Binary relation learning and classifying for preselection in evolutionary algorithms},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A hybrid deep grouping algorithm for large scale global
optimization. <em>TEVC</em>, <em>24</em>(6), 1112–1124. (<a
href="https://doi.org/10.1109/TEVC.2020.2985672">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real-world problems contain a large number of decision variables which can be modeled as large scale global optimization (LSGO) problems. One effective way to solve an LSGO problem is to decompose it into smaller subproblems to solve. The existing works mainly focused on designing methods to decompose separable problems, while seldom focused on the decomposition of nonseparable large scale problems. Also, the existing decomposition methods only learn the interaction (correlation or interdependence) among variables to make the decomposition. In this article, we make the decomposition deeper: we not only consider the variable interaction but also take the essentialness of the variable into account to form a deep grouping method. To do this, we first design an essential/trivial variable detection scheme to support the deep decomposition for both separable problems and nonseparable problems. Based on it, we propose a new decomposition method called deep grouping method. Then, we design a new differential evolution (DE) algorithm with a new mutation strategy. By integrating all these, we propose a hybrid deep grouping (HDG) algorithm. Finally, the experiments are conducted on the widely used and most challenging LSGO benchmark suites, and the comparison results of the proposed algorithm with the state-of-the-art algorithms indicate the proposed algorithm is more effective.},
  archive      = {J_TEVC},
  author       = {Haiyan Liu and Yuping Wang and Ninglei Fan},
  doi          = {10.1109/TEVC.2020.2985672},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1112-1124},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A hybrid deep grouping algorithm for large scale global optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Empirical linkage learning. <em>TEVC</em>, <em>24</em>(6),
1097–1111. (<a href="https://doi.org/10.1109/TEVC.2020.2985497">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Linkage learning techniques are a crucial part of many modern evolutionary methods dedicated to solving problems in discrete domains. Linkage information quality is decisive for the effectiveness of these methods. In this article, we point on two possible linkage inaccuracy types. The missing linkage that occurs when some gene dependencies remain undiscovered, and the false linkage that takes place when linkage identifies gene dependencies that do not exist. To the best of our knowledge, all linkage learning techniques proposed so far are based on predictions, which can commit both of the mistake types. We propose a different approach. Instead of using statistical measures, or evolving the linkage, we check which genes are dependent on one another employing disturbances and the local search. We prove that the proposed technique will never report any false linkage. Thus, the proposed linkage learning based on local optimization (3LO) may miss some linkage but will never report a false one. The main objective of this article is to show the potential brought by 3LO that is fundamentally different from other linkage learning techniques. Since the main disadvantage of the proposed technique is its computational cost, it does not seem suitable for some of the already known, effective evolutionary methods. To overcome this issue, we propose an evolutionary method that employs 3LO. The extensive experimental analysis performed on a large set of hard computational problems shows that the method using 3LO is found to be competitive with other state-of-the-art methods.},
  archive      = {J_TEVC},
  author       = {Michal Witold Przewozniczek and Marcin Michal Komarnicki},
  doi          = {10.1109/TEVC.2020.2985497},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1097-1111},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Empirical linkage learning},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Does preference always help? A holistic study on
preference-based evolutionary multiobjective optimization using
reference points. <em>TEVC</em>, <em>24</em>(6), 1078–1096. (<a
href="https://doi.org/10.1109/TEVC.2020.2987559">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ultimate goal of multiobjective optimization is to help a decision maker (DM) identify solution(s) of interest (SOI) achieving satisfactory tradeoffs among multiple conflicting criteria. This can be realized by leveraging DM&#39;s preference information in evolutionary multiobjective optimization (EMO). No consensus has been reached on the effectiveness brought by incorporating preference in EMO (either a priori or interactively) versus a posteriori decision making after a complete run of an EMO algorithm. Bearing this consideration in mind, this article: 1) provides a pragmatic overview of the existing developments of preference-based EMO (PBEMO) and 2) conducts a series of experiments to investigate the effectiveness brought by preference incorporation in EMO for approximating various SOI. In particular, the DM&#39;s preference information is elicited as a reference point, which represents her/his aspirations for different objectives. The experimental results demonstrate that preference incorporation in EMO does not always lead to a desirable approximation of SOI if the DM&#39;s preference information is not well utilized, nor does the DM elicit invalid preference information, which is not uncommon when encountering a black-box system. To a certain extent, this issue can be remedied through an interactive preference elicitation. Last but not the least, we find that a PBEMO algorithm is able to be generalized to approximate the whole PF given an appropriate setup of preference information.},
  archive      = {J_TEVC},
  author       = {Ke Li and Minhui Liao and Kalyanmoy Deb and Geyong Min and Xin Yao},
  doi          = {10.1109/TEVC.2020.2987559},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1078-1096},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Does preference always help? a holistic study on preference-based evolutionary multiobjective optimization using reference points},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Landscape-aware performance prediction for evolutionary
multiobjective optimization. <em>TEVC</em>, <em>24</em>(6), 1063–1077.
(<a href="https://doi.org/10.1109/TEVC.2019.2940828">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We expose and contrast the impact of landscape characteristics on the performance of search heuristics for black-box multiobjective combinatorial optimization problems. A sound and concise summary of features characterizing the structure of an arbitrary problem instance is identified and related to the expected performance of global and local dominance-based multiobjective optimization algorithms. We provide a critical review of existing features tailored to multiobjective combinatorial optimization problems, and we propose additional ones that do not require any global knowledge from the landscape, making them suitable for large-size problem instances. Their intercorrelation and their association with algorithm performance are also analyzed. This allows us to assess the individual and the joint effect of problem features on algorithm performance, and to highlight the main difficulties encountered by such search heuristics. By providing effective tools for multiobjective landscape analysis, we highlight that multiple features are required to capture problem difficulty, and we provide further insights into the importance of ruggedness and multimodality to characterize multiobjective combinatorial landscapes.},
  archive      = {J_TEVC},
  author       = {Arnaud Liefooghe and Fabio Daolio and Sébastien Verel and Bilel Derbel and Hernán Aguirre and Kiyoshi Tanaka},
  doi          = {10.1109/TEVC.2019.2940828},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1063-1077},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Landscape-aware performance prediction for evolutionary multiobjective optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Population diversity of nonelitist evolutionary algorithms
in the exploration phase. <em>TEVC</em>, <em>24</em>(6), 1050–1062. (<a
href="https://doi.org/10.1109/TEVC.2019.2917275">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper discusses the genetic diversity of real-coded populations processed by an evolutionary algorithm (EA). Diversity is expressed as a variance or a covariance matrix of individuals contained in the population, in one- or multi-dimensional cases, respectively. We focus on the exploration stage of the optimization, therefore, the fitness function is modeled as noise. We prove that the expected value of genetic diversity achieves a level proportional to the mutation covariance matrix. The proportionality coefficient depends solely on the EA parameters. Formulas are derived to predict the diversity for fitness proportionate, tournament, and truncation selection, with and without arithmetic crossover and with Gaussian mutation. Experimental validation of the multidimensional case shows that prediction accuracy is satisfactory in a broad spectrum of settings of EA parameters.},
  archive      = {J_TEVC},
  author       = {Jarosław Arabas and Karol Opara},
  doi          = {10.1109/TEVC.2019.2917275},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1050-1062},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Population diversity of nonelitist evolutionary algorithms in the exploration phase},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Finite-sample analysis of information geometric optimization
with isotropic gaussian distribution on convex quadratic functions.
<em>TEVC</em>, <em>24</em>(6), 1035–1049. (<a
href="https://doi.org/10.1109/TEVC.2019.2917709">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We theoretically analyze the information geometric optimization (IGO), which is a unified framework of stochastic search algorithms for black-box optimization. The IGO framework has two parameters: 1) the learning rate and 2) the sample size, and they influence the behavior of the algorithm. We investigate the strategy parameters of the IGO with the family of isotropic Gaussian distributions on a general convex quadratic function. Compared to the previous theoretical works, where an infinite sample size is assumed and the deterministic algorithm dynamics is studied, we investigate the expected improvement of the algorithm with a finite sample size. The analysis finds that the relative decrease rates of the distance from the distribution mean to the landscape optimum and the distribution standard deviation must be the same, which we observe in practice, while the analysis based on an infinite sample size failed to obtain. We derive these rates explicitly as a function of the eigenvalues of the Hessian of the objective function and the strategy parameters. We also derive the stable value of the ratio of the square distance to the optimum over the distribution variance, as well as the conditions that the stable value exists. These theoretical values coincide with our numerical simulations.},
  archive      = {J_TEVC},
  author       = {Kento Uchida and Shinichi Shirakawa and Youhei Akimoto},
  doi          = {10.1109/TEVC.2019.2917709},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1035-1049},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Finite-sample analysis of information geometric optimization with isotropic gaussian distribution on convex quadratic functions},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Significance-based estimation-of-distribution algorithms.
<em>TEVC</em>, <em>24</em>(6), 1025–1034. (<a
href="https://doi.org/10.1109/TEVC.2019.2956633">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimation-of-distribution algorithms (EDAs) are randomized search heuristics that create a probabilistic model of the solution space, which is updated iteratively, based on the quality of the solutions sampled according to the model. As previous works show, this iteration-based perspective can lead to erratic updates of the model, in particular, to bit-frequencies approaching a random boundary value. In order to overcome this problem, we propose a new EDA based on the classic compact genetic algorithm (cGA) that takes into account a longer history of samples and updates its model only with respect to information which it classifies as statistically significant. We prove that this significance-based cGA (sig-cGA) optimizes the commonly regarded benchmark functions OneMax (OM), LeadingOnes, and BinVal all in quasilinear time, a result shown for no other EDA or evolutionary algorithm so far. For the recently proposed stable compact genetic algorithm - an EDA that tries to prevent erratic model updates by imposing a bias to the uniformly distributed model - we prove that it optimizes OM only in a time exponential in its hypothetical population size. Similarly, we show that the convex search algorithm cannot optimize OM in polynomial time.},
  archive      = {J_TEVC},
  author       = {Benjamin Doerr and Martin S. Krejca},
  doi          = {10.1109/TEVC.2019.2956633},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1025-1034},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Significance-based estimation-of-distribution algorithms},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Parallel black-box complexity with tail bounds.
<em>TEVC</em>, <em>24</em>(6), 1010–1024. (<a
href="https://doi.org/10.1109/TEVC.2019.2954234">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new black-box complexity model for search algorithms evaluating λ search points in parallel. The parallel unary unbiased black-box complexity gives lower bounds on the number of function evaluations every parallel unary unbiased black-box algorithm needs to optimize a given problem. It captures the inertia caused by offspring populations in evolutionary algorithms and the total computational effort in parallel metaheuristics. We present complexity results for LeadingOnes and OneMax. Our main result is a general performance limit: we prove that on every function every λ-parallel unary unbiased algorithm needs at least a certain number of evaluations (a function of problem size and λ) to find any desired target set of up to exponential size, with an overwhelming probability. This yields lower bounds for the typical optimization time on unimodal and multimodal problems, for the time to find any local optimum, and for the time to even get close to any optimum. The power and versatility of this approach is shown for a wide range of illustrative problems from combinatorial optimization. Our performance limits can guide parameter choice and algorithm design; we demonstrate the latter by presenting an optimal λ-parallel algorithm for OneMax that uses parallelism most effectively.},
  archive      = {J_TEVC},
  author       = {Per Kristian Lehre and Dirk Sudholt},
  doi          = {10.1109/TEVC.2019.2954234},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1010-1024},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Parallel black-box complexity with tail bounds},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A general dichotomy of evolutionary algorithms on monotone
functions. <em>TEVC</em>, <em>24</em>(6), 995–1009. (<a
href="https://doi.org/10.1109/TEVC.2019.2917014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is known that the (1 + 1)-EA with mutation rate c/n optimizes every monotone function efficiently if c 2 /m 1 , where m 1 and m 2 are the first and second falling moment of the number of bit flips. Surprisingly, the range of efficient parameters is not affected by either population size μ nor by the offspring population size λ. The picture changes completely if crossover is allowed. The genetic algorithms (μ + 1)-GA and (μ+1)-fGA are efficient for arbitrary mutations strengths if μ is large enough.},
  archive      = {J_TEVC},
  author       = {Johannes Lengler},
  doi          = {10.1109/TEVC.2019.2917014},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {995-1009},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A general dichotomy of evolutionary algorithms on monotone functions},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Guest editorial special issue on theoretical foundations of
evolutionary computation. <em>TEVC</em>, <em>24</em>(6), 993–994. (<a
href="https://doi.org/10.1109/TEVC.2020.3035225">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is our pleasure to introduce this special issue on the recent advances in the theoretical foundations of evolutionary computation (EC). While in the early days of this field, theoretical analyses inevitably focused on simplified models of evolutionary algorithms (EAs), the continuous progress made in the development of suitable mathematical techniques for the analysis now allows to derive proven statements regarding the performance of off-the-shelf metaheuristics, such as standard generational and steady-state genetic algorithms with no algorithmic simplifications. Comparisons between the performance of a given EA with the best possible one can also be made nowadays, allowing to assess whether a given algorithm may be improved upon or whether its performance is optimal for a given class of problems. Such understanding often provides insights for the design of new EAs which provably have better performance for given problems. We are glad that examples of results of this kind are present within this special issue. A total of 27 papers were submitted which were the subject of at least three independent reviews, and six manuscripts of the highest quality were selected for publication in the special issue. In the following, we provide a brief summary of these manuscripts.},
  archive      = {J_TEVC},
  author       = {Pietro S. Oliveto and Anne Auger and Francisco Chicano and Carlos M. Fonseca},
  doi          = {10.1109/TEVC.2020.3035225},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {993-994},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Guest editorial special issue on theoretical foundations of evolutionary computation},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). IEEE transactions on evolutionary computation society
information. <em>TEVC</em>, <em>24</em>(5), C3. (<a
href="https://doi.org/10.1109/TEVC.2020.3027106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {These instructions give guidelines for preparing papers for this publication. Presents information for authors publishing in this journal.},
  archive      = {J_TEVC},
  doi          = {10.1109/TEVC.2020.3027106},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {C3},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {IEEE transactions on evolutionary computation society information},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Introducing IEEE collabratec. <em>TEVC</em>,
<em>24</em>(5), 990. (<a
href="https://doi.org/10.1109/TEVC.2020.3027116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advertisement, IEEE. IEEE Collabratec is a new, integrated online community where IEEE members, researchers, authors, and technology professionals with similar fields of interest can network and collaborate, as well as create and manage content. Featuring a suite of powerful online networking and collaboration tools, IEEE Collabratec allows you to connect according to geographic location, technical interests, or career pursuits. You can also create and share a professional identity that showcases key accomplishments and participate in groups focused around mutual interests, actively learning from and contributing to knowledgeable communities. All in one place! Learn about IEEE Collabratec at ieeecollabratec.org.},
  archive      = {J_TEVC},
  doi          = {10.1109/TEVC.2020.3027116},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {990},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Introducing IEEE collabratec},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multiobjective evolution strategy for dynamic multiobjective
optimization. <em>TEVC</em>, <em>24</em>(5), 974–988. (<a
href="https://doi.org/10.1109/TEVC.2020.2985323">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a novel evolution strategy-based evolutionary algorithm, named DMOES, which can efficiently and effectively solve multiobjective optimization problems in dynamic environments. First, an efficient self-adaptive precision controllable mutation operator is designed for individuals to explore and exploit the decision space. Second, the simulated isotropic magnetic particles niching can guide the individuals to keep uniform distance and extent to approximate the entire Pareto front automatically. Third, the nondominated solutions (NDS) guided immigration can facilitate the population convergence with two different strategies for the NDSs and the dominated solutions, respectively. As a result, our algorithm can track the new approximate Pareto set and approximate Pareto front as quickly as possible when the environment changes. In addition, DMOES can obtain a well-converged and well-diversified Pareto front with much less population size and far lower computational cost. The larger the number of individuals, the sharper the contour of the resulted approximate Pareto front will be. Finally, the proposed algorithm is evaluated by the FDA, dMOP, UDF, and ZJZ test suites. The experimental results have been demonstrated to provide a competitive and oftentimes better performance when compared against some chosen state-of-the-art dynamic multiobjective evolutionary algorithms.},
  archive      = {J_TEVC},
  author       = {Kai Zhang and Chaonan Shen and Xiaoming Liu and Gary G. Yen},
  doi          = {10.1109/TEVC.2020.2985323},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {974-988},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Multiobjective evolution strategy for dynamic multiobjective optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Specializing context-free grammars with a (1 + 1)-EA.
<em>TEVC</em>, <em>24</em>(5), 960–973. (<a
href="https://doi.org/10.1109/TEVC.2020.2983664">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Context-free grammars are useful tools for modeling the solution space of problems that can be solved by optimization algorithms. For a given solution space, there exists an infinite number of grammars defining that space, and there are clues that changing the grammar may impact the effectiveness of the optimization. In this article, we investigate theoretically and experimentally the possibility of specializing a grammar in a problem, that is, of systematically improving the quality of the grammar for the given problem. To this end, we define the quality of a grammar for a problem in terms of the average fitness of the candidate solutions generated using that grammar. Theoretically, we demonstrate the following findings: 1) that a simple mutation operator employed in a (1 + 1)-EA setting can be used to specialize a grammar in a problem without changing the solution space defined by the grammar and 2) that three grammars of equal quality for a grammar-based version of the ONEMAX problem greatly vary in how they can be specialized with that (1 + 1)-EA, as the expected time required to obtain the same improvement in quality can vary exponentially among grammars. Then, experimentally, we validate the theoretical findings and extend them to other problems, grammars, and a more general version of the mutation operator.},
  archive      = {J_TEVC},
  author       = {Luca Manzoni and Alberto Bartoli and Mauro Castelli and Ivo Gonçalves and Eric Medvet},
  doi          = {10.1109/TEVC.2020.2983664},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {960-973},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Specializing context-free grammars with a (1 + 1)-EA},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Limit-cycle-based mutant multiobjective pigeon-inspired
optimization. <em>TEVC</em>, <em>24</em>(5), 948–959. (<a
href="https://doi.org/10.1109/TEVC.2020.2983311">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a limit-cycle-based mutant multiobjective pigeon-inspired optimization (PIO). In this algorithm, the limit-cycle-based mechanism is devised to consider the factors that affect the flight of pigeons to simplify the multiobjective PIO algorithm. The mutant mechanism is incorporated to strengthen the exploration capability in the evolutionary process. Additionally, the application of the dual repository makes the nondominated solutions stored and selected to guide the flight of pigeons. Attributed to the limit-cycle-based mutant mechanisms, this algorithm not only obtains the faster convergence speed and higher accuracy but also improves its population diversity. To confirm the universal application of this algorithm, theoretical analysis of the convergence is discussed in this article. Finally, comparative experiments of our proposed algorithm and other five multiobjective methods are conducted to verify the accuracy, efficiency, and convergence stability of the proposed algorithm.},
  archive      = {J_TEVC},
  author       = {Haibin Duan and Mengzhen Huo and Yuhui Shi},
  doi          = {10.1109/TEVC.2020.2983311},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {948-959},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Limit-cycle-based mutant multiobjective pigeon-inspired optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A constrained multiobjective evolutionary algorithm with
detect-and-escape strategy. <em>TEVC</em>, <em>24</em>(5), 938–947. (<a
href="https://doi.org/10.1109/TEVC.2020.2981949">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Overall constraint violation functions are commonly used in multiobjective evolutionary algorithms (MOEAs) for handling constraints. Constraints could cause these algorithms stuck in two stagnation states: 1) since the feasible region of a multiobjective optimization problem can consist of several disconnected feasible subregions, the search can be easily trapped in a feasible subregion which does not contain all the global Pareto optimal solutions and 2) an overall constraint violation function may have many nonzero minimal points, it can make the search stuck in an unfeasible area. To address these two issues, this article proposes a strategy to detect whether or not the search is stuck in these two stagnation states and then escape from them. Our proposed detect-and-escape strategy uses the feasible ratio and the change rate of overall constraint violation to detect stagnation, and adjusts the weight of the constraint violation for guiding the search to escape from stagnation states. We develop and implement a decomposition-based constrained MOEA with this strategy. Extensive experiments on a number of benchmark problems demonstrate the competitiveness of our proposed algorithm when compared to five other state-of-the-art constrained evolutionary algorithms.},
  archive      = {J_TEVC},
  author       = {Qingling Zhu and Qingfu Zhang and Qiuzhen Lin},
  doi          = {10.1109/TEVC.2020.2981949},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {938-947},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A constrained multiobjective evolutionary algorithm with detect-and-escape strategy},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Boosting data-driven evolutionary algorithm with localized
data generation. <em>TEVC</em>, <em>24</em>(5), 923–937. (<a
href="https://doi.org/10.1109/TEVC.2020.2979740">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By efficiently building and exploiting surrogates, data-driven evolutionary algorithms (DDEAs) can be very helpful in solving expensive and computationally intensive problems. However, they still often suffer from two difficulties. First, many existing methods for building a single ad hoc surrogate are suitable for some special problems but may not work well on some other problems. Second, the optimization accuracy of DDEAs deteriorates if available data are not enough for building accurate surrogates, which is common in expensive optimization problems. To this end, this article proposes a novel DDEA with two efficient components. First, a boosting strategy (BS) is proposed for self-aware model managements, which can iteratively build and combine surrogates to obtain suitable surrogate models for different problems. Second, a localized data generation (LDG) method is proposed to generate synthetic data to alleviate data shortage and increase data quantity, which is achieved by approximating fitness through data positions. By integrating the BS and the LDG, the BDDEA-LDG algorithm is able to improve model accuracy and data quantity at the same time automatically according to the problems at hand. Besides, a tradeoff is empirically considered to strike a better balance between the effectiveness of surrogates and the time cost for building them. The experimental results show that the proposed BDDEA-LDG algorithm can generally outperform both traditional methods without surrogates and other state-of-the-art DDEA son widely used benchmarks and an arterial traffic signal timing real-world optimization problem. Furthermore, the proposed BDDEA-LDG algorithm can use only about 2\% computational budgets of traditional methods for producing competitive results.},
  archive      = {J_TEVC},
  author       = {Jian-Yu Li and Zhi-Hui Zhan and Chuan Wang and Hu Jin and Jun Zhang},
  doi          = {10.1109/TEVC.2020.2979740},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {923-937},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Boosting data-driven evolutionary algorithm with localized data generation},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A multifactorial evolutionary algorithm for multitasking
under interval uncertainties. <em>TEVC</em>, <em>24</em>(5), 908–922.
(<a href="https://doi.org/10.1109/TEVC.2020.2975381">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various real-world applications with interval uncertainty, such as the path planning of mobile robot, layout of radio frequency identification readers and solar desalination, can be formulated as an interval multiobjective optimization problem (IMOOP), which is usually transformed into one or a series of certain problems to solve by using evolutionary algorithms. However, a definite characteristic among them is that only a single optimization task can be catched up at a time. Inspired by the multifactorial evolutionary algorithm (MFEA), a novel interval MFEA (IMFEA) is proposed to solve IMOOPs simultaneously using a single population of evolving individuals. In the proposed method, the potential interdependency across related problems can be explored in the unified genotype space, and multitasks of multiobjective interval optimization problems are solved at once by promoting knowledge transfer for the greater synergistic search to improve the convergence speed and the quality of the optimal solution set. Specifically, an interval crowding distance based on shape evaluation is calculated to evaluate the interval solutions more comprehensively. In addition, an interval dominance relationship based on the evolutionary state of the population is designed to obtain the interval confidence level, which considers the difference of average convergence levels and the relative size of the potential possibility between individuals. Correspondingly, the strict transitivity proof of the presented dominance relationship is given. The efficacy of the associated evolutionary algorithm is validated on a series of benchmark test functions, as well as a real-world case of robot path planning with many terrains that provides insight into the performance of the method in the face of IMOOPs.},
  archive      = {J_TEVC},
  author       = {Jun Yi and Junren Bai and Haibo He and Wei Zhou and Lizhong Yao},
  doi          = {10.1109/TEVC.2020.2975381},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {908-922},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A multifactorial evolutionary algorithm for multitasking under interval uncertainties},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Combining simple and adaptive monte carlo methods for
approximating hypervolume. <em>TEVC</em>, <em>24</em>(5), 896–907. (<a
href="https://doi.org/10.1109/TEVC.2020.2969965">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The computation of hypervolume is a key issue in multiobjective optimization, particularly, multiobjective evolutionary optimization. However, it is NP-hard to compute the exact hypervolume value. Monte Carlo methods have been widely used for approximating the hypervolume. Observing that the basic Monte Carlo method and the fully polynomial-time randomized approximation scheme (FPRAS) suit different solution sets, we propose a combination of these two methods and show that it performs very well on a number of solution sets.},
  archive      = {J_TEVC},
  author       = {Jingda Deng and Qingfu Zhang},
  doi          = {10.1109/TEVC.2020.2969965},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {896-907},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Combining simple and adaptive monte carlo methods for approximating hypervolume},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Variable-size cooperative coevolutionary particle swarm
optimization for feature selection on high-dimensional data.
<em>TEVC</em>, <em>24</em>(5), 882–895. (<a
href="https://doi.org/10.1109/TEVC.2020.2968743">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary feature selection (FS) methods face the challenge of “curse of dimensionality” when dealing with high-dimensional data. Focusing on this challenge, this article studies a variable-size cooperative coevolutionary particle swarm optimization algorithm (VS-CCPSO) for FS. The proposed algorithm employs the idea of “divide and conquer” in cooperative coevolutionary approach, but several new developed problem-guided operators/strategies make it more suitable for FS problems. First, a space division strategy based on the feature importance is presented, which can classify relevant features into the same subspace with a low computational cost. Following that, an adaptive adjustment mechanism of subswarm size is developed to maintain an appropriate size for each subswarm, with the purpose of saving computational cost on evaluating particles. Moreover, a particle deletion strategy based on fitness-guided binary clustering, and a particle generation strategy based on feature importance and crossover both are designed to ensure the quality of particles in the subswarms. We apply VS-CCPSO to 12 typical datasets and compare it with six state-of-the-art methods. The experimental results show that VS-CCPSO has the capability of obtaining good feature subsets, suggesting its competitiveness for tackling FS problems with high dimensionality.},
  archive      = {J_TEVC},
  author       = {Xian-Fang Song and Yong Zhang and Yi-Nan Guo and Xiao-Yan Sun and Yong-Li Wang},
  doi          = {10.1109/TEVC.2020.2968743},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {882-895},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Variable-size cooperative coevolutionary particle swarm optimization for feature selection on high-dimensional data},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evolutionary large-scale multiobjective optimization for
ratio error estimation of voltage transformers. <em>TEVC</em>,
<em>24</em>(5), 868–881. (<a
href="https://doi.org/10.1109/TEVC.2020.2967501">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ratio error (RE) estimation of the voltage transformers (VTs) plays an important role in modern power delivery systems. Existing RE estimation methods mainly focus on periodical calibration but ignore the time-varying property. Consequently, it is difficult to efficiently estimate the state of the VTs in real time. To address this issue, we formulate a time-varying RE estimation (TREE) problem into a large-scale multiobjective optimization problem, where the multiple objectives and inequality constraints are formulated by statistical and physical rules extracted from the power delivery systems. Furthermore, a set of TREE problems from different substations is systematically formulated into a benchmark test suite for characterizing their different properties. The formulation of these TREE problems not only transfers an expensive RE estimation task to a relatively cheaper optimization problem but also promotes the research in large-scale multiobjective optimization by providing a real-world benchmark test suite with complex variable interactions and correlations to different objectives. To the best of our knowledge, this is the first time to formulate a real-world problem into a benchmark test suite for large-scale multiobjective optimization, and it is also the first work proposing to solve TREE problems via evolutionary multiobjective optimization.},
  archive      = {J_TEVC},
  author       = {Cheng He and Ran Cheng and Chuanji Zhang and Ye Tian and Qin Chen and Xin Yao},
  doi          = {10.1109/TEVC.2020.2967501},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {868-881},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolutionary large-scale multiobjective optimization for ratio error estimation of voltage transformers},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020c). An analysis of quality indicators using approximated
optimal distributions in a 3-d objective space. <em>TEVC</em>,
<em>24</em>(5), 853–867. (<a
href="https://doi.org/10.1109/TEVC.2020.2966014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although quality indicators play a crucial role in benchmarking evolutionary multiobjective optimization algorithms, their properties are still unclear. One promising approach for understanding quality indicators is the use of the optimal distribution of objective vectors that optimizes each quality indicator. However, it is difficult to obtain the optimal distribution for each quality indicator, especially, when its theoretical property is unknown. Thus, optimal distributions for most quality indicators have not been well investigated. To address these issues, first, we propose a problem formulation of finding the optimal distribution for each quality indicator on an arbitrary Pareto front. Then, we approximate the optimal distributions for nine quality indicators using the proposed problem formulation. We analyze the nine quality indicators using their approximated optimal distributions on eight types of Pareto fronts of three-objective problems. Our analysis demonstrates that uniformly distributed objective vectors over the entire Pareto front are not optimal in many cases. Each quality indicator has its own optimal distribution for each Pareto front. We also examine the consistency among the nine quality indicators.},
  archive      = {J_TEVC},
  author       = {Ryoji Tanabe and Hisao Ishibuchi},
  doi          = {10.1109/TEVC.2020.2966014},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {853-867},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {An analysis of quality indicators using approximated optimal distributions in a 3-D objective space},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new hypervolume-based evolutionary algorithm for
many-objective optimization. <em>TEVC</em>, <em>24</em>(5), 839–852. (<a
href="https://doi.org/10.1109/TEVC.2020.2964705">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, a new hypervolume-based evolutionary multiobjective optimization algorithm (EMOA), namely, R2HCA-EMOA (R2-based hypervolume contribution approximation EMOA), is proposed for many-objective optimization. The core idea of the algorithm is to use an R2 indicator variant to approximate the hypervolume contribution. The basic framework of the proposed algorithm is the same as SMS-EMOA. In order to make the algorithm computationally efficient, a utility tensor structure is introduced for the calculation of the R2 indicator variant. Moreover, a normalization mechanism is incorporated into R2HCA-EMOA to enhance the performance of the algorithm. Through experimental studies, R2HCA-EMOA is compared with three hypervolume-based EMOAs and several other state-of-the-art EMOAs on 5-, 10-, and 15-objective DTLZ, WFG problems, and their minus versions. Our results show that R2HCA-EMOA is more efficient than the other hypervolume-based EMOAs, and is superior to all the compared state-of-the-art EMOAs.},
  archive      = {J_TEVC},
  author       = {Ke Shang and Hisao Ishibuchi},
  doi          = {10.1109/TEVC.2020.2964705},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {839-852},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A new hypervolume-based evolutionary algorithm for many-objective optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multiobjective multitasking optimization based on
incremental learning. <em>TEVC</em>, <em>24</em>(5), 824–838. (<a
href="https://doi.org/10.1109/TEVC.2019.2962747">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiobjective multitasking optimization (MTO) is an emerging research topic in the field of evolutionary computation. In contrast to multiobjective optimization, MTO solves multiple optimization tasks simultaneously. MTO aims to improve the overall performance of multiple tasks through knowledge transfer among tasks. Recently, MTO has attracted the attention of many researchers, and several algorithms have been proposed in the literature. However, one of the crucial issues, finding useful knowledge, has been rarely studied. Keeping this in mind, this article proposes an MTO algorithm based on incremental learning (EMTIL). Specifically, the transferred solutions (the form of knowledge) will be selected by incremental classifiers, which are capable of finding valuable solutions for knowledge transfer. The training data are generated by the knowledge transfer at each generation. Furthermore, the search space of the tasks will be explored by the proposed mapping (among tasks) approach, which helps these tasks to escape from their local Pareto Fronts. Empirical studies have been conducted on 15 MTO problems to assess the effectiveness of EMTIL. The experimental results demonstrate that EMTIL works more effectively for MTO compared to the existing algorithms.},
  archive      = {J_TEVC},
  author       = {Jiabin Lin and Hai-Lin Liu and Bing Xue and Mengjie Zhang and Fangqing Gu},
  doi          = {10.1109/TEVC.2019.2962747},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {824-838},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Multiobjective multitasking optimization based on incremental learning},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Approximating complex pareto fronts with predefined
normal-boundary intersection directions. <em>TEVC</em>, <em>24</em>(5),
809–823. (<a href="https://doi.org/10.1109/TEVC.2019.2958921">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decomposition-based evolutionary algorithms using predefined reference points have shown good performance in many-objective optimization. Unfortunately, almost all experimental studies have focused on problems having regular Pareto fronts (PFs). Recently, it has been shown that the performance of such algorithms is deteriorated when facing irregular PFs, such as degenerate, discontinuous, inverted, strongly convex, and/or strongly concave fronts. The main issue is that the predefined reference points may not all intersect with the PF. Therefore, many researchers have proposed to update the reference points with the aim of adapting them to the discovered Pareto shape. Unfortunately, the adaptive update does not really solve the issue for two main reasons. On the one hand, there is a considerable difficulty to set the time and the frequency of updates. On the other hand, it is not easy to define how to update the search directions for an unknown PF shape. This article proposes to approximate irregular PFs using a set of predefined normal-boundary intersection (NBI) directions. The main motivation behind this article is that when using a set of well-distributed NBI directions, all these directions intersect with the PF regardless of its shape, except for the case of discontinuous and/or degenerate fronts. To handle the latter cases, a simple interaction mechanism between the decision maker (DM) and the algorithm is used. In fact, the DM is asked if the number of NBI directions needs to be increased in some stages of the evolutionary process. If so, the resolution of the NBI directions that intersect the PF is increased to properly cover discontinuous and/or degenerate PFs. Our experimental results on benchmark problems with regular and irregular PFs, having up to fifteen objectives, show the merits of our algorithm when compared to eight of the most representative state-of-the-art algorithms.},
  archive      = {J_TEVC},
  author       = {Maha Elarbi and Slim Bechikh and Carlos A. Coello Coello and Mohamed Makhlouf and Lamjed Ben Said},
  doi          = {10.1109/TEVC.2019.2958921},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {809-823},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Approximating complex pareto fronts with predefined normal-boundary intersection directions},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020c). IEEE transactions on evolutionary computation society
information. <em>TEVC</em>, <em>24</em>(4), C3. (<a
href="https://doi.org/10.1109/TEVC.2020.3008740">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Presents a listing of the editorial board, board of governors, current staff, committee members, and/or society editors for this issue of the publication.},
  archive      = {J_TEVC},
  doi          = {10.1109/TEVC.2020.3008740},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {C3},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {IEEE transactions on evolutionary computation society information},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020c). Introducing IEEE collabratec. <em>TEVC</em>,
<em>24</em>(4), 808. (<a
href="https://doi.org/10.1109/TEVC.2020.3009802">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advertisement, IEEE. IEEE Collabratec is a new, integrated online community where IEEE members, researchers, authors, and technology professionals with similar fields of interest can network and collaborate, as well as create and manage content. Featuring a suite of powerful online networking and collaboration tools, IEEE Collabratec allows you to connect according to geographic location, technical interests, or career pursuits. You can also create and share a professional identity that showcases key accomplishments and participate in groups focused around mutual interests, actively learning from and contributing to knowledgeable communities. All in one place! Learn about IEEE Collabratec at ieeecollabratec.org.},
  archive      = {J_TEVC},
  doi          = {10.1109/TEVC.2020.3009802},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {808},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Introducing IEEE collabratec},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Erratum to “R2-based hypervolume contribution
approximation” [feb 20 185-192]. <em>TEVC</em>, <em>24</em>(4), 807. (<a
href="https://doi.org/10.1109/TEVC.2020.3007272">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In [1] , the authors’ names appeared incorrectly on the Table of Contents. They should have appeared as follows:},
  archive      = {J_TEVC},
  author       = {Ke Shang and Hisao Ishibuchi and Xizi Ni},
  doi          = {10.1109/TEVC.2020.3007272},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {807},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Erratum to “R2-based hypervolume contribution approximation” [Feb 20 185-192]},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel evolutionary algorithm for dynamic constrained
multiobjective optimization problems. <em>TEVC</em>, <em>24</em>(4),
792–806. (<a href="https://doi.org/10.1109/TEVC.2019.2958075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To promote research on dynamic constrained multiobjective optimization, we first propose a group of generic test problems with challenging characteristics, including different modes of the true Pareto front (e.g., convexity-concavity and connectedness-disconnectedness) and the changing feasible region. Subsequently, motivated by the challenges presented by dynamism and constraints, we design a dynamic constrained multiobjective optimization algorithm with a nondominated solution selection operator, a mating selection strategy, a population selection operator, a change detection method, and a change response strategy. The designed nondominated solution selection operator can obtain a nondominated population with diversity when the environment changes. The mating selection strategy and population selection operator can adaptively handle infeasible solutions. If a change is detected, the proposed change response strategy reuses some portion of the old solutions in combination with randomly generated solutions to reinitialize the population, and a steady-state update method is designed to improve the retained previous solutions. The experimental results show that the proposed test problems can be used to clearly distinguish the performance of algorithms, and that the proposed algorithm is very competitive for solving dynamic constrained multiobjective optimization problems in comparison with state-of-the-art algorithms.},
  archive      = {J_TEVC},
  author       = {Qingda Chen and Jinliang Ding and Shengxiang Yang and Tianyou Chai},
  doi          = {10.1109/TEVC.2019.2958075},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {792-806},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A novel evolutionary algorithm for dynamic constrained multiobjective optimization problems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Paradoxes in numerical comparison of optimization
algorithms. <em>TEVC</em>, <em>24</em>(4), 777–791. (<a
href="https://doi.org/10.1109/TEVC.2019.2955110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerical comparison is often key to verifying the performance of optimization algorithms, especially, global optimization algorithms. However, studies have so far neglected issues concerning comparison strategies necessary to rank optimization algorithms properly. To fill this gap for the first time, we combine voting theory and numerical comparison research areas, which have been disjoint so far, and thus extend the results of the former to the latter for optimization algorithms. In particular, we investigate compatibility issues arising from comparing two and more than two algorithms, termed “C2” and “C2+” in this article, respectively. Through defining and modeling “C2” and “C2+” mathematically, it is uncovered and illustrated that numerical comparison can be incompatible. Further, two possible paradoxes, namely, “cycle ranking” and “survival of the nonfittest,” are discovered and analyzed rigorously. The occurrence probabilities of these two paradoxes are also calculated under the no-free-lunch assumption, which shows the first justifiable use of the impartial culture assumption from voting theory, providing a point of reference to the frequency of the paradoxes occurring. It is also shown that significant influence on these probabilities comes from the number of algorithms and the number of optimization problems studied in the comparison. Further, various limiting probabilities when the number of optimization problems goes to infinity are also derived and characterized. The results would help guide benchmarking and developing optimization and machine learning algorithms.},
  archive      = {J_TEVC},
  author       = {Qunfeng Liu and William V. Gehrlein and Ling Wang and Yuan Yan and Yingying Cao and Wei Chen and Yun Li},
  doi          = {10.1109/TEVC.2019.2955110},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {777-791},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Paradoxes in numerical comparison of optimization algorithms},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). MUMI: Multitask module identification for biological
networks. <em>TEVC</em>, <em>24</em>(4), 765–776. (<a
href="https://doi.org/10.1109/TEVC.2019.2952220">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying modules from biological networks is important since modules reveal essential mechanisms and dynamic processes in biological systems. Existing algorithms focus on identifying either active modules or topological modules (communities), which represent dynamic and topological units in the network, respectively. However, high-level biological phenomena, e.g., functions are emergent properties from the interplay between network topology and dynamics. Therefore, to fully explain the mechanisms underlying the high-level biological phenomena, it is important to identify the overlaps between communities and active modules, which indicate the topological units with significant changes of dynamics. However, despite the importance, there are no existing methods to do so. In this article, we propose the multitask module identification (MUMI) algorithm to detect the overlaps between active modules and communities simultaneously. The experimental results show that our method provides new insights into biological mechanisms by combining information from active modules and communities. By formulating the problem as a multitasking learning problem which searches for these two types of modules simultaneously, the algorithm can exploit their latent complementarities to obtain better search performance in terms of accuracy and convergence. Our MATLAB implementation of MUMI is available at https://github.com/WeiqiChen/Mumi-multitask-module-identification.},
  archive      = {J_TEVC},
  author       = {Weiqi Chen and Zexuan Zhu and Shan He},
  doi          = {10.1109/TEVC.2019.2952220},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {765-776},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {MUMI: Multitask module identification for biological networks},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Novel interactive preference-based multiobjective
evolutionary optimization for bolt supporting networks. <em>TEVC</em>,
<em>24</em>(4), 750–764. (<a
href="https://doi.org/10.1109/TEVC.2019.2951217">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous methods of designing a bolt supporting network, which depend on engineering experiences, seek optimal bolt supporting schemes in terms of supporting quality. The supporting cost and time, however, have not been considered, which restricts their applications in real-world situations. We formulate the problem of designing a bolt supporting network as a three-objective optimization model by simultaneously considering such indicators as quality, economy, and efficiency. Especially, two surrogate models are constructed by support vector regression for roof-to-floor convergence and the two-sided displacement, respectively, so as to rapidly evaluate supporting quality during optimization. To solve the formulated model, a novel interactive preference-based multiobjective evolutionary algorithm is proposed. The highlight of generic methods which interactively articulate preferences is to systematically manage the regions of interest by three steps, that is, “partitioning-updating-tracking” in accordance with the cognition process of human. The preference regions of a decision-maker (DM) are first articulated and employed to narrow down the feasible objective space before the evolution in terms of nadir point, not the commonly used ideal point. Then, the DM’s preferences are tracked by dynamically updating these preference regions based on satisfactory candidates during the evolution. Finally, individuals in the population are evaluated based on the preference regions. We apply the proposed model and algorithm to design the bolt supporting network of a practical roadway. The experimental results show that the proposed method can generate an optimal bolt supporting scheme with a good balance between supporting quality and the other demands, besides speeding up its convergence.},
  archive      = {J_TEVC},
  author       = {Yi-Nan Guo and Xu Zhang and Dun-Wei Gong and Zhen Zhang and Jian-Jian Yang},
  doi          = {10.1109/TEVC.2019.2951217},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {750-764},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Novel interactive preference-based multiobjective evolutionary optimization for bolt supporting networks},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Surrogate-assisted robust optimization of large-scale
networks based on graph embedding. <em>TEVC</em>, <em>24</em>(4),
735–749. (<a href="https://doi.org/10.1109/TEVC.2019.2950935">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust optimization of complex networks has attracted much attention in recent years. Although existing methods have been successful in achieving promising results, the computational cost for robust optimization tasks is extremely high, which prevents them from being further applied to large-scale networks. Thus, computationally efficient robust optimization methods are in high demand. This article proposes a low-cost method for estimating the robustness of networks with the help of graph embedding techniques and surrogate models. An evolutionary algorithm is then developed to find large-scale robust networks by combining the surrogate-assisted low-cost robustness estimator with the time-consuming real robustness measure by means of a model management strategy. The experimental results on different kinds of synthetic and real networks demonstrate the highly competitive search ability of the proposed algorithm. In addition, the algorithm is able to save up to 80\% of the computation time for enhancing the robustness of large-scale networks compared with the state-of-the-art methods.},
  archive      = {J_TEVC},
  author       = {Shuai Wang and Jing Liu and Yaochu Jin},
  doi          = {10.1109/TEVC.2019.2950935},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {735-749},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Surrogate-assisted robust optimization of large-scale networks based on graph embedding},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). A framework to handle multimodal multiobjective
optimization in decomposition-based evolutionary algorithms.
<em>TEVC</em>, <em>24</em>(4), 720–734. (<a
href="https://doi.org/10.1109/TEVC.2019.2949841">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal multiobjective optimization is to locate (almost) equivalent Pareto optimal solutions as many as possible. While decomposition-based evolutionary algorithms have good performance for multiobjective optimization, they are likely to perform poorly for multimodal multiobjective optimization due to the lack of mechanisms to maintain the solution space diversity. To address this issue, this article proposes a framework to improve the performance of decomposition-based evolutionary algorithms for multimodal multiobjective optimization. Our framework is based on three operations: 1) assignment; 2) deletion; and 3) addition operations. One or more individuals can be assigned to the same subproblem to handle multiple equivalent solutions. In each iteration, a child is assigned to a subproblem based on its objective vector, i.e., its location in the objective space. The child is compared with its neighbors in the solution space assigned to the same subproblem. The performance of improved versions of six decomposition-based evolutionary algorithms by our framework is evaluated on various test problems regarding the number of objectives, decision variables, and equivalent Pareto optimal solution sets. Results show that the improved versions perform clearly better than their original algorithms.},
  archive      = {J_TEVC},
  author       = {Ryoji Tanabe and Hisao Ishibuchi},
  doi          = {10.1109/TEVC.2019.2949841},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {720-734},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A framework to handle multimodal multiobjective optimization in decomposition-based evolutionary algorithms},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Distributed individuals for multiple peaks: A novel
differential evolution for multimodal optimization problems.
<em>TEVC</em>, <em>24</em>(4), 708–719. (<a
href="https://doi.org/10.1109/TEVC.2019.2944180">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Locating more peaks and refining the solution accuracy on the found peaks are two challenging issues in solving multimodal optimization problems (MMOPs). To deal with these two challenges, a distributed individuals differential evolution (DIDE) algorithm is proposed in this article based on a distributed individuals for multiple peaks (DIMP) framework and two novel mechanisms. First, the DIMP framework provides sufficient diversity by letting each individual act as a distributed unit to track a peak. Based on the DIMP framework, each individual uses a virtual population controlled by an adaptive range adjustment strategy to explore the search space sufficiently for locating a peak and then gradually approach it. Second, the two novel mechanisms named lifetime mechanism and elite learning mechanism (ELM) cooperate with the DIMP framework. The lifetime mechanism is inspired by the natural phenomenon that every organism will gradually age and has a limited lifespan. When an individual runs out of its lifetime and also has good fitness, it is regarded as an elite solution and will be added to an archive. Then the individual restarts a new lifetime, so as to bring further diversity to locate more peaks. The ELM is proposed to refine the accuracy of those elite solutions in the archive, being efficient in dealing with the solution accuracy issue on the found peaks. The experimental results on 20 multimodal benchmark test functions show that the proposed DIDE algorithm has generally better or competitive performance compared with the state-of-the-art multimodal optimization algorithms.},
  archive      = {J_TEVC},
  author       = {Zong-Gan Chen and Zhi-Hui Zhan and Hua Wang and Jun Zhang},
  doi          = {10.1109/TEVC.2019.2944180},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {708-719},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Distributed individuals for multiple peaks: A novel differential evolution for multimodal optimization problems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Distributed pareto optimization for large-scale noisy subset
selection. <em>TEVC</em>, <em>24</em>(4), 694–707. (<a
href="https://doi.org/10.1109/TEVC.2019.2929555">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subset selection, aiming to select the best subset from a ground set with respect to some objective function, is a fundamental problem with applications in many areas, such as combinatorial optimization, machine learning, data mining, computer vision, information retrieval, etc. Along with the development of data collection and storage, the size of the ground set grows larger. Furthermore, in many subset selection applications, the objective function evaluation is subject to noise. We thus study the large-scale noisy subset selection problem in this paper. The recently proposed DPOSS algorithm based on multiobjective evolutionary optimization is a powerful distributed solver for large-scale subset selection. Its performance, however, has been only validated in the noise-free environment. In this paper, we first prove its approximation guarantee under two common noise models, i.e., multiplicative noise and additive noise, disclosing that the presence of noise degrades the performance of DPOSS largely. Next, we propose a new distributed multiobjective evolutionary algorithm called DPONSS for large-scale noisy subset selection. We prove that the approximation guarantee of DPONSS under noise is significantly better than that of DPOSS. We also conduct experiments on the application of sparse regression, where the objective evaluation is often estimated using a sample data, bringing noise. The results on various real-world data sets, whose size can reach millions, clearly show the excellent performance of DPONSS.},
  archive      = {J_TEVC},
  author       = {Chao Qian},
  doi          = {10.1109/TEVC.2019.2929555},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {694-707},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Distributed pareto optimization for large-scale noisy subset selection},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A data-driven parallel scheduling approach for multiple
agile earth observation satellites. <em>TEVC</em>, <em>24</em>(4),
679–693. (<a href="https://doi.org/10.1109/TEVC.2019.2934148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the large-scale and time-consuming multiple agile earth observation satellite (multi-AEOS) scheduling problems, this article proposes a data-driven parallel scheduling approach, which is composed of a probability prediction model, a task assignment strategy, and a parallel scheduling manner. In this approach, given the historical data of satellite scheduling, a prediction model is trained based on the cooperative neuro-evolution of augmenting topologies (C-NEAT) to predict the probabilities that a task will be fulfilled by different satellites. Driven by the probability prediction model, an assignment strategy is adopted for dividing the multi-AEOS scheduling problem into several single-AEOS scheduling subproblems, which can adaptively assign each task to the satellite with the highest predicted probability and greatly decrease the problem size. In a parallel manner, the single-AEOS scheduling subproblems are optimized, respectively, leading to an acceleration in the optimization efficiency of the original problem. Computational experiments indicate that the proposed approach presents better overall performance than other state-of-the-art methods within a very limited scheduling time. As the two main components of the proposed approach, the prediction model based on C-NEAT and the task assignment strategy also outperform other models with traditional training algorithms and inadaptive assignment strategies, respectively.},
  archive      = {J_TEVC},
  author       = {Yonghao Du and Tao Wang and Bin Xin and Ling Wang and Yingguo Chen and Lining Xing},
  doi          = {10.1109/TEVC.2019.2934148},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {679-693},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A data-driven parallel scheduling approach for multiple agile earth observation satellites},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficacy of the metropolis algorithm for the minimum-weight
codeword problem using codeword and generator search spaces.
<em>TEVC</em>, <em>24</em>(4), 664–678. (<a
href="https://doi.org/10.1109/TEVC.2020.2980111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article studies the efficacy of the Metropolis algorithm for the minimum-weight codeword problem. The input is a linear code C given by its generator matrix and our task is to compute a nonzero codeword in the code C of least weight. In particular, we study the Metropolis algorithm on two possible search spaces for the problem: 1) the codeword space and 2) the generator space. The former is the space of all codewords of the input code and is the most natural one to use and hence has been used in previous work on this problem. The latter is the space of all generator matrices of the input code and is studied for the first time in this article. In this article, we show that for an appropriately chosen temperature parameter the Metropolis algorithm mixes rapidly when either of the search spaces mentioned above are used. Experimentally, we demonstrate that the Metropolis algorithm performs favorably when compared to previous attempts. When using the generator space, the Metropolis algorithm is able to outperform the previous algorithms in most of the cases. We have also provided both theoretical and experimental justification to show why the generator space is a worthwhile search space to use for this problem.},
  archive      = {J_TEVC},
  author       = {K. B. Ajitha Shenoy and Somenath Biswas and Piyush P. Kurur},
  doi          = {10.1109/TEVC.2020.2980111},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {664-678},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Efficacy of the metropolis algorithm for the minimum-weight codeword problem using codeword and generator search spaces},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Self-adaptation in nonelitist evolutionary algorithms on
discrete problems with unknown structure. <em>TEVC</em>, <em>24</em>(4),
650–663. (<a href="https://doi.org/10.1109/TEVC.2020.2985450">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A key challenge to make effective use of evolutionary algorithms (EAs) is to choose appropriate settings for their parameters. However, the appropriate parameter setting generally depends on the structure of the optimization problem, which is often unknown to the user. Nondeterministic parameter control mechanisms adjust parameters using information obtained from the evolutionary process. Self-adaptation-where parameter settings are encoded in the chromosomes of individuals and evolve through mutation and crossover-is a popular parameter control mechanism in evolutionary strategies. However, there is little theoretical evidence that self-adaptation is effective, and self-adaptation has largely been ignored by the discrete evolutionary computation community. Here, we show through a theoretical runtime analysis that a nonelitist, discrete EA which self-adapts its mutation rate not only outperforms EAs which use static mutation rates on LEADINGONESk but also improves asymptotically on an EA using a state-of-the-art control mechanism. The structure of this problem depends on a parameter k, which is a priori unknown to the algorithm, and which is needed to appropriately set a fixed mutation rate. The self-adaptive EA achieves the same asymptotic runtime as if this parameter was known to the algorithm beforehand, which is an asymptotic speedup for this problem compared to all other EAs previously studied. An experimental study of how the mutation-rates evolve show that they respond adequately to a diverse range of problem structures. These results suggest that self-adaptation should be adopted more broadly as a parameter control mechanism in discrete, nonelitist EAs.},
  archive      = {J_TEVC},
  author       = {Brendan Case and Per Kristian Lehre},
  doi          = {10.1109/TEVC.2020.2985450},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {650-663},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Self-adaptation in nonelitist evolutionary algorithms on discrete problems with unknown structure},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey of weight vector adjustment methods for
decomposition-based multiobjective evolutionary algorithms.
<em>TEVC</em>, <em>24</em>(4), 634–649. (<a
href="https://doi.org/10.1109/TEVC.2020.2978158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiobjective evolutionary algorithms based on decomposition (MOEA/D) have attracted tremendous attention and achieved great success in the fields of optimization and decision-making. MOEA/Ds work by decomposing the target multiobjective optimization problem (MOP) into multiple single-objective subproblems based on a set of weight vectors. The subproblems are solved cooperatively in an evolutionary algorithm framework. Since weight vectors define the search directions and, to a certain extent, the distribution of the final solution set, the configuration of weight vectors is pivotal to the success of MOEA/Ds. The most straightforward method is to use predefined and uniformly distributed weight vectors. However, it usually leads to the deteriorated performance of MOEA/Ds on solving MOPs with irregular Pareto fronts. To deal with this issue, many weight vector adjustment methods have been proposed by periodically adjusting the weight vectors in a random, predefined, or adaptive way. This article focuses on weight vector adjustment on a simplex and presents a comprehensive survey of these weight vector adjustment methods covering the weight vector adaptation strategies, theoretical analyses, benchmark test problems, and applications. The current limitations, new challenges, and future directions of weight vector adjustment are also discussed.},
  archive      = {J_TEVC},
  author       = {Xiaoliang Ma and Yanan Yu and Xiaodong Li and Yutao Qi and Zexuan Zhu},
  doi          = {10.1109/TEVC.2020.2978158},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {634-649},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A survey of weight vector adjustment methods for decomposition-based multiobjective evolutionary algorithms},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evolutionary black-box topology optimization: Challenges and
promises. <em>TEVC</em>, <em>24</em>(4), 613–633. (<a
href="https://doi.org/10.1109/TEVC.2019.2954411">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Black-box topology optimization (BBTO) uses evolutionary algorithms and other soft computing techniques to generate near-optimal topologies of mechanical structures. Although evolutionary algorithms are widely used to compensate the limited applicability of conventional gradient optimization techniques, methods based on BBTO have been criticized due to numerous drawbacks. In this article, we discuss topology optimization as a black-box optimization problem. We review the main BBTO methods, discuss their challenges and present approaches to relax them. Dealing with those challenges effectively can lead to wider applicability of topology optimization, as well as the ability to tackle industrial, highly constrained, nonlinear, many-objective, and multimodal problems. Consequently, future research in this area may open the door for innovating new applications in science and engineering that may go beyond solving classical optimization problems of mechanical structures. Furthermore, algorithms designed for BBTO can be added to existing software toolboxes and packages of topology optimization.},
  archive      = {J_TEVC},
  author       = {David Guirguis and Nikola Aulig and Renato Picelli and Bo Zhu and Yuqing Zhou and William Vicente and Francesco Iorio and Markus Olhofer and Wojciech Matusik and Carlos Artemio Coello Coello and Kazuhiro Saitou},
  doi          = {10.1109/TEVC.2019.2954411},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {613-633},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolutionary black-box topology optimization: Challenges and promises},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020d). IEEE transactions on evolutionary computation society
information. <em>TEVC</em>, <em>24</em>(3), C3. (<a
href="https://doi.org/10.1109/TEVC.2020.2994569">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Presents a listing of the editorial board, board of governors, current staff, committee members, and/or society editors for this issue of the publication.},
  archive      = {J_TEVC},
  doi          = {10.1109/TEVC.2020.2994569},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {C3},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {IEEE transactions on evolutionary computation society information},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020d). Introducing IEEE collabratec. <em>TEVC</em>,
<em>24</em>(3), 612. (<a
href="https://doi.org/10.1109/TEVC.2020.2994571">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advertisement, IEEE. IEEE Collabratec is a new, integrated online community where IEEE members, researchers, authors, and technology professionals with similar fields of interest can network and collaborate, as well as create and manage content. Featuring a suite of powerful online networking and collaboration tools, IEEE Collabratec allows you to connect according to geographic location, technical interests, or career pursuits. You can also create and share a professional identity that showcases key accomplishments and participate in groups focused around mutual interests, actively learning from and contributing to knowledgeable communities. All in one place! Learn about IEEE Collabratec at ieeecollabratec.org.},
  archive      = {J_TEVC},
  doi          = {10.1109/TEVC.2020.2994571},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {612},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Introducing IEEE collabratec},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Understanding hypervolume behavior theoretically for
benchmarking in evolutionary multi/many-objective optimization.
<em>TEVC</em>, <em>24</em>(3), 603–610. (<a
href="https://doi.org/10.1109/TEVC.2019.2931191">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hypervolume (HV) is one of the most commonly used metrics for evaluating the Pareto front (PF) approximations generated by multiobjective evolutionary algorithms. Even so, HV is a resultant of a complex interplay between the PF shape, number of objectives, and user-specified reference points which, if not well understood, may lead to misinformed inferences about benchmarking performance. In order to understand this behavior, some previous studies have investigated such interactions empirically. In this letter, a new and unconventional approach is taken for gaining further insights about HV behavior. The key idea is to develop theoretical formulas for certain linear (equilateral simplex) and quadratic (orthant) PFs in two specific orientations: 1) regular and 2) inverted. These PFs represent a large number of problems in the existing DTLZ and WFG suites commonly used for benchmarking. The numerical experiments are presented to demonstrate the utility of the proposed work in benchmarking, and in understanding the contributions of the different regions of the PFs, such as corners, edges, as well explaining the contrast between the HV behaviors for regular versus inverted PFs. This letter provides a foundation and computationally fast means to undertake parametric studies to understand various aspects of HV.},
  archive      = {J_TEVC},
  author       = {Hemant Kumar Singh},
  doi          = {10.1109/TEVC.2019.2931191},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {603-610},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Understanding hypervolume behavior theoretically for benchmarking in evolutionary Multi/Many-objective optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Analysis of the <span
class="math inline">(<em>μ</em>/<em>μ</em><sub><em>I</em></sub>, <em>λ</em>) − <em>σ</em></span>
-self-adaptation evolution strategy with repair by projection applied to
a conically constrained problem. <em>TEVC</em>, <em>24</em>(3), 593–602.
(<a href="https://doi.org/10.1109/TEVC.2019.2930316">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A theoretical performance analysis of the (μ/μI, λ)σ-self-adaptation evolution strategy (σSA-ES) is presented considering a conically constrained problem. Infeasible offspring are repaired using projection onto the boundary of the feasibility region. Closed-form approximations are used for the one-generation progress of the evolution strategy. Approximate deterministic evolution equations are formulated for analyzing the strategy&#39;s dynamics. By iterating the evolution equations with the approximate one-generation expressions, the evolution strategy&#39;s dynamics can be predicted. The derived theoretical results are compared to experiments for assessing the approximation quality. It is shown that in the steady state the (μ/μI, λ)σSA-ES exhibits a performance as if the ES were optimizing a sphere model. Unlike the nonrecombinative (1, λ)-ES, the parental steady state behavior does not evolve on the cone boundary but stays away from the boundary to a certain extent.},
  archive      = {J_TEVC},
  author       = {Patrick Spettel and Hans-Georg Beyer},
  doi          = {10.1109/TEVC.2019.2930316},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {593-602},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Analysis of the $(\mu/\mu_{I},\lambda)-\sigma$ -self-adaptation evolution strategy with repair by projection applied to a conically constrained problem},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Runtime analysis of crowding mechanisms for multimodal
optimization. <em>TEVC</em>, <em>24</em>(3), 581–592. (<a
href="https://doi.org/10.1109/TEVC.2019.2914606">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real-world optimization problems lead to multimodal domains and require the identification of multiple optima. Crowding methods have been developed to maintain population diversity, to investigate many peaks in parallel and to reduce genetic drift. We present the first rigorous runtime analyses of probabilistic crowding and generalized crowding, embedded in a (μ +1) EA. In probabilistic crowding the offspring compete with their parent in a fitness-proportional selection. Generalized crowding decreases the fitness of the inferior solution by a scaling factor during selection. We consider the bimodal function TwoMax and introduce a novel and natural notion for functions with bounded gradients. For a broad range of such functions we prove that probabilistic crowding needs exponential time with overwhelming probability to find solutions significantly closer to any global optimum than those found by random search. Even when the fitness function is scaled exponentially, probabilistic crowding still fails badly. Only if the exponential&#39;s base is linear in the problem size, probabilistic crowding becomes efficient on TwoMax. A similar threshold behavior holds for generalized crowding on TwoMax with respect to the scaling factor. Our theoretical results are accompanied by experiments for TwoMax showing that the threshold behaviors also apply to the best fitness found.},
  archive      = {J_TEVC},
  author       = {Edgar Covantes Osuna and Dirk Sudholt},
  doi          = {10.1109/TEVC.2019.2914606},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {581-592},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Runtime analysis of crowding mechanisms for multimodal optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A divide-and-conquer evolutionary algorithm for large-scale
virtual network embedding. <em>TEVC</em>, <em>24</em>(3), 566–580. (<a
href="https://doi.org/10.1109/TEVC.2019.2941824">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The subgraph isomorphism problems, which aim to map subgraphs to a given graph, are widely seen in many applications and are usually nondeterministic polynomial-time complete (NP-complete). As a representative extension of the subgraph isomorphism problem, virtual network embedding (VNE) is a key problem in datacenter scheduling and network virtualization. Existing metaheuristic approaches to VNE problems tend to schedule networks as a whole. But when the problem scale grows, the performance of these approaches may degenerate due to the curse of dimensionality. In this article, we intend to propose a divide-and-conquer evolutionary algorithm with overlapping decomposition (ODEA) to solve large-scale VNE problems. First, realizing the fact that the decision variables in graph-based optimization problems like VNE are usually nonseparable, an overlapping decomposition method is introduced by investigating the characteristic of the network structure. In this method, the critical elements which have tight connections to many other nodes can belong to multiple subcomponents. As a result, the decision variables with tight connections can always be evolved together in multiple subcomponents. Second, to combine the subsolutions into a complete feasible solution, a competitive strategy is devised. Through the competition among critical elements, the optimizing information is shared among subcomponents, which can further improve the effectiveness of ODEA. The proposed ODEA can adopt different metaheuristics as the optimizer, and we conduct experiments on both the scenarios with a single virtual network and with a series of online networks. The experimental results verify that ODEA can significantly improve the performance of different metaheuristics in large-scale VNE problems.},
  archive      = {J_TEVC},
  author       = {An Song and Wei-Neng Chen and Yue-Jiao Gong and Xiaonan Luo and Jun Zhang},
  doi          = {10.1109/TEVC.2019.2941824},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {566-580},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A divide-and-conquer evolutionary algorithm for large-scale virtual network embedding},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Handling imbalance between convergence and diversity in the
decision space in evolutionary multimodal multiobjective optimization.
<em>TEVC</em>, <em>24</em>(3), 551–565. (<a
href="https://doi.org/10.1109/TEVC.2019.2938557">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There may exist more than one Pareto optimal solution with the same objective vector to a multimodal multiobjective optimization problem (MMOP). The difficulties in finding such solutions can be different. Although a number of evolutionary multimodal multiobjective algorithms (EMMAs) have been proposed, they are unable to solve such an MMOP due to their convergence-first selection criteria. They quickly converge to the Pareto optimal solutions which are easy to find and therefore lose diversity in the decision space. That is, such an MMOP features an imbalance between achieving convergence and preserving diversity in the decision space. In this article, we first present a set of imbalanced distance minimization benchmark problems. Then we propose an evolutionary algorithm using a convergence-penalized density method (CPDEA). In CPDEA, the distances among solutions in the decision space are transformed based on their local convergence quality. Their density values are estimated based on the transformed distances and used as the selection criterion. We compare CPDEA with five state-of-the-art EMMAs on the proposed benchmarks. Our experimental results show that CPDEA is clearly superior in solving these problems.},
  archive      = {J_TEVC},
  author       = {Yiping Liu and Hisao Ishibuchi and Gary G. Yen and Yusuke Nojima and Naoki Masuyama},
  doi          = {10.1109/TEVC.2019.2938557},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {551-565},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Handling imbalance between convergence and diversity in the decision space in evolutionary multimodal multiobjective optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Underestimation-assisted global-local cooperative
differential evolution and the application to protein structure
prediction. <em>TEVC</em>, <em>24</em>(3), 536–550. (<a
href="https://doi.org/10.1109/TEVC.2019.2938531">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various mutation strategies show distinct advantages in differential evolution (DE). The cooperation of multiple strategies in the evolutionary process may be effective. This article presents an underestimation-assisted global and local cooperative DE to simultaneously enhance the effectiveness and efficiency. In the proposed algorithm, two phases, namely, the global exploration and the local exploitation, are performed in each generation. In the global phase, a set of trial vectors is produced for each target individual by employing multiple strategies with strong exploration capability. Afterward, an adaptive underestimation model with an self-adapted slope control parameter is proposed to evaluate these trial vectors, the best of which is selected as the candidate. In the local phase, the better-based strategies guided by individuals that are better than the target individual are designed. For each individual accepted in the global phase, multiple trial vectors are generated by using these strategies and filtered by the underestimation value. The cooperation between the global and local phases includes two aspects. First, both of them concentrate on generating better individuals for the next generation. Second, the global phase aims to locate promising regions quickly while the local phase serves as a local search for enhancing convergence. Moreover, a simple mechanism is designed to determine the parameter of DE adaptively in the searching process. Finally, the proposed approach is applied to predict the protein 3-D structure. The experimental studies on classical benchmark functions, CEC test sets, and protein structure prediction problem show that the proposed approach is superior to the competitors.},
  archive      = {J_TEVC},
  author       = {Xiao-Gen Zhou and Chun-Xiang Peng and Jun Liu and Yang Zhang and Gui-Jun Zhang},
  doi          = {10.1109/TEVC.2019.2938531},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {536-550},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Underestimation-assisted global-local cooperative differential evolution and the application to protein structure prediction},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evolutionary network embedding preserving both local
proximity and community structure. <em>TEVC</em>, <em>24</em>(3),
523–535. (<a href="https://doi.org/10.1109/TEVC.2019.2937455">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complex network is an important tool to represent relational data in nature and human society, which has been widely applied in various real-world application scenarios. A key issue for analyzing the features of networks is to represent the characteristic information in the network with rationality. Network embedding, attracting plenty of attention recently, aims to convert network information into a low-dimensional space while maintaining the structure and properties of the network maximally. Most of the existing network embedding methods intend to preserve the pairwise relationship or similarity between nodes, but the community structure, which is one of the most important features of complex networks, is largely ignored. In this article, we propose a novel network embedding method based on evolutionary algorithm (EA), termed as EA-NECommunity, which can preserve both the local proximity of nodes and the community structure of the network by optimizing a carefully designed objective function. The number of communities in the network can be automatically determined without any prior knowledge. Moreover, taking the intrinsic properties of the network embedding problems in mind, we design a local search operator based on multidirectional search which can effectively find feasible solutions. In the experiments, we first visualize the embedding representation obtained by different algorithms, and then use the problems of node clustering, node classification, and link prediction to further validate the quality of the embedding representation obtained. The experimental results show that EA-NECommunity outperforms other state-of-the-art algorithms on both the real life and synthetic networks.},
  archive      = {J_TEVC},
  author       = {Mingming Li and Jing Liu and Peng Wu and Xiangyi Teng},
  doi          = {10.1109/TEVC.2019.2937455},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {523-535},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolutionary network embedding preserving both local proximity and community structure},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A niching memetic algorithm for multi-solution traveling
salesman problem. <em>TEVC</em>, <em>24</em>(3), 508–522. (<a
href="https://doi.org/10.1109/TEVC.2019.2936440">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-solution problems extensively exist in practice. Particularly, the traveling salesman problem (TSP) may possess multiple shortest tours, from which travelers can choose one according to their specific requirements. However, very few efforts have been devoted to the multi-solution problems in the discrete domain. In order to fill this research gap and to effectively tackle the multi-solution TSP, we propose a niching memetic algorithm in this article. The proposed algorithm is characterized by a niche preservation technique to enable the parallel search of multiple optimal solutions; an adaptive neighborhood strategy to balance the exploration and exploitation; a critical edge-aware method to provide effective guidance to the reproduction; and a selective local search strategy to improve the search efficiency. To evaluate the performance of the proposed algorithm, we conduct comprehensive experiments on a recently published multi-solution optimization test suite. The experimental results show that our algorithm outperforms other compared algorithms. Furthermore, the proposed algorithm is adopted to tackle problems from the well-known TSPLIB library to obtain a set of distinct but good solutions.},
  archive      = {J_TEVC},
  author       = {Ting Huang and Yue-Jiao Gong and Sam Kwong and Hua Wang and Jun Zhang},
  doi          = {10.1109/TEVC.2019.2936440},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {508-522},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A niching memetic algorithm for multi-solution traveling salesman problem},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evolutionary multiobjective optimization with robustness
enhancement. <em>TEVC</em>, <em>24</em>(3), 494–507. (<a
href="https://doi.org/10.1109/TEVC.2019.2933444">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncertainty is an important feature abstracted from real-world applications. Multiobjective optimization problems (MOPs) with uncertainty can always be characterized as robust MOPs (RMOPs). Over recent years, multiobjective optimization evolutionary algorithms (EAs) have demonstrated the success in solving MOPs. However, most of them do not consider disturbance in the design. In order to handling the uncertainty in the optimization problem, we first give a thorough analysis of three important issues on robust optimization. Then, a novel EA called multiobjective optimization EA with robustness enhancement is developed, where the seamless integration of robustness and optimality is achieved by a proposed novel archive updating mechanism applied on the evolutionary process as well as the new robust optimal front building strategy designed to construct the final robust optimal front. Furthermore, the new designed archive updating mechanism makes the robust optimization process free of the enormous computational workload induced from sampling. The experimental results on a set of benchmark functions show the superiority of the proposed design in terms of both solutions&#39; quality under the disturbance and computational efficiency in solving RMOPs.},
  archive      = {J_TEVC},
  author       = {Zhenan He and Gary G. Yen and Jiancheng Lv},
  doi          = {10.1109/TEVC.2019.2933444},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {494-507},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolutionary multiobjective optimization with robustness enhancement},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An estimation of distribution algorithm for mixed-variable
newsvendor problems. <em>TEVC</em>, <em>24</em>(3), 479–493. (<a
href="https://doi.org/10.1109/TEVC.2019.2932624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of the classical problems in the economic market, the newsvendor problem aims to make maximal profit by determining the optimal order quantity of products. However, the previous newsvendor models assume that the selling price of a product is a predefined constant and only regard the order quantity as a decision variable, which may result in an unreasonable investment decision. In this article, a new newsvendor model is first proposed, which involves of both order quantity and selling price as decision variables. In this way, the newsvendor problem is reformulated as a mixed-variable nonlinear programming problem, rather than an integer linear programming problem as in previous investigations. In order to solve the mixed-variable newsvendor problem, a histogram model-based estimation of distribution algorithm (EDA) called EDA mvn is developed, in which an adaptive-width histogram model is used to deal with the continuous variables and a learning-based histogram model is applied to deal with the discrete variables. The performance of EDAmvn was assessed on a test suite with eight representative instances generated by the orthogonal experiment design method and a real-world instance generated from real market data of Alibaba. The experimental results show that, EDA mvn outperforms not only the state-of-the-art mixed-variable evolutionary algorithms, but also a commercial software, i.e., Lingo.},
  archive      = {J_TEVC},
  author       = {Feng Wang and Yixuan Li and Aimin Zhou and Ke Tang},
  doi          = {10.1109/TEVC.2019.2932624},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {479-493},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {An estimation of distribution algorithm for mixed-variable newsvendor problems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Data structures for direct spanning tree representations in
mutation-based evolutionary algorithms. <em>TEVC</em>, <em>24</em>(3),
467–478. (<a href="https://doi.org/10.1109/TEVC.2019.2928991">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimization methods for spanning tree problems may require efficient data structures. The node-depth-degree representation (NDDR) has achieved relevant results for direct spanning tree representation together with evolutionary algorithms (EAs). Its two mutation operators have average time O(√n), where n is the number of vertices of the graph, while similar operators implemented by predecessor arrays, a typical tree data structure, have time O(n). Dynamic trees are also relevant when investigating tree representations since they have low time complexity, but there is no proper extension of them for EAs. Using aspects of both a dynamic tree and NDDR, namely, Euler tours and structural sharing, we propose a data structure called 2LETT, whose mutation operators have time O(√n) in the worst case. Experiments with the mutation operators using 2LETT, predecessor arrays, and NDDR are carried out for graphs with up to 300000 vertices. For a mutation operator that exchanges any two valid edges, predecessor arrays present the best performance for random trees with fewer than 10000 vertices; while 2LETT has the best performance for trees with more than 10000 vertices. Especially, noteworthy is the fact that 2LETT is the only structure whose running time is independent of tree diameter.},
  archive      = {J_TEVC},
  author       = {Marco Aurélio Lopes Barbosa and Alexandre C. B. Delbem and Letícia R. Bueno},
  doi          = {10.1109/TEVC.2019.2928991},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {467-478},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Data structures for direct spanning tree representations in mutation-based evolutionary algorithms},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Feature extraction and selection for parsimonious
classifiers with multiobjective genetic programming. <em>TEVC</em>,
<em>24</em>(3), 454–466. (<a
href="https://doi.org/10.1109/TEVC.2019.2927526">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objectives of this paper are to investigate the capability of genetic programming to select and extract linearly separable features when the evolutionary process is guided to achieve the same and to propose an integrated system for that. We decompose a c-class problem into c binary classification problems and evolve c sets of binary classifiers employing a steady-state multiobjective genetic programming with three minimizing objectives. Each binary classifier is composed of a binary tree and a linear support vector machine (SVM). The features extracted by the feature nodes and some of the function nodes of the tree are used to train the SVM. The decision made by the SVM is considered the decision of the corresponding classifier. During crossover and mutation, the SVM-weights are used to determine the usefulness of the corresponding nodes. We also use a fitness function based on Golub&#39;s index to select useful features. To discard less frequently used features, we employ unfitness functions for the feature nodes. We compare our method with 34 classification systems using 18 datasets. The performance of the proposed method is found to be better than 432 out of 570, i.e., 75.79\% of comparing cases. Our results confirm that the proposed method is capable of achieving our objectives.},
  archive      = {J_TEVC},
  author       = {Kaustuv Nag and Nikhil R. Pal},
  doi          = {10.1109/TEVC.2019.2927526},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {454-466},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Feature extraction and selection for parsimonious classifiers with multiobjective genetic programming},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adapting reference vectors and scalarizing functions by
growing neural gas to handle irregular pareto fronts. <em>TEVC</em>,
<em>24</em>(3), 439–453. (<a
href="https://doi.org/10.1109/TEVC.2019.2926151">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of decomposition-based multiobjective evolutionary algorithms (MOEAs) often deteriorates clearly when solving multiobjective optimization problems with irregular Pareto fronts (PFs). The main reason is the improper settings of reference vectors and scalarizing functions. In this paper, we propose a decomposition-based MOEA guided by a growing neural gas network, which learns the topological structure of the PF. Both reference vectors and scalarizing functions are adapted based on the topological structure to enhance the evolutionary algorithm&#39;s search ability. The proposed algorithm is compared with eight state-of-the-art optimizers on 34 test problems. The experimental results demonstrate that the proposed method is competitive in handling irregular PFs.},
  archive      = {J_TEVC},
  author       = {Yiping Liu and Hisao Ishibuchi and Naoki Masuyama and Yusuke Nojima},
  doi          = {10.1109/TEVC.2019.2926151},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {439-453},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Adapting reference vectors and scalarizing functions by growing neural gas to handle irregular pareto fronts},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multisource selective transfer framework in multiobjective
optimization problems. <em>TEVC</em>, <em>24</em>(3), 424–438. (<a
href="https://doi.org/10.1109/TEVC.2019.2926107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For complex system design [e.g., satellite layout optimization design (SLOD)] in practical engineering, when launching a new optimization instance with another parameter configuration from the intuition of designers, it is always executed from scratch which wastes much time to repeat the similar search process. Inspired by transfer learning which can reuse past experiences to solve relevant tasks, many researchers pay more attention to explore how to learn from past optimization instances to accelerate the target one. In real-world applications, there have been numerous similar source instances stored in the database. The primary question is how to measure the transferability from numerous sources to avoid the notorious negative transferring. To obtain the relatedness between source and target instance, we develop an optimization instance representation method named centroid distribution, which is by the aid of the probabilistic model learned by elite candidate solutions in estimation of distribution algorithm (EDA) during the evolutionary process. Wasserstein distance is employed to evaluate the similarity between the centroid distributions of different optimization instances, based on which, we present a novel framework called multisource selective transfer optimization with three strategies to select sources reasonably. To choose the suitable strategy, four selection suggestions are summarized according to the similarity between the source and target centroid distribution. The framework is beneficial to choose the most suitable sources, which could improve the search efficiency in solving multiobjective optimization problems. To evaluate the effectiveness of the proposed framework and selection suggestions, we conduct two experiments: 1) comprehensive empirical studies on complex multiobjective optimization problem benchmarks and 2) a real-world SLOD problem. Suggestions for strategy selection coincide with the experiment results, based on which, we propose a mixed strategy to deal with the negative transfer in the experiments successfully. The results demonstrate that our proposed framework achieves competitive performance on most of the benchmark problems in convergence speed and hypervolume values and performs best on the real-world applications among all the comparison algorithms.},
  archive      = {J_TEVC},
  author       = {Jun Zhang and Weien Zhou and Xianqi Chen and Wen Yao and Lu Cao},
  doi          = {10.1109/TEVC.2019.2926107},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {424-438},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Multisource selective transfer framework in multiobjective optimization problems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Offline data-driven multiobjective optimization: Knowledge
transfer between surrogates and generation of final solutions.
<em>TEVC</em>, <em>24</em>(3), 409–423. (<a
href="https://doi.org/10.1109/TEVC.2019.2925959">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In offline data-driven optimization, only historical data is available for optimization, making it impossible to validate the obtained solutions during the optimization. To address these difficulties, this paper proposes an evolutionary algorithm assisted by two surrogates, one coarse model and one fine model. The coarse surrogate (CS) aims to guide the algorithm to quickly find a promising subregion in the search space, whereas the fine one focuses on leveraging good solutions according to the knowledge transferred from the CS. Since the obtained Pareto optimal solutions have not been validated using the real fitness function, a technique for generating the final optimal solutions is suggested. All achieved solutions during the whole optimization process are grouped into a number of clusters according to a set of reference vectors. Then, the solutions in each cluster are averaged and outputted as the final solution of that cluster. The proposed algorithm is compared with its three variants and two state-of-the-art offline data-driven multiobjective algorithms on eight benchmark problems to demonstrate its effectiveness. Finally, the proposed algorithm is successfully applied to an operational indices optimization problem in beneficiation processes.},
  archive      = {J_TEVC},
  author       = {Cuie Yang and Jinliang Ding and Yaochu Jin and Tianyou Chai},
  doi          = {10.1109/TEVC.2019.2925959},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {409-423},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Offline data-driven multiobjective optimization: Knowledge transfer between surrogates and generation of final solutions},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020e). IEEE transactions on evolutionary computation society
information. <em>TEVC</em>, <em>24</em>(2), C3. (<a
href="https://doi.org/10.1109/TEVC.2020.2980690">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Presents a listing of the editorial board, board of governors, current staff, committee members, and/or society editors for this issue of the publication.},
  archive      = {J_TEVC},
  doi          = {10.1109/TEVC.2020.2980690},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {C3},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {IEEE transactions on evolutionary computation society information},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020e). Introducing IEEE collabratec. <em>TEVC</em>,
<em>24</em>(2), 408. (<a
href="https://doi.org/10.1109/TEVC.2020.2980692">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advertisement, IEEE. IEEE Collabratec is a new, integrated online community where IEEE members, researchers, authors, and technology professionals with similar fields of interest can network and collaborate, as well as create and manage content. Featuring a suite of powerful online networking and collaboration tools, IEEE Collabratec allows you to connect according to geographic location, technical interests, or career pursuits. You can also create and share a professional identity that showcases key accomplishments and participate in groups focused around mutual interests, actively learning from and contributing to knowledgeable communities. All in one place! Learn about IEEE Collabratec at ieeecollabratec.org.},
  archive      = {J_TEVC},
  doi          = {10.1109/TEVC.2020.2980692},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {408},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Introducing IEEE collabratec},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evolving deep convolutional neural networks for image
classification. <em>TEVC</em>, <em>24</em>(2), 394–407. (<a
href="https://doi.org/10.1109/TEVC.2019.2916183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary paradigms have been successfully applied to neural network designs for two decades. Unfortunately, these methods cannot scale well to the modern deep neural networks due to the complicated architectures and large quantities of connection weights. In this paper, we propose a new method using genetic algorithms for evolving the architectures and connection weight initialization values of a deep convolutional neural network to address image classification problems. In the proposed algorithm, an efficient variable-length gene encoding strategy is designed to represent the different building blocks and the potentially optimal depth in convolutional neural networks. In addition, a new representation scheme is developed for effectively initializing connection weights of deep convolutional neural networks, which is expected to avoid networks getting stuck into local minimum that is typically a major issue in the backward gradient-based optimization. Furthermore, a novel fitness evaluation method is proposed to speed up the heuristic search with substantially less computational resource. The proposed algorithm is examined and compared with 22 existing algorithms on nine widely used image classification tasks, including the state-of-the-art methods. The experimental results demonstrate the remarkable superiority of the proposed algorithm over the state-of-the-art designs in terms of classification error rate and the number of parameters (weights).},
  archive      = {J_TEVC},
  author       = {Yanan Sun and Bing Xue and Mengjie Zhang and Gary G. Yen},
  doi          = {10.1109/TEVC.2019.2916183},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {394-407},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolving deep convolutional neural networks for image classification},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An evolutionary algorithm for large-scale sparse
multiobjective optimization problems. <em>TEVC</em>, <em>24</em>(2),
380–393. (<a href="https://doi.org/10.1109/TEVC.2019.2918140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last two decades, a variety of different types of multiobjective optimization problems (MOPs) have been extensively investigated in the evolutionary computation community. However, most existing evolutionary algorithms encounter difficulties in dealing with MOPs whose Pareto optimal solutions are sparse (i.e., most decision variables of the optimal solutions are zero), especially when the number of decision variables is large. Such large-scale sparse MOPs exist in a wide range of applications, for example, feature selection that aims to find a small subset of features from a large number of candidate features, or structure optimization of neural networks whose connections are sparse to alleviate overfitting. This paper proposes an evolutionary algorithm for solving large-scale sparse MOPs. The proposed algorithm suggests a new population initialization strategy and genetic operators by taking the sparse nature of the Pareto optimal solutions into consideration, to ensure the sparsity of the generated solutions. Moreover, this paper also designs a test suite to assess the performance of the proposed algorithm for large-scale sparse MOPs. The experimental results on the proposed test suite and four application examples demonstrate the superiority of the proposed algorithm over seven existing algorithms in solving large-scale sparse MOPs.},
  archive      = {J_TEVC},
  author       = {Ye Tian and Xingyi Zhang and Chao Wang and Yaochu Jin},
  doi          = {10.1109/TEVC.2019.2918140},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {380-393},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {An evolutionary algorithm for large-scale sparse multiobjective optimization problems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient generalized surrogate-assisted evolutionary
algorithm for high-dimensional expensive problems. <em>TEVC</em>,
<em>24</em>(2), 365–379. (<a
href="https://doi.org/10.1109/TEVC.2019.2919762">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Engineering optimization problems usually involve computationally expensive simulations and many design variables. Solving such problems in an efficient manner is still a major challenge. In this paper, a generalized surrogate-assisted evolutionary algorithm is proposed to solve such high-dimensional expensive problems. The proposed algorithm is based on the optimization framework of the genetic algorithm (GA). This algorithm proposes to use a surrogate-based trust region local search method, a surrogate-guided GA (SGA) updating mechanism with a neighbor region partition strategy and a prescreening strategy based on the expected improvement infilling criterion of a simplified Kriging in the optimization process. The SGA updating mechanism is a special characteristic of the proposed algorithm. This mechanism makes a fusion between surrogates and the evolutionary algorithm. The neighbor region partition strategy effectively retains the diversity of the population. Moreover, multiple surrogates used in the SGA updating mechanism make the proposed algorithm optimize robustly. The proposed algorithm is validated by testing several high-dimensional numerical benchmark problems with dimensions varying from 30 to 100, and an overall comparison is made between the proposed algorithm and other optimization algorithms. The results show that the proposed algorithm is very efficient and promising for optimizing high-dimensional expensive problems.},
  archive      = {J_TEVC},
  author       = {Xiwen Cai and Liang Gao and Xinyu Li},
  doi          = {10.1109/TEVC.2019.2919762},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {365-379},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Efficient generalized surrogate-assisted evolutionary algorithm for high-dimensional expensive problems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Surrogate-assisted evolutionary deep learning using an
end-to-end random forest-based performance predictor. <em>TEVC</em>,
<em>24</em>(2), 350–364. (<a
href="https://doi.org/10.1109/TEVC.2019.2924461">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) have shown remarkable performance in various real-world applications. Unfortunately, the promising performance of CNNs can be achieved only when their architectures are optimally constructed. The architectures of state-of-the-art CNNs are typically handcrafted with extensive expertise in both CNNs and the investigated data, which consequently hampers the widespread adoption of CNNs for less experienced users. Evolutionary deep learning (EDL) is able to automatically design the best CNN architectures without much expertise. However, the existing EDL algorithms generally evaluate the fitness of a new architecture by training from scratch, resulting in the prohibitive computational cost even operated on high-performance computers. In this paper, an end-to-end offline performance predictor based on the random forest is proposed to accelerate the fitness evaluation in EDL. The proposed performance predictor shows the promising performance in term of the classification accuracy and the consumed computational resources when compared with 18 state-of-the-art peer competitors by integrating into an existing EDL algorithm as a case study. The proposed performance predictor is also compared with the other two representatives of existing performance predictors. The experimental results show the proposed performance predictor not only significantly speeds up the fitness evaluations but also achieves the best prediction among the peer performance predictors.},
  archive      = {J_TEVC},
  author       = {Yanan Sun and Handing Wang and Bing Xue and Yaochu Jin and Gary G. Yen and Mengjie Zhang},
  doi          = {10.1109/TEVC.2019.2924461},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {350-364},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Surrogate-assisted evolutionary deep learning using an end-to-end random forest-based performance predictor},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Parameter-free voronoi neighborhood for evolutionary
multimodal optimization. <em>TEVC</em>, <em>24</em>(2), 335–349. (<a
href="https://doi.org/10.1109/TEVC.2019.2921830">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neighborhood information plays an important role in improving the performance of evolutionary computation in various optimization scenarios, particularly in the context of multimodal optimization. Several neighborhood concepts, i.e., index-based neighborhood, nearest neighborhood, and fuzzy neighborhood, have been studied and engaged in the design of niching methods. However, the use of these neighborhood concepts requires the specification of some problem-related parameters, which is difficult to determine without a prior knowledge. In this paper, we introduce a new neighborhood concept based on a geometrical construction called Voronoi diagram. The new concept offers two advantages at the expense of increasing the computational complexity to a higher level. It eliminates the need of additional parameters and it is more informative than the existing ones. The information provided by the Voronoi neighbors of an individual can be exploited to estimate the evolutionary state. Based on the information, we divide the population into three groups and assign each group a different reproduction strategy to support the exploration and exploitation of the search space. We show the use of the concept in the design of an effective evolutionary algorithm for multimodal optimization. The experiments have been conducted to investigate the performance of the algorithm. The results reveal that the proposed algorithm compare favorably with the state-of-the-art algorithms designed based on other types of neighborhood concepts.},
  archive      = {J_TEVC},
  author       = {Yu-Hui Zhang and Yue-Jiao Gong and Ying Gao and Hua Wang and Jun Zhang},
  doi          = {10.1109/TEVC.2019.2921830},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {335-349},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Parameter-free voronoi neighborhood for evolutionary multimodal optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Decomposition-based interactive evolutionary algorithm for
multiple objective optimization. <em>TEVC</em>, <em>24</em>(2), 320–334.
(<a href="https://doi.org/10.1109/TEVC.2019.2915767">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a decomposition-based interactive evolutionary algorithm (EA) for multiple objective optimization. During an evolutionary search, a decision maker (DM) is asked to compare pairwise solutions from the current population. Using the Monte Carlo simulation, the proposed algorithm generates from a uniform distribution a set of instances of the preference model compatible with such an indirect preference information. These instances are incorporated as the search directions with the aim of systematically converging a population toward the DMs most preferred region of the Pareto front. The experimental comparison proves that the proposed decomposition-based method outperforms the state-of-the-art interactive counterparts of the dominance-based EAs. We also show that the quality of constructed solutions is highly affected by the form of the incorporated preference model.},
  archive      = {J_TEVC},
  author       = {Michał K. Tomczyk and Miłosz Kadziński},
  doi          = {10.1109/TEVC.2019.2915767},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {320-334},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Decomposition-based interactive evolutionary algorithm for multiple objective optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evolutionary dynamic multiobjective optimization assisted by
a support vector regression predictor. <em>TEVC</em>, <em>24</em>(2),
305–319. (<a href="https://doi.org/10.1109/TEVC.2019.2925722">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic multiobjective optimization problems (DMOPs) challenge multiobjective evolutionary algorithms (MOEAs) because those problems change rapidly over time. The class of DMOPs whose objective functions change over time steps, in ways that exhibit some hidden patterns has gained much attention. Their predictability indicates that the problem exhibits some correlations between solutions obtained in sequential time periods. Most of the current approaches use linear models or similar strategies to describe the correlations between historical solutions obtained, and predict the new solutions in the following time period as an initial population from which the MOEA can begin searching in order to improve its efficiency. However, nonlinear correlations between historical solutions and current solutions are more common in practice, and a linear model may not be suitable for the nonlinear case. In this paper, we present a support vector regression (SVR)-based predictor to generate the initial population for the MOEA in the new environment. The basic idea of this predictor is to map the historical solutions into a high-dimensional feature space via a nonlinear mapping, and to do linear regression in this space. SVR is used to implement this process. We incorporate this predictor into the MOEA based on decomposition (MOEA/D) to construct a novel algorithm for solving the aforementioned class of DMOPs. Comprehensive experiments have shown the effectiveness and competitiveness of our proposed predictor, comparing with the state-of-the-art methods.},
  archive      = {J_TEVC},
  author       = {Leilei Cao and Lihong Xu and Erik D. Goodman and Chunteng Bao and Shuwei Zhu},
  doi          = {10.1109/TEVC.2019.2925722},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {305-319},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolutionary dynamic multiobjective optimization assisted by a support vector regression predictor},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A multimodel prediction method for dynamic multiobjective
evolutionary optimization. <em>TEVC</em>, <em>24</em>(2), 290–304. (<a
href="https://doi.org/10.1109/TEVC.2019.2925358">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A large number of prediction strategies are specific to a dynamic multiobjective optimization problem (DMOP) with only one type of the Pareto set (PS) change. However, a continuous DMOP with more than one type of the unknown PS change has been seldom investigated. We present a multimodel prediction approach (MMP) realized in the framework of evolutionary algorithms (EAs) to tackle the problem. In this paper, we first detect the type of the PS change, followed by the selection of an appropriate prediction model to provide an initial population for the subsequent evolution. To observe the influence of MMP on EAs, optimal solutions obtained by three classical dynamic multiobjective EAs with and without MMP are investigated. Furthermore, to investigate the performance of MMP, three state-of-the-art prediction strategies are compared on a large number of dynamic test instances under the same particle swarm optimizer. The experimental results demonstrate that the proposed approach outperforms its counterparts under comparison on most optimization problems.},
  archive      = {J_TEVC},
  author       = {Miao Rong and Dunwei Gong and Witold Pedrycz and Ling Wang},
  doi          = {10.1109/TEVC.2019.2925358},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {290-304},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A multimodel prediction method for dynamic multiobjective evolutionary optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An experimental method to estimate running time of
evolutionary algorithms for continuous optimization. <em>TEVC</em>,
<em>24</em>(2), 275–289. (<a
href="https://doi.org/10.1109/TEVC.2019.2921547">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Running time analysis is a fundamental problem of critical importance in evolutionary computation. However, the analysis results have rarely been applied to advanced evolutionary algorithms (EAs) in practice, let alone their variants for continuous optimization. In this paper, an experimental method is proposed for analyzing the running time of EAs that are widely used for solving continuous optimization problems. Based on Glivenko-Cantelli theorem, the proposed method simulates the distribution of gain, which is introduced by average gain model to characterize progress during the optimization process. Data fitting techniques are subsequently adopted to obtain a desired function for further analyses. To verify the validity of the proposed method, experiments were conducted to estimate the upper bounds on expected first hitting time of various evolutionary strategies, such as (1, $\lambda $ ) evolution strategy, standard evolution strategy, covariance matrix adaptation evolution strategy, and its improved variants. The results suggest that all estimated upper bounds are correct. Backed up by the proposed method, state-of-the-art EAs for continuous optimization will have identical results about the running time as simplified schemes, which will bridge the gap between theoretical foundation and applications of evolutionary computation.},
  archive      = {J_TEVC},
  author       = {Han Huang and Junpeng Su and Yushan Zhang and Zhifeng Hao},
  doi          = {10.1109/TEVC.2019.2921547},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {275-289},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {An experimental method to estimate running time of evolutionary algorithms for continuous optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Novel prediction strategies for dynamic multiobjective
optimization. <em>TEVC</em>, <em>24</em>(2), 260–274. (<a
href="https://doi.org/10.1109/TEVC.2019.2922834">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new prediction-based dynamic multiobjective optimization (PBDMO) method, which combines a new prediction-based reaction mechanism and a popular regularity model-based multiobjective estimation of distribution algorithm (RM-MEDA) for solving dynamic multiobjective optimization problems. Whenever a change is detected, PBDMO reacts effectively to it by generating three subpopulations based on different strategies. The first subpopulation is created by moving nondominated individuals using a simple linear prediction model with different step sizes. The second subpopulation consists of some individuals generated by a novel sampling strategy to improve population convergence as well as distribution. The third subpopulation comprises some individuals generated using a shrinking strategy based on the probability distribution of variables. These subpopulations are tailored to form a population for the new environment. The experimental results carried out on a variety of bi- and three-objective benchmark functions demonstrate that the proposed technique has competitive performance compared with some state-of-the-art algorithms.},
  archive      = {J_TEVC},
  author       = {Qingyang Zhang and Shengxiang Yang and Shouyong Jiang and Ronggui Wang and Xiaoli Li},
  doi          = {10.1109/TEVC.2019.2922834},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {260-274},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Novel prediction strategies for dynamic multiobjective optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Enhancing decomposition-based algorithms by estimation of
distribution for constrained optimal software product selection.
<em>TEVC</em>, <em>24</em>(2), 245–259. (<a
href="https://doi.org/10.1109/TEVC.2019.2922419">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper integrates an estimation of distribution (EoD)-based update operator into decomposition-based multiobjective evolutionary algorithms for binary optimization. The probabilistic model in the update operator is a probability vector, which is adaptively learned from historical information of each subproblem. We show that this update operator can significantly enhance decomposition-based algorithms on a number of benchmark problems. Moreover, we apply the enhanced algorithms to the constrained optimal software product selection (OSPS) problem in the field of search-based software engineering. For this real-world problem, we give its formal definition and then develop a new repair operator based on satisfiability solvers. It is demonstrated by the experimental results that the algorithms equipped with the EoD operator are effective in dealing with this practical problem, particularly for large-scale instances. The interdisciplinary studies in this paper provide a new real-world application scenario for constrained multiobjective binary optimizers and also offer valuable techniques for software engineers in handling the OSPS problem.},
  archive      = {J_TEVC},
  author       = {Yi Xiang and Xiaowei Yang and Yuren Zhou and Han Huang},
  doi          = {10.1109/TEVC.2019.2922419},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {245-259},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Enhancing decomposition-based algorithms by estimation of distribution for constrained optimal software product selection},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evolutionary development of growing generic sorting networks
by means of rewriting systems. <em>TEVC</em>, <em>24</em>(2), 232–244.
(<a href="https://doi.org/10.1109/TEVC.2019.2918212">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an evolutionary developmental method for the design of arbitrarily growing sorting networks. The developmental model is based on a parallel rewriting system (a grammar) that is specified by an alphabet, an initial string (an axiom), and a set of rewriting rules. The rewriting process iteratively expands the axiom in order to develop more complex strings during a series of development steps (i.e., derivations in the grammar). A mapping function is introduced that allows for converting the strings onto comparator structures-building blocks of sorting networks. The construction of the networks is performed in such a way that a given (initial) sorting network grows progressively by adding further building blocks within each development step. For a given (fixed) alphabet, the axiom together with the rewriting rules themselves are the subjects of the evolutionary search. It will be shown that suitable grammars can be evolved for the construction of arbitrarily large sorting networks that grow with various given sizes of development steps. Moreover, the resulting networks exhibit significantly better properties (the number of comparators and delay) in comparison with those obtained by means of similar existing methods.},
  archive      = {J_TEVC},
  author       = {Michal Bidlo and Michal Dobeš},
  doi          = {10.1109/TEVC.2019.2918212},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {232-244},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolutionary development of growing generic sorting networks by means of rewriting systems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evolutionary collaborative human-UAV search for escaped
criminals. <em>TEVC</em>, <em>24</em>(2), 217–231. (<a
href="https://doi.org/10.1109/TEVC.2019.2925175">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of unmanned aerial vehicles (UAVs) for target searching in complex environments has increased considerably in recent years. The numerous studies on UAV search methods have been reported, but few have been conducted on collaborative human-UAV search which is common in many applications. In this paper, we present a problem of collaborative human-UAV search for escaped criminals, the aim of which is to minimize the expected time of capture rather than detection. We show that our problem is much more complex than the problem of pure UAV search. The difficulty of our problem is further increased by the fact that criminals will attempt to avoid detection and capture. To solve the problem, we propose a hybrid evolutionary algorithm (EA) that uses three evolutionary operators, namely, comprehensive learning, variable mutation, and local search, to efficiently explore the solution space. The experimental results demonstrate that the proposed method outperforms some well-known EAs and other popular UAV search methods on test instances. An application of our method to a real-world operation took 311 min to capture a criminal who had escaped for over three days, validating its practicability and performance advantage. This paper provides a good basis for promoting the application of EAs to a wider class of man-machine collaboration scheduling problems.},
  archive      = {J_TEVC},
  author       = {Yu-Jun Zheng and Yi-Chen Du and Hai-Feng Ling and Wei-Guo Sheng and Sheng-Yong Chen},
  doi          = {10.1109/TEVC.2019.2925175},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {217-231},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolutionary collaborative human-UAV search for escaped criminals},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey of automatic parameter tuning methods for
metaheuristics. <em>TEVC</em>, <em>24</em>(2), 201–216. (<a
href="https://doi.org/10.1109/TEVC.2019.2921598">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parameter tuning, that is, to find appropriate parameter settings (or configurations) of algorithms so that their performance is optimized, is an important task in the development and application of metaheuristics. Automating this task, i.e., developing algorithmic procedure to address parameter tuning task, is highly desired and has attracted significant attention from the researchers and practitioners. During last two decades, many automatic parameter tuning approaches have been proposed. This paper presents a comprehensive survey of automatic parameter tuning methods for metaheuristics. A new classification (or taxonomy) of automatic parameter tuning methods is introduced according to the structure of tuning methods. The existing automatic parameter tuning approaches are consequently classified into three categories: 1) simple generate-evaluate methods; 2) iterative generate-evaluate methods; and 3) high-level generate-evaluate methods. Then, these three categories of tuning methods are reviewed in sequence. In addition to the description of each tuning method, its main strengths and weaknesses are discussed, which is helpful for new researchers or practitioners to select appropriate tuning methods to use. Furthermore, some challenges and directions of this field are pointed out for further research.},
  archive      = {J_TEVC},
  author       = {Changwu Huang and Yuanxiang Li and Xin Yao},
  doi          = {10.1109/TEVC.2019.2921598},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {201-216},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A survey of automatic parameter tuning methods for metaheuristics},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020f). IEEE transactions on evolutionary computation society
information. <em>TEVC</em>, <em>24</em>(1), C3. (<a
href="https://doi.org/10.1109/TEVC.2020.2967828">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Presents a listing of the editorial board, board of governors, current staff, committee members, and/or society editors for this issue of the publication.},
  archive      = {J_TEVC},
  doi          = {10.1109/TEVC.2020.2967828},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {C3},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {IEEE transactions on evolutionary computation society information},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). A review of evolutionary multimodal multiobjective
optimization. <em>TEVC</em>, <em>24</em>(1), 193–200. (<a
href="https://doi.org/10.1109/TEVC.2019.2909744">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal multiobjective optimization aims to find all Pareto optimal solutions, including overlapping solutions in the objective space. Multimodal multiobjective optimization has been investigated in the evolutionary computation community since 2005. However, it is difficult to survey existing studies in this field because they have been independently conducted and do not explicitly use the term “multimodal multiobjective optimization.” To address this issue, this letter reviews the existing studies of evolutionary multimodal multiobjective optimization, including studies published under names that are different from multimodal multiobjective optimization. Our review also clarifies open issues in this research area.},
  archive      = {J_TEVC},
  author       = {Ryoji Tanabe and Hisao Ishibuchi},
  doi          = {10.1109/TEVC.2019.2909744},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {193-200},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A review of evolutionary multimodal multiobjective optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). R2-based hypervolume contribution approximation.
<em>TEVC</em>, <em>24</em>(1), 185–192. (<a
href="https://doi.org/10.1109/TEVC.2019.2909271">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this letter, a new hypervolume contribution approximation method is proposed which is formulated as an R2 indicator. The basic idea of the proposed method is to use different line segments only in the hypervolume contribution region for the hypervolume contribution approximation. Comparing with a traditional method which is based on the R2 indicator to approximate the hypervolume, the new method can directly approximate the hypervolume contribution and will utilize all the direction vectors only in the hypervolume contribution region. The new method, the traditional method, and the Monte Carlo sampling method together with two exact methods are compared through comprehensive experiments. Our results show the advantages of the new method over the other methods. Comparing with the other two approximation methods, the new method achieves the best performance for comparing hypervolume contributions of different solutions and identifying the solution with the smallest hypervolume contribution. Comparing with the exact methods, the new method is computationally efficient in high-dimensional spaces where the exact methods are impractical to use.},
  archive      = {J_TEVC},
  author       = {Ke Shang and Hisao Ishibuchi and Xizi Ni},
  doi          = {10.1109/TEVC.2019.2909271},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {185-192},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {R2-based hypervolume contribution approximation},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multiple reference points-based decomposition for
multiobjective feature selection in classification: Static and dynamic
mechanisms. <em>TEVC</em>, <em>24</em>(1), 170–184. (<a
href="https://doi.org/10.1109/TEVC.2019.2913831">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is an important task in machine learning that has two main objectives: 1) reducing dimensionality and 2) improving learning performance. Feature selection can be considered a multiobjective problem. However, it has its problematic characteristics, such as a highly discontinuous Pareto front, imbalance preferences, and partially conflicting objectives. These characteristics are not easy for existing evolutionary multiobjective optimization (EMO) algorithms. We propose a new decomposition approach with two mechanisms (static and dynamic) based on multiple reference points under the multiobjective evolutionary algorithm based on decomposition (MOEA/D) framework to address the above-mentioned difficulties of feature selection. The static mechanism alleviates the dependence of the decomposition on the Pareto front shape and the effect of the discontinuity. The dynamic one is able to detect regions in which the objectives are mostly conflicting, and allocates more computational resources to the detected regions. In comparison with other EMO algorithms on 12 different classification datasets, the proposed decomposition approach finds more diverse feature subsets with better performance in terms of hypervolume and inverted generational distance. The dynamic mechanism successfully identifies conflicting regions and further improves the approximation quality for the Pareto fronts.},
  archive      = {J_TEVC},
  author       = {Bach Hoai Nguyen and Bing Xue and Peter Andreae and Hisao Ishibuchi and Mengjie Zhang},
  doi          = {10.1109/TEVC.2019.2913831},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {170-184},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Multiple reference points-based decomposition for multiobjective feature selection in classification: Static and dynamic mechanisms},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Toward efficient design space exploration for fault-tolerant
multiprocessor systems. <em>TEVC</em>, <em>24</em>(1), 157–169. (<a
href="https://doi.org/10.1109/TEVC.2019.2912726">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The design space exploration (DSE) of fault-tolerant multiprocessor systems is very complex, as it contains three interacting NP-hard problems: 1) task hardening; 2) task mapping; and 3) task scheduling. In addition, replication-based task hardening can introduce new tasks, called replicas, into the system, enlarging the design space further. As a population-based global optimization algorithm, evolutionary algorithms (EAs) have been widely used to explore this huge design space over the last decade. However, as analyzed in this paper, the search space of previous works is highly redundant, resulting in poor efficiency and scalability. This paper proposes an efficient EA-based DSE method for the design of large-scale fault-tolerant multiprocessor systems. The main novelties of this paper include: 1) mapping exploration is explicitly separated, i.e., task mapping is optimized during the evolutionary search, while replica mapping is constructed heuristically according to the current co-synthesis state; 2) the design space of task hardening and task mapping are explored independently by a cooperative co-EA; and 3) as a complement to global search of EA, problem-specific local search operators are designed for both task hardening and task mapping, reducing the number of fitness evaluations required. Compared with the most relevant state-of-the-art method, the superiority of the proposed method is demonstrated using extensive experiments on a large set of benchmarks, e.g., $1.75\times \sim 2.50\times $ better results can be obtained on the benchmarks of 300 tasks and 30 processors.},
  archive      = {J_TEVC},
  author       = {Bo Yuan and Huanhuan Chen and Xin Yao},
  doi          = {10.1109/TEVC.2019.2912726},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {157-169},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Toward efficient design space exploration for fault-tolerant multiprocessor systems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A similarity-based cooperative co-evolutionary algorithm for
dynamic interval multiobjective optimization problems. <em>TEVC</em>,
<em>24</em>(1), 142–156. (<a
href="https://doi.org/10.1109/TEVC.2019.2912204">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic interval multiobjective optimization problems (DI-MOPs) are very common in real-world applications. However, there are few evolutionary algorithms (EAs) that are suitable for tackling DI-MOPs up to date. A framework of dynamic interval multiobjective cooperative co-evolutionary optimization based on the interval similarity is presented in this paper to handle DI-MOPs. In the framework, a strategy for decomposing decision variables is first proposed, through which all the decision variables are divided into two groups according to the interval similarity between each decision variable and interval parameters. Following that, two subpopulations are utilized to cooperatively optimize decision variables in the two groups. Furthermore, two response strategies, i.e., a strategy based on the change intensity and a random mutation strategy, are employed to rapidly track the changing Pareto front of the optimization problem. The proposed algorithm is applied to eight benchmark optimization instances as well as a multiperiod portfolio selection problem and compared with five state-of-the-art EAs. The experimental results reveal that the proposed algorithm is very competitive on most optimization instances.},
  archive      = {J_TEVC},
  author       = {Dunwei Gong and Biao Xu and Yong Zhang and Yinan Guo and Shengxiang Yang},
  doi          = {10.1109/TEVC.2019.2912204},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {142-156},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A similarity-based cooperative co-evolutionary algorithm for dynamic interval multiobjective optimization problems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A graph-based fuzzy evolutionary algorithm for solving
two-echelon vehicle routing problems. <em>TEVC</em>, <em>24</em>(1),
129–141. (<a href="https://doi.org/10.1109/TEVC.2019.2911736">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two-echelon vehicle routing problem (2E-VRP) is a challenging problem that involves both the strategic and tactical planning decisions on both echelons. The satellite locations and the customer distribution affect the cost of different components on the second echelon, thus the possibilities of satellite-to-customer assignment complicates the problem. In this paper, we propose a graph-based fuzzy evolutionary algorithm for solving 2E-VRP. The proposed method integrates a graph-based fuzzy assignment scheme into an iteratively evolutionary learning process to minimize the total cost. To resolve the possibilities of the satellite-to-customer assignment, graph-based fuzzy operator is used to take advantage of population evolution and avoid excessive fitness evaluations of unpromising moves in different satellites. Each offspring is produced via graph-based fuzzy assignment procedure out of an assignment graph from parent individuals, and fuzzy local search procedure is used to further improve the offspring. The experimental results on the public test sets demonstrate the competitiveness of the proposed method.},
  archive      = {J_TEVC},
  author       = {Xueming Yan and Han Huang and Zhifeng Hao and Jiahai Wang},
  doi          = {10.1109/TEVC.2019.2911736},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {129-141},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A graph-based fuzzy evolutionary algorithm for solving two-echelon vehicle routing problems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Automatic niching differential evolution with contour
prediction approach for multimodal optimization problems. <em>TEVC</em>,
<em>24</em>(1), 114–128. (<a
href="https://doi.org/10.1109/TEVC.2019.2910721">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Niching techniques have been widely incorporated into evolutionary algorithms (EAs) for solving multimodal optimization problems (MMOPs). However, most of the existing niching techniques are either sensitive to the niching parameters or require extra fitness evaluations (FEs) to maintain the niche detection accuracy. In this paper, we propose a new automatic niching technique based on the affinity propagation clustering (APC) and design a novel niching differential evolution (DE) algorithm, termed as automatic niching DE (ANDE), for solving MMOPs. In the proposed ANDE algorithm, APC acts as a parameter-free automatic niching method that does not need to predefine the number of clusters or the cluster size. Also, it can facilitate locating multiple peaks without extra FEs. Furthermore, the ANDE algorithm is enhanced by a contour prediction approach (CPA) and a two-level local search (TLLS) strategy. First, the CPA is a predictive search strategy. It exploits the individual distribution information in each niche to estimate the contour landscape, and then predicts the rough position of the potential peak to help accelerate the convergence speed. Second, the TLLS is a solution refine strategy to further increase the solution accuracy after the CPA roughly predicting the peaks. Compared with the other state-of-the-art DE and non-DE multimodal algorithms, even the winner of competition on multimodal optimization, the experimental results on 20 widely used benchmark functions illustrate the superiority of the proposed ANDE algorithm.},
  archive      = {J_TEVC},
  author       = {Zi-Jia Wang and Zhi-Hui Zhan and Ying Lin and Wei-Jie Yu and Hua Wang and Sam Kwong and Jun Zhang},
  doi          = {10.1109/TEVC.2019.2910721},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {114-128},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Automatic niching differential evolution with contour prediction approach for multimodal optimization problems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A many-objective evolutionary algorithm with pareto-adaptive
reference points. <em>TEVC</em>, <em>24</em>(1), 99–113. (<a
href="https://doi.org/10.1109/TEVC.2019.2909636">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new many-objective evolutionary algorithm with Pareto-adaptive reference points. In this algorithm, the shape of the Pareto-optimal front (PF) is estimated based on a ratio of Euclidean distances. If the estimated shape is likely to be convex, the nadir point is used as the reference point to calculate the convergence and diversity indicators for individuals. Otherwise, the reference point is set to the ideal point. In addition, the estimation of the nadir point is different from what was widely used in the literature. The nadir point, together with the ideal point, provides a feasible way to deal with dominance resistant solutions, which are difficult to be detected and eliminated in Pareto-based algorithms. The proposed algorithm is compared with the state-of-the-art many-objective optimization algorithms on a number of unconstrained and constrained test problems with up to 15 objectives. The experimental results show that it performs better than other algorithms in most of the test instances. Moreover, the new algorithm shows good performance on problems whose PFs are irregular (being discontinuous, degenerated, bent, or mixed). The observed high performance and inherent good properties (such as being free of weight vectors and control parameters) make the new proposal a promising tool for other similar problems.},
  archive      = {J_TEVC},
  author       = {Yi Xiang and Yuren Zhou and Xiaowei Yang and Han Huang},
  doi          = {10.1109/TEVC.2019.2909636},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {99-113},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A many-objective evolutionary algorithm with pareto-adaptive reference points},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Toward a matrix-free covariance matrix adaptation evolution
strategy. <em>TEVC</em>, <em>24</em>(1), 84–98. (<a
href="https://doi.org/10.1109/TEVC.2019.2907266">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we discuss a method for generating new individuals such that their mean vector and the covariance matrix are defined by formulas analogous to the covariance matrix adaptation evolution strategy (CMA-ES). In contrast to CMA-ES, which generates new individuals using multivariate Gaussian distribution with an explicitly defined covariance matrix, the introduced method uses combinations of difference vectors between archived individuals and univariate Gaussian random vectors along directions of past shifts of the population midpoints. We use this method to formulate the differential evolution strategy (DES)-an algorithm that is a crossover between differential evolution (DE) and CMA-ES. The numerical results presented in this paper indicate that DES is competitive against CMA-ES in performing both local and global optimization.},
  archive      = {J_TEVC},
  author       = {Jarosław Arabas and Dariusz Jagodziński},
  doi          = {10.1109/TEVC.2019.2907266},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {84-98},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Toward a matrix-free covariance matrix adaptation evolution strategy},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multifactorial evolutionary algorithm with online transfer
parameter estimation: MFEA-II. <em>TEVC</em>, <em>24</em>(1), 69–83. (<a
href="https://doi.org/10.1109/TEVC.2019.2906927">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans rarely tackle every problem from scratch. Given this observation, the motivation for this paper is to improve optimization performance through adaptive knowledge transfer across related problems. The scope for spontaneous transfers under the simultaneous occurrence of multiple problems unveils the benefits of multitasking. Multitask optimization has recently demonstrated competence in solving multiple (related) optimization tasks concurrently. Notably, in the presence of underlying relationships between problems, the transfer of high-quality solutions across them has shown to facilitate superior performance characteristics. However, in the absence of any prior knowledge about the intertask synergies (as is often the case with general black-box optimization), the threat of predominantly negative transfer prevails. Susceptibility to negative intertask interactions can impede the overall convergence behavior. To allay such fears, in this paper, we propose a novel evolutionary computation framework that enables online learning and exploitation of the similarities (and discrepancies) between distinct tasks in multitask settings, for an enhanced optimization process. Our proposal is based on the principled theoretical arguments that seek to minimize the tendency of harmful interactions between tasks, based on a purely data-driven learning of relationships among them. The efficacy of our proposed method is validated experimentally on a series of synthetic benchmarks, as well as a practical study that provides insights into the behavior of the method in the face of several tasks occurring at once.},
  archive      = {J_TEVC},
  author       = {Kavitesh Kumar Bali and Yew-Soon Ong and Abhishek Gupta and Puay Siew Tan},
  doi          = {10.1109/TEVC.2019.2906927},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {69-83},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Multifactorial evolutionary algorithm with online transfer parameter estimation: MFEA-II},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A theoretical guideline for designing an effective adaptive
particle swarm. <em>TEVC</em>, <em>24</em>(1), 57–68. (<a
href="https://doi.org/10.1109/TEVC.2019.2906894">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the underlying assumptions that have been used for designing adaptive particle swarm optimization (PSO) algorithms in the past years are theoretically investigated. I relate these assumptions to the movement patterns of particles controlled by coefficient values (inertia weight and acceleration coefficients) and introduce three factors, namely the autocorrelation of the particle positions, the average movement distance of the particle in each iteration, and the focus of the search, that describe these movement patterns. I show how these factors represent movement patterns of a particle within a swarm and how they are affected by particle coefficients (i.e., inertia weight and acceleration coefficients). I derive equations that provide exact coefficient values to guarantee to achieve the desired movement pattern defined by these three factors within a swarm. I then relate these movements to the searching capability of particles and provide a guideline for designing potentially successful adaptive methods to control coefficients in particle swarm. Finally, I propose a new simple time adaptive particle swarm and compare its results with previous adaptive particle swarm approaches. Experiments show that the theoretical findings indeed provide a beneficial guideline for the successful adaptation of the coefficients in the PSO algorithm.},
  archive      = {J_TEVC},
  author       = {Mohammad Reza Bonyadi},
  doi          = {10.1109/TEVC.2019.2906894},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {57-68},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A theoretical guideline for designing an effective adaptive particle swarm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Tackling large-scale and combinatorial bi-level problems
with a genetic programming hyper-heuristic. <em>TEVC</em>,
<em>24</em>(1), 44–56. (<a
href="https://doi.org/10.1109/TEVC.2019.2906581">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Combinatorial bi-level optimization remains a challenging topic, especially when the lower-level is an NP-hard problem. In this paper, we tackle large-scale and combinatorial bi-level problems using GP hyper-heuristics, i.e., an approach that permits to train heuristics like a machine learning model. Our contribution aims at targeting the intensive and complex lower-level optimizations that occur when solving a large-scale and combinatorial bi-level problem. For this purpose, we consider hyper-heuristics through heuristic generation. Using a GP hyper-heuristic approach, we train greedy heuristics in order to make them more reliable when encountering unseen lower-level instances that could be generated during bi-level optimization. To validate our approach referred to as GA+AGH, we tackle instances from the bi-level cloud pricing optimization problem (BCPOP) that model the trading interactions between a cloud service provider and cloud service customers. Numerical results demonstrate the abilities of the trained heuristics to cope with the inherent nested structure that makes bi-level optimization problems so hard. Furthermore, it has been shown that training heuristics for lower-level optimization permits to outperform human-based heuristics and metaheuristics which constitute an excellent outcome for bi-level optimization.},
  archive      = {J_TEVC},
  author       = {Emmanuel Kieffer and Grégoire Danoy and Matthias R. Brust and Pascal Bouvry and Anass Nagih},
  doi          = {10.1109/TEVC.2019.2906581},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {44-56},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Tackling large-scale and combinatorial bi-level problems with a genetic programming hyper-heuristic},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Utilizing the correlation between constraints and objective
function for constrained evolutionary optimization. <em>TEVC</em>,
<em>24</em>(1), 29–43. (<a
href="https://doi.org/10.1109/TEVC.2019.2904900">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When solving constrained optimization problems by evolutionary algorithms, the core issue is to balance constraints and objective function. This paper is the first attempt to utilize the correlation between constraints and objective function to keep this balance. First of all, the correlation between constraints and objective function is mined and represented by a correlation index. Afterward, a weighted sum updating approach and an archiving and replacement mechanism are proposed to make use of this correlation index to guide the evolution. By the above process, a novel constrained optimization evolutionary algorithm is presented. Experiments on a broad range of benchmark test functions indicate that the proposed method shows better or at least competitive performance against other state-of-the-art methods. Moreover, the proposed method is applied to the gait optimization of humanoid robots.},
  archive      = {J_TEVC},
  author       = {Yong Wang and Jia-Peng Li and Xihui Xue and Bing-chuan Wang},
  doi          = {10.1109/TEVC.2019.2904900},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {29-43},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Utilizing the correlation between constraints and objective function for constrained evolutionary optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Self-regulated evolutionary multitask optimization.
<em>TEVC</em>, <em>24</em>(1), 16–28. (<a
href="https://doi.org/10.1109/TEVC.2019.2904696">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary multitask optimization (EMTO) is a newly emerging research area in the field of evolutionary computation. It investigates how to solve multiple optimization problems (tasks) at the same time via evolutionary algorithms (EAs) to improve on the performance of solving each task independently, assuming if some component tasks are related then the useful knowledge (e.g., promising candidate solutions) acquired during the process of solving one task may assist in (and also benefit from) solving the other tasks. In EMTO, task relatedness is typically unknown in advance and needs to be captured via EA&#39;s population. Since the population of an EA can only cover a subregion of the solution space and keeps evolving during the search, thus captured task relatedness is local and dynamic. The multifactorial EA (MFEA) is one of the most representative EMTO techniques, inspired by the bio-cultural model of multifactorial inheritance, which transmits both biological and cultural traits from the parents to the offspring. MFEA has succeeded in solving various multitask optimization (MTO) problems. However, the intensity of knowledge transfer in MFEA is determined via its algorithmic configuration without considering the degree of task relatedness, which may prevent the effective sharing and utilization of the useful knowledge acquired in related tasks. To address this issue, we propose a self-regulated EMTO (SREMTO) algorithm to automatically adapt the intensity of cross-task knowledge transfer to different and varying degrees of relatedness between different tasks as the search proceeds so that the useful knowledge in common for solving related tasks can be captured, shared, and utilized to a great extent. We compare SREMTO with MFEA and its variants as well as the single-task optimization counterpart of SREMTO on two MTO test suites, which demonstrates the superiority of SREMTO.},
  archive      = {J_TEVC},
  author       = {Xiaolong Zheng and A. K. Qin and Maoguo Gong and Deyun Zhou},
  doi          = {10.1109/TEVC.2019.2904696},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {16-28},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Self-regulated evolutionary multitask optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Scaling up dynamic optimization problems: A
divide-and-conquer approach. <em>TEVC</em>, <em>24</em>(1), 1–15. (<a
href="https://doi.org/10.1109/TEVC.2019.2902626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scalability is a crucial aspect of designing efficient algorithms. Despite their prevalence, large-scale dynamic optimization problems are not well studied in the literature. This paper is concerned with designing benchmarks and frameworks for the study of large-scale dynamic optimization problems. We start by a formal analysis of the moving peaks benchmark (MPB) and show its nonseparable nature irrespective of its number of peaks. We then propose a composite MPB suite with exploitable modularity covering a wide range of scalable partially separable functions suitable for the study of large-scale dynamic optimization problems. The benchmark exhibits modularity, heterogeneity, and imbalance features to resemble real-world problems. To deal with the intricacies of large-scale dynamic optimization problems, we propose a decomposition-based coevolutionary framework which breaks a large-scale dynamic optimization problem into a set of lower-dimensional components. A novel aspect of the framework is its efficient bi-level resource allocation mechanism which controls the budget assignment to components and the populations responsible for tracking multiple moving optima. Based on a comprehensive empirical study on a wide range of large-scale dynamic optimization problems with up to 200-D, we show the crucial role of problem decomposition and resource allocation in dealing with these problems. The experimental results clearly show the superiority of the proposed framework over three other approaches in solving large-scale dynamic optimization problems.},
  archive      = {J_TEVC},
  author       = {Danial Yazdani and Mohammad Nabi Omidvar and Jürgen Branke and Trung Thanh Nguyen and Xin Yao},
  doi          = {10.1109/TEVC.2019.2902626},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Scaling up dynamic optimization problems: A divide-and-conquer approach},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
