<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>PIEEE_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="pieee---144">PIEEE - 144</h2>
<ul>
<li><details>
<summary>
(2020a). Recruit a member. <em>PIEEE</em>, <em>108</em>(12), 2324.
(<a href="https://doi.org/10.1109/JPROC.2020.3036505">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advertisement, IEEE.},
  archive      = {J_PIEEE},
  doi          = {10.1109/JPROC.2020.3036505},
  journal      = {Proceedings of the IEEE},
  number       = {12},
  pages        = {2324},
  shortjournal = {Proc. IEEE},
  title        = {Recruit a member},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). IEEE women in engineering. <em>PIEEE</em>,
<em>108</em>(12), 2323. (<a
href="https://doi.org/10.1109/JPROC.2020.3036503">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advertisement, IEEE.},
  archive      = {J_PIEEE},
  doi          = {10.1109/JPROC.2020.3036503},
  journal      = {Proceedings of the IEEE},
  number       = {12},
  pages        = {2323},
  shortjournal = {Proc. IEEE},
  title        = {IEEE women in engineering},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bell, watson, soft iron, and the insight that commercialized
the magneto telephone [scanning our past]. <em>PIEEE</em>,
<em>108</em>(12), 2311–2320. (<a
href="https://doi.org/10.1109/JPROC.2020.3017878">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This month&#39;s history article focuses on the story behind the technological breakthrough that led to the world&#39;s first commercial telephones.},
  archive      = {J_PIEEE},
  author       = {Ralph O. Meyer},
  doi          = {10.1109/JPROC.2020.3017878},
  journal      = {Proceedings of the IEEE},
  number       = {12},
  pages        = {2311-2320},
  shortjournal = {Proc. IEEE},
  title        = {Bell, watson, soft iron, and the insight that commercialized the magneto telephone [Scanning our past]},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Resistive crossbars as approximate hardware building blocks
for machine learning: Opportunities and challenges. <em>PIEEE</em>,
<em>108</em>(12), 2276–2310. (<a
href="https://doi.org/10.1109/JPROC.2020.3003007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional computing systems based on the von Neumann architecture are fundamentally bottlenecked by data transfers between processors and memory. The emergence of data-intensive workloads, such as machine learning (ML), creates an urgent need to address this bottleneck by designing computing platforms that utilize the principle of colocated memory and processing units. Such an approach, known as “in-memory computing,” can potentially eliminate data movement costs by computing inside the memory array itself. Crossbars based on resistive nonvolatile memory (NVM) devices have shown immense promise in serving as the building blocks of in-memory computing systems for ML workloads. This is because their high density can lead to higher on-chip storage capacity, while they can also perform massively parallel, in situ matrix-vector multiplication (MVM) operations, thereby accelerating the main computational kernel of ML workloads. However, resistive crossbar-based analog computing is inherently approximate due to the device- and circuit-level nonidealities. Furthermore, the area and energy costs of peripheral circuits for conversions between the analog and digital domains can greatly diminish the intrinsic efficiency of crossbar-based MVM computation. We present a comprehensive overview of the emerging paradigm of computing using NVM crossbars for accelerating ML workloads. We describe the design principles of resistive crossbars, including the devices and associated circuits that constitute them. We discuss intrinsic approximations arising from the device and circuit characteristics and study their functional impact on the MVM operation. Next, we present an overview of spatial architectures that exploit the high storage density of NVM crossbars. Furthermore, we elaborate on software frameworks that effectively capture device-circuit-architecture characteristics to evaluate the performance of large-scale deep neural networks (DNNs) using resistive crossbar-based hardware. Finally, we discuss open challenges and future research directions that need to be explored in order to realize the vision of resistive crossbars as the building blocks of future computing platforms.},
  archive      = {J_PIEEE},
  author       = {Indranil Chakraborty and Mustafa Ali and Aayush Ankit and Shubham Jain and Sourjya Roy and Shrihari Sridharan and Amogh Agrawal and Anand Raghunathan and Kaushik Roy},
  doi          = {10.1109/JPROC.2020.3003007},
  journal      = {Proceedings of the IEEE},
  number       = {12},
  pages        = {2276-2310},
  shortjournal = {Proc. IEEE},
  title        = {Resistive crossbars as approximate hardware building blocks for machine learning: Opportunities and challenges},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep in-memory architectures in SRAM: An analog approach to
approximate computing. <em>PIEEE</em>, <em>108</em>(12), 2251–2275. (<a
href="https://doi.org/10.1109/JPROC.2020.3034117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article provides an overview of recently proposed deep in-memory architectures (DIMAs) in SRAM for energyand latency-efficient hardware realization of machine learning (ML) algorithms. DIMA tackles the data movement problem in von Neumann architectures head-on by deeply embedding mixed-signal computations into a conventional memory array. In doing so, it trades off its computational signal-to-noise ratio (compute SNR) with energy and latency, and therefore, it represents an analog form of approximate computing. DIMA exploits the inherent error immunity of ML algorithms and SNR budgeting methods to operate its analog circuitry in a low-swing/low-compute SNR regime, thereby achieving &gt;100× reduction in the energy-delay product (EDP) over an equivalent von Neumann architecture with no loss in inference accuracy. This article describes DIMA&#39;s computational pipeline and provides a Shannon-inspired rationale for its robustness to process, temperature, and voltage variations and design guidelines to manage its analog nonidealities. DIMA&#39;s versatility, effectiveness, and practicality demonstrated via multiple silicon IC prototypes in a 65-nm CMOS process are described. A DIMA-based instruction set architecture (ISA) to realize an end-to-end application-toarchitecture mapping for the accelerating diverse ML algorithms is also presented. Finally, DIMA&#39;s fundamental tradeoff between energy and accuracy in the low-compute SNR regime is analyzed to determine energy-optimum design parameters.},
  archive      = {J_PIEEE},
  author       = {Mingu Kang and Sujan K. Gonugondla and Naresh R. Shanbhag},
  doi          = {10.1109/JPROC.2020.3034117},
  journal      = {Proceedings of the IEEE},
  number       = {12},
  pages        = {2251-2275},
  shortjournal = {Proc. IEEE},
  title        = {Deep in-memory architectures in SRAM: An analog approach to approximate computing},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient AI system design with cross-layer approximate
computing. <em>PIEEE</em>, <em>108</em>(12), 2232–2250. (<a
href="https://doi.org/10.1109/JPROC.2020.3029453">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advances in deep neural networks (DNNs) and the availability of massive real-world data have enabled superhuman levels of accuracy on many AI tasks and ushered the explosive growth of AI workloads across the spectrum of computing devices. However, their superior accuracy comes at a high computational cost, which necessitates approaches beyond traditional computing paradigms to improve their operational efficiency. Leveraging the application-level insight of error resilience, we demonstrate how approximate computing (AxC) can significantly boost the efficiency of AI platforms and play a pivotal role in the broader adoption of AI-based applications and services. To this end, we present RaPiD, a multi-tera operations per second (TOPS) AI hardware accelerator core (fabricated at 14-nm technology) that we built from the ground-up using AxC techniques across the stack including algorithms, architecture, programmability, and hardware. We highlight the workload-guided systematic explorations of AxC techniques for AI, including custom number representations, quantization/pruning methodologies, mixed-precision architecture design, instruction sets, and compiler technologies with quality programmability, employed in the RaPiD accelerator.},
  archive      = {J_PIEEE},
  author       = {Swagath Venkataramani and Xiao Sun and Naigang Wang and Chia-Yu Chen and Jungwook Choi and Mingu Kang and Ankur Agarwal and Jinwook Oh and Shubham Jain and Tina Babinsky and Nianzheng Cao and Thomas Fox and Bruce Fleischer and George Gristede and Michael Guillorn and Howard Haynie and Hiroshi Inoue and Kazuaki Ishizaki and Michael Klaiber and Shih-Hsien Lo and Gary Maier and Silvia Mueller and Michael Scheuermann and Eri Ogawa and Marcel Schaal and Mauricio Serrano and Joel Silberman and Christos Vezyrtzis and Wei Wang and Fanchieh Yee and Jintao Zhang and Matthew Ziegler and Ching Zhou and Moriyoshi Ohara and Pong-Fei Lu and Brian Curran and Sunil Shukla and Vijayalakshmi Srinivasan and Leland Chang and Kailash Gopalakrishnan},
  doi          = {10.1109/JPROC.2020.3029453},
  journal      = {Proceedings of the IEEE},
  number       = {12},
  pages        = {2232-2250},
  shortjournal = {Proc. IEEE},
  title        = {Efficient AI system design with cross-layer approximate computing},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Security in approximate computing and approximate computing
for security: Challenges and opportunities. <em>PIEEE</em>,
<em>108</em>(12), 2214–2231. (<a
href="https://doi.org/10.1109/JPROC.2020.3030121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Approximate computing is an advanced computational technique that trades the accuracy of computation results for better utilization of system resources. It has emerged as a new preferable paradigm over traditional computing architectures for many applications where inaccurate results are acceptable. However, approximate computing also introduces security vulnerabilities mainly due to the fact that the uncertain and unpredictable intrinsic errors during approximate execution may be indistinguishable from malicious modification of the input data, the execution process, and the results. On the other hand, interestingly, approximate computing presents new opportunities to secure the system and the computation. Existing work on the security of approximate computing covers threat models, countermeasures, and evaluations but lacks a framework for analysis and comparison. In this article, we provide a classification of the state-of-the-art works in this research field, including threat models in approximate computing and promising security approaches using approximate computing. Open questions and potential future research directions are also discussed.},
  archive      = {J_PIEEE},
  author       = {Weiqiang Liu and Chongyan Gu and Máire O’Neill and Gang Qu and Paolo Montuschi and Fabrizio Lombardi},
  doi          = {10.1109/JPROC.2020.3030121},
  journal      = {Proceedings of the IEEE},
  number       = {12},
  pages        = {2214-2231},
  shortjournal = {Proc. IEEE},
  title        = {Security in approximate computing and approximate computing for security: Challenges and opportunities},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Approximate logic synthesis: A survey. <em>PIEEE</em>,
<em>108</em>(12), 2195–2213. (<a
href="https://doi.org/10.1109/JPROC.2020.3014430">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Approximate computing is an emerging paradigm that, by relaxing the requirement for full accuracy, offers benefits in terms of design area and power consumption. This paradigm is particularly attractive in applications where the underlying computation has inherent resilience to small errors. Such applications are abundant in many domains, including machine learning, computer vision, and signal processing. In circuit design, a major challenge is the capability to synthesize the approximate circuits automatically without manually relying on the expertise of designers. In this work, we review methods devised to synthesize approximate circuits, given their exact functionality and an approximability threshold. We summarize strategies for evaluating the error that circuit simplification can induce on the output, which guides synthesis techniques in choosing the circuit transformations that lead to the largest benefit for a given amount of induced error. We then review circuit simplification methods that operate at the gate or Boolean level, including those that leverage classical Boolean synthesis techniques to realize the approximations. We also summarize strategies that take high-level descriptions, such as C or behavioral Verilog, and synthesize approximate circuits from these descriptions.},
  archive      = {J_PIEEE},
  author       = {Ilaria Scarabottolo and Giovanni Ansaloni and George A. Constantinides and Laura Pozzi and Sherief Reda},
  doi          = {10.1109/JPROC.2020.3014430},
  journal      = {Proceedings of the IEEE},
  number       = {12},
  pages        = {2195-2213},
  shortjournal = {Proc. IEEE},
  title        = {Approximate logic synthesis: A survey},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey of testing techniques for approximate integrated
circuits. <em>PIEEE</em>, <em>108</em>(12), 2178–2194. (<a
href="https://doi.org/10.1109/JPROC.2020.2999613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Approximate computing (AxC) is increasingly emerging as a new design paradigm to produce more efficient computation systems by judiciously reducing the computation quality. In particular, AxC has been successfully applied to integrated circuits (ICs), in the last years. Hence, concerning the test of such new class of ICs, namely approximate ICs (AxICs), new challenges-as well as new opportunities-have emerged. In this survey, we provide a thorough analysis of issues related to test procedures for AxICs and review the state-of-the-art techniques to deal with them. We resort to an illustrative example having the twofold aim of: 1) guiding the reader through the AxIC testing challenges and 2) illustrating the existing solutions to correctly overcome them, while suitably taking advantage of opportunities coming from approximation. We analyze experimentally the most recent testing techniques for AxICs and highlight their mature aspects, as well as their shortcomings. Experimental outcomes show that the testing process for AxIC is not completely mature. Indeed, only under specific conditions existing testing procedures achieve good results.},
  archive      = {J_PIEEE},
  author       = {Marcello Traiola and Arnaud Virazel and Patrick Girard and Mario Barbareschi and Alberto Bosio},
  doi          = {10.1109/JPROC.2020.2999613},
  journal      = {Proceedings of the IEEE},
  number       = {12},
  pages        = {2178-2194},
  shortjournal = {Proc. IEEE},
  title        = {A survey of testing techniques for approximate integrated circuits},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Circuit-level techniques for logic and memory blocks in
approximate computing systemsx. <em>PIEEE</em>, <em>108</em>(12),
2150–2177. (<a
href="https://doi.org/10.1109/JPROC.2020.3020792">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents an overview of circuit-level techniques used for approximate computing (AC), including both computation and data storage units. After providing some background concept and methodology review, this article proceeds to provide a detailed review of prior art in circuit-level approximation techniques for data path and memory. The focus is on identifying key circuit-level approximation techniques that are applicable to the computational blocks in general and for both volatile and nonvolatile memory circuit technologies. Emphasis is also placed on the error metrics used to assess the output quality of approximate compute and memory units and whether the accuracy setting is dynamically reconfigurable. This article is concluded with a summary of the key distinguishing features of the reviewed prior art.},
  archive      = {J_PIEEE},
  author       = {Saba Amanollahi and Mehdi Kamal and Ali Afzali-Kusha and Massoud Pedram},
  doi          = {10.1109/JPROC.2020.3020792},
  journal      = {Proceedings of the IEEE},
  number       = {12},
  pages        = {2150-2177},
  shortjournal = {Proc. IEEE},
  title        = {Circuit-level techniques for logic and memory blocks in approximate computing systemsx},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Elementary functions and approximate computing.
<em>PIEEE</em>, <em>108</em>(12), 2136–2149. (<a
href="https://doi.org/10.1109/JPROC.2020.2991885">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we review some of the classical methods used for quickly obtaining low-precision approximations to the elementary functions. Then, for each of the three main classes of elementary function algorithms (shift-and-add algorithms, polynomial or rational approximations, and table-based methods) and for the additional, specific to approximate computing, “bit-manipulation” techniques, we examine what can be done for obtaining very fast estimates of a function, at the cost of a (controlled) loss in terms of accuracy.},
  archive      = {J_PIEEE},
  author       = {Jean-Michel Muller},
  doi          = {10.1109/JPROC.2020.2991885},
  journal      = {Proceedings of the IEEE},
  number       = {12},
  pages        = {2136-2149},
  shortjournal = {Proc. IEEE},
  title        = {Elementary functions and approximate computing},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Approximate arithmetic circuits: A survey, characterization,
and recent applications. <em>PIEEE</em>, <em>108</em>(12), 2108–2135.
(<a href="https://doi.org/10.1109/JPROC.2020.3006451">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Approximate computing has emerged as a new paradigm for high-performance and energy-efficient design of circuits and systems. For the many approximate arithmetic circuits proposed, it has become critical to understand a design or approximation technique for a specific application to improve performance and energy efficiency with a minimal loss in accuracy. This article aims to provide a comprehensive survey and a comparative evaluation of recently developed approximate arithmetic circuits under different design constraints. Specifically, approximate adders, multipliers, and dividers are synthesized and characterized under optimizations for performance and area. The error and circuit characteristics are then generalized for different classes of designs. The applications of these circuits in image processing and deep neural networks indicate that the circuits with lower error rates or error biases perform better in simple computations, such as the sum of products, whereas more complex accumulative computations that involve multiple matrix multiplications and convolutions are vulnerable to single-sided errors that lead to a large error bias in the computed result. Such complex computations are more sensitive to errors in addition than those in multiplication, so a larger approximation can be tolerated in multipliers than in adders. The use of approximate arithmetic circuits can improve the quality of image processing and deep learning in addition to the benefits in performance and power consumption for these applications.},
  archive      = {J_PIEEE},
  author       = {Honglan Jiang and Francisco Javier Hernandez Santiago and Hai Mo and Leibo Liu and Jie Han},
  doi          = {10.1109/JPROC.2020.3006451},
  journal      = {Proceedings of the IEEE},
  number       = {12},
  pages        = {2108-2135},
  shortjournal = {Proc. IEEE},
  title        = {Approximate arithmetic circuits: A survey, characterization, and recent applications},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Approximate computing: From circuits to applications
[scanning the issue]. <em>PIEEE</em>, <em>108</em>(12), 2103–2107. (<a
href="https://doi.org/10.1109/JPROC.2020.3033361">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This special issue explores the technological contributions and developments of approximate computing at disparate levels and provides insight into exciting directions for the future.},
  archive      = {J_PIEEE},
  author       = {Weiqiang Liu and Fabrizio Lombardi and Michael Schulte},
  doi          = {10.1109/JPROC.2020.3033361},
  journal      = {Proceedings of the IEEE},
  number       = {12},
  pages        = {2103-2107},
  shortjournal = {Proc. IEEE},
  title        = {Approximate computing: From circuits to applications [Scanning the issue]},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Recruit a member. <em>PIEEE</em>, <em>108</em>(11), 2100.
(<a href="https://doi.org/10.1109/JPROC.2020.3031806">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advertisement, IEEE.},
  archive      = {J_PIEEE},
  doi          = {10.1109/JPROC.2020.3031806},
  journal      = {Proceedings of the IEEE},
  number       = {11},
  pages        = {2100},
  shortjournal = {Proc. IEEE},
  title        = {Recruit a member},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). IEEE women in engineering. <em>PIEEE</em>,
<em>108</em>(11), 2099. (<a
href="https://doi.org/10.1109/JPROC.2020.3031804">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advertisement, IEEE.},
  archive      = {J_PIEEE},
  doi          = {10.1109/JPROC.2020.3031804},
  journal      = {Proceedings of the IEEE},
  number       = {11},
  pages        = {2099},
  shortjournal = {Proc. IEEE},
  title        = {IEEE women in engineering},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The bell versus gray telephone dispute: Resolving a
144-year-old controversy [scanning our past]. <em>PIEEE</em>,
<em>108</em>(11), 2083–2096. (<a
href="https://doi.org/10.1109/JPROC.2020.3017876">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {On February 14, 1876, attorneys for Alexander Graham Bell, speech teacher for the deaf, and Elisha Gray, professional inventor, submitted their clients&#39; similar talking telegraph, or telephone, ideas to the U.S. Patent Office. The Patent Office ruled that Bell&#39;s application had arrived first and the telephone patent, one of the most valuable patents in history, was issued to Bell on March 7. On March 10, shortly after Bell had visited Washington, D. C., he demonstrated the first working telephone, based on a liquid transmitter similar to that described in Gray&#39;s confidential patent caveat, which Bell could have illicitly seen during his trip. Did Bell and his attorneys plagiarize Gray and commit fraud with others as several have claimed? This article centers on the controversy between Bell and Gray, and the persistent claim that Gray conceived of the first working telephone before Bell. Three independent sets of evidence - correspondence, notes from a Bell associate, and engineering details - show that Bell and his attorneys did not plagiarize Gray. This resolves a 144-year-old controversy and re-establish Bell&#39;s reputation.},
  archive      = {J_PIEEE},
  author       = {Benjamin Lathrop Brown},
  doi          = {10.1109/JPROC.2020.3017876},
  journal      = {Proceedings of the IEEE},
  number       = {11},
  pages        = {2083-2096},
  shortjournal = {Proc. IEEE},
  title        = {The bell versus gray telephone dispute: Resolving a 144-year-old controversy [Scanning our past]},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Accelerated first-order optimization algorithms for machine
learning. <em>PIEEE</em>, <em>108</em>(11), 2067–2082. (<a
href="https://doi.org/10.1109/JPROC.2020.3007634">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerical optimization serves as one of the pillars of machine learning. To meet the demands of big data applications, lots of efforts have been put on designing theoretically and practically fast algorithms. This article provides a comprehensive survey on accelerated first-order algorithms with a focus on stochastic algorithms. Specifically, this article starts with reviewing the basic accelerated algorithms on deterministic convex optimization, then concentrates on their extensions to stochastic convex optimization, and at last introduces some recent developments on acceleration for nonconvex optimization.},
  archive      = {J_PIEEE},
  author       = {Huan Li and Cong Fang and Zhouchen Lin},
  doi          = {10.1109/JPROC.2020.3007634},
  journal      = {Proceedings of the IEEE},
  number       = {11},
  pages        = {2067-2082},
  shortjournal = {Proc. IEEE},
  title        = {Accelerated first-order optimization algorithms for machine learning},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Graph learning under partial observability. <em>PIEEE</em>,
<em>108</em>(11), 2049–2066. (<a
href="https://doi.org/10.1109/JPROC.2020.3013432">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many optimization, inference, and learning tasks can be accomplished efficiently by means of decentralized processing algorithms where the network topology (i.e., the graph) plays a critical role in enabling the interactions among neighboring nodes. There is a large body of literature examining the effect of the graph structure on the performance of decentralized processing strategies. In this article, we examine the inverse problem and consider the reverse question: How much information does observing the behavior at the nodes of a graph convey about the underlying topology? For large-scale networks, the difficulty in addressing such inverse problems is compounded by the fact that usually only a limited fraction of the nodes can be probed, giving rise to a second important question: Despite the presence of unobserved nodes, can partial observations still be sufficient to discover the graph linking the probed nodes? The article surveys recent advances on this challenging learning problem and related questions.},
  archive      = {J_PIEEE},
  author       = {Vincenzo Matta and Augusto Santos and Ali H. Sayed},
  doi          = {10.1109/JPROC.2020.3013432},
  journal      = {Proceedings of the IEEE},
  number       = {11},
  pages        = {2049-2066},
  shortjournal = {Proc. IEEE},
  title        = {Graph learning under partial observability},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Time-varying convex optimization: Time-structured algorithms
and applications. <em>PIEEE</em>, <em>108</em>(11), 2032–2048. (<a
href="https://doi.org/10.1109/JPROC.2020.3003156">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimization underpins many of the challenges that science and technology face on a daily basis. Recent years have witnessed a major shift from traditional optimization paradigms grounded on batch algorithms for medium-scale problems to challenging dynamic, time-varying, and even huge-size settings. This is driven by technological transformations that converted infrastructural and social platforms into complex and dynamic networked systems with even pervasive sensing and computing capabilities. This article reviews a broad class of state-of-the-art algorithms for time-varying optimization, with an eye to performing both algorithmic development and performance analysis. It offers a comprehensive overview of available tools and methods and unveils open challenges in application domains of broad range of interest. The real-world examples presented include smart power systems, robotics, machine learning, and data analytics, highlighting domain-specific issues and solutions. The ultimate goal is to exemplify wide engineering relevance of analytical tools and pertinent theoretical foundations.},
  archive      = {J_PIEEE},
  author       = {Andrea Simonetto and Emiliano Dall&#39;Anese and Santiago Paternain and Geert Leus and Georgios B. Giannakis},
  doi          = {10.1109/JPROC.2020.3003156},
  journal      = {Proceedings of the IEEE},
  number       = {11},
  pages        = {2032-2048},
  shortjournal = {Proc. IEEE},
  title        = {Time-varying convex optimization: Time-structured algorithms and applications},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Advances in asynchronous parallel and distributed
optimization. <em>PIEEE</em>, <em>108</em>(11), 2013–2031. (<a
href="https://doi.org/10.1109/JPROC.2020.3026619">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by large-scale optimization problems arising in the context of machine learning, there have been several advances in the study of asynchronous parallel and distributed optimization methods during the past decade. Asynchronous methods do not require all processors to maintain a consistent view of the optimization variables. Consequently, they generally can make more efficient use of computational resources than synchronous methods, and they are not sensitive to issues like stragglers (i.e., slow nodes) and unreliable communication links. Mathematical modeling of asynchronous methods involves proper accounting of information delays, which makes their analysis challenging. This article reviews recent developments in the design and analysis of asynchronous optimization methods, covering both centralized methods, where all processors update a master copy of the optimization variables, and decentralized methods, where each processor maintains a local copy of the variables. The analysis provides insights into how the degree of asynchrony impacts convergence rates, especially in stochastic optimization methods.},
  archive      = {J_PIEEE},
  author       = {By Mahmoud Assran and Arda Aytekin and Hamid Reza Feyzmahdavian and Mikael Johansson and Michael G. Rabbat},
  doi          = {10.1109/JPROC.2020.3026619},
  journal      = {Proceedings of the IEEE},
  number       = {11},
  pages        = {2013-2031},
  shortjournal = {Proc. IEEE},
  title        = {Advances in asynchronous parallel and distributed optimization},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Scaling-up distributed processing of data streams for
machine learning. <em>PIEEE</em>, <em>108</em>(11), 1984–2012. (<a
href="https://doi.org/10.1109/JPROC.2020.3021381">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emerging applications of machine learning in numerous areas-including online social networks, remote sensing, Internet-of-Things (IoT) systems, smart grids, and more-involve continuous gathering of and learning from streams of data samples. Real-time incorporation of streaming data into the learned machine learning models is essential for improved inference in these applications. Furthermore, these applications often involve data that are either inherently gathered at geographically distributed entities due to physical reasons, for example, IoT systems and smart grids, or that are intentionally distributed across multiple computing machines for memory, storage, computational, and/or privacy reasons. Training of machine learning models in this distributed, streaming setting requires solving stochastic optimization (SO) problems in a collaborative manner over communication links between the physical entities. When the streaming data rate is high compared with the processing capabilities of individual computing entities and/or the rate of the communications links, this poses a challenging question: How can one best leverage the incoming data for distributed training of machine learning models under constraints on computing capabilities and/or communications rate? A large body of research in distributed online optimization has emerged in recent decades to tackle this and related problems. This article reviews recently developed methods that focus on large-scale distributed SO in the compute- and bandwidth-limited regimes, with an emphasis on convergence analysis that explicitly accounts for the mismatch between computation, communication, and streaming rates and provides sufficient conditions for order-optimum convergence. In particular, it focuses on methods that solve: 1) distributed stochastic convex problems and 2) distributed principal component analysis, which is a nonconvex problem with the geometric structure that permits global convergence. For such methods, this article discusses recent advances in terms of distributed algorithmic designs when faced with high-rate streaming data. Furthermore, it reviews theoretical guarantees underlying these methods that show that there exist regimes in which systems can learn from distributed processing of streaming data at order-optimal rates-nearly as fast as if all the data were processed at a single superpowerful machine.},
  archive      = {J_PIEEE},
  author       = {Matthew Nokleby and Haroon Raja and Waheed U. Bajwa},
  doi          = {10.1109/JPROC.2020.3021381},
  journal      = {Proceedings of the IEEE},
  number       = {11},
  pages        = {1984-2012},
  shortjournal = {Proc. IEEE},
  title        = {Scaling-up distributed processing of data streams for machine learning},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Variance-reduced methods for machine learning.
<em>PIEEE</em>, <em>108</em>(11), 1968–1983. (<a
href="https://doi.org/10.1109/JPROC.2020.3028013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic optimization lies at the heart of machine learning, and its cornerstone is stochastic gradient descent (SGD), a method introduced over 60 years ago. The last eight years have seen an exciting new development: variance reduction for stochastic optimization methods. These variance-reduced (VR) methods excel in settings where more than one pass through the training data is allowed, achieving a faster convergence than SGD in theory and practice. These speedups underline the surge of interest in VR methods and the fast-growing body of work on this topic. This review covers the key principles and main developments behind VR methods for optimization with finite data sets and is aimed at nonexpert readers. We focus mainly on the convex setting and leave pointers to readers interested in extensions for minimizing nonconvex functions.},
  archive      = {J_PIEEE},
  author       = {Robert M. Gower and Mark Schmidt and Francis Bach and Peter Richtárik},
  doi          = {10.1109/JPROC.2020.3028013},
  journal      = {Proceedings of the IEEE},
  number       = {11},
  pages        = {1968-1983},
  shortjournal = {Proc. IEEE},
  title        = {Variance-reduced methods for machine learning},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Distributed optimization for robot networks: From real-time
convex optimization to game-theoretic self-organization. <em>PIEEE</em>,
<em>108</em>(11), 1953–1967. (<a
href="https://doi.org/10.1109/JPROC.2020.3028295">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in sensing, communication, and computing technologies have enabled the use of multirobot systems for practical applications such as surveillance, area mapping, and search and rescue. For such systems, a major challenge is to design decision rules that are real-time-implementable, require local information only, and guarantee some desired global performance. Distributed optimization provides a framework for designing such local decision-making rules for multirobot systems. In this article, we present a collection of selected results for distributed optimization for robot networks. We will focus on two special classes of problems: 1) real-time path planning for multirobot systems and 2) self-organization in multirobot systems using game-theoretic approaches. For multirobot path planning, we will present some recent approaches that are based on approximately solving distributed optimization problems over continuous and discrete domains of actions. The main idea underlying these approaches is that a variety of path planning problems can be formulated as convex optimization and submodular minimization problems over continuous and discrete action spaces, respectively. To generate local update rules that are efficiently implementable in real time, these approaches rely on approximate solutions to the global problems that can still guarantee some level of desired global performance. For game-theoretic self-organization, we will present a sampling of results for area coverage and real-time target assignment. In these results, the problems are formulated as games, and online updating rules are designed to enable teams of robots to achieve the collective objective in a distributed manner.},
  archive      = {J_PIEEE},
  author       = {Hassan Jaleel and Jeff S. Shamma},
  doi          = {10.1109/JPROC.2020.3028295},
  journal      = {Proceedings of the IEEE},
  number       = {11},
  pages        = {1953-1967},
  shortjournal = {Proc. IEEE},
  title        = {Distributed optimization for robot networks: From real-time convex optimization to game-theoretic self-organization},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Distributed optimization, averaging via ADMM, and network
topology. <em>PIEEE</em>, <em>108</em>(11), 1939–1952. (<a
href="https://doi.org/10.1109/JPROC.2020.3022687">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There has been an increasing necessity for scalable optimization methods, especially due to the explosion in the size of data sets and model complexity in modern machine learning applications. Scalable solvers often distribute the computation over a network of processing units. For simple algorithms, such as gradient descent, the dependence of the convergence time with the topology of this network is well known. However, for more involved algorithms, such as the alternating direction method of multipliers (ADMM), much less is known. At the heart of many distributed optimization algorithms, there exists a gossip subroutine which averages local information over the network, whose efficiency is crucial for the overall performance of the method. In this article, we review recent research in this area, and with the goal of isolating such a communication exchange behavior, we compare different algorithms when applied to a canonical distributed averaging consensus problem. We also show interesting connections between ADMM and the lifted Markov chains besides providing an explicit characterization of its convergence and optimal parameter tuning in terms of spectral properties of the network. Finally, we empirically study the connection between network topology and convergence rates for different algorithms on a real-world problem of sensor localization.},
  archive      = {J_PIEEE},
  author       = {Guilherme França and José Bento},
  doi          = {10.1109/JPROC.2020.3022687},
  journal      = {Proceedings of the IEEE},
  number       = {11},
  pages        = {1939-1952},
  shortjournal = {Proc. IEEE},
  title        = {Distributed optimization, averaging via ADMM, and network topology},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Primal–dual methods for large-scale and distributed convex
optimization and data analytics. <em>PIEEE</em>, <em>108</em>(11),
1923–1938. (<a
href="https://doi.org/10.1109/JPROC.2020.3007395">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The augmented Lagrangian method (ALM) is a classical optimization tool that solves a given “difficult” (constrained) problem via finding solutions of a sequence of “easier” (often unconstrained) subproblems with respect to the original (primal) variable, wherein constraints satisfaction is controlled via the so-called dual variables. ALM is highly flexible with respect to how primal subproblems can be solved, giving rise to a plethora of different primal-dual methods. The powerful ALM mechanism has recently proved to be very successful in various large-scale and distributed applications. In addition, several significant advances have appeared, primarily on precise complexity results with respect to computational and communication costs in the presence of inexact updates and design and analysis of novel optimal methods for distributed consensus optimization. We provide a tutorial-style introduction to ALM and its variants for solving convex optimization problems in large-scale and distributed settings. We describe control-theoretic tools for the algorithms&#39; analysis and design, survey recent results, and provide novel insights into the context of two emerging applications: federated learning and distributed energy trading.},
  archive      = {J_PIEEE},
  author       = {Dušan Jakovetić and Dragana Bajović and João Xavier and José M. F. Moura},
  doi          = {10.1109/JPROC.2020.3007395},
  journal      = {Proceedings of the IEEE},
  number       = {11},
  pages        = {1923-1938},
  shortjournal = {Proc. IEEE},
  title        = {Primal–Dual methods for large-scale and distributed convex optimization and data analytics},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stochastic quasi-newton methods. <em>PIEEE</em>,
<em>108</em>(11), 1906–1922. (<a
href="https://doi.org/10.1109/JPROC.2020.3023660">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale data science trains models for data sets containing massive numbers of samples. Training is often formulated as the solution of empirical risk minimization problems that are optimization programs whose complexity scales with the number of elements in the data set. Stochastic optimization methods overcome this challenge, but they come with their own set of limitations. This article discusses recent developments to accelerate the convergence of stochastic optimization through the exploitation of second-order information. This is achieved with stochastic variants of quasi-Newton methods that approximate the curvature of the objective function using stochastic gradient information. The reasons for why this leads to faster convergence are discussed along with the introduction of an incremental method that exploits memory to achieve a superlinear convergence rate. This is the best-known convergence rate for a stochastic optimization method. Stochastic quasi-Newton methods are applied to several problems, including prediction of the click-through rate of an advertisement displayed in response to a specific search engine query by a specific visitor. Experimental evaluations showcase reductions in overall computation time relative to stochastic gradient descent algorithms.},
  archive      = {J_PIEEE},
  author       = {Aryan Mokhtari and Alejandro Ribeiro},
  doi          = {10.1109/JPROC.2020.3023660},
  journal      = {Proceedings of the IEEE},
  number       = {11},
  pages        = {1906-1922},
  shortjournal = {Proc. IEEE},
  title        = {Stochastic quasi-newton methods},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Decentralized zeroth-order constrained stochastic
optimization algorithms: Frank–wolfe and variants with applications to
black-box adversarial attacks. <em>PIEEE</em>, <em>108</em>(11),
1890–1905. (<a
href="https://doi.org/10.1109/JPROC.2020.3012609">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zeroth-order optimization algorithms are an attractive alternative for stochastic optimization problems, when gradient computations are expensive or when closed-form loss functions are not available. Recently, there has been a surge of activity in utilizing zeroth-order optimization algorithms in myriads of applications including black-box adversarial attacks on machine learning frameworks, reinforcement learning, and simulation-based optimization, to name a few. In addition to utilizing the simplicity of a typical zeroth-order optimization scheme, distributed implementations of zeroth-order schemes so as to exploit data parallelizability are getting significant attention recently. This article presents an overview of recent work in the area of distributed zeroth-order optimization, focusing on constrained optimization settings and algorithms built around the Frank-Wolfe framework. In particular, we review different types of architectures, from master-worker-based decentralized to fully distributed, and describe appropriate zeroth-order projection-free schemes for solving constrained stochastic optimization problems catered to these architectures. We discuss performance issues including convergence rates and dimension dependence. In addition, we also focus on more refined extensions such as by employing variance reduction and describe and quantify convergence rates for a variance-reduced decentralized zeroth-order optimization method inspired by martingale difference sequences. We discuss limitations of zeroth-order optimization frameworks in terms of dimension dependence. Finally, we illustrate the use of distributed zeroth-order algorithms in the context of adversarial attacks on deep learning models.},
  archive      = {J_PIEEE},
  author       = {Anit Kumar Sahu and Soummya Kar},
  doi          = {10.1109/JPROC.2020.3012609},
  journal      = {Proceedings of the IEEE},
  number       = {11},
  pages        = {1890-1905},
  shortjournal = {Proc. IEEE},
  title        = {Decentralized zeroth-order constrained stochastic optimization algorithms: Frank–Wolfe and variants with applications to black-box adversarial attacks},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A general framework for decentralized optimization with
first-order methods. <em>PIEEE</em>, <em>108</em>(11), 1869–1889. (<a
href="https://doi.org/10.1109/JPROC.2020.3024266">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decentralized optimization to minimize a finite sum of functions, distributed over a network of nodes, has been a significant area within control and signal-processing research due to its natural relevance to optimal control and signal estimation problems. More recently, the emergence of sophisticated computing and large-scale data science needs have led to a resurgence of activity in this area. In this article, we discuss decentralized first-order gradient methods, which have found tremendous success in control, signal processing, and machine learning problems, where such methods, due to their simplicity, serve as the first method of choice for many complex inference and training tasks. In particular, we provide a general framework of decentralized first-order methods that is applicable to directed and undirected communication networks alike and show that much of the existing work on optimization and consensus can be related explicitly to this framework. We further extend the discussion to decentralized stochastic first-order methods that rely on stochastic gradients at each node and describe how local variance reduction schemes, previously shown to have promise in the centralized settings, are able to improve the performance of decentralized methods when combined with what is known as gradient tracking. We motivate and demonstrate the effectiveness of the corresponding methods in the context of machine learning and signal-processing problems that arise in decentralized environments.},
  archive      = {J_PIEEE},
  author       = {Ran Xin and Shi Pu and Angelia Nedić and Usman A. Khan},
  doi          = {10.1109/JPROC.2020.3024266},
  journal      = {Proceedings of the IEEE},
  number       = {11},
  pages        = {1869-1889},
  shortjournal = {Proc. IEEE},
  title        = {A general framework for decentralized optimization with first-order methods},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimization for data-driven learning and control.
<em>PIEEE</em>, <em>108</em>(11), 1863–1868. (<a
href="https://doi.org/10.1109/JPROC.2020.3031225">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This special issue provides a comprehensive overview of modern optimization tools and methods for the purposes of data-driven learning and control.},
  archive      = {J_PIEEE},
  author       = {Usman A. Khan and Waheed U. Bajwa and Angelia Nedić and Michael G. Rabbat and Ali H. Sayed},
  doi          = {10.1109/JPROC.2020.3031225},
  journal      = {Proceedings of the IEEE},
  number       = {11},
  pages        = {1863-1868},
  shortjournal = {Proc. IEEE},
  title        = {Optimization for data-driven learning and control},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020c). IEEE women in engineering. <em>PIEEE</em>,
<em>108</em>(10), 1860. (<a
href="https://doi.org/10.1109/JPROC.2020.3026201">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advertisement, IEEE.},
  archive      = {J_PIEEE},
  doi          = {10.1109/JPROC.2020.3026201},
  journal      = {Proceedings of the IEEE},
  number       = {10},
  pages        = {1860},
  shortjournal = {Proc. IEEE},
  title        = {IEEE women in engineering},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The incredible rocket-engine laser [scanning our past].
<em>PIEEE</em>, <em>108</em>(10), 1849–1857. (<a
href="https://doi.org/10.1109/JPROC.2020.3013579">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Charles Townes’s original laser proposal envisioned a low-power coherent light source for communications. Theodore Maiman’s demonstration of the first laser at Hughes Research Laboratories in 1960 produced bright pulses of red light and gave great hopes for bigger and better things, especially in the Pentagon. Two years later, a Sunday newspaper supplement feature titled “The Incredible Laser: Death Ray or Hope” illustrated with science-fictional laser cannons, opined: The laser may have greater impact than any discovery so far in the burgeoning field of electronics, which has already brought us radar, transistors, satellite tracking networks, [and] TV. The technological revolution it brings about may dwarf any in the past [1].},
  archive      = {J_PIEEE},
  author       = {Jeff Hecht},
  doi          = {10.1109/JPROC.2020.3013579},
  journal      = {Proceedings of the IEEE},
  number       = {10},
  pages        = {1849-1857},
  shortjournal = {Proc. IEEE},
  title        = {The incredible rocket-engine laser [Scanning our past]},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Software vulnerability detection using deep neural networks:
A survey. <em>PIEEE</em>, <em>108</em>(10), 1825–1848. (<a
href="https://doi.org/10.1109/JPROC.2020.2993293">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The constantly increasing number of disclosed security vulnerabilities have become an important concern in the software industry and in the field of cybersecurity, suggesting that the current approaches for vulnerability detection demand further improvement. The booming of the open-source software community has made vast amounts of software code available, which allows machine learning and data mining techniques to exploit abundant patterns within software code. Particularly, the recent breakthrough application of deep learning to speech recognition and machine translation has demonstrated the great potential of neural models’ capability of understanding natural languages. This has motivated researchers in the software engineering and cybersecurity communities to apply deep learning for learning and understanding vulnerable code patterns and semantics indicative of the characteristics of vulnerable code. In this survey, we review the current literature adopting deep-learning-/neural-network-based approaches for detecting software vulnerabilities, aiming at investigating how the state-of-the-art research leverages neural techniques for learning and understanding code semantics to facilitate vulnerability discovery. We also identify the challenges in this new field and share our views of potential research directions.},
  archive      = {J_PIEEE},
  author       = {Guanjun Lin and Sheng Wen and Qing-Long Han and Jun Zhang and Yang Xiang},
  doi          = {10.1109/JPROC.2020.2993293},
  journal      = {Proceedings of the IEEE},
  number       = {10},
  pages        = {1825-1848},
  shortjournal = {Proc. IEEE},
  title        = {Software vulnerability detection using deep neural networks: A survey},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Digital twin in the IoT context: A survey on technical
features, scenarios, and architectural models. <em>PIEEE</em>,
<em>108</em>(10), 1785–1824. (<a
href="https://doi.org/10.1109/JPROC.2020.2998530">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital twin (DT) is an emerging concept that is gaining attention in various industries. It refers to the ability to clone a physical object (PO) into a software counterpart. The softwarized object, termed logical object, reflects all the important properties and characteristics of the original object within a specific application context. To fully determine the expected properties of the DT, this article surveys the state-of-the-art starting from the original definition within the manufacturing industry. It takes into account related proposals emerging in other fields, namely augmented and virtual reality (e.g., avatars), multiagent systems, and virtualization. This survey thereby allows for the identification of an extensive set of DT features that point to the “softwarization” of POs. To properly consolidate a shared DT definition, a set of foundational properties is identified and proposed as a common ground outlining the essential characteristics (must-haves) of a DT. Once the DT definition has been consolidated, its technical and business value is discussed in terms of applicability and opportunities. Four application scenarios illustrate how the DT concept can be used and how some industries are applying it. The scenarios also lead to a generic DT architectural model. This analysis is then complemented by the identification of software architecture models and guidelines in order to present a general functional framework for the DT. This article, eventually, analyses a set of possible evolution paths for the DT considering its possible usage as a major enabler for the softwarization process.},
  archive      = {J_PIEEE},
  author       = {Roberto Minerva and Gyu Myoung Lee and Noël Crespi},
  doi          = {10.1109/JPROC.2020.2998530},
  journal      = {Proceedings of the IEEE},
  number       = {10},
  pages        = {1785-1824},
  shortjournal = {Proc. IEEE},
  title        = {Digital twin in the IoT context: A survey on technical features, scenarios, and architectural models},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Integrated nonreciprocal photonic devices with dynamic
modulation. <em>PIEEE</em>, <em>108</em>(10), 1759–1784. (<a
href="https://doi.org/10.1109/JPROC.2020.3023959">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonreciprocal components, such as isolators and circulators, are crucial components for photonic systems. In this article, we review theoretical and experimental progress toward developing nonreciprocal photonic devices based on dynamic modulation. In particular, we focus on approaches that operate at optical wavelengths and device architectures that have the potential for chip-scale integration. We first discuss the requirements for constructing an isolator or circulator using dynamic modulation. We review a number of different isolator and circulator architectures, including waveguide and resonant devices, and describe their underlying operating principles. We then compare these device architectures from a system-level performance perspective, considering how their figures of merit, such as footprint, bandwidth, isolation, and insertion loss scale with respect to device parameters.},
  archive      = {J_PIEEE},
  author       = {Ian A. D. Williamson and Momchil Minkov and Avik Dutt and Jiahui Wang and Alex Y. Song and Shanhui Fan},
  doi          = {10.1109/JPROC.2020.3023959},
  journal      = {Proceedings of the IEEE},
  number       = {10},
  pages        = {1759-1784},
  shortjournal = {Proc. IEEE},
  title        = {Integrated nonreciprocal photonic devices with dynamic modulation},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Microwave nonreciprocity. <em>PIEEE</em>, <em>108</em>(10),
1728–1758. (<a
href="https://doi.org/10.1109/JPROC.2020.3006041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we provide a comprehensive review of past and present efforts in the field of microwave nonreciprocity with an emphasis on the most commonly used nonreciprocal devices, namely gyrators, isolators, and circulators. After discussing the origin and history of such efforts, we elaborate on the pros and cons of four distinct approaches to break reciprocity which include magnetic biasing of ferrite materials, intrinsic nonreciprocity of solid-state devices, nonlinearities with geometric asymmetries, and finally, periodic spatiotemporal variation. We subsequently pay due attention to the spatiotemporal approach and show that the recently emerging proposals to achieve magnet-free nonreciprocity with linear, periodically time-varying circuits can compete with traditional ferrite devices and even outperform them in several metrics, thus opening the door to exciting venues for miniaturized low-cost and high-performance nonreciprocal devices with numerous applications ranging from full-duplex communications and quantum computing to biomedical imaging and radar systems.},
  archive      = {J_PIEEE},
  author       = {Ahmed Kord and Dimitrios L. Sounas and Andrea Alù},
  doi          = {10.1109/JPROC.2020.3006041},
  journal      = {Proceedings of the IEEE},
  number       = {10},
  pages        = {1728-1758},
  shortjournal = {Proc. IEEE},
  title        = {Microwave nonreciprocity},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Tutorial on electromagnetic nonreciprocity and its origins.
<em>PIEEE</em>, <em>108</em>(10), 1684–1727. (<a
href="https://doi.org/10.1109/JPROC.2020.3012381">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This tutorial provides an intuitive and concrete description of the phenomena of electromagnetic nonreciprocity that will be useful for readers with engineering or physics backgrounds. The notion of time reversal and its different definitions are discussed with special emphasis on its relationship with the reciprocity concept. Starting from the Onsager reciprocal relations that are generally applicable to many physical processes, we present the derivation of the Lorentz theorem and discuss other implications of reciprocity for electromagnetic systems. Next, we identify all possible routes toward engineering nonreciprocal devices and analyze three of them in detail, based on external bias and on nonlinear and time-variant systems. The principles of the operation of different nonreciprocal devices are explained. We address the similarity and fundamental difference between nonreciprocal effects and asymmetric transmission in reciprocal systems. In addition to the tutorial description of the topic, this article also contains the original findings. In particular, the general classification of reciprocal and nonreciprocal phenomena in linear bianisotropic media based on the space- and time-reversal symmetries is presented. This classification serves as a powerful tool for drawing analogies between seemingly distinct effects having the same physical origin and can be used for predicting novel electromagnetic phenomena. Furthermore, electromagnetic reciprocity theorem for time-varying systems is derived, and its applicability is discussed.},
  archive      = {J_PIEEE},
  author       = {Viktar S. Asadchy and Mohammad Sajjad Mirmoosa and Ana Díaz-Rubio and Shanhui Fan and Sergei A. Tretyakov},
  doi          = {10.1109/JPROC.2020.3012381},
  journal      = {Proceedings of the IEEE},
  number       = {10},
  pages        = {1684-1727},
  shortjournal = {Proc. IEEE},
  title        = {Tutorial on electromagnetic nonreciprocity and its origins},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Magnet-free nonreciprocity [scanning the section].
<em>PIEEE</em>, <em>108</em>(10), 1682–1683. (<a
href="https://doi.org/10.1109/JPROC.2020.3023895">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electromagnetic waves, from radio signals to light, generally obey a strict symmetry in transmission: if they can travel from point A to point B, they can also travel backward from B to A with the same properties. This general symmetry, rooted in the fact that Maxwell’s equations are symmetric with respect to time and known as reciprocity, has profound implications on a variety of technologies and device functionalities. On the one hand, we count on reciprocity when we operate an antenna, in a variety of measurement schemes, and in analytical/numerical techniques to study the response of electromagnetic systems. On the other hand, reciprocity inherently limits the degree of control in manipulating electromagnetic waves and hence the overall functionality of many devices. For instance, breaking reciprocity enables the possibility of transmitting a signal without having to worry about backreflections, which may harm sensitive equipment or interfere with incoming data streams, and of transmitting and receiving signals through the same transducer at the same frequency and at the same time—the holy grail of full-duplex communication schemes. Fields as diverse as radar technologies, wireless communications, and optical and quantum computing all require nonreciprocal signal routing to enable reception of signal echoes while transmitting, data transmission without worrying about jammers, and to guarantee one-way streams of data that can be robustly processed.},
  archive      = {J_PIEEE},
  author       = {Andrea Alù},
  doi          = {10.1109/JPROC.2020.3023895},
  journal      = {Proceedings of the IEEE},
  number       = {10},
  pages        = {1682-1683},
  shortjournal = {Proc. IEEE},
  title        = {Magnet-free nonreciprocity [Scanning the section]},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020c). Recruit a member. <em>PIEEE</em>, <em>108</em>(9), 1680.
(<a href="https://doi.org/10.1109/JPROC.2020.3016582">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advertisement, IEEE.},
  archive      = {J_PIEEE},
  doi          = {10.1109/JPROC.2020.3016582},
  journal      = {Proceedings of the IEEE},
  number       = {9},
  pages        = {1680},
  shortjournal = {Proc. IEEE},
  title        = {Recruit a member},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Gift of membership. <em>PIEEE</em>, <em>108</em>(9), 1679.
(<a href="https://doi.org/10.1109/JPROC.2020.3016580">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advertisement, IEEE.},
  archive      = {J_PIEEE},
  doi          = {10.1109/JPROC.2020.3016580},
  journal      = {Proceedings of the IEEE},
  number       = {9},
  pages        = {1679},
  shortjournal = {Proc. IEEE},
  title        = {Gift of membership},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020d). IEEE women in engineering. <em>PIEEE</em>, <em>108</em>(9),
1678. (<a href="https://doi.org/10.1109/JPROC.2020.3016576">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advertisement, IEEE.},
  archive      = {J_PIEEE},
  doi          = {10.1109/JPROC.2020.3016576},
  journal      = {Proceedings of the IEEE},
  number       = {9},
  pages        = {1678},
  shortjournal = {Proc. IEEE},
  title        = {IEEE women in engineering},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Recent developments in machine learning for energy systems
reliability management. <em>PIEEE</em>, <em>108</em>(9), 1656–1676. (<a
href="https://doi.org/10.1109/JPROC.2020.2988715">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article reviews recent works applying machine learning (ML) techniques in the context of energy systems&#39; reliability assessment and control. We showcase both the progress achieved to date as well as the important future directions for further research, while providing an adequate background in the fields of reliability management and of ML. The objective is to foster the synergy between these two fields and speed up the practical adoption of ML techniques for energy systems reliability management. We focus on bulk electric power systems and use them as an example, but we argue that the methods, tools, etc. can be extended to other similar systems, such as distribution systems, microgrids, and multienergy systems.},
  archive      = {J_PIEEE},
  author       = {Laurine Duchesne and Efthymios Karangelos and Louis Wehenkel},
  doi          = {10.1109/JPROC.2020.2988715},
  journal      = {Proceedings of the IEEE},
  number       = {9},
  pages        = {1656-1676},
  shortjournal = {Proc. IEEE},
  title        = {Recent developments in machine learning for energy systems reliability management},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Chance-constrained water pumping to manage water and power
demand uncertainty in distribution networks. <em>PIEEE</em>,
<em>108</em>(9), 1640–1655. (<a
href="https://doi.org/10.1109/JPROC.2020.2997520">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Water pumping in drinking water distribution networks (WDNs) can be treated as a flexible load in the power distribution network (PDN). In this article, we formulate an optimization problem to minimize the electricity costs associated with pumping subject to WDN and PDN constraints. In practice, both water and power demands are uncertain and pumps should be scheduled to ensure that pump operation does not violate either networks&#39; constraints for nearly all possible uncertainty realizations. To address this problem, we formulate a chance-constrained (CC) optimization problem that simultaneously determines pumping schedules along with the parameters of real-time control policies that can be used to respond to water and power demand forecast errors. We use approximations and relaxations along with the scenario approach for CC programming to reformulate the optimization problem into a convex deterministic problem. We demonstrate the performance of the approach through case studies and also explore the impact of the relaxations, an approach to improve computational tractability, and tradeoffs associated with the way in which we define the cost of real-time control actions. We find that optimal scheduling and real-time control of water pumping can effectively manage water and power demand uncertainty, meaning water demand is satisfied and both the WDN and PDN operate within their limits; however, the approach is conservative leading to high reliability at high cost.},
  archive      = {J_PIEEE},
  author       = {Anna Stuhlmacher and Johanna L. Mathieu},
  doi          = {10.1109/JPROC.2020.2997520},
  journal      = {Proceedings of the IEEE},
  number       = {9},
  pages        = {1640-1655},
  shortjournal = {Proc. IEEE},
  title        = {Chance-constrained water pumping to manage water and power demand uncertainty in distribution networks},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A critical exploration of the efficiency impacts of demand
response from HVAC in commercial buildings. <em>PIEEE</em>,
<em>108</em>(9), 1623–1639. (<a
href="https://doi.org/10.1109/JPROC.2020.3006804">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Increasing quantities of renewable energy generation has yielded a need for greater energy storage capacity in power systems. Thermal storage in variable air volume (VAV) heating, ventilation, and air conditioning (HVAC) in commercial buildings has been identified as an inexpensive source of grid storage, but the true costs are not known. Recent literature explores the inefficiency associated with providing grid services from these HVAC-based demand response (DR) resources by employing a battery analogy to calculate round-trip efficiency (RTE). Results vary significantly across studies and in some cases reported efficiencies are strikingly low. This article has three objectives to address these prior results. First, we synthesize and expand on insights into existing literature by systematically exploring the potential causes for the discrepancies in results. We reinforce previous work indicating baseline modeling may drive differences across studies and deduce that control accuracy plays a role in the major differences between experiments and simulation. Second, we discuss why the RTE metric is problematic for DR applications, discuss another proposed metric, additional energy consumption (AEC), and propose an extension, which we call uninstructed energy consumption (UEC), to evaluate DR performance. Finally, we explore the merits of different metrics using experimental data and highlight UEC&#39;s reduced sensitivity to the characteristics of the DR signal than previously proposed metrics.},
  archive      = {J_PIEEE},
  author       = {Jason S. MacDonald and Evangelos Vrettos and Duncan S. Callaway},
  doi          = {10.1109/JPROC.2020.3006804},
  journal      = {Proceedings of the IEEE},
  number       = {9},
  pages        = {1623-1639},
  shortjournal = {Proc. IEEE},
  title        = {A critical exploration of the efficiency impacts of demand response from HVAC in commercial buildings},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal configuration of power-to-cool technology in
district cooling systems. <em>PIEEE</em>, <em>108</em>(9), 1612–1622.
(<a href="https://doi.org/10.1109/JPROC.2020.2987420">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a multienergy framework, power-to-heat technology is becoming increasingly attractive. This interest is mainly due to the possibility of exploiting excesses and unbalances of electricity, which are becoming more and more common with the increasing capacity of the renewable sources. An interesting option consists in using heat pumps to convert excess of electricity produced by photovoltaic systems (especially in the midday hours) into cold to be provided to district heating and district cooling networks. This article aims to propose a methodology to select the best heat pump location in district cooling system. The analysis is performed with the aim of minimizing the cost of network construction and pumping. The procedure includes the best heat pump location and the design of the pipeline. Results show that distributed heat pumps allow one reducing both the costs and the average pipeline diameters by about 50\% with respect to concentrated production. Furthermore, the optimal location of distributed heat pumps allows reducing costs of about 7\% with respect to a uniformly distributed production.},
  archive      = {J_PIEEE},
  author       = {Elisa Guelpa and Luca Bellando and Antonio Giordano and Vittorio Verda},
  doi          = {10.1109/JPROC.2020.2987420},
  journal      = {Proceedings of the IEEE},
  number       = {9},
  pages        = {1612-1622},
  shortjournal = {Proc. IEEE},
  title        = {Optimal configuration of power-to-cool technology in district cooling systems},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Smarter smart district heating. <em>PIEEE</em>,
<em>108</em>(9), 1596–1611. (<a
href="https://doi.org/10.1109/JPROC.2020.2990490">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article reviews modern district heating systems (DHS), with the main emphasis on the new challenges in modeling, operation, and planning. We give a brief historical overview of evolution of heating systems around the world and provide the description of DHS in the countries where they constitute a substantial component of the energy supply infrastructure. Main modeling approaches are then reviewed. The review is followed by discussion of the major challenges in modern DHS: active consumers, state estimation, control issues, and future challenges of the operation under uncertainties.},
  archive      = {J_PIEEE},
  author       = {Nikolay N. Novitsky and Zoya I. Shalaginova and Aleksandr A. Alekseev and Vyacheslav V. Tokarev and Oksana A. Grebneva and Aleksandr V. Lutsenko and Olga V. Vanteeva and Egor A. Mikhailovsky and Roman Pop and Petr Vorobev and Michael Chertkov},
  doi          = {10.1109/JPROC.2020.2990490},
  journal      = {Proceedings of the IEEE},
  number       = {9},
  pages        = {1596-1611},
  shortjournal = {Proc. IEEE},
  title        = {Smarter smart district heating},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modeling and simulation of gas distribution networks in a
multienergy system environment. <em>PIEEE</em>, <em>108</em>(9),
1580–1595. (<a
href="https://doi.org/10.1109/JPROC.2020.2989114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The role of modeling and simulation in development and operational planning of gas distribution networks is crucially important for system designers and operators, since it allows to get a detailed knowledge of the hydraulic properties of the network. The challenges in simulation of gas distribution networks are usually that of computational efficiency of the methods due to large dimensionality of the simulated networks, though it can also be related to flexible incorporation of the peripheral equipment (e.g., valves, compressors, pressure, and flow regulators) into the network model. Today, however, new challenges emerge as a consequence of market changes facing the gas industry in a multienergy system environment. These changes are expected to bring about significant fluctuations and uncertainty in distributed gas supply and demand as a consequence of increased gas-to-power activities, and a number of decentralized entry points, where deliveries of both liquefied natural gas (LNG) and renewable gases, such as hydrogen and synthetic methane, can be achieved. In this article, technical challenges related to problems with maintaining a stable overall gas distribution system with growing diversification of gas quality combined with gas trading activities (nominations and allocations) in units of energy rather than volume are addressed. Models and selected methods of steady state and transient analysis of gas networks relevant to the ongoing discussion in the field of multienergy systems are considered. The simulation problems of a real large-scale gas distribution network are presented and discussed.},
  archive      = {J_PIEEE},
  author       = {Andrzej J. Osiadacz and Maciej Chaczykowski},
  doi          = {10.1109/JPROC.2020.2989114},
  journal      = {Proceedings of the IEEE},
  number       = {9},
  pages        = {1580-1595},
  shortjournal = {Proc. IEEE},
  title        = {Modeling and simulation of gas distribution networks in a multienergy system environment},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Monotonicity properties of physical network flows and
application to robust optimal allocation. <em>PIEEE</em>,
<em>108</em>(9), 1558–1579. (<a
href="https://doi.org/10.1109/JPROC.2020.3014069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We derive conditions for monotonicity properties that characterize general flows of a commodity over a network, where the flow is described by potential and flow dynamics on the edges, as well as potential continuity and the Kirchhoff-Neumann mass balance requirements at nodes. The transported commodity may be injected or withdrawn at any of the network nodes, and its movement throughout the network is controlled by nodal actuators. For a class of dissipative nonlinear parabolic partial differential equation (PDE) systems on networks, we derive conditions for monotonicity properties in steady-state flow, as well as for propagation of monotone ordering of states with respect to time-varying boundary condition parameters. In the latter case, initial conditions and time-varying parameters in the coupling conditions at vertices provide an initial boundary value problem (IBVP). We prove that ordering properties of the solution to the IBVP are preserved when the initial conditions and the parameters of the time-varying coupling law are appropriately ordered. Then, we prove that when monotone ordering is not preserved, the first crossing of solutions occurs at a network node. We consider the implications for robust optimization and optimal control formulations and real-time monitoring of uncertain dynamic flows on networks and discuss the application to subsonic compressible fluid flow with energy dissipation on physical networks. The main result and monitoring policy are demonstrated for gas pipeline test networks and a case study using data corresponding to a real working system. We propose applications of this general result to the control and monitoring of natural gas transmission networks.},
  archive      = {J_PIEEE},
  author       = {Sidhant Misra and Marc Vuffray and Anatoly Zlotnik},
  doi          = {10.1109/JPROC.2020.3014069},
  journal      = {Proceedings of the IEEE},
  number       = {9},
  pages        = {1558-1579},
  shortjournal = {Proc. IEEE},
  title        = {Monotonicity properties of physical network flows and application to robust optimal allocation},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Operations and long-term expansion planning of natural-gas
and power systems: A market perspective. <em>PIEEE</em>,
<em>108</em>(9), 1541–1557. (<a
href="https://doi.org/10.1109/JPROC.2020.3005284">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural-gas and power systems are increasingly interdependent due to the integration of an increasing number of combined cycle gas turbines in the power generation mix. However, natural gas and power systems are generally independently operated. This is the result of history and the fact that natural gas has not been important for electricity production until recently. Adopting a power system perspective, this article reviews in a tutorial manner models for the operations and long-term expansion planning of interdependent but independently operated natural-gas and power systems.},
  archive      = {J_PIEEE},
  author       = {By Antonio J. Conejo and Sheng Chen and Gonzalo E. Constante},
  doi          = {10.1109/JPROC.2020.3005284},
  journal      = {Proceedings of the IEEE},
  number       = {9},
  pages        = {1541-1557},
  shortjournal = {Proc. IEEE},
  title        = {Operations and long-term expansion planning of natural-gas and power systems: A market perspective},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An uncertainty management framework for integrated
gas-electric energy systems. <em>PIEEE</em>, <em>108</em>(9), 1518–1540.
(<a href="https://doi.org/10.1109/JPROC.2020.3005505">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many parts of the world, electric power systems have seen a significant shift toward generation from renewable energy and natural gas. Because of their ability to flexibly adjust power generation in real time, gas-fired power plants are frequently seen as the perfect partner for variable renewable generation. However, this reliance on gas generation increases interdependence and propagates uncertainty between power grids and gas pipelines and brings coordination and uncertainty management challenges. To address these issues, we propose an uncertainty management framework for uncertain, but bounded gas consumption by gas-fired power plants. The admissible ranges are computed based on a joint optimization problem for the combined gas and electricity networks, which involves chance-constrained scheduling for the electric grid and a novel robust optimization formulation for the natural-gas network. This formulation ensures feasibility of the integrated system with a high probability, while providing a tractable numerical formulation. A key advance with respect to existing methods is that our method is based on a physically accurate, validated model for transient gas pipeline flows. Our case study benchmarks our proposed formulation against methods that ignore how reserve activation impacts the fuel use of gas power plants and only consider predetermined gas consumption. The results demonstrate the importance of considering uncertainty to avoid operating constraint violations and curtailment of gas to the generators.},
  archive      = {J_PIEEE},
  author       = {Line A. Roald and Kaarthik Sundar and Anatoly Zlotnik and Sidhant Misra and Göran Andersson},
  doi          = {10.1109/JPROC.2020.3005505},
  journal      = {Proceedings of the IEEE},
  number       = {9},
  pages        = {1518-1540},
  shortjournal = {Proc. IEEE},
  title        = {An uncertainty management framework for integrated gas-electric energy systems},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Flexibility from distributed multienergy systems.
<em>PIEEE</em>, <em>108</em>(9), 1496–1517. (<a
href="https://doi.org/10.1109/JPROC.2020.2986378">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multienergy systems (MES), in which multiple energy vectors are integrated and optimally operated, are key assets in low-carbon energy systems. Multienergy interactions of distributed energy resources via different energy networks generate the so-called distributed MES (DMES). While it is now well recognized that DMES can provide power system flexibility by shifting across different energy vectors, it is essential to have a systematic discussion on the main features of such flexibility. This article presents a comprehensive overview of DMES modeling and characterization of flexibility applications. The concept of “multienergy node” is introduced to extend the power node model, used for electrical flexibility, in the multienergy case. A general definition of DMES flexibility is given, and a general mathematical and graphical modeling framework, based on multidimensional maps, is formulated to describe the operational characteristics of individual MES and aggregate DMES, including the role of multienergy networks in enabling or constraining flexibility. Several tutorial examples are finally presented with illustrative case studies on current and future DMES practical applications.},
  archive      = {J_PIEEE},
  author       = {Gianfranco Chicco and Shariq Riaz and Andrea Mazza and Pierluigi Mancarella},
  doi          = {10.1109/JPROC.2020.2986378},
  journal      = {Proceedings of the IEEE},
  number       = {9},
  pages        = {1496-1517},
  shortjournal = {Proc. IEEE},
  title        = {Flexibility from distributed multienergy systems},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal capacity design and operation of energy hub systems.
<em>PIEEE</em>, <em>108</em>(9), 1475–1495. (<a
href="https://doi.org/10.1109/JPROC.2020.3009323">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article takes an integrated view of optimized capacity design and operation of islanded energy hubs. We consider energy hubs that incorporate emerging distributed energy resources as well as energy storage devices and fully support electricity and heat demand of an islanded installation. Both battery and hydrogen storage are incorporated. To explicitly account for the stochasticity in renewable energy generation and load, the energy hub capacity design problem is first expressed as a chance-constrained optimization problem and then reformulated as a robust counterpart problem, where battery charging/discharging responds to stochastic renewable energy generation and load realizations through a control policy. In particular, an affine policy is considered, enabling a linear program formulation of the problem. To reduce conservativeness of the design, an iterative algorithm is proposed, where the interaction between a chance-constrained design problem and a validation problem is achieved through a scalar auxiliary variable. The design result demonstrates a balanced tradeoff between robustness and cost efficiency. After the energy hub has been designed, we propose a bi-level operating strategy, where a day-ahead schedule is optimized at the higher level and model predictive control is used for tracking the schedule in real time at the lower level. Finally, we discuss the potential for increasing the reliability of energy hub systems while decreasing operational cost by sharing energy between multiple energy hubs through networking.},
  archive      = {J_PIEEE},
  author       = {Sijia Geng and Maria Vrakopoulou and Ian A. Hiskens},
  doi          = {10.1109/JPROC.2020.3009323},
  journal      = {Proceedings of the IEEE},
  number       = {9},
  pages        = {1475-1495},
  shortjournal = {Proc. IEEE},
  title        = {Optimal capacity design and operation of energy hub systems},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A hierarchical approach to multienergy demand response: From
electricity to multienergy applications. <em>PIEEE</em>,
<em>108</em>(9), 1457–1474. (<a
href="https://doi.org/10.1109/JPROC.2020.2983388">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to proliferation of energy efficiency measures and availability of the renewable energy resources, traditional energy infrastructure systems (electricity, heat, gas) can no longer be operated in a centralized manner under the assumption that consumer behavior is inflexible, i.e., cannot be adjusted in return for an adequate incentive. To allow for a less centralized operating paradigm, consumer-end perspective and abilities should be integrated in current dispatch practices and accounted for in switching between different energy sources not only at the system but also at the individual consumer level. Since consumers are confined within different built environments, this article looks into an opportunity to control energy consumption of an aggregation of many residential, commercial, and industrial consumers, into an ensemble. This ensemble control becomes a modern demand response (DR) contributor to the set of modeling tools for multienergy infrastructure systems.},
  archive      = {J_PIEEE},
  author       = {Ali Hassan and Samrat Acharya and Michael Chertkov and Deepjyoti Deka and Yury Dvorkin},
  doi          = {10.1109/JPROC.2020.2983388},
  journal      = {Proceedings of the IEEE},
  number       = {9},
  pages        = {1457-1474},
  shortjournal = {Proc. IEEE},
  title        = {A hierarchical approach to multienergy demand response: From electricity to multienergy applications},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multicarrier energy systems: Shaping our energy future.
<em>PIEEE</em>, <em>108</em>(9), 1437–1456. (<a
href="https://doi.org/10.1109/JPROC.2020.2992251">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multicarrier energy systems (MCESs) are characterized by strong coordination in operation and planning across multiple energy vectors and/or sectors to deliver reliable, cost-effective energy services to end users/customers with minimal impact on the environment. They have efficiency and flexibility benefits and are deployed in large and small scales on the supply and demand sides and at the network level but are more complex to control and manage. In this article, MCESs are reviewed in the context of future low carbon energy systems based on electrification and very high variable renewable energy penetrations. Fully exploiting these systems requires some cost reductions, more sophisticated operations enabled by standardized communications and control capabilities detailed planning paradigms, and addressing their corresponding economic challenges. All these point toward the direction of analysis, markets, and technology research and development coupled with better policy and regulatory frameworks. One futuristic vision of a very low carbon energy system is proposed that illustrates potential pathways to an MCES-dominated energy future.},
  archive      = {J_PIEEE},
  author       = {Mark J. O’Malley and Muhammad Bashar Anwar and Steve Heinen and Tom Kober and James McCalley and Madeleine McPherson and Matteo Muratori and Antje Orths and Mark Ruth and Thomas J. Schmidt and Aidan Tuohy},
  doi          = {10.1109/JPROC.2020.2992251},
  journal      = {Proceedings of the IEEE},
  number       = {9},
  pages        = {1437-1456},
  shortjournal = {Proc. IEEE},
  title        = {Multicarrier energy systems: Shaping our energy future},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multienergy networks analytics: Standardized modeling,
optimization, and low carbon analysis. <em>PIEEE</em>, <em>108</em>(9),
1411–1436. (<a
href="https://doi.org/10.1109/JPROC.2020.2993787">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multienergy systems (MESs) are able to unlock the energy system flexibility using the coupling across multiple energy sectors. Such coupling contributes to improving the overall energy efficiency and promoting the accommodation of renewable energy. Among a wide range of literature, this article provides a perspective of network analytics on how to model, optimize, and conduct low-carbon analysis on MESs. The energy sector coupling involves different levels, for example, from a single building to nationwide. In this article, we categorize multienergy networks into two levels, that is, the district level that covers a relatively small area such as a campus or a community, where the energy conversion and utilization is the major focus, and the multiregion level that covers a relatively large area such as a big city, a province, or the whole country, where the energy transmission is the major concern. We first review the state-of-the-art multienergy networks standardized modeling approaches including: 1) energy hub (EH) model for district level energy networks; 2) network models, including power, heat, and gas steady-state and dynamic network models, for multiregion level energy networks; and 3) load models, including electricity, heat, and gas load forecasting models. Second, we explore the planning and operation methods for both district level and multiregion level energy networks. Third, we introduce a special technique named the carbon emission flow (CEF) model that is able to calculate the equivalent CO2 emission associated with the energy flows in multienergy networks. We also demonstrate how the technique can help multienergy networks planning and operation toward a low carbon society. Finally, we envision several further key research topics in the field of multienergy networks.},
  archive      = {J_PIEEE},
  author       = {Wujing Huang and Ning Zhang and Yaohua Cheng and Jingwei Yang and Yi Wang and Chongqing Kang},
  doi          = {10.1109/JPROC.2020.2993787},
  journal      = {Proceedings of the IEEE},
  number       = {9},
  pages        = {1411-1436},
  shortjournal = {Proc. IEEE},
  title        = {Multienergy networks analytics: Standardized modeling, optimization, and low carbon analysis},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Integrated electricity– heat–gas systems: Techno–economic
modeling, optimization, and application to multienergy districts.
<em>PIEEE</em>, <em>108</em>(9), 1392–1410. (<a
href="https://doi.org/10.1109/JPROC.2020.2989382">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multienergy systems (MES) can optimally deploy their internal operational flexibility to use combinations of different energy vectors to meet the needs of end-users and potentially support the wider system. Key relevant applications of MES are multienergy districts (MEDs) with, for example, integrated electricity and gas distribution and district heating networks. Simulation and optimization of MEDs is a grand challenge requiring sophisticated techno-economic tools that are capable of modeling buildings and distributed energy resources (DERs) across multienergy networks. This article provides a tutorial-like overview of the state-of-the-art concepts for techno-economic modeling and optimization of integrated electricity-heat-gas systems in flexible MEDs, also considering operational uncertainty and multiple grid support services. Relevant mixed integer linear programming (MILP) formulations for two-stage stochastic scheduling of buildings and DER, iteratively soft-coupled to nonlinear network models, are then presented as the basis of a practical network-constrained MED energy management tool developed in several projects. The concepts presented are demonstrated through real-world applications based on The University of Manchester MED case study, the details of which are also provided as a testbed for future research.},
  archive      = {J_PIEEE},
  author       = {Eduardo Alejandro Martínez Ceseña and Emmanouil Loukarakis and Nicholas Good and Pierluigi Mancarella},
  doi          = {10.1109/JPROC.2020.2989382},
  journal      = {Proceedings of the IEEE},
  number       = {9},
  pages        = {1392-1410},
  shortjournal = {Proc. IEEE},
  title        = {Integrated electricity– Heat–Gas systems: Techno–Economic modeling, optimization, and application to multienergy districts},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multienergy systems. <em>PIEEE</em>, <em>108</em>(9),
1387–1391. (<a
href="https://doi.org/10.1109/JPROC.2020.3015320">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This Special Issue on Multienergy Systems is motivated by the tremendous changes and opportunities in integrated planning, operation, and modeling of the energy systems, including electric, natural gas, and district heating–cooling systems together with the demand side. Traditionally, the role of electric power has been regarded as an energy carrier between the power plants and the consumers. Consequently, the focus of power system analysis, planning, and operation has been limited to those parts of the system that are between the electrical side of the power generators and the power outlets of the consumers. By expanding the system boundaries to also include the dynamics of supply of primary energy, for example, gas, and the characteristics of consumers’ power consumption, the overall efficiency and security of the power system can be improved. Furthermore, energy requirements of some consumers can be satisfied by different energy carriers. For example, heating can be achieved by electric power, gas, or, if available, district heating networks. An integrated analysis of all these systems would, therefore, offer new possibilities of providing an energy system with additional redundancy and flexibility, resulting in more efficient and resilient energy offerings to the consumers and the society, in general.},
  archive      = {J_PIEEE},
  author       = {Michael Chertkov and Göran Andersson},
  doi          = {10.1109/JPROC.2020.3015320},
  journal      = {Proceedings of the IEEE},
  number       = {9},
  pages        = {1387-1391},
  shortjournal = {Proc. IEEE},
  title        = {Multienergy systems},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Gift of membership. <em>PIEEE</em>, <em>108</em>(8), 1384.
(<a href="https://doi.org/10.1109/JPROC.2020.3006924">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advertisement, IEEE.},
  archive      = {J_PIEEE},
  doi          = {10.1109/JPROC.2020.3006924},
  journal      = {Proceedings of the IEEE},
  number       = {8},
  pages        = {1384},
  shortjournal = {Proc. IEEE},
  title        = {Gift of membership},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). John logie baird and the secret in the box: The undiscovered
story behind the world’s first public demonstration of television
[scanning our past]. <em>PIEEE</em>, <em>108</em>(8), 1371–1382. (<a
href="https://doi.org/10.1109/JPROC.2020.2996793">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {On January 26, 1926, John Logie Baird gave a demonstration at his laboratory in 22 Frith Street, London, UK, of the live transmission of moving images, obtained in reflected light with tonal graduation, to members of the Royal Institution. This event is generally accepted as the first public demonstration of true television. Ten months earlier, on March 25, 1925, Baird had demonstrated the televising of moving silhouette images, at Selfridge’s department store, on Oxford Street in London. What had changed in those ten months to enable Baird to televise a sufficient tonal range of moving human faces? This article describes the set of events which led up to Baird’s accomplishment and answers the question concerning the technology employed.},
  archive      = {J_PIEEE},
  author       = {Brandon D. Inglis and Gary D. Couples},
  doi          = {10.1109/JPROC.2020.2996793},
  journal      = {Proceedings of the IEEE},
  number       = {8},
  pages        = {1371-1382},
  shortjournal = {Proc. IEEE},
  title        = {John logie baird and the secret in the box: The undiscovered story behind the world’s first public demonstration of television [Scanning our past]},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Resource-efficient quantum computing by breaking
abstractions. <em>PIEEE</em>, <em>108</em>(8), 1353–1370. (<a
href="https://doi.org/10.1109/JPROC.2020.2994765">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Building a quantum computer that surpasses the computational power of its classical counterpart is a great engineering challenge. Quantum software optimizations can provide an accelerated pathway to the first generation of quantum computing (QC) applications that might save years of engineering effort. Current quantum software stacks follow a layered approach similar to the stack of classical computers, which was designed to manage the complexity. In this review, we point out that greater efficiency of QC systems can be achieved by breaking the abstractions between these layers. We review several works along this line, including two hardware-aware compilation optimizations that break the quantum instruction set architecture (ISA) abstraction and two error-correction/information-processing schemes that break the qubit abstraction. Last, we discuss several possible future directions.},
  archive      = {J_PIEEE},
  author       = {Yunong Shi and Pranav Gokhale and Prakash Murali and Jonathan M. Baker and Casey Duckering and Yongshan Ding and Natalie C. Brown and Christopher Chamberland and Ali Javadi-Abhari and Andrew W. Cross and David I. Schuster and Kenneth R. Brown and Margaret Martonosi and Frederic T. Chong},
  doi          = {10.1109/JPROC.2020.2994765},
  journal      = {Proceedings of the IEEE},
  number       = {8},
  pages        = {1353-1370},
  shortjournal = {Proc. IEEE},
  title        = {Resource-efficient quantum computing by breaking abstractions},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Challenges and opportunities of near-term quantum computing
systems. <em>PIEEE</em>, <em>108</em>(8), 1338–1352. (<a
href="https://doi.org/10.1109/JPROC.2019.2954005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concept of quantum computing has inspired a whole new generation of scientists, including physicists, engineers, and computer scientists, to fundamentally change the landscape of information technology. With experimental demonstrations stretching back more than two decades, the quantum computing community has achieved a major milestone over the past few years: the ability to build systems that are stretching the limits of what can be classically simulated, and which enable cloud-based research for a wide range of scientists, thus increasing the pool of talent exploring early quantum systems. While such noisy near-term quantum computing systems fall far short of the requirements for fault-tolerant systems, they provide unique test beds for exploring the opportunities for quantum applications. Here, we highlight an IBM-specific perspective of the facets associated with these systems, including quantum software, cloud access, benchmarking quantum systems, error correction and mitigation in such systems, understanding the complexity of quantum circuits, and how early quantum applications can run on near-term quantum computers.},
  archive      = {J_PIEEE},
  author       = {Antonio D. Córcoles and Abhinav Kandala and Ali Javadi-Abhari and Douglas T. McClure and Andrew W. Cross and Kristan Temme and Paul D. Nation and Matthias Steffen and Jay M. Gambetta},
  doi          = {10.1109/JPROC.2019.2954005},
  journal      = {Proceedings of the IEEE},
  number       = {8},
  pages        = {1338-1352},
  shortjournal = {Proc. IEEE},
  title        = {Challenges and opportunities of near-term quantum computing systems},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). From charge to spin and spin to charge: Stochastic magnets
for probabilistic switching. <em>PIEEE</em>, <em>108</em>(8), 1322–1337.
(<a href="https://doi.org/10.1109/JPROC.2020.2966925">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the rapid pace of Moore’s Law has been slowing down, there has been intense activity to “reinvent the transistor.” An emerging paradigm is to complement the existing complementary metal-oxide–semiconductor (CMOS) technology with new functionalities, rather than finding a drop-in replacement for it. In this article, we discuss such a complementary approach that we call probabilistic spin logic (PSL) based on the concept of a probabilistic or p-bit. p-bits fluctuate between 0 and 1 and can be imagined in between deterministic bits that are either 0 or 1 and quantum bits that are a superposition of 0 and 1. Interconnected circuits built out of p-bits (p-circuits) can be broadly useful for machine learning and quantum computing in the solution of problems that conventional CMOS may not be particularly suited for. Although such p-bits can be implemented using standard CMOS technology, we will show that the inherent physics of nanomagnets can naturally provide an energy efficient and scalable p-bit implementation through the use of low-barrier magnetic tunnel junctions (MTJs). In this article, we provide a general description of p-bits and p-circuits and discuss their applications. We review experimental progress toward constructing p-bits and p-circuits exploiting the inherent stochasticity of nanomagnets, from a physics/device/circuits perspective. In particular, we identify building blocks for “write” and “read” operations that can be used in different combinations to construct functional p-bits and p-circuits. Finally, we discuss the prospects and challenges of PSL as an emerging, unconventional computing paradigm for a beyond CMOS era.},
  archive      = {J_PIEEE},
  author       = {Kerem Y. Camsari and Punyashloka Debashis and Vaibhav Ostwal and Ahmed Zeeshan Pervaiz and Tingting Shen and Zhihong Chen and Supriyo Datta and Joerg Appenzeller},
  doi          = {10.1109/JPROC.2020.2966925},
  journal      = {Proceedings of the IEEE},
  number       = {8},
  pages        = {1322-1337},
  shortjournal = {Proc. IEEE},
  title        = {From charge to spin and spin to charge: Stochastic magnets for probabilistic switching},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Magnetic racetrack memory: From physics to the cusp of
applications within a decade. <em>PIEEE</em>, <em>108</em>(8),
1303–1321. (<a
href="https://doi.org/10.1109/JPROC.2020.2975719">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Racetrack memory (RTM) is a novel spintronic memory-storage technology that has the potential to overcome fundamental constraints of existing memory and storage devices. It is unique in that its core differentiating feature is the movement of data, which is composed of magnetic domain walls (DWs), by short current pulses. This enables more data to be stored per unit area compared to any other current technologies. On the one hand, RTM has the potential for mass data storage with unlimited endurance using considerably less energy than today’s technologies. On the other hand, RTM promises an ultrafast nonvolatile memory competitive with static random access memory (SRAM) but with a much smaller footprint. During the last decade, the discovery of novel physical mechanisms to operate RTM has led to a major enhancement in the efficiency with which nanoscopic, chiral DWs can be manipulated. New materials and artificially atomically engineered thin-film structures have been found to increase the speed and lower the threshold current with which the data bits can be manipulated. With these recent developments, RTM has attracted the attention of the computer architecture community that has evaluated the use of RTM at various levels in the memory stack. Recent studies advocate RTM as a promising compromise between, on the one hand, power-hungry, volatile memories and, on the other hand, slow, nonvolatile storage. By optimizing the memory subsystem, significant performance improvements can be achieved, enabling a new era of cache, graphical processing units, and high capacity memory devices. In this article, we provide an overview of the major developments of RTM technology from both the physics and computer architecture perspectives over the past decade. We identify the remaining challenges and give an outlook on its future.},
  archive      = {J_PIEEE},
  author       = {Robin Bläsing and Asif Ali Khan and Panagiotis Ch. Filippou and Chirag Garg and Fazal Hameed and Jeronimo Castrillon and Stuart S. P. Parkin},
  doi          = {10.1109/JPROC.2020.2975719},
  journal      = {Proceedings of the IEEE},
  number       = {8},
  pages        = {1303-1321},
  shortjournal = {Proc. IEEE},
  title        = {Magnetic racetrack memory: From physics to the cusp of applications within a decade},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Large-scale field-programmable analog arrays.
<em>PIEEE</em>, <em>108</em>(8), 1283–1302. (<a
href="https://doi.org/10.1109/JPROC.2019.2950173">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale field-programmable analog array (FPAA) devices could enable ubiquitous analog or mixed-signal low-power sensor to processing devices similar to the ubiquitous implementation of the existing field-programmable gate array (FPGA) devices. Design tools enable high-level synthesis to gate/transistor design targeting today&#39;s FPGA devices and the opportunity for analog or mixed-signal applications with FPAA devices. This discussion will illustrate the FPAA concepts and FPAA history. The development of FPAAs enables the development of multiple potential metrics, and these metrics illustrate future FPAA device directions. The system-on-chip (SoC) FPAA devices illustrate the IC capabilities, computation, tools, and resulting hardware infrastructure. SoC FPAA device generation has enabled analog computing with levels of abstraction for application design.},
  archive      = {J_PIEEE},
  author       = {Jennifer Hasler},
  doi          = {10.1109/JPROC.2019.2950173},
  journal      = {Proceedings of the IEEE},
  number       = {8},
  pages        = {1283-1302},
  shortjournal = {Proc. IEEE},
  title        = {Large-scale field-programmable analog arrays},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Silicon photonics codesign for deep learning.
<em>PIEEE</em>, <em>108</em>(8), 1261–1282. (<a
href="https://doi.org/10.1109/JPROC.2020.2968184">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning is revolutionizing many aspects of our society, addressing a wide variety of decision-making tasks, from image classification to autonomous vehicle control. Matrix multiplication is an essential and computationally intensive step of deep-learning calculations. The computational complexity of deep neural networks requires dedicated hardware accelerators for additional processing throughput and improved energy efficiency in order to enable scaling to larger networks in the upcoming applications. Silicon photonics is a promising platform for hardware acceleration due to recent advances in CMOS-compatible manufacturing capabilities, which enable efficient exploitation of the inherent parallelism of optics. This article provides a detailed description of recent implementations in the relatively new and promising platform of silicon photonics for deep learning. Opportunities for multiwavelength microring silicon photonic architectures codesigned with field-programmable gate array (FPGA) for pre- and postprocessing are presented. The detailed analysis of a silicon photonic integrated circuit shows that a codesigned implementation based on the decomposition of large matrix-vector multiplication into smaller instances and the use of nonnegative weights could significantly simplify the photonic implementation of the matrix multiplier and allow increased scalability. We conclude this article by presenting an overview and a detailed analysis of design parameters. Insights for ways forward are explored.},
  archive      = {J_PIEEE},
  author       = {Qixiang Cheng and Jihye Kwon and Madeleine Glick and Meisam Bahadori and Luca P. Carloni and Keren Bergman},
  doi          = {10.1109/JPROC.2020.2968184},
  journal      = {Proceedings of the IEEE},
  number       = {8},
  pages        = {1261-1282},
  shortjournal = {Proc. IEEE},
  title        = {Silicon photonics codesign for deep learning},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The heterogeneous deep neural network processor with a
non-von neumann architecture. <em>PIEEE</em>, <em>108</em>(8),
1245–1260. (<a
href="https://doi.org/10.1109/JPROC.2019.2897076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today&#39;s CPUs are general-purpose processors, which have the von Neumann architecture (including the Harvard architectures) to maximize the generality and programmability. On the other hand, application-specific integrated circuits (ASICs) have domain-specific architectures to optimize the cost-effective performance but show very low generality. The combination of generality and ASIC, which usually seemed to have no contact, is expected to be enabled by deep learning (DL). DL, realized with deep neural networks (DNNs), has changed the paradigm of machine learning (ML) and brought significant progress in vision, speech, language processing, and many other applications. DNNs have special features that can be efficiently implemented with dedicated architectures, ASICs. Sharing their special features, DNNs have a wide variety of network architectures, and even the same network architecture can be used for different applications depending on the weight parameters. This paper aims to provide the necessity, validity, and characteristics of the ML-specific integrated circuits (MSICs) that have a different architecture from the von Neumann architecture. MSICs can avoid the overhead from the complex instruction set, instruction decoder, multilevel caches, and branch prediction of the recent von Neumann architecture processors designed for high generality and programmability. We will also discuss the necessity and validity of a heterogeneous architecture in MSIC, starting from the differences between the visual-type information processing and the vector-type information processing, and show the chip implementation results.},
  archive      = {J_PIEEE},
  author       = {Dongjoo Shin and Hoi-Jun Yoo},
  doi          = {10.1109/JPROC.2019.2897076},
  journal      = {Proceedings of the IEEE},
  number       = {8},
  pages        = {1245-1260},
  shortjournal = {Proc. IEEE},
  title        = {The heterogeneous deep neural network processor with a non-von neumann architecture},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Tunnel-FET switching is governed by non-lorentzian spectral
line shape. <em>PIEEE</em>, <em>108</em>(8), 1235–1244. (<a
href="https://doi.org/10.1109/JPROC.2019.2904011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In tunnel field-effect transistors (tFETs), the preferred mechanism for switching occurs by alignment (on) or misalignment (off) of two energy levels or band edges. Unfortunately, energy levels are never perfectly sharp. When a quantum dot interacts with a wire, its energy is broadened. Its actual spectral shape controls the current/voltage response of such transistor switches, from on (aligned) to off (misaligned). The most common model of spectral line shape is the Lorentzian, which falls off as reciprocal energy offset squared. Unfortunately, this is too slow a turnoff, algebraically, to be useful as a transistor switch. Electronic switches generally demand an on/off ratio of at least a million. Steep exponentially falling spectral tails would be needed for rapid off-state switching. This requires a new electronic feature, not previously recognized: narrowband, heavy-effective mass, quantum wire electrical contacts, to the tunneling quantum states. These are a necessity for spectrally sharp switching.},
  archive      = {J_PIEEE},
  author       = {Sri Krishna Vadlamani and Sapan Agarwal and David T. Limmer and Steven G. Louie and Felix R. Fischer and Eli Yablonovitch},
  doi          = {10.1109/JPROC.2019.2904011},
  journal      = {Proceedings of the IEEE},
  number       = {8},
  pages        = {1235-1244},
  shortjournal = {Proc. IEEE},
  title        = {Tunnel-FET switching is governed by non-lorentzian spectral line shape},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Addressing unreliability in emerging devices and non-von
neumann architectures using coded computing. <em>PIEEE</em>,
<em>108</em>(8), 1219–1234. (<a
href="https://doi.org/10.1109/JPROC.2020.2986362">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computing systems are evolving rapidly. At the device level, emerging devices are beginning to compete with traditional CMOS systems. At the architecture level, novel architectures are successfully avoiding the communication bottleneck that is a central feature, and a central limitation, of the von Neumann architecture. Furthermore, such systems are increasingly plagued by unreliability. This unreliability arises at device or gate-level in emerging devices, and can percolate up to processor or system-level if left unchecked. The goal of this article is to survey recent advances in reliable computing using unreliable elements, with an eye on nonsilicon and non-von Neumann architectures. We first observe that instead of aiming for generic computing problems, the community could use “dwarfs of modern computing,” first noted in the high-performance computing (HPC) community, as a starting point. These computing problems are the basic building blocks of almost all scientific computing, machine learning, and data analytics today. Next, we survey the state of the art in “coded computing,” which is an emerging area that advances on classical algorithm-based fault-tolerance (ABFT) and brings a fundamental information-theoretic perspective. By weaving error-correcting codes into a computing algorithm, coded computing provides dramatic improvements on solutions, as well as obtains novel fundamental limits, for problems that have been open for more than 30 years. We introduce existing and novel coded computing techniques in the context of “coded dwarfs,” where a specific dwarf&#39;s computation is made resilient by applying coding. We discuss how, for the same redundancy, “coded dwarfs” are significantly more resilient compared to classical techniques such as replication. Furthermore, by examining a widely popular computation task-training large neural networks-we demonstrate how coded dwarfs can be applied to address this fundamentally nonlinear problem. Finally, we discuss practical challenges and future directions in implementing coded computing techniques on emerging and existing nonsilicon and/or non-von Neumann architectures.},
  archive      = {J_PIEEE},
  author       = {Sanghamitra Dutta and Haewon Jeong and Yaoqing Yang and Viveck Cadambe and Tze Meng Low and Pulkit Grover},
  doi          = {10.1109/JPROC.2020.2986362},
  journal      = {Proceedings of the IEEE},
  number       = {8},
  pages        = {1219-1234},
  shortjournal = {Proc. IEEE},
  title        = {Addressing unreliability in emerging devices and non-von neumann architectures using coded computing},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Nonsilicon, non-von neumann computing—part II.
<em>PIEEE</em>, <em>108</em>(8), 1211–1218. (<a
href="https://doi.org/10.1109/JPROC.2020.3001748">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The articles in this month’s special issue provide insight into future computing technologies such as novel architectures, spintronic memories, and quantum computing.},
  archive      = {J_PIEEE},
  author       = {Sankar Basu and Randal E. Bryant and Giovanni De Micheli and Thomas Theis and Lloyd Whitman},
  doi          = {10.1109/JPROC.2020.3001748},
  journal      = {Proceedings of the IEEE},
  number       = {8},
  pages        = {1211-1218},
  shortjournal = {Proc. IEEE},
  title        = {Nonsilicon, non-von neumann Computing—Part II},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Achieving resiliency and behavior assurance in autonomous
navigation: An industry perspective. <em>PIEEE</em>, <em>108</em>(7),
1196–1207. (<a
href="https://doi.org/10.1109/JPROC.2020.2978661">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we present an industry perspective on key drivers for autonomous navigation, with a particular focus on resiliency and behavior assurance. We provide a brief survey of current deployed mobile autonomous systems and their capabilities (with a primary focus on the air domain but including other domains-underwater, ground, space, and surface-as well). We discuss techniques that are currently used for achieving resiliency and assurance in autonomous navigation, pointing out some of the shortcomings of these techniques. We describe techniques under development in the industry that aims to overcome these shortcomings by combining emerging approaches to resilient behavior with assured autonomous behavior constructs to yield reliable and mission-effective systems necessary to operate successfully in dynamic and adversarial environments. We briefly discuss ongoing efforts to develop multidomain standards that are designed to be applicable across these disparate vehicle domains.},
  archive      = {J_PIEEE},
  author       = {Sanjoy Baruah and Peter Lee and Prakash Sarathy and Marilyn Wolf},
  doi          = {10.1109/JPROC.2020.2978661},
  journal      = {Proceedings of the IEEE},
  number       = {7},
  pages        = {1196-1207},
  shortjournal = {Proc. IEEE},
  title        = {Achieving resiliency and behavior assurance in autonomous navigation: An industry perspective},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Self-aware swarm navigation in autonomous exploration
missions. <em>PIEEE</em>, <em>108</em>(7), 1168–1195. (<a
href="https://doi.org/10.1109/JPROC.2020.2985950">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A multitude of autonomous robotic platforms collectively organized as a swarm attracts increasing attention for remote sensing and exploration tasks. A navigation system is essential for the swarm to collectively localize itself as well as external sources. In this article, we propose a self-aware swarm navigation system that is conscious of the causality between its position and the localization uncertainty. This knowledge allows the swarm to move in a way to not only account for external mission objectives but also enhance position information. Position information for classical navigation systems has already been studied with the Fisher information (FI) and Bayesian information (BI) theories. We show how to extend these theories to a self-aware swarm navigation system, particularly emphasizing the collective performance. In this respect, fundamental limits and geometric interpretations of localization with generic observation models are discussed. We further propose a general concept of FI and BI based information seeking swarm control. The weighted position Cramér-Rao bound (CRB) and posterior CRB (PCRB) are employed flexibly as either a control cost function or constraints according to different mission criteria. As a result, the swarm actively adapts its position to enrich position information with different emerging collective behaviors. The proposed concept is illustrated by a case study of a swarm mission for gas exploration on Mars.},
  archive      = {J_PIEEE},
  author       = {Siwei Zhang and Robert Pöhlmann and Thomas Wiedemann and Armin Dammann and Henk Wymeersch and Peter Adam Hoeher},
  doi          = {10.1109/JPROC.2020.2985950},
  journal      = {Proceedings of the IEEE},
  number       = {7},
  pages        = {1168-1195},
  shortjournal = {Proc. IEEE},
  title        = {Self-aware swarm navigation in autonomous exploration missions},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Self-aware networks that optimize security, QoS, and energy.
<em>PIEEE</em>, <em>108</em>(7), 1150–1167. (<a
href="https://doi.org/10.1109/JPROC.2020.2992559">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The need to adaptively manage computer systems and networks so as to offer good Quality of Service (QoS) and Quality of Experience (QoE) with secure operation at relatively low levels of energy consumption is challenged by their sheer complexity and the wide variability of the workloads. A possible way forward is through self-awareness, whereby self-measurement and self-observation, together with on-line control mechanisms, operate adaptively to attain the required performance and QoE. We survey the premises for these ideas arising from cognitive science and active networks and review recent work on self-aware computer systems and networks, including those that propose the use of software-defined networks as a means to implement these concepts. Then we provide some examples from the literature on self-aware systems to illustrate the performance gains that they can provide. Finally, we detail an example system and its working algorithms to allow the reader to understand how such a system may be implemented. Measurements showing how it can react rapidly to changing network conditions regarding QoS and security are presented. Some conclusions and suggestions for further work are listed.},
  archive      = {J_PIEEE},
  author       = {Erol Gelenbe and Joanna Domanska and Piotr Fröhlich and Mateusz P. Nowak and Sławomir Nowak},
  doi          = {10.1109/JPROC.2020.2992559},
  journal      = {Proceedings of the IEEE},
  number       = {7},
  pages        = {1150-1167},
  shortjournal = {Proc. IEEE},
  title        = {Self-aware networks that optimize security, QoS, and energy},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Acoustic self-awareness of autonomous systems in a world of
sounds. <em>PIEEE</em>, <em>108</em>(7), 1127–1149. (<a
href="https://doi.org/10.1109/JPROC.2020.2977372">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous systems (ASs) operating in real-world environments are exposed to a plurality and diversity of sounds that carry a wealth of information for perception in cognitive dynamic systems. While the importance of the acoustic modality for humans as “ASs” is obvious, it is investigated to what extent current technical ASs operating in scenarios filled with airborne sound exploit their potential for supporting self-awareness. As a first step, the state of the art of relevant generic techniques for acoustic scene analysis (ASA) is reviewed, i.e., source localization and the various facets of signal enhancement, including spatial filtering, source separation, noise suppression, dereverberation, and echo cancellation. Then, a comprehensive overview of current techniques for ego-noise suppression, as a specific additional challenge for ASs, is presented. Not only generic methods for robust source localization and signal extraction but also specific models and estimation methods for ego-noise based on various learning techniques are discussed. Finally, active sensing is considered with its unique potential for ASA and, thus, for supporting self-awareness of ASs. Therefore, recent techniques for binaural listening exploiting head motion, for active localization and exploration, and for active signal enhancement are presented, with humanoïd robots as typical platforms. Underlining the multimodal nature of self-awareness, links to other modalities and nonacoustic reference information are pointed out where appropriate.},
  archive      = {J_PIEEE},
  author       = {Alexander Schmidt and Heinrich W. Löllmann and Walter Kellermann},
  doi          = {10.1109/JPROC.2020.2977372},
  journal      = {Proceedings of the IEEE},
  number       = {7},
  pages        = {1127-1149},
  shortjournal = {Proc. IEEE},
  title        = {Acoustic self-awareness of autonomous systems in a world of sounds},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Synergizing domain expertise with self-awareness in software
systems: A patternized architecture guideline. <em>PIEEE</em>,
<em>108</em>(7), 1094–1126. (<a
href="https://doi.org/10.1109/JPROC.2020.2985293">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To promote engineering self-aware and self-adaptive software systems in a reusable manner, architectural patterns and the related methodology provide an unified solution to handle the recurring problems in the engineering process. However, in existing patterns and methods, domain knowledge and engineers’ expertise that is built over time are not explicitly linked to the self-aware processes. This link is important, as knowledge is a valuable asset for the related problems and its absence would cause unnecessary overhead, possibly misleading results, and unwise waste of the tremendous benefits that could have been brought by the domain expertise. This article highlights the importance of synergizing domain expertise and the self-awareness to enable better self-adaptation in software systems, relying on well-defined expertise representation, algorithms, and techniques. In particular, we present a holistic framework of notions, enriched patterns and methodology, dubbed DBASES, that offers a principled guideline for the engineers to perform difficulty and benefit analysis on possible synergies, in an attempt to keep “engineers-in-the-loop.” Through three tutorial case studies, we demonstrate how DBASES can be applied in different domains, within which a carefully selected set of candidates with different synergies can be used for quantitative investigation, providing more informed decisions of the design choices.},
  archive      = {J_PIEEE},
  author       = {Tao Chen and Rami Bahsoon and Xin Yao},
  doi          = {10.1109/JPROC.2020.2985293},
  journal      = {Proceedings of the IEEE},
  number       = {7},
  pages        = {1094-1126},
  shortjournal = {Proc. IEEE},
  title        = {Synergizing domain expertise with self-awareness in software systems: A patternized architecture guideline},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Time series forecasting for self-aware systems.
<em>PIEEE</em>, <em>108</em>(7), 1068–1093. (<a
href="https://doi.org/10.1109/JPROC.2020.2983857">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern distributed systems and Internet-of-Things applications are governed by fast living and changing requirements. Moreover, they have to struggle with huge amounts of data that they create or have to process. To improve the self-awareness of such systems and enable proactive and autonomous decisions, reliable time series forecasting methods are required. However, selecting a suitable forecasting method for a given scenario is a challenging task. According to the “No-Free-Lunch Theorem,” there is no general forecasting method that always performs best. Thus, manual feature engineering remains to be a mandatory expert task to avoid trial and error. Furthermore, determining the expected time-to-result of existing forecasting methods is a challenge. In this article, we extensively assess the state-of-the-art in time series forecasting. We compare existing methods and discuss the issues that have to be addressed to enable their use in a self-aware computing context. To address these issues, we present a step-by-step approach to fully automate the feature engineering and forecasting process. Then, following the principles from benchmarking, we establish a level-playing field for evaluating the accuracy and time-to-result of automated forecasting methods for a broad set of application scenarios. We provide results of a benchmarking competition to guide in selecting and appropriately using existing forecasting methods for a given self-aware computing context. Finally, we present a case study in the area of self-aware data-center resource management to exemplify the benefits of fully automated learning and reasoning processes on time series data.},
  archive      = {J_PIEEE},
  author       = {André Bauer and Marwin Züfle and Nikolas Herbst and Albin Zehe and Andreas Hotho and Samuel Kounev},
  doi          = {10.1109/JPROC.2020.2983857},
  journal      = {Proceedings of the IEEE},
  number       = {7},
  pages        = {1068-1093},
  shortjournal = {Proc. IEEE},
  title        = {Time series forecasting for self-aware systems},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Self-aware neural network systems: A survey and new
perspective. <em>PIEEE</em>, <em>108</em>(7), 1047–1067. (<a
href="https://doi.org/10.1109/JPROC.2020.2977722">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural network (NN) processors are specially designed to handle deep learning tasks by utilizing multilayer artificial NNs. They have been demonstrated to be useful in broad application fields such as image recognition, speech processing, machine translation, and scientific computing. Meanwhile, innovative self-aware techniques, whereby a system can dynamically react based on continuously sensed information from the execution environment, have attracted attention from both academia and industry. Actually, various self-aware techniques have been applied to NN systems to significantly improve the computational speed and energy efficiency. This article surveys state-of-the-art self-aware NN systems (SaNNSs), which can be achieved at different layers, that is, the architectural layer, the physical layer, and the circuit layer. At the architectural layer, SaNNS can be characterized from a data-centric perspective where different data properties (i.e., data value, data precision, dataflow, and data distribution) are exploited. At the physical layer, various parameters of physical implementation are considered. At the circuit layer, different logics and devices can be used for high efficiency. In fact, the self-awareness of existing SaNNS is still in a preliminary form. We propose a comprehensive SaNNS from a new perspective, that is, the model layer, to exploit more opportunities for high efficiency. The proposed system is called as MinMaxNN, which features model switching and elastic sparsity based on monitored information from the execution environment. The model switching mechanism implies that models (i.e., min and max model) dynamically switch given different inputs for both efficiency and accuracy. The elastic sparsity mechanism indicates that the sparsity of NNs can be dynamically adjusted in each layer for efficiency. The experimental results show that compared with traditional SaNNS, MinMaxNN can achieve 5.64× and 19.66\% performance improvement and energy reduction, respectively, without notable loss of accuracy and negative effects on developers&#39; productivity.},
  archive      = {J_PIEEE},
  author       = {By Zidong Du and Qi Guo and Yongwei Zhao and Tian Zhi and Yunji Chen and Zhiwei Xu},
  doi          = {10.1109/JPROC.2020.2977722},
  journal      = {Proceedings of the IEEE},
  number       = {7},
  pages        = {1047-1067},
  shortjournal = {Proc. IEEE},
  title        = {Self-aware neural network systems: A survey and new perspective},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Embodied self-aware computing systems. <em>PIEEE</em>,
<em>108</em>(7), 1027–1046. (<a
href="https://doi.org/10.1109/JPROC.2020.2977054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Embodied self-aware computing systems are embedded in a physical environment with a rich set of sensors and actuators to interact both with their environment and with their own embodiment. Through this interaction, they learn about their situation, their own state, and their performance. Although they are application specific like traditional embedded systems (ESs), they are significantly more flexible, robust, and autonomous; they can adapt to a wide range of environmental variation and can cope with deterioration and shortcomings of their own performance. As such, embodied self-aware computing systems are an evolution of traditional embedded and cyber-physical systems into the direction of more autonomy, robustness, and flexibility. When traditional ESs operate in a changing world by demanding unchanging and fully characterized computing resources, embodied self-aware computing systems adapt to a changing world and changing computing resources. This article surveys the methods and methodologies used for embodied self-aware computing systems structured along with the faculties of: 1) sensory observation and abstraction; 2) self-aware assessment; and 3) hierarchical goals and control. The discussion is exemplified by application cases in the areas of systems-on-chip, control systems, health monitoring, and condition monitoring in industrial production systems.},
  archive      = {J_PIEEE},
  author       = {Henry Hoffmann and Axel Jantsch and Nikil D. Dutt},
  doi          = {10.1109/JPROC.2020.2977054},
  journal      = {Proceedings of the IEEE},
  number       = {7},
  pages        = {1027-1046},
  shortjournal = {Proc. IEEE},
  title        = {Embodied self-aware computing systems},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Verifiable self-aware agent-based autonomous systems.
<em>PIEEE</em>, <em>108</em>(7), 1011–1026. (<a
href="https://doi.org/10.1109/JPROC.2020.2991262">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we describe an approach to autonomous system construction that not only supports self-awareness but also formal verification. This is based on modular construction where the key autonomous decision making is captured within a symbolically described “agent.” So, this article leads us from traditional systems architectures, via agent-based computing, to explainability, reconfigurability, and verifiability, and on to applications in robotics, autonomous vehicles, and machine ethics. Fundamentally, we consider self-awareness from an agent-based perspective. Agents are an important abstraction capturing autonomy, and we are particularly concerned with intentional, or rational, agents that expose the “intentions” of the autonomous system. Beyond being a useful abstract concept, agents also provide a practical engineering approach for building the core software in autonomous systems such as robots and vehicles. In a modular autonomous system architecture, agents of this form capture important decision making elements. Furthermore, this ability to transparently capture such decision making processes, and especially being able to expose their intentions, within an agent allows us to apply strong (formal) agent verification techniques to these systems.},
  archive      = {J_PIEEE},
  author       = {Louise A. Dennis and Michael Fisher},
  doi          = {10.1109/JPROC.2020.2991262},
  journal      = {Proceedings of the IEEE},
  number       = {7},
  pages        = {1011-1026},
  shortjournal = {Proc. IEEE},
  title        = {Verifiable self-aware agent-based autonomous systems},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multisensorial generative and descriptive self-awareness
models for autonomous systems. <em>PIEEE</em>, <em>108</em>(7),
987–1010. (<a href="https://doi.org/10.1109/JPROC.2020.2986602">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a computational context, self-awareness (SA) is a capability of an autonomous system to describe the acquired experience about itself and its surrounding environment with appropriate models and correlate them incrementally with the currently perceived situation to expand its knowledge continuously. This article introduces a bio-inspired framework for generative and descriptive dynamic models that support SA computationally and efficiently. Generative models facilitate predicting future states, while descriptive models enable the selection of the representation that best fits the current observation. Our framework is founded on the analysis and extension of three bio-inspired theories that have studied SA from different viewpoints, and we demonstrate how probabilistic techniques, such as cognitive dynamic Bayesian networks and generalized filtering paradigms, can learn appropriate models from multidimensional proprioceptive and exteroceptive signals acquired by the autonomous system. We discuss essential capabilities for SA and show how our modeling framework supports these capabilities in theory and through a case study where a mobile robot uses multisensorial data to determine its internal and environmental state as well as distinguishing among normal and abnormal behaviors.},
  archive      = {J_PIEEE},
  author       = {Carlo S. Regazzoni and Lucio Marcenaro and Damian Campo and Bernhard Rinner},
  doi          = {10.1109/JPROC.2020.2986602},
  journal      = {Proceedings of the IEEE},
  number       = {7},
  pages        = {987-1010},
  shortjournal = {Proc. IEEE},
  title        = {Multisensorial generative and descriptive self-awareness models for autonomous systems},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Neurobiologically inspired self-monitoring systems.
<em>PIEEE</em>, <em>108</em>(7), 976–986. (<a
href="https://doi.org/10.1109/JPROC.2020.2979233">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we explore neurobiological principles that could be deployed in systems requiring self-preservation, adaptive control, and contextual awareness. We start with low-level control for sensor processing and motor reflexes. We then discuss how critical it is at an intermediate level to maintain homeostasis and predict system set points. We end with a discussion at a high level, or cognitive level, where planning and prediction can further monitor the system and optimize performance. We emphasize the information flow between these levels both from a systems neuroscience and an engineering point of view. Throughout the article, we describe the brain systems that carry out these functions and provide examples from artificial intelligence, machine learning, and robotics which include these features. Our goal is to show how biological organisms performing self-monitoring can inspire the design of autonomous and embedded systems.},
  archive      = {J_PIEEE},
  author       = {Andrea A. Chiba and Jeffrey L. Krichmar},
  doi          = {10.1109/JPROC.2020.2979233},
  journal      = {Proceedings of the IEEE},
  number       = {7},
  pages        = {976-986},
  shortjournal = {Proc. IEEE},
  title        = {Neurobiologically inspired self-monitoring systems},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Self-awareness for autonomous systems. <em>PIEEE</em>,
<em>108</em>(7), 971–975. (<a
href="https://doi.org/10.1109/JPROC.2020.2990784">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The articles in this month’s special issue cover concepts and fundamentals, architectures and techniques, and applications and case studies in the exciting area of self-awareness in autonomous systems.},
  archive      = {J_PIEEE},
  author       = {Nikil Dutt and Carlo S. Regazzoni and Bernhard Rinner and Xin Yao},
  doi          = {10.1109/JPROC.2020.2990784},
  journal      = {Proceedings of the IEEE},
  number       = {7},
  pages        = {971-975},
  shortjournal = {Proc. IEEE},
  title        = {Self-awareness for autonomous systems},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020e). IEEE women in engineering. <em>PIEEE</em>, <em>108</em>(6),
968. (<a href="https://doi.org/10.1109/JPROC.2020.2996693">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advertisement, IEEE.},
  archive      = {J_PIEEE},
  doi          = {10.1109/JPROC.2020.2996693},
  journal      = {Proceedings of the IEEE},
  number       = {6},
  pages        = {968},
  shortjournal = {Proc. IEEE},
  title        = {IEEE women in engineering},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020c). Gift of membership. <em>PIEEE</em>, <em>108</em>(6), 967.
(<a href="https://doi.org/10.1109/JPROC.2020.2996691">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advertisement, IEEE.},
  archive      = {J_PIEEE},
  doi          = {10.1109/JPROC.2020.2996691},
  journal      = {Proceedings of the IEEE},
  number       = {6},
  pages        = {967},
  shortjournal = {Proc. IEEE},
  title        = {Gift of membership},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Methodology for maximizing information transmission of
haptic devices: A survey. <em>PIEEE</em>, <em>108</em>(6), 945–965. (<a
href="https://doi.org/10.1109/JPROC.2020.2992561">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This is a survey article on the information transmission capability of haptic devices and ways of maximizing it. It is intended for readers who are engineering professionals interested in developing novel haptic interfaces for a variety of applications but are not necessarily trained in haptic science or human user research. We posit that the ultimate goal of any interface is the exchange of information between a machine and a user, and as such, the evaluation should involve estimating the information-transmission capability with human users. We conducted a literature survey on studies of haptic devices evaluated with human users using an information theoretic framework. Our goal was to discover and summarize best practices that can lead to high information transmission. The results confirmed findings from our own previous studies, uncovered new ways to effectively increase information transmission, and pointed to the need for broader dissemination of proper experimental methodology. We, therefore, present a concise yet comprehensive tutorial on psychophysical methodology for estimating information transfer (IT) and IT rate with humans, survey results on the typical IT achievable with haptic devices, and guidelines for maximizing information transmission with any human-machine interfaces. Although we focus on haptic systems, the information-theoretic framework, the psychophysical methods, and the guidelines presented in this article are applicable to other sensory modalities and multimodal interface systems also.},
  archive      = {J_PIEEE},
  author       = {Hong Z. Tan and Seungmoon Choi and Frances W. Y. Lau and Freddy Abnousi},
  doi          = {10.1109/JPROC.2020.2992561},
  journal      = {Proceedings of the IEEE},
  number       = {6},
  pages        = {945-965},
  shortjournal = {Proc. IEEE},
  title        = {Methodology for maximizing information transmission of haptic devices: A survey},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Indoor millimeter-wave systems: Design and performance
evaluation. <em>PIEEE</em>, <em>108</em>(6), 923–944. (<a
href="https://doi.org/10.1109/JPROC.2020.2989189">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Indoor areas, such as offices and shopping malls, are a natural environment for initial millimeter-wave (mmWave) deployments. Although we already have the technology that enables us to realize indoor mmWave deployments, there are many remaining challenges associated with system-level design and planning for such. The objective of this article is to bring together multiple strands of research to provide a comprehensive and integrated framework for the design and performance evaluation of indoor mmWave systems. This article introduces the framework with a status update on mmWave technology, including ongoing fifth generation (5G) wireless standardization efforts and then moves on to experimentally validated channel models that inform performance evaluation and deployment planning. Together these yield insights on indoor mmWave deployment strategies and system configurations, from feasible deployment densities to beam management strategies and necessary capacity extensions.},
  archive      = {J_PIEEE},
  author       = {Jacek Kibiłda and Allen B. MacKenzie and Mohammad J. Abdel-Rahman and Seong Ki Yoo and Lorenzo Galati Giordano and Simon L. Cotton and Nicola Marchetti and Walid Saad and William G. Scanlon and Adrian Garcia-Rodriguez and David López-Pérez and Holger Claussen and Luiz A. DaSilva},
  doi          = {10.1109/JPROC.2020.2989189},
  journal      = {Proceedings of the IEEE},
  number       = {6},
  pages        = {923-944},
  shortjournal = {Proc. IEEE},
  title        = {Indoor millimeter-wave systems: Design and performance evaluation},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Towards robust pattern recognition: A review.
<em>PIEEE</em>, <em>108</em>(6), 894–922. (<a
href="https://doi.org/10.1109/JPROC.2020.2989782">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accuracies for many pattern recognition tasks have increased rapidly year by year, achieving or even outperforming human performance. From the perspective of accuracy, pattern recognition seems to be a nearly solved problem. However, once launched in real applications, the high-accuracy pattern recognition systems may become unstable and unreliable due to the lack of robustness in open and changing environments. In this article, we present a comprehensive review of research toward robust pattern recognition from the perspective of breaking three basic and implicit assumptions: closed-world assumption, independent and identically distributed assumption, and clean and big data assumption, which form the foundation of most pattern recognition models. Actually, our brain is robust at learning concepts continually and incrementally, in complex, open, and changing environments, with different contexts, modalities, and tasks, by showing only a few examples, under weak or noisy supervision. These are the major differences between human intelligence and machine intelligence, which are closely related to the above three assumptions. After witnessing the significant progress in accuracy improvement nowadays, this review paper will enable us to analyze the shortcomings and limitations of current methods and identify future research directions for robust pattern recognition.},
  archive      = {J_PIEEE},
  author       = {Xu-Yao Zhang and Cheng-Lin Liu and Ching Y. Suen},
  doi          = {10.1109/JPROC.2020.2989782},
  journal      = {Proceedings of the IEEE},
  number       = {6},
  pages        = {894-922},
  shortjournal = {Proc. IEEE},
  title        = {Towards robust pattern recognition: A review},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). 5G key technologies for smart railways. <em>PIEEE</em>,
<em>108</em>(6), 856–893. (<a
href="https://doi.org/10.1109/JPROC.2020.2988595">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Railway communications has attracted significant attention from both academia and industries due to the booming development of railways, especially high-speed railways (HSRs). To be in line with the vision of future smart rail communications, the rail transport industry needs to develop innovative communication network architectures and key technologies that ensure high-quality transmissions for both passengers and railway operations and control systems. Under high mobility and with safety, eco-friendliness, comfort, transparency, predictability, and reliability. Fifth-generation (5G) technologies could be a promising solution to dealing with the design challenges on high reliability and high throughput for HSR communications. Based on our in-depth analysis of smart rail traffic services and communication scenarios, we propose a network slicing architecture for a 5G-based HSR system. With a ray tracing-based analysis of radio wave propagation characteristics and channel models for millimeter wave (mmWave) bands in railway scenarios, we draw important conclusions with regard to appropriate operating frequency bands for HSRs. mymargin Specifically, we have identified significant 5G-based key technologies for HSRs, such as spatial modulation, fast channel estimation, cell-free massive multiple-input-multiple-output (MIMO), mmWave, efficient beamforming, wireless backhaul, ultrareliable low latency communications, and enhanced handover strategies. Based on these technologies, we have developed a complete framework of 5G technologies for smart railways and pointed out exciting future research directions.},
  archive      = {J_PIEEE},
  author       = {Bo Ai and Andreas F. Molisch and Markus Rupp and Zhang-Dui Zhong},
  doi          = {10.1109/JPROC.2020.2988595},
  journal      = {Proceedings of the IEEE},
  number       = {6},
  pages        = {856-893},
  shortjournal = {Proc. IEEE},
  title        = {5G key technologies for smart railways},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Scanning the issue. <em>PIEEE</em>, <em>108</em>(6),
854–855. (<a href="https://doi.org/10.1109/JPROC.2020.2993418">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rail traffic systems are widely acknowledged to be an alternative green transportation for goods and people due to their higher mobility, energy efficiency (EE), and/or substantially lower environmental impact than conventional transportation systems. Railway communications have attracted significant attention due to its potential for not only improving operational mobility, safety, and reliability but also improving quality-of-service, eco-friendliness, comfort, and cost efficiency.},
  archive      = {J_PIEEE},
  author       = {B. Ai and A. F. Molisch and M. Rupp and Z.-D. Zhong and X.-Y. Zhang and C.-L. Liu and C. Y. Suen and J. Kibiłda and A. B. MacKenzie and M. J. Abdel-Rahman and S. K. Yoo and L. Galati Giordano and S. L. Cotton and N. Marchetti and W. Saad and W. G. Scanlon and A. Garcia-Rodriguez and D. López-Pérez and H. Claussen and L. A. DaSilva and H. Z. Tan and S. Choi and F. W. Y. Lau and F. Abnousi},
  doi          = {10.1109/JPROC.2020.2993418},
  journal      = {Proceedings of the IEEE},
  number       = {6},
  pages        = {854-855},
  shortjournal = {Proc. IEEE},
  title        = {Scanning the issue},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020f). IEEE women in engineering. <em>PIEEE</em>, <em>108</em>(5),
852. (<a href="https://doi.org/10.1109/JPROC.2020.2989027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advertisement, IEEE.},
  archive      = {J_PIEEE},
  doi          = {10.1109/JPROC.2020.2989027},
  journal      = {Proceedings of the IEEE},
  number       = {5},
  pages        = {852},
  shortjournal = {Proc. IEEE},
  title        = {IEEE women in engineering},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). What + if = IEEE. <em>PIEEE</em>, <em>108</em>(5), 851. (<a
href="https://doi.org/10.1109/JPROC.2020.2989025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advertisement, IEEE.},
  archive      = {J_PIEEE},
  doi          = {10.1109/JPROC.2020.2989025},
  journal      = {Proceedings of the IEEE},
  number       = {5},
  pages        = {851},
  shortjournal = {Proc. IEEE},
  title        = {What + if = IEEE},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Topological nanophotonics: Toward robust quantum circuits.
<em>PIEEE</em>, <em>108</em>(5), 837–849. (<a
href="https://doi.org/10.1109/JPROC.2019.2939987">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last five years, the combination of advances in nanofabrication and a series of ingenious design ideas has enabled the implementation of topological concepts into nanophotonic platforms. In parallel, an unprecedented amount of research effort is being devoted to quantum technologies, with quantum information processing promising exponentially better performance than its classic counterpart for certain tasks. Nanophotonics is bound to play a key role in quantum information technologies given its compactness, low-power requirements, room-temperature operation, and the inherent high speed and low noise of photons. However, the scalability of quantum information systems in integrated photonic platforms is limited by scattering loss and other errors from random fabrication imperfections. The remarkable robustness to disorder and imperfections manifested by photonic states in topological systems emerges as a fascinating research avenue to tackle this issue. Furthermore, the ease of engineering and fabricating nanophotonic platforms with distinctive geometries and symmetries that can effectively generate and transport complex quantum states makes nanophotonics an ideal platform in which to realize topological protection of quantum photonic states. This article highlights the pioneering experimental efforts to understand the potential of topological protection on quantum photonic states and to outline a path toward robust quantum circuits.},
  archive      = {J_PIEEE},
  author       = {Andrea Blanco-Redondo},
  doi          = {10.1109/JPROC.2019.2939987},
  journal      = {Proceedings of the IEEE},
  number       = {5},
  pages        = {837-849},
  shortjournal = {Proc. IEEE},
  title        = {Topological nanophotonics: Toward robust quantum circuits},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Electrically pumped microring parity-time-symmetric lasers.
<em>PIEEE</em>, <em>108</em>(5), 827–836. (<a
href="https://doi.org/10.1109/JPROC.2019.2935901">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microscale and nanoscale electrically pumped lasers are expected to play an indispensable role in future photonic integrated circuits. Small footprint, low threshold, high efficiency, and large side-mode suppression ratio (SMSR) are among the most important characteristics that such on-chip emitters should exhibit-allowing for large-scale integrability, low energy consumption, and stable output power. Microring resonators are one of the main contenders for the realization of such compact light sources. However, the use of microring laser cavities has been so far hindered by their tendency to operate in multiple modes. Quite recently, several studies have shown that notions from parity-time (PT)-symmetry and non-Hermitian physics can be utilized to effectively enforce single-mode operation in semiconductor microring laser arrangements. However, as of now, most works in this area were mainly devoted to the proof of concept demonstrations, while the feasibility of practical implementation has remained largely unexplored. In this article, we demonstrate the first regrowth free, electrically pumped microscale PT-symmetric laser. Our results can pave the way toward the utilization of exceptional points in more diverse applications ranging from on-chip light sources and modulators to laser beam steering systems and active sensors.},
  archive      = {J_PIEEE},
  author       = {William E. Hayenga and Hipolito Garcia-Gracia and Enrique Sanchez Cristobal and Midya Parto and Hossein Hodaei and Patrick LiKamWa and Demetrios N. Christodoulides and Mercedeh Khajavikhan},
  doi          = {10.1109/JPROC.2019.2935901},
  journal      = {Proceedings of the IEEE},
  number       = {5},
  pages        = {827-836},
  shortjournal = {Proc. IEEE},
  title        = {Electrically pumped microring parity-time-symmetric lasers},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Experimental investigation of lasing modes in double-lattice
photonic-crystal resonators and introduction of in-plane
heterostructures. <em>PIEEE</em>, <em>108</em>(5), 819–826. (<a
href="https://doi.org/10.1109/JPROC.2019.2935159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Photonic-crystal surface-emitting lasers (PCSELs) are attractive for a wide range of applications such as material processing and remote sensing owing to their advantage of broad-area coherent lasing supported by a 2-D photonic crystal. Recently, we proposed double-lattice photonic-crystal resonators and achieved 10-W-class high-power and high-beam-quality (namely, high-brightness) operation. To further increase the brightness, it is important to understand the lasing mode behavior of PCSELs in detail. In this article, we experimentally investigate the change in the lasing mode depending on the current injection levels and compare the results with a theoretical analysis that accounts for the change in refractive index and gain distributions due to the current injection. We observed a transition from single-mode lasing to two-mode lasing at high injection currents. We develop a technique for resolving the near-field profiles of individual lasing modes and show that these profiles coincide with theoretical predictions. A comparison of experimental and theoretical results reveals that high-order modes appear due to a bandgap confinement effect induced by a change in the refractive index in the carrier injection area. To effectively remove this confinement effect and suppress the oscillation of high-order modes, we incorporate an in-plane heterostructure into the PCSEL.},
  archive      = {J_PIEEE},
  author       = {Masahiro Yoshida and Masato Kawasaki and Menaka De Zoysa and Kenji Ishizaki and Takuya Inoue and Yoshinori Tanaka and Ranko Hatsuda and Susumu Noda},
  doi          = {10.1109/JPROC.2019.2935159},
  journal      = {Proceedings of the IEEE},
  number       = {5},
  pages        = {819-826},
  shortjournal = {Proc. IEEE},
  title        = {Experimental investigation of lasing modes in double-lattice photonic-crystal resonators and introduction of in-plane heterostructures},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Lattice resonances in optical metasurfaces with gain and
loss. <em>PIEEE</em>, <em>108</em>(5), 795–818. (<a
href="https://doi.org/10.1109/JPROC.2019.2939396">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Periodic lattices of strongly scattering objects coupled to active media are of central importance in applied nanophotonics, serving as light-emitting metasurfaces of tailored emission properties and promising an attractive platform for testing novel physical concepts and realization of unprecedented light-shaping functions. We provide an overview of the semianalytical Green function method with Ewald lattice summation applied to the investigation of surface lattice resonances in periodic arrays of resonant nanoscatterers with gain and loss. This theory is meant as a minimal model for plasmonic lattices and metasurfaces with gain: minimal in complexity, yet sufficiently rich to be a self-consistent, fully retarded multiple scattering model. It enables to include the electromagnetic interactions between electric and/or magnetic point dipoles of arbitrary orientation and arrangement, taking into account retardation and tensorial nature of these interactions and including radiation damping. It gives access to the far-field observables (reflection/transmission), as well as to the photonic band structure of guided modes. At the same time, it does not violate the optical theorem, as opposed to the commonly used tight-binding or quasi-static models. After extending the lattice Green function formalism to include gain and loss in the unit cell, we demonstrate the effects of parity-time (PT) symmetry breaking in active-lossy plasmonic arrays: the emergence of exceptional points, nontrivial topology of photonic bands, diverging effective unit-cell polarizability, and spin polarization in the PT-broken phase.},
  archive      = {J_PIEEE},
  author       = {Radoslaw Kolkowski and A. Femius Koenderink},
  doi          = {10.1109/JPROC.2019.2939396},
  journal      = {Proceedings of the IEEE},
  number       = {5},
  pages        = {795-818},
  shortjournal = {Proc. IEEE},
  title        = {Lattice resonances in optical metasurfaces with gain and loss},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Structured semiconductor interfaces: Active functionality on
light manipulation. <em>PIEEE</em>, <em>108</em>(5), 772–794. (<a
href="https://doi.org/10.1109/JPROC.2019.2919675">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structured interfaces with subwavelength features enable modulations of phase, amplitude, and polarization on demand, leading to a plethora of flat-profile devices and metasurfaces. Plasmonic and dielectric metasurfaces have been intensively explored, building up the frameworks of flat optics for ultrathin and integrated nanophotonics. The in situ controllability and tunability of aforementioned family of metasurfaces, however, has been a grand challenge, due to the intrinsic limitations of the materials. Semiconductors with diversified catalogs of material candidates thus demonstrate promising potentials, owing to the mature and versatile technologies developed nowadays. The fuse of semiconductors and nanostructured metasurfaces has been witnessed more recently, paving a distinct avenue toward active, tunable, reconfigurable light manipulation for next-generation optical nanodevices. Judicious selection of the active materials for metasurfaces empowers the active functionality of the designer applications. This paper presents a review of this merging semiconductor paradigm for active metasurfaces across a wide range of spectrum and shows unprecedented potentials in the future interface-based optoelectronics, quantum optics, nano-optics, and surface engineering with full compatibility of semiconductor foundry.},
  archive      = {J_PIEEE},
  author       = {Yao-Wei Huang and He-Xiu Xu and Shang Sun and Yunkai Wu and Zhuo Wang and Shumin Xiao and Wei Xiang Jiang and Tie Jun Cui and Din Ping Tsai and Cheng-Wei Qiu},
  doi          = {10.1109/JPROC.2019.2919675},
  journal      = {Proceedings of the IEEE},
  number       = {5},
  pages        = {772-794},
  shortjournal = {Proc. IEEE},
  title        = {Structured semiconductor interfaces: Active functionality on light manipulation},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Active and tunable nanophotonics with dielectric
nanoantennas. <em>PIEEE</em>, <em>108</em>(5), 749–771. (<a
href="https://doi.org/10.1109/JPROC.2019.2943183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, high-index dielectric nanoantennas supporting Mie resonances have emerged as a promising platform to create low-loss nanophotonic devices. The multipolar resonances naturally supported by this kind of nanoantennas allow designing systems in which the out-coupling radiation, and in particular the directivity, can be tailored at will. Moreover, unlike plasmonic counterparts, local electromagnetic fields in resonant dielectric nanoparticles concentrate inside the structures rather than outside. This allows enhancing light-matter interactions in their volume and boosting their linear and nonlinear optical properties by choosing suitable semiconductors as the material platform to build them. In this article, we will discuss recent results on active and tunable nanophotonics based on resonant dielectric and semiconductor nanostructures. Specifically, we will focus on two main topics: active tuning of dielectric nanoantennas and enhancement and spectral shaping of light emission using dielectric nanoantennas, including lasing. Finally, future research directions and proposed practical applications will also be discussed.},
  archive      = {J_PIEEE},
  author       = {Ramón Paniagua-Domínguez and Son Tung Ha and Arseniy I. Kuznetsov},
  doi          = {10.1109/JPROC.2019.2943183},
  journal      = {Proceedings of the IEEE},
  number       = {5},
  pages        = {749-771},
  shortjournal = {Proc. IEEE},
  title        = {Active and tunable nanophotonics with dielectric nanoantennas},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Physical limits of NanoLEDs and nanolasers for optical
communications. <em>PIEEE</em>, <em>108</em>(5), 735–748. (<a
href="https://doi.org/10.1109/JPROC.2019.2912293">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nanoscale light sources are being intensively investigated for their potential to enable low-energy, high-density optical communication and sensing systems. Both nanolight-emitting diodes (nanoLEDs) and nanolasers have been considered, based on advanced nanophotonic concepts such as photonic crystals and plasmonic structures, with dimensions well into the submicrometer domain. With decreasing dimensions, light-matter interaction becomes stronger, potentially leading to efficient and ultrafast radiative emission, both in the spontaneous and stimulated regimes. These features have created wide expectations for the practical prospects of such nanoscale light sources, in particular for optical interconnects. In this paper, we examine the limits to the downscaling of LEDs and lasers and ask ourselves which type of source is most suited to ultralow-power optical communications. Based on simple physical considerations on the scaling of spontaneous and stimulated emission rates for semiconductor active regions at room temperature, we analyze the speed and energy limits for nanoLEDs and nanolasers as a function of their size. The role of spontaneous emission enhancement (Purcell effect) in practical nanophotonic sources is also revisited. The main conclusion is that nanoLEDs reach a fundamental energy/speed limit for data rates exceeding a few gigahertz per second, whereas nanolasers with active dimensions in the range of few hundred nanometers may enable direct modulation rates larger than 40 Gb/s at power levels adequate for short-distance and low-energy optical interconnects.},
  archive      = {J_PIEEE},
  author       = {Bruno Romeira and Andrea Fiore},
  doi          = {10.1109/JPROC.2019.2912293},
  journal      = {Proceedings of the IEEE},
  number       = {5},
  pages        = {735-748},
  shortjournal = {Proc. IEEE},
  title        = {Physical limits of NanoLEDs and nanolasers for optical communications},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Integrated, portable, tunable, and coherent terahertz
sources and sensitive detectors based on layered superconductors.
<em>PIEEE</em>, <em>108</em>(5), 721–734. (<a
href="https://doi.org/10.1109/JPROC.2019.2958810">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current compact emitter and receiver technologies are generally inefficient and impractical at terahertz (THz) frequencies between 0.1 and 10 THz. Hence, a gap exists between mature microwave and developed optical technologies. On-chip, integrated broadly tunable and powerful quantum sources that coherently radiate THz waves between 0.1 and 11 THz (potentially extendable to 15 THz) and with potential output power of &gt;1 mW can be achieved based on quantum tunneling of electron pairs across the stack of intrinsic Josephson junctions (IJJs) naturally present in a single crystal of the layered high-T c superconducting Bi 2 Sr 2 CaCu 2 O 8+δ (BSCCO). Such devices have been found to be especially promising solid-state THz sources capable of bridging the entire THz gap, as their wide-frequency tunability range is superior to that obtained from their semiconducting-based rivals, either single resonant-tunneling diodes (RTDs) or THz-quantum cascade lasers (QCLs). Due to the unique electrodynamics of BSCCO, they can also be operated as switching current detectors, paving the way for the realization of on-chip THz-integrated circuits for applications in ultrahigh-speed telecommunications, quantum information, on-chip spectroscopy, and nondestructive sensing, testing, and imaging. This article reviews the history and recent advances in THz sources and detectors based on IJJs with a focus on the application of IJJ THz devices in THz spectroscopy and various types of THz imaging systems such as reflection, transmission, and computed tomography. We show that compact IJJ THz devices with sub-centimeter-sized modules are easy to use in many applications, as they can be regarded as pocket quantum THz torches.},
  archive      = {J_PIEEE},
  author       = {Kaveh Delfanazari and Richard A. Klemm and Hannah J. Joyce and David A. Ritchie and Kazuo Kadowaki},
  doi          = {10.1109/JPROC.2019.2958810},
  journal      = {Proceedings of the IEEE},
  number       = {5},
  pages        = {721-734},
  shortjournal = {Proc. IEEE},
  title        = {Integrated, portable, tunable, and coherent terahertz sources and sensitive detectors based on layered superconductors},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Colloidal plasmonics for active nanophotonics.
<em>PIEEE</em>, <em>108</em>(5), 704–720. (<a
href="https://doi.org/10.1109/JPROC.2019.2958875">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nanoplasmonics represents one of the most extensive research fields in optics on the nanoscale and has emerging applications in sensors, light-emitting devices, and photovoltaic devices. It offers a number of effects and can be combined with existing technologies by a number of approaches, the colloidal techniques representing the easiest implementation in the existing and emerging photonic components and devices. In this article, plasmonic effects are discussed in terms of three major physical phenomena (incident field enhancement, photon density of states enhancement, and nonradiative decay enhancement) in the context of various photonic processes and devices related to Raman scattering, photo- and electroluminescence, photovoltaics, photochemistry, and photodetectors. A number of instructive examples are given for metal nanospheres and nanorods showing how size, shape, core-shell design, and ambient environment can be used to get maximal use of the favorable factors while keeping unfavorable ones at reasonably safe level. A number of aspects of plasmonically enhanced secondary radiation are emphasized which have not gained close consideration to date. Among them, the following properties are discussed: the decisive role of scattering component of metal-dielectric extinction spectrum overlapping with incident and emitted/scattered light wavelength, valuable contribution to enhancement factors from spacers used to prevent emission quenching but simultaneously affecting the extinction spectrum, a pronounced dependence of enhancement factors on dielectric permittivity of the substrate, dielectric shell, and ambient medium.},
  archive      = {J_PIEEE},
  author       = {Sergey V. Gaponenko and Dmitry V. Guzatov},
  doi          = {10.1109/JPROC.2019.2958875},
  journal      = {Proceedings of the IEEE},
  number       = {5},
  pages        = {704-720},
  shortjournal = {Proc. IEEE},
  title        = {Colloidal plasmonics for active nanophotonics},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optical properties and light-emission device applications of
2-d layered semiconductors. <em>PIEEE</em>, <em>108</em>(5), 676–703.
(<a href="https://doi.org/10.1109/JPROC.2019.2936424">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two-dimensional layered semiconductors have attracted a great deal of attention recently from many fields of science and technology. This article overviews the major progress from the perspective of light-emission properties and related device applications of such 2-D materials. We begin with the overview of basic optical properties, including emission features of various excitonic complexes, many-body effects, light-emission enhancement due to plasmonic coupling, and mechanisms of optical gain. This is followed by discussions of coupling of 2-D materials with an optical cavity, including cavity-enhanced emission due to the Purcell effect, strong and weak coupling, as well as lasing behavior. We then discuss the design and the fabrication of various heterostructures by stacking layers of different 2-D materials for the purpose of confining and injecting charge carriers. Such structures are indispensable for light-emitting devices under electrical injection, the ultimate goal of any semiconductor-based light-emitting diode (LED) or lasers. The progress in electrical injection devices is reviewed next, where LEDs under lateral and vertical electrical injection schemes are discussed. The review is concluded with an outlook and future perspectives.},
  archive      = {J_PIEEE},
  author       = {Yongzhuo Li and Hao Sun and Lin Gan and Jianxing Zhang and Jiabin Feng and Danyang Zhang and Cun-Zheng Ning},
  doi          = {10.1109/JPROC.2019.2936424},
  journal      = {Proceedings of the IEEE},
  number       = {5},
  pages        = {676-703},
  shortjournal = {Proc. IEEE},
  title        = {Optical properties and light-emission device applications of 2-D layered semiconductors},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Two-dimensional CdSe-based nanoplatelets: Their
heterostructures, doping, photophysical properties, and applications.
<em>PIEEE</em>, <em>108</em>(5), 655–675. (<a
href="https://doi.org/10.1109/JPROC.2019.2944277">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past decade, colloidal quantum wells, also known as 2-D semiconductor nanoplatelets (NPLs), have been added to the colloidal nanocrystal (NC) family. Through the unique control of the thickness with monolayer precision, these novel materials exhibit strong 1-D quantum confinement that offers unique optical properties along with the possibility of fabricating advanced heterostructures, which are not possible with other quantum-confined nanostructures. The 2-D CdX (X = Se, S)-based NPLs provide high color purities, fast fluorescence lifetimes, and large exciton binding energies. This review covers the latest developments in the successful utilization of these flat NCs in different nanophotonic device applications. The synthesis of the advanced heterostructures of flat 2-D NCs (e.g., core-shell, core-crown, and core-crown-shell) has matured very rapidly, and new exciting optical and electronic applications are emerging. Doping of these atomically thin NCs also offers new possibilities for their utilization in different solar light harvesting, magnetic, electronic, and lasing applications. This review also includes the recent advancements in the understanding of their unique optical properties that are of utmost importance for their practical implementation in light-emitting devices and lasers. Finally, we present a future perspective on their successful utilization in different nanophotonic applications.},
  archive      = {J_PIEEE},
  author       = {Manoj Sharma and Savas Delikanli and Hilmi Volkan Demir},
  doi          = {10.1109/JPROC.2019.2944277},
  journal      = {Proceedings of the IEEE},
  number       = {5},
  pages        = {655-675},
  shortjournal = {Proc. IEEE},
  title        = {Two-dimensional CdSe-based nanoplatelets: Their heterostructures, doping, photophysical properties, and applications},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Active nanophotonics. <em>PIEEE</em>, <em>108</em>(5),
628–654. (<a href="https://doi.org/10.1109/JPROC.2020.2985048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent progress in nanofabrication has led to tremendous technological developments for devices that rely on the interaction of light with nanostructured matter. Nanophotonics has hence experienced a large surge of interest in recent years, from basic research to applied technology. For instance, the increased importance of ultralow-energy data processing at fast speeds has been encouraging the use of light for signal transport and processing. Energy demands and interaction time scales become smaller with the physical size of the nanostructures, hence nanophotonics opens important opportunities for integrating a large number of devices that can generate, control, modulate, sense, and process light signals at ultrafast speeds and below femtojoule/bit energy levels. However, losses and diffraction pose fundamental challenges to the fundamental ability of nanophotonic structures to efficiently confine light in smaller and smaller volumes. In this framework, active nanophotonics, which combines the latest advances in nanotechnology with gain materials, has recently become a vital area of optics research, both from the physics, material science, and engineering standpoint. In this article, we review recent efforts in enabling active nanodevices for lasing and optical sources, loss compensation, and to realize new optical functionalities, like PT-symmetry, exceptional points, and nontrivial lasing based on suitably engineered distributions of gain and loss in nanostructures.},
  archive      = {J_PIEEE},
  author       = {Alex Krasnok and Andrea Alù},
  doi          = {10.1109/JPROC.2020.2985048},
  journal      = {Proceedings of the IEEE},
  number       = {5},
  pages        = {628-654},
  shortjournal = {Proc. IEEE},
  title        = {Active nanophotonics},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Active nanophotonics [scanning the issue]. <em>PIEEE</em>,
<em>108</em>(5), 625–627. (<a
href="https://doi.org/10.1109/JPROC.2020.2986176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Being able to manipulate and control light flows at small scales holds the promise to open groundbreaking opportunities for a variety of technologies. Consider, for instance, the challenges currently faced in the world of computing: as data rates and processing demands increase worldwide at an exponential rate, we are facing unsustainable increases in energy consumption associated with data centers and streaming providers. To address these challenges, optical computing and communications offer an interesting alternative to electronic-based systems. Using light for these purposes, however, is hindered by the fact that photons are not easily squeezed to volumes beyond the diffraction limit, i.e., below the wavelength scale, which would be required both to enable lowenergy computation at sufficiently high speeds and to match the degree of integration density available in electronic systems. Today, the field of optoelectronics, which combines highdensity electronic devices to process the data and low-energy data transport enabled by light, is growing at a very fast pace.},
  archive      = {J_PIEEE},
  author       = {Andrea Alù and Hilmi Volkan Demir and Chennupati Jagadish},
  doi          = {10.1109/JPROC.2020.2986176},
  journal      = {Proceedings of the IEEE},
  number       = {5},
  pages        = {625-627},
  shortjournal = {Proc. IEEE},
  title        = {Active nanophotonics [Scanning the issue]},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). DC is the future [point of view]. <em>PIEEE</em>,
<em>108</em>(5), 615–624. (<a
href="https://doi.org/10.1109/JPROC.2020.2982707">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For ac electricity grids, the aim has always been at low-cost and disruption-proof solutions. The power grid is inherently vulnerable to environmental disturbances. However, the introduction of power electronics (PEs) and changes in load and generator characteristics have introduced a game changer at an unprecedented pace over the last decade. During this change, load specifications, load characteristics, and control and monitoring requirements for power system security have also dramatically evolved. Efficiency and reliability of system components have progressed in parallel with this evolution. However, high penetration of renewable energy sources has reduced the percentage contribution of conventional electricity based on synchronous generation, which affects grid stability and hence reliability. Furthermore, numerous camouflaged dc generators and dc loads are being embedded in ac and dc microgrids at ever increasing rates. While embedded generation rapidly increases its share in the hybrid power grid (where ac and dc coexist), the current developments in PE switches-based on wide bandgap (WBG) technology-indicate that within the next two decades Max Planck&#39;s well-known sentiment that science advances one funeral at a time will repeat itself on the ac grid. This article aims to summarize the technical developments and problems facing the utilization of ac during widescale electrification of the world using numerous distributed energy resources (DERs). Then, it will map out evolutionary changes toward a future dc grid.},
  archive      = {J_PIEEE},
  author       = {Nesimi Ertugrul and Derek Abbott},
  doi          = {10.1109/JPROC.2020.2982707},
  journal      = {Proceedings of the IEEE},
  number       = {5},
  pages        = {615-624},
  shortjournal = {Proc. IEEE},
  title        = {DC is the future [Point of view]},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). What + if = IEEE. <em>PIEEE</em>, <em>108</em>(4), 612. (<a
href="https://doi.org/10.1109/JPROC.2020.2984845">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advertisement, IEEE.},
  archive      = {J_PIEEE},
  doi          = {10.1109/JPROC.2020.2984845},
  journal      = {Proceedings of the IEEE},
  number       = {4},
  pages        = {612},
  shortjournal = {Proc. IEEE},
  title        = {What + if = IEEE},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020g). IEEE women in engineering. <em>PIEEE</em>, <em>108</em>(4),
610. (<a href="https://doi.org/10.1109/JPROC.2020.2984847">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advertisement, IEEE.},
  archive      = {J_PIEEE},
  doi          = {10.1109/JPROC.2020.2984847},
  journal      = {Proceedings of the IEEE},
  number       = {4},
  pages        = {610},
  shortjournal = {Proc. IEEE},
  title        = {IEEE women in engineering},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A tutorial on clique problems in communications and signal
processing. <em>PIEEE</em>, <em>108</em>(4), 583–608. (<a
href="https://doi.org/10.1109/JPROC.2020.2977595">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since its first use by Euler on the problem of the seven bridges of Königsberg, graph theory has shown excellent abilities in solving and unveiling the properties of multiple discrete optimization problems. The study of the structure of some integer programs reveals equivalence with graph theory problems making a large body of the literature readily available for solving and characterizing the complexity of these problems. This tutorial presents a framework for utilizing a particular graph theory problem, known as the clique problem, for solving communications and signal processing problems. In particular, this article aims to illustrate the structural properties of integer programs that can be formulated as clique problems through multiple examples in communications and signal processing. To that end, the first part of the tutorial provides various optimal and heuristic solutions for the maximum clique, maximum weight clique, and ${k}$ -clique problems. The tutorial, further, illustrates the use of the clique formulation through numerous contemporary examples in communications and signal processing, mainly in maximum access for nonorthogonal multiple access networks, throughput maximization using index and instantly decodable network coding, collision-free radio-frequency identification networks, and resource allocation in cloud-radio access networks. Finally, the tutorial sheds light on the recent advances of such applications, and provides technical insights on ways of dealing with mixed discrete-continuous optimization problems.},
  archive      = {J_PIEEE},
  author       = {Ahmed Douik and Hayssam Dahrouj and Tareq Y. Al-Naffouri and Mohamed-Slim Alouini},
  doi          = {10.1109/JPROC.2020.2977595},
  journal      = {Proceedings of the IEEE},
  number       = {4},
  pages        = {583-608},
  shortjournal = {Proc. IEEE},
  title        = {A tutorial on clique problems in communications and signal processing},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A key 6G challenge and opportunity—connecting the base of
the pyramid: A survey on rural connectivity. <em>PIEEE</em>,
<em>108</em>(4), 533–582. (<a
href="https://doi.org/10.1109/JPROC.2020.2976703">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Providing connectivity to around half of the world population living in rural or underprivileged areas is a tremendous challenge, but, at the same time, a unique opportunity. Access to the Internet would provide the population living in these areas a possibility to progress on the educational, health, environment, and business levels. In this article, a survey of technologies for providing connectivity to rural areas, which can help address this challenge, is provided. Although access/fronthaul and backhaul techniques are discussed in this article, it is noted that the major limitation for providing connectivity to rural and underprivileged areas is the cost of backhaul deployment. In addition, energy requirements and cost-efficiency of the studied technologies are analyzed. In fact, the challenges faced for deploying an electricity network, as a prerequisite for deploying communication networks, are huge in these areas, and they are granted an important share of the discussions in this article. Furthermore, typical application scenarios in rural areas are discussed, and several country-specific use cases are surveyed. The main initiatives by key international players aiming to provide rural connectivity are also described. Moreover, directions for the future evolution of rural connectivity are outlined in this article. Although there is no single solution that can solve all rural connectivity problems, building gradually on the current achievements in order to reach ubiquitous connectivity, while taking into account the particularities of each region and tailoring the solution accordingly, seems to be the most suitable path to follow.},
  archive      = {J_PIEEE},
  author       = {Elias Yaacoub and Mohamed-Slim Alouini},
  doi          = {10.1109/JPROC.2020.2976703},
  journal      = {Proceedings of the IEEE},
  number       = {4},
  pages        = {533-582},
  shortjournal = {Proc. IEEE},
  title        = {A key 6G challenge and Opportunity—Connecting the base of the pyramid: A survey on rural connectivity},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Model compression and hardware acceleration for neural
networks: A comprehensive survey. <em>PIEEE</em>, <em>108</em>(4),
485–532. (<a href="https://doi.org/10.1109/JPROC.2020.2976475">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain-specific hardware is becoming a promising topic in the backdrop of improvement slow down for general-purpose processors due to the foreseeable end of Moore&#39;s Law. Machine learning, especially deep neural networks (DNNs), has become the most dazzling domain witnessing successful applications in a wide spectrum of artificial intelligence (AI) tasks. The incomparable accuracy of DNNs is achieved by paying the cost of hungry memory consumption and high computational complexity, which greatly impedes their deployment in embedded systems. Therefore, the DNN compression concept was naturally proposed and widely used for memory saving and compute acceleration. In the past few years, a tremendous number of compression techniques have sprung up to pursue a satisfactory tradeoff between processing efficiency and application accuracy. Recently, this wave has spread to the design of neural network accelerators for gaining extremely high performance. However, the amount of related works is incredibly huge and the reported approaches are quite divergent. This research chaos motivates us to provide a comprehensive survey on the recent advances toward the goal of efficient compression and execution of DNNs without significantly compromising accuracy, involving both the high-level algorithms and their applications in hardware design. In this article, we review the mainstream compression approaches such as compact model, tensor decomposition, data quantization, and network sparsification. We explain their compression principles, evaluation metrics, sensitivity analysis, and joint-way use. Then, we answer the question of how to leverage these methods in the design of neural network accelerators and present the state-of-the-art hardware architectures. In the end, we discuss several existing issues such as fair comparison, testing workloads, automatic compression, influence on security, and framework/hardware-level support, and give promising topics in this field and the possible challenges as well. This article attempts to enable readers to quickly build up a big picture of neural network compression and acceleration, clearly evaluate various methods, and confidently get started in the right way.},
  archive      = {J_PIEEE},
  author       = {Lei Deng and Guoqi Li and Song Han and Luping Shi and Yuan Xie},
  doi          = {10.1109/JPROC.2020.2976475},
  journal      = {Proceedings of the IEEE},
  number       = {4},
  pages        = {485-532},
  shortjournal = {Proc. IEEE},
  title        = {Model compression and hardware acceleration for neural networks: A comprehensive survey},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Scanning the issue. <em>PIEEE</em>, <em>108</em>(4),
483–484. (<a href="https://doi.org/10.1109/JPROC.2020.2979196">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This month’s issue offers insight into efficient compression and execution of DNNs, the challenge of connecting rural areas, and the clique problem in wireless communication. which},
  archive      = {J_PIEEE},
  author       = {H. -S. P. Wong and K. Akarvardar and D. Antoniadis and J. Bokor and C. Hu and T. -J. King-Liu and S. Mitra and J. D. Plummer and S. Salahuddin and L. Deng and G. Li and S. Han and L. Shi and Y. Xie and E. Yaacoub and M.-S. Alouini and A. Douik and H. Dahrouj and T. Y. Al-Naffouri and M.-S. Alouini},
  doi          = {10.1109/JPROC.2020.2979196},
  journal      = {Proceedings of the IEEE},
  number       = {4},
  pages        = {483-484},
  shortjournal = {Proc. IEEE},
  title        = {Scanning the issue},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A density metric for semiconductor technology [point of
view]. <em>PIEEE</em>, <em>108</em>(4), 478–482. (<a
href="https://doi.org/10.1109/JPROC.2020.2981715">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since its inception, the semiconductor industry has used a physical dimension (the minimum gate length of a transistor) as a means to gauge continuous technology advancement. This metric is all but obsolete today. As a replacement, we propose a density metric, which aims to capture how advances in semiconductor device technologies enable system-level benefits. The proposed metric can be used to gauge advances in future generations of semi-conductor technologies in a holistic way, by accounting for the progress in logic, memory, and packaging/integration technologies simultaneously.},
  archive      = {J_PIEEE},
  author       = {H.-S. Philip Wong and Kerem Akarvardar and Dimitri Antoniadis and Jeffrey Bokor and Chenming Hu and Tsu-Jae King-Liu and Subhasish Mitra and James D. Plummer and Sayeef Salahuddin},
  doi          = {10.1109/JPROC.2020.2981715},
  journal      = {Proceedings of the IEEE},
  number       = {4},
  pages        = {478-482},
  shortjournal = {Proc. IEEE},
  title        = {A density metric for semiconductor technology [Point of view]},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020h). IEEE women in engineering. <em>PIEEE</em>, <em>108</em>(3),
476. (<a href="https://doi.org/10.1109/JPROC.2020.2976268">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advertisement, IEEE.},
  archive      = {J_PIEEE},
  doi          = {10.1109/JPROC.2020.2976268},
  journal      = {Proceedings of the IEEE},
  number       = {3},
  pages        = {476},
  shortjournal = {Proc. IEEE},
  title        = {IEEE women in engineering},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Electrostatic telegraphy—1753–1816 [scanning our past].
<em>PIEEE</em>, <em>108</em>(3), 465–473. (<a
href="https://doi.org/10.1109/JPROC.2020.2975521">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {After being rubbed against cotton or wool, amber acquires a static electric charge and attracts lightweight objects such as pieces of dried grass or dried leaves (Fig. 1). Amber has been prized for its beauty since antiquity; it was gathered at the shores of the Baltic Sea as far back as 10 000 BC [1]. The word electric has its origin in ηλεκτρo (ilektro), a Greek word for amber. It has been widely asserted that Thales of Miletus was the first to notice that amber attracts some types of light objects. Thales, who is believed to have lived from about 640-610 BC to about 548-545 BC, left nothing in writing and his alleged existence was first announced by Diogenes Laërtius about nine centuries after Thales&#39;s era [2]. Amber jewelry and ornaments existed long before Thales&#39;s period [3], [4]. It is likely that people who handled amber, not philosophers, first observed that leaves, straws, and other objects cling to amber.},
  archive      = {J_PIEEE},
  author       = {Adam Allerhand},
  doi          = {10.1109/JPROC.2020.2975521},
  journal      = {Proceedings of the IEEE},
  number       = {3},
  pages        = {465-473},
  shortjournal = {Proc. IEEE},
  title        = {Electrostatic telegraphy—1753–1816 [Scanning our past]},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Combinatorial optimization of graphical user interface
designs. <em>PIEEE</em>, <em>108</em>(3), 434–464. (<a
href="https://doi.org/10.1109/JPROC.2020.2969687">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The graphical user interface (GUI) has become the prime means for interacting with computing systems. It leverages human perceptual and motor capabilities for elementary tasks such as command exploration and invocation, information search, and multitasking. For designing a GUI, numerous interconnected decisions must be made such that the outcome strikes a balance between human factors and technical objectives. Normally, design choices are specified manually and coded within the software by professional designers and developers. This article surveys combinatorial optimization as a flexible and powerful tool for computational generation and adaptation of GUIs. As recently as 15 years ago, applications were limited to keyboards and widget layouts. The obstacle has been the mathematical definition of design tasks, on the one hand, and the lack of objective functions that capture essential aspects of human behavior, on the other. This article presents definitions of layout design problems as integer programming tasks, a coherent formalism that permits identification of problem types, analysis of their complexity, and exploitation of known algorithmic solutions. It then surveys advances in formulating evaluative functions for common design-goal foci such as user performance and experience. The convergence of these two advances has expanded the range of solvable problems. Approaches to practical deployment are outlined with a wide spectrum of applications. This article concludes by discussing the position of this application area within optimization and human-computer interaction research and outlines challenges for future work.},
  archive      = {J_PIEEE},
  author       = {Antti Oulasvirta and Niraj Ramesh Dayama and Morteza Shiripour and Maximilian John and Andreas Karrenbauer},
  doi          = {10.1109/JPROC.2020.2969687},
  journal      = {Proceedings of the IEEE},
  number       = {3},
  pages        = {434-464},
  shortjournal = {Proc. IEEE},
  title        = {Combinatorial optimization of graphical user interface designs},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adversarial learning targeting deep neural network
classification: A comprehensive review of defenses against attacks.
<em>PIEEE</em>, <em>108</em>(3), 402–433. (<a
href="https://doi.org/10.1109/JPROC.2020.2970615">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With wide deployment of machine learning (ML)-based systems for a variety of applications including medical, military, automotive, genomic, multimedia, and social networking, there is great potential for damage from adversarial learning (AL) attacks. In this article, we provide a contemporary survey of AL, focused particularly on defenses against attacks on deep neural network classifiers. After introducing relevant terminology and the goals and range of possible knowledge of both attackers and defenders, we survey recent work on test-time evasion (TTE), data poisoning (DP), backdoor DP, and reverse engineering (RE) attacks and particularly defenses against the same. In so doing, we distinguish robust classification from anomaly detection (AD), unsupervised from supervised, and statistical hypothesis-based defenses from ones that do not have an explicit null (no attack) hypothesis. We also consider several scenarios for detecting backdoors. We provide a technical assessment for reviewed works, including identifying any issues/limitations, required hyperparameters, needed computational complexity, as well as the performance measures evaluated and the obtained quality. We then delve deeper, providing novel insights that challenge conventional AL wisdom and that target unresolved issues, including: robust classification versus AD as a defense strategy; the belief that attack success increases with attack strength, which ignores susceptibility to AD; small perturbations for TTE attacks: a fallacy or a requirement; validity of the universal assumption that a TTE attacker knows the ground-truth class for the example to be attacked; black, gray, or white-box attacks as the standard for defense evaluation; and susceptibility of query-based RE to an AD defense. We also discuss attacks on the privacy of training data. We then present benchmark comparisons of several defenses against TTE, RE, and backdoor DP attacks on images. The article concludes with a discussion of continuing research directions, including the supreme challenge of detecting attacks whose goal is not to alter classification decisions, but rather simply to embed, without detection, “fake news” or other false content.},
  archive      = {J_PIEEE},
  author       = {David J. Miller and Zhen Xiang and George Kesidis},
  doi          = {10.1109/JPROC.2020.2970615},
  journal      = {Proceedings of the IEEE},
  number       = {3},
  pages        = {402-433},
  shortjournal = {Proc. IEEE},
  title        = {Adversarial learning targeting deep neural network classification: A comprehensive review of defenses against attacks},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Scanning the issue. <em>PIEEE</em>, <em>108</em>(3),
400–401. (<a href="https://doi.org/10.1109/JPROC.2020.2975522">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computing systems have been facing severe technology challenges in recent years with regard to power consumption, circuit reliability, and high performance. For many years, the issues of power consumption and performance have been addressed with the use of technology scaling.However, as Dennard’s scaling tends toward an end, it has become difficult to further improve the performance under the same power constraints. In addition to power, reliability also becomes a critical issue when the feature size of the complementary metal-oxide–semiconductor (CMOS) technology is reduced below 7 nm. Thus, ensuring the complete accuracy of the signal has become increasingly challenging in recent years.},
  archive      = {J_PIEEE},
  author       = {W. Liu and F. Lombardi and M. Shulte and D. J. Miller and Z. Xiang and G. Kesidis and A. Oulasvirta and N. R. Dayama and M. Shiripour and M. John and A. Karrenbauer and A. Allerhand},
  doi          = {10.1109/JPROC.2020.2975522},
  journal      = {Proceedings of the IEEE},
  number       = {3},
  pages        = {400-401},
  shortjournal = {Proc. IEEE},
  title        = {Scanning the issue},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A retrospective and prospective view of approximate
computing [point of view]. <em>PIEEE</em>, <em>108</em>(3), 394–399. (<a
href="https://doi.org/10.1109/JPROC.2020.2975695">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computing systems are conventionally designed to operate as accurately as possible. However, this trend faces severe technology challenges, such as power consumption, circuit reliability, and high performance. For nearly half a century, performance and power consumption of computing systems have been consistently improved by relying mostly on technology scaling. As per Dennard&#39;s scaling, the size of a transistor has been considerably shrunk and the supply voltage has been reduced over the years, such that circuits operate at higher frequencies but nearly at the same power dissipation level. However, as Dennard&#39;s scaling tends toward an end, it is difficult to further improve performance under the same power constraints. Power consumption has been a major concern, and it is now an industry-wide problem of critical importance. In addition to power, reliability deteriorates when the feature size of complementary metal-oxide-semiconductor (CMOS) technology is reduced below 7 nm, because parameter variations and faults at advanced nanoscales become difficult to control and prevent. Thus, to ensure the complete accuracy of signals, logic values, devices, and interconnects, manufacturing and verification costs will increase significantly.},
  archive      = {J_PIEEE},
  author       = {Weiqiang Liu and Fabrizio Lombardi and Michael Shulte},
  doi          = {10.1109/JPROC.2020.2975695},
  journal      = {Proceedings of the IEEE},
  number       = {3},
  pages        = {394-399},
  shortjournal = {Proc. IEEE},
  title        = {A retrospective and prospective view of approximate computing [Point of view]},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020i). IEEE women in engineering. <em>PIEEE</em>, <em>108</em>(2),
392. (<a href="https://doi.org/10.1109/JPROC.2020.2966560">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advertisement, IEEE Women in Engineering.},
  archive      = {J_PIEEE},
  doi          = {10.1109/JPROC.2020.2966560},
  journal      = {Proceedings of the IEEE},
  number       = {2},
  pages        = {392},
  shortjournal = {Proc. IEEE},
  title        = {IEEE women in engineering},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020c). What + if = IEEE. <em>PIEEE</em>, <em>108</em>(2), 391. (<a
href="https://doi.org/10.1109/JPROC.2020.2966562">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advertisement, IEEE. 420,000+ members in 160 countries. Embrace the largest, global, technical community. People Driving Technological Innovation.},
  archive      = {J_PIEEE},
  doi          = {10.1109/JPROC.2020.2966562},
  journal      = {Proceedings of the IEEE},
  number       = {2},
  pages        = {391},
  shortjournal = {Proc. IEEE},
  title        = {What + if = IEEE},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). 5G vehicle-to-everything services: Gearing up for security
and privacy. <em>PIEEE</em>, <em>108</em>(2), 373–389. (<a
href="https://doi.org/10.1109/JPROC.2019.2948302">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {5G is emerging to serve as a platform to support networking connections for sensors and vehicles on roads and provide vehicle-to-everything (V2X) services to drivers and pedestrians. 5G V2X communication brings tremendous benefits to us, including improved safety, high reliability, large communication coverage, and low service latency. On the other hand, due to ubiquitous network connectivity, it also presents serious trust, security, and privacy issues toward vehicles, which may impede the success of 5G V2X. In this article, we present a comprehensive survey on the security of 5G V2X services. Specifically, we first review the architecture and the use cases of 5G V2X. We also study a series of trust, security, and privacy issues in 5G V2X services and discuss the potential attacks on trust, security, and privacy in 5G V2X. Then, we offer an in-depth analysis of the state-of-the-art strategies for securing 5G V2X services and elaborate on how to achieve the trust, security, or privacy protection in each strategy. Finally, by pointing out several future research directions, it is expected to draw more attention and efforts into the emerging 5G V2X services.},
  archive      = {J_PIEEE},
  author       = {Rongxing Lu and Lan Zhang and Jianbing Ni and Yuguang Fang},
  doi          = {10.1109/JPROC.2019.2948302},
  journal      = {Proceedings of the IEEE},
  number       = {2},
  pages        = {373-389},
  shortjournal = {Proc. IEEE},
  title        = {5G vehicle-to-everything services: Gearing up for security and privacy},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The security of autonomous driving: Threats, defenses, and
future directions. <em>PIEEE</em>, <em>108</em>(2), 357–372. (<a
href="https://doi.org/10.1109/JPROC.2019.2948775">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous vehicles (AVs) have promised to drastically improve the convenience of driving by releasing the burden of drivers and reducing traffic accidents with more precise control. With the fast development of artificial intelligence and significant advancements of the Internet of Things technologies, we have witnessed the steady progress of autonomous driving over the recent years. As promising as it is, the march of autonomous driving technologies also faces new challenges, among which security is the top concern. In this article, we give a systematic study on the security threats surrounding autonomous driving, from the angles of perception, navigation, and control. In addition to the in-depth overview of these threats, we also summarize the corresponding defense strategies. Furthermore, we discuss future research directions about the new security threats, especially those related to deep-learning-based self-driving vehicles. By providing the security guidelines at this early stage, we aim to promote new techniques and designs related to AVs from both academia and industry and boost the development of secure autonomous driving.},
  archive      = {J_PIEEE},
  author       = {Kui Ren and Qian Wang and Cong Wang and Zhan Qin and Xiaodong Lin},
  doi          = {10.1109/JPROC.2019.2948775},
  journal      = {Proceedings of the IEEE},
  number       = {2},
  pages        = {357-372},
  shortjournal = {Proc. IEEE},
  title        = {The security of autonomous driving: Threats, defenses, and future directions},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep-learning-based wireless resource allocation with
application to vehicular networks. <em>PIEEE</em>, <em>108</em>(2),
341–356. (<a href="https://doi.org/10.1109/JPROC.2019.2957798">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It has been a long-held belief that judicious resource allocation is critical to mitigating interference, improving network efficiency, and ultimately optimizing wireless communication performance. The traditional wisdom is to explicitly formulate resource allocation as an optimization problem and then exploit mathematical programming to solve the problem to a certain level of optimality. Nonetheless, as wireless networks become increasingly diverse and complex, for example, in the high-mobility vehicular networks, the current design methodologies face significant challenges and thus call for rethinking of the traditional design philosophy. Meanwhile, deep learning, with many success stories in various disciplines, represents a promising alternative due to its remarkable power to leverage data for problem solving. In this article, we discuss the key motivations and roadblocks of using deep learning for wireless resource allocation with application to vehicular networks. We review major recent studies that mobilize the deep-learning philosophy in wireless resource allocation and achieve impressive results. We first discuss deep-learning-assisted optimization for resource allocation. We then highlight the deep reinforcement learning approach to address resource allocation problems that are difficult to handle in the traditional optimization framework. We also identify some research directions that deserve further investigation.},
  archive      = {J_PIEEE},
  author       = {Le Liang and Hao Ye and Guanding Yu and Geoffrey Ye Li},
  doi          = {10.1109/JPROC.2019.2957798},
  journal      = {Proceedings of the IEEE},
  number       = {2},
  pages        = {341-356},
  shortjournal = {Proc. IEEE},
  title        = {Deep-learning-based wireless resource allocation with application to vehicular networks},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Toward reliable and scalable internet of vehicles:
Performance analysis and resource management. <em>PIEEE</em>,
<em>108</em>(2), 324–340. (<a
href="https://doi.org/10.1109/JPROC.2019.2950349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reliable and scalable wireless transmissions for Internet of Vehicles (IoV) are technically challenging. Each vehicle, from driver-assisted to automated one, will generate a flood of information, up to thousands of times of that by a person. Vehicle density may change drastically over time and location. Emergency messages and real-time cooperative control messages have stringent delay constraints while infotainment applications may tolerate a certain degree of latency. On a congested road, thousands of vehicles need to exchange information badly, only to find that service is limited due to the scarcity of wireless spectrum. Considering the service requirements of heterogeneous IoV applications, service guarantee relies on an in-depth understanding of network performance and innovations in wireless resource management leveraging the mobility of vehicles, which are addressed in this article. For single-hop transmissions, we study and compare the performance of vehicle-to-vehicle (V2V) beacon broadcasting using random access-based (IEEE 802.11p) and resource allocation-based (cellular vehicle-to-everything) protocols, and the enhancement strategies using distributed congestion control. For messages propagated in IoV using multihop V2V relay transmissions, the fundamental network connectivity property of 1-D and 2-D roads is given. To have a message delivered farther away in a sparse, disconnected V2V network, vehicles can carry and forward the message, with the help of infrastructure if possible. The optimal locations to deploy different types of roadside infrastructures, including storage-only devices and roadside units with Internet connections, are analyzed.},
  archive      = {J_PIEEE},
  author       = {Yuanzhi Ni and Lin Cai and Jianping He and Alexey Vinel and Yue Li and Hamed Mosavat-Jahromi and Jianping Pan},
  doi          = {10.1109/JPROC.2019.2950349},
  journal      = {Proceedings of the IEEE},
  number       = {2},
  pages        = {324-340},
  shortjournal = {Proc. IEEE},
  title        = {Toward reliable and scalable internet of vehicles: Performance analysis and resource management},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evolutionary V2X technologies toward the internet of
vehicles: Challenges and opportunities. <em>PIEEE</em>, <em>108</em>(2),
308–323. (<a href="https://doi.org/10.1109/JPROC.2019.2961937">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To enable large-scale and ubiquitous automotive network access, traditional vehicle-to-everything (V2X) technologies are evolving to the Internet of Vehicles (IoV) for increasing demands on emerging advanced vehicular applications, such as intelligent transportation systems (ITS) and autonomous vehicles. In recent years, IoV technologies have been developed and achieved significant progress. However, it is still unclear what is the evolution path and what are the challenges and opportunities brought by IoV. For the aforementioned considerations, this article provides a thorough survey on the historical process and status quo of V2X technologies, as well as demonstration of emerging technology developing directions toward IoV. We first review the early stage when the dedicated short-range communications (DSRC) was issued as an important initial beginning and compared the cellular V2X with IEEE 802.11 V2X communications in terms of both the pros and cons. In addition, considering the advent of big data and cloud-edge regime, we highlight the key technical challenges and pinpoint the opportunities toward the big data-driven IoV and cloud-based IoV, respectively. We believe our comprehensive survey on evolutionary V2X technologies toward IoV can provide beneficial insights and inspirations for both academia and the IoV industry.},
  archive      = {J_PIEEE},
  author       = {Haibo Zhou and Wenchao Xu and Jiacheng Chen and Wei Wang},
  doi          = {10.1109/JPROC.2019.2961937},
  journal      = {Proceedings of the IEEE},
  number       = {2},
  pages        = {308-323},
  shortjournal = {Proc. IEEE},
  title        = {Evolutionary V2X technologies toward the internet of vehicles: Challenges and opportunities},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Future intelligent and secure vehicular network toward 6G:
Machine-learning approaches. <em>PIEEE</em>, <em>108</em>(2), 292–307.
(<a href="https://doi.org/10.1109/JPROC.2019.2954595">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a powerful tool, the vehicular network has been built to connect human communication and transportation around the world for many years to come. However, with the rapid growth of vehicles, the vehicular network becomes heterogeneous, dynamic, and large scaled, which makes it difficult to meet the strict requirements, such as ultralow latency, high reliability, high security, and massive connections of the next-generation (6G) network. Recently, machine learning (ML) has emerged as a powerful artificial intelligence (AI) technique to make both the vehicle and wireless communication highly efficient and adaptable. Naturally, employing ML into vehicular communication and network becomes a hot topic and is being widely studied in both academia and industry, paving the way for the future intelligentization in 6G vehicular networks. In this article, we provide a survey on various ML techniques applied to communication, networking, and security parts in vehicular networks and envision the ways of enabling AI toward a future 6G vehicular network, including the evolution of intelligent radio (IR), network intelligentization, and self-learning with proactive exploration.},
  archive      = {J_PIEEE},
  author       = {Fengxiao Tang and Yuichi Kawamoto and Nei Kato and Jiajia Liu},
  doi          = {10.1109/JPROC.2019.2954595},
  journal      = {Proceedings of the IEEE},
  number       = {2},
  pages        = {292-307},
  shortjournal = {Proc. IEEE},
  title        = {Future intelligent and secure vehicular network toward 6G: Machine-learning approaches},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). SDN/NFV-empowered future IoV with enhanced communication,
computing, and caching. <em>PIEEE</em>, <em>108</em>(2), 274–291. (<a
href="https://doi.org/10.1109/JPROC.2019.2951169">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet-of-Vehicles (IoV) connects vehicles, sensors, pedestrians, mobile devices, and the Internet with advanced communication and networking technologies, which can enhance road safety, improve road traffic management, and support immerse user experience. However, the increasing number of vehicles and other IoV devices, high vehicle mobility, and diverse service requirements render the operation and management of IoV intractable. Software-defined networking (SDN) and network function virtualization (NFV) technologies offer potential solutions to achieve flexible and automated network management, global network optimization, and efficient network resource orchestration with cost-effectiveness and are envisioned as a key enabler to future IoV. In this article, we provide an overview of SDN/NFV-enabled IoV, in which SDN/NFV technologies are leveraged to enhance the performance of IoV and enable diverse IoV scenarios and applications. In particular, the IoV and SDN/NFV technologies are first introduced. Then, the state-of-the-art research works are surveyed comprehensively, which is categorized into topics according to the role that the SDN/NFV technologies play in IoV, i.e., enhancing the performance of data communication, computing, and caching, respectively. Some open research issues are discussed for future directions.},
  archive      = {J_PIEEE},
  author       = {Weihua Zhuang and Qiang Ye and Feng Lyu and Nan Cheng and Ju Ren},
  doi          = {10.1109/JPROC.2019.2951169},
  journal      = {Proceedings of the IEEE},
  number       = {2},
  pages        = {274-291},
  shortjournal = {Proc. IEEE},
  title        = {SDN/NFV-empowered future IoV with enhanced communication, computing, and caching},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Learning driving models from parallel end-to-end driving
data set. <em>PIEEE</em>, <em>108</em>(2), 262–273. (<a
href="https://doi.org/10.1109/JPROC.2019.2952735">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parallel end-to-end driving aims to improve the performance of end-to-end driving models using both simulated- and real-world data. However, how to efficiently utilize the data from both the simulated world and the real world remains a difficult issue, since these data are usually not well aligned. In this article, we build a data set called the parallel end-to-end driving data set (PED) for parallel end-to-end driving research. PED consists of 13 000 images from the simulated world and 13 000 images from the real world that are used to train the model, as well as 2700 images from the real world that are used to test the model. The simulated-world data in PED are constructed according to the real world, and each simulated-world image corresponds to a real-world image. PED also contains the vehicle measurement data (GPS, speed, steering angle, and heading direction of the vehicle) related to both the simulated- and real-world images, which are not available in some other data sets. We conduct two types of experiments to illustrate the effectiveness and the superiority of PED and explore some ways to mix the simulated-world data with the real-world data to improve the performance of end-to-end driving models.},
  archive      = {J_PIEEE},
  author       = {Long Chen and Qing Wang and Xiankai Lu and Dongpu Cao and Fei-Yue Wang},
  doi          = {10.1109/JPROC.2019.2952735},
  journal      = {Proceedings of the IEEE},
  number       = {2},
  pages        = {262-273},
  shortjournal = {Proc. IEEE},
  title        = {Learning driving models from parallel end-to-end driving data set},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mobile edge intelligence and computing for the internet of
vehicles. <em>PIEEE</em>, <em>108</em>(2), 246–261. (<a
href="https://doi.org/10.1109/JPROC.2019.2947490">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Vehicles (IoV) is an emerging paradigm that is driven by recent advancements in vehicular communications and networking. Meanwhile, the capability and intelligence of vehicles are being rapidly enhanced, and this will have the potential of supporting a plethora of new exciting applications that will integrate fully autonomous vehicles, the Internet of Things (IoT), and the environment. These trends will bring about an era of intelligent IoV, which will heavily depend on communications, computing, and data analytics technologies. To store and process the massive amount of data generated by intelligent IoV, onboard processing and cloud computing will not be sufficient due to resource/power constraints and communication overhead/latency, respectively. By deploying storage and computing resources at the wireless network edge, e.g., radio access points, the edge information system (EIS), including edge caching, edge computing, and edge AI, will play a key role in the future intelligent IoV. EIS will provide not only low-latency content delivery and computation services but also localized data acquisition, aggregation, and processing. This article surveys the latest development in EIS for intelligent IoV. Key design issues, methodologies, and hardware platforms are introduced. In particular, typical use cases for intelligent vehicles are illustrated, including edge-assisted perception, mapping, and localization. In addition, various open-research problems are identified.},
  archive      = {J_PIEEE},
  author       = {Jun Zhang and Khaled B. Letaief},
  doi          = {10.1109/JPROC.2019.2947490},
  journal      = {Proceedings of the IEEE},
  number       = {2},
  pages        = {246-261},
  shortjournal = {Proc. IEEE},
  title        = {Mobile edge intelligence and computing for the internet of vehicles},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Internet of vehicles [scanning the issue]. <em>PIEEE</em>,
<em>108</em>(2), 242–245. (<a
href="https://doi.org/10.1109/JPROC.2020.2964107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicular communication networks have emerged to enable numerous vehicular data services and applications. Conventional vehicular ad hoc networks (VANETs) are often operated in the ad hoc mode and mainly focus on road safety applications based on the connection between vehicles and roadside units (RSUs). To support vehicular communications, dedicated shortrange communication (DSRC) and car-to-car communication consortium (C2C-CC) have been initiated in the United States and Europe, respectively. With the new era of the Internet of Things (IoT), the conventional VANETs have evolved to the Internet of Vehicles (IoV). In IoV, each vehicle is envisioned as an intelligent object, equipped with sensing platforms, computing facilities, control units, and storages and is connected to any entity (other vehicles, RSUs, charging/gas stations, cloud, and so on) via vehicle-to-everything (V2X) communications. Intelligent vehicles can take different roles, i.e., being both a client and a server, taking and providing big data services, leading to numerous new IoV applications, from assisted/autonomous driving and platooning, secure information sharing and learning to traffic control and optimization.},
  archive      = {J_PIEEE},
  author       = {Xuemin Shen and Romano Fantacci and Shanzhi Chen},
  doi          = {10.1109/JPROC.2020.2964107},
  journal      = {Proceedings of the IEEE},
  number       = {2},
  pages        = {242-245},
  shortjournal = {Proc. IEEE},
  title        = {Internet of vehicles [Scanning the issue]},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sustainable and resilient distribution systems with
networked microgrids [point of view]. <em>PIEEE</em>, <em>108</em>(2),
238–241. (<a href="https://doi.org/10.1109/JPROC.2019.2963605">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grid modernization calls for increasing requirements of electric grid operation with enhanced sustainability and resilience [1]. In particular, distribution grids serve as a critical venue to bridge bulk upstream transmission and generation systems and a large number of downstream end users on the customer side, playing a significant role in modern electric grids for multiple purposes (e.g., renewable energy integration, power flow distribution, and end-user power quality enhancement) [2]. Under a normal grid operation condition, the increasing penetration level of renewable energy sources imposes new challenges on conventional distribution grid infrastructure (e.g., protection malfunction [3] and voltage violation [4]); on the other hand, in an extreme grid operation scenario, it is urgently needed to restore grid services after severe power outages, such as those caused by natural disasters [5]. In particular, for critical infrastructures, an efficient grid service restoration strategy should be implemented to avoid further damage over an extended period of time.},
  archive      = {J_PIEEE},
  author       = {Jianhui Wang and Xiaonan Lu},
  doi          = {10.1109/JPROC.2019.2963605},
  journal      = {Proceedings of the IEEE},
  number       = {2},
  pages        = {238-241},
  shortjournal = {Proc. IEEE},
  title        = {Sustainable and resilient distribution systems with networked microgrids [Point of view]},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A grid of microgrids: Is it the right answer? [Point of
view]. <em>PIEEE</em>, <em>108</em>(2), 231–237. (<a
href="https://doi.org/10.1109/JPROC.2019.2963604">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid and worldwide rise in distributed generation capacity, especially photovoltaic, has raised the issue on whether the development and operation of large interconnected systems on a national or continental level will vanish. The usual question is: will the large electric energy systems of today, planned and operated in either a centralized or decentralized way, be replaced by various independent smart-city systems, all with self-healing and other eye-catching characteristics, forming “a grid of microgrids?”},
  archive      = {J_PIEEE},
  author       = {Nelson Martins and Andre Luiz Diniz and João G. C. Barros},
  doi          = {10.1109/JPROC.2019.2963604},
  journal      = {Proceedings of the IEEE},
  number       = {2},
  pages        = {231-237},
  shortjournal = {Proc. IEEE},
  title        = {A grid of microgrids: Is it the right answer? [Point of view]},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). [Back cover]. <em>PIEEE</em>, <em>108</em>(1), C4. (<a
href="https://doi.org/10.1109/JPROC.2019.2950757">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advertisement, IEEE.},
  archive      = {J_PIEEE},
  doi          = {10.1109/JPROC.2019.2950757},
  journal      = {Proceedings of the IEEE},
  number       = {1},
  pages        = {C4},
  shortjournal = {Proc. IEEE},
  title        = {[Back cover]},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Introducing IEEE collabratec. <em>PIEEE</em>,
<em>108</em>(1), C3. (<a
href="https://doi.org/10.1109/JPROC.2019.2950755">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advertisement, IEEE.},
  archive      = {J_PIEEE},
  doi          = {10.1109/JPROC.2019.2950755},
  journal      = {Proceedings of the IEEE},
  number       = {1},
  pages        = {C3},
  shortjournal = {Proc. IEEE},
  title        = {Introducing IEEE collabratec},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). The earliest years of three-phase power—1891–1893 [scanning
our past]. <em>PIEEE</em>, <em>108</em>(1), 215–227. (<a
href="https://doi.org/10.1109/JPROC.2019.2955618">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article is about the earliest innovations in polyphase power, with an emphasis on three phases. Inventions are presented when necessary to describe products, which is why the inventions of Michael von Dolivo–Dobrowolsky, Friedrich August Haselwander, Nikola Tesla, and Jonas Wenström make an appearance while those of Galileo Ferraris and Charles S. Bradley do not.},
  archive      = {J_PIEEE},
  author       = {Adam Allerhand},
  doi          = {10.1109/JPROC.2019.2955618},
  journal      = {Proceedings of the IEEE},
  number       = {1},
  pages        = {215-227},
  shortjournal = {Proc. IEEE},
  title        = {The earliest years of three-phase power—1891–1893 [Scanning our past]},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). CAI4CAI: The rise of contextual artificial intelligence in
computer-assisted interventions. <em>PIEEE</em>, <em>108</em>(1),
198–214. (<a href="https://doi.org/10.1109/JPROC.2019.2946993">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven computational approaches have evolved to enable extraction of information from medical images with reliability, accuracy, and speed, which is already transforming their interpretation and exploitation in clinical practice. While similar benefits are longed for in the field of interventional imaging, this ambition is challenged by a much higher heterogeneity. Clinical workflows within interventional suites and operating theaters are extremely complex and typically rely on poorly integrated intraoperative devices, sensors, and support infrastructures. Taking stock of some of the most exciting developments in machine learning and artificial intelligence for computer-assisted interventions, we highlight the crucial need to take the context and human factors into account in order to address these challenges. Contextual artificial intelligence for computer-assisted intervention (CAI4CAI) arises as an emerging opportunity feeding into the broader field of surgical data science. Central challenges being addressed in CAI4CAI include how to integrate the ensemble of prior knowledge and instantaneous sensory information from experts, sensors, and actuators; how to create and communicate a faithful and actionable shared representation of the surgery among a mixed human-AI actor team; and how to design interventional systems and associated cognitive shared control schemes for online uncertainty-aware collaborative decision-making ultimately producing more precise and reliable interventions.},
  archive      = {J_PIEEE},
  author       = {Tom Vercauteren and Mathias Unberath and Nicolas Padoy and Nassir Navab},
  doi          = {10.1109/JPROC.2019.2946993},
  journal      = {Proceedings of the IEEE},
  number       = {1},
  pages        = {198-214},
  shortjournal = {Proc. IEEE},
  title        = {CAI4CAI: The rise of contextual artificial intelligence in computer-assisted interventions},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Wireless capsule endoscopy: A new tool for cancer screening
in the colon with deep-learning-based polyp recognition. <em>PIEEE</em>,
<em>108</em>(1), 178–197. (<a
href="https://doi.org/10.1109/JPROC.2019.2950506">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate recognition of polyps is crucial for early colorectal cancer diagnosis and treatment. Wireless capsule endoscopy (WCE) is a noninvasive, wireless imaging tool that allows direct visualization of the entire colon without discomfort to patients and has the potential to revolutionize the screening workup for colorectal diseases. However, current manual review is laborious and time consuming, requiring the undivided concentration of the gastroenterologist. Computational methods that can assist automated polyp recognition will enhance the outcome both in terms of diagnostic accuracy and efficiency of WCE. This review introduces the computer-assisted algorithms as applied to colorectal polyp screening, focusing on the successes of deep-learning-based strategies in the WCE sequences. We survey key applications of WCE polyp recognition, covering deep-learning-based image-level classification, lesion region detection, and pixel-accurate segmentation. We conclude by discussing emerging research challenges, possible trends, and future directions.},
  archive      = {J_PIEEE},
  author       = {Xiao Jia and Xiaohan Xing and Yixuan Yuan and Lei Xing and Max Q.-H. Meng},
  doi          = {10.1109/JPROC.2019.2950506},
  journal      = {Proceedings of the IEEE},
  number       = {1},
  pages        = {178-197},
  shortjournal = {Proc. IEEE},
  title        = {Wireless capsule endoscopy: A new tool for cancer screening in the colon with deep-learning-based polyp recognition},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Comparison of breast MRI tumor classification using
human-engineered radiomics, transfer learning from deep convolutional
neural networks, and fusion methods. <em>PIEEE</em>, <em>108</em>(1),
163–177. (<a href="https://doi.org/10.1109/JPROC.2019.2950187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital image-based signatures of breast tumors may ultimately contribute to the design of patient-specific breast cancer diagnostics and treatments. Beyond traditional human-engineered computer vision methods, tumor classification methods using transfer learning from deep convolutional neural networks (CNNs) are actively under development. This article will first discuss our progress in using CNN-based transfer learning to characterize breast tumors for various diagnostic, prognostic, or predictive image-based tasks across multiple imaging modalities, including mammography, digital breast tomosynthesis, ultrasound (US), and magnetic resonance imaging (MRI), compared to both human-engineered feature-based radiomics and fusion classifiers created through combination of such features. Second, a new study is presented that reports on a comprehensive comparison of the classification performances of features derived from human-engineered radiomic features, CNN transfer learning, and fusion classifiers for breast lesions imaged with MRI. These studies demonstrate the utility of transfer learning for computer-aided diagnosis and highlight the synergistic improvement in classification performance using fusion classifiers.},
  archive      = {J_PIEEE},
  author       = {Heather M. Whitney and Hui Li and Yu Ji and Peifang Liu and Maryellen L. Giger},
  doi          = {10.1109/JPROC.2019.2950187},
  journal      = {Proceedings of the IEEE},
  number       = {1},
  pages        = {163-177},
  shortjournal = {Proc. IEEE},
  title        = {Comparison of breast MRI tumor classification using human-engineered radiomics, transfer learning from deep convolutional neural networks, and fusion methods},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Brain imaging genomics: Integrated analysis and machine
learning. <em>PIEEE</em>, <em>108</em>(1), 125–162. (<a
href="https://doi.org/10.1109/JPROC.2019.2947272">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain imaging genomics is an emerging data science field, where integrated analysis of brain imaging and genomics data, often combined with other biomarker, clinical, and environmental data, is performed to gain new insights into the phenotypic, genetic, and molecular characteristics of the brain as well as their impact on normal and disordered brain function and behavior. It has enormous potential to contribute significantly to biomedical discoveries in brain science. Given the increasingly important role of statistical and machine learning in biomedicine and rapidly growing literature in brain imaging genomics, we provide an up-to-date and comprehensive review of statistical and machine learning methods for brain imaging genomics, as well as a practical discussion on method selection for various biomedical applications.},
  archive      = {J_PIEEE},
  author       = {Li Shen and Paul M. Thompson},
  doi          = {10.1109/JPROC.2019.2947272},
  journal      = {Proceedings of the IEEE},
  number       = {1},
  pages        = {125-162},
  shortjournal = {Proc. IEEE},
  title        = {Brain imaging genomics: Integrated analysis and machine learning},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Model-based and data-driven strategies in medical image
computing. <em>PIEEE</em>, <em>108</em>(1), 110–124. (<a
href="https://doi.org/10.1109/JPROC.2019.2943836">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model-based approaches for image reconstruction, analysis, and interpretation have made significant progress over the past decades. Many of these approaches are based on either mathematical, physical, or biological models. A challenge for these approaches is the modeling of the underlying processes (e.g., the physics of image acquisition or the patho-physiology of a disease) with appropriate levels of detail and realism. With the availability of large amounts of imaging data and machine learning (in particular deep learning) techniques, data-driven approaches have become more widespread for use in different tasks in reconstruction, analysis, and interpretation. These approaches learn statistical models directly from labeled or unlabeled image data and have been shown to be very powerful for extracting clinically useful information from medical imaging. While these data-driven approaches often outperform traditional model-based approaches, their clinical deployment often poses challenges in terms of robustness, generalization ability, and interpretability. In this article, we discuss what developments have motivated the shift from model-based approaches toward data-driven strategies and what potential problems are associated with the move toward purely data-driven approaches, in particular deep learning. We also discuss some of the open challenges for data-driven approaches, e.g., generalization to new unseen data (e.g., transfer learning), robustness to adversarial attacks, and interpretability. Finally, we conclude with a discussion on how these approaches may lead to the development of more closely coupled imaging pipelines that are optimized in an end-to-end fashion.},
  archive      = {J_PIEEE},
  author       = {Daniel Rueckert and Julia A. Schnabel},
  doi          = {10.1109/JPROC.2019.2943836},
  journal      = {Proceedings of the IEEE},
  number       = {1},
  pages        = {110-124},
  shortjournal = {Proc. IEEE},
  title        = {Model-based and data-driven strategies in medical image computing},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Image reconstruction: From sparsity to data-adaptive methods
and machine learning. <em>PIEEE</em>, <em>108</em>(1), 86–109. (<a
href="https://doi.org/10.1109/JPROC.2019.2936204">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of medical image reconstruction has seen roughly four types of methods. The first type tended to be analytical methods, such as filtered backprojection (FBP) for X-ray computed tomography (CT) and the inverse Fourier transform for magnetic resonance imaging (MRI), based on simple mathematical models for the imaging systems. These methods are typically fast, but have suboptimal properties such as poor resolution-noise tradeoff for CT. A second type is iterative reconstruction methods based on more complete models for the imaging system physics and, where appropriate, models for the sensor statistics. These iterative methods improved image quality by reducing noise and artifacts. The U.S. Food and Drug Administration (FDA)-approved methods among these have been based on relatively simple regularization models. A third type of methods has been designed to accommodate modified data acquisition methods, such as reduced sampling in MRI and CT to reduce scan time or radiation dose. These methods typically involve mathematical image models involving assumptions such as sparsity or low rank. A fourth type of methods replaces mathematically designed models of signals and systems with data-driven or adaptive models inspired by the field of machine learning. This article focuses on the two most recent trends in medical image reconstruction: methods based on sparsity or low-rank models and data-driven methods based on machine learning techniques.},
  archive      = {J_PIEEE},
  author       = {Saiprasad Ravishankar and Jong Chul Ye and Jeffrey A. Fessler},
  doi          = {10.1109/JPROC.2019.2936204},
  journal      = {Proceedings of the IEEE},
  number       = {1},
  pages        = {86-109},
  shortjournal = {Proc. IEEE},
  title        = {Image reconstruction: From sparsity to data-adaptive methods and machine learning},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Machine learning for rapid magnetic resonance fingerprinting
tissue property quantification. <em>PIEEE</em>, <em>108</em>(1), 69–85.
(<a href="https://doi.org/10.1109/JPROC.2019.2936998">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic resonance fingerprinting (MRF) is a magnetic resonance imaging (MRI)-based method that can provide quantitative maps of multiple tissue properties simultaneously from a single rapid acquisition. Tissue property maps are generated by matching the complex signal evolutions collected at the scanner to a dictionary of signals derived using the Bloch equation simulations. However, in some circumstances, the process of dictionary generation and signal matching can be time-consuming, reducing the utility of this technique. Recently, several groups have proposed using machine learning to accelerate the extraction of quantitative maps from the MRF data. This article will provide an overview of current research that combines MRF and machine learning, as well as present original research demonstrating how machine learning can speed up dictionary generation for cardiac MRF (cMRF).},
  archive      = {J_PIEEE},
  author       = {Jesse I. Hamilton and Nicole Seiberlich},
  doi          = {10.1109/JPROC.2019.2936998},
  journal      = {Proceedings of the IEEE},
  number       = {1},
  pages        = {69-85},
  shortjournal = {Proc. IEEE},
  title        = {Machine learning for rapid magnetic resonance fingerprinting tissue property quantification},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Machine learning in PET: From photon detection to
quantitative image reconstruction. <em>PIEEE</em>, <em>108</em>(1),
51–68. (<a href="https://doi.org/10.1109/JPROC.2019.2936809">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning has found unique applications in nuclear medicine from photon detection to quantitative image reconstruction. Although there have been impressive strides in detector development for time-of-flight positron emission tomography (PET), most detectors still make use of simple signal processing methods to extract the time and position information from the detector signals. Now, with the availability of fast waveform digitizers, machine learning techniques have been applied to estimate the position and arrival time of high-energy photons. In quantitative image reconstruction, machine learning has been used to estimate various corrections factors, including scattered events and attenuation images, as well as to reduce statistical noise in reconstructed images. Here, machine learning either provides a faster alternative to an existing time-consuming computation, such as in the case of scatter estimation, or creates a data-driven approach to map an implicitly defined function, such as in the case of estimating the attenuation map for PET/MR scans. In this article, we will review the above-mentioned applications of machine learning in nuclear medicine.},
  archive      = {J_PIEEE},
  author       = {Kuang Gong and Eric Berg and Simon R. Cherry and Jinyi Qi},
  doi          = {10.1109/JPROC.2019.2936809},
  journal      = {Proceedings of the IEEE},
  number       = {1},
  pages        = {51-68},
  shortjournal = {Proc. IEEE},
  title        = {Machine learning in PET: From photon detection to quantitative image reconstruction},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep-learning-based image reconstruction and enhancement in
optical microscopy. <em>PIEEE</em>, <em>108</em>(1), 30–50. (<a
href="https://doi.org/10.1109/JPROC.2019.2949575">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep learning has been shown to be one of the leading machine learning techniques for a wide variety of inference tasks. In addition to its mainstream applications, such as classification, it has created transformative opportunities for image reconstruction and enhancement in optical microscopy. Some of these emerging applications of deep learning range from image transformations between microscopic imaging systems to adding new capabilities to existing imaging techniques, as well as solving various inverse problems based on microscopy image data. Deep learning is helping us move toward data-driven instrument designs that blend microscopy and computing to achieve what neither can do alone. This article provides an overview of some of the recent work using deep neural networks to advance computational microscopy and sensing systems, also covering their current and future biomedical applications.},
  archive      = {J_PIEEE},
  author       = {Kevin de Haan and Yair Rivenson and Yichen Wu and Aydogan Ozcan},
  doi          = {10.1109/JPROC.2019.2949575},
  journal      = {Proceedings of the IEEE},
  number       = {1},
  pages        = {30-50},
  shortjournal = {Proc. IEEE},
  title        = {Deep-learning-based image reconstruction and enhancement in optical microscopy},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep learning in ultrasound imaging. <em>PIEEE</em>,
<em>108</em>(1), 11–29. (<a
href="https://doi.org/10.1109/JPROC.2019.2932116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we consider deep learning strategies in ultrasound systems, from the front end to advanced applications. Our goal is to provide the reader with a broad understanding of the possible impact of deep learning methodologies on many aspects of ultrasound imaging. In particular, we discuss methods that lie at the interface of signal acquisition and machine learning, exploiting both data structure (e.g., sparsity in some domain) and data dimensionality (big data) already at the raw radio-frequency channel stage. As some examples, we outline efficient and effective deep learning solutions for adaptive beamforming and adaptive spectral Doppler through artificial agents, learn compressive encodings for the color Doppler, and provide a framework for structured signal recovery by learning fast approximations of iterative minimization problems, with applications to clutter suppression and super-resolution ultrasound. These emerging technologies may have a considerable impact on ultrasound imaging, showing promise across key components in the receive processing chain.},
  archive      = {J_PIEEE},
  author       = {Ruud J. G. van Sloun and Regev Cohen and Yonina C. Eldar},
  doi          = {10.1109/JPROC.2019.2932116},
  journal      = {Proceedings of the IEEE},
  number       = {1},
  pages        = {11-29},
  shortjournal = {Proc. IEEE},
  title        = {Deep learning in ultrasound imaging},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Biomedical imaging and analysis in the age of big data and
deep learning [scanning the issue]. <em>PIEEE</em>, <em>108</em>(1),
3–10. (<a href="https://doi.org/10.1109/JPROC.2019.2956422">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imaging of the human body using a number of different modalities has revolutionized the field of medicine over the past several decades and continues to grow at a rapid pace [2] . More than ever, previously unknown information about biology and disease is being unveiled at a range of spatiotemporal scales. Although results and clinical adoption of strategies related to the computational and quantitative analysis of the images have lagged behind development of image acquisition approaches, there has been a noticeable increase of effort and interest in these areas in recent years [6] . This special issue aims to define and highlight some of the “hot” newer ideas that are in biomedical imaging and analysis, intending to shine a light on where the field might move in the next several decades, and focuses on emphasizing where electrical engineers have been involved and could potentially have the most impact. These areas include image acquisition physics, image/signal processing, and image analysis, including pattern recognition and machine learning. This issue focuses on two themes common in much of this effort: first, engineers and computer scientists have found that the information contained in medical images, when viewed through image-based vector spaces, is generally quite sparse. This observation has been transformative in many ways and is quite pervasive in the articles we include here. Second, medical imaging is one of the largest producers of “big data,” and, data-driven machinelearning techniques (e.g., deep learning) are gaining significant attention because improved performance over previous approaches. Thus, data-driven techniques, e.g., formation via image reconstruction [11] and image analysis via deep learning [8] , [9] , are gaining momentum in their development.},
  archive      = {J_PIEEE},
  author       = {James S. Duncan and Michael F. Insana and Nicholas Ayache},
  doi          = {10.1109/JPROC.2019.2956422},
  journal      = {Proceedings of the IEEE},
  number       = {1},
  pages        = {3-10},
  shortjournal = {Proc. IEEE},
  title        = {Biomedical imaging and analysis in the age of big data and deep learning [Scanning the issue]},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
