<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TETC_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tetc---88">TETC - 88</h2>
<ul>
<li><details>
<summary>
(2020). TITAN: Uncovering the paradigm shift in security
vulnerability at near-threshold computing. <em>TETC</em>, <em>8</em>(4),
986–997. (<a href="https://doi.org/10.1109/TETC.2018.2794070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the emerging security threats at Near-Threshold Computing (NTC) that are poised to jeopardize the trustworthy operation of future low-power electronic devices. A substantial research effort over the last decade has bolstered energy efficient operation in low-power computing. However, innovation in low-power security has received only marginal attention, thwarting a ubiquitous adoption of critical Internet of Things applications, such as wearable gadgets. Using a cross-layer methodology, we demonstrate that the timing fault vulnerability of a circuit rapidly increases as the operating conditions of the transistor devices shift from super-threshold to near-threshold values. Exploiting this vulnerability, we propose a novel threat model for NTC, referred to as a Timing Fault Attack atNTC (TITAN). TITAN relies on a malicious application software to induce timing fault attacks in the underlying NTC hardware. We evaluate the efficacy of TITAN using real hardware. Additionally, we propose two security parameters that dictate the fault resilience of a system. Based on those parameters, we show a 1.6× and a 2.8× deterioration in the fault resilience of a low-power operation, over a traditional super-threshold operation. Using a GDB driven analysis, we also present different user-level impacts of TITAN, on some real-life applications.},
  archive      = {J_TETC},
  author       = {Prabal Basu and Pramesh Pandey and Aatreyi Bal and Chidhambaranathan Rajamanikkam and Koushik Chakraborty and Sanghamitra Roy},
  doi          = {10.1109/TETC.2018.2794070},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {986-997},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {TITAN: Uncovering the paradigm shift in security vulnerability at near-threshold computing},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Selecting microarchitecture configuration of processors for
internet of things. <em>TETC</em>, <em>8</em>(4), 973–985. (<a
href="https://doi.org/10.1109/TETC.2018.2817923">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) makes use of ubiquitous internet connectivity to form a network of everyday physical objects for purposes of automation, remote data sensing and centralized management/control. IoT objects need to be embedded with processing capabilities to fulfill these services. The design of processing units for IoT objects is constrained by various stringent requirements, such as performance, power, thermal dissipation etc. In order to meet these diverse requirements, a multitude of processor design parameters need to be tuned accordingly. In this paper, we propose a temporally efficient design space exploration methodology which determines power and performance optimized microarchitecture configurations. We also discuss the possible combinations of these microarchitecture configurations to form an effective two-tiered heterogeneous processor for IoT applications. We evaluate our design space exploration methodology using a cycle-accurate simulator (ESESC) and a standard set of PARSEC and SPLASH2 benchmarks. The results show that our methodology determines microarchitecture configurations which are within 2.23-3.69 percent of the configurations obtained from fully exhaustive exploration while only exploring 3-5 percent of the design space. Our methodology achieves on average 24.16× speedup in design space exploration as compared to fully exhaustive exploration in finding power and performance optimized microarchitecture configurations for processors.},
  archive      = {J_TETC},
  author       = {Prasanna Kansakar and Arslan Munir},
  doi          = {10.1109/TETC.2018.2817923},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {973-985},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Selecting microarchitecture configuration of processors for internet of things},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the difficulty of inserting trojans in reversible
computing architectures. <em>TETC</em>, <em>8</em>(4), 960–972. (<a
href="https://doi.org/10.1109/TETC.2018.2823315">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fabrication-less design houses outsource their designs to third-party foundries to lower fabrication cost. However, this creates opportunities for a rogue in the semiconductor foundry to introduce hardware Trojans, which stay inactive most of the time and cause unintended consequences to the system when triggered. Hardware Trojans in traditional CMOS-based circuits have been studied, and Design-for-Trust (DFT) techniques have been proposed to detect them. Different from traditional circuits in many ways, reversible circuits implement one-to-one input/output mappings. In this paper, we investigate the security implications of reversible circuits with a particular focus on the susceptibility to hardware Trojans. To this end, we consider reversible functions implemented using reversible circuits as well as irreversible functions embedded in reversible circuits.},
  archive      = {J_TETC},
  author       = {Xiaotong Cui and Samah Mohamed Saeed and Alwin Zulehner and Robert Wille and Kaijie Wu and Rolf Drechsler and Ramesh Karri},
  doi          = {10.1109/TETC.2018.2823315},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {960-972},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {On the difficulty of inserting trojans in reversible computing architectures},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new class topper optimization algorithm with an
application to data clustering. <em>TETC</em>, <em>8</em>(4), 948–959.
(<a href="https://doi.org/10.1109/TETC.2018.2812927">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new Class Topper Optimization (CTO) algorithm is proposed. The optimization algorithm is inspired from the learning intelligence of students in a class. The algorithm is population based search algorithm. In this approach, solution is converging towards the best solution. This may lead to a global best solution. To verify the performance of the algorithm, a clustering problem is considered. Five standard data sets are considered for real time validation. The analysis shows that the proposed algorithm performs very well compared to various well known existing heuristic or meta-heuristic optimization algorithms.},
  archive      = {J_TETC},
  author       = {Pranesh Das and Dushmanta Kumar Das and Shouvik Dey},
  doi          = {10.1109/TETC.2018.2812927},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {948-959},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {A new class topper optimization algorithm with an application to data clustering},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Generation of abstract driver models for IP integration
verification. <em>TETC</em>, <em>8</em>(4), 938–947. (<a
href="https://doi.org/10.1109/TETC.2017.2787192">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new application of formal methods in the domain of low-level software (firmware) development of Embedded Systems. The development of low-level device drivers is difficult because of the complex interaction between the device hardware, the driver core routines and the application programmer&#39;s interface (API). Also the development of firmware components using such drivers is difficult because the driver specification may be ambiguous or erroneous or it may be misinterpreted by the developer. In this paper, we propose an abstract FSM model (“AFSM”) to support systematic top-down development of low-level device drivers. The model serves as a formal specification that can be soundly refined into an implementation. The AFSM can also be generated semi-automatically in a bottom-up approach from the binary (machine code) of the driver. This allows for generating a formal documentation of a driver software that may be available as third-party IP for which no source code is available. The generated AFSM can serve as a technical reference during integration of such “black-box” driver IP and when developing firmware components that call the functions of the API. We present three case studies with industrial HW device and SW driver IPs demonstrating the potential of the proposed approach.},
  archive      = {J_TETC},
  author       = {Thomas Fehmel and Dominik Stoffel and Wolfgang Kunz},
  doi          = {10.1109/TETC.2017.2787192},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {938-947},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Generation of abstract driver models for IP integration verification},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Aster: Multi-bit soft error recovery using idempotent
processing. <em>TETC</em>, <em>8</em>(4), 928–937. (<a
href="https://doi.org/10.1109/TETC.2017.2787107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft errors are a major concern in current and future computing systems. They degrade the system reliability significantly. Existing solutions to soft errors either incur unaffordable area and power overheads or fail to provide resilience against multiple-cell-upsets. We present the first low-cost, compiler-based approach Aster to handle multi-bit soft errors. Aster relies on acoustic wave detectors to detect soft errors, and uses idempotent processing and checkpointing to provide a complete solution to multi-bit soft errors. Aster comes into action when a soft error is detected. Based upon the information about the error location, Aster determines the impact of the error on the program correctness. The program continues to execute in case of no impact. Otherwise, it finds an optimal idempotent region which can recover the program from the error completely, and executes the program from the optimal idempotent region. Experimental results show that the time overhead is within 5 percent, approximately 60 percent reduction compared to the state-of-the-art schemes requiring expensive hardware support.},
  archive      = {J_TETC},
  author       = {Kashif Naveed and Hui Wu},
  doi          = {10.1109/TETC.2017.2787107},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {928-937},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Aster: Multi-bit soft error recovery using idempotent processing},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). LibreKV: A persistent in-memory key-value store.
<em>TETC</em>, <em>8</em>(4), 916–927. (<a
href="https://doi.org/10.1109/TETC.2017.2787341">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emerging Non-Volatile Memory (NVM) possesses unique features including byte-addressability and high density which bring huge opportunities to combine DRAM and NVM in a unified main memory space. And key-value store (KVS) systems play an important role in many applications, such as large-scale websites. Several existing KVS have been proposed for NVMs. However, they have drawbacks such as extra write overhead leading, lower memory utilization and worse endurance. In this paper, we design and develop an NVM-based key-value store system named LibreKV. It specifically targets the hybrid DRAM and NVM memory architecture, leveraging the NVM as the eventual persistent storage medium. It uses both static hash table and dynamic hash tables to achieve a balance between system performance and memory utilization. It adopts a checksum based consistency mechanism to guarantee data consistency and persistent storage on NVM. LibreKV works independently without relying on an underlying file system and simplified the IO stack comparing to the traditional KVS system. Experimental results show that LibreKV outperforms the state-of-the-art KVS systems and achieves better scalability and consistency while with low overhead.},
  archive      = {J_TETC},
  author       = {Hao Liu and Linpeng Huang and Yanmin Zhu and Yanyan Shen},
  doi          = {10.1109/TETC.2017.2787341},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {916-927},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {LibreKV: A persistent in-memory key-value store},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Feature-based signal selection for post-silicon debug using
machine learning. <em>TETC</em>, <em>8</em>(4), 907–915. (<a
href="https://doi.org/10.1109/TETC.2017.2787610">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A key challenge of post-silicon validation methodology is to select a limited number of trace signals that are effective during post-silicon debug. Structural analysis used by traditional signal selection techniques are fast but lead to poor restoration quality. In contrast, simulation-based selection techniques provide superior restorability but incur significant computation overhead. While early work on machine learning based signal selection is promising [1] , it is still not applicable on large industrial designs since it needs thousands of simulations of large and complex designs. In this paper, we propose a signal selection technique that addresses the scalability issue of simulation-based techniques while maintaining a high restoration performance. The basic idea is to train a machine learning framework using a small set of circuits, and apply the trained model to the bigger circuit under test, without any need for simulating the large industry-scale designs. This paper makes two fundamental contributions: i) this is the first attempt to show that learning from small related circuits can be useful for signal selection, and ii) this is the first automated signal selection approach that is applicable on industrial designs without sacrificing restoration quality. Experimental results indicate that our approach can improve restorability by up to 135.4 percent (8.8 percent on average) while significantly reduce (up to 37X, 16.6X on average) the runtime compared to existing signal selection approaches.},
  archive      = {J_TETC},
  author       = {Kamran Rahmani and Prabhat Mishra},
  doi          = {10.1109/TETC.2017.2787610},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {907-915},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Feature-based signal selection for post-silicon debug using machine learning},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Nacre**nacre, or mother-of-pearl, is one of nature’s
remarkable examples of a durable and break-resistant structure.:
Durable, secure and energy-efficient non-volatile memory utilizing data
versioning. <em>TETC</em>, <em>8</em>(4), 897–906. (<a
href="https://doi.org/10.1109/TETC.2017.2787622">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As we begin to utilize non-volatile memory (NVM) technologies as main memory elements, new challenges will emerge. While non-volatility is a desirable feature to save energy, it creates security vulnerabilities since data will persistent after system power-off. Data stored in NVMs can be secured using data encryption. However, side effects imposed by memory encryption result in excessive bit writes, which will drastically reduce NVM lifetimes and increase energy consumption. In this paper, we propose Nacre to bridge the gap between fully encrypted and unencrypted NVMs. Nacre exploits standard counter-mode encryption to maintain security. By tracking the different versions of the modified data in each memory writeback, Nacre attempts to limit the number of bit writes. Selective re-encryption is performed based on the history of the modified data in cache lines. We show that on average, Nacre improves memory lifetime by 53 percent (2.87x) as compared to state-of-the-art (full encryption) schemes. In addition, Nacre only increases energy consumption by 6 percent versus an unencrypted memory system.},
  archive      = {J_TETC},
  author       = {Mohammad Khavari Tavana and Yunsi Fei and David Kaeli},
  doi          = {10.1109/TETC.2017.2787622},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {897-906},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Nacre**Nacre, or mother-of-pearl, is one of nature&#39;s remarkable examples of a durable and break-resistant structure.: Durable, secure and energy-efficient non-volatile memory utilizing data versioning},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Joint crosstalk aware burst error fault tolerance mechanism
for reliable on-chip communication. <em>TETC</em>, <em>8</em>(4),
889–896. (<a href="https://doi.org/10.1109/TETC.2017.2787549">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a Nano-scale technology, reliability is one of the main issues for on-chip communication systems. To make communication system more reliable, Joint Crosstalk Aware Multiple Error Correction with interleaving scheme is proposed for crosstalk errors. This technique is very useful while dealing with burst error. The number of burst errors which can be tolerated by this technique can be adjusted by changing the interleaving distance between adjacent bits of the same module. The burst of 9 adjacent errors can be corrected if 4 modules of encoder and decoder are used. The design is implemented on FPGA to calculate area overhead and delay. The proposed JMEC/JMEC-Inter encoder and decoder are both fast, with maximum operating frequencies of 163.308 MHz and 307.977 MHz respectively by trading off by I/O&#39;s pins (48.53 and 19.85 percent more I/O&#39;s than Hamming and JTEC respectively). The area consumed by the proposed technique is less than the 3 percent of the FPGA resources, making the technique good candidate on chip fault tolerance mechanism.},
  archive      = {J_TETC},
  author       = {Madiha Gul and Mohamed Chouikha and Mamadou Wade},
  doi          = {10.1109/TETC.2017.2787549},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {889-896},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Joint crosstalk aware burst error fault tolerance mechanism for reliable on-chip communication},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Guest editors’ introduction: Special issue on emerging
technologies in computer design. <em>TETC</em>, <em>8</em>(4), 887–888.
(<a href="https://doi.org/10.1109/TETC.2020.3031743">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The articles in this special section were presented at the 2017 IEEE International Conference on Computer Design (ICCD).},
  archive      = {J_TETC},
  author       = {Ozgur Sinanoglu and Umit Ogras},
  doi          = {10.1109/TETC.2020.3031743},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {887-888},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Guest editors&#39; introduction: Special issue on emerging technologies in computer design},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Message from the editor-in-chief. <em>TETC</em>,
<em>8</em>(4), 885–886. (<a
href="https://doi.org/10.1109/TETC.2020.3031745">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Presents the introductory editorial for this issue of the publication.},
  archive      = {J_TETC},
  author       = {Cecilia Metra},
  doi          = {10.1109/TETC.2020.3031745},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {885-886},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Message from the editor-in-chief},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust robot tracking for next-generation collaborative
robotics-based gaming environments. <em>TETC</em>, <em>8</em>(3),
869–882. (<a href="https://doi.org/10.1109/TETC.2017.2769705">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The collaboration between humans and robots is one of the most disruptive and challenging research areas. Even considering advances in design and artificial intelligence, humans and robots could soon ally to perform together a number of different tasks. Robots could also became new playmates. In fact, an emerging trend is associated with the so-called phygital gaming, which builds upon the idea of merging the physical world with a virtual one in order to let physical and virtual entities, such as players, robots, animated characters and other game objects interact seamlessly as if they were all part of the same reality. This paper specifically focuses on mixed reality gaming environments that can be created by using floor projection, and tackles the issue of enabling accurate and robust tracking of off-the-shelf robots endowed with limited sensing capabilities. The proposed solution is implemented by fusing visual tracking data gathered via a fixed camera in a smart environment with odometry data obtained from robot&#39;s on-board sensors. The solution has been tested within a phygital gaming platform in a real usage scenario, by experimenting with a robotic game that exhibits many challenging situations which would be hard to manage using conventional tracking techniques.},
  archive      = {J_TETC},
  author       = {Giovanni Piumatti and Fabrizio Lamberti and Andrea Sanna and Paolo Montuschi},
  doi          = {10.1109/TETC.2017.2769705},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {869-882},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Robust robot tracking for next-generation collaborative robotics-based gaming environments},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Quantifying privacy vulnerability to socialbot attacks: An
adaptive non-submodular model. <em>TETC</em>, <em>8</em>(3), 855–868.
(<a href="https://doi.org/10.1109/TETC.2018.2840433">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Privacy breaches are one of the biggest concerns on Online Social Networks (OSNs), especially with an introduction of automated attacks by socialbots, which can automatically extract victims&#39; private content by exploiting social behavior to befriend them. The key insight of this attack is that by intelligently sending friend requests to a small subset of users, called the Critical Friending Set (CFS), such a bot can evade current defense mechanisms. We study the vulnerability of OSNs to socialbot attacks. Specifically, we introduce a new optimization problem, Min-Friending, which identifies a minimum CFS to friend in order to obtain at least Q benefit, which quantifies the amount of private information the bot obtains. The two main challenges of this problem are how to cope with incomplete knowledge of network topology and how to model users&#39; responses to friend requests. In this paper, we show that Min-Friending is inapproximable within a factor of (1-o(1)) ln Q and present an adaptive approximation algorithm using adaptive stochastic optimization. The key feature of our solution lies in the adaptive method, where partial network topology is revealed after each successful friend request. Thus the decision of whom to send a friend request to next is made with the outcomes of past decisions taken into account. Traditional tools break down when attempting to place a bound on the performance of this technique with realistic user models. Therefore, we additionally introduce a novel curvature-based technique to construct an approximation ratio of ln Q for a model of user behavior learned from empirical measurements on Facebook.},
  archive      = {J_TETC},
  author       = {Xiang Li and J. David Smith and Tianyi Pan and Thang N. Dinh and My T. Thai},
  doi          = {10.1109/TETC.2018.2840433},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {855-868},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Quantifying privacy vulnerability to socialbot attacks: An adaptive non-submodular model},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fast networking for disaster recovery. <em>TETC</em>,
<em>8</em>(3), 845–854. (<a
href="https://doi.org/10.1109/TETC.2017.2775798">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Content-Centric Networking (CCN) is now a research hotspot aiming at building up a new network architecture compared with the traditional IP-based, host-centric one. In this paper, after leaning that CCN&#39;s content naming and content-based properties make it suitable for fast network organizing in disaster recovery, we propose methods on access point placement and routing to fast connect users in a middle-scale post-disaster scenario model. Our work includes the design of a placement algorithm using graphic union coverage and a CCN routing strategy based on Breadth-First Searching, both extracting the social attributes of user node distribution. We use real-world maps for simulation and carry out comparative analysis with existing Ad Hoc methods under the same experimental conditions. The simulation results show that CCN can bring more efficient routing and robust framework to fulfill the urgent demands of post-disaster recovery.},
  archive      = {J_TETC},
  author       = {Jianwen Xu and Kaoru Ota and Mianxiong Dong},
  doi          = {10.1109/TETC.2017.2775798},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {845-854},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Fast networking for disaster recovery},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Content-centric group user authentication for secure social
networks. <em>TETC</em>, <em>8</em>(3), 833–844. (<a
href="https://doi.org/10.1109/TETC.2017.2779163">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Content-centric computing systems, which can obtain users&#39; attributes by analyzing information from content, have been widely used in many fields. In social networks, the computing resources of users are restricted. Group authentication schemes are required to ensure the validity of the user and the accuracy of the shared data. In this paper, we propose a content-centric group user authentication scheme to guarantee the security and accuracy of shared data. The proposed group user authentication scheme makes use of the user&#39;s content to generate the user&#39;s feature vector. Furthermore, the group authentication scheme based on the identity of each user can guarantee the network security before data sharing. In addition, regular operations in the network are not affected or damaged by incidents that occur during the authentication process. The security and performance analyses show that our scheme is secure against various attacks and has lower computational cost than the existing schemes.},
  archive      = {J_TETC},
  author       = {Jian Shen and Anxi Wang and Chen Wang and Jiguo Li and Yan Zhang},
  doi          = {10.1109/TETC.2017.2779163},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {833-844},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Content-centric group user authentication for secure social networks},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Classification and mapping of adaptive security for mobile
computing. <em>TETC</em>, <em>8</em>(3), 814–832. (<a
href="https://doi.org/10.1109/TETC.2018.2791459">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Context: Mobile computing has emerged as a disruptive technology that has empowered its users with portable, connected and context-aware computation. However, issues such as resource poverty, energy efficiency and specifically data security and privacy represents the critical challenges for mobile computing. Objective: The objective of this work is to systematically identify, taxonomically classify and map the state-of-research on adaptive security (a.k.a. self-protection) for mobile computing. Methodology: We followed evidence based software engineering method to conduct a systematic mapping study of 43 qualitatively selected studies-published from 2003 to 2017-on adaptive security for mobile computing. Results and Conclusions: Classification and mapping of the research highlights three prominent themes that support adaptive security for (i) Mobile Device Data and Resources, (ii) Mobile to Mobile Communication, and (iii) Mobile to Server Communication. Mapping analysis suggests that security of mobile device data and resources is the most researched theme. The mapping study highlights that active and futuristic research trends are primarily focused on security as a service, whereas; the frequent research challenges relate to self-protecting mobile devices, user-driven privacy decisions and context-aware security. The results of the mapping study facilitate knowledge transfer that can benefit researchers and practitioners to understand the role of adaptive and context-aware security in mobile computing environments.},
  archive      = {J_TETC},
  author       = {Maryam Sajjad and Aakash Ahmad and Asad Waqar Malik and Ahmed B. Altamimi and Ibrahim Alseadoon},
  doi          = {10.1109/TETC.2018.2791459},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {814-832},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Classification and mapping of adaptive security for mobile computing},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Minimizing convergecast time and energy consumption in green
internet of things. <em>TETC</em>, <em>8</em>(3), 797–813. (<a
href="https://doi.org/10.1109/TETC.2018.2844282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time surveillance systems with green wireless sensor networks (WSNs) are vital for maintaining high energy efficiency in many situations. This paper considers a scenario utilizing green WSNs to monitor the situation of Internet of Things (IoT), which constitute one of the most crucial sources of electricity consumption in information and communications technologies (ICT). More specifically, we focus on optimizing the cluster structure to minimize the delay and energy consumption for aggregation convergecast in green WSNs. We first find the optimal value of the network cluster radius for minimizing the delay through theoretical analysis. We then propose a novel cluster network architecture in which clusters that are far from the sink are small, allowing inter-cluster data aggregation to be processed earlier, and clusters that are near the sink are relatively large to allow more time for intra-cluster data aggregation. Hence, the sensor nodes can be scheduled in consecutive time slots to reduce the number of state transitions, consequently achieving the goal of minimizing both delay and energy consumption. Simulation results indicate that the proposed Algorithm outperforms previously reported solutions in terms of both schedule length and lifetime, thereby demonstrating its effectiveness.},
  archive      = {J_TETC},
  author       = {Zhetao Li and Yuxin Liu and Anfeng Liu and Shiguo Wang and Haolin Liu},
  doi          = {10.1109/TETC.2018.2844282},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {797-813},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Minimizing convergecast time and energy consumption in green internet of things},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Green resource allocation based on deep reinforcement
learning in content-centric IoT. <em>TETC</em>, <em>8</em>(3), 781–796.
(<a href="https://doi.org/10.1109/TETC.2018.2805718">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of information, the green services of content-centric IoT are expected to offer users the better satisfaction of Quality of Experience (QoE) than that in a conventional IoT. Nevertheless, the network traffic and new demands from IoT users increase along with the promising of the content-centric computing system. Therefore, the satisfaction of QoE will become the major challenge in the content-centric computing system for IoT users. In this article, to enhance the satisfaction of QoE, we propose QoE models to evaluate the qualities of the IoT concerning both network and users. The value of QoE does not only refer to the network cost, but also the Mean Opinion Score (MOS) of users. Therefore, our models could capture the influence factors from network cost and services for IoT users based on IoT conditions. Specially, we mainly focus on the issues of cache allocation and transmission rate. Under this content-centric IoT, aiming to allocate the cache capacity among content-centric computing nodes and handle the transmission rates under a constrained total network cost and MOS for the whole IoT, we devote our efforts to the following two aspects. First, we formulate the QoE as a green resource allocation problem under the different transmission rate to acquire the best QoE. Then, in the basis of the node centrality, we will propose a suboptimal dynamic approach, which is suitable for IoT with content delivery frequently. Furthermore, we present a green resource allocation algorithm based on Deep Reinforcement Learning (DRL) to improve accuracy of QoE adaptively. Simulation results reveal that our proposals could achieve high QoE performance for content-centric IoT.},
  archive      = {J_TETC},
  author       = {Xiaoming He and Kun Wang and Huawei Huang and Toshiaki Miyazaki and Yixuan Wang and Song Guo},
  doi          = {10.1109/TETC.2018.2805718},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {781-796},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Green resource allocation based on deep reinforcement learning in content-centric IoT},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An approach to optimise resource provision with
energy-awareness in datacentres by combating task heterogeneity.
<em>TETC</em>, <em>8</em>(3), 762–780. (<a
href="https://doi.org/10.1109/TETC.2018.2794328">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud workloads are increasingly heterogeneous such that a single Cloud job may encompass one to several tasks, and tasks belonging to the same job may behave distinctively during their actual execution. This inherent task heterogeneity imposes increased complexities in achieving an energy efficient management of the Cloud jobs. The phenomenon of a few proportions of tasks characterising increased resource intensity within a given job usually lead the providers to over-provision all the encompassed tasks, resulting in majority of the tasks incurring an increased proportions of resource idleness. To this end, this paper proposes a novel analytics framework which integrates a resource estimation module to estimate the resource requirements of tasks a priori, a straggler classification module to classify tasks based on their resource intensity, and a resource optimisation module to optimise the level of resource provision depending on the task nature and various runtime factors. Performance evaluations conducted both theoretically and through practical experiments prove that the proposed methodology performs better than the compared statistical resource estimation methods and existing models of straggler mitigation, and further demonstrate the effectiveness of the proposed methodology in achieving energy conservation by postulating appropriate level of resource provisioning for task execution.},
  archive      = {J_TETC},
  author       = {John Panneerselvam and Lu Liu and Nick Antonopoulos},
  doi          = {10.1109/TETC.2018.2794328},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {762-780},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {An approach to optimise resource provision with energy-awareness in datacentres by combating task heterogeneity},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). SEARE: A system for exercise activity recognition and
quality evaluation based on green sensing. <em>TETC</em>, <em>8</em>(3),
752–761. (<a href="https://doi.org/10.1109/TETC.2018.2790080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Green-computing technology and energy-saving design have become the focus of research in various fields in recent years. As a ubiquitously deployed infrastructure, WiFi can be considered as a platform for green sensing, and a plethora of efforts have been made in WiFi-based passive detection recently. However, little work has been done on the exercise activity recognition. In this paper, we propose SEARE, a novel energy-efficient solution using WiFi for exercise activity recognition. It is prototyped by fine-grained CSI extracted from existing commercial WiFi devices. Different from traditional features like mean or max value exploited in previous activity recognition works, involving either time or frequency information, we select CSI-waveform shape as activity feature, which contains the information from both of these two domains. A series of de-noise methods are designed, including low-pass, PCA, and median filtering, where PCA can remove the in-band noise that traditional low-pass filters fail to do. Finally the evaluation of activities quality can be made. Extensive experimental result validates the great performance of SEARE in both LOS and NLOS scenarios, with average recognition accuracies of 97.8 and 91.2 percent respectively.},
  archive      = {J_TETC},
  author       = {Fu Xiao and Jing Chen and Xiaohui Xie and Linqing Gui and Lijuan Sun and Ruchuan Wang},
  doi          = {10.1109/TETC.2018.2790080},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {752-761},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {SEARE: A system for exercise activity recognition and quality evaluation based on green sensing},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Guest editor’s introduction: Special section on green
computing in internet of things. <em>TETC</em>, <em>8</em>(3), 750–751.
(<a href="https://doi.org/10.1109/TETC.2020.2999237">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The four articles in this special section identifies and discusses technical challenges and recent results related to Green Computing in Internet of Things. Green Computing is attracting worldwide attention. The emergence of Green Computing will significantly change the way we see the world. All aspects of Information Technology are under investigation, from energy saving design of individual devices, to strategies that consider the entire energy consumption in the design, planning, and management phases, to new paradigms for long term sustainability that includes reformed attitudes of users’ as well as smart energy harvesting techniques. As the advanced information technology at the present stage, Green Computing has received worldwide attention and efforts. Although the concept of Green Computing has been around for some time, its development is still at an exploratory stage.},
  archive      = {J_TETC},
  author       = {Haijun Zhang and Didier El Baz and Victor C. M. Leung},
  doi          = {10.1109/TETC.2020.2999237},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {750-751},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Guest editor&#39;s introduction: Special section on green computing in internet of things},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Gate level NBTI and leakage co-optimization in combinational
circuits with input vector cycling. <em>TETC</em>, <em>8</em>(3),
738–749. (<a href="https://doi.org/10.1109/TETC.2018.2799739">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Negative Bias Temperature Instability (NBTI) effect occurs in a PMOS transistor when turned ON leading to threshold voltage degradation. As sub-threshold leakage is significant in nanoscale CMOS circuits, input vector control can be employed wherein a Minimum Leakage Vector (MLV) is applied to the circuit during idle periods. In such a case, the ON PMOS transistors on the critical path are subject to NBTI stress for prolonged periods. Transistors can recover from stress when turned OFF. Based on this observation, we propose a vector cycling based leakage/NBTI co-optimization: a pair of MLVs are identified such that when applied alternately, on the critical path, PMOS transistors activated by one vector are turned OFF by the other vector. We employ Simulated Annealing (SA) for stochastic search of the first vector followed by back tracking to identify the second vector. Experimental results for a subset of ISCAS85 benchmarks implemented in 45 nm technology demonstrate the feasibility of vector cycling approach. When compared to leakage-only optimization, NBTI-only optimization, and co-optimization, on average, vector cycling yields 11, 3, and 6 percent NBTI improvements with 18, -9, and 4 percent leakage overheads respectively. The average area and dynamic power overheads are 13.78 and 0.15 percent respectively.},
  archive      = {J_TETC},
  author       = {Shilpa Pendyala and Sheikh Ariful Islam and Srinivas Katkoori},
  doi          = {10.1109/TETC.2018.2799739},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {738-749},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Gate level NBTI and leakage co-optimization in combinational circuits with input vector cycling},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mitigating process variability for non-volatile cache
resilience and yield. <em>TETC</em>, <em>8</em>(3), 724–737. (<a
href="https://doi.org/10.1109/TETC.2018.2799005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While inclusion of emerging technology-based Non-Volatile Memory (NVM) devices in on-chip memory subsystems offers excellent potential for energy savings and scalability, their sensing vulnerability creates Process Variation (PV) challenges. This paper presents a circuit-architecture cross-layer solution to realize a radically-different approach to leveraging as-built variations via specific Sense Amplifier (SA) design and use. This novel approach, referred to as a Self-Organized Sub-bank (SOS) design, assigns the preferred SA to each Sub-Bank (SB) based on a PV assessment, resulting in energy consumption reduction and increased read access reliability. To improve the PV immunity of SAs, two reliable and power efficient SAs, called the Merged SA (MSA) and the Adaptive SA (ASA) are introduced herein for use in the SOS scheme. Furthermore, we propose a dynamic PV and energy-aware cache block migration policy that utilizes mixed SRAM and STT-MRAM banks in Last Level Cache (LLC) to maximize the SOS bandwidth. Our experimental results indicate that SOS can alleviate the sensing vulnerability by 89 percent on average, which significantly reduces the risk of application contamination by fault propagation. Furthermore, in the light of the proposed block migration policy, write performance is improved by 12.4 percent on average compared to the STT-MRAM-only design.},
  archive      = {J_TETC},
  author       = {Soheil Salehi and Navid Khoshavi and Ronald F. DeMara},
  doi          = {10.1109/TETC.2018.2799005},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {724-737},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Mitigating process variability for non-volatile cache resilience and yield},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Analysis of design parameters in safety-critical computers.
<em>TETC</em>, <em>8</em>(3), 712–723. (<a
href="https://doi.org/10.1109/TETC.2018.2801463">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, safety-critical computers are extensively used in many civil domains like transportation including railways, avionics, and automotive. In evaluating these safety critical systems, previous studies considered different metrics, but some of safety design parameters like failure diagnostic coverage (C) or common cause failure (CCF) ratio have not been seriously taken into account. Moreover, in some cases safety has not been compared with standard safety integrity levels (IEC-61508: SIL1-SIL4) or even have not met them. Most often, it is not very clear that which part of the system is the Achilles heel and how design can be improved to reach standard safety levels. Motivated by such design ambiguities, we aim to study the effect of various design parameters on safety in some prevalent safety configurations, namely, 1oo2 and 2oo3, where 1oo1 is also used as a reference. By employing Markov modeling, we analyzed the sensitivity of safety to important parameters including: failure rate of processor, failure diagnostic coverage, CCF ratio, test and repair rates. This study aims to provide a deeper understanding on the influence of variation in design parameters over safety. Consequently, to meet appropriate safety integrity level, instead of improving some parts of a system blindly, it will be possible to make an informed decision on more relevant parameters.},
  archive      = {J_TETC},
  author       = {Hamzeh Ahangari and Funda Atik and Yusuf Ibrahim Ozkok and Asil Yildirim and Serdar Oguz Ata and Ozcan Ozturk},
  doi          = {10.1109/TETC.2018.2801463},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {712-723},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Analysis of design parameters in safety-critical computers},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Memory physical aware multi-level fault diagnosis flow.
<em>TETC</em>, <em>8</em>(3), 700–711. (<a
href="https://doi.org/10.1109/TETC.2018.2789818">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advanced methods of fault detection and diagnosis become increasingly important for the improvement of reliability, safety and efficiency in nanoscale designs. Because the existing approaches do not give a deeper insight and usually do not allow a comprehensive fault diagnosis, multi-level model based methods of fault detection were developed by using hierarchy of detection and diagnosis methods. This contribution proposes a memory physical (scrambling) aware multi-level fault diagnosis flow which is generic and applicable both for planar- and FinFET-based memories. In addition, special test algorithms for classification of static and dynamic faults are discussed while for classification of FinFET-specific faults a new test algorithm March FFDD is proposed. The flow is validated on 16nm FPGA board as well as it has been applied to numerous chips enabling successful physical failure analysis (PFA). At the end of the paper some real-life case scenarios of the flow application are presented.},
  archive      = {J_TETC},
  author       = {Gurgen Harutyunyan and Suren Martirosyan and Samvel Shoukourian and Yervant Zorian},
  doi          = {10.1109/TETC.2018.2789818},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {700-711},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Memory physical aware multi-level fault diagnosis flow},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel low complexity logic encryption technique for
design-for-trust. <em>TETC</em>, <em>8</em>(3), 688–699. (<a
href="https://doi.org/10.1109/TETC.2018.2795706">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The outsourcing of several untrusted intellectual property designs makes the development of integrated circuits vulnerable to piracy, overbuilding, reverse engineering, and hardware Trojan (HT). To thwart the hardware-based attacks, several design-for-trust (DFT) techniques are reported in the literature. In this paper, we analyze that the existing methods are inefficient to prevent hardware Trojan attacks and also exhibit significant design overhead. Hence, we propose a novel DFT technique that effectively increases the immunity of design against the Trojan attack while requiring minimal overhead. In the proposed technique, various new light-weight key-gate topologies are proposed that effectively increase the triggering probability of Trojan at the rare-triggered nets by encrypting the design. We also propose a new encryption algorithm that identifies an optimal node using a new metric called vulnerability factor in-order to replace it with the proposed key-gate. Our encryption algorithm significantly reduces the number of vulnerable-nets with minimum replacements. The simulation results show that the proposed key-gates reduce on an average 34.2 percent and 35.1 percent per-gate area and energy respectively over the stack-based key-gates. Finally, our DFT technique gives on an average 94 percent area overhead reduction as compared to the best known DFT technique on the ISCAS-85 benchmarks.},
  archive      = {J_TETC},
  author       = {Vijaypal Singh Rathor and Bharat Garg and G. K. Sharma},
  doi          = {10.1109/TETC.2018.2795706},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {688-699},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {A novel low complexity logic encryption technique for design-for-trust},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the theory and design of polynomial division circuits.
<em>TETC</em>, <em>8</em>(3), 668–687. (<a
href="https://doi.org/10.1109/TETC.2017.2785126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a theory and design techniques for polynomial division circuits with the primary focus on testing of digital and mixed-signal devices. We estimate the aliasing rate for the proposed circuits (signature analyzers) and show how to improve it. Two types of design techniques are examined for mixed-signal circuit analyzers that are arithmetical by nature. The techniques are scalable and valid for an arbitrary size and base of the number system. The proposed devices have both low hardware complexity and aliasing rate. The design techniques and devices can also be used in general arithmetic/algebraic error-control coding, cryptography, digital broadcasting and communication.},
  archive      = {J_TETC},
  author       = {Vadim Geurkov},
  doi          = {10.1109/TETC.2017.2785126},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {668-687},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {On the theory and design of polynomial division circuits},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Securing cyber-physical systems from hardware trojan
collusion. <em>TETC</em>, <em>8</em>(3), 655–667. (<a
href="https://doi.org/10.1109/TETC.2017.2787694">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hardware Trojans, which are malicious modifications made to circuits, may cause severe security issues in Cyber-Physical Systems (CPS). CPS are usually composed of multiple untrusted nodes and a trusted server, with each node connecting to the server wirelessly in a multi-hop manner. A Trojan in one node may broadcast messages with triggers secretly embedded to simultaneously activate multiple Trojans in other nodes, causing system-wide catastrophe. To prevent hardware Trojan collusion in CPS, this paper presents a collaborative defensive framework. When deploying the network, a security requirement of vendor diversity is enforced between neighboring nodes, thus precluding collusion between neighboring nodes and allowing them to monitor each other&#39;s behavior. At runtime, a mutual auditing protocol is utilized to check, for each message, whether it is correctly encrypted by the source node and whether its content is maliciously changed by any node on the routing path. This protocol ensures that any message embedded with hardware Trojan trigger is either muted or detected and abandoned, while the benign messages are thwarted. The experimental results show that the framework effectively prevents hardware Trojan collusion with low latency overhead and almost no impact on packet completion rate and network throughput.},
  archive      = {J_TETC},
  author       = {Chen Liu and Patrick Cronin and Chengmo Yang},
  doi          = {10.1109/TETC.2017.2787694},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {655-667},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Securing cyber-physical systems from hardware trojan collusion},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A dynamic sufficient condition of deadlock-freedom for
high-performance fault-tolerant routing in networks-on-chips.
<em>TETC</em>, <em>8</em>(3), 642–654. (<a
href="https://doi.org/10.1109/TETC.2017.2776909">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Networks-on-Chips (NoCs) are considered to be the paradigm of choice for on-chip communication and are today widely adopted in many-core systems. Many existing routing solutions make use of virtual channels (VCs) to avoid deadlocks while offering enough routing flexibility to avoid faulty and congested areas in a NoC. However, most of the current solutions rely on an overly restrictive, static partitioning of VCs, which results in an underutilization of their throughput enhancement capabilities. To overcome the limitations of such approaches, we introduce a new sufficient condition of deadlock-freedom that greatly relaxes the restrictions imposed by the classic VC-based deadlock-avoidance methods. The strength of our condition lies in the fact that it is imposed on packets at runtime and does not require any partitioning of virtual channels, which makes it possible to fully exploit them to reduce packet blocking and boost performance. Based on this condition, we present a generic, topology-agnostic routing algorithm design methodology that can be used to construct highly flexible routing algorithms in only a few steps. Several examples are presented to showcase the usefulness of our approach for the construction of fault-tolerant routing algorithms, as well as the enhancement and the proof of existing routing algorithms. The implementation of all the required mechanisms in hardware is also described in detail, thereby demonstrating its feasibility in an on-chip environment.},
  archive      = {J_TETC},
  author       = {Amir Charif and Alexandre Coelho and Nacer-Eddine Zergainoh and Michael Nicolaidis},
  doi          = {10.1109/TETC.2017.2776909},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {642-654},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {A dynamic sufficient condition of deadlock-freedom for high-performance fault-tolerant routing in networks-on-chips},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Self-adjusting monitor for measuring aging rate and
advancement. <em>TETC</em>, <em>8</em>(3), 627–641. (<a
href="https://doi.org/10.1109/TETC.2017.2771441">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-variant age information of different parts of a system can be used for system-level performance improvement through high-level task scheduling, thus extending the life-time of the system. Progressive age information should provide the age state that the system is in, and the rate that it is being aged at. In this paper, we propose a structure that monitors certain paths of a circuit and detects its gradual age growth, and provides the aging rate and aging state of the circuit. The proposed monitors are placed on a selected set of nodes that represent a timing bottleneck of the system. These monitors sample expected data on these nodes, and compare them with the expected values. The timing of sampling changes as the circuit ages and its delay increases. The timing of sampling will provide a measure of aging advancement of a circuit. To assess the efficacy of the proposed method and compare it with other state-of-the-art aging monitors, we use them on selected nodes of the execution unit of different processors, as well as some circuits from ITC99 benchmarks. The results reveal that the precision of our proposed method is between 0.12 (ns) to 0.401 (ns). Its Area and power overhead are negligible and are about 2.13 and 0.69 percent respectively.},
  archive      = {J_TETC},
  author       = {Somayeh Sadeghi-Kohan and Mehdi Kamal and Zainalabedin Navabi},
  doi          = {10.1109/TETC.2017.2771441},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {627-641},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Self-adjusting monitor for measuring aging rate and advancement},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Radiation hardened latch designs for double and triple node
upsets. <em>TETC</em>, <em>8</em>(3), 616–626. (<a
href="https://doi.org/10.1109/TETC.2017.2776285">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the process feature size continues to scale down, the susceptibility of logic circuits to radiation induced error has increased. This trend has led to the increase in sensitivity of circuits to multi-node upsets. Previously, work has been done to harden latches against single event upsets (SEU). Currently, there has been a concerted effort to design latches that are tolerant to double node upsets (DNU) and triple node upsets (TNU). In this paper, we first propose a novel DNU tolerant latch design. The latch is designed specifically to provide additional reliability when clock gating is used. Through experimentation, it is shown that the DNU tolerant latch is 11.3 percent more power efficient than existing latch designs suited for clock gating. In addition to the DNU tolerant design, we propose the first TNU tolerant latch. The TNU tolerant latch is shown to provide superior soft error resiliency while incurring a 40 percent overhead compared to DNU tolerant designs.},
  archive      = {J_TETC},
  author       = {Adam Watkins and Spyros Tragoudas},
  doi          = {10.1109/TETC.2017.2776285},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {616-626},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Radiation hardened latch designs for double and triple node upsets},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Reliability aware design and lifetime management of
computing platforms. <em>TETC</em>, <em>8</em>(3), 602–615. (<a
href="https://doi.org/10.1109/TETC.2017.2768821">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Meeting reliability targets with viable costs in the nanometer landscape become a significant challenge, requiring to be addressed in an unitary manner from design to run time. To this end, we propose a holistic reliability-aware design and lifetime management framework concerned (i) at design time, with providing a reliability enhanced adaptive architecture fabric, and (ii) at run time, with observing and dynamically managing fabric&#39;s wear-out profile such that user defined Quality-of-Service requirements are fulfilled, and with maintaining a full-life reliability log to be utilized as auxiliary information during the next IC generation design. After introducing our framework and the general philosophy behind it we delve into its key components. Specifically, we first introduce design time transistor and circuit level aging models, which provide the foundation for a 4-dimensional Design Space Exploration (DSE) meant to identify a reliability optimized circuit realization compliant with area, power, and delay constraints. Subsequently, to enable the creation of a low cost but yet accurate fabric observation infrastructure, we propose a methodology to minimize the number of aging sensors to be deployed in a circuit and identify their location, and introduce a sensor design able to directly capture circuit level amalgamated effects of concomitant degradation mechanisms. Furthermore, to make the information collected from sensors meaningful to the run-time management framework we introduce a circuit level model that can estimate the overall circuit aging and predict its End-of-Life based on imprecise sensors measurements, while taking into account the degradation nonlinearities. Finally, to provide more DSE reliability enhancement options we focus on the realization of reliable processing with unreliable components, and propose a methodology to obtain Error Correction Codes protected data processing units with an output error rate smaller than the fabrication technology gate error rate.},
  archive      = {J_TETC},
  author       = {Nicoleta Cucu Laurenciu and Sorin Dan Cotofana},
  doi          = {10.1109/TETC.2017.2768821},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {602-615},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Reliability aware design and lifetime management of computing platforms},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A flexible scan-in power control method in logic BIST and
its evaluation with TEG chips. <em>TETC</em>, <em>8</em>(3), 591–601.
(<a href="https://doi.org/10.1109/TETC.2017.2767070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High power dissipation in scan-based logic built-in self-test (LBIST) is a crucial issue that can cause over-testing, reliability degradation, chip damage, and so on. While many sophisticated approaches to low-power testing have been proposed in the past, it remains a serious problem to control the test power of LBIST to a predetermined appropriate level that matches the power requirements of the circuit-under-test. This paper proposes a novel power-control method for LBIST that can control the scan-shift power to an arbitrary level. The proposed method modifies pseudo-random patterns generated by an embedded test pattern generator (TPG) so that the modified patterns have the specific toggle rate without sacrificing fault coverage and test time. In order to evaluate the effectiveness of the proposed method, this paper shows not only simulation-based experimental results but also measurement results on test element group (TEG) chips.},
  archive      = {J_TETC},
  author       = {Takaaki Kato and Senling Wang and Yasuo Sato and Seiji Kajihara and Xiaoqing Wen},
  doi          = {10.1109/TETC.2017.2767070},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {591-601},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {A flexible scan-in power control method in logic BIST and its evaluation with TEG chips},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Scalable design methodology and online algorithm for
TSV-cluster defects recovery in highly reliable 3D-NoC systems.
<em>TETC</em>, <em>8</em>(3), 577–590. (<a
href="https://doi.org/10.1109/TETC.2017.2762407">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D-Network-on-Chips exploit the benefits of Network-on-Chips and 3D-Integrated Circuits allowing them to be considered as one of the most advanced and auspicious communication methodologies. On the other hand, the reliability of 3D-NoCs, due to the vulnerability of Through Silicon Vias, remains a major problem. Most of the existing techniques rely on correcting the TSV defects by using redundancies or employing routing algorithms. Nevertheless, they are not suitable for TSV-cluster defects as they can either lead to costly area and power consumption overheads, or they may result in non-minimal routing paths; thus, posing serious threats to the system reliability and overall performance. In this work, we present a scalable and low-overhead TSV usage and design method for 3D-NoC systems where the TSVs of a router can be utilized by its neighbors to deal with the cluster open defects. An adaptive online algorithm is also introduced to assist the proposed system to immediately work around the newly detected defects without using redundancies. The experimental results show the proposal ensure less than 2 percent of the routers being disabled, even with 50 percent of the TSV clusters defects. The performance evaluations also demonstrate unchanged performances for real applications under 5 percent of cluster defects.},
  archive      = {J_TETC},
  author       = {Khanh N. Dang and Akram Ben Ahmed and Yuichi Okuyama and Abderazek Ben Abdallah},
  doi          = {10.1109/TETC.2017.2762407},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {577-590},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Scalable design methodology and online algorithm for TSV-cluster defects recovery in highly reliable 3D-NoC systems},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Scrubbing-aware placement for reliable FPGA systems.
<em>TETC</em>, <em>8</em>(3), 564–576. (<a
href="https://doi.org/10.1109/TETC.2017.2757978">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Field Programmable Gate Arrays (FPGAs) provide complex embedded blocks to ease the development of high-performance computing systems for diverse area applications, including among others space, avionics and health. Although the rich set of features is ever expanding, there is one significant shortcoming of the SRAM-based FPGAs which concerns system designers for applications demanding high reliability: their vulnerability to Single Event Upsets (SEUs) which can cause system malfunction. In this work, we propose a placement approach to improve system reliability by reducing the execution time of configuration memory scrubbing, which can be used in conjunction with other reliability mechanisms proposed in the literature. The proposed placement approach is based on i) an automated floorplanning process to shape and locate the design region(s) and ii) a modified version of the Simulated Annealing placement algorithm aiming to reduce the scrubbing time. First, we performed a set of experiments with three QUIP benchmarks to demonstrate the efficiency of the proposed approach at different device utilization levels. Moreover, we illustrated its effectiveness for three different fault tolerance schemes, where scrubbing plays a different role in each one: i) a TMR microcontroller combined with scrubbing, ii) a soft processor protected by a low-cost mitigation scheme including scrubbing and checkpointing, iii) a JPEG encoder protected by a prioritized scrubbing scheduling scheme based on module criticality levels. The experimental results showed that the proposed approach improves system reliability in all the above schemes by reducing critical timing parameters, such as mean-time-to-detect and mean-time-to-repair. This reduction leads to a modest or high reliability improvement depending on the role of scrubbing in the adopted fault tolerance (FT) scheme.},
  archive      = {J_TETC},
  author       = {Aitzan Sari and Mihalis Psarakis},
  doi          = {10.1109/TETC.2017.2757978},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {564-576},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Scrubbing-aware placement for reliable FPGA systems},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Guest editor’s introduction: Special section on
reliability-aware design and analysis methods for digital systems: From
gate to system level. <em>TETC</em>, <em>8</em>(3), 561–563. (<a
href="https://doi.org/10.1109/TETC.2020.2998932">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fourteen articles in this special section represent world-leading current research into reliability-aware design methods for digital systems and provide interesting and valuable insights into current and future trends in the considered research areas. The focus on these articles is on investigating novel solutions for the reliability-aware design and analysis in digital systems, comprising a large number of issues and aspects (e.g. fault tolerance techniques, circuit aging and security), focusing on various architectures and devices (such as combinatorial circuits, memories, NoCs or FPGAs), and acting at different levels of abstraction (from circuit level to system level).},
  archive      = {J_TETC},
  author       = {Antonio Miele and Qiaoyan Yu and Maria K. Michael},
  doi          = {10.1109/TETC.2020.2998932},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {561-563},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Guest editor&#39;s introduction: special section on reliability-aware design and analysis methods for digital systems: from gate to system level},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Skeleton-based synthesis flow for computation-in-memory
architectures. <em>TETC</em>, <em>8</em>(2), 545–558. (<a
href="https://doi.org/10.1109/TETC.2017.2760927">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Memristor-based Computation-in-Memory (CIM) is one of the emerging architectures for next-generation Big Data problems. Its design requires a radically new synthesis flow as the memristor is a passive device that uses resistances to encode its logic values. This article proposes a synthesis flow for mapping parallel applications on memristor-based CIM architecture. First, it employs solution templates that contain scheduling, placement, and routing information to map multiple algorithms with similar data flow graphs to the memristor crossbar; this template is named skeleton. Complex algorithms that do not fit a single skeleton can be solved by nested skeletons. Therefore, this approach can be applied to a wide range of applications while using a limited number of skeletons only. Second, it further improves the design when spatial and temporal patterns exist in input data. To accelerate simulation of generated SystemC models, we integrate MPI in skeletons. The synthesis flow and its additional features are verified with multiple applications, and the results are compared against a multicore platform. These experiments demonstrate the feasibility and the potential of this approach.},
  archive      = {J_TETC},
  author       = {Jintao Yu and Răzvan Nane and Imran Ashraf and Mottaqiallah Taouil and Said Hamdioui and Henk Corporaal and Koen Bertels},
  doi          = {10.1109/TETC.2017.2760927},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {545-558},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Skeleton-based synthesis flow for computation-in-memory architectures},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Scalable photonic networks-on-chip architecture based on a
novel wavelength-shifting mechanism. <em>TETC</em>, <em>8</em>(2),
533–544. (<a href="https://doi.org/10.1109/TETC.2017.2737016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since Photonic Networks-on-Chip (PNoCs) were proposed, there was an unanimity about the benefits that photonic links could bring to the on-chip interconnection. However, a debate always takes place regarding the suitable architecture and routing scheme to be used. This debate concerns the use of fully photonic PNoC or an Electro-assisted one. Both schemes have their pros and cons, but the main drawback in both architectures is their scalability. We propose in this paper an alternative to these two conventional PNoC architectures. Our proposed system is based on a novel Wavelength-Shifting mechanism, which combines the benefits of the previously mentioned schemes while limiting their drawbacks. The proposed system was validated by an analytical model, in addition to a set of simulations using synthetic and realistic traffic patterns. Evaluation results show that compared to the electro-assisted architectures, we could enhance the latency, power, and bandwidth by an order of magnitude, reaching a performance similar to the fully photonic architecture. In addition, the number of used photonic devices still much lower than the one used in conventional fully photonic architectures by an average of 60 percent. Furthermore, the new wavelength-shifting mechanism is highly scalable, and it is not affected anymore by the communication&#39;s distance, nor the traffic pattern, which make it a promising solution to replace existing conventional architectures.},
  archive      = {J_TETC},
  author       = {Achraf Ben Ahmed and Tsutomu Yoshinaga and Abderazek Ben Abdallah},
  doi          = {10.1109/TETC.2017.2737016},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {533-544},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Scalable photonic networks-on-chip architecture based on a novel wavelength-shifting mechanism},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Removal attacks on logic locking and camouflaging
techniques. <em>TETC</em>, <em>8</em>(2), 517–532. (<a
href="https://doi.org/10.1109/TETC.2017.2740364">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the adoption of a globalized and distributed IC design flow, IP piracy, reverse engineering, and counterfeiting threats are becoming more prevalent. Logic obfuscation techniques including logic locking and IC camouflaging have been developed to address these emergent challenges. A major challenge for logic locking and camouflaging techniques is to resist Boolean satisfiability (SAT) based attacks that can circumvent state-of-the-art solutions within minutes. Over the past year, multiple SAT attack resilient solutions such as Anti-SAT and AND-tree insertion (ATI) have been presented. In this paper, we perform a security analysis of these countermeasures and show that they leave structural traces behind in their attempts to thwart the SAT attack. We present three attacks, namely “signal probability skew” (SPS) attack, “AppSAT guided removal (AGR) attack, and “sensitization guided SAT” (SGS) attack”, that can break Anti-SAT and ATI, within minutes.},
  archive      = {J_TETC},
  author       = {Muhammad Yasin and Bodhisatwa Mazumdar and Ozgur Sinanoglu and Jeyavijayan Rajendran},
  doi          = {10.1109/TETC.2017.2740364},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {517-532},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Removal attacks on logic locking and camouflaging techniques},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). High performance dynamic resource allocation for guaranteed
service in network-on-chips. <em>TETC</em>, <em>8</em>(2), 503–516. (<a
href="https://doi.org/10.1109/TETC.2017.2765825">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a dedicated connection allocation unit-the NoCManager-implementing the connection allocation functionality in circuit-switched network-on-chip (NoC) based on time-division-multiplexing (TDM). The NoCManager employs a novel trellis-search-algorithm (TESSA) that solves the allocation optimization problem by making use of dynamic programming approach. This enables to explore all possible paths between source-destination node pairs in order to determine the shortest available path. Three different trellis structures are proposed and analyzed for the purpose of different application scenarios. In contrast to previous TDM allocation approaches, the proposed method offers the following advantages: (1) hardware supported fast and high-throughput allocation mechanism; (2) improved success rate due to parallel multi-slot multi-path search mechanism; (3) selection of the contention-free shortest path with a guaranteed low latency; (4) general mathematical formulation allowing a variety of optimization ideas. The proposed method is compared to the state of the art centralized and distributed techniques under uniformly distributed random traffic as well as real-application traffic. The experimental results demonstrate two orders of magnitude improvement in allocation speed and tens of times higher success rate against the centralized software solutions, and 5 to 10 percent higher success rate against the centralized hardware solution. Moreover, it achieves up to 8x higher allocation speed and up to 29 percent higher success rate against recently proposed distributed solution.},
  archive      = {J_TETC},
  author       = {Yong Chen and Emil Matus and Sadia Moriam and Gerhard P. Fettweis},
  doi          = {10.1109/TETC.2017.2765825},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {503-516},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {High performance dynamic resource allocation for guaranteed service in network-on-chips},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cyber-enabled well-being oriented daily living support based
on personal data analysis. <em>TETC</em>, <em>8</em>(2), 493–502. (<a
href="https://doi.org/10.1109/TETC.2017.2763966">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We are living in a cyber-physical-social environment with a variety of lifestyles and values. Living support has become important in such a diverse society. Owing to the ability to collect a large amount of personal data or life logs in the cyber-physical-social environment, it is now possible for us to provide living support based on personal data analysis. Moreover, analyzing such data can facilitate a deep understanding of an individual. In this study, we focus on the provision of cyber-enabled well-being oriented daily living support for an individual based on personal data analysis. Three categories of personal data are identified from an individual&#39;s daily life data. In this paper, we discuss the basic concept, model, and framework for well-being oriented personal data analysis in order to offer suggestions and advices to improve the living quality of an individual. Finally, we report a feasibility study with an application scenario by using personal and environmental data.},
  archive      = {J_TETC},
  author       = {Seiji Kasuya and Xiaokang Zhou and Kiichi Tago and Shoji Nishimura and Qun Jin},
  doi          = {10.1109/TETC.2017.2763966},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {493-502},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Cyber-enabled well-being oriented daily living support based on personal data analysis},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Community detection by fuzzy relations. <em>TETC</em>,
<em>8</em>(2), 478–492. (<a
href="https://doi.org/10.1109/TETC.2017.2751101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing demand for knowledge from network data poses significant challenges in many tasks. Discovering community structure from a network is one of the classic and significant problems faced in network analysis. In this paper, we study the network structure from the perspective of the composition of fuzzy relations, and a novel algorithm based on fuzzy relations, i.e., CDFR (Community Detection by Fuzzy Relations), is proposed for non-overlapping community detection. The key idea of CDFR is to find the NGC node (Nearest node with Greater Centrality) for each node and compute the fuzzy relation between them. Then, the community to which a node belongs depends on its NGC node. In addition, the decision graph will be constructed to guide community detection. Experimental results on artificial and real-world networks verify the effectiveness and superiority of our CDFR algorithm.},
  archive      = {J_TETC},
  author       = {Wenjian Luo and Zhenglong Yan and Chenyang Bu and Daofu Zhang},
  doi          = {10.1109/TETC.2017.2751101},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {478-492},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Community detection by fuzzy relations},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Software-based self-test techniques for dual-issue embedded
processors. <em>TETC</em>, <em>8</em>(2), 464–477. (<a
href="https://doi.org/10.1109/TETC.2017.2758641">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, Self-Test strategies for testing embedded processors are increasingly diffused, especially for safety critical systems. Test programs can be effectively used for this purpose. This paper describes a set of systematic self-test techniques for in-order dual-issue embedded processors. The paper shows how to produce test programs suitable for the detection of faults in five classes of sub-modules: duplicated computational modules; multi-port register file; duplicated pipeline registers and feed-forward paths; pipeline interlocking logic; and pre-fetch buffer. While some techniques extend single-issue test programs, new techniques are also shown; results are illustrated for a couple of 32-bit in-order dual-issue processors included in automotive Systems-on-Chip manufactured by STMicroelectronics.},
  archive      = {J_TETC},
  author       = {Paolo Bernardi and Riccardo Cantoro and Sergio De Luca and Ernesto Sanchez and Alessandro Sansonetti and Giovanni Squillero},
  doi          = {10.1109/TETC.2017.2758641},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {464-477},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Software-based self-test techniques for dual-issue embedded processors},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A holistic formulation for system margining and jitter
tolerance optimization in industrial post-silicon validation.
<em>TETC</em>, <em>8</em>(2), 453–463. (<a
href="https://doi.org/10.1109/TETC.2017.2757937">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is an increasingly higher number of mixed-signal circuits within microprocessors and systems on chip (SoC). A significant portion of them corresponds to high-speed input/output (HSIO) links. Post-silicon validation of HSIO links can be critical for making a product release qualification decision under aggressive launch schedules. The optimization of receiver analog circuitry in modern HSIO links is a very time consuming post-silicon validation process. Current industrial practices are based on exhaustive enumeration methods to improve either the system margins or the jitter tolerance compliance test. In this paper, these two requirements are addressed in a holistic optimization-based approach. We propose a novel objective function based on these two metrics. Our method employs Kriging to build a surrogate model based on system margining and jitter tolerance measurements. The proposed method, tested with three different realistic server HSIO links, is able to deliver optimal system margins and guarantee jitter tolerance compliance while substantially decreasing the typical post-silicon validation time.},
  archive      = {J_TETC},
  author       = {Francisco Elias Rangel-PatiÑo and Andres Viveros-Wacher and José Ernesto Rayas-Sánchez and Ismael Duron-Rosales and Edgar Andrei Vega-Ochoa and Nagib Hakim and Enrique Lopez-Miralrio},
  doi          = {10.1109/TETC.2017.2757937},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {453-463},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {A holistic formulation for system margining and jitter tolerance optimization in industrial post-silicon validation},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). In-field recovery of RF circuits from wearout based
performance degradation. <em>TETC</em>, <em>8</em>(2), 442–452. (<a
href="https://doi.org/10.1109/TETC.2017.2737320">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Performance failure due to aging is an increasing concern for RF circuits. While most aging studies are focused on the concept of mean-time-to-failure, for analog circuits, aging results in continuous degradation in performance before it causes catastrophic failures. In this paper, we present a methodology for monitoring and recovering the performance of RF circuits in the field at little or no performance penalty. The proposed technique is based on two phases: During the design time, degradation profiles of the aged circuit are obtained through simulations. From these profiles, we identify reliability hotspots and focus on monitoring these components, and recovering from the effects of their aging. After deployment, an on-chip monitor circuit is periodically activated and its results are used to trigger the recovery mechanism if necessary. The recovery mechanism is designed to offset the degradation in the reliability hotspots to enhance the lifetime of the circuit. Lifetime is defined as the point where at least one specification of the circuit fails due to aging degradation. A Low noise amplifier (LNA) is fabricated as a case study to demonstrate that the lifetime can be enhanced by the proposed monitoring and recovery techniques.},
  archive      = {J_TETC},
  author       = {Doohwang Chang and Jennifer N. Kitchen and Sayfe Kiaei and Sule Ozev},
  doi          = {10.1109/TETC.2017.2737320},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {442-452},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {In-field recovery of RF circuits from wearout based performance degradation},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). LEXACT: Low energy n-modular redundancy using approximate
computing for real-time multicore processors. <em>TETC</em>,
<em>8</em>(2), 431–441. (<a
href="https://doi.org/10.1109/TETC.2017.2737045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multicore processors are becoming popular in safety-critical applications. A series of these applications comprises of kernels where inexact computations may produce results within the boundary of sufficient quality though, for which the reliability should stay at the maximum possible level. Intrinsic core-level redundancy in multicore processors can be leveraged to achieve the desired reliability level in form of N-modular redundancy (NMR). While NMR provides a proactive means of reliability for critical systems, it has two main drawbacks: Increase in the area and energy consumption that are both limiting factors in the embedded systems. This paper presents a software-based method to construct NMR in a multicore processor through k cores using approximate computing concept, where k &lt;; N. The method uses a combination of exact and approximate versions of a task to run on different cores in order to increase the reliability. To identify the suitable approximation factor, a tool called LEXACT has been developed to process the target applications. The method reduces the energy consumption and area overheads of the NMR as compared to its traditional implementation. Experimental results show at least 35 percent reduction in the energy consumption, and some 40 percent area reduction while achieving the desired reliability level and quality of result.},
  archive      = {J_TETC},
  author       = {Farshad Baharvand and Seyed Ghassem Miremadi},
  doi          = {10.1109/TETC.2017.2737045},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {431-441},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {LEXACT: Low energy N-modular redundancy using approximate computing for real-time multicore processors},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bridging the gap between resilient networks-on-chip and
real-time systems. <em>TETC</em>, <em>8</em>(2), 418–430. (<a
href="https://doi.org/10.1109/TETC.2017.2736783">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional fault-tolerance approaches for Networks-on-Chip (NoCs) cannot be applied to high dependability systems due to their different goals and constraints. These systems impose strict integrity, resilience and real-time requirements. In order to meet these requirements, all possible effects of random hardware errors must be taken into account, silent data corruption must be prevented and the resulting system must be predictable in the presence of errors. In this paper, we present a wormhole-switched NoC with virtual channels for high dependability systems hardened against soft errors. The NoC is developed based on results of a Failure Mode and Effects Analysis. It efficiently handles errors in different network layers and operates with formal guarantees. Our experimental evaluation, including an industrial avionics use case, shows that the network is able to achieve predictable behavior even in aggressive environments with very high error rates while presenting competitive overheads.},
  archive      = {J_TETC},
  author       = {Eberle A. Rambo and Christoph Seitz and Selma Saidi and Rolf Ernst},
  doi          = {10.1109/TETC.2017.2736783},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {418-430},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Bridging the gap between resilient networks-on-chip and real-time systems},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Guest editor’s introduction: Special section on high
dependability systems. <em>TETC</em>, <em>8</em>(2), 416–417. (<a
href="https://doi.org/10.1109/TETC.2020.2995450">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The papers in this special section focus on high dependability systems. The continuous scaling of microelectronic technology has enabled electronic devices to become more and more pervasive and widespread. Nowadays most of the objects surrounding us include electronic devices, which are connected together through the Internet, creating the well-known Internet of Things. A huge amount of data is collected, processed and exchanged among these objects, on a daily basis. Humans’ life is becoming more and more dependent on decisions taken on the basis of such data and their processing. Autonomous vehicles and robots, trained and guided by such data, are becoming more and more popular. Their dependability (that is reliability, availability, safety and security) emerges as an obvious, mandatory constraint, that constitutes a challenge to enable the development of more and more autonomous systems. Major, worldwide efforts are consequently conducted to provide hardware and software solutions for high dependability systems.},
  archive      = {J_TETC},
  author       = {CECILIA Metra and MATTEO Sonza Reorda},
  doi          = {10.1109/TETC.2020.2995450},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {416-417},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Guest editor&#39;s introduction: Special section on high dependability systems},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Detection and threat prioritization of pivoting attacks in
large networks. <em>TETC</em>, <em>8</em>(2), 404–415. (<a
href="https://doi.org/10.1109/TETC.2017.2764885">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several advanced cyber attacks adopt the technique of “pivoting” through which attackers create a command propagation tunnel through two or more hosts in order to reach their final target. Identifying such malicious activities is one of the most tough research problems because of several challenges: command propagation is a rare event that cannot be detected through signatures, the huge amount of internal communications facilitates attackers evasion, timely pivoting discovery is computationally demanding. This paper describes the first pivoting detection algorithm that is based on network flows analyses, does not rely on any a-priori assumption on protocols and hosts, and leverages an original problem formalization in terms of temporal graph analytics. We also introduce a prioritization algorithm that ranks the detected paths on the basis of a threat score thus letting security analysts investigate just the most suspicious pivoting tunnels. Feasibility and effectiveness of our proposal are assessed through a broad set of experiments that demonstrate its higher accuracy and performance against related algorithms.},
  archive      = {J_TETC},
  author       = {Giovanni Apruzzese and Fabio Pierazzi and Michele Colajanni and Mirco Marchetti},
  doi          = {10.1109/TETC.2017.2764885},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {404-415},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Detection and threat prioritization of pivoting attacks in large networks},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Weird machines, exploitability, and provable
unexploitability. <em>TETC</em>, <em>8</em>(2), 391–403. (<a
href="https://doi.org/10.1109/TETC.2017.2785299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concept of exploit is central to computer security, particularly in the context of memory corruptions. Yet, in spite of the centrality of the concept and voluminous descriptions of various exploitation techniques or countermeasures, a good theoretical framework for describing and reasoning about exploitation has not yet been put forward. A body of concepts and folk theorems exists in the community of exploitation practitioners; unfortunately, these concepts are rarely written down or made sufficiently precise for people outside of this community to benefit from them. This paper clarifies a number of these concepts, provides a clear definition of exploit, a clear definition of the concept of a weird machine, and how programming of a weird machine leads to exploitation. The papers also shows, somewhat counterintuitively, that it is feasible to design some software in a way that even powerful attackers-with the ability to corrupt memory once-cannot gain an advantage. The approach in this paper is focused on memory corruptions. While it can be applied to many security vulnerabilities introduced by other programming mistakes, it does not address side channel attacks, protocol weaknesses, or security problems that are present by design.},
  archive      = {J_TETC},
  author       = {Thomas Dullien},
  doi          = {10.1109/TETC.2017.2785299},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {391-403},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Weird machines, exploitability, and provable unexploitability},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Attribute-based cloud data integrity auditing for secure
outsourced storage. <em>TETC</em>, <em>8</em>(2), 377–390. (<a
href="https://doi.org/10.1109/TETC.2017.2759329">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outsourced storage such as cloud storage can significantly reduce the burden of data management of data owners. Despite of a long list of merits of cloud storage, it triggers many security risks at the same time. Data integrity, one of the most burning challenges in secure cloud storage, is a fundamental and pivotal element in outsourcing services. Outsourced data auditing protocols enable a verifier to efficiently check the integrity of the outsourced files without downloading the entire file from the cloud, which can dramatically reduce the communication overhead between the cloud server and the verifier. Existing protocols are mostly based on public key infrastructure or an exact identity, which lacks flexibility of key management. In this paper, we seek to address the complex key management challenge in cloud data integrity checking by introducing attribute-based cloud data auditing, where users can upload files to cloud through some customized attribute set and specify some designated auditor set to check the integrity of the outsourced data. We formalize the system model and the security model for this new primitive, and describe a concrete construction of attribute-based cloud data integrity auditing protocol. The new protocol offers desirable properties namely attribute privacy-preserving and collusion-resistance. We prove soundness of our protocol based on the computational Diffie-Hellman assumption and the discrete logarithm assumption. Finally, we develop a prototype of the protocol which demonstrates the practicality of the protocol.},
  archive      = {J_TETC},
  author       = {Yong Yu and Yannan Li and Bo Yang and Willy Susilo and Guomin Yang and Jian Bai},
  doi          = {10.1109/TETC.2017.2759329},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {377-390},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Attribute-based cloud data integrity auditing for secure outsourced storage},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Energy-efficient distance-bounding with residual charge
computation. <em>TETC</em>, <em>8</em>(2), 365–376. (<a
href="https://doi.org/10.1109/TETC.2017.2761702">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time location systems are often required in industrial applications. In addition to securely determining an item&#39;s location, these systems also need to accommodate energy-limited tracking tokens. Distance-bounding protocols enable a Verifier to cryptographically determine an upper-bound on the physical distance to a Prover by measuring the round-trip time of specially designed challenge-response messages. This type of protocols serve as countermeasure to three common attacks on location-based systems and have been extensively studied with the goal of achieving optimal security bounds for the respective attacks. In this paper, we propose a new energy-efficient distance-bounding protocol that protects against all three common attacks in a distance-bounding scenario with improved security bounds. We provide a new approach to combining the response registers and Prover&#39;s key to determine responses. Furthermore, the protocol design allows offline pre-computation of the function f used to determine the Prover&#39;s response registers. This results in faster protocol execution, the reader does not wait for the tag to compute any cryptographic function during the protocol execution, and also allows passive tokens to effectively use residual energy after the preceding transaction to compute response registers for the next protocol run.},
  archive      = {J_TETC},
  author       = {Yunhui Zhuang and Anjia Yang and Gerhard P. Hancke and Duncan S. Wong and Guomin Yang},
  doi          = {10.1109/TETC.2017.2761702},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {365-376},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Energy-efficient distance-bounding with residual charge computation},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Private machine learning classification based on fully
homomorphic encryption. <em>TETC</em>, <em>8</em>(2), 352–364. (<a
href="https://doi.org/10.1109/TETC.2018.2794611">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning classification is an useful tool for trend prediction by analyzing big data. As supporting homomorphic operations over encrypted data without decryption, fully homomorphic encryption (FHE) contributes to machine learning classification without leaking user privacy, especially in the outsouring scenario. In this paper, we propose an improved FHE scheme based on HElib, which is a FHE library implemented based on Brakerski&#39;s FHE scheme. Our improvement focuses on two aspects. On the one hand, we first use the relinearization technique to reduce the ciphertext size, and then the modulus switching technique is used to reduce the modulus and decryption noise. On the other hand, we need no relinearization and modulus switching if there is additive homomorphic or no homomorphic operation in the multiplicative ciphertext&#39;s next homomorphic operation. Homomorphic comparison protocol, private hyperplane decision-based classification and private Naïve Bayes classification are implemented by additive homomorphic and multiplicative homomorphic first. In our homomorphic comparison protocol, the number of interactions is reduced from 3 to 1. We choose the proposed FHE scheme to implement private decision tree classification. Simulation results show that the efficiency of our FHE scheme and implementation of private decision tree classification are more efficient than other two schemes.},
  archive      = {J_TETC},
  author       = {Xiaoqiang Sun and Peng Zhang and Joseph K. Liu and Jianping Yu and Weixin Xie},
  doi          = {10.1109/TETC.2018.2794611},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {352-364},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Private machine learning classification based on fully homomorphic encryption},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Know abnormal, find evil: Frequent pattern mining for
ransomware threat hunting and intelligence. <em>TETC</em>,
<em>8</em>(2), 341–351. (<a
href="https://doi.org/10.1109/TETC.2017.2756908">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emergence of crypto-ransomware has significantly changed the cyber threat landscape. A crypto ransomware removes data custodian access by encrypting valuable data on victims&#39; computers and requests a ransom payment to re-instantiate custodian access by decrypting data. Timely detection of ransomware very much depends on how quickly and accurately system logs can be mined to hunt abnormalities and stop the evil. In this paper we first setup an environment to collect activity logs of 517 Locky ransomware samples, 535 Cerber ransomware samples and 572 samples of TeslaCrypt ransomware. We utilize Sequential Pattern Mining to find Maximal Frequent Patterns (MFP) of activities within different ransomware families as candidate features for classification using J48, Random Forest, Bagging and MLP algorithms. We could achieve 99 percent accuracy in detecting ransomware instances from goodware samples and 96.5 percent accuracy in detecting family of a given ransomware sample. Our results indicate usefulness and practicality of applying pattern mining techniques in detection of good features for ransomware hunting. Moreover, we showed existence of distinctive frequent patterns within different ransomware families which can be used for identification of a ransomware sample family for building intelligence about threat actors and threat profile of a given target.},
  archive      = {J_TETC},
  author       = {Sajad Homayoun and Ali Dehghantanha and Marzieh Ahmadzadeh and Sattar Hashemi and Raouf Khayami},
  doi          = {10.1109/TETC.2017.2756908},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {341-351},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Know abnormal, find evil: Frequent pattern mining for ransomware threat hunting and intelligence},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel stealthy attack to gather SDN
configuration-information. <em>TETC</em>, <em>8</em>(2), 328–340. (<a
href="https://doi.org/10.1109/TETC.2018.2806977">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software Defined Networking (SDN) is a recent network architecture based on the separation of forwarding functions from network logic, and provides high flexibility in the management of the network. In this paper, we show how an attacker can exploit SDN programmability to obtain detailed knowledge about the network behaviour. In particular, we introduce a novel attack, named Know Your Enemy (KYE), which allows an attacker to gather vital information about the configuration of the network. Through the KYE attack, an attacker can obtain information ranging from the configuration of security tools, such as attack detection thresholds for network scanning, to general network policies like QoS and network virtualization. Additionally, we show that the KYE attack can be performed in a stealthy fashion, allowing an attacker to learn configuration secrets without being detected. We underline that the vulnerability exploited by the KYE attack is proper of SDN and is not present in legacy networks. Finally, we address the KYE attack by proposing an active defense countermeasure based on network flows obfuscation, which considerably increases the complexity for a successful attack. Our solution offers provable security guarantees that can be tailored to the needs of the specific network under consideration.},
  archive      = {J_TETC},
  author       = {Mauro Conti and Fabio De Gaspari and Luigi V. Mancini},
  doi          = {10.1109/TETC.2018.2806977},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {328-340},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {A novel stealthy attack to gather SDN configuration-information},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Privy: Privacy preserving collaboration across multiple
service providers to combat telecom spams. <em>TETC</em>, <em>8</em>(2),
313–327. (<a href="https://doi.org/10.1109/TETC.2017.2771251">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nuisance or unsolicited calls and instant messages come at any time in a variety of different ways. These calls would not only exasperate recipients with the unwanted ringing, impacting their productivity, but also lead to a direct financial loss to users and service providers. Telecommunication Service Providers (TSPs) often employ standalone detection systems to classify call originators as spammers or non-spammers using their behavioral patterns. These approaches perform well when spammers target a large number of recipients of one service provider. However, professional spammers try to evade the standalone systems by intelligently reducing the number of spam calls sent to one service provider, and instead distribute calls to the recipients of many service providers. Naturally, collaboration among service providers could provide an effective defense, but it brings the challenge of privacy protection and system resources required for the collaboration process. In this paper, we propose a novel decentralized collaborative system named privy for the effective blocking of spammers who target multiple TSPs. More specifically, we develop a system that aggregates the feedback scores reported by the collaborating TSPs without employing any trusted third party system, while preserving the privacy of users and collaborators. We evaluate the system performance of privy using both the synthetic and real call detail records. We find that privy can correctly block spammers in a quicker time, as compared to standalone systems. Further, we also analyze the security and privacy properties of the privy system under different adversarial models.},
  archive      = {J_TETC},
  author       = {Muhammad Ajmal Azad and Samiran Bag and Shazia Tabassum and Feng Hao},
  doi          = {10.1109/TETC.2017.2771251},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {313-327},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Privy: Privacy preserving collaboration across multiple service providers to combat telecom spams},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). You think, therefore you are: Transparent authentication
system with brainwave-oriented bio-features for IoT networks.
<em>TETC</em>, <em>8</em>(2), 303–312. (<a
href="https://doi.org/10.1109/TETC.2017.2759306">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet-of-Things (IoT) is an evolutionary paradigm seamlessly integrating an enormous number of smart objects within the Internet. Recently, with the rapid growth and universality of wearable technology, novel security threats are emerging at the system level as well as at edge nodes in IoT-based networks. In this study, we envision a future IoT scenario in which end-users are with smart wearable objects related to human brainwave retrieval. A novel transparent authentication system using brainwaves as bio-features for IoT-based networks is proposed. In brief, this study first provides a comprehensive review of transparent authentication in recent years and presents the state of the art of this important research field. Second, we investigate the feasibility of extracting long-term memory ability from users&#39; brainwaves. Third, we conduct the bio-features identified in the brainwaves of users as authentication tokens in the proposed authentication system which transparently performs continuous (or real-time) entity verification in the background without the need for direct input from the user. Experiment results demonstrate the efficacy of the proposed authentication system in achieving high verification accuracy.},
  archive      = {J_TETC},
  author       = {Lu Zhou and Chunhua Su and Wayne Chiu and Kuo-Hui Yeh},
  doi          = {10.1109/TETC.2017.2759306},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {303-312},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {You think, therefore you are: Transparent authentication system with brainwave-oriented bio-features for IoT networks},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Authenticated data redaction with fine-grained control.
<em>TETC</em>, <em>8</em>(2), 291–302. (<a
href="https://doi.org/10.1109/TETC.2017.2754646">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Redactable signatures, a branch of malleable homomorphic signatures for editing, have wide applications in online interactions, from privacy enhancing to bandwidth saving. Recent research tends to apply this technique to solve the issue of authenticated data redaction in electronic health records (EHRs) systems, social networks, smart grid, etc. However, most of existing schemes are vulnerable to unauthorized arbitrary redaction or additional redaction. Redaction control is a crucial mechanism to restrict the actions that legitimate users can perform in sensitive systems, as well as constrain unauthorized manipulations from any user. In this paper, we propose a novel and generalized approach for constructing redactable signature scheme with fine-grained redaction control (RSS-FGRC), which allows the signer to specify a flexible and expressive redaction control policy to regulate the redaction operation of redactors. We analyse the security, efficiency and functionality of our new construction by comparing with other related works. The analysis results show that the performance of our construction has significant advantages over others, from the aspects of security and efficiency.},
  archive      = {J_TETC},
  author       = {Jinhua Ma and Jianghua Liu and Xinyi Huang and Yang Xiang and Wei Wu},
  doi          = {10.1109/TETC.2017.2754646},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {291-302},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Authenticated data redaction with fine-grained control},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Secure verifiable database supporting efficient dynamic
operations in cloud computing. <em>TETC</em>, <em>8</em>(2), 280–290.
(<a href="https://doi.org/10.1109/TETC.2017.2776402">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Storage is one of the main services that the cloud provides users. Utilizing the cloud to store large amounts of data can alleviate the cost of storage and the hardware investment on the local side, which is very important for resource-restricted clients. An emerging issue for clients is how to verify the database in the could after outsourcing their data to the cloud. Many verifiable database (VDB) schemes have been proposed by researchers that can solve this issue. However, some of the existing schemes cannot satisfy the practical requirements of database verifiability. In this paper, we propose a secure verifiable database scheme that is based on the polynomial commitment for cloud computing, which can realize the verifiability of database records in the cloud. Moreover, the proposed scheme can support public verifiability in that all clients in the system can verify the database. In addition, we use the BLS signature and the index-hash table to construct dynamic operations for the database. Security analysis shows that our scheme can achieve real-world security requirements. The simulation results show that our scheme is more efficient than similar schemes.},
  archive      = {J_TETC},
  author       = {Jian Shen and Dengzhi Liu and Md Zakirul Alam Bhuiyan and Jun Shen and Xingming Sun and Aniello Castiglione},
  doi          = {10.1109/TETC.2017.2776402},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {280-290},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Secure verifiable database supporting efficient dynamic operations in cloud computing},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). VulHunter: A discovery for unknown bugs based on analysis
for known patches in industry internet of things. <em>TETC</em>,
<em>8</em>(2), 267–279. (<a
href="https://doi.org/10.1109/TETC.2017.2754103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With Industry 4.0 or Internet of Things (IoT) era coming, security problem plays a key role in Industry Internet of Things (IIoT), especially vulnerability discovery and analysis. However, how to discover some new bugs or vulnerabilities based on analysis for known patches is an open issue. To our best knowledge, few effective methods are established, especially for vulnerabilities in software or firmware of IIoT. In order to deal with these problems, we propose VulHunter, a discovery for unknown vulnerabilities based on analysis for known vulnerability patch packs in IIoT. Some new algorithms in binary comparison, pack extractor and background semantic solver are designed and realized in this paper. To verify our proposal, experimental tests are verified in a large number of vulnerabilities in IIoT applications and devices, and test results demonstrated that we can discover some new bugs based on analysis for known patch pack as expected, some of which can be picked to report CVE list.},
  archive      = {J_TETC},
  author       = {Fu Xiao and Le-Tian Sha and Zai-Ping Yuan and Ru-Chuan Wang},
  doi          = {10.1109/TETC.2017.2754103},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {267-279},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {VulHunter: A discovery for unknown bugs based on analysis for known patches in industry internet of things},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Guest editorial: Introduction to the special section on
cyber security threats and defense advance. <em>TETC</em>,
<em>8</em>(2), 264–266. (<a
href="https://doi.org/10.1109/TETC.2020.2995250">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The papers in this special section focus on cyber security threats and efforts to ensure secure communications. With rapid and ongoing advances in information and communications technology (ICT) and “expansion” of cyber space, cyber security is, and will continue to be, of crucial importance to the stability of our Internet-connected society. For example, how do we ensure secure communications between servers, network nodes, terminals and user applications across public and private networks, particularly in cyber-physical systems? Defending our cyber space is both a research challenge and an operational challenge. Designing effective security solutions is complicated by the need to carefully balance between security and usability, as well as the amount of efforts and resources required.},
  archive      = {J_TETC},
  author       = {Zhe Liu and Kim-Kwang Raymond Choo and Weiqiang Liu and Muhammad Khurram Khan},
  doi          = {10.1109/TETC.2020.2995250},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {264-266},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Guest editorial: Introduction to the special section on cyber security threats and defense advance},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Exploring the progression of early programmers in a set of
computational thinking challenges via clickstream analysis.
<em>TETC</em>, <em>8</em>(1), 256–261. (<a
href="https://doi.org/10.1109/TETC.2017.2768550">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, many initiatives have aimed to develop basic computational thinking skills. Despite the popularity of online platforms for early programmers, we still lack detailed information to analyze how these skills are acquired. In the present study we analyzed clickstream data from 3,355 participants enrolled in several Computational Thinking workshops using Kodetu, an online platform with fine grained logging features. Participants used Kodetu&#39;s coding blocks to solve challenges of increasing difficulty while we gathered their clickstream in the platform. Here, we present our findings after evaluating these data in regards of participants&#39; characteristics (age, sex, previous knowledge), similarity with previously submitted solutions, and degree of discrepancy from the optimal solution. To facilitate collaboration with other researchers in this area, we released our dataset under an open license. To the best of our knowledge, this is the largest Computational Thinking-related datasets publicly available.},
  archive      = {J_TETC},
  author       = {Andoni Eguíluz and Mariluz Guenaga and Pablo Garaizar and Cristian Olivares-Rodríguez},
  doi          = {10.1109/TETC.2017.2768550},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {256-261},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Exploring the progression of early programmers in a set of computational thinking challenges via clickstream analysis},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Reasons and responses: A multimodal serious games evaluation
framework. <em>TETC</em>, <em>8</em>(1), 245–255. (<a
href="https://doi.org/10.1109/TETC.2017.2737953">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evaluation is an essential part of any software development process as it helps compare intended with actual outcomes and identify possible improvements. To do this, it is important to understand how users interact with the product. As interactions with the interdisciplinary product category of Serious Games can be multifaceted, pure text-logging of gameplay actions is not always sufficient to cover all aspects needed to satisfy researchers&#39; needs, for instance how the user feels or what s/he thinks while carrying out a certain action. For this reason, studies evaluating serious games are increasingly applying multimodal methods in recent years. This makes it important to establish theoretical foundations considering the changing research landscape. This paper presents a theoretical framework for multimodal Serious Games evaluation based on a review of relevant research.},
  archive      = {J_TETC},
  author       = {Laila Shoukry and Stefan Göbel},
  doi          = {10.1109/TETC.2017.2737953},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {245-255},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Reasons and responses: A multimodal serious games evaluation framework},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Comparison of the effect of interactive versus passive
virtual reality learning activities in evoking and sustaining conceptual
change. <em>TETC</em>, <em>8</em>(1), 233–244. (<a
href="https://doi.org/10.1109/TETC.2017.2737983">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The key question we address is whether interactivity in a virtual environment (VE) impacts conceptual learning. We developed a Virtual Reality (VR) application to simulate a playground, in which children had to engage in tasks that required solving arithmetical fractions problems. Fifty (50) children were tested in an empirical study with different conditions that varied the levels of interactivity and immersion, from a fully interactive to a non-immersive and non-interactive activity with LEGOs. A methodological framework, where quantitative and qualitative analyses complement each other, was developed to analyze children&#39;s activity. Our findings from the quantitative analysis showed that participants in the VEs seemed to have a greater overall gain than those that did not perform the activity in VR but did not clarify whether interactivity in the VE was the defining factor in this gain. The qualitative analysis indicated that it was the “passive” VR condition which provided evidence of sustained conceptual change. With countless educational VR applications becoming available nowadays to the public due to VR&#39;s recent resurgence in prominence through inexpensive headsets, the study of the effect of VE attributes, such as interactivity, is timely.},
  archive      = {J_TETC},
  author       = {Maria Roussou and Mel Slater},
  doi          = {10.1109/TETC.2017.2737983},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {233-244},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Comparison of the effect of interactive versus passive virtual reality learning activities in evoking and sustaining conceptual change},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A comparison of seated and room-scale virtual reality in a
serious game for epidural preparation. <em>TETC</em>, <em>8</em>(1),
218–232. (<a href="https://doi.org/10.1109/TETC.2017.2746085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A room-scale virtual reality (VR) configuration allows users to physically walk within an interactive area while reflecting their real-world motion in the virtual environment. Room-scale VR provides developers of serious games and virtual simulations the opportunity to develop more realistic applications that are highly interactive and engaging. Despite these benefits, room-scale VR hardware is generally more expensive due to motion tracking and headset costs, also requiring a potentially large open physical space for the player to walk around in. Here we provide a quantitative and qualitative comparison between the usability, performance, and engagement of traditional seated VR with a room-scale variation within the scope of a medical-based epidural preparation serious game. This is a first-step in examining the differences between the two configurations and determining whether the additional requirements and resources associated with a room-scale VR configuration are warranted. Although our quantitative results reveal limited differences, the room scale VR configuration led to higher immersion. Our qualitative results indicate that the hardware being used and the requirements imposed upon it by the desired fidelity of the simulation must be carefully considered; higher fidelity implies greater computational requirements that may not be readily available to the average computer user.},
  archive      = {J_TETC},
  author       = {Robert Shewaga and Alvaro Uribe-Quevedo and Bill Kapralos and Fahad Alam},
  doi          = {10.1109/TETC.2017.2746085},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {218-232},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {A comparison of seated and room-scale virtual reality in a serious game for epidural preparation},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Integrating programming learning analytics across physical
and digital space. <em>TETC</em>, <em>8</em>(1), 206–217. (<a
href="https://doi.org/10.1109/TETC.2017.2701201">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we study students&#39; learning effectiveness through their use of a homegrown innovative educational technology, Web Programming Grading Assistant (WPGA), which facilitates grading and feedback delivery of paper-based assessments. We designed a lab study and a classroom study from a lower-division blended-instruction computer science course. We evaluated a partial credit assignment algorithm. We tracked and modeled students&#39; learning behaviors through their use of WPGA. Results showed that students demonstrated an effort and desire to review assessments regardless of if they were graded for academic performance or for attendance. Diligent students achieved higher exam scores on average and were found to review their exams and the correct questions frequently. Additionally, student cohorts exhibited similar initial reviewing patterns, but different in-depth reviewing and reflecting strategies. Ultimately, the work contributes to multidimensional learning analytics aggregation across the physical and cybersphere.},
  archive      = {J_TETC},
  author       = {I-Han Hsiao and Po-Kai Huang and Hannah Murphy},
  doi          = {10.1109/TETC.2017.2701201},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {206-217},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Integrating programming learning analytics across physical and digital space},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Towards data-driven learning paths to develop computational
thinking with scratch. <em>TETC</em>, <em>8</em>(1), 193–205. (<a
href="https://doi.org/10.1109/TETC.2017.2734818">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the introduction of computer programming in schools around the world, a myriad of guides are being published to support educators who are teaching this subject, often for the first time. Most of these books offer a learning path based on the experience of the experts who author them. In this paper we propose and investigate an alternative way of determining the most suitable learning paths by analyzing projects developed by learners hosted in public repositories. Therefore, we downloaded 250 projects of different types from the Scratch online platform, and identified the differences and clustered them based on a quantitative measure, the computational thinking score provided by Dr. Scratch. We then triangulated the results by qualitatively studying in detail the source code of the prototypical projects to explain the progression required to move from one cluster to the next one. The result is a data-driven itinerary that can support teachers and policy makers in the creation of a curriculum for learning to program. Aiming to generalize this approach, we discuss a potential recommender tool, populated with data from public repositories, to allow educators and learners creating their own learning paths, contributing thus to a personalized learning connected with students&#39; interests.},
  archive      = {J_TETC},
  author       = {JesÚs Moreno-LeÓn and Gregorio Robles and Marcos RomÁn-GonzÁlez},
  doi          = {10.1109/TETC.2017.2734818},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {193-205},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Towards data-driven learning paths to develop computational thinking with scratch},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Design and evaluation of a block-based environment with a
data science context. <em>TETC</em>, <em>8</em>(1), 182–192. (<a
href="https://doi.org/10.1109/TETC.2017.2729585">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As computing becomes pervasive across fields, introductory computing curricula needs new tools to motivate and educate the influx of learners with little prior background and divergent goals. We seek to improve curricula by enriching it with authentic, real-world contexts and powerful scaffolds that can guide learners to success using automated tools, thereby reducing the strain on limited human instructional resources. To address these issues, we have created the BlockPy programming environment, a web-based, open-access, open-source platform for introductory computing students (https://www.blockpy.com). BlockPy has an embedded data science context that allows learners to connect the educational content with real-world scenarios through meaningful problems. The environment is block-based and gives guiding feedback to learners as they complete problems, but also mediates transfer to more sophisticated programming environments by supporting bidirectional, seamless transitions between block and text programming. Although it can be used as a stand-alone application, the environment has first-class support for the latest Learning Tools Interoperability standards, so that instructors can embed the environment directly within their Learning Management System. In this paper, we describe interesting design issues that we encountered during the development of BlockPy, an evaluation of the environment from fine-grained logs, and our future plans for the environment.},
  archive      = {J_TETC},
  author       = {Austin Cory Bart and Javier Tibau and Dennis Kafura and Clifford A. Shaffer and Eli Tilevich},
  doi          = {10.1109/TETC.2017.2729585},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {182-192},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Design and evaluation of a block-based environment with a data science context},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Guest editorial: Joint special issue on “innovation in
technologies for educational computing.” <em>TETC</em>, <em>8</em>(1),
179–181. (<a href="https://doi.org/10.1109/TETC.2020.2969591">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The papers in this special section examines new technologies for educational computing applications. Educational computing encompasses the full range of uses of computers pursuant to conducting the profession of educators. History of educational computing is scattered of innovations and discoveries pertaining both technical matters and learning sciences, which all contributed at shaping the way education is delivered today. In some cases, revolutionary technologies with a disruptive potential have been introduced, which brought immediate changes to common education practice, such as with distance and ubiquitous learning, massive online open courses, etc. In other cases, developments in the field have been the result of rediscovery of methods presented years before, as it is happening today, for instance, with virtual and augmented reality applications. Lastly, there are cases in which new approaches to educational computing derive from an evolution of existing solutions, which are sometimes applied for the first time to education, e.g., in reaction to changes in the society. An example is represented by gamification, which indeed has been made possible by achievements in the field of mobile computing, but also responds to the changed habits of a generation of learners who has grown up playing video games.},
  archive      = {J_TETC},
  author       = {Fabrizio Lamberti and Gwo-Jen Hwang and Baltasar FernÁndez ManjÓn and Wenping Wang},
  doi          = {10.1109/TETC.2020.2969591},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {179-181},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Guest editorial: Joint special issue on “Innovation in technologies for educational computing”},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Object-based video coding by visual saliency and temporal
correlation. <em>TETC</em>, <em>8</em>(1), 168–178. (<a
href="https://doi.org/10.1109/TETC.2017.2695640">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When a disaster occurs, video communication is an effective way to disseminate large quantities of important information. However, video coding standards such as High Efficiency Video Coding (HEVC) compress entire videos, whatever the contents are; at low bit rates, the quality of significant objects deteriorates. In this paper, an object-based video coding method is proposed to address this problem. The proposed method extracts objects on the basis of visual saliency and temporal correlation between frames. Subsequently, we execute pre-processing which degrades the background quality before encoding the video with HEVC. This method can reduce the bit rate while preserving target object quality. Experimental comparison with HEVC demonstrates the superior performance of the proposed method.},
  archive      = {J_TETC},
  author       = {Kazuya Ogasawara and Tomo Miyazaki and Yoshihiro Sugaya and Shinichiro Omachi},
  doi          = {10.1109/TETC.2017.2695640},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {168-178},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Object-based video coding by visual saliency and temporal correlation},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Flexibility-enhanced HTS system for disaster management:
Responding to communication demand explosion in a disaster.
<em>TETC</em>, <em>8</em>(1), 159–167. (<a
href="https://doi.org/10.1109/TETC.2017.2688078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural disaster interrupts essential services due to the facility damage and lack of power supply. Especially, significant communication outages occurs in a wide area for hierarchical network such as cellular communication system in case core nodes are damaged or congested. In order to provide alternative communication ability, high throughput satellite (HTS) is one of the ideal candidates for disaster management because it provides operative communication for a wide area regardless of the availability of regular terrestrial infrastructures. However, conventional HTS relays data with predetermined beam bandwidth and connection, it is inefficient when the communication demand explodes in a disaster area. Therefore, this paper proposes novel frequency allocation technique with flexibility-enhanced HTS system for disaster management to respond to communication demand explosion. While related research works consider user-link resource allocation, this paper focuses on how to control feeder-link and user-link bandwidths in case that the both links can be assigned at continuous frequency such as Ka-band. Furthermore, our proposal addresses resilient satellite network by selecting optimum gateway based on the traffic demand at neighboring user-link beams. The effectiveness of our proposal is verified through simulation results.},
  archive      = {J_TETC},
  author       = {Shigenori Tani and Katsuyuki Motoyoshi and Hiroyasu Sano and Atsushi Okamura and Hiroki Nishiyama and Nei Kato},
  doi          = {10.1109/TETC.2017.2688078},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {159-167},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Flexibility-enhanced HTS system for disaster management: Responding to communication demand explosion in a disaster},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Earthquake prediction based on spatio-temporal data mining:
An LSTM network approach. <em>TETC</em>, <em>8</em>(1), 148–158. (<a
href="https://doi.org/10.1109/TETC.2017.2699169">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Earthquake prediction is a very important problem in seismology, the success of which can potentially save many human lives. Various kinds of technologies have been proposed to address this problem, such as mathematical analysis, machine learning algorithms like decision trees and support vector machines, and precursors signal study. Unfortunately, they usually do not have very good results due to the seemingly dynamic and unpredictable nature of earthquakes. In contrast, we notice that earthquakes are spatially and temporally correlated because of the crust movement. Therefore, earthquake prediction for a particular location should not be conducted only based on the history data in that location, but according to the history data in a larger area. In this paper, we employ a deep learning technique called long short-term memory (LSTM) networks to learn the spatio-temporal relationship among earthquakes in different locations and make predictions by taking advantage of that relationship. Simulation results show that the LSTM network with two-dimensional input developed in this paper is able to discover and exploit the spatio-temporal correlations among earthquakes to make better predictions than before.},
  archive      = {J_TETC},
  author       = {Qianlong Wang and Yifan Guo and Lixing Yu and Pan Li},
  doi          = {10.1109/TETC.2017.2699169},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {148-158},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Earthquake prediction based on spatio-temporal data mining: An LSTM network approach},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Detecting the dangerous area of toxic gases with wireless
sensor networks. <em>TETC</em>, <em>8</em>(1), 137–147. (<a
href="https://doi.org/10.1109/TETC.2017.2700358">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Petrochemical accidents, e.g., toxic gas leaking and explosion, result in serious damage, so the detection and visualization of the dangerous area of leaking toxic gases is an important research issue for large-scale petrochemical plants. There have been many efforts made to address this issue by using a large number of special monitoring devices. These special devices provide the gas concentration reports within their individual ranges. However, because of the continuity of gas diffusion and the invisibility of toxic gases, it is difficult to detect and visualize the continuous dangerous area of gas diffusion by only using the scattered concentration reports. This paper proposes a scheme to detect and visualize the dangerous area using Wireless Sensor Networks (WSNs). In this proposed scheme, a planarization algorithm is used to planarize a WSN, and based on the planarized network, the boundary area of gas diffusion is calculated to delimitate the dangerous area. This study also verifies the robustness of the proposed scheme in regards to the node failure. The node failure has a special kind of influence on the accuracy of dangerous area detection. This paper also analyzes the impact of 5 planarization algorithms on the accuracy of dangerous area detection.},
  archive      = {J_TETC},
  author       = {Lei Shu and Yuanfang Chen and Zhihong Sun and Fei Tong and Mithun Mukherjee},
  doi          = {10.1109/TETC.2017.2700358},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {137-147},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Detecting the dangerous area of toxic gases with wireless sensor networks},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Audio data mining for anthropogenic disaster identification:
An automatic taxonomy approach. <em>TETC</em>, <em>8</em>(1), 126–136.
(<a href="https://doi.org/10.1109/TETC.2017.2700843">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Disasters are undesirable and often sudden events causing human, material and economic losses, which exceed the coping capability of the affected community or society. In recent years, with significant advancement in information technology, various intelligent systems have been developed to support various aspects of disaster management, including emergency prediction, timely response and aftermath recovery. This paper addresses the anthropogenic disaster identification issue by exploiting ambient sound data. Specifically, a novel and efficient acoustic event classification scheme is proposed, which is based on unsupervised acoustic feature learning and data-driven taxonomy. The proposed framework could accurately identify anthropogenic disaster events, e.g., gun shot, explosion, scream cry, etc. from dynamic audio data. and it consists of three major stages as follows. First, predominant acoustic patterns are characterized by dictionary learning algorithms, which can generate robust acoustic feature representations for recognition under noisy conditions. Second, hazard sound event taxonomy is created by exploiting probabilistic distances between extracted class-wise dictionaries. Finally, taxonomy structure is embedded into hierarchical classification algorithm to improve event identification performance. The Proposed approach is evaluated using real-world dataset with 10 emergency sound categories and 3,275 clips. According to extensive experimental comparisons, proposed approach achieved state-of-the-art performance in anthropogenic disaster identification.},
  archive      = {J_TETC},
  author       = {Jiaxing Ye and Takumi Kobayashi and Xiaoyan Wang and Hiroshi Tsuda and Masahiro Murakawa},
  doi          = {10.1109/TETC.2017.2700843},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {126-136},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Audio data mining for anthropogenic disaster identification: An automatic taxonomy approach},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A disaster management-oriented path planning for mobile
anchor node-based localization in wireless sensor networks.
<em>TETC</em>, <em>8</em>(1), 115–125. (<a
href="https://doi.org/10.1109/TETC.2017.2687319">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The localization of sensor nodes is a significant issue in wireless sensor networks (WSNs) because many applications cannot provide services without geolocation data, especially during disaster management. In recent years, a promising unknown-nodes positioning method has been developed that localizes unknown nodes, employing a GPS-enabled mobile anchor node moving in the network, and broadcasting its location information periodically to assist localization. In contrast to most studies on path planning that assume infinite energy of the mobile anchor node, the anchor node in this study, consumes different amounts of energy during phases of startup, turning, and uniform motion considering the aftermath of disasters. To enable a trade-off between location accuracy and energy consumption, a path-planning algorithm combining a Localization algorithm with a Mobile Anchor node based on Trilateration (LMAT) and SCAN algorithm (SLMAT) is proposed. SLMAT ensures that each unknown node is covered by a regular triangle formed by beacons. Furthermore, the number of corners along the planned path is reduced to save the energy of the mobile anchor node. In addition, a series of experiments have been conducted to evaluate the performance of the SLMAT algorithm. Simulation results indicate that SLMAT outperforms SCAN, LMAT, HILBERT, and Z-curve in terms of localization accuracy and energy consumption.},
  archive      = {J_TETC},
  author       = {Guangjie Han and Xuan Yang and Li Liu and Wenbo Zhang and Mohsen Guizani},
  doi          = {10.1109/TETC.2017.2687319},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {115-125},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {A disaster management-oriented path planning for mobile anchor node-based localization in wireless sensor networks},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). ELDC: An artificial neural network based energy-efficient
and robust routing scheme for pollution monitoring in WSNs.
<em>TETC</em>, <em>8</em>(1), 106–114. (<a
href="https://doi.org/10.1109/TETC.2017.2671847">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The range of applications of Wireless Sensor Networks (WSNs) is increasing continuously despite of their serious constraints of the sensor nodes’ resources such as storage, processing capacity, communication range and energy. The main issues in WSN are the energy consumption and the delay in relaying data to the Sink node. This becomes extremely important when deploying a big number of nodes, like the case of industry pollution monitoring. We propose an artificial neural network based energy-efficient and robust routing scheme for WSNs called ELDC. In this technique, the network is trained on huge data set containing almost all scenarios to make the network more reliable and adaptive to the environment. Additionally, it uses group based methodology to increase the life-span of the overall network, where groups may have different sizes. An artificial neural network provides an efficient threshold values for the selection of a group&#39;s CN and a cluster head based on back propagation technique and allows intelligent, efficient, and robust group organization. Thus, our proposed technique is highly energy-efficient capable to increase sensor nodes’ lifetime. Simulation results show that it outperforms LEACH protocol by 42 percent, and other state-of-the-art protocols by more than 30 percent.},
  archive      = {J_TETC},
  author       = {Amjad Mehmood and Zhihan Lv and Jaime Lloret and Muhammad Muneer Umar},
  doi          = {10.1109/TETC.2017.2671847},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {106-114},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {ELDC: An artificial neural network based energy-efficient and robust routing scheme for pollution monitoring in WSNs},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Guest editor’s introduction: Special section on emerging
technologies for disaster management. <em>TETC</em>, <em>8</em>(1),
104–105. (<a href="https://doi.org/10.1109/TETC.2020.2973785">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The papers in this special section examine new and emerging technologies for disaster management. We live in a world in which natural and man-made disasters (such as earthquakes, hurricanes, terrorist attacks, and industrial accidents) often occur. These disasters are so sudden in nature, so causing loss of human lives and interruption of essential public services (such as health care, electricity, water, transportation and communication). Disaster management aims to reduce or avoid potential losses from hazards, ensure prompt and appropriate assistance to victims and achieve a rapid and effective recovery. In recent years, new computing/communication technologies have emerged to improve the efficiency of disaster management; for example, crowdsourcing has been applied in the Nepal earthquake to collect the latest information from earthquake-affected areas and create a dynamic map that shows the locations in which aid and relief are needed. Although some preliminary attempts have been made to apply emerging technologies for disaster management, there are many open challenges that need to be addressed to fully exploit the potentials of these promising technologies.},
  archive      = {J_TETC},
  author       = {Nei Kato and Song Guo},
  doi          = {10.1109/TETC.2020.2973785},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {104-105},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Guest editor&#39;s introduction: Special section on emerging technologies for disaster management},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Incentive scheme for cyber physical social systems based on
user behaviors. <em>TETC</em>, <em>8</em>(1), 92–103. (<a
href="https://doi.org/10.1109/TETC.2017.2671843">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyber-physical social system (CPSS) has emerged as a new paradigm to help social users share and exchange data by the close association with the cyberspace and physical world. To further improve the performance of CPSS, the incentive computing scheme to provide efficient crowd sourcing in the CPPS becomes a challenge. Therefore, in this paper we propose a novel incentive scheme for CPSS based on the reputation of social users. First, we present a framework to provide crowd sourcing service in CPSS by dividing social users into three types, which are malicious users, speculative users and honest users, respectively. Second, based on the reputation of social users, an incentive scheme is proposed to encourage users to contribute sourcing data. Next, an auction game model is developed to help CPSS select the optimal social user to obtain the needed data. Finally, simulation results show that the proposal can obtain a lower cost and higher data accuracy than other conventional methods.},
  archive      = {J_TETC},
  author       = {Zhou Su and Qifan Qi and Qichao Xu and Song Guo and Xiaowei Wang},
  doi          = {10.1109/TETC.2017.2671843},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {92-103},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Incentive scheme for cyber physical social systems based on user behaviors},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Service composition in cyber-physical-social systems.
<em>TETC</em>, <em>8</em>(1), 82–91. (<a
href="https://doi.org/10.1109/TETC.2017.2675479">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyber-physical-social systems comprise physical, cyber, and social worlds with various resources as services. The operation and configuration of these services require service composition approaches that can be used to integrate essential components in these worlds, and organize and share relevant information as needed. Although the present service-oriented architecture can effectively support service composition, there still exist many challenges such as high time cost and low reliability for cyber-physical-social systems. In this paper, we propose a fast and reliable service composition approach to integrate the physical network, cyberspace, and social network. In this approach, first, skyline component computation is performed to reduce the solution space; then, the coefficient of variation is employed to filter the components with high quality of service (QoS) fluctuation and finally the best optimal components are selected by maximizing the fitness function based on users&#39; end-to-end QoS requirements. We applied our approach to real-world dataset and the results showed that our proposed approach has better reliability as well as lower time cost than other approaches.},
  archive      = {J_TETC},
  author       = {Shangguang Wang and Ao Zhou and Mingzhe Yang and Lei Sun and Ching-Hsien Hsu and Fangchun Yang},
  doi          = {10.1109/TETC.2017.2675479},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {82-91},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Service composition in cyber-physical-social systems},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Tensor-based multiple clustering approaches for
cyber-physical-social applications. <em>TETC</em>, <em>8</em>(1), 69–81.
(<a href="https://doi.org/10.1109/TETC.2018.2801464">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multiple analysis tasks and personalized services, tremendous challenges in Cyber-Physical-Social Systems (CPSS) are clustering large-scale multi-source data and generating multiple distinct clusterings dependent on different applications. To address these challenges, this paper first presents two simple multiple clustering methods which can produce different clustering results according to arbitrarily selected combinations of features, one is similarity matrices-based multiple clusterings which computes the weighted average of similarity matrices for selected feature spaces, another is Euclidean distance-based multiple clusterings which fuses different feature spaces using selective weighted Euclidean distance. Furthermore, a tensor decomposition-based multiple clusterings is presented for efficiently clustering high-dimensional data, and a multi-relational attribute ranking method is further proposed to improve the clustering performance. This paper illustrates and evaluates the proposed methods on a design example and a real world data set. Experimental results show that the proposed methods can effectively cluster big data to provide enhanced knowledge extractions and services in CPSS.},
  archive      = {J_TETC},
  author       = {Yaliang Zhao and Laurence T. Yang and Ronghao Zhang},
  doi          = {10.1109/TETC.2018.2801464},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {69-81},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Tensor-based multiple clustering approaches for cyber-physical-social applications},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A triangular NodeTrix visualization interface for
overlapping social community structures of cyber-physical-social systems
in smart factories. <em>TETC</em>, <em>8</em>(1), 58–68. (<a
href="https://doi.org/10.1109/TETC.2017.2671846">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work proposes a cyber-physical-social system (CPSS) framework for smart factories which associates the social-network-based physical factory circumference with the cyber control through a visualization interface based on NodeTrix. The NodeTrix representation consisting of adjacency matrices and node-link diagrams has been popularly used in social network analysis. Different from previous works on NodeTrix based on square-shaped matrices, the proposed NodeTrix applies triangle-shaped matrices for visualizing overlapping communities to save the displaying space, and a simulated annealing algorithm is used to reduce the crossings among links and communities. In the CPSS for smart factories, working-in-process (WIP) products are categorized according to their attributes, and are placed at different storage locations for later different production processes. By the NodeTrix-based interface for CPSS, when users with different domains and experiences work together to make instant decisions on production and logistics, the physical production environment will be adjusted accordingly and immediately through technological support of Industry 4.0. Through the interface, the information on locations, parameters, and interoperability of WIP products can be visualized and adjusted in time. By comparison with other works, the proposed representation looks promising in displaying social networks for the CPSS with fewer crossings within a smaller screen space.},
  archive      = {J_TETC},
  author       = {Chun-Cheng Lin and Der-Jiunn Deng and Shun-Yu Jhong},
  doi          = {10.1109/TETC.2017.2671846},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {58-68},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {A triangular NodeTrix visualization interface for overlapping social community structures of cyber-physical-social systems in smart factories},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Human behavior aware energy management in residential
cyber-physical systems. <em>TETC</em>, <em>8</em>(1), 45–57. (<a
href="https://doi.org/10.1109/TETC.2017.2680322">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Technological advancements, such as smart appliances, have enabled residential buildings to become a true Cyber-Physical System (CPS), where the devices correspond to the physical system and the smart computation and control mechanisms define the cyber part. An important aspect of these residential cyber-physical systems is their large portion of the overall energy consumption in the electric grid. Researchers have proposed several methods to address the issue, targeting to reduce both the consumption and the cost associated with it, either individually or simultaneously. These methods include using renewable energy sources, energy storage devices, efficient control methods to maximize the benefits of these resources, and smart appliance rescheduling. However, a residential CPS, different than a common CPS, has a lot of direct human interaction within the system. Although the previous residential energy management methods are effective, they do not consider the inherent and dominant human factor. This paper develops a human-behavior-centric smart appliance rescheduling method for a residential neighborhood. We first show an accurate representation of the relationship between the activities of the household members and the power demand of the house. We use this model to efficiently generate several power profiles based on different household characteristics. Then, we formally model how flexible users are when rescheduling appliances. In contrast to previous studies, our work is able to capture the intrinsic human behavior related decisions and actions when automating the residential energy consumption. Our results show 16 percent energy savings and 22 percent reduction in peak power relative to the case without appliance rescheduling while accurately representing and meeting human-related constraints. We also demonstrate that ignoring human preferences can lead to up to more than 90 percent violation of user deadlines.},
  archive      = {J_TETC},
  author       = {Baris Aksanli and Tajana Simunic Rosing},
  doi          = {10.1109/TETC.2017.2680322},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {45-57},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Human behavior aware energy management in residential cyber-physical systems},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A prototype model to predict human interest: Data based
design to combine humans and machines. <em>TETC</em>, <em>8</em>(1),
31–44. (<a href="https://doi.org/10.1109/TETC.2017.2686487">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the possibility of quantifying a person&#39;s interest using data-driven algorithms is investigated. In doing so, interest estimation problem is formulated as a latent state estimation problem, and an answer is deduced via Bayesian Inference. First, a Subjective-Objective approach is used to measure activity. Through this calculated activity, the method indirectly infers human latent state values. A formulation of interest is then presented by drawing inspiration from the Ornstein-Uhlenbeck (OU) process in Physics. Moreover, concepts of stochastic volatility are employed to vary the instantaneous volatility of the OU process. This is done to further improve the performance. Subsequently, the convergence speed of the OU process is varied with time. A novel statistical framework is discussed that dynamically transforms interest into activity. Each of these individual contributions is combined to present a solution via Monte Carlo Simulations. To demonstrate the efficacy of the proposed method, numerical simulations are performed on real datasets. Lastly, a prototype is engineered and the method is implemented as a RESTful Web service. The prototype is hosted as a Web service on several Virtual Machines to demonstrate the practical feasibility of the framework in cloud-based deployment scenarios.},
  archive      = {J_TETC},
  author       = {Tanveer Ahmed and Abhishek Srivastava},
  doi          = {10.1109/TETC.2017.2686487},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {31-44},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {A prototype model to predict human interest: Data based design to combine humans and machines},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). High performance computing for cyber physical social systems
by using evolutionary multi-objective optimization algorithm.
<em>TETC</em>, <em>8</em>(1), 20–30. (<a
href="https://doi.org/10.1109/TETC.2017.2703784">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyber-physical social systems (CPSS) is an emerging complicated topic which is a combination of cyberspace, physical space, and social space. Many problems in CPSS can be mathematically modelled as optimization problems, and some of them are multi-objective optimization (MOO) problems (MOPs). In general, the MOPs are difficult to solve by traditional mathematical programming methods. High performance computing with much faster speed is required to address these issues. In this paper, a kind of high performance computing approaches, evolutionary multi-objective optimization (EMO) algorithms, is used to deal with these MOPs. A floorplanning case study is presented to demonstrate the feasibility of our proposed approach. B*-tree and a multistep simulated annealing (MSA) algorithm are cooperatively used to solve this case. As per experimental results for this case, the proposed method is well capable of searching for feasible floorplan solutions, and it can reach 74.44 percent (268/360) success rates for floorplanning problems.},
  archive      = {J_TETC},
  author       = {Gai-Ge Wang and Xingjuan Cai and Zhihua Cui and Geyong Min and Jinjun Chen},
  doi          = {10.1109/TETC.2017.2703784},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {20-30},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {High performance computing for cyber physical social systems by using evolutionary multi-objective optimization algorithm},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A programming model for hybrid collaborative adaptive
systems. <em>TETC</em>, <em>8</em>(1), 6–19. (<a
href="https://doi.org/10.1109/TETC.2017.2702578">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hybrid Diversity-aware Collective Adaptive Systems (HDA-CAS) are a new generation of socio-technical systems where both human and machine peers collectively participate in complex cognitive and physical tasks. These systems are characterized by the fundamental properties of hybridity and collectiveness, hiding from users the complexities associated with managing the collaboration and coordination of human-machine teams. The SmartSociety platform is a set of integrated software components that jointly provide a number of advanced HDA-CAS functionalities. As part of the CAS initiative, we have developed a programming model and Java APIs that make the use of those functionalities easy and accessible to application developers. In this paper we present the SmartSociety programming model elements, including the principal contributions - Collectives and Collective-based Tasks. We describe and discuss their functionality, implementation and runtime environment. Finally, we qualitatively evaluate the programming model and the language constructs with respect to the desired HDA-CAS properties.},
  archive      = {J_TETC},
  author       = {Ognjen Scekic and Tommaso Schiavinotto and Svetoslav Videnov and Michael Rovatsos and Hong-Linh Truong and Daniele Miorandi and Schahram Dustdar},
  doi          = {10.1109/TETC.2017.2702578},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {6-19},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {A programming model for hybrid collaborative adaptive systems},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Guest editorial: Special section on cyber-physical social
systems—integrating human into computing. <em>TETC</em>, <em>8</em>(1),
4–5. (<a href="https://doi.org/10.1109/TETC.2019.2934339">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The papers in this special section examine the human factors integration of cyber-physical social systems in computer applications. Human factors are becoming increasingly important in computing systems. A cyber-physical social system (CPSS), which incorporates human factors, encompasses not only cyberspace and physical world, but also human knowledge, mental capacity, and sociocultural elements. Rapid developments in cloud computing, smart grid, autonomous automotive systems, medical monitoring, process control systems, distributed robotics, and mobile networks are instigating a new paradigm shift in CPSS architectures, platforms and services by bringing improvement not only to the performance but also to the user experience in terms of the energy efficiency, reliability, security, and cost efficiency with human factors. The integration of cyber-physical systems and human social behaviors also provides a good opportunity to address challenges in human-centric technology development by using advanced technologies such as social computing, social system, and social networking.},
  archive      = {J_TETC},
  author       = {Mianxiong Dong and Nirwan Ansari},
  doi          = {10.1109/TETC.2019.2934339},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {4-5},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Guest editorial: Special section on cyber-physical social Systems—Integrating human into computing},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Thank-you state of the journal editorial by the 2019
outgoing (acting) editor-in-chief. <em>TETC</em>, <em>8</em>(1), 3. (<a
href="https://doi.org/10.1109/TETC.2020.2964356">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Presents the editorial for this issue of the publication.},
  archive      = {J_TETC},
  author       = {Paolo Montuschi},
  doi          = {10.1109/TETC.2020.2964356},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {3},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Thank-you state of the journal editorial by the 2019 outgoing (Acting) editor-in-chief},
  volume       = {8},
  year         = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
