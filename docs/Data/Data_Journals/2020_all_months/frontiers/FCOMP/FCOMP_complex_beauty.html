<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>FCOMP_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="fcomp---56">FCOMP - 56</h2>
<ul>
<li><details>
<summary>
(2020). Evaluation of the skeleton avatar technique for assessment
of mobility and balance among older adults. <em>FCOMP</em>, <em>2</em>,
601271. (<a href="https://doi.org/10.3389/fcomp.2020.601271">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background: Mobility and balance is essential for older adults&#39; well-being and independence and the ability to maintain physically active. Early identification of functional impairment may enable early risk-of-fall assessments and preventive measures. There is a need to find new solutions to assess functional ability in easy, efficient, and accurate ways, which can be clinically used frequently and repetitively. Therefore, we need to understand how functional tests and expert assessments (EAs) correlate with new techniques.Objective: To explore whether the skeleton avatar technique (SAT) can predict the results of functional tests (FTs) of mobility and balance: Timed Up and Go (TUG), the 30-s chair stand test (30sCST), the 4-stage balance test (4SBT), and EA scoring of movement quality.Methods: Fifty-four older adults (+65 years) were recruited through pensioners&#39; associations. The test procedure contained three standardized FTs: TUG, 30sCST, and 4SBT. The test performances were recorded using a three-dimensional SAT camera. EA scoring was performed based on the video recordings of the 30sCST. Functional ability scores were aggregated from balance and mobility scores. Probability theory-based statistical analyses were used on the data to aggregate sets of individual variables into scores, with correlation analysis used to assess the dependency between variables and between scores. Machine learning techniques were used to assess the appropriateness of easily observable variables/scores as predictors of the other variables included.Results: The results indicate that SAT data of the fourth 4SBT stage could be used to predict the aggregated results of all stages of 4SBT (with 7.82% mean absolute error), the results of the 30sCST (11.0%), the TUG test (8.03%), and the EA of the sit-to-stand movement (8.79%). There is a moderate (significant) correlation between the 30sCST and the 4SBT (0.31, p = 0.03), but not between the EA and the 30sCST.Conclusion: SAT can predict the results of the 4SBT, the 30sCST (moderate accuracy), and the TUG test and might add important qualitative information to the assessment of movement performance in active older adults. SAT might in the future provide the means for a simple, easy, and accessible assessment of functional ability among older adults.},
  archive      = {J_FCOMP},
  author       = {Backåberg, Sofia and Hellström, Amanda and Fagerström, Cecilia and Halling, Anders and Lincke, Alisa and Löwe, Welf and Ekstedt, Mirjam},
  doi          = {10.3389/fcomp.2020.601271},
  journal      = {Frontiers in Computer Science},
  month        = {12},
  pages        = {601271},
  shortjournal = {Front. Comput. Sci.},
  title        = {Evaluation of the skeleton avatar technique for assessment of mobility and balance among older adults},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Together we can make it work! Toward a design framework for
inclusive and participatory city-making of playable cities.
<em>FCOMP</em>, <em>2</em>, 600654. (<a
href="https://doi.org/10.3389/fcomp.2020.600654">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Making it work together can be challenging when various stakeholders are involved. Given the context of neighborhoods and cities specifically, stakeholders values and interests are not always aligned. In these settings, to construct long-term and sustaining participatory city-making projects, to make it work together, is demanding. To address this challenge, this paper proposes a design framework for inclusive and participatory city-making. This framework is inspired by the playable city perspective in that it endorses an open, exploratory, and interactive mindset of city actors. An extensive literature review on approaches taken for playful and participatory interventions in local communities provides the foundations for the framework. The review brings forward four pillars on which the framework is grounded and four activities for exploration of the design space for participatory city-making. A case study from The Hague (NL) is used to demonstrate how the framework can be applied to design and analyze processes in which city stakeholders together make it work. The case study analysis complements the framework with various research methods to support researchers, urban planners, and designers to engage with all city stakeholders to create playful and participatory interventions, which are inclusive and meaningful for the local community. The research contributions of this paper are the proposed framework and informed suggestions on how this framework in practice assists city stakeholders to together make it work.},
  archive      = {J_FCOMP},
  author       = {Slingerland, Geertje and Lukosch, Stephan and Hengst, Mariëlle den and Nevejan, Caroline and Brazier, Frances},
  doi          = {10.3389/fcomp.2020.600654},
  journal      = {Frontiers in Computer Science},
  month        = {12},
  pages        = {600654},
  shortjournal = {Front. Comput. Sci.},
  title        = {Together we can make it work! toward a design framework for inclusive and participatory city-making of playable cities},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Increasing interpretability of bayesian probabilistic
programming models through interactive representations. <em>FCOMP</em>,
<em>2</em>, 567344. (<a
href="https://doi.org/10.3389/fcomp.2020.567344">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian probabilistic modeling is supported by powerful computational tools like probabilistic programming and efficient Markov Chain Monte Carlo (MCMC) sampling. However, the results of Bayesian inference are challenging for users to interpret in tasks like decision-making under uncertainty or model refinement. Decision-makers need simultaneous insight into both the model&#39;s structure and its predictions, including uncertainty in inferred parameters. This enables better assessment of the risk overall possible outcomes compatible with observations and thus more informed decisions. To support this, we see a need for visualization tools that make probabilistic programs interpretable to reveal the interdependencies in probabilistic models and their inherent uncertainty. We propose the automatic transformation of Bayesian probabilistic models, expressed in a probabilistic programming language, into an interactive graphical representation of the model&#39;s structure at varying levels of granularity, with seamless integration of uncertainty visualization. This interactive graphical representation supports the exploration of the prior and posterior distribution of MCMC samples. The interpretability of Bayesian probabilistic programming models is enhanced through the interactive graphical representations, which provide human users with more informative, transparent, and explainable probabilistic models. We present a concrete implementation that translates probabilistic programs to interactive graphical representations and show illustrative examples for a variety of Bayesian probabilistic models.},
  archive      = {J_FCOMP},
  author       = {Taka, Evdoxia and Stein, Sebastian and Williamson, John H.},
  doi          = {10.3389/fcomp.2020.567344},
  journal      = {Frontiers in Computer Science},
  month        = {12},
  pages        = {567344},
  shortjournal = {Front. Comput. Sci.},
  title        = {Increasing interpretability of bayesian probabilistic programming models through interactive representations},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Focusing on emotional and social intelligence stimulation of
people with dementia by playing a serious game—proof of concept study.
<em>FCOMP</em>, <em>2</em>, 536880. (<a
href="https://doi.org/10.3389/fcomp.2020.536880">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Context: Dementia is one of the top five chronic diseases, which has an overwhelming impact on patients&#39; life quality, family, and caregivers. Currently, research relating to people with dementia (PwD) focuses on the deterioration of cognitive abilities. A more innovative approach, and the one taken by this paper, is focusing on methods to maintain and improve functionality, communication and quality of life of PwD by building on remaining capacities in the yet unexplored domain of emotional and social intelligence (ESI). The use of serious games for PwD (SG4D) aimed at building social and emotional capacity is a budding field of research.Objectives: Proof of concept that the, low cost, easy to deploy SG4D, called “My Brain Works” (MBW), co-designed with PwD, enhances ESI, based on the Bar-On ESI model.Methods: 27 PwD, clients at MELABEV dementia day center, participated in a mixed methods 12 weeks pilot, proof of concept study using a tablet SG4D co-designed with PwD. Quantitative performance data was collected automatically by the tablet during game sessions. In this paper we focus on the analysis of the qualitative and quantitative data related to ESI, observed by 10 different researchers, during each game session.Results: Quantitative data revealed: both the PwD with high and low MoCA scores had similar average ESI scores. Qualitative analysis revealed that the PwD demonstrated 9 sub-components of the Bar-On ESI Model.Conclusion: While there is no drug to stop cognitive decline associated with dementia, interventions related to ESI, on the other hand, may improve functioning and quality of life. Despite declines in cognitive abilities, our study shows that a tablet based SG4D can stimulate their ESI and evoke responses in self-awareness, empathy, social and communication capacities. Using SG4D to exercise and maintain social skills is an area that may be promising in the future and may help counter the negative effects of social isolation and loneliness. Such games, while not focusing on cognitive improvement, may also impact on cognitive functioning and help bridge the gap between caregiver and PwD. More research is needed with larger sample sizes.},
  archive      = {J_FCOMP},
  author       = {Berenbaum, Rakel and Tziraki, Chariklia and Baum, Reem and Rosen, Adi and Reback, Tuvia and Abikhzer, Judith and Naparstek, Daphna and Ben-David, Boaz M.},
  doi          = {10.3389/fcomp.2020.536880},
  journal      = {Frontiers in Computer Science},
  month        = {12},
  pages        = {536880},
  shortjournal = {Front. Comput. Sci.},
  title        = {Focusing on emotional and social intelligence stimulation of people with dementia by playing a serious Game—Proof of concept study},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Analysis techniques for illicit bitcoin transactions.
<em>FCOMP</em>, <em>2</em>, 600596. (<a
href="https://doi.org/10.3389/fcomp.2020.600596">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This comprehensive overview of analysis techniques for illicit Bitcoin transactions addresses both technical, machine learning approaches as well as a non-technical, legal, and governance considerations. We focus on the field of ransomware countermeasures to illustrate our points.},
  archive      = {J_FCOMP},
  author       = {Turner, Adam Brian and McCombie, Stephen and Uhlmann, Allon J.},
  doi          = {10.3389/fcomp.2020.600596},
  journal      = {Frontiers in Computer Science},
  month        = {11},
  pages        = {600596},
  shortjournal = {Front. Comput. Sci.},
  title        = {Analysis techniques for illicit bitcoin transactions},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Implementation and transfer of predictive analytics for
smart maintenance: A case study. <em>FCOMP</em>, <em>2</em>, 578469. (<a
href="https://doi.org/10.3389/fcomp.2020.578469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart maintenance offers a promising potential to increase efficiency of the maintenance process, leading to a reduction of machine downtime and thus an overall productivity increase in industrial manufacturing. By applying fault detection and prediction algorithms to machine and sensor data, maintenance measures (i.e., planning of human resources, materials and spare parts) can be better planned and thus machine stoppage can be prevented. While many examples of Predictive Maintenance (PdM) have been proven successful and commercial solutions are offered by machine and part manufacturers, wide-spread implementation of Smart Maintenance solutions and processes in industrial production is still not observed. In this work, we present a case study motivated by a typical maintenance activity in an industrial plant. The paper focuses on the crucial aspects of each phase of the PdM implementation and deployment process, toward the holistic integration of the solution within a company. A concept is derived for the model transfer to a different factory. This is illustrated by practical examples from a lighthouse factory within the BOOST 4.0 project. The quantitative impact of the deployed solutions is described. Based on empirical results, best practices are derived in the domain and data understanding, the implementation, integration and model transfer phases.},
  archive      = {J_FCOMP},
  author       = {von Enzberg, Sebastian and Naskos, Athanasios and Metaxa, Ifigeneia and Köchling, Daniel and Kühn, Arno},
  doi          = {10.3389/fcomp.2020.578469},
  journal      = {Frontiers in Computer Science},
  month        = {11},
  pages        = {578469},
  shortjournal = {Front. Comput. Sci.},
  title        = {Implementation and transfer of predictive analytics for smart maintenance: A case study},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A systematic review of personalized collaborative systems.
<em>FCOMP</em>, <em>2</em>, 562679. (<a
href="https://doi.org/10.3389/fcomp.2020.562679">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalization, aiming at supporting users individually, according to their individual needs and prerequisites, has been discussed in a number of domains including learning, search, or information retrieval. In the field of human–computer interaction, personalization also bears high potential as users might exhibit varying and strongly individual preferences and abilities related to interaction. For instance, there is a good amount of work on personalized or adaptive user interfaces (also under the notion of intelligent user interfaces). Personalized human–computer interaction, however, does not only subsume approaches to support the individual user, it also bears high potential if applied to collaborative settings, for example, through supporting the individuals in a group as well as the group itself (considering all of its special dynamics). In collaborative settings (remote or co-located), there generally is a number of additional challenges related to human-to-human collaboration in a group, such as group communication, awareness or territoriality, device or software tool selection, or selection of collaborators. Personalized Collaborative Systems thus attempt to tackle many of these challenges. For instance, there are collaborative systems that recommend tools, content, or team constellations. Such systems have been suggested in different domains and different collaborative settings and contexts. In most cases, these systems explicitly focus on a certain aspect of personalized collaboration support (such as team composition). This article provides a broader, concise overview of existing approaches to Personalized Collaborative Systems based on a systematic literature review considering the ACM Digital Library.},
  archive      = {J_FCOMP},
  author       = {Neumayr, Thomas and Augstein, Mirjam},
  doi          = {10.3389/fcomp.2020.562679},
  journal      = {Frontiers in Computer Science},
  month        = {11},
  pages        = {562679},
  shortjournal = {Front. Comput. Sci.},
  title        = {A systematic review of personalized collaborative systems},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cognitive style and information visualization—modeling users
through eye gaze data. <em>FCOMP</em>, <em>2</em>, 562290. (<a
href="https://doi.org/10.3389/fcomp.2020.562290">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information visualizations can be regarded as one of the most powerful cognitive tools to significantly amplify human cognition. However, traditional information visualization systems have been designed in a manner that does not consider individual user differences, even though human cognitive abilities and styles have been shown to differ significantly. In order to address this research gap, novel adaptive systems need to be developed that are able to (1) infer individual user characteristics and (2) provide an adaptation mechanism to personalize the system to the inferred characteristic. This paper presents a first step toward this goal by investigating the extent to which a user&#39;s cognitive style can be inferred from their behavior with an information visualization system. In particular, this paper presents a series of experiments that utilize features calculated from user eye gaze data in order to infer a user&#39;s cognitive style. Several different data and feature sets are presented, and results overall show that a user&#39;s eye gaze data can be used successfully to infer a user&#39;s cognitive style during information visualization usage.},
  archive      = {J_FCOMP},
  author       = {Steichen, Ben and Fu, Bo},
  doi          = {10.3389/fcomp.2020.562290},
  journal      = {Frontiers in Computer Science},
  month        = {11},
  pages        = {562290},
  shortjournal = {Front. Comput. Sci.},
  title        = {Cognitive style and information Visualization—Modeling users through eye gaze data},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Latent class and transition analysis of alzheimer’s disease
data. <em>FCOMP</em>, <em>2</em>, 551481. (<a
href="https://doi.org/10.3389/fcomp.2020.551481">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study uses independent latent class analysis (LCA) and latent transition analysis (LTA) to explore accurate diagnosis and disease status change of a big Alzheimer&#39;s disease Neuroimaging Initiative (ADNI) data of 2,132 individuals over a 3-year period. The data includes clinical and neural measures of controls (CN), individuals with subjective memory complains (SMC), early-onset mild cognitive impairment (EMCI), late-onset mild cognitive impairment (LMCI), and Alzheimer&#39;s disease (AD). LCA at each time point yielded 3 classes: Class 1 is mostly composed of individuals from CN, SMC, and EMCI groups; Class 2 represents individuals from LMCI and AD groups with improved scores on memory, clinical, and neural measures; in contrast, Class 3 represents LMCI and from AD individuals with deteriorated scores on memory, clinical, and neural measures. However, 63 individuals from Class 1 were diagnosed as AD patients. This could be misdiagnosis, as their conditional probability of belonging to Class 1 (0.65) was higher than that of Class 2 (0.27) and Class 3 (0.08). LTA results showed that individuals had a higher probability of staying in the same class over time with probability &amp;gt;0.90 for Class 1 and 3 and probability &amp;gt;0.85 for Class 2. Individuals from Class 2, however, transitioned to Class 1 from time 2 to time 3 with a probability of 0.10. Other transition probabilities were not significant. Lastly, further analysis showed that individuals in Class 2 who moved to Class 1 have different memory, clinical, and neural measures to other individuals in the same class. We acknowledge that the proposed framework is sophisticated and time-consuming. However, given the severe neurodegenerative nature of AD, we argue that clinicians should prioritize an accurate diagnosis. Our findings show that LCA can provide a more accurate prediction for classifying and identifying the progression of AD compared to traditional clinical cut-off measures on neuropsychological assessments.},
  archive      = {J_FCOMP},
  author       = {Alashwal, Hany and Diallo, Thierno M. O. and Tindle, Richard and Moustafa, Ahmed A.},
  doi          = {10.3389/fcomp.2020.551481},
  journal      = {Frontiers in Computer Science},
  month        = {11},
  pages        = {551481},
  shortjournal = {Front. Comput. Sci.},
  title        = {Latent class and transition analysis of alzheimer&#39;s disease data},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). I can feel it moving: Science communicators talking about
the potential of mid-air haptics. <em>FCOMP</em>, <em>2</em>, 534974.
(<a href="https://doi.org/10.3389/fcomp.2020.534974">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We explored the potential of haptics for improving science communication, and recognized that mid-air haptic interaction supports public engagement with science in three relevant themes. While science instruction often focuses on the cognitive domain of acquiring new knowledge, in science communication the primary goal is to produce personal responses, such as awareness, enjoyment, or interest in science. Science communicators seek novel ways of communicating with the public, often using new technologies to produce personal responses. Thus, we explored how mid-air haptics technology could play a role in communicating scientific concepts. We prototyped six mid-air haptic probes for three thematic areas: particle physics, quantum mechanics, cell biology; and conducted three qualitative focus group sessions with domain expert science communicators. Participants highlighted values of the dynamic features of mid-air haptics, its ability to produce shared experiences, and its flexibility in communicating scientific concepts through metaphors and stories. We discuss how mid-air haptics can complement existing approaches of science communication, for example multimedia experiences or live exhibits by helping to create enjoyment or interest, generalized to any fields of science.},
  archive      = {J_FCOMP},
  author       = {Hajas, Daniel and Ablart, Damien and Schneider, Oliver and Obrist, Marianna},
  doi          = {10.3389/fcomp.2020.534974},
  journal      = {Frontiers in Computer Science},
  month        = {11},
  pages        = {534974},
  shortjournal = {Front. Comput. Sci.},
  title        = {I can feel it moving: Science communicators talking about the potential of mid-air haptics},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Ontology-based context modeling in physical asset integrity
management. <em>FCOMP</em>, <em>2</em>, 578673. (<a
href="https://doi.org/10.3389/fcomp.2020.578673">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Asset management is concerned with the management practices, technologies and tools necessary to maximize the value delivered by physical engineering assets. IoT-generated data are increasingly considered as an asset and the data asset value needs to be maximized too. However, asset-generated data in practice are often collected in non-actionable form. Collected data may comprise a wide number of parameters, over long periods of time and be of significant scale. Yet they may fail to represent the range of possible scenarios of asset operation or the causal relationships between the monitored parameters, and so the size of the data collection, while adding to the complexity of the problem, does not necessarily allow direct data asset value exploitation. One way to handle data complexity is to introduce context information modeling and management, wherein data and service delivery are determined upon resolving the apparent context of a service or data request. The aim of the present paper is, therefore, 2-fold: to analyse current approaches to addressing IoT context information management, mapping how context-aware computing addresses key challenges and supports the delivery of monitoring solutions; and to develop a maintenance context ontology focused on failure analysis of mechanical components so as to drive monitoring services adaptation. The approach is demonstrated by applying the ontology on an industrially relevant physical gearbox test rig, designed to model complex misalignment cases met in manufacturing and aerospace applications.},
  archive      = {J_FCOMP},
  author       = {Al-Shdifat, Ali and Emmanouilidis, Christos and Khan, Muhammad and Starr, Andrew G.},
  doi          = {10.3389/fcomp.2020.578673},
  journal      = {Frontiers in Computer Science},
  month        = {10},
  pages        = {578673},
  shortjournal = {Front. Comput. Sci.},
  title        = {Ontology-based context modeling in physical asset integrity management},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Extraction of hierarchical behavior patterns using a
non-parametric bayesian approach. <em>FCOMP</em>, <em>2</em>, 546917.
(<a href="https://doi.org/10.3389/fcomp.2020.546917">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extraction of complex temporal patterns, such as human behaviors, from time series data is a challenging yet important problem. The double articulation analyzer has been previously proposed by Taniguchi et al. to discover a hierarchical structure that leads to complex temporal patterns. It segments time series into hierarchical state subsequences, with the higher level and the lower level analogous to words and phonemes, respectively. The double articulation analyzer approximates the sequences in the lower level by linear functions. However, it is not suitable to model real behaviors since such a linear function is too simple to represent their non-linearity even after the segmentation. Thus, we propose a new method that models the lower segments by fitting autoregressive functions that allows for more complex dynamics, and discovers a hierarchical structure based on these dynamics. To achieve this goal, we propose a method that integrates the beta process—autoregressive hidden Markov model and the double articulation by nested Pitman-Yor language model. Our results showed that the proposed method extracted temporal patterns in both low and high levels from synthesized datasets and a motion capture dataset with smaller errors than those of the double articulation analyzer.},
  archive      = {J_FCOMP},
  author       = {Briones, Jeric and Kubo, Takatomi and Ikeda, Kazushi},
  doi          = {10.3389/fcomp.2020.546917},
  journal      = {Frontiers in Computer Science},
  month        = {10},
  pages        = {546917},
  shortjournal = {Front. Comput. Sci.},
  title        = {Extraction of hierarchical behavior patterns using a non-parametric bayesian approach},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). “HIIT” the ExerCube: Comparing the effectiveness of
functional high-intensity interval training in conventional
vs. Exergame-based training. <em>FCOMP</em>, <em>2</em>, 531554. (<a
href="https://doi.org/10.3389/fcomp.2020.00033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regular physical activity is crucial for a physically and mentally healthy lifestyle. Training methods such as high-intensity interval training (HIIT) have become increasingly popular as they enable substantial training effects in little time. HIIT typically involves recurring short phases of close-to-maximal exercise intensity, interspersed with low-intensity recovery phases. Originally mainly practiced via uniformly repetitive movements, newer variations include varied functional and holistic exercises (fHIIT). While HIIT facilitates many health advantages, fHIIT is considered more beneficial since it activates more muscles, requires more coordination, strength and balance, and mimics more natural movements which transfer well to daily life. However, fHIIT is a very intense training approach; it requires strong focus and intrinsic motivation to frequently push beyond perceived physical and mental limits. This is a common barrier to exploiting the full potential of this efficient training method. Exergames may facilitate this kind of training due to their playful, immersive, motivating nature. Yet so far, few studies have investigated HIIT-exergames – no fHIIT-exergames. This is possibly because few exergames featured both (1) an effective training concept that is comparable to HIIT, and (2) an attractive and motivating game design. We believe that this lack of holistic integration of both aspects is partly why there is currently little evidence for long-term motivation and training effects in exergame-based training. Our work addresses this gap through the design of an adaptive fHIIT protocol for the ExerCube fitness game system, creating a HIIT-level functional exergame. We conducted a within-subjects study to compare objective and subjective training intensity induced by the ExerCube against a conventional fHIIT session with healthy young adults. Furthermore, we evaluated participants&#39; subjective experience with regards to motivation, flow, and enjoyment during both conditions. Our results contribute empirical evidence that exergames can induce HIIT-level intensity. While perceived physical exertion was slightly lower in the ExerCube condition, it yielded significantly better results for flow, enjoyment, and motivation. Moreover, the ExerCube seemed to enable a dual-domain training (higher cognitive load). We discuss these results in the context of exergame design for fHIIT, and provide practical suggestions covering topics such as safety precautions and physical-cognitive load balancing.},
  archive      = {J_FCOMP},
  author       = {Martin-Niedecken, Anna Lisa and Mahrer, Andrea and Rogers, Katja and de Bruin, Eling D. and Schättin, Alexandra},
  doi          = {10.3389/fcomp.2020.00033},
  journal      = {Frontiers in Computer Science},
  month        = {10},
  pages        = {531554},
  shortjournal = {Front. Comput. Sci.},
  title        = {“HIIT” the ExerCube: Comparing the effectiveness of functional high-intensity interval training in conventional vs. exergame-based training},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Technology facilitates physical activity through
gamification: A thematic analysis of an 8-week study. <em>FCOMP</em>,
<em>2</em>, 530309. (<a
href="https://doi.org/10.3389/fcomp.2020.530309">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gamification has enabled technology to facilitate behavior change through increasing the engagement and motivation of people in health and wellness domains. While research on physical activity (PA) and why older adults engage in PA exists, there are not many long-term studies on how gamification influences technology use and adherence to PA by older adults. We conducted a synchronous, 8-week, experimental study with older adults in the 50+ age group. Participants were randomized into three groups: Gamified technology, non-gamified technology and a control group. We conducted a weekly semi-structured interview with them focused on their PA motivations, setting up goals, accomplishments, fears or barriers, (immediate and long-term) rewards, and tracking in PA. Thematic analysis (TA) of the interview data showed these distinct variations in themes for the three groups over the 8-week period. This indicates that motivational affordances or gamification elements can be customized for older adults to suit their current health conditions and PA participation barriers. We define gamification design guidelines for PA motivation of older adults based on self-determination theory, setting up progressive goals, accomplishments to track PA quality, intangible rewards, and activity tracking.},
  archive      = {J_FCOMP},
  author       = {Kappen, Dennis L. and Mirza-Babaei, Pejman and Nacke, Lennart E.},
  doi          = {10.3389/fcomp.2020.530309},
  journal      = {Frontiers in Computer Science},
  month        = {10},
  pages        = {530309},
  shortjournal = {Front. Comput. Sci.},
  title        = {Technology facilitates physical activity through gamification: A thematic analysis of an 8-week study},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Meta-analysis of cross-language plagiarism and
self-plagiarism detection methods for russian-english language pair.
<em>FCOMP</em>, <em>2</em>, 523053. (<a
href="https://doi.org/10.3389/fcomp.2020.523053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scientists need to publish the results of their work to remain relevant and in demanded. The well-known principle of “publish or perish” often forces scientists to pursue an increase in quantity, not quality. Along with the problems of authorship, paid research, fabrication of results, plagiarism, and self-plagiarism are among the most common violations. Their impact is more subtle but no less destructive for the scientific community. Statistics show that the reuse of texts in different languages is very common in various studies. Identification of translated plagiarism is a complex task, and there are almost no such tools for this purpose on the Russian market now. In this article, we have provided an overview of the existing methods for the identification of cross-language borrowings in the scientific articles of the authors. We analyzed solutions by studying the works on various language pairs and paid the great attention to the Russian-English language pair.},
  archive      = {J_FCOMP},
  author       = {Tlitova, Alina and Toschev, Alexander and Talanov, Max and Kurnosov, Vitaliy},
  doi          = {10.3389/fcomp.2020.523053},
  journal      = {Frontiers in Computer Science},
  month        = {10},
  pages        = {523053},
  shortjournal = {Front. Comput. Sci.},
  title        = {Meta-analysis of cross-language plagiarism and self-plagiarism detection methods for russian-english language pair},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Digital twins and the emerging science of self: Implications
for digital health experience design and “small” data. <em>FCOMP</em>,
<em>2</em>, 516124. (<a
href="https://doi.org/10.3389/fcomp.2020.00031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The technology currently available for quantifying various biometric, behavioral, emotional, cognitive, and psychological aspects of daily life has become increasingly diverse, accurate, and accessible as a result of ongoing and continuous improvements. These burgeoning technologies can and will profoundly alter the way lifestyle, health, wellness, and chronic diseases are managed in the future. For those pursuing the potential of such digital technologies in the creation of a compelling and effective connected healthcare experience, a number of new concepts have surfaced. We have taken these concepts (many of which originate in engineering) and extended them so they can be incorporated into managing health risk and health conditions via a blended digital health experience. For example, the advent of mobile technology for health has given rise to concepts, such as ecological momentary assessment and ecological momentary intervention that assess the person&#39;s (digital twin) status and delivers interventions as needed, when needed—perhaps even preemptively. For such concepts to be fully realized, the experience design of mobile health (mHealth) program(s) (aka connected care) should and now can actually guide end users through a series of self-experiments directed by data-driven feedback from a version of their digital twin. As treatment development and testing move toward the precision of individual differences inherent in every person and every treatment response (or non-response), group data and more recent big data approaches for generating new knowledge offer limited help to end users (including practitioners) for helping individuals evaluate their own digital twin–generated data and change over time under different conditions. This is the renaissance of N-of-1 or individual science. N-of-1 evaluation creates the opportunity to evaluate each individual uniquely. The rigor and logic of N-of-1 designs have been well articulated and expanded upon for over a half century. For the clinician, this revitalized form of scientific and behavioral interaction evaluation can help validate or reject the impact a given treatment has for a given patient with increased efficiency and accuracy. Further, N-of-1 can incorporate biological (genomic), behavioral, psychological, and digital health data such that users themselves can begin to evaluate the relationships of their own treatment response patterns and the contingencies that impact them. Thus, emerges the self-scientist.},
  archive      = {J_FCOMP},
  author       = {Schwartz, Steven M. and Wildenhaus, Kevin and Bucher, Amy and Byrd, Brigid},
  doi          = {10.3389/fcomp.2020.00031},
  journal      = {Frontiers in Computer Science},
  month        = {10},
  pages        = {516124},
  shortjournal = {Front. Comput. Sci.},
  title        = {Digital twins and the emerging science of self: Implications for digital health experience design and “Small” data},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Physically inspired data compression and management for
industrial data analytics. <em>FCOMP</em>, <em>2</em>, 580768. (<a
href="https://doi.org/10.3389/fcomp.2020.00041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the huge and ever-growing volume of industrial data, an enormous challenge of how this data should be handled, stored, and analyzed emerges. In this paper, we describe a novel method that facilitates automated signal parsing into a set of exhaustive and mutually exclusive segments, which is coupled with extraction of physically interpretable signatures that characterize those segments. The resulting numerical signatures can be used to approximate a wide range of signals within some arbitrary accuracy, thus effectively turning the aforementioned signal parsing and signature extraction procedure into a signal compression process. This compression converts raw signals into physically plausible and interpretable features that can then be directly mined in order to extract useful information via anomaly detection and characterization, quality prediction, or process control. In addition, distance-based unsupervised clustering is utilized to organize the compressed data into a tree-structured database enabling rapid searches through the data and consequently facilitating efficient data mining. Application of the aforementioned methods to multiple large datasets of sensor readings collected from several advanced manufacturing plants showed the feasibility of physics-inspired compression of industrial data, as well as tremendous gains in terms of search speeds when compressed data were organized into a distance-based, tree-structured database.},
  archive      = {J_FCOMP},
  author       = {Sabbagh, Ramin and Cai, Zicheng and Stothert, Alec and Djurdjanovic, Dragan},
  doi          = {10.3389/fcomp.2020.00041},
  journal      = {Frontiers in Computer Science},
  month        = {9},
  pages        = {580768},
  shortjournal = {Front. Comput. Sci.},
  title        = {Physically inspired data compression and management for industrial data analytics},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Handling user-oriented cyber-attacks: STRIM, a user-based
security training model. <em>FCOMP</em>, <em>2</em>, 549917. (<a
href="https://doi.org/10.3389/fcomp.2020.00025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Privacy is an increasingly rare commodity. Once personal information is entered into a social network, it is no longer private. Such networks have become an incubation environment and carrier for cyber-attacks either by providing the necessary information about victims or facilitating the ways in which cyber-criminals can reach them. Social media create relationships and trust between individuals, but there is often no authority checking and validating user identities. This paper analyses different attack vectors examining the techniques used against end-users, who are targeted as a way of accessing larger organizations. It shows how the information that is disclosed to social networks can be transformed to provide insights about an organization, and the role of the victim in this process. These leaks not only expose users to the risk of cyber-attacks, but they also give attackers the opportunity to create personalized strategies that are difficult to avoid. This paper highlights these user-oriented attacks by first demonstrating the impact of disclosed information in the process of formulating an attack, in addition to group influence on an individual&#39;s vulnerability. Next, the various psychological manipulation factors and cognitive bias behind the user&#39;s failure to detect these attacks is demonstrated. This research introduces a theoretical user-based security training model called STRIM, which aims to educate and train users to detect, avoid, and report cyber-attacks in which they are the primary target. The proposed model is a solution to help organizations establish security-conscious behaviors among their employees.},
  archive      = {J_FCOMP},
  author       = {Hamoud, Aymen and Aïmeur, Esma},
  doi          = {10.3389/fcomp.2020.00025},
  journal      = {Frontiers in Computer Science},
  month        = {9},
  pages        = {549917},
  shortjournal = {Front. Comput. Sci.},
  title        = {Handling user-oriented cyber-attacks: STRIM, a user-based security training model},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A planning game over a map: Playing cards and moving bits to
collaboratively plan a city. <em>FCOMP</em>, <em>2</em>, 549898. (<a
href="https://doi.org/10.3389/fcomp.2020.00037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rational systemic planning and collaborative planning seem to be two conflicting approaches in spatial planning practice and research. However, some authors are trying to make them compliant through new approaches that are more human centered. Applying games to planning processes can be one of many solutions to consider. This article describes the process of developing an analog game session and the first test of this serious board game approach. This game approach began with modern board game design elements as a starting design base and was adapted for further developments in game-based planning processes, following the methods of serious games through the adaptation of the design, play, experience framework. The purpose of this game session is to create a simple and flexible tool to train students and future planners for the use of games in the development of collaborative urban planning processes, contributing to filling the gap created by the absence of simple and flexible games to use in daily planning practices.},
  archive      = {J_FCOMP},
  author       = {Sousa, Micael},
  doi          = {10.3389/fcomp.2020.00037},
  journal      = {Frontiers in Computer Science},
  month        = {9},
  pages        = {549898},
  shortjournal = {Front. Comput. Sci.},
  title        = {A planning game over a map: Playing cards and moving bits to collaboratively plan a city},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deriving a cortisol-related stress indicator from wearable
skin conductance measurements: Quantitative model &amp; experimental
validation. <em>FCOMP</em>, <em>2</em>, 536912. (<a
href="https://doi.org/10.3389/fcomp.2020.00039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to find a stress indicator that can be used to monitor stress with wearables, we compare the almost instantaneous effects of psychological stress on skin conductance, with the effects on the stress hormone cortisol, peaking about 20–30 min later. We modeled this relation deploying a convolution of the height of the skin conductance peaks with the cortisol stress response curve, and used it to determine a skin conductance-derived estimate of stress-induced cortisol. We then conducted a first experiment to validate this model, comparing the stress-induced cortisol estimates with cortisol as measured in saliva samples. Participants (N = 46) completed stressful, boring, and performance tasks in a controlled laboratory setting. Salivary cortisol samples were taken at regular moments. Based upon the pattern of measured salivary cortisol before and after the performed stressful task we divided subjects in high-cortisol responders and low-cortisol responders. For both groups, we found substantial correlations between the skin conductance-based stress-induced cortisol estimates and the measured salivary cortisol. In addition, the (Fisher-corrected) mean within-participant correlation between these variables was found to be 0.48, which proved to be significantly different from zero. These findings support the use of the skin conductance-based stress-induced cortisol estimates as a stress indicator reflecting in-body cortisol changes.},
  archive      = {J_FCOMP},
  author       = {Westerink, Joyce H. D. M. and Rajae-Joordens, Roos J. E. and Ouwerkerk, Martin and van Dooren, Marieke and Jelfs, Sam and Denissen, Ad J. M. and Penning de Vries, Eric and van Ee, Raymond},
  doi          = {10.3389/fcomp.2020.00039},
  journal      = {Frontiers in Computer Science},
  month        = {9},
  pages        = {536912},
  shortjournal = {Front. Comput. Sci.},
  title        = {Deriving a cortisol-related stress indicator from wearable skin conductance measurements: Quantitative model &amp;amp; experimental validation},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A taxonomy of coping strategies and discriminatory stressors
in digital gaming. <em>FCOMP</em>, <em>2</em>, 531738. (<a
href="https://doi.org/10.3389/fcomp.2020.00040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital gaming&#39;s many benefits starkly contradict its well-cited toxicity. To accurately understand and compare how players cope with discriminatory stress in the context of play, 241 US players were surveyed on recurring sources of discrimination during gameplay and strategies for coping across ranging experiential prompts. Qualitative analysis created a taxonomy of discriminatory targets, discriminatory acts, and coping strategies specific to online digital play. We compare experiences, perceptions, and beliefs around coping across intersections of race, gender, and class (with notes on ability and age) and describe how player identities inform in-game behavior and exposure to types of discrimination and how coping strategies are navigated. We discuss the accumulative, anticipatory, and intergenerational nature of discriminatory stress in gaming, its stratified effects on well-being, and the role of discrimination in belief formation as well as ability to advocate for oneself and others.},
  archive      = {J_FCOMP},
  author       = {Passmore, Cale J. and Mandryk, Regan L.},
  doi          = {10.3389/fcomp.2020.00040},
  journal      = {Frontiers in Computer Science},
  month        = {9},
  pages        = {531738},
  shortjournal = {Front. Comput. Sci.},
  title        = {A taxonomy of coping strategies and discriminatory stressors in digital gaming},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Effects of uncertainty visualization on map-based decision
making under time pressure. <em>FCOMP</em>, <em>2</em>, 564723. (<a
href="https://doi.org/10.3389/fcomp.2020.00032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of our daily activities in a highly mobile digital society require timely spatial decision-making. Much of such decision-making is supported by map displays on various devices with different modalities. Spatial information visualized on maps, however, is always subject to a multitude of uncertainties. If space-time decision-makers are not informed about potential uncertainties, misleading, or at worst, life-threatening outcomes might result from map-based decisions. Therefore, data uncertainties should be communicated to decision-makers, especially when they are made with limited time resources and when decision outcomes can have dramatic consequences. Thus, the current study investigates how data uncertainty visualized in maps might influence the process and outcomes of spatial decision-making, especially when made under time pressure in risky situations. Although there is very little empirical evidence from prior uncertainty visualization research that considered decision time constraints, we hypothesized that uncertainty visualization would also have an effect on decision-making under time critical and complex decision contexts. Using a map-based helicopter landing scenario in mountainous terrain, we found that neither time pressure nor uncertainty affected participants decision-making accuracy. However, uncertainty affected participants&#39; decision strategies, and time pressure affected participants&#39; response times. Specifically, when presented with two equally correct answers, participants avoided uncertainty more often at a cost of landing distance (an equally important decision criteria). We interpret our results as consistent with a loss-aversion heuristic and suggest implications for the study of decision-making with uncertainty visualizations.},
  archive      = {J_FCOMP},
  author       = {Korporaal, Michelle and Ruginski, Ian T. and Fabrikant, Sara Irina},
  doi          = {10.3389/fcomp.2020.00032},
  journal      = {Frontiers in Computer Science},
  month        = {8},
  pages        = {564723},
  shortjournal = {Front. Comput. Sci.},
  title        = {Effects of uncertainty visualization on map-based decision making under time pressure},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The challenges of leveraging threat intelligence to stop
data breaches. <em>FCOMP</em>, <em>2</em>, 562053. (<a
href="https://doi.org/10.3389/fcomp.2020.00036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the significant increase in cybersecurity solutions investment, organizations are still plagued by security breaches, especially data breaches. As more organizations experience crippling security breaches, the wave of compromised data is growing significantly. The financial consequences of a data breach are set on the rise, but the cost goes beyond potential fines. Data breaches could have a catastrophic impact not only in loss of company&#39;s reputation and stock price, but also in economic terms. Threat Intelligence has been recently introduced to enable greater visibility of cyber threats, in order to better protect organizations&#39; digital assets and prevent data breaches. Threat intelligence is the practice of integrating and analyzing disjointed cyber data to extract evidence-based insights regarding an organization&#39;s unique threat landscape. This helps explain who the adversary is, how and why they are comprising the organization&#39;s digital assets, what consequences could happen following the attack, what assets actually could be compromised, and how to detect or respond to the threat. Every organization is different and threat intelligence frameworks are custom-tailored to the business process itself and the organization&#39;s risks, as there is no “one-size-fits-all” in cyber. In this paper, we review the problem of data breaches and discuss the challenges of implementing threat intelligence that scales in today&#39;s complex threat landscape and digital infrastructure. This is followed by an illustration of how the future of effective threat intelligence is closely linked to efficiently applying Artificial Intelligence and Machine Learning approaches, and we conclude by outlining future research directions in this area.},
  archive      = {J_FCOMP},
  author       = {Ibrahim, Amani and Thiruvady, Dhananjay and Schneider, Jean-Guy and Abdelrazek, Mohamed},
  doi          = {10.3389/fcomp.2020.00036},
  journal      = {Frontiers in Computer Science},
  month        = {8},
  pages        = {562053},
  shortjournal = {Front. Comput. Sci.},
  title        = {The challenges of leveraging threat intelligence to stop data breaches},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Product quality improvement policies in industry 4.0:
Characteristics, enabling factors, barriers, and evolution toward zero
defect manufacturing. <em>FCOMP</em>, <em>2</em>, 541465. (<a
href="https://doi.org/10.3389/fcomp.2020.00026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the competitive market of manufacturing, quality is a criterion of primary importance in order to win market share. Quality improvement must be coupled with performance point of view. Lean Manufacturing, Six Sigma, Lean Six Sigma, Total Quality Management, Theory of Constraints, and their combination are philosophies dedicated to this goal. This study is a literature review on the implementation of these philosophies to improve quality of processes and products in a system, and also covers the commonalities and differences with Zero Defect Manufacturing (ZDM) philosophy. In this study, 45 articles have been analyzed. These articles have been selected by a research on several scientific libraries with specific keywords. The methodology is based on a list of information extracted from each paper. The data searched are on the tool selections, critical factors of implementations and the benefits obtained from them. Based on the review and analysis of the literature and practices, we provide the top 10 main components of the tools used for quality improvement, enabling factors, benefits, and barriers to implementation. Moreover, we present and discuss categorization of quality improvement methods and the way toward ZDM. The need of standardized toolkits for different levels of maturity in quality management systems and a better education have been enlightened. Thanks to technological improvement in information flow management, ZDM seems close to be achieved even though some new risks and wastes have to be taken care of within the implementation.},
  archive      = {J_FCOMP},
  author       = {Psarommatis, Foivos and Prouvost, Sylvain and May, Gökan and Kiritsis, Dimitris},
  doi          = {10.3389/fcomp.2020.00026},
  journal      = {Frontiers in Computer Science},
  month        = {8},
  pages        = {541465},
  shortjournal = {Front. Comput. Sci.},
  title        = {Product quality improvement policies in industry 4.0: Characteristics, enabling factors, barriers, and evolution toward zero defect manufacturing},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Validation of user preferences and effects of personalized
gamification on task performance. <em>FCOMP</em>, <em>2</em>, 531710.
(<a href="https://doi.org/10.3389/fcomp.2020.00029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized gamification is the tailoring of gameful design elements to user preferences to improve engagement. However, studies of user preferences have so far relied on self-reported data only and few studies investigated the effects of personalized gameful systems on task performance. This study shows that personalized gamification works in practice as predicted by survey studies and leads to higher task performance. We asked 252 participants in two studies to interact with a customized (experimental) or a generic (control) online gameful application to classify images. In the customized version, they could select the game elements that they wanted to use for their experience. The results showed significant correlations between participants&#39; choice of gameful design elements and their Hexad user type scores, which partly support existing user preference models based on self-reported preferences. On the other hand, user type scores were not correlated with participants&#39; preferred game elements rated after interacting with the gameful system. These findings demonstrate that the Hexad user types are a viable model to create personalized gameful systems. However, it seems that there are other yet unknown factors that can influence user preferences, which should be considered together with the user type scores. Additionally, participants in the experimental condition classified more images and rated their experience of selecting the game elements they wanted to use higher than in the control, demonstrating that task performance improved with personalization. Nonetheless, other measures of task performance that were not explicitly incentivized by the game elements did not equally improve. This contribution shows that personalized gameful design creates systems that are more successful in helping users achieve their goals than generic systems. However, gameful designers should be aware that they must balance the game elements and how much they incentivize each user behavior, so that the business goals can be successfully promoted. Finally, we analyzed participants&#39; qualitative answers about their experience with the generic and the customized gameful applications, extracting useful lessons for the designers of personalized gameful systems.},
  archive      = {J_FCOMP},
  author       = {Tondello, Gustavo F. and Nacke, Lennart E.},
  doi          = {10.3389/fcomp.2020.00029},
  journal      = {Frontiers in Computer Science},
  month        = {8},
  pages        = {531710},
  shortjournal = {Front. Comput. Sci.},
  title        = {Validation of user preferences and effects of personalized gamification on task performance},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A virtual tour of a hardly accessible archaeological site:
The effect of immersive virtual reality on user experience, learning and
attitude change. <em>FCOMP</em>, <em>2</em>, 531036. (<a
href="https://doi.org/10.3389/fcomp.2020.00023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Some archaeological sites are not easily accessible by visitors due to mobility or geographical restrictions. Digital technology can make such sites virtually accessible and provide educational information at the same time. Toward this goal, we created a digital reconstruction of the archaeological site of Choirokoitia. Given that a 3D digital reconstruction can be used along with different technologies, we designed and developed an interactive application, where users can navigate and get information about the site, for two different systems: Virtual Reality (VR) systems and desktop computers. A feasibility study was conducted where we compared aspects of the two systems so as to allow the suggestion of the proper technology to utilize according to a user&#39;s aims. The results showed higher levels of presence and more positive experience by the participants who used the VR system compared to those who used the desktop version. On the other hand, greater learning gains were demonstrated in participants who used the desktop version compared to those who used the VR version. No differences were shown between the two groups regarding the participants&#39; change of attitudes toward the archaeology of Cyprus.},
  archive      = {J_FCOMP},
  author       = {Kyrlitsias, Christos and Christofi, Maria and Michael-Grigoriou, Despina and Banakou, Domna and Ioannou, Andri},
  doi          = {10.3389/fcomp.2020.00023},
  journal      = {Frontiers in Computer Science},
  month        = {8},
  pages        = {531036},
  shortjournal = {Front. Comput. Sci.},
  title        = {A virtual tour of a hardly accessible archaeological site: The effect of immersive virtual reality on user experience, learning and attitude change},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Serious pervasive games. <em>FCOMP</em>, <em>2</em>, 528526.
(<a href="https://doi.org/10.3389/fcomp.2020.00030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Serious Pervasive Games extend the magic circle (Huizinga, 1938) to the players&#39; context and surrounding environment. The blend of both physical and fictive game worlds provides a push in player engagement and promotes situated learning approaches. Space and time, as well as social context, acquire a more meaningful impact on the gameplay. From pervasive learning towards science communication with location-based games, this article presents research and case studies that exemplify their benefits and related problems. Pervasive learning can be defined as “learning at the speed of need through formal, informal and social learning modalities” (Pontefract, 2013). The first case study—the BEACONING project—aims to contextualize the teaching and learning process, connecting it with problem-based game mechanics within STEM. The main goal of this project is to provide the missing connection between STEM subjects and real-world interactions and applications. The pedagogical foundation is supported on problem-based learning (PBL), in which active learning is in the center, and learners have to work with different tools and resources in order to solve problems (quests). Teachers create, facilitate, and assess pervasive and gamified learning activities (missions). Furthermore, these quests are gamified in order to provide non-linear game plots. In a second case study, we demonstrate and evaluate how natural heritage can benefit from pervasive games. This study is based on a set of location-based games for an existing natural park, which have been developed in order to provide enhanced experiences, as well as additional information about some species that are more difficult to observe or that are seasonal. Throughout the research and development of these projects, we have encountered and identified several problems, of different nature, present in pervasive games.},
  archive      = {J_FCOMP},
  author       = {Coelho, António and Rodrigues, Rui and Nóbrega, Rui and Jacob, João and Morgado, Leonel and Cardoso, Pedro and van Zeller, Maria and Santos, Liliana and Sousa, A. Augusto},
  doi          = {10.3389/fcomp.2020.00030},
  journal      = {Frontiers in Computer Science},
  month        = {8},
  pages        = {528526},
  shortjournal = {Front. Comput. Sci.},
  title        = {Serious pervasive games},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The quantified self-in-place: Opportunities and challenges
for place-based n-of-1 datasets. <em>FCOMP</em>, <em>2</em>, 515983. (<a
href="https://doi.org/10.3389/fcomp.2020.00038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FCOMP},
  author       = {Chrisinger, Benjamin W.},
  doi          = {10.3389/fcomp.2020.00038},
  journal      = {Frontiers in Computer Science},
  month        = {8},
  pages        = {515983},
  shortjournal = {Front. Comput. Sci.},
  title        = {The quantified self-in-place: Opportunities and challenges for place-based N-of-1 datasets},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The use of a serious game to assess inhibition mechanisms in
children. <em>FCOMP</em>, <em>2</em>, 514652. (<a
href="https://doi.org/10.3389/fcomp.2020.00034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The design and implementation of a serious game (SG) concerning inhibition skills in children are presented. The SG consists of a set of activities, each eliciting the tendency to respond in an immediate and inappropriate (wrong) way. The SG is based on the Dual Pathway model of attention-deficit/hyperactivity disorder (ADHD) proposed by Sonuga-Barke and on the Unity/Diversity model of executive functions proposed by Miyake. In the SG, children must block impulsive tendencies, reflect upon the situation, inhibit irrelevant thoughts, and find the non-immediate solution. A study was carried out by testing the SG on typically developing primary school children (30 children, 16 boys; age, M = 9.30 years, SD = 0.87) to verify that it measures the same variables addressed by tests usually employed to assess attention ability in children and to diagnose ADHD. Three standardized tasks belonging to the Italian Battery for ADHD were administered, as well as an ad hoc questionnaire devised to check the acceptability, usability, and comprehensibility of the SG. Positive correlations between impulsiveness as measured by standard tests and impulsiveness scores in the SG emerged. These findings support the notion that skills associated with the control of impulsivity are involved in the SG. Furthermore, self-report ratings in the questionnaire showed that the SG is easy to be understood, is engaging, and elicits positive reactions in children.},
  archive      = {J_FCOMP},
  author       = {Crepaldi, Maura and Colombo, Vera and Mottura, Stefano and Baldassini, Davide and Sacco, Marco and Cancer, Alice and Antonietti, Alessandro},
  doi          = {10.3389/fcomp.2020.00034},
  journal      = {Frontiers in Computer Science},
  month        = {8},
  pages        = {514652},
  shortjournal = {Front. Comput. Sci.},
  title        = {The use of a serious game to assess inhibition mechanisms in children},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dynamic deep networks for retinal vessel segmentation.
<em>FCOMP</em>, <em>2</em>, 510300. (<a
href="https://doi.org/10.3389/fcomp.2020.00035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has recently yielded impressive gains in retinal vessel segmentation. However, state-of-the-art methods tend to be conservative, favoring precision over recall. Thus, they tend to under-segment faint vessels, underestimate the width of thicker vessels, or even miss entire vessels. To address this limitation, we propose a stochastic training scheme for deep neural networks that robustly balances precision and recall. First, we train our deep networks with dynamic class weights in the loss function that fluctuate during each training iteration. This stochastic approach–which we believe is applicable to many other machine learning problems–forces the network to learn a balanced classification. Second, we decouple the segmentation process into two steps. In the first half of our pipeline, we estimate the likelihood of every pixel and then use these likelihoods to segment pixels that are clearly vessel or background. In the latter part of our pipeline, we use a second network to classify the ambiguous regions in the image. Our proposed method obtained state-of-the-art results on five retinal datasets—DRIVE, STARE, CHASE-DB, AV-WIDE, and VEVIO—by learning a robust balance between false positive and false negative rates. Our novel training paradigm makes a neural network more robust to inter-sample differences in class ratios, which we believe will prove particularly effective for settings with sparse training data, such as medical image analysis. In addition, we are the first to report segmentation results on the AV-WIDE dataset, and we have made the ground-truth annotations for this dataset publicly available. An implementation of this work can be found at https://github.com/sraashis/deepdyn.},
  archive      = {J_FCOMP},
  author       = {Khanal, Aashis and Estrada, Rolando},
  doi          = {10.3389/fcomp.2020.00035},
  journal      = {Frontiers in Computer Science},
  month        = {8},
  pages        = {510300},
  shortjournal = {Front. Comput. Sci.},
  title        = {Dynamic deep networks for retinal vessel segmentation},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improving hazard map comprehension for protective action
decision making. <em>FCOMP</em>, <em>2</em>, 568733. (<a
href="https://doi.org/10.3389/fcomp.2020.00027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A major challenge in the communication of spatial hazard information is the existence of substantial variation in people&#39;s ability to correctly infer the appropriate conclusions from hazard maps. Examination of the results from a variety of different types of hazard maps has identified patterns of erroneous as well as accurate processing of map information. In response, most hazard map studies have focused on the erroneous inferences and sought to develop displays that would cause hazard map viewers to make more accurate inferences about the hazard. This research has made some significant advances, but it has neglected the development and testing of spatial displays that can help people to make more timely and effective protective action decisions. This article concludes by summarizing the findings from hazard map research and recommending future research that will address these unresolved issues.},
  archive      = {J_FCOMP},
  author       = {Lindell, Michael K.},
  doi          = {10.3389/fcomp.2020.00027},
  journal      = {Frontiers in Computer Science},
  month        = {7},
  pages        = {568733},
  shortjournal = {Front. Comput. Sci.},
  title        = {Improving hazard map comprehension for protective action decision making},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mobile phone-based persuasive technology for physical
activity and sedentary behavior: A systematic review. <em>FCOMP</em>,
<em>2</em>, 537643. (<a
href="https://doi.org/10.3389/fcomp.2020.00019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile phone technology has been progressively employed in persuasive technology interventions design to promote physical activity (PA) and discourage sedentary behavior (SB). Because of the ubiquitous nature and seamless integration of mobile phones into user&#39;s daily lives, mobile phone-based persuasive technologies (PTs) have the potential to influence and change a user&#39;s behavior or attitude continuously. This paper provides a systematic review of 15 years of research (80 papers) focusing on the effectiveness of mobile phone-based PT in promoting PA and reducing SB. Specifically, this review aims to (1) assess the effectiveness of mobile phone-based PT in persuading users to be more physically active and less sedentary, (2) highlight research trends in this area including other technology platforms implemented along with mobile phone-based PT, (3) reveal some strengths and weaknesses of existing mobile phone interventions in PA and SB domains, and (4) provide recommendations to inform future research in this area.},
  archive      = {J_FCOMP},
  author       = {Aldenaini, Noora and Oyebode, Oladapo and Orji, Rita and Sampalli, Srinivas},
  doi          = {10.3389/fcomp.2020.00019},
  journal      = {Frontiers in Computer Science},
  month        = {7},
  pages        = {537643},
  shortjournal = {Front. Comput. Sci.},
  title        = {Mobile phone-based persuasive technology for physical activity and sedentary behavior: A systematic review},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Innovative parkinson’s disease patients’ motor skills
assessment: The i-PROGNOSIS paradigm. <em>FCOMP</em>, <em>2</em>,
536901. (<a href="https://doi.org/10.3389/fcomp.2020.00020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Being the second most common neurodegenerative disease, Parkinson&#39;s disease (PD) can be symptomatically treated, although, unfortunately, it cannot be cured yet. Moreover, diagnosing and assessing PD patients is a complex process, requiring continuous monitoring. In this vein, the design, development, and validation of innovative assessment tools may be helpful in the management of patients with PD, in particular. Based on intelligent ICT interventions, the i-PROGNOSIS project intends to mitigate PD&#39;s specific symptoms, such as neurological movement disorders of gait, balance, coordination, and posture, already characterized in the early phase of the disease. From this perspective, an innovative iPrognosis motor assessment tool is presented here, taking into consideration the Unified Parkinson Disease Rating Scale (UPDRS) Part III motor skills testing items, for evaluating the motor skills status. The efficiency of the proposed Assessment Tests to reflect the motor skills status, similarly to the UPDRS Part III items, was validated via 27 participants (18 males; mean age = 62 years, SD = 10.36 years; range, 43–79 years) with early (n = 10) and moderate (n = 17) PD who performed the Assessment Tests. Features from the latter were then correlated with the corresponding clinically assessed UPDRS Part III items, and statistically significant negative correlations (range, −0.364 to −0.802) were identified between the median values of the Assessment Tests and the UPDRS Part III items. In this vein, the iPrognosis Assessment Tests were integrated within the personalized interventions of the i-PROGNOSIS project, providing alternative means of assessing their effect on the PD patient&#39;s motor skills enhancement. The promising results presented here elaborate on the concept of using ICT-based assessment means to achieve comparable outcomes with the clinical standards in motor skills assessment.},
  archive      = {J_FCOMP},
  author       = {Dias, Sofia Balula and Grammatikopoulou, Athina and Diniz, José Alves and Dimitropoulos, Kosmas and Grammalidis, Nikos and Zilidou, Vicky and Savvidis, Theodore and Konstantinidis, Evdokimos and Bamidis, Panagiotis D. and Jaeger, Hagen and Stadtschnitzer, Michael and Silva, Hugo and Telo, Gonçalo and Ioakeimidis, Ioannis and Ntakakis, George and Karayiannis, Fotis and Huchet, Estelle and Hoermann, Vera and Filis, Konstantinos and Theodoropoulou, Elina and Lyberopoulos, George and Kyritsis, Konstantinos and Papadopoulos, Alexandros and Delopoulos, Anastasios and Trivedi, Dhaval and Chaudhuri, K. Ray and Klingelhoefer, Lisa and Reichmann, Heinz and Bostantzopoulou, Sevasti and Katsarou, Zoe and Iakovakis, Dimitrios and Hadjidimitriou, Stelios and Charisis, Vasileios and Apostolidis, George and Hadjileontiadis, Leontios J.},
  doi          = {10.3389/fcomp.2020.00020},
  journal      = {Frontiers in Computer Science},
  month        = {7},
  pages        = {536901},
  shortjournal = {Front. Comput. Sci.},
  title        = {Innovative parkinson&#39;s disease patients&#39; motor skills assessment: The i-PROGNOSIS paradigm},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Digital training in the aeronautical industry: Measuring the
usability of two mobile applications. <em>FCOMP</em>, <em>2</em>,
536158. (<a href="https://doi.org/10.3389/fcomp.2020.00022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The air traffic control industry is highly regulated, with stringent processes and procedures to ensure that IP (Intellectual Property) and workplaces are kept secure. The training of air traffic controllers (ATCs) and other roles relating to air traffic services is a lengthy and expensive process. The rate in which trainees can be trained is projected to fall significantly short of the demand for staff to work in the air traffic industry. This paper focuses on two prototype mobile training applications—Location Indicators (LI) and the Aircraft Control Positions Operator (ACPO) Starter Pack. LI and the ACPO Starter Pack have been produced to explore how air traffic control training could be improved and supported using digital applications. Each application explores a key learning area for trainees in the air traffic control industry and presents an alternative to the equivalent training that is currently in use. The two prototypes that have been designed focus on producing a succinct user experience alongside gamified elements to improve engagement. As part of this paper, usability testing has been undertaken with LI and the ACPO Starter Pack. A total of nine usability tests have been undertaken at four different locations. These usability tests consisted of participants from differing demographics, varying experience with the current training and differing amounts of time with both applications. The System Usability Scale (SUS) was adapted and used to quantify participant&#39;s reactions to the usability of each application. Usability scores for both applications were collected and then averaged to produce an overall score for each application. We can conclude from both usability scores and qualitative feedback that digital applications have the potential to engage future trainees in the air traffic services industry.},
  archive      = {J_FCOMP},
  author       = {Smy, Phillip James and Donald, Iain and Scott-Brown, Kenneth and Falconer, Ruth E.},
  doi          = {10.3389/fcomp.2020.00022},
  journal      = {Frontiers in Computer Science},
  month        = {7},
  pages        = {536158},
  shortjournal = {Front. Comput. Sci.},
  title        = {Digital training in the aeronautical industry: Measuring the usability of two mobile applications},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A technical and conceptual framework for serious
role-playing games in the area of social skill training. <em>FCOMP</em>,
<em>2</em>, 523355. (<a
href="https://doi.org/10.3389/fcomp.2020.00028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Virtual role-playing games can provide an authentic experience of situated learning and allow for trying out different problem-solving and communication strategies without consequences in the real world. This is of particular interest and benefit for the training of social skills. This article presents a conceptual and technical framework for serious role-playing games for the training of specific social skills in virtual 2D learning environments involving chatbots in dialog-centric settings. It summarizes different use cases and evaluation results from prior studies. From the design perspective, several distinctive conceptual features characterize our framework: (1) chat-like interaction with an AI-controlled chatbot, (2) separate phases of immersion and reflection to facilitate a change of perspective that is considered conducive for learning, (3) the learning process is emphasized by means of adaptive feedback based on individual analyses. We propose a system architecture that is based on three components: (1) AI-controlled chatbots that adapt to the player&#39;s behavior, (2) a multi-agent blackboard system as the backbone in order to keep components independent and optimize performance due to parallel processing, and (3) intelligent support for an automated evaluation of the player&#39;s performance and feedback generation. The training scenarios presented and discussed in this article include workplace-oriented conflict management, patient-centered medical interviews, and customer complaint management. First evaluation studies indicate that the scenarios may be well-suited for real training situations. Due to its flexible architecture, our framework and approach can easily be tailored to different settings and use cases and thus serve as a basis for future research focusing on the adaptation to other contexts and systems. On the basis of these developments, we elaborate important design dimensions, reflect and discuss general issues and major challenges, summarize and contrast different approaches and strategies, and identify opportunities for serious role-playing games in the area of social skills training.},
  archive      = {J_FCOMP},
  author       = {Othlinghaus-Wulhorst, Julia and Hoppe, H. Ulrich},
  doi          = {10.3389/fcomp.2020.00028},
  journal      = {Frontiers in Computer Science},
  month        = {7},
  pages        = {523355},
  shortjournal = {Front. Comput. Sci.},
  title        = {A technical and conceptual framework for serious role-playing games in the area of social skill training},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Analysis of video retinal angiography with deep learning and
eulerian magnification. <em>FCOMP</em>, <em>2</em>, 516530. (<a
href="https://doi.org/10.3389/fcomp.2020.00024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objective: The aim of this research is to present a novel computer-aided decision support tool in analyzing, quantifying, and evaluating the retinal blood vessel structure from fluorescein angiogram (FA) videos.Methods: The proposed method consists of three phases: (i) image registration for large motion removal from fluorescein angiogram videos, followed by (ii) retinal vessel segmentation, and lastly, (iii) segmentation-guided video magnification. In the image registration phase, individual frames of the video are spatiotemporally aligned using a novel wavelet-based registration approach to compensate for the global camera and patient motion. In the second phase, a capsule-based neural network architecture is employed to perform the segmentation of retinal vessels for the first time in the literature. In the final phase, a segmentation-guided Eulerian video magnification is proposed for magnifying subtle changes in the retinal video produced by blood flow through the retinal vessels. The magnification is applied only to the segmented vessels, as determined by the capsule network. This minimizes the high levels of noise present in these videos and maximizes useful information, enabling ophthalmologists to more easily identify potential regions of pathology.Results: The collected fluorescein angiogram video dataset consists of 1, 402 frames from 10 normal subjects (prospective study). Experimental results for retinal vessel segmentation show that the capsule-based algorithm outperforms a state-of-the-art convolutional neural networks (U-Net), obtaining a higher dice coefficient (85.94%) and sensitivity (92.36%) while using just 5% of the network parameters. Qualitative analysis of these videos was performed after the final phase by expert ophthalmologists, supporting the claim that artificial intelligence assisted decision support tool can be helpful for providing a better analysis of blood flow dynamics.Conclusions: The authors introduce a novel computational tool, combining a wavelet-based video registration method with a deep learning capsule-based retinal vessel segmentation algorithm and a Eulerian video magnification technique to quantitatively and qualitatively analyze FA videos. To authors&#39; best knowledge, this is the first-ever development of such a computational tool to assist ophthalmologists with analyzing blood flow in FA videos.},
  archive      = {J_FCOMP},
  author       = {Laha, Sumit and LaLonde, Rodney and Carmack, Austin E. and Foroosh, Hassan and Olson, John C. and Shaikh, Saad and Bagci, Ulas},
  doi          = {10.3389/fcomp.2020.00024},
  journal      = {Frontiers in Computer Science},
  month        = {7},
  pages        = {516530},
  shortjournal = {Front. Comput. Sci.},
  title        = {Analysis of video retinal angiography with deep learning and eulerian magnification},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). External assistance techniques that target core game tasks
for balancing game difficulty. <em>FCOMP</em>, <em>2</em>, 531916. (<a
href="https://doi.org/10.3389/fcomp.2020.00017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Game balancing is a time consuming and complex requirement in game design, where game mechanics and other aspects of a game are tweaked to provide the right level of challenge and play experience. One way that game designers help make challenging mechanics easier is through the use of External Assistance Techniques—a set of techniques outside of games&#39; main mechanics. While External Assistance Techniques are well-known to game designers (like providing onscreen guides to help players push the right buttons at the right times), there are no guiding principles for how these can be applied to help balance challenge in games. In this work, we present a design framework that can guide designers in identifying and applying External Assistance Techniques from a range of existing assistance techniques. We provide a first characterization of External Assistance Techniques showing how they can be applied by first identifying a game&#39;s Core Tasks. In games that require skill mechanics, Core Tasks are the basic motor and perceptual unit tasks required to interact with a game, such as aiming at a target or remembering a detail. In this work we analyze 54 games, identifying and organizing 27 External Assistance Techniques into a descriptive framework that connects them to the ten core tasks that they assist. We then demonstrate how designers can use our framework to assist a previously understudied core task in three games. Through an evaluation, we show that the framework is an effective tool for game balancing, and provide commentary on key ways that External Assistance Techniques can affect player experience. Our work provides new directions for research into improving and maturing game balancing practices.},
  archive      = {J_FCOMP},
  author       = {Refai, Jawad Jandali and Bateman, Scott and Fleming, Michael W.},
  doi          = {10.3389/fcomp.2020.00017},
  journal      = {Frontiers in Computer Science},
  month        = {6},
  pages        = {531916},
  shortjournal = {Front. Comput. Sci.},
  title        = {External assistance techniques that target core game tasks for balancing game difficulty},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). What is it like to be a game?—object oriented inquiry for
games research, design, and evaluation. <em>FCOMP</em>, <em>2</em>,
531724. (<a href="https://doi.org/10.3389/fcomp.2020.00018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human-Computer Interaction (HCI) researchers more and more challenge the notion of technologies as objects and humans as subjects. This conceptualization has led to various approaches inquiring into object perspectives within HCI. Even though the development and analysis of games and players is filled with notions of intersubjectivity, games research has yet to embrace an object oriented perspective. Through an analysis of existing methods, we show how Object-Oriented Inquiry offers a useful, playful, and speculative lens to pro-actively engage with and reflect on how we might know what it is like to be a game. We illustrate how to actively attend to a game&#39;s perspective as a valid position. This has the potential to not only sharpen our understanding of implicit affordances but, in turn, about our assumptions regarding play and games more generally. In a series of case studies, we apply several object-oriented methods across three methodological explorations on becoming, being, and acting as a game, and illustrate their usefulness for generating meaningful insights for game design and evaluation. Our work contributes to emerging object-oriented practices that acknowledge the agency of technologies within HCI at large and its games-oriented strand in particular.},
  archive      = {J_FCOMP},
  author       = {Spiel, Katta and Nacke, Lennart E.},
  doi          = {10.3389/fcomp.2020.00018},
  journal      = {Frontiers in Computer Science},
  month        = {6},
  pages        = {531724},
  shortjournal = {Front. Comput. Sci.},
  title        = {What is it like to be a Game?—Object oriented inquiry for games research, design, and evaluation},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A conceptual framework for personal science. <em>FCOMP</em>,
<em>2</em>, 504683. (<a
href="https://doi.org/10.3389/fcomp.2020.00021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a conceptual framework to guide research and education into the practice of personal science, which we define as using empirical methods to pursue personal health questions. Personal science consists of five activities: questioning, designing, observing, reasoning, and discovering. These activities are conceptual abstractions derived from review of self-tracking practices in the Quantified Self community. These practices have been enabled by digital tools to collect personal real-world data. Similarities and differences between personal science, citizen science and single subject (N-of-1) research in medicine are described. Finally, barriers that constrain widespread adoption of personal science and limit the potential benefits to individual well-being and clinical and public health discovery are briefly discussed, with perspectives for overcoming these barriers.},
  archive      = {J_FCOMP},
  author       = {Wolf, Gary Isaac and De Groot, Martijn},
  doi          = {10.3389/fcomp.2020.00021},
  journal      = {Frontiers in Computer Science},
  month        = {6},
  pages        = {504683},
  shortjournal = {Front. Comput. Sci.},
  title        = {A conceptual framework for personal science},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Machine learning approaches for motor learning: A short
review. <em>FCOMP</em>, <em>2</em>, 531563. (<a
href="https://doi.org/10.3389/fcomp.2020.00016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning approaches have seen a considerable number of applications in human movement modeling but remain limited for motor learning. Motor learning requires that motor variability be taken into account and poses new challenges because the algorithms need to be able to differentiate between new movements and variation in known ones. In this short review, we outline existing machine learning models for motor learning and their adaptation capabilities. We identify and describe three types of adaptation: Parameter adaptation in probabilistic models, Transfer and meta-learning in deep neural networks, and Planning adaptation by reinforcement learning. To conclude, we discuss challenges for applying these models in the domain of motor learning support systems.},
  archive      = {J_FCOMP},
  author       = {Caramiaux, Baptiste and Françoise, Jules and Liu, Wanyu and Sanchez, Téo and Bevilacqua, Frédéric},
  doi          = {10.3389/fcomp.2020.00016},
  journal      = {Frontiers in Computer Science},
  month        = {5},
  pages        = {531563},
  shortjournal = {Front. Comput. Sci.},
  title        = {Machine learning approaches for motor learning: A short review},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). To be or not be human-like in virtual world. <em>FCOMP</em>,
<em>2</em>, 529414. (<a
href="https://doi.org/10.3389/fcomp.2020.00015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main objective is a double one. First and foremost, it is a question of showing that foot-in-the-door as a proven behavioral influence technique in offline interactions maintains its efficiency in online interactions. It is then a question of exploring the impact of the anthropomorphism vs. the non-anthropomorphism of the requester avatar on the efficiency of this technique. Foot-in-the-door is based on a simple principle: you start by asking for a little in a first step to increase the probability of obtaining a lot in a second step. The research was conducted in the Second Life virtual world. In a control condition (n = 200), a requester avatar directly proposed the target request. In a foot-in-the-door condition (n = 200), the requester avatar started by presenting a preparatory request before proposing the target request. According to the conditions, the requester avatar was human-like (female or male), or non-human-like (flower, balloon, cube). As expected, our results show that overall the foot-in-the door-technique remains efficient in the virtual world; they also show that this efficiency depends on the human-like form of the requester avatar. This last result is interpreted as a reference to the theory of social presence. Non-human-like avatars could generate a weak social presence, to the point where the mechanisms of self-perception and commitment underlying the foot-in-the-door effect may not be automatically initiated. Player avatars would in this way be freed from the rules of social interaction occurring in offline interactions.},
  archive      = {J_FCOMP},
  author       = {Barbier, Laura and Fointiat, Valerie},
  doi          = {10.3389/fcomp.2020.00015},
  journal      = {Frontiers in Computer Science},
  month        = {5},
  pages        = {529414},
  shortjournal = {Front. Comput. Sci.},
  title        = {To be or not be human-like in virtual world},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Real-time speech emotion recognition using a pre-trained
image classification network: Effects of bandwidth reduction and
companding. <em>FCOMP</em>, <em>2</em>, 497007. (<a
href="https://doi.org/10.3389/fcomp.2020.00014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper examines the effects of reduced speech bandwidth and the μ-low companding procedure used in transmission systems on the accuracy of speech emotion recognition (SER). A step by step description of a real-time speech emotion recognition implementation using a pre-trained image classification network AlexNet is given. The results showed that the baseline approach achieved an average accuracy of 82% when trained on the Berlin Emotional Speech (EMO-DB) data with seven categorical emotions. Reduction of the sampling frequency from the baseline 16–8 kHz (i.e., bandwidth reduction from 8 to 4 kHz, respectively) led to a decrease of SER accuracy by about 3.3%. The companding procedure on its own reduced the average accuracy by 3.8%, and the combined effect of companding and band reduction decreased the accuracy by about 7% compared to the baseline results. The SER was implemented in real-time with emotional labels generated every 1.033–1.026 s. Real-time implementation timelines are presented.},
  archive      = {J_FCOMP},
  author       = {Lech, Margaret and Stolar, Melissa and Best, Christopher and Bolia, Robert},
  doi          = {10.3389/fcomp.2020.00014},
  journal      = {Frontiers in Computer Science},
  month        = {5},
  pages        = {497007},
  shortjournal = {Front. Comput. Sci.},
  title        = {Real-time speech emotion recognition using a pre-trained image classification network: Effects of bandwidth reduction and companding},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A waveform-feature dual branch acoustic embedding network
for emotion recognition. <em>FCOMP</em>, <em>2</em>, 490955. (<a
href="https://doi.org/10.3389/fcomp.2020.00013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research in advancing speech emotion recognition (SER) has attracted a lot of attention due to its critical role for better human behaviors understanding scientifically and comprehensive applications commercially. Conventionally, performing SER highly relies on hand-crafted acoustic features. The recent progress in deep learning has attempted to model emotion directly from raw waveform in an end-to-end learning scheme; however, this particular approach remains to be generally a sub-optimal approach. An alternative direction has been proposed to enhance and augment the knowledge-based acoustic representation with affect-related representation derived directly from raw waveform. Here, we propose a complimentary waveform-feature dual branch learning network, termed as Dual-Complementary Acoustic Embedding Network (DCaEN), to effectively integrate psychoacoustic knowledge and raw waveform embedding within an augmented feature space learning approach. DCaEN contains an acoustic feature embedding network and a raw waveform network, that is learned by integrating negative cosine distance constraint in the loss function. The experiment results show that DCaEN can achieve 59.31 an 46.73% unweighted average recall (UAR) in the USC IEMOCAP and the MSP-IMPROV speech emotion databases, which improves the performance compared to modeling either acoustic hand-crafted features or raw waveform only and without this particular loss constraint. Further analysis illustrates a reverse mirroring pattern in the learned latent space demonstrating the complementary nature of DCaEN feature space learning.},
  archive      = {J_FCOMP},
  author       = {Li, Jeng-Lin and Huang, Tzu-Yun and Chang, Chun-Min and Lee, Chi-Chun},
  doi          = {10.3389/fcomp.2020.00013},
  journal      = {Frontiers in Computer Science},
  month        = {5},
  pages        = {490955},
  shortjournal = {Front. Comput. Sci.},
  title        = {A waveform-feature dual branch acoustic embedding network for emotion recognition},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Selfies as duplex non-verbal communication: Human—media
interaction, human—human interaction, case study, and research
manifesto. <em>FCOMP</em>, <em>2</em>, 522129. (<a
href="https://doi.org/10.3389/fcomp.2020.00012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using conceptual tools from semiotics, proxemics, and sensorimotor neuroscience, we propose a duplex model for understanding selfies as non-verbal communication involving an interplay between two layers of interaction: human—media (semiotically primary) and human—human (secondary). We suggest that this approach has promise as a tool for understanding this newborn form of human social behavior and its social, psychological, and neural underpinnings. To support our claim, we do several things. We offer a definition of selfies and outline our model. We review the existing literature on selfies as non-verbal communication to show that there is evidence bearing on our theoretical framework. We present a case study documenting how a combination of image analysis and kinematic measurement can be used to compare taker—smartphone interactions during selfie-taking with image features that play a role in the virtual interaction between the selfie-taker and his or her viewers. Our results support the feasibility of our approach and reveal a sex-related effect on the composition of selfies matching a related difference in the kinematic markers that describe the taker—smartphone interaction. Finally, we discuss outstanding questions in understanding selfies as duplex non-verbal communication and conclude by inviting further research on this topic.},
  archive      = {J_FCOMP},
  author       = {Bruno, Nicola and Uccelli, Stefano and Pisu, Veronica and Belluardo, Mauro and De Stefani, Elisa},
  doi          = {10.3389/fcomp.2020.00012},
  journal      = {Frontiers in Computer Science},
  month        = {4},
  pages        = {522129},
  shortjournal = {Front. Comput. Sci.},
  title        = {Selfies as duplex non-verbal communication: Human—Media interaction, Human—Human interaction, case study, and research manifesto},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Development and evaluation of the nebraska assessment of
computing knowledge. <em>FCOMP</em>, <em>2</em>, 515362. (<a
href="https://doi.org/10.3389/fcomp.2020.00011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One way to increase the quality of computing education research is to increase the quality of the measurement tools that are available to researchers, especially measures of students&#39; knowledge and skills. This paper represents a step toward increasing the number of available thoroughly-evaluated tests that can be used in computing education research by evaluating the psychometric properties of a multiple-choice test designed to differentiate undergraduate students in terms of their mastery of foundational computing concepts. Classical test theory and item response theory analyses are reported and indicate that the test is a reliable, psychometrically-sound instrument suitable for research with undergraduate students. Limitations and the importance of using standardized measures of learning in education research are discussed.},
  archive      = {J_FCOMP},
  author       = {Peteranetz, Markeya S. and Albano, Anthony D.},
  doi          = {10.3389/fcomp.2020.00011},
  journal      = {Frontiers in Computer Science},
  month        = {4},
  pages        = {515362},
  shortjournal = {Front. Comput. Sci.},
  title        = {Development and evaluation of the nebraska assessment of computing knowledge},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). HOMEX: Persuasive technology acceptance model and the
moderating effect of culture. <em>FCOMP</em>, <em>2</em>, 521849. (<a
href="https://doi.org/10.3389/fcomp.2020.00010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The number of fitness applications on the market is increasing annually, driven by the increasing awareness of the need to support and motivate physical activity to reduce the incidence of non-communicable diseases worldwide. However, there is limited research on the user-experience (UX) design attributes that drive their adoption and the moderating role culture plays. Consequently, we conducted a study on the Persuasive Technology Acceptance Model (PTAM) for a fitness application aimed at motivating physical activity at home. Using Canada (an individualist culture, n = 189) and Nigeria (a collectivist culture, n = 67) as a case study, we investigated: (1) which of the commonly researched UX design attributes (perceived aesthetics, perceived usability, perceived credibility and perceived usefulness) have the strongest influence on users&#39; intention to use a fitness application; (2) the moderating effect of culture; and (3) how perceived persuasiveness mediates the direct effect of perceived usefulness on the intention to use a fitness application. The results of our path analysis show that, regardless of culture, perceived usefulness and perceived aesthetics are the strongest determinants of users&#39; intention to use a fitness application, with perceived usefulness being stronger in the collectivist culture than in the individualist culture. Secondly, our results show that perceived persuasiveness partially mediates the effect of perceived usefulness on intention to use for the individualist culture, but not for the collectivist culture. Hence, we recommend that designers should invest more in improving functionality (utilitarian benefit) and aesthetics (hedonic benefit) than other UX design attributes such as credibility and usability. However, for the collectivist culture, designers should focus more on usefulness than aesthetics. On the other hand, for the individualist culture, designers should strike a balance between usefulness and aesthetics. Our main contribution is that, our study, to the best of our knowledge, is the first to investigate the moderating effect of culture using subjects from North America and Africa (an understudied population) as a case study.},
  archive      = {J_FCOMP},
  author       = {Oyibo, Kiemute and Vassileva, Julita},
  doi          = {10.3389/fcomp.2020.00010},
  journal      = {Frontiers in Computer Science},
  month        = {3},
  pages        = {521849},
  shortjournal = {Front. Comput. Sci.},
  title        = {HOMEX: Persuasive technology acceptance model and the moderating effect of culture},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Integration of the ImageJ ecosystem in KNIME analytics
platform. <em>FCOMP</em>, <em>2</em>, 502883. (<a
href="https://doi.org/10.3389/fcomp.2020.00008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Open-source software tools are often used for the analysis of scientific image data due to their flexibility and transparency in dealing with rapidly evolving imaging technologies. The complex nature of image analysis problems frequently requires many tools to be used in conjunction, including image processing and analysis, data processing, machine learning and deep learning, statistical analysis of the results, visualization, correlation to heterogeneous but related data, and more. However, the development, and therefore application, of these computational tools is impeded by a lack of integration across platforms. Integration of tools goes beyond convenience, as it is impractical for one tool to anticipate and accommodate the current and future needs of every user. This problem is emphasized in the field of bioimage analysis, where various rapidly emerging methods are quickly being adopted by researchers. ImageJ is a popular open-source image analysis platform, with contributions from a worldwide community resulting in hundreds of specialized routines for a wide array of scientific tasks. ImageJ&#39;s strength lies in its accessibility and extensibility, allowing researchers to easily improve the software to solve their image analysis tasks. However, ImageJ is not designed for the development of complex end-to-end image analysis workflows. Scientists are often forced to create highly specialized and hard-to-reproduce scripts to orchestrate individual software fragments and cover the entire life cycle of an analysis of an image dataset. KNIME Analytics Platform, a user-friendly data integration, analysis, and exploration workflow system, was designed to handle huge amounts of heterogeneous data in a platform-agnostic, computing environment and has been successful in meeting complex end-to-end demands in several communities, such as cheminformatics and mass spectrometry. Similar needs within the bioimage analysis community led to the creation of the KNIME Image Processing extension, which integrates ImageJ into KNIME Analytics Platform, enabling researchers to develop reproducible and scalable workflows, integrating a diverse range of analysis tools. Here, we present how users and developers alike can leverage the ImageJ ecosystem via the KNIME Image Processing extension to provide robust and extensible image analysis within KNIME workflows. We illustrate the benefits of this integration with examples, as well as representative scientific use cases.},
  archive      = {J_FCOMP},
  author       = {Dietz, Christian and Rueden, Curtis T. and Helfrich, Stefan and Dobson, Ellen T. A. and Horn, Martin and Eglinger, Jan and Evans, Edward L. and McLean, Dalton T. and Novitskaya, Tatiana and Ricke, William A. and Sherer, Nathan M. and Zijlstra, Andries and Berthold, Michael R. and Eliceiri, Kevin W.},
  doi          = {10.3389/fcomp.2020.00008},
  journal      = {Frontiers in Computer Science},
  month        = {3},
  pages        = {502883},
  shortjournal = {Front. Comput. Sci.},
  title        = {Integration of the ImageJ ecosystem in KNIME analytics platform},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Relevance-based data masking: A model-agnostic transfer
learning approach for facial expression recognition. <em>FCOMP</em>,
<em>2</em>, 502441. (<a
href="https://doi.org/10.3389/fcomp.2020.00006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning approaches are now a popular choice in the field of automatic emotion recognition (AER) across various modalities. Due to the high costs of manually labeling human emotions however, the amount of available training data is relatively scarce in comparison to other tasks. To facilitate the learning process and reduce the necessary amount of training-data, modern approaches therefore often rely on leveraging knowledge from models that have already been trained on related tasks where data is available abundantly. In this work we introduce a novel approach to transfer learning, which addresses two shortcomings of traditional methods: The (partial) inheritance of the original models structure and the restriction to other neural network models as an input source. To this end we identify the parts in the input that have been relevant for the decision of the model we want to transfer knowledge from, and directly encode those relevant regions in the data on which we train our new model. To validate our approach we performed experiments on well-established datasets for the task of automatic facial expression recognition. The results of those experiments are suggesting that our approach helps to accelerate the learning process.},
  archive      = {J_FCOMP},
  author       = {Schiller, Dominik and Huber, Tobias and Dietz, Michael and André, Elisabeth},
  doi          = {10.3389/fcomp.2020.00006},
  journal      = {Frontiers in Computer Science},
  month        = {3},
  pages        = {502441},
  shortjournal = {Front. Comput. Sci.},
  title        = {Relevance-based data masking: A model-agnostic transfer learning approach for facial expression recognition},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dynamic concept maps for eTextbook glossaries: Design and
evaluation. <em>FCOMP</em>, <em>2</em>, 517867. (<a
href="https://doi.org/10.3389/fcomp.2020.00007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Glossaries play a major role in enhancing students&#39; comprehension of core concepts. Glossary terms have complex interrelationship that cannot be fully illustrated by standard approaches such as including all terms in a linear, alphabetized list. To overcome this limitation, we introduce an interactive design for glossary terms within the OpenDSA interactive eTextbook system using concept maps. Glossary terms are visualized as nodes in graphs and their relationships are described on the edges. A concept map associated with the selected term is generated on demand. We evaluate the effectiveness of our design by comparing student use of our concept-map based glossary to the traditional alphabetized list. We used exercises that target the comprehension of the glossary terms to make students familiar with the concept maps.},
  archive      = {J_FCOMP},
  author       = {Elgendi, Ehsan and Shaffer, Clifford A.},
  doi          = {10.3389/fcomp.2020.00007},
  journal      = {Frontiers in Computer Science},
  month        = {2},
  pages        = {517867},
  shortjournal = {Front. Comput. Sci.},
  title        = {Dynamic concept maps for eTextbook glossaries: Design and evaluation},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Measuring the effects of caffeine and l-theanine on
cognitive performance: A protocol for self-directed, mobile n-of-1
studies. <em>FCOMP</em>, <em>2</em>, 512965. (<a
href="https://doi.org/10.3389/fcomp.2020.00004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background: The growing consumer digital tools market has made using individual health data to inform lifestyle changes more accessible than ever. The n-of-1 trial–a single participant, multiple crossover, comparative effectiveness trial–offers methodological tools that link interventions directly with personalized outcomes to determine the best treatment for an individual. We have developed a complete digital platform to support self-directed n-of-1 trials, comprised of virtual study on-boarding, visual informed consent, device integrations, in-app assessments, and automated data analysis.Objective: To evaluate the n-of-1 platform, a pilot study was launched to investigate the effects of commonly consumed substances on cognition. The purpose of the study is to allow an individual to measure the effect of 2 treatments (caffeine alone vs. caffeine + L-theanine) on 3 measures of cognitive performance: creative thinking, processing speed, and visual attention. Upon completion of the study, individuals receive personalized results that compare the impact of the two treatments on each of the cognitive performance measures.Methods: After the onboarding process, participants are randomized to a study length (5, 15, or 27 days), starting treatment (caffeine or caffeine + L-theanine), and app notification frequency (light, moderate). Each trial begins with a baseline period, during which participants abstain from either treatment, followed by 2 randomized counterbalanced treatment sequences (either ABBA or BAAB). Throughout the trial, daily tests assess participant cognitive performance. These tests are digital versions of the Remote Associates Test, Stroop Test, and Trail Making Test, and are implemented directly in the n-of-1 mobile application (“N1”). Assessments are completed at a fixed time, defined by the individual during study setup. Treatments are taken daily within a fixed time window prior to the user-defined assessment time. Cognitive assessment results are analyzed using a linear model with factors for treatment and block, and each treatment is compared to baseline.Results: We launched our N1 app on the Apple App Store in mid-October 2019 and recruited over 40 participants within the first month.Conclusion: This platform provides individuals the opportunity to investigate their response to treatments through n-of-1 methods, empowering them to make data-driven, personalized lifestyle choices.Trial Registration:www.ClinicalTrials.gov, identifier: NCT04056650.},
  archive      = {J_FCOMP},
  author       = {Golden, Eddye and Johnson, Matthew and Jones, Michael and Viglizzo, Ryan and Bobe, Jason and Zimmerman, Noah},
  doi          = {10.3389/fcomp.2020.00004},
  journal      = {Frontiers in Computer Science},
  month        = {2},
  pages        = {512965},
  shortjournal = {Front. Comput. Sci.},
  title        = {Measuring the effects of caffeine and L-theanine on cognitive performance: A protocol for self-directed, mobile N-of-1 studies},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Data-efficient framework for personalized physiotherapy
feedback. <em>FCOMP</em>, <em>2</em>, 510906. (<a
href="https://doi.org/10.3389/fcomp.2020.00003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physiotherapy is a labor-intensive process that has become increasingly inaccessible. Existing telehealth solutions overcome many of the logistical problems, but they are cumbersome to re-calibrate for the various exercises involved. To facilitate self-exercise efficiently, we developed a framework for personalized physiotherapy exercises. Our approach eliminates the need to re-calibrate for different exercises, using only few user-specific demonstrations available during collocated therapy. Two types of augmented feedback are available to the user for self-correction. The framework&#39;s utility was demonstrated for the sit-to-stand task, an important activity of daily living. Although further testing is necessary, our results suggest that the framework can be generalized to the learning of arbitrary motor behaviors.},
  archive      = {J_FCOMP},
  author       = {Lao, Bryan and Tamei, Tomoya and Ikeda, Kazushi},
  doi          = {10.3389/fcomp.2020.00003},
  journal      = {Frontiers in Computer Science},
  month        = {2},
  pages        = {510906},
  shortjournal = {Front. Comput. Sci.},
  title        = {Data-efficient framework for personalized physiotherapy feedback},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Strengthening enforcement in a comprehensive architecture
for privacy enforcement at internet websites. <em>FCOMP</em>,
<em>2</em>, 490775. (<a
href="https://doi.org/10.3389/fcomp.2020.00002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper extends previous work to strengthen the enforcement portion of a comprehensive architecture for enforcing privacy when a user needs to submit personal data to an Internet website in order to obtain goods or services. Our extension proposes to use a website&#39;s P3P privacy policy (derived in an automated way from its internal XACML access control policy) as a public key to encrypt the user&#39;s data using IBE (identity-based encryption) technology. The website will only acquire the corresponding private key to decrypt this data if a trusted 3rd-party auditor (acting as an IBE private key generator) has verified that the P3P policy is an accurate statement of the site&#39;s internal privacy practices. We discuss all the components of this model and describe our proof-of-concept implementation which demonstrates that such an architecture is feasible in real-world scenarios.},
  archive      = {J_FCOMP},
  author       = {Adams, Carlisle and Dai, Yu and DesOrmeaux, Catherine and McAvoy, Sean and Nguyen, NamChi and Trindade, Francisco},
  doi          = {10.3389/fcomp.2020.00002},
  journal      = {Frontiers in Computer Science},
  month        = {2},
  pages        = {490775},
  shortjournal = {Front. Comput. Sci.},
  title        = {Strengthening enforcement in a comprehensive architecture for privacy enforcement at internet websites},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A review of generalizable transfer learning in automatic
emotion recognition. <em>FCOMP</em>, <em>2</em>, 488594. (<a
href="https://doi.org/10.3389/fcomp.2020.00009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic emotion recognition is the process of identifying human emotion from signals such as facial expression, speech, and text. Collecting and labeling such signals is often tedious and many times requires expert knowledge. An effective way to address challenges related to the scarcity of data and lack of human labels, is transfer learning. In this manuscript, we will describe fundamental concepts in the field of transfer learning and review work which has successfully applied transfer learning for automatic emotion recognition. We will finally discuss promising future research directions of transfer learning for improving the generalizability of automatic emotion recognition systems.},
  archive      = {J_FCOMP},
  author       = {Feng, Kexin and Chaspari, Theodora},
  doi          = {10.3389/fcomp.2020.00009},
  journal      = {Frontiers in Computer Science},
  month        = {2},
  pages        = {488594},
  shortjournal = {Front. Comput. Sci.},
  title        = {A review of generalizable transfer learning in automatic emotion recognition},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Probabilistic Noise2Void: Unsupervised content-aware
denoising. <em>FCOMP</em>, <em>2</em>, 481941. (<a
href="https://doi.org/10.3389/fcomp.2020.00005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today, Convolutional Neural Networks (CNNs) are the leading method for image denoising. They are traditionally trained on pairs of images, which are often hard to obtain for practical applications. This motivates self-supervised training methods, such as Noise2Void (N2V) that operate on single noisy images. Self-supervised methods are, unfortunately, not competitive with models trained on image pairs. Here, we present Probabilistic Noise2Void (PN2V), a method to train CNNs to predict per-pixel intensity distributions. Combining these with a suitable description of the noise, we obtain a complete probabilistic model for the noisy observations and true signal in every pixel. We evaluate PN2V on publicly available microscopy datasets, under a broad range of noise regimes, and achieve competitive results with respect to supervised state-of-the-art methods.},
  archive      = {J_FCOMP},
  author       = {Krull, Alexander and Vičar, Tomáš and Prakash, Mangal and Lalit, Manan and Jug, Florian},
  doi          = {10.3389/fcomp.2020.00005},
  journal      = {Frontiers in Computer Science},
  month        = {2},
  pages        = {481941},
  shortjournal = {Front. Comput. Sci.},
  title        = {Probabilistic Noise2Void: Unsupervised content-aware denoising},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An active data representation of videos for automatic
scoring of oral presentation delivery skills and feedback generation.
<em>FCOMP</em>, <em>2</em>, 485167. (<a
href="https://doi.org/10.3389/fcomp.2020.00001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Public speaking is an important skill, the acquisition of which requires dedicated and time consuming training. In recent years, researchers have started to investigate automatic methods to support public speaking skills training. These methods include assessment of the trainee&#39;s oral presentation delivery skills which may be accomplished through automatic understanding and processing of social and behavioral cues displayed by the presenter. In this study, we propose an automatic scoring system for presentation delivery skills using a novel active data representation method to automatically rate segments of a full video presentation. While most approaches have employed a two step strategy consisting of detecting multiple events followed by classification, which involve the annotation of data for building the different event detectors and generating a data representation based on their output for classification, our method does not require event detectors. The proposed data representation is generated unsupervised using low-level audiovisual descriptors and self-organizing mapping and used for video classification. This representation is also used to analyse video segments within a full video presentation in terms of several characteristics of the presenter&#39;s performance. The audio representation provides the best prediction results for self-confidence and enthusiasm, posture and body language, structure and connection of ideas, and overall presentation delivery. The video data representation provides the best results for presentation of relevant information with good pronunciation, usage of language according to audience, and maintenance of adequate voice volume for the audience. The fusion of audio and video data provides the best results for eye contact. Applications of the method to provision of feedback to teachers and trainees are discussed.},
  archive      = {J_FCOMP},
  author       = {Haider, Fasih and Koutsombogera, Maria and Conlan, Owen and Vogel, Carl and Campbell, Nick and Luz, Saturnino},
  doi          = {10.3389/fcomp.2020.00001},
  journal      = {Frontiers in Computer Science},
  month        = {1},
  pages        = {485167},
  shortjournal = {Front. Comput. Sci.},
  title        = {An active data representation of videos for automatic scoring of oral presentation delivery skills and feedback generation},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Guidelines for the development of immersive virtual reality
software for cognitive neuroscience and neuropsychology: The development
of virtual reality everyday assessment lab (VR-EAL), a
neuropsychological test battery in immersive virtual reality.
<em>FCOMP</em>, <em>1</em>, 497368. (<a
href="https://doi.org/10.3389/fcomp.2019.00012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Virtual reality (VR) head-mounted displays (HMD) appear to be effective research tools, which may address the problem of ecological validity in neuropsychological testing. However, their widespread implementation is hindered by VR induced symptoms and effects (VRISE) and the lack of skills in VR software development. This study offers guidelines for the development of VR software in cognitive neuroscience and neuropsychology, by describing and discussing the stages of the development of Virtual Reality Everyday Assessment Lab (VR-EAL), the first neuropsychological battery in immersive VR. Techniques for evaluating cognitive functions within a realistic storyline are discussed. The utility of various assets in Unity, software development kits, and other software are described so that cognitive scientists can overcome challenges pertinent to VRISE and the quality of the VR software. In addition, this pilot study attempts to evaluate VR-EAL in accordance with the necessary criteria for VR software for research purposes. The VR neuroscience questionnaire (VRNQ; Kourtesis et al., 2019b) was implemented to appraise the quality of the three versions of VR-EAL in terms of user experience, game mechanics, in-game assistance, and VRISE. Twenty-five participants aged between 20 and 45 years with 12–16 years of full-time education evaluated various versions of VR-EAL. The final version of VR-EAL achieved high scores in every sub-score of the VRNQ and exceeded its parsimonious cut-offs. It also appeared to have better in-game assistance and game mechanics, while its improved graphics substantially increased the quality of the user experience and almost eradicated VRISE. The results substantially support the feasibility of the development of effective VR research and clinical software without the presence of VRISE during a 60-min VR session.},
  archive      = {J_FCOMP},
  author       = {Kourtesis, Panagiotis and Korre, Danai and Collina, Simona and Doumas, Leonidas A. A. and MacPherson, Sarah E.},
  doi          = {10.3389/fcomp.2019.00012},
  journal      = {Frontiers in Computer Science},
  month        = {1},
  pages        = {497368},
  shortjournal = {Front. Comput. Sci.},
  title        = {Guidelines for the development of immersive virtual reality software for cognitive neuroscience and neuropsychology: The development of virtual reality everyday assessment lab (VR-EAL), a neuropsychological test battery in immersive virtual reality},
  volume       = {1},
  year         = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
