<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>FROBT_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="frobt---211">FROBT - 211</h2>
<ul>
<li><details>
<summary>
(2020). Editorial: Bridging the gap between the lab and the real
world: Future perspectives for legged robots. <em>FROBT</em>,
<em>7</em>, 629002. (<a
href="https://doi.org/10.3389/frobt.2020.629002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Focchi, Michele and Pucci, Daniele and Del Prete, Andrea},
  doi          = {10.3389/frobt.2020.629002},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {629002},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: bridging the gap between the lab and the real world: future perspectives for legged robots},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A soft five-fingered hand actuated by shape memory alloy
wires: Design, manufacturing, and evaluation. <em>FROBT</em>,
<em>7</em>, 608841. (<a
href="https://doi.org/10.3389/frobt.2020.608841">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a novel five-fingered soft hand prototype actuated by Shape Memory Alloy (SMA) wires. The use of thin (100 μm diameter) SMA wire actuators, in conjunction with an entirely 3D printed hand skeleton, guarantees an overall lightweight and flexible structure capable of silent motion. To enable high forces with sufficiently high actuation speed at each fingertip, bundles of welded actuated SMA wires are used. In order to increase the compliance of each finger, flexible joints from superelastic SMA wires are inserted between each phalanx. The resulting system is a versatile hand prototype having intrinsically elastic fingers, which is capable to grasp several types of objects with a considerable force. The paper starts with the description of the finger hand design, along with practical considerations for the optimal placement of the superelastic SMA in the soft joint. The maximum achievable displacement of each finger phalanx is measured together with the phalanxes dynamic responsiveness at different power stimuli. Several force measurement are also realized at each finger phalanx. The versatility of the prototype is finally demonstrated by presenting several possible hand configurations while handling objects with different sizes and shapes.},
  archive      = {J_FROBT},
  author       = {Simone, Filomena and Rizzello, Gianluca and Seelecke, Stefan and Motzki, Paul},
  doi          = {10.3389/frobt.2020.608841},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {608841},
  shortjournal = {Front. Robot. AI},
  title        = {A soft five-fingered hand actuated by shape memory alloy wires: Design, manufacturing, and evaluation},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Genetic fuzzy based scalable system of distributed robots
for a collaborative task. <em>FROBT</em>, <em>7</em>, 601243. (<a
href="https://doi.org/10.3389/frobt.2020.601243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a new genetic fuzzy based paradigm for developing scalable set of decentralized homogenous robots for a collaborative task. In this work, the number of robots in the team can be changed without any additional training. The dynamic problem considered in this work involves multiple stationary robots that are assigned with the goal of bringing a common effector, which is physically connected to each of these robots through cables, to any arbitrary target position within the workspace of the robots. The robots do not communicate with each other. This means that each robot has no explicit knowledge of the actions of the other robots in the team. At any instant, the robots only have information related to the common effector and the target. Genetic Fuzzy System (GFS) framework is used to train controllers for the robots to achieve the common goal. The same GFS model is shared among all robots. This way, we take advantage of the homogeneity of the robots to reduce the training parameters. This also provides the capability to scale to any team size without any additional training. This paper shows the effectiveness of this methodology by testing the system on an extensive set of cases involving teams with different number of robots. Although the robots are stationary, the GFS framework presented in this paper does not put any restriction on the placement of the robots. This paper describes the scalable GFS framework and its applicability across a wide set of cases involving a variety of team sizes and robot locations. We also show results in the case of moving targets.},
  archive      = {J_FROBT},
  author       = {Sathyan, Anoop and Cohen, Kelly and Ma, Ou},
  doi          = {10.3389/frobt.2020.601243},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {601243},
  shortjournal = {Front. Robot. AI},
  title        = {Genetic fuzzy based scalable system of distributed robots for a collaborative task},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Editorial: Towards real world impacts: Design, development,
and deployment of social robots in the wild. <em>FROBT</em>, <em>7</em>,
600830. (<a href="https://doi.org/10.3389/frobt.2020.600830">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Park, Chung Hyuk and Ros, Raquel and Kwak, Sonya S. and Huang, Chien-Ming and Lemaignan, Séverin},
  doi          = {10.3389/frobt.2020.600830},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {600830},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: towards real world impacts: design, development, and deployment of social robots in the wild},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Combining self-organizing and graph neural networks for
modeling deformable objects in robotic manipulation. <em>FROBT</em>,
<em>7</em>, 600584. (<a
href="https://doi.org/10.3389/frobt.2020.600584">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling deformable objects is an important preliminary step for performing robotic manipulation tasks with more autonomy and dexterity. Currently, generalization capabilities in unstructured environments using analytical approaches are limited, mainly due to the lack of adaptation to changes in the object shape and properties. Therefore, this paper proposes the design and implementation of a data-driven approach, which combines machine learning techniques on graphs to estimate and predict the state and transition dynamics of deformable objects with initially undefined shape and material characteristics. The learned object model is trained using RGB-D sensor data and evaluated in terms of its ability to estimate the current state of the object shape, in addition to predicting future states with the goal to plan and support the manipulation actions of a robotic hand.},
  archive      = {J_FROBT},
  author       = {Valencia, Angel J. and Payeur, Pierre},
  doi          = {10.3389/frobt.2020.600584},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {600584},
  shortjournal = {Front. Robot. AI},
  title        = {Combining self-organizing and graph neural networks for modeling deformable objects in robotic manipulation},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Motion planning and iterative learning control of a modular
soft robotic snake. <em>FROBT</em>, <em>7</em>, 599242. (<a
href="https://doi.org/10.3389/frobt.2020.599242">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Snake robotics is an important research topic with a wide range of applications, including inspection in confined spaces, search-and-rescue, and disaster response. Snake robots are well-suited to these applications because of their versatility and adaptability to unstructured and constrained environments. In this paper, we introduce a soft pneumatic robotic snake that can imitate the capabilities of biological snakes, its soft body can provide flexibility and adaptability to the environment. This paper combines soft mobile robot modeling, proprioceptive feedback control, and motion planning to pave the way for functional soft robotic snake autonomy. We propose a pressure-operated soft robotic snake with a high degree of modularity that makes use of customized embedded flexible curvature sensing. On this platform, we introduce the use of iterative learning control using feedback from the on-board curvature sensors to enable the snake to automatically correct its gait for superior locomotion. We also present a motion planning and trajectory tracking algorithm using an adaptive bounding box, which allows for efficient motion planning that still takes into account the kinematic state of the soft robotic snake. We test this algorithm experimentally, and demonstrate its performance in obstacle avoidance scenarios.},
  archive      = {J_FROBT},
  author       = {Luo, Ming and Wan, Zhenyu and Sun, Yinan and Skorina, Erik H. and Tao, Weijia and Chen, Fuchen and Gopalka, Lakshay and Yang, Hao and Onal, Cagdas D.},
  doi          = {10.3389/frobt.2020.599242},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {599242},
  shortjournal = {Front. Robot. AI},
  title        = {Motion planning and iterative learning control of a modular soft robotic snake},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Relationship between muscular activity and assistance
magnitude for a myoelectric model based controlled exosuit.
<em>FROBT</em>, <em>7</em>, 595844. (<a
href="https://doi.org/10.3389/frobt.2020.595844">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing field of soft wearable exosuits, is gradually gaining terrain and proposing new complementary solutions in assistive technology, with several advantages in terms of portability, kinematic transparency, ergonomics, and metabolic efficiency. Those are palatable benefits that can be exploited in several applications, ranging from strength and resistance augmentation in industrial scenarios, to assistance or rehabilitation for people with motor impairments. To be effective, however, an exosuit needs to synergistically work with the human and matching specific requirements in terms of both movements kinematics and dynamics: an accurate and timely intention-detection strategy is the paramount aspect which assume a fundamental importance for acceptance and usability of such technology. We previously proposed to tackle this challenge by means of a model-based myoelectric controller, treating the exosuit as an external muscular layer in parallel to the human biomechanics and as such, controlled by the same efferent motor commands of biological muscles. However, previous studies that used classical control methods, demonstrated that the level of device&#39;s intervention and effectiveness of task completion are not linearly related: therefore, using a newly implemented EMG-driven controller, we isolated and characterized the relationship between assistance magnitude and muscular benefits, with the goal to find a range of assistance which could make the controller versatile for both dynamic and static tasks. Ten healthy participants performed the experiment resembling functional daily activities living in separate assistance conditions: without the device&#39;s active support and with different levels of intervention by the exosuit. Higher assistance levels resulted in larger reductions in the activity of the muscles augmented by the suit actuation and a good performance in motion accuracy, despite involving a decrease of the movement velocities, with respect to the no assistance condition. Moreover, increasing torque magnitude by the exosuit resulted in a significant reduction in the biological torque at the elbow joint and in a progressive effective delay in the onset of muscular fatigue. Thus, contrarily to classical force and proportional myoelectric schemes, the implementation of an opportunely tailored EMG-driven model based controller affords to naturally match user&#39;s intention detection and provide an assistance level working symbiotically with the human biomechanics.},
  archive      = {J_FROBT},
  author       = {Missiroli, Francesco and Lotti, Nicola and Xiloyannis, Michele and Sloot, Lizeth H. and Riener, Robert and Masia, Lorenzo},
  doi          = {10.3389/frobt.2020.595844},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {595844},
  shortjournal = {Front. Robot. AI},
  title        = {Relationship between muscular activity and assistance magnitude for a myoelectric model based controlled exosuit},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Feature guided search for creative problem solving through
tool construction. <em>FROBT</em>, <em>7</em>, 592382. (<a
href="https://doi.org/10.3389/frobt.2020.592382">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots in the real world should be able to adapt to unforeseen circumstances. Particularly in the context of tool use, robots may not have access to the tools they need for completing a task. In this paper, we focus on the problem of tool construction in the context of task planning. We seek to enable robots to construct replacements for missing tools using available objects, in order to complete the given task. We introduce the Feature Guided Search (FGS) algorithm that enables the application of existing heuristic search approaches in the context of task planning, to perform tool construction efficiently. FGS accounts for physical attributes of objects (e.g., shape, material) during the search for a valid task plan. Our results demonstrate that FGS significantly reduces the search effort over standard heuristic search approaches by ≈93% for tool construction.},
  archive      = {J_FROBT},
  author       = {Nair, Lakshmi and Chernova, Sonia},
  doi          = {10.3389/frobt.2020.592382},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {592382},
  shortjournal = {Front. Robot. AI},
  title        = {Feature guided search for creative problem solving through tool construction},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Phormica: Photochromic pheromone release and detection
system for stigmergic coordination in robot swarms. <em>FROBT</em>,
<em>7</em>, 591402. (<a
href="https://doi.org/10.3389/frobt.2020.591402">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stigmergy is a form of indirect communication and coordination in which agents modify the environment to pass information to their peers. In nature, animals use stigmergy by, for example, releasing pheromone that conveys information to other members of their species. A few systems in swarm robotics research have replicated this process by introducing the concept of artificial pheromone. In this paper, we present Phormica, a system to conduct experiments in swarm robotics that enables a swarm of e-puck robots to release and detect artificial pheromone. Phormica emulates pheromone-based stigmergy thanks to the ability of robots to project UV light on the ground, which has been previously covered with a photochromic material. As a proof of concept, we test Phormica on three collective missions in which robots act collectively guided by the artificial pheromone they release and detect. Experimental results indicate that a robot swarm can effectively self-organize and act collectively by using stigmergic coordination based on the artificial pheromone provided by Phormica.},
  archive      = {J_FROBT},
  author       = {Salman, Muhammad and Garzón Ramos, David and Hasselmann, Ken and Birattari, Mauro},
  doi          = {10.3389/frobt.2020.591402},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {591402},
  shortjournal = {Front. Robot. AI},
  title        = {Phormica: Photochromic pheromone release and detection system for stigmergic coordination in robot swarms},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Variable impedance control and learning—a review.
<em>FROBT</em>, <em>7</em>, 590681. (<a
href="https://doi.org/10.3389/frobt.2020.590681">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots that physically interact with their surroundings, in order to accomplish some tasks or assist humans in their activities, require to exploit contact forces in a safe and proficient manner. Impedance control is considered as a prominent approach in robotics to avoid large impact forces while operating in unstructured environments. In such environments, the conditions under which the interaction occurs may significantly vary during the task execution. This demands robots to be endowed with online adaptation capabilities to cope with sudden and unexpected changes in the environment. In this context, variable impedance control arises as a powerful tool to modulate the robot&#39;s behavior in response to variations in its surroundings. In this survey, we present the state-of-the-art of approaches devoted to variable impedance control from control and learning perspectives (separately and jointly). Moreover, we propose a new taxonomy for mechanical impedance based on variability, learning, and control. The objective of this survey is to put together the concepts and efforts that have been done so far in this field, and to describe advantages and disadvantages of each approach. The survey concludes with open issues in the field and an envisioned framework that may potentially solve them.},
  archive      = {J_FROBT},
  author       = {Abu-Dakka, Fares J. and Saveriano, Matteo},
  doi          = {10.3389/frobt.2020.590681},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {590681},
  shortjournal = {Front. Robot. AI},
  title        = {Variable impedance control and Learning—A review},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Analysis of compensatory movements using a supernumerary
robotic hand for upper limb assistance. <em>FROBT</em>, <em>7</em>,
587759. (<a href="https://doi.org/10.3389/frobt.2020.587759">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, extratheses, aka Supernumerary Robotic Limbs (SRLs), are emerging as a new trend in the field of assistive and rehabilitation devices. We proposed the SoftHand X, a system composed of an anthropomorphic soft hand extrathesis, with a gravity support boom and a control interface for the patient. In preliminary tests, the system exhibited a positive outlook toward assisting impaired people during daily life activities and fighting learned-non-use of the impaired arm. However, similar to many robot-aided therapies, the use of the system may induce side effects that can be detrimental and worsen patients&#39; conditions. One of the most common is the onset of alternative grasping strategies and compensatory movements, which clinicians absolutely need to counter in physical therapy. Before embarking in systematic experimentation with the SoftHand X on patients, it is essential that the system is demonstrated not to lead to an increase of compensation habits. This paper provides a detailed description of the compensatory movements performed by healthy subjects using the SoftHand X. Eleven right-handed healthy subjects were involved within an experimental protocol in which kinematic data of the upper body and EMG signals of the arm were acquired. Each subject executed tasks with and without the robotic system, considering this last situation as reference of optimal behavior. A comparison between two different configurations of the robotic hand was performed to understand if this aspect may affect the compensatory movements. Results demonstrated that the use of the apparatus reduces the range of motion of the wrist, elbow and shoulder, while it increases the range of the trunk and head movements. On the other hand, EMG analysis indicated that muscle activation was very similar among all the conditions. Results obtained suggest that the system may be used as assistive device without causing an over-use of the arm joints, and opens the way to clinical trials with patients.},
  archive      = {J_FROBT},
  author       = {Rossero, Martina and Ciullo, Andrea S. and Grioli, Giorgio and Catalano, Manuel G. and Bicchi, Antonio},
  doi          = {10.3389/frobt.2020.587759},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {587759},
  shortjournal = {Front. Robot. AI},
  title        = {Analysis of compensatory movements using a supernumerary robotic hand for upper limb assistance},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Machine gaze: Self-identification through play with a
computer vision-based projection and robotics system. <em>FROBT</em>,
<em>7</em>, 580835. (<a
href="https://doi.org/10.3389/frobt.2020.580835">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Children begin to develop self-awareness when they associate images and abilities with themselves. Such “construction of self” continues throughout adult life as we constantly cycle through different forms of self-awareness, seeking, to redefine ourselves. Modern technologies like screens and artificial intelligence threaten to alter our development of self-awareness, because children and adults are exposed to machines, tele-presences, and displays that increasingly become part of human identity. We use avatars, invent digital lives, and augment ourselves with digital imprints that depart from reality, making the development of self-identification adjust to digital technologies that blur the boundary between us and our devices. To empower children and adults to see themselves and artificially intelligent machines as separately aware entities, we created the persona of a salvaged supermarket security camera refurbished and enhanced with the power of computer vision to detect human faces, and project them on a large-scale 3D face sculpture. The surveillance camera system moves its head to point to human faces at times, but at other times, humans have to get its attention by moving to its vicinity, creating a dynamic where audiences attempt to see their own faces on the sculpture by gazing into the machine&#39;s eye. We found that audiences began attaining an understanding of machines that interpret our faces as separate from our identities, with their own agendas and agencies that show by the way they serendipitously interact with us. The machine-projected images of us are their own interpretation rather than our own, distancing us from our digital analogs. In the accompanying workshop, participants learn about how computer vision works by putting on disguises in order to escape from an algorithm detecting them as the same person by analyzing their faces. Participants learn that their own agency affects how machines interpret them, gaining an appreciation for the way their own identities and machines&#39; awareness of them can be separate entities that can be manipulated for play. Together the installation and workshop empower children and adults to think beyond identification with digital technology to recognize the machine&#39;s own interpretive abilities that lie separate from human being&#39;s own self-awareness.},
  archive      = {J_FROBT},
  author       = {LC, RAY and Alcibar, Aaliyah and Baez, Alejandro and Torossian, Stefanie},
  doi          = {10.3389/frobt.2020.580835},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {580835},
  shortjournal = {Front. Robot. AI},
  title        = {Machine gaze: Self-identification through play with a computer vision-based projection and robotics system},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Applicability of an active back-support exoskeleton to
carrying activities. <em>FROBT</em>, <em>7</em>, 579963. (<a
href="https://doi.org/10.3389/frobt.2020.579963">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Occupational back-support exoskeletons are becoming a more and more common solution to mitigate work-related lower-back pain associated with lifting activities. In addition to lifting, there are many other tasks performed by workers, such as carrying, pushing, and pulling, that might benefit from the use of an exoskeleton. In this work, the impact that carrying has on lower-back loading compared to lifting and the need to select different assistive strategies based on the performed task are presented. This latter need is studied by using a control strategy that commands for constant torques. The results of the experimental campaign conducted on 9 subjects suggest that such a control strategy is beneficial for the back muscles (up to 12% reduction in overall lumbar activity), but constrains the legs (around 10% reduction in hip and knee ranges of motion). Task recognition and the design of specific controllers can be exploited by active and, partially, passive exoskeletons to enhance their versatility, i.e., the ability to adapt to different requirements.},
  archive      = {J_FROBT},
  author       = {Poliero, Tommaso and Lazzaroni, Maria and Toxiri, Stefano and Di Natali, Christian and Caldwell, Darwin G. and Ortiz, Jesús},
  doi          = {10.3389/frobt.2020.579963},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {579963},
  shortjournal = {Front. Robot. AI},
  title        = {Applicability of an active back-support exoskeleton to carrying activities},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A framework for automatic behavior generation in
multi-function swarms. <em>FROBT</em>, <em>7</em>, 579403. (<a
href="https://doi.org/10.3389/frobt.2020.579403">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-function swarms are swarms that solve multiple tasks at once. For example, a quadcopter swarm could be tasked with exploring an area of interest while simultaneously functioning as ad-hoc relays. With this type of multi-function comes the challenge of handling potentially conflicting requirements simultaneously. Using the Quality-Diversity algorithm MAP-elites in combination with a suitable controller structure, a framework for automatic behavior generation in multi-function swarms is proposed. The framework is tested on a scenario with three simultaneous tasks: exploration, communication network creation and geolocation of Radio Frequency (RF) emitters. A repertoire is evolved, consisting of a wide range of controllers, or behavior primitives, with different characteristics and trade-offs in the different tasks. This repertoire enables the swarm to online transition between behaviors featuring different trade-offs of applications depending on the situational requirements. Furthermore, the effect of noise on the behavior characteristics in MAP-elites is investigated. A moderate number of re-evaluations is found to increase the robustness while keeping the computational requirements relatively low. A few selected controllers are examined, and the dynamics of transitioning between these controllers are explored. Finally, the study investigates the importance of individual sensor or controller inputs. This is done through ablation, where individual inputs are disabled and their impact on the performance of the swarm controllers is assessed and analyzed.},
  archive      = {J_FROBT},
  author       = {Engebraaten, Sondre A. and Moen, Jonas and Yakimenko, Oleg A. and Glette, Kyrre},
  doi          = {10.3389/frobt.2020.579403},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {579403},
  shortjournal = {Front. Robot. AI},
  title        = {A framework for automatic behavior generation in multi-function swarms},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A brief survey of telerobotic time delay mitigation.
<em>FROBT</em>, <em>7</em>, 578805. (<a
href="https://doi.org/10.3389/frobt.2020.578805">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is a substantial number of telerobotics and teleoperation applications ranging from space operations, ground/aerial robotics, drive-by-wire systems to medical interventions. Major obstacles for such applications include latency, channel corruptions, and bandwidth which limit teleoperation efficacy. This survey reviews the time delay problem in teleoperation systems. We briefly review different solutions from early approaches which consist of control-theory-based models and user interface designs and focus on newer approaches developed since 2014. Future solutions to the time delay problem will likely be hybrid solutions which include modeling of user intent, prediction of robot movements, and time delay prediction all potentially using time series prediction methods. Hence, we examine methods that are primarily based on time series prediction. Recent prediction approaches take advantage of advances in nonlinear statistical models as well as machine learning and neural network techniques. We review Recurrent Neural Networks, Long Short-Term Memory, Sequence to Sequence, and Generative Adversarial Network models and examine each of these approaches for addressing time delay. As time delay is still an unsolved problem, we suggest some possible future research directions from information-theory-based modeling, which may lead to promising new approaches to advancing the field.},
  archive      = {J_FROBT},
  author       = {Farajiparvar, Parinaz and Ying, Hao and Pandya, Abhilash},
  doi          = {10.3389/frobt.2020.578805},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {578805},
  shortjournal = {Front. Robot. AI},
  title        = {A brief survey of telerobotic time delay mitigation},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evaluation of motor primitive-based adaptive control for
lower limb exoskeletons. <em>FROBT</em>, <em>7</em>, 575217. (<a
href="https://doi.org/10.3389/frobt.2020.575217">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to assist after-stroke individuals to rehabilitate their movements, research centers have developed lower limbs exoskeletons and control strategies for them. Robot-assisted therapy can help not only by providing support, accuracy, and precision while performing exercises, but also by being able to adapt to different patient needs, according to their impairments. As a consequence, different control strategies have been employed and evaluated, although with limited effectiveness. This work presents a bio-inspired controller, based on the concept of motor primitives. The proposed approach was evaluated on a lower limbs exoskeleton, in which the knee joint was driven by a series elastic actuator. First, to extract the motor primitives, the user torques were estimated by means of a generalized momentum-based disturbance observer combined with an extended Kalman filter. These data were provided to the control algorithm, which, at every swing phase, assisted the subject to perform the desired movement, based on the analysis of his previous step. Tests are performed in order to evaluate the controller performance for a subject walking actively, passively, and at a combination of these two conditions. Results suggest that the robot assistance is capable of compensating the motor primitive weight deficiency when the subject exerts less torque than expected. Furthermore, though only the knee joint was actuated, the motor primitive weights with respect to the hip joint were influenced by the robot torque applied at the knee. The robot also generated torque to compensate for eventual asynchronous movements of the subject, and adapted to a change in the gait characteristics within three to four steps.},
  archive      = {J_FROBT},
  author       = {Nunes, Polyana F. and Ostan, Icaro and Siqueira, Adriano A. G.},
  doi          = {10.3389/frobt.2020.575217},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {575217},
  shortjournal = {Front. Robot. AI},
  title        = {Evaluation of motor primitive-based adaptive control for lower limb exoskeletons},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dynamic margins of stability during robot-assisted walking
in able-bodied individuals: A preliminary study. <em>FROBT</em>,
<em>7</em>, 574365. (<a
href="https://doi.org/10.3389/frobt.2020.574365">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background: Gait analysis studies during robot-assisted walking have been predominantly focused on lower limb biomechanics. During robot-assisted walking, the users&#39; interaction with the robot and their adaptations translate into altered gait mechanics. Hence, robust and objective metrics for quantifying walking performance during robot-assisted gait are especially relevant as it relates to dynamic stability. In this study, we assessed bi-planar dynamic stability margins for healthy adults during robot-assisted walking using EksoGT™, ReWalk™, and Indego® compared to independent overground walking at slow, self-selected, and fast speeds. Further, we examined the use of forearm crutches and its influence on dynamic gait stability margins.Methods: Kinematic data were collected at 60 Hz under several walking conditions with and without the robotic exoskeleton for six healthy controls. Outcome measures included (i) whole-body center of mass (CoM) and extrapolated CoM (XCoM), (ii) base of support (BoS), (iii) margin of stability (MoS) with respect to both feet and bilateral crutches.Results: Stability outcomes during exoskeleton-assisted walking at self-selected, comfortable walking speeds were significantly (p &amp;lt; 0.05) different compared to overground walking at self-selected speeds. Unlike overground walking, the control mechanisms for stability using these exoskeletons were not related to walking speed. MoSs were lower during the single support phase of gait, especially in the medial–lateral direction for all devices. MoSs relative to feet were significantly (p &amp;lt; 0.05) lower than those relative to crutches. The spatial location of crutches during exoskeleton-assisted walking pushed the whole-body CoM, during single support, beyond the lateral boundary of the lead foot, increasing the risk for falls if crutch slippage were to occur.Conclusion: Careful consideration of crutch placement is critical to ensuring that the margins of stability are always within the limits of the BoS to control stability and decrease fall risk.},
  archive      = {J_FROBT},
  author       = {Ramanujam, Arvind and Momeni, Kamyar and Ravi, Manikandan and Augustine, Jonathan and Garbarini, Erica and Barrance, Peter and Spungen, Ann M. and Asselin, Pierre and Knezevic, Steven and Forrest, Gail F.},
  doi          = {10.3389/frobt.2020.574365},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {574365},
  shortjournal = {Front. Robot. AI},
  title        = {Dynamic margins of stability during robot-assisted walking in able-bodied individuals: A preliminary study},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). FMG- and RNN-based estimation of motor intention of
upper-limb motion in human-robot collaboration. <em>FROBT</em>,
<em>7</em>, 573096. (<a
href="https://doi.org/10.3389/frobt.2020.573096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research on human-robot interactions has been driven by the increasing employment of robotic manipulators in manufacturing and production. Toward developing more effective human-robot collaboration during shared tasks, this paper proposes an interaction scheme by employing machine learning algorithms to interpret biosignals acquired from the human user and accordingly planning the robot reaction. More specifically, a force myography (FMG) band was wrapped around the user&#39;s forearm and was used to collect information about muscle contractions during a set of collaborative tasks between the user and an industrial robot. A recurrent neural network model was trained to estimate the user&#39;s hand movement pattern based on the collected FMG data to determine whether the performed motion was random or intended as part of the predefined collaborative tasks. Experimental evaluation during two practical collaboration scenarios demonstrated that the trained model could successfully estimate the category of hand motion, i.e., intended or random, such that the robot either assisted with performing the task or changed its course of action to avoid collision. Furthermore, proximity sensors were mounted on the robotic arm to investigate if monitoring the distance between the user and the robot had an effect on the outcome of the collaborative effort. While further investigation is required to rigorously establish the safety of the human worker, this study demonstrates the potential of FMG-based wearable technologies to enhance human-robot collaboration in industrial settings.},
  archive      = {J_FROBT},
  author       = {Anvaripour, Mohammad and Khoshnam, Mahta and Menon, Carlo and Saif, Mehrdad},
  doi          = {10.3389/frobt.2020.573096},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {573096},
  shortjournal = {Front. Robot. AI},
  title        = {FMG- and RNN-based estimation of motor intention of upper-limb motion in human-robot collaboration},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optical see-through head-mounted displays with short focal
distance: Conditions for mitigating parallax-related registration error.
<em>FROBT</em>, <em>7</em>, 572001. (<a
href="https://doi.org/10.3389/frobt.2020.572001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optical see-through (OST) augmented reality head-mounted displays are quickly emerging as a key asset in several application fields but their ability to profitably assist high precision activities in the peripersonal space is still sub-optimal due to the calibration procedure required to properly model the user&#39;s viewpoint through the see-through display. In this work, we demonstrate the beneficial impact, on the parallax-related AR misregistration, of the use of optical see-through displays whose optical engines collimate the computer-generated image at a depth close to the fixation point of the user in the peripersonal space. To estimate the projection parameters of the OST display for a generic viewpoint position, our strategy relies on a dedicated parameterization of the virtual rendering camera based on a calibration routine that exploits photogrammetry techniques. We model the registration error due to the viewpoint shift and we validate it on an OST display with short focal distance. The results of the tests demonstrate that with our strategy the parallax-related registration error is submillimetric provided that the scene under observation stays within a suitable view volume that falls in a ±10 cm depth range around the focal plane of the display. This finding will pave the way to the development of new multi-focal models of OST HMDs specifically conceived to aid high-precision manual tasks in the peripersonal space.},
  archive      = {J_FROBT},
  author       = {Cutolo, Fabrizio and Cattari, Nadia and Fontana, Umberto and Ferrari, Vincenzo},
  doi          = {10.3389/frobt.2020.572001},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {572001},
  shortjournal = {Front. Robot. AI},
  title        = {Optical see-through head-mounted displays with short focal distance: Conditions for mitigating parallax-related registration error},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). ExoNet database: Wearable camera images of human locomotion
environments. <em>FROBT</em>, <em>7</em>, 562061. (<a
href="https://doi.org/10.3389/frobt.2020.562061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Laschowski, Brock and McNally, William and Wong, Alexander and McPhee, John},
  doi          = {10.3389/frobt.2020.562061},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {562061},
  shortjournal = {Front. Robot. AI},
  title        = {ExoNet database: Wearable camera images of human locomotion environments},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A formal account of structuring motor actions with sensory
prediction for a naive agent. <em>FROBT</em>, <em>7</em>, 561660. (<a
href="https://doi.org/10.3389/frobt.2020.561660">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For naive robots to become truly autonomous, they need a means of developing their perceptive capabilities instead of relying on hand crafted models. The sensorimotor contingency theory asserts that such a way resides in learning invariants of the sensorimotor flow. We propose a formal framework inspired by this theory for the description of sensorimotor experiences of a naive agent, extending previous related works. We then use said formalism to conduct a theoretical study where we isolate sufficient conditions for the determination of a sensory prediction function. Furthermore, we also show that algebraic structure found in this prediction can be taken as a proxy for structure on the motor displacements, allowing for the discovery of the combinatorial structure of said displacements. Both these claims are further illustrated in simulations where a toy naive agent determines the sensory predictions of its spatial displacements from its uninterpreted sensory flow, which it then uses to infer the combinatorics of said displacements.},
  archive      = {J_FROBT},
  author       = {Godon, Jean-Merwan and Argentieri, Sylvain and Gas, Bruno},
  doi          = {10.3389/frobt.2020.561660},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {561660},
  shortjournal = {Front. Robot. AI},
  title        = {A formal account of structuring motor actions with sensory prediction for a naive agent},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The eternal robot: Anchoring effects in humans’ mental
models of robots and their self. <em>FROBT</em>, <em>7</em>, 546724. (<a
href="https://doi.org/10.3389/frobt.2020.546724">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current robot designs often reflect an anthropomorphic approach, apparently aiming to convince users through an ideal system, being most similar or even on par with humans. The present paper challenges human-likeness as a design goal and questions whether simulating human appearance and performance adequately fits into how humans think about robots in a conceptual sense, i.e., human&#39;s mental models of robots and their self. Independent of the technical possibilities and limitations, our paper explores robots&#39; attributed potential to become human-like by means of a thought experiment. Four hundred eighty-one participants were confronted with fictional transitions from human-to-robot and robot-to-human, consisting of 20 subsequent steps. In each step, one part or area of the human (e.g., brain, legs) was replaced with robotic parts providing equal functionalities and vice versa. After each step, the participants rated the remaining humanness and remaining self of the depicted entity on a scale from 0 to 100%. It showed that the starting category (e.g., human, robot) serves as an anchor for all former judgments and can hardly be overcome. Even if all body parts had been exchanged, a former robot was not perceived as totally human-like and a former human not as totally robot-like. Moreover, humanness appeared as a more sensible and easier denied attribute than robotness, i.e., after the objectively same transition and exchange of the same parts, the former human was attributed less humanness and self left compared to the former robot&#39;s robotness and self left. The participants&#39; qualitative statements about why the robot has not become human-like, often concerned the (unnatural) process of production, or simply argued that no matter how many parts are exchanged, the individual keeps its original entity. Based on such findings, we suggest that instead of designing most human-like robots in order to reach acceptance, it might be more promising to understand robots as an own “species” and underline their specific characteristics and benefits. Limitations of the present study and implications for future HRI research and practice are discussed.},
  archive      = {J_FROBT},
  author       = {Ullrich, Daniel and Butz, Andreas and Diefenbach, Sarah},
  doi          = {10.3389/frobt.2020.546724},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {546724},
  shortjournal = {Front. Robot. AI},
  title        = {The eternal robot: Anchoring effects in humans&#39; mental models of robots and their self},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Crossmodal pattern discrimination in humans and robots: A
visuo-tactile case study. <em>FROBT</em>, <em>7</em>, 540565. (<a
href="https://doi.org/10.3389/frobt.2020.540565">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quality of crossmodal perception hinges on two factors: The accuracy of the independent unimodal perception and the ability to integrate information from different sensory systems. In humans, the ability for cognitively demanding crossmodal perception diminishes from young to old age. Here, we propose a new approach to research to which degree the different factors contribute to crossmodal processing and the age-related decline by replicating a medical study on visuo-tactile crossmodal pattern discrimination utilizing state-of-the-art tactile sensing technology and artificial neural networks (ANN). We implemented two ANN models to specifically focus on the relevance of early integration of sensory information during the crossmodal processing stream as a mechanism proposed for efficient processing in the human brain. Applying an adaptive staircase procedure, we approached comparable unimodal classification performance for both modalities in the human participants as well as the ANN. This allowed us to compare crossmodal performance between and within the systems, independent of the underlying unimodal processes. Our data show that unimodal classification accuracies of the tactile sensing technology are comparable to humans. For crossmodal discrimination of the ANN the integration of high-level unimodal features on earlier stages of the crossmodal processing stream shows higher accuracies compared to the late integration of independent unimodal classifications. In comparison to humans, the ANN show higher accuracies than older participants in the unimodal as well as the crossmodal condition, but lower accuracies than younger participants in the crossmodal task. Taken together, we can show that state-of-the-art tactile sensing technology is able to perform a complex tactile recognition task at levels comparable to humans. For crossmodal processing, human inspired early sensory integration seems to improve the performance of artificial neural networks. Still, younger participants seem to employ more efficient crossmodal integration mechanisms than modeled in the proposed ANN. Our work demonstrates how collaborative research in neuroscience and embodied artificial neurocognitive models can help to derive models to inform the design of future neurocomputational architectures.},
  archive      = {J_FROBT},
  author       = {Higgen, Focko L. and Ruppel, Philipp and Görner, Michael and Kerzel, Matthias and Hendrich, Norman and Feldheim, Jan and Wermter, Stefan and Zhang, Jianwei and Gerloff, Christian},
  doi          = {10.3389/frobt.2020.540565},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {540565},
  shortjournal = {Front. Robot. AI},
  title        = {Crossmodal pattern discrimination in humans and robots: A visuo-tactile case study},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Emotion recognition for human-robot interaction: Recent
advances and future perspectives. <em>FROBT</em>, <em>7</em>, 532279.
(<a href="https://doi.org/10.3389/frobt.2020.532279">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A fascinating challenge in the field of human–robot interaction is the possibility to endow robots with emotional intelligence in order to make the interaction more intuitive, genuine, and natural. To achieve this, a critical point is the capability of the robot to infer and interpret human emotions. Emotion recognition has been widely explored in the broader fields of human–machine interaction and affective computing. Here, we report recent advances in emotion recognition, with particular regard to the human–robot interaction context. Our aim is to review the state of the art of currently adopted emotional models, interaction modalities, and classification strategies and offer our point of view on future developments and critical issues. We focus on facial expressions, body poses and kinematics, voice, brain activity, and peripheral physiological responses, also providing a list of available datasets containing data from these modalities.},
  archive      = {J_FROBT},
  author       = {Spezialetti, Matteo and Placidi, Giuseppe and Rossi, Silvia},
  doi          = {10.3389/frobt.2020.532279},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {532279},
  shortjournal = {Front. Robot. AI},
  title        = {Emotion recognition for human-robot interaction: Recent advances and future perspectives},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Control protocols for range-based navigation of a networked
group of underwater vehicles. <em>FROBT</em>, <em>7</em>, 519985. (<a
href="https://doi.org/10.3389/frobt.2020.519985">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper tackles the problem of formation reconstruction for a team of vehicles based on the knowledge of the range between agents of a subset of the participants. One main peculiarity of the proposed approach is that the relative velocity between agents, which is a fundamental data to solve the problem, is not assumed to be known in advance neither directly communicated. For the purpose of estimating this quantity, a collaborative control protocol is designed in order to mount the velocity data in the motion of each vehicle as a parameter through a dedicated control protocol, so that it can be inferred from the motion of the neighbor agents. Moreover, some suitable geometrical constraints related to the agents&#39; relative positions are built and explicitly taken into account in the estimation framework providing a more accurate estimate. The issue of the presence of delays in the transmitted signals is also studied and two possible solutions are provided explaining how it is possible to get a reasonable range data exchange to get the solution both in a centralized fashion and in a decentralized one. Numerical examples are presented corroborating the validity of the proposed approach.},
  archive      = {J_FROBT},
  author       = {De Palma, Daniela and Indiveri, Giovanni and Parlangeli, Gianfranco},
  doi          = {10.3389/frobt.2020.519985},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {519985},
  shortjournal = {Front. Robot. AI},
  title        = {Control protocols for range-based navigation of a networked group of underwater vehicles},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Automatic fracture characterization using tactile and
proximity optical sensing. <em>FROBT</em>, <em>7</em>, 513004. (<a
href="https://doi.org/10.3389/frobt.2020.513004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper demonstrates how tactile and proximity sensing can be used to perform automatic mechanical fractures detection (surface cracks). For this purpose, a custom-designed integrated tactile and proximity sensor has been implemented. With the help of fiber optics, the sensor measures the deformation of its body, when interacting with the physical environment, and the distance to the environment&#39;s objects. This sensor slides across different surfaces and records data which are then analyzed to detect and classify fractures and other mechanical features. The proposed method implements machine learning techniques (handcrafted features, and state of the art classification algorithms). An average crack detection accuracy of ~94% and width classification accuracy of ~80% is achieved. Kruskal-Wallis results (p &amp;lt; 0.001) indicate statistically significant differences among results obtained when analysing only integrated deformation measurements, only proximity measurements and both deformation and proximity data. A real-time classification method has been implemented for online classification of explored surfaces. In contrast to previous techniques, which mainly rely on visual modality, the proposed approach based on optical fibers might be more suitable for operation in extreme environments (such as nuclear facilities) where radiation may damage electronic components of commonly employed sensing devices, such as standard force sensors based on strain gauges and video cameras.},
  archive      = {J_FROBT},
  author       = {Palermo, Francesca and Konstantinova, Jelizaveta and Althoefer, Kaspar and Poslad, Stefan and Farkhatdinov, Ildar},
  doi          = {10.3389/frobt.2020.513004},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {513004},
  shortjournal = {Front. Robot. AI},
  title        = {Automatic fracture characterization using tactile and proximity optical sensing},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dielectric elastomer actuator driven soft robotic structures
with bioinspired skeletal and muscular reinforcement. <em>FROBT</em>,
<em>7</em>, 510757. (<a
href="https://doi.org/10.3389/frobt.2020.510757">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural motion types found in skeletal and muscular systems of vertebrate animals inspire researchers to transfer this ability into engineered motion, which is highly desired in robotic systems. Dielectric elastomer actuators (DEAs) have shown promising capabilities as artificial muscles for driving such structures, as they are soft, lightweight, and can generate large strokes. For maximum performance, dielectric elastomer membranes need to be sufficiently pre-stretched. This fact is challenging, because it is difficult to integrate pre-stretched membranes into entirely soft systems, since the stored strain energy can significantly deform soft elements. Here, we present a soft robotic structure, possessing a bioinspired skeleton integrated into a soft body element, driven by an antagonistic pair of DEA artificial muscles, that enable the robot bending. In its equilibrium state, the setup maintains optimum isotropic pre-stretch. The robot itself has a length of 60 mm and is based on a flexible silicone body, possessing embedded transverse 3D printed struts. These rigid bone-like elements lead to an anisotropic bending stiffness, which only allows bending in one plane while maintaining the DEA&#39;s necessary pre-stretch in the other planes. The bones, therefore, define the degrees of freedom and stabilize the system. The DEAs are manufactured by aerosol deposition of a carbon-silicone-composite ink onto a stretchable membrane that is heat cured. Afterwards, the actuators are bonded to the top and bottom of the silicone body. The robotic structure shows large and defined bimorph bending curvature and operates in static as well as dynamic motion. Our experiments describe the influence of membrane pre-stretch and varied stiffness of the silicone body on the static and dynamic bending displacement, resonance frequencies and blocking forces. We also present an analytical model based on the Classical Laminate Theory for the identification of the main influencing parameters. Due to the simple design and processing, our new concept of a bioinspired DEA based robotic structure, with skeletal and muscular reinforcement, offers a wide range of robotic application.},
  archive      = {J_FROBT},
  author       = {Franke, M. and Ehrenhofer, A. and Lahiri, S. and Henke, E.-F. M. and Wallmersperger, T. and Richter, A.},
  doi          = {10.3389/frobt.2020.510757},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {510757},
  shortjournal = {Front. Robot. AI},
  title        = {Dielectric elastomer actuator driven soft robotic structures with bioinspired skeletal and muscular reinforcement},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modeling task uncertainty for safe meta-imitation learning.
<em>FROBT</em>, <em>7</em>, 606361. (<a
href="https://doi.org/10.3389/frobt.2020.606361">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To endow robots with the flexibility to perform a wide range of tasks in diverse and complex environments, learning their controller from experience data is a promising approach. In particular, some recent meta-learning methods are shown to solve novel tasks by leveraging their experience of performing other tasks during training. Although studies around meta-learning of robot control have worked on improving the performance, the safety issue has not been fully explored, which is also an important consideration in the deployment. In this paper, we firstly relate uncertainty on task inference with the safety in meta-learning of visual imitation, and then propose a novel framework for estimating the task uncertainty through probabilistic inference in the task-embedding space, called PETNet. We validate PETNet with a manipulation task with a simulated robot arm in terms of the task performance and uncertainty evaluation on task inference. Following the standard benchmark procedure in meta-imitation learning, we show PETNet can achieve the same or higher level of performance (success rate of novel tasks at meta-test time) as previous methods. In addition, by testing PETNet with semantically inappropriate or synthesized out-of-distribution demonstrations, PETNet shows the ability to capture the uncertainty about the tasks inherent in the given demonstrations, which allows the robot to identify situations where the controller might not perform properly. These results illustrate our proposal takes a significant step forward to the safe deployment of robot learning systems into diverse tasks and environments.},
  archive      = {J_FROBT},
  author       = {Matsushima, Tatsuya and Kondo, Naruya and Iwasawa, Yusuke and Nasuno, Kaoru and Matsuo, Yutaka},
  doi          = {10.3389/frobt.2020.606361},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {606361},
  shortjournal = {Front. Robot. AI},
  title        = {Modeling task uncertainty for safe meta-imitation learning},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Employing pneumatic, telescopic actuators for the
development of soft and hybrid robotic grippers. <em>FROBT</em>,
<em>7</em>, 601274. (<a
href="https://doi.org/10.3389/frobt.2020.601274">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditionally, the robotic end-effectors that are employed in unstructured and dynamic environments are rigid and their operation requires sophisticated sensing elements and complicated control algorithms in order to handle and manipulate delicate and fragile objects. Over the last decade, considerable research effort has been put into the development of adaptive, under-actuated, soft robots that facilitate robust interactions with dynamic environments. In this paper, we present soft, retractable, pneumatically actuated, telescopic actuators that facilitate the efficient execution of stable grasps involving a plethora of everyday life objects. The efficiency of the proposed actuators is validated by employing them in two different soft and hybrid robotic grippers. The hybrid gripper uses three rigid fingers to accomplish the execution of all the tasks required by a traditional robotic gripper, while three inflatable, telescopic fingers provide soft interaction with objects. This synergistic combination of soft and rigid structures allows the gripper to cage/trap and firmly hold heavy and irregular objects. The second, simplistic and highly affordable robotic gripper employs just the telescopic actuators, exhibiting an adaptive behavior during the execution of stable grasps of fragile and delicate objects. The experiments demonstrate that both grippers can successfully and stably grasp a wide range of objects, being able to exert significantly high contact forces.},
  archive      = {J_FROBT},
  author       = {Gerez, Lucas and Chang, Che-Ming and Liarokapis, Minas},
  doi          = {10.3389/frobt.2020.601274},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {601274},
  shortjournal = {Front. Robot. AI},
  title        = {Employing pneumatic, telescopic actuators for the development of soft and hybrid robotic grippers},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Editorial: Designing self-organization in the physical
realm. <em>FROBT</em>, <em>7</em>, 597859. (<a
href="https://doi.org/10.3389/frobt.2020.597859">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Hamann, Heiko and Schranz, Melanie and Elmenreich, Wilfried and Trianni, Vito and Pinciroli, Carlo and Bredeche, Nicolas and Ferrante, Eliseo},
  doi          = {10.3389/frobt.2020.597859},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {597859},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Designing self-organization in the physical realm},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). COVID-19 pandemic spurs medical telerobotic systems: A
survey of applications requiring physiological organ motion
compensation. <em>FROBT</em>, <em>7</em>, 594673. (<a
href="https://doi.org/10.3389/frobt.2020.594673">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The coronavirus disease 2019 (COVID-19) pandemic has resulted in public health interventions such as physical distancing restrictions to limit the spread and transmission of the novel coronavirus, causing significant effects on the delivery of physical healthcare procedures worldwide. The unprecedented pandemic spurs strong demand for intelligent robotic systems in healthcare. In particular, medical telerobotic systems can play a positive role in the provision of telemedicine to both COVID-19 and non-COVID-19 patients. Different from typical studies on medical teleoperation that consider problems such as time delay and information loss in long-distance communication, this survey addresses the consequences of physiological organ motion when using teleoperation systems to create physical distancing between clinicians and patients in the COVID-19 era. We focus on the control-theoretic approaches that have been developed to address inherent robot control issues associated with organ motion. The state-of-the-art telerobotic systems and their applications in COVID-19 healthcare delivery are reviewed, and possible future directions are outlined.},
  archive      = {J_FROBT},
  author       = {Cheng, Lingbo and Tavakoli, Mahdi},
  doi          = {10.3389/frobt.2020.594673},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {594673},
  shortjournal = {Front. Robot. AI},
  title        = {COVID-19 pandemic spurs medical telerobotic systems: A survey of applications requiring physiological organ motion compensation},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). End-to-end automated latent fingerprint identification with
improved DCNN-FFT enhancement. <em>FROBT</em>, <em>7</em>, 594412. (<a
href="https://doi.org/10.3389/frobt.2020.594412">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic Latent Fingerprint Identification Systems (AFIS) are most widely used by forensic experts in law enforcement and criminal investigations. One of the critical steps used in automatic latent fingerprint matching is to automatically extract reliable minutiae from fingerprint images. Hence, minutiae extraction is considered to be a very important step in AFIS. The performance of such systems relies heavily on the quality of the input fingerprint images. Most of the state-of-the-art AFIS failed to produce good matching results due to poor ridge patterns and the presence of background noise. To ensure the robustness of fingerprint matching against low quality latent fingerprint images, it is essential to include a good fingerprint enhancement algorithm before minutiae extraction and matching. In this paper, we have proposed an end-to-end fingerprint matching system to automatically enhance, extract minutiae, and produce matching results. To achieve this, we have proposed a method to automatically enhance the poor-quality fingerprint images using the “Automated Deep Convolutional Neural Network (DCNN)” and “Fast Fourier Transform (FFT)” filters. The Deep Convolutional Neural Network (DCNN) produces a frequency enhanced map from fingerprint domain knowledge. We propose an “FFT Enhancement” algorithm to enhance and extract the ridges from the frequency enhanced map. Minutiae from the enhanced ridges are automatically extracted using a proposed “Automated Latent Minutiae Extractor (ALME)”. Based on the extracted minutiae, the fingerprints are automatically aligned, and a matching score is calculated using a proposed “Frequency Enhanced Minutiae Matcher (FEMM)” algorithm. Experiments are conducted on FVC2002, FVC2004, and NIST SD27 latent fingerprint databases. The minutiae extraction results show significant improvement in precision, recall, and F1 scores. We obtained the highest Rank-1 identification rate of 100% for FVC2002/2004 and 84.5% for NIST SD27 fingerprint databases. The matching results reveal that the proposed system outperforms state-of-the-art systems.},
  archive      = {J_FROBT},
  author       = {Deshpande, Uttam U. and Malemath, V. S. and Patil, Shivanand M. and Chaugule, Sushma V.},
  doi          = {10.3389/frobt.2020.594412},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {594412},
  shortjournal = {Front. Robot. AI},
  title        = {End-to-end automated latent fingerprint identification with improved DCNN-FFT enhancement},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Automatic detection and classification of knee
osteoarthritis using hu’s invariant moments. <em>FROBT</em>, <em>7</em>,
591827. (<a href="https://doi.org/10.3389/frobt.2020.591827">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Significant information extraction from the images that are geometrically distorted or transformed is mainstream procedure in image processing. It becomes difficult to retrieve the relevant region when the images get distorted by some geometric deformation. Hu&#39;s moments are helpful in extracting information from such distorted images due to their unique invariance property. This work focuses on early detection and gradation of Knee Osteoarthritis utilizing Hu&#39;s invariant moments to understand the geometric transformation of the cartilage region in Knee X-ray images. The seven invariant moments are computed for the rotated version of the test image. The results demonstrated are found to be more competitive and promising, which are validated by ortho surgeons and rheumatologists.},
  archive      = {J_FROBT},
  author       = {Gornale, Shivanand S. and Patravali, Pooja U. and Hiremath, Prakash S.},
  doi          = {10.3389/frobt.2020.591827},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {591827},
  shortjournal = {Front. Robot. AI},
  title        = {Automatic detection and classification of knee osteoarthritis using hu&#39;s invariant moments},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Editorial: Robot-assisted learning and education.
<em>FROBT</em>, <em>7</em>, 591319. (<a
href="https://doi.org/10.3389/frobt.2020.591319">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Augello, Agnese and Daniela, Linda and Gentile, Manuel and Ifenthaler, Dirk and Pilato, Giovanni},
  doi          = {10.3389/frobt.2020.591319},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {591319},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Robot-assisted learning and education},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Applicant fairness perceptions of a robot-mediated job
interview: A video vignette-based experimental survey. <em>FROBT</em>,
<em>7</em>, 586263. (<a
href="https://doi.org/10.3389/frobt.2020.586263">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is well-established in the literature that biases (e. g., related to body size, ethnicity, race etc.) can occur during the employment interview and that applicants&#39; fairness perceptions related to selection procedures can influence attitudes, intentions, and behaviors toward the recruiting organization. This study explores how social robotics may affect this situation. Using an online, video vignette-based experimental survey (n = 235), the study examines applicant fairness perceptions of two types of job interviews: a face-to-face and a robot-mediated interview. To reduce the risk of socially desirable responses, desensitize the topic, and detect any inconsistencies in the respondents&#39; reactions to vignette scenarios, the study employs a first-person and a third-person perspective. In the robot-mediated interview, two teleoperated robots are used as fair proxies for the applicant and the interviewer, thus providing symmetrical visual anonymity unlike prior research that relied on asymmetrical anonymity, in which only one party was anonymized. This design is intended to eliminate visual cues that typically cause implicit biases and discrimination of applicants, but also to prevent biasing the interviewer&#39;s assessment through impression management tactics typically used by applicants. We hypothesize that fairness perception (i.e., procedural fairness and interactional fairness) and behavioral intentions (i.e., intentions of job acceptance, reapplication intentions, and recommendation intentions) will be higher in a robot-mediated job interview than in a face-to-face job interview, and that this effect will be stronger for introvert applicants. The study shows, contrary to our expectations, that the face-to-face interview is perceived as fairer, and that the applicant&#39;s personality (introvert vs. extravert) does not affect this perception. We discuss this finding and its implications, and address avenues for future research.},
  archive      = {J_FROBT},
  author       = {Nørskov, Sladjana and Damholdt, Malene F. and Ulhøi, John P. and Jensen, Morten B. and Ess, Charles and Seibt, Johanna},
  doi          = {10.3389/frobt.2020.586263},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {586263},
  shortjournal = {Front. Robot. AI},
  title        = {Applicant fairness perceptions of a robot-mediated job interview: A video vignette-based experimental survey},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Design of a high-speed prosthetic finger driven by
peano-HASEL actuators. <em>FROBT</em>, <em>7</em>, 586216. (<a
href="https://doi.org/10.3389/frobt.2020.586216">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current designs of powered prosthetic limbs are limited by the nearly exclusive use of DC motor technology. Soft actuators promise new design freedom to create prosthetic limbs which more closely mimic intact neuromuscular systems and improve the capabilities of prosthetic users. This work evaluates the performance of a hydraulically amplified self-healing electrostatic (HASEL) soft actuator for use in a prosthetic hand. We compare a linearly-contracting HASEL actuator, termed a Peano-HASEL, to an existing actuator (DC motor) when driving a prosthetic finger like those utilized in multi-functional prosthetic hands. A kinematic model of the prosthetic finger is developed and validated, and is used to customize a prosthetic finger that is tuned to complement the force-strain characteristics of the Peano-HASEL actuators. An analytical model is used to inform the design of an improved Peano-HASEL actuator with the goal of increasing the fingertip pinch force of the prosthetic finger. When compared to a weight-matched DC motor actuator, the Peano-HASEL and custom finger is 10.6 times faster, has 11.1 times higher bandwidth, and consumes 8.7 times less electrical energy to grasp. It reaches 91% of the maximum range of motion of the original finger. However, the DC motor actuator produces 10 times the fingertip force at a relevant grip position. In this body of work, we present ways to further increase the force output of the Peano-HASEL driven prosthetic finger system, and discuss the significance of the unique properties of Peano-HASELs when applied to the field of upper-limb prosthetic design. This approach toward clinically-relevant actuator performance paired with a substantially different form-factor compared to DC motors presents new opportunities to advance the field of prosthetic limb design.},
  archive      = {J_FROBT},
  author       = {Yoder, Zachary and Kellaris, Nicholas and Chase-Markopoulou, Christina and Ricken, Devon and Mitchell, Shane K. and Emmett, Madison B. and Weir, Richard F. ff. and Segil, Jacob and Keplinger, Christoph},
  doi          = {10.3389/frobt.2020.586216},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {586216},
  shortjournal = {Front. Robot. AI},
  title        = {Design of a high-speed prosthetic finger driven by peano-HASEL actuators},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Pilot study of trans-oral robotic-assisted needle direct
tracheostomy puncture in patients requiring prolonged mechanical
ventilation. <em>FROBT</em>, <em>7</em>, 575445. (<a
href="https://doi.org/10.3389/frobt.2020.575445">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 can induce severe respiratory problems that need prolonged mechanical ventilation in the intensive care unit. While Open Tracheostomy (OT) is the preferred technique due to the excellent visualization of the surgical field and structures, Percutaneous Tracheostomy (PT) has proven to be a feasible minimally invasive alternative. However, PT&#39;s limitation relates to the inability to precisely enter the cervical trachea at the exact spot since the puncture is often performed based on crude estimation from anatomical laryngeal surface landmarks. Besides, there is no absolute control of the trajectory and force required to make the percutaneous puncture into the trachea, resulting in inadvertent injury to the cricoid ring, cervical esophagus, and vessels in the neck. Therefore, we hypothesize that a flexible mini-robotic system, incorporating the robotic needling technology, can overcome these challenges by allowing the trans-oral robotic instrument of the cervical trachea. This approach promises to improve current PT technology by making the initial trachea puncture from an “inside-out” approach, rather than an “outside-in” manner, fraught with several technical uncertainties.},
  archive      = {J_FROBT},
  author       = {Xiao, Xiao and Poon, Howard and Lim, Chwee Ming and Meng, Max Q.-H. and Ren, Hongliang},
  doi          = {10.3389/frobt.2020.575445},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {575445},
  shortjournal = {Front. Robot. AI},
  title        = {Pilot study of trans-oral robotic-assisted needle direct tracheostomy puncture in patients requiring prolonged mechanical ventilation},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Practical aspects of model-based collision detection.
<em>FROBT</em>, <em>7</em>, 571574. (<a
href="https://doi.org/10.3389/frobt.2020.571574">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, with the increased number of robots entering numerous manufacturing fields, a considerable wealth of literature has appeared on the theme of physical human-robot interaction using data from proprioceptive sensors (motor or/and load side encoders). Most of the studies have then the accurate dynamic model of a robot for granted. In practice, however, model identification and observer design proceeds collision detection. To the best of our knowledge, no previous study has systematically investigated each aspect underlying physical human-robot interaction and the relationship between those aspects. In this paper, we bridge this gap by first reviewing the literature on model identification, disturbance estimation and collision detection, and discussing the relationship between the three, then by examining the practical sides of model-based collision detection on a case study conducted on UR10e. We show that the model identification step is critical for accurate collision detection, while the choice of the observer should be mostly based on computation time and the simplicity and flexibility of tuning. It is hoped that this study can serve as a roadmap to equip industrial robots with basic physical human-robot interaction capabilities.},
  archive      = {J_FROBT},
  author       = {Mamedov, Shamil and Mikhel, Stanislav},
  doi          = {10.3389/frobt.2020.571574},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {571574},
  shortjournal = {Front. Robot. AI},
  title        = {Practical aspects of model-based collision detection},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Effective multi-mode grasping assistance control of a soft
hand exoskeleton using force myography. <em>FROBT</em>, <em>7</em>,
567491. (<a href="https://doi.org/10.3389/frobt.2020.567491">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human intention detection is fundamental to the control of robotic devices in order to assist humans according to their needs. This paper presents a novel approach for detecting hand motion intention, i.e., rest, open, close, and grasp, and grasping force estimation using force myography (FMG). The output is further used to control a soft hand exoskeleton called an SEM Glove. In this method, two sensor bands constructed using force sensing resistor (FSR) sensors are utilized to detect hand motion states and muscle activities. Upon placing both bands on an arm, the sensors can measure normal forces caused by muscle contraction/relaxation. Afterwards, the sensor data is processed, and hand motions are identified through a threshold-based classification method. The developed method has been tested on human subjects for object-grasping tasks. The results show that the developed method can detect hand motions accurately and to provide assistance w.r.t to the task requirement.},
  archive      = {J_FROBT},
  author       = {Islam, Muhammad Raza Ul and Bai, Shaoping},
  doi          = {10.3389/frobt.2020.567491},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {567491},
  shortjournal = {Front. Robot. AI},
  title        = {Effective multi-mode grasping assistance control of a soft hand exoskeleton using force myography},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Repetitive robot behavior impacts perception of
intentionality and gaze-related attentional orienting. <em>FROBT</em>,
<em>7</em>, 565825. (<a
href="https://doi.org/10.3389/frobt.2020.565825">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gaze behavior is an important social signal between humans as it communicates locations of interest. People typically orient their attention to where others look as this informs about others&#39; intentions and future actions. Studies have shown that humans can engage in similar gaze behavior with robots but presumably more so when they adopt the intentional stance toward them (i.e., believing robot behaviors are intentional). In laboratory settings, the phenomenon of attending toward the direction of others&#39; gaze has been examined with the use of the gaze-cueing paradigm. While the gaze-cueing paradigm has been successful in investigating the relationship between adopting the intentional stance toward robots and attention orienting to gaze cues, it is unclear if the repetitiveness of the gaze-cueing paradigm influences adopting the intentional stance. Here, we examined if the duration of exposure to repetitive robot gaze behavior in a gaze-cueing task has a negative impact on subjective attribution of intentionality. Participants performed a short, medium, or long face-to-face gaze-cueing paradigm with an embodied robot while subjective ratings were collected pre and post the interaction. Results show that participants in the long exposure condition had the smallest change in their intention attribution scores, if any, while those in the short exposure condition had a positive change in their intention attribution, indicating that participants attributed more intention to the robot after short interactions. The results also show that attention orienting to robot gaze-cues was positively related to how much intention was attributed to the robot, but this relationship became more negative as the length of exposure increased. In contrast to subjective ratings, the gaze-cueing effects (GCEs) increased as a function of the duration of exposure to repetitive behavior. The data suggest a tradeoff between the desired number of trials needed for observing various mechanisms of social cognition, such as GCEs, and the likelihood of adopting the intentional stance toward a robot.},
  archive      = {J_FROBT},
  author       = {Abubshait, Abdulaziz and Wykowska, Agnieszka},
  doi          = {10.3389/frobt.2020.565825},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {565825},
  shortjournal = {Front. Robot. AI},
  title        = {Repetitive robot behavior impacts perception of intentionality and gaze-related attentional orienting},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Few-shot induction of generalized logical concepts via human
guidance. <em>FROBT</em>, <em>7</em>, 561926. (<a
href="https://doi.org/10.3389/frobt.2020.00122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of learning generalized first-order representations of concepts from a small number of examples. We augment an inductive logic programming learner with 2 novel contributions. First, we define a distance measure between candidate concept representations that improves the efficiency of search for target concept and generalization. Second, we leverage richer human inputs in the form of advice to improve the sample efficiency of learning. We prove that the proposed distance measure is semantically valid and use that to derive a PAC bound. Our experiments on diverse learning tasks demonstrate both the effectiveness and efficiency of our approach.},
  archive      = {J_FROBT},
  author       = {Das, Mayukh and Ramanan, Nandini and Doppa, Janardhan Rao and Natarajan, Sriraam},
  doi          = {10.3389/frobt.2020.00122},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {561926},
  shortjournal = {Front. Robot. AI},
  title        = {Few-shot induction of generalized logical concepts via human guidance},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Benchmarking wearable robots: Challenges and recommendations
from functional, user experience, and methodological perspectives.
<em>FROBT</em>, <em>7</em>, 561774. (<a
href="https://doi.org/10.3389/frobt.2020.561774">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wearable robots (WRs) are increasingly moving out of the labs toward real-world applications. In order for WRs to be effectively and widely adopted by end-users, a common benchmarking framework needs to be established. In this article, we outline the perspectives that in our opinion are the main determinants of this endeavor, and exemplify the complex landscape into three areas. The first perspective is related to quantifying the technical performance of the device and the physical impact of the device on the user. The second one refers to the understanding of the user&#39;s perceptual, emotional, and cognitive experience of (and with) the technology. The third one proposes a strategic path for a global benchmarking methodology, composed by reproducible experimental procedures representing real-life conditions. We hope that this paper can enable developers, researchers, clinicians and end-users to efficiently identify the most promising directions for validating their technology and drive future research efforts in the short and medium term.},
  archive      = {J_FROBT},
  author       = {Torricelli, Diego and Rodriguez-Guerrero, Carlos and Veneman, Jan F. and Crea, Simona and Briem, Kristin and Lenggenhager, Bigna and Beckerle, Philipp},
  doi          = {10.3389/frobt.2020.561774},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {561774},
  shortjournal = {Front. Robot. AI},
  title        = {Benchmarking wearable robots: Challenges and recommendations from functional, user experience, and methodological perspectives},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Kinesthetic device vs. Keyboard/mouse: A comparison in home
care telemanipulation. <em>FROBT</em>, <em>7</em>, 561015. (<a
href="https://doi.org/10.3389/frobt.2020.561015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensuring care is one of the biggest humanitarian challenges of the future since an acute shortage in nursing staff is expected. At the same time, this offers the opportunity for new technologies in nursing, as the use of robotic systems. One potential use case is outpatient care, which nowadays involves traveling long distances. Here, the use of telerobotics could provide a major relief for the nursing staff, as it could spare them many of those—partially far—journeys. Since autonomous robotic systems are not desired at least in Germany for ethical reasons, this paper evaluates the design of a telemanipulation system consisting of off-the-shelf components for outpatient care. Furthermore, we investigated the suitability of two different input devices for control, a kinesthetic device, and a keyboard plus mouse. We conducted the investigations in a laboratory study. This laboratory represents a realistic environment of an elderly home and a remote care service center. It was carried out with 25 nurses. Tasks common in outpatient care, such as handing out things (manipulation) and examining body parts (set camera view), were used in the study. After a short training period, all nurses were able to control a manipulator with the two input devices and perform the two tasks. It was shown that the Falcon leads to shorter execution times (on average 0:54.82 min, compared to 01:10.92 min with keyboard and mouse), whereby the participants were more successful with the keyboard plus mouse, in terms of task completion. There is no difference in usability and cognitive load. Moreover, we pointed out, that the access to this kind of technology is desirable, which is why we identified further usage scenarios.},
  archive      = {J_FROBT},
  author       = {Gliesche, Pascal and Krick, Tobias and Pfingsthorn, Max and Drolshagen, Sandra and Kowalski, Christian and Hein, Andreas},
  doi          = {10.3389/frobt.2020.561015},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {561015},
  shortjournal = {Front. Robot. AI},
  title        = {Kinesthetic device vs. Keyboard/Mouse: A comparison in home care telemanipulation},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Closed-loop control of electro-ribbon actuators.
<em>FROBT</em>, <em>7</em>, 557624. (<a
href="https://doi.org/10.3389/frobt.2020.557624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electro-ribbon actuators are lightweight, flexible, high-performance actuators for next generation soft robotics. When electrically charged, electrostatic forces cause the electrode ribbons to progressively zip together through a process called dielectrophoretic liquid zipping (DLZ), delivering contractions of more than 99% of their length. Electro-ribbon actuators exhibit pull-in instability, and this phenomenon makes them challenging to control: below the pull-in voltage threshold, actuator contraction is small, while above this threshold, increasing electrostatic forces cause the actuator to completely contract, providing a narrow contraction range for feedforward control. We show that application of a time-varying voltage profile that starts above pull-in threshold, but subsequently reduces, allows access to intermediate steady-states not accessible using traditional feed-forward control. A modified proportional-integral closed-loop controller is proposed (Boost-PI), which incorporates a variable boost voltage to temporarily elevate actuation close to, but not exceeding, the pull-in voltage threshold. This primes the actuator for zipping and drastically reduces rise time compared with a traditional PI controller. A multi-objective parameter-space approach was implemented to choose appropriate controller gains by assessing the metrics of rise time, overshoot, steady-state error, and settle time. This proposed control method addresses a key limitation of the electro-ribbon actuators, allowing the actuator to perform staircase and oscillatory control tasks. This significantly increases the range of applications which can exploit this new DLZ actuation technology.},
  archive      = {J_FROBT},
  author       = {Diteesawat, Richard Suphapol and Fishman, Aaron and Helps, Tim and Taghavi, Majid and Rossiter, Jonathan},
  doi          = {10.3389/frobt.2020.557624},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {557624},
  shortjournal = {Front. Robot. AI},
  title        = {Closed-loop control of electro-ribbon actuators},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Occurrence and type of adverse events during the use of
stationary gait robots—a systematic literature review. <em>FROBT</em>,
<em>7</em>, 557606. (<a
href="https://doi.org/10.3389/frobt.2020.557606">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robot-assisted gait training (RAGT) devices are used in rehabilitation to improve patients&#39; walking function. While there are some reports on the adverse events (AEs) and associated risks in overground exoskeletons, the risks of stationary gait trainers cannot be accurately assessed. We therefore aimed to collect information on AEs occurring during the use of stationary gait robots and identify associated risks, as well as gaps and needs, for safe use of these devices. We searched both bibliographic and full-text literature databases for peer-reviewed articles describing the outcomes of stationary RAGT and specifically mentioning AEs. We then compiled information on the occurrence and types of AEs and on the quality of AE reporting. Based on this, we analyzed the risks of RAGT in stationary gait robots. We included 50 studies involving 985 subjects and found reports of AEs in 18 of those studies. Many of the AE reports were incomplete or did not include sufficient detail on different aspects, such as severity or patient characteristics, which hinders the precise counts of AE-related information. Over 169 device-related AEs experienced by between 79 and 124 patients were reported. Soft tissue-related AEs occurred most frequently and were mostly reported in end-effector-type devices. Musculoskeletal AEs had the second highest prevalence and occurred mainly in exoskeleton-type devices. We further identified physiological AEs including blood pressure changes that occurred in both exoskeleton-type and end-effector-type devices. Training in stationary gait robots can cause injuries or discomfort to the skin, underlying tissue, and musculoskeletal system, as well as unwanted blood pressure changes. The underlying risks for the most prevalent injury types include excessive pressure and shear at the interface between robot and human (cuffs/harness), as well as increased moments and forces applied to the musculoskeletal system likely caused by misalignments (between joint axes of robot and human). There is a need for more structured and complete recording and dissemination of AEs related to robotic gait training to increase knowledge on risks. With this information, appropriate mitigation strategies can and should be developed and implemented in RAGT devices to increase their safety.},
  archive      = {J_FROBT},
  author       = {Bessler, Jule and Prange-Lasonder, Gerdienke B. and Schulte, Robert V. and Schaake, Leendert and Prinsen, Erik C. and Buurke, Jaap H.},
  doi          = {10.3389/frobt.2020.557606},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {557606},
  shortjournal = {Front. Robot. AI},
  title        = {Occurrence and type of adverse events during the use of stationary gait Robots—A systematic literature review},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Inertial-robotic motion tracking in end-effector-based
rehabilitation robots. <em>FROBT</em>, <em>7</em>, 554639. (<a
href="https://doi.org/10.3389/frobt.2020.554639">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {End-effector-based robotic systems provide easy-to-set-up motion support in rehabilitation of stroke and spinal-cord-injured patients. However, measurement information is obtained only about the motion of the limb segments to which the systems are attached and not about the adjacent limb segments. We demonstrate in one particular experimental setup that this limitation can be overcome by augmenting an end-effector-based robot with a wearable inertial sensor. Most existing inertial motion tracking approaches rely on a homogeneous magnetic field and thus fail in indoor environments and near ferromagnetic materials and electronic devices. In contrast, we propose a magnetometer-free sensor fusion method. It uses a quaternion-based algorithm to track the heading of a limb segment in real time by combining the gyroscope and accelerometer readings with position measurements of one point along that segment. We apply this method to an upper-limb rehabilitation robotics use case in which the orientation and position of the forearm and elbow are known, and the orientation and position of the upper arm and shoulder are estimated by the proposed method using an inertial sensor worn on the upper arm. Experimental data from five healthy subjects who performed 282 proper executions of a typical rehabilitation motion and 163 executions with compensation motion are evaluated. Using a camera-based system as a ground truth, we demonstrate that the shoulder position and the elbow angle are tracked with median errors around 4 cm and 4°, respectively; and that undesirable compensatory shoulder movements, which were defined as shoulder displacements greater ±10 cm for more than 20% of a motion cycle, are detected and classified 100% correctly across all 445 performed motions. The results indicate that wearable inertial sensors and end-effector-based robots can be combined to provide means for effective rehabilitation therapy with likewise detailed and accurate motion tracking for performance assessment, real-time biofeedback and feedback control of robotic and neuroprosthetic motion support.},
  archive      = {J_FROBT},
  author       = {Passon, Arne and Schauer, Thomas and Seel, Thomas},
  doi          = {10.3389/frobt.2020.554639},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {554639},
  shortjournal = {Front. Robot. AI},
  title        = {Inertial-robotic motion tracking in end-effector-based rehabilitation robots},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bioinspired postural controllers for a locked-ankle
exoskeleton targeting complete SCI users. <em>FROBT</em>, <em>7</em>,
553828. (<a href="https://doi.org/10.3389/frobt.2020.553828">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several lower-limb exoskeletons enable overcoming obstacles that would impair daily activities of wheelchair users, such as going upstairs. Still, as most of the currently commercialized exoskeletons require the use of crutches, they prevent the user from interacting efficiently with the environment. In a previous study, a bio-inspired controller was developed to allow dynamic standing balance for such exoskeletons. It was however only tested on the device without any user. This work describes and evaluates a new controller that extends this previous one with an online model compensation, and the contribution of the hip joint against strong perturbations. In addition, both controllers are tested with the exoskeleton TWIICE One, worn by a complete spinal cord injury pilot. Their performances are compared by the mean of three tasks: standing quietly, resisting external perturbations, and lifting barbells of increasing weight. The new controller exhibits a similar performance for quiet standing, longer recovery time for dynamic perturbations but better ability to sustain prolonged perturbations, and higher weightlifting capability.},
  archive      = {J_FROBT},
  author       = {Fasola, Jemina and Baud, Romain and Vouga, Tristan and Ijspeert, Auke and Bouri, Mohamed},
  doi          = {10.3389/frobt.2020.553828},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {553828},
  shortjournal = {Front. Robot. AI},
  title        = {Bioinspired postural controllers for a locked-ankle exoskeleton targeting complete SCI users},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Design, modeling, control, and application of everting vine
robots. <em>FROBT</em>, <em>7</em>, 548266. (<a
href="https://doi.org/10.3389/frobt.2020.548266">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In nature, tip-localized growth allows navigation in tightly confined environments and creation of structures. Recently, this form of movement has been artificially realized through pressure-driven eversion of flexible, thin-walled tubes. Here we review recent work on robots that “grow” via pressure-driven eversion, referred to as “everting vine robots,” due to a movement pattern that is similar to that of natural vines. We break this work into four categories. First, we examine the design of everting vine robots, highlighting tradeoffs in material selection, actuation methods, and placement of sensors and tools. These tradeoffs have led to application-specific implementations. Second, we describe the state of and need for modeling everting vine robots. Quasi-static models of growth and retraction and kinematic and force-balance models of steering and environment interaction have been developed that use simplifying assumptions and limit the involved degrees of freedom. Third, we report on everting vine robot control and planning techniques that have been developed to move the robot tip to a target, using a variety of modalities to provide reference inputs to the robot. Fourth, we highlight the benefits and challenges of using this paradigm of movement for various applications. Everting vine robot applications to date include deploying and reconfiguring structures, navigating confined spaces, and applying forces on the environment. We conclude by identifying gaps in the state of the art and discussing opportunities for future research to advance everting vine robots and their usefulness in the field.},
  archive      = {J_FROBT},
  author       = {Blumenschein, Laura H. and Coad, Margaret M. and Haggerty, David A. and Okamura, Allison M. and Hawkes, Elliot W.},
  doi          = {10.3389/frobt.2020.548266},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {548266},
  shortjournal = {Front. Robot. AI},
  title        = {Design, modeling, control, and application of everting vine robots},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Lost in the woods? Place recognition for navigation in
difficult forest environments. <em>FROBT</em>, <em>7</em>, 541770. (<a
href="https://doi.org/10.3389/frobt.2020.541770">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forests present one of the most challenging environments for computer vision due to traits, such as complex texture, rapidly changing lighting, and high dynamicity. Loop closure by place recognition is a crucial part of successfully deploying robotic systems to map forests for the purpose of automating conservation. Modern CNN-based place recognition systems like NetVLAD have reported promising results, but the datasets used to train and test them are primarily of urban scenes. In this paper, we investigate how well NetVLAD generalizes to forest environments and find that it out performs state of the art loop closure approaches. Finally, integrating NetVLAD with ORBSLAM2 and evaluating on a novel forest data set, we find that, although suitable locations for loop closure can be identified, the SLAM system is unable to resolve matched places with feature correspondences. We discuss additional considerations to be addressed in future to deal with this challenging problem.},
  archive      = {J_FROBT},
  author       = {Garforth, James and Webb, Barbara},
  doi          = {10.3389/frobt.2020.541770},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {541770},
  shortjournal = {Front. Robot. AI},
  title        = {Lost in the woods? place recognition for navigation in difficult forest environments},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Blocks world of touch: Exploiting the advantages of
all-around finger sensing in robot grasping. <em>FROBT</em>, <em>7</em>,
541661. (<a href="https://doi.org/10.3389/frobt.2020.541661">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tactile sensing is an essential capability for a robot to perform manipulation tasks in cluttered environments. While larger areas can be assessed instantly with cameras, Lidars, and other remote sensors, tactile sensors can reduce their measurement uncertainties and gain information of the physical interactions between the objects and the robot end-effector that is not accessible via remote sensors. In this paper, we introduce the novel tactile sensor GelTip that has the shape of a finger and can sense contacts on any location of its surface. This contrasts to other camera-based tactile sensors that either only have a flat sensing surface, or a compliant tip of a limited sensing area, and our proposed GelTip sensor is able to detect contacts from all the directions, like a human finger. The sensor uses a camera located at its base to track the deformations of the opaque elastomer that covers its hollow, rigid, and transparent body. Because of this design, a gripper equipped with GelTip sensors is capable of simultaneously monitoring contacts happening inside and outside its grasp closure. Our extensive experiments show that the GelTip sensor can effectively localize these contacts at different locations of the finger body, with a small localization error of approximately 5 mm on average, and under 1 mm in the best cases. Furthermore, our experiments in a Blocks World environment demonstrate the advantages, and possibly a necessity, of leveraging all-around touch sensing in manipulation tasks. In particular, the experiments show that the contacts at different moments of the reach-to-grasp movements can be sensed using our novel GelTip sensor.},
  archive      = {J_FROBT},
  author       = {Gomes, Daniel Fernandes and Lin, Zhonglin and Luo, Shan},
  doi          = {10.3389/frobt.2020.541661},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {541661},
  shortjournal = {Front. Robot. AI},
  title        = {Blocks world of touch: Exploiting the advantages of all-around finger sensing in robot grasping},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-lateral teleoperation based on multi-agent framework:
Application to simultaneous training and therapy in telerehabilitation.
<em>FROBT</em>, <em>7</em>, 538347. (<a
href="https://doi.org/10.3389/frobt.2020.538347">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new scheme for multi-lateral remote rehabilitation is proposed. There exist one therapist, one patient, and several trainees, who are participating in the process of telerehabilitation (TR) in this scheme. This kind of strategy helps the therapist to facilitate the neurorehabilitation remotely. Thus, the patients can stay in their homes, resulting in safer and less expensive costs. Meanwhile, several trainees in medical education centers can be trained by participating partially in the rehabilitation process. The trainees participate in a “hands-on” manner; so, they feel like they are rehabilitating the patient directly. For implementing such a scheme, a novel theoretical method is proposed using the power of multi-agent systems (MAS) theory into the multi-lateral teleoperation, based on the self-intelligence in the MAS. In the previous related works, changing the number of participants in the multi-lateral teleoperation tasks required redesigning the controllers; while, in this paper using both of the decentralized control and the self-intelligence of the MAS, avoids the need for redesigning the controller in the proposed structure. Moreover, in this research, uncertainties in the operators&#39; dynamics, as well as time-varying delays in the communication channels, are taken into account. It is shown that the proposed structure has two tuning matrices (L and D) that can be used for different scenarios of multi-lateral teleoperation. By choosing proper tuning matrices, many related works about the multi-lateral teleoperation/telerehabilitation process can be implemented. In the final section of the paper, several scenarios were introduced to achieve “Simultaneous Training and Therapy” in TR and are implemented with the proposed structure. The results confirmed the stability and performance of the proposed framework.},
  archive      = {J_FROBT},
  author       = {Sharifi, Iman and Talebi, Heidar Ali and Patel, Rajni R. and Tavakoli, Mahdi},
  doi          = {10.3389/frobt.2020.538347},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {538347},
  shortjournal = {Front. Robot. AI},
  title        = {Multi-lateral teleoperation based on multi-agent framework: Application to simultaneous training and therapy in telerehabilitation},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Behavioral cues of humanness in complex environments: How
people engage with human and artificially intelligent agents in a
multiplayer videogame. <em>FROBT</em>, <em>7</em>, 531805. (<a
href="https://doi.org/10.3389/frobt.2020.531805">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of AI that can socially engage with humans is exciting to imagine, but such advanced algorithms might prove harmful if people are no longer able to detect when they are interacting with non-humans in online environments. Because we cannot fully predict how socially intelligent AI will be applied, it is important to conduct research into how sensitive humans are to behaviors of humans compared to those produced by AI. This paper presents results from a behavioral Turing Test, in which participants interacted with a human, or a simple or “social” AI within a complex videogame environment. Participants (66 total) played an open world, interactive videogame with one of these co-players and were instructed that they could interact non-verbally however they desired for 30 min, after which time they would indicate their beliefs about the agent, including three Likert measures of how much participants trusted and liked the co-player, the extent to which they perceived them as a “real person,” and an interview about the overall perception and what cues participants used to determine humanness. T-tests, Analysis of Variance and Tukey&#39;s HSD was used to analyze quantitative data, and Cohen&#39;s Kappa and χ2 was used to analyze interview data. Our results suggest that it was difficult for participants to distinguish between humans and the social AI on the basis of behavior. An analysis of in-game behaviors, survey data and qualitative responses suggest that participants associated engagement in social interactions with humanness within the game.},
  archive      = {J_FROBT},
  author       = {Tulk Jesso, Stephanie and Kennedy, William G. and Wiese, Eva},
  doi          = {10.3389/frobt.2020.531805},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {531805},
  shortjournal = {Front. Robot. AI},
  title        = {Behavioral cues of humanness in complex environments: How people engage with human and artificially intelligent agents in a multiplayer videogame},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A simple yet effective whole-body locomotion framework for
quadruped robots. <em>FROBT</em>, <em>7</em>, 528473. (<a
href="https://doi.org/10.3389/frobt.2020.528473">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of legged robotics, many criteria based on the control of the Center of Mass (CoM) have been developed to ensure a stable and safe robot locomotion. Defining a whole-body framework with the control of the CoM requires a planning strategy, often based on a specific type of gait and a reliable state-estimation. In a whole-body control approach, if the CoM task is not specified, the consequent redundancy can still be resolved by specifying a postural task that set references for all the joints. Therefore, the postural task can be exploited to keep a well-behaved, stable kinematic configuration. In this work, we propose a generic locomotion framework which is able to generate different kind of gaits, ranging from very dynamic gaits, such as the trot, to more static gaits like the crawl, without the need to plan the CoM trajectory. Consequently, the whole-body controller becomes planner-free and it does not require the estimation of the floating base state, which is often prone to drift. The framework is composed of a priority-based whole-body controller that works in synergy with a walking pattern generator. We show the effectiveness of the framework by presenting simulations on different types of simulated terrains, including rough terrain, using different quadruped platforms.},
  archive      = {J_FROBT},
  author       = {Raiola, Gennaro and Mingo Hoffman, Enrico and Focchi, Michele and Tsagarakis, Nikos and Semini, Claudio},
  doi          = {10.3389/frobt.2020.528473},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {528473},
  shortjournal = {Front. Robot. AI},
  title        = {A simple yet effective whole-body locomotion framework for quadruped robots},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hierarchical tactile-based control decomposition of
dexterous in-hand manipulation tasks. <em>FROBT</em>, <em>7</em>,
521448. (<a href="https://doi.org/10.3389/frobt.2020.521448">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In-hand manipulation and grasp adjustment with dexterous robotic hands is a complex problem that not only requires highly coordinated finger movements but also deals with interaction variability. The control problem becomes even more complex when introducing tactile information into the feedback loop. Traditional approaches do not consider tactile feedback and attempt to solve the problem either by relying on complex models that are not always readily available or by constraining the problem in order to make it more tractable. In this paper, we propose a hierarchical control approach where a higher level policy is learned through reinforcement learning, while low level controllers ensure grip stability throughout the manipulation action. The low level controllers are independent grip stabilization controllers based on tactile feedback. The independent controllers allow reinforcement learning approaches to explore the manipulation tasks state-action space in a more structured manner. We show that this structure allows learning the unconstrained task with RL methods that cannot learn it in a non-hierarchical setting. The low level controllers also provide an abstraction to the tactile sensors input, allowing transfer to real robot platforms. We show preliminary results of the transfer of policies trained in simulation to the real robot hand.},
  archive      = {J_FROBT},
  author       = {Veiga, Filipe and Akrour, Riad and Peters, Jan},
  doi          = {10.3389/frobt.2020.521448},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {521448},
  shortjournal = {Front. Robot. AI},
  title        = {Hierarchical tactile-based control decomposition of dexterous in-hand manipulation tasks},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Virtual reality and empathy enhancement: Ethical aspects.
<em>FROBT</em>, <em>7</em>, 506984. (<a
href="https://doi.org/10.3389/frobt.2020.506984">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The history of humankind is full of examples that indicate a constant desire to make human beings more moral. Nowadays, technological breakthroughs might have a significant impact on our moral character and abilities. This is the case of Virtual Reality (VR) technologies. The aim of this paper is to consider the ethical aspects of the use of VR in enhancing empathy. First, we will offer an introduction to VR, explaining its fundamental features, devices and concepts. Then, we will approach the characterization of VR as an “empathy machine,” showing why this medium has aroused so much interest and why, nevertheless, we do not believe it is the ideal way to enhance empathy. As an alternative, we will consider fostering empathy-related abilities through virtual embodiment in avatars. In the conclusion, however, we will examine some of the serious concerns related to the ethical relevance of empathy and will defend the philosophical case for a reason-guided empathy, also suggesting specific guidelines for possible future developments of empathy enhancement projects through VR embodied experiences.},
  archive      = {J_FROBT},
  author       = {Rueda, Jon and Lara, Francisco},
  doi          = {10.3389/frobt.2020.506984},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {506984},
  shortjournal = {Front. Robot. AI},
  title        = {Virtual reality and empathy enhancement: Ethical aspects},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Time-aware multi-agent symbiosis. <em>FROBT</em>,
<em>7</em>, 503452. (<a
href="https://doi.org/10.3389/frobt.2020.503452">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contemporary research in human-machine symbiosis has mainly concentrated on enhancing relevant sensory, perceptual, and motor capacities, assuming short-term and nearly momentary interaction sessions. Still, human-machine confluence encompasses an inherent temporal dimension that is typically overlooked. The present work shifts the focus on the temporal and long-lasting aspects of symbiotic human-robot interaction (sHRI). We explore the integration of three time-aware modules, each one focusing on a diverse part of the sHRI timeline. Specifically, the Episodic Memory considers past experiences, the Generative Time Models estimate the progress of ongoing activities, and the Daisy Planner devices plans for the timely accomplishment of goals. The integrated system is employed to coordinate the activities of a multi-agent team. Accordingly, the proposed system (i) predicts human preferences based on past experience, (ii) estimates performance profile and task completion time, by monitoring human activity, and (iii) dynamically adapts multi-agent activity plans to changes in expectation and Human-Robot Interaction (HRI) performance. The system is deployed and extensively assessed in real-world and simulated environments. The obtained results suggest that building upon the unfolding and the temporal properties of team tasks can significantly enhance the fluency of sHRI.},
  archive      = {J_FROBT},
  author       = {Maniadakis, Michail and Hourdakis, Emmanouil and Sigalas, Markos and Piperakis, Stylianos and Koskinopoulou, Maria and Trahanias, Panos},
  doi          = {10.3389/frobt.2020.503452},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {503452},
  shortjournal = {Front. Robot. AI},
  title        = {Time-aware multi-agent symbiosis},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Radiation mapping and laser profiling using a robotic
manipulator. <em>FROBT</em>, <em>7</em>, 499056. (<a
href="https://doi.org/10.3389/frobt.2020.499056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of a robotic arm manipulator as a platform for coincident radiation mapping and laser profiling of radioactive sources on a flat surface is investigated in this work. A combined scanning head, integrating a micro-gamma spectrometer and Time of Flight (ToF) sensor were moved in a raster scan pattern across the surface, autonomously undertaken by the robot arm over a 600 × 260 mm survey area. A series of radioactive sources of different emission intensities were scanned in different configurations to test the accuracy and sensitivity of the system. We demonstrate that in each test configuration the system was able to generate a centimeter accurate 3D model complete with an overlaid radiation map detailing the emitted radiation intensity and the corrected surface dose rate.},
  archive      = {J_FROBT},
  author       = {White, Samuel R. and Megson-Smith, David A. and Zhang, Kaiqiang and Connor, Dean T. and Martin, Peter G. and Hutson, Chris and Herrmann, Guido and Dilworth, John and Scott, Thomas B.},
  doi          = {10.3389/frobt.2020.499056},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {499056},
  shortjournal = {Front. Robot. AI},
  title        = {Radiation mapping and laser profiling using a robotic manipulator},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modeling propulsion of soft magnetic nanowires.
<em>FROBT</em>, <em>7</em>, 595777. (<a
href="https://doi.org/10.3389/frobt.2020.595777">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergent interest in artificial nanostructures that can be remotely navigated a specific location in a fluidic environment is motivated by the enormous potential this technology offers to biomedical applications. Originally, bio-inspired micro-/nanohelices driven by a rotating magnetic field were proposed. However, fabrication of 3D helical nanostructures is complicated. One idea to circumvent complex microfabrication is to use 1D soft magnetic nanowires that acquire chiral shape when actuated by a rotating field. The paper describes the comprehensive numerical approach for modeling propulsion of externally actuated soft magnetic nanowires. The proposed bead-spring model allows for arbitrary filament geometry and flexibility and takes rigorous account of intra-filament hydrodynamic interactions. The comparison of the numerical predictions with the previous experimental results on propulsion of composite two-segment (Ni-Ag) nanowires shows an excellent agreement. Using our model we could substantiate and rationalize important and previously unexplained details, such as bidirectional propulsion of three-segment (Ni-Ag-Au) nanowires.},
  archive      = {J_FROBT},
  author       = {Mirzae, Yoni and Rubinstein, Boris Y. and Morozov, Konstantin I. and Leshansky, Alexander M.},
  doi          = {10.3389/frobt.2020.595777},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {595777},
  shortjournal = {Front. Robot. AI},
  title        = {Modeling propulsion of soft magnetic nanowires},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A review of magnetic elastomers and their role in soft
robotics. <em>FROBT</em>, <em>7</em>, 588391. (<a
href="https://doi.org/10.3389/frobt.2020.588391">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft robotics as a field of study incorporates different mechanisms, control schemes, as well as multifunctional materials to realize robots able to perform tasks inaccessible to traditional rigid robots. Conventional methods for controlling soft robots include pneumatic or hydraulic pressure sources, and some more recent methods involve temperature and voltage control to enact shape change. Magnetism was more recently introduced as a building block for soft robotic design and control, with recent publications incorporating magnetorheological fluids and magnetic particles in elastomers, to realize some of the same objectives present in more traditional soft robotics research. This review attempts to organize and emphasize the existing work with magnetism and soft robotics, specifically studies on magnetic elastomers, while highlighting potential avenues for further research enabled by these advances.},
  archive      = {J_FROBT},
  author       = {Bira, Nicholas and Dhagat, Pallavi and Davidson, Joseph R.},
  doi          = {10.3389/frobt.2020.588391},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {588391},
  shortjournal = {Front. Robot. AI},
  title        = {A review of magnetic elastomers and their role in soft robotics},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Interactive multi-robot painting through colored motion
trails. <em>FROBT</em>, <em>7</em>, 580415. (<a
href="https://doi.org/10.3389/frobt.2020.580415">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a robotic painting system whereby a team of mobile robots equipped with different color paints create pictorial compositions by leaving trails of color as they move throughout a canvas. We envision this system to be used by an external user who can control the concentration of different colors over the painting by specifying density maps associated with the desired colors over the painting domain, which may vary over time. The robots distribute themselves according to such color densities by means of a heterogeneous distributed coverage control paradigm, whereby only those robots equipped with the appropriate paint will track the corresponding color density function. The painting composition therefore arises as the integration of the motion trajectories of the robots, which lay paint as they move throughout the canvas tracking the color density functions. The proposed interactive painting system is evaluated on a team of mobile robots. Different experimental setups in terms of paint capabilities given to the robots highlight the effects and benefits of considering heterogeneous teams when the painting resources are limited.},
  archive      = {J_FROBT},
  author       = {Santos, María and Notomista, Gennaro and Mayya, Siddharth and Egerstedt, Magnus},
  doi          = {10.3389/frobt.2020.580415},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {580415},
  shortjournal = {Front. Robot. AI},
  title        = {Interactive multi-robot painting through colored motion trails},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Errors in human-robot interactions and their effects on
robot learning. <em>FROBT</em>, <em>7</em>, 558531. (<a
href="https://doi.org/10.3389/frobt.2020.558531">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During human-robot interaction, errors will occur. Hence, understanding the effects of interaction errors and especially the effect of prior knowledge on robot learning performance is relevant to develop appropriate approaches for learning under natural interaction conditions, since future robots will continue to learn based on what they have already learned. In this study, we investigated interaction errors that occurred under two learning conditions, i.e., in the case that the robot learned without prior knowledge (cold-start learning) and in the case that the robot had prior knowledge (warm-start learning). In our human-robot interaction scenario, the robot learns to assign the correct action to a current human intention (gesture). Gestures were not predefined but the robot had to learn their meaning. We used a contextual-bandit approach to maximize the expected payoff by updating (a) the current human intention (gesture) and (b) the current human intrinsic feedback after each action selection of the robot. As an intrinsic evaluation of the robot behavior we used the error-related potential (ErrP) in the human electroencephalogram as reinforcement signal. Either gesture errors (human intentions) can be misinterpreted by incorrectly captured gestures or errors in the ErrP classification (human feedback) can occur. We investigated these two types of interaction errors and their effects on the learning process. Our results show that learning and its online adaptation was successful under both learning conditions (except for one subject in cold-start learning). Furthermore, warm-start learning achieved faster convergence, while cold-start learning was less affected by online changes in the current context.},
  archive      = {J_FROBT},
  author       = {Kim, Su Kyoung and Kirchner, Elsa Andrea and Schloßmüller, Lukas and Kirchner, Frank},
  doi          = {10.3389/frobt.2020.558531},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {558531},
  shortjournal = {Front. Robot. AI},
  title        = {Errors in human-robot interactions and their effects on robot learning},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Model reference predictive adaptive control for large-scale
soft robots. <em>FROBT</em>, <em>7</em>, 558027. (<a
href="https://doi.org/10.3389/frobt.2020.558027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Past work has shown model predictive control (MPC) to be an effective strategy for controlling continuum joint soft robots using basic lumped-parameter models. However, the inaccuracies of these models often mean that an integral control scheme must be combined with MPC. In this paper we present a novel dynamic model formulation for continuum joint soft robots that is more accurate than previous models yet remains tractable for fast MPC. This model is based on a piecewise constant curvature (PCC) assumption and a relatively new kinematic representation that allows for computationally efficient state prediction. However, due to the difficulty in determining model parameters (e.g., inertias, damping, and spring effects) as well as effects common in continuum joint soft robots (hysteresis, complex pressure dynamics, etc.), we submit that regardless of the model selected, most model-based controllers of continuum joint soft robots would benefit from online model adaptation. Therefore, in this paper we also present a form of adaptive model predictive control based on model reference adaptive control (MRAC). We show that like MRAC, model reference predictive adaptive control (MRPAC) is able to compensate for “parameter mismatch&quot; such as unknown inertia values. Our experiments also show that like MPC, MRPAC is robust to “structure mismatch” such as unmodeled disturbance forces not represented in the form of the adaptive regressor model. Experiments in simulation and hardware show that MRPAC outperforms individual MPC and MRAC.},
  archive      = {J_FROBT},
  author       = {Hyatt, Phillip and Johnson, Curtis C. and Killpack, Marc D.},
  doi          = {10.3389/frobt.2020.558027},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {558027},
  shortjournal = {Front. Robot. AI},
  title        = {Model reference predictive adaptive control for large-scale soft robots},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Controlling of pneumatic muscle actuator systems by parallel
structure of neural network and proportional controllers (PNNP).
<em>FROBT</em>, <em>7</em>, 557832. (<a
href="https://doi.org/10.3389/frobt.2020.00115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposed a novel controller structure to track the non-linear behavior of the pneumatic muscle actuator (PMA), such as the elongation for the extensor actuator and bending for the bending PMA. The proposed controller consists of a neural network (NN) controller laid in parallel with the proportional controller (P). The parallel neural network proportional (PNNP) controllers provide a high level of precision and fast-tracking control system. The PNNP has been applied to control the length of the single extensor PMA and the bending angle of the single self-bending contraction actuator (SBCA) at different load values. For further validation, the PNNP has been applied to control a human–robot shared control system. The results show the efficiency of the proposed controller structure.},
  archive      = {J_FROBT},
  author       = {Al-Ibadi, Alaa and Nefti-Meziani, Samia and Davis, Steve},
  doi          = {10.3389/frobt.2020.00115},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {557832},
  shortjournal = {Front. Robot. AI},
  title        = {Controlling of pneumatic muscle actuator systems by parallel structure of neural network and proportional controllers (PNNP)},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A comparison of social robot to tablet and teacher in a new
script learning context. <em>FROBT</em>, <em>7</em>, 555050. (<a
href="https://doi.org/10.3389/frobt.2020.00099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research occurred in a special context where Kazakhstan&#39;s recent decision to switch from Cyrillic to the Latin-based alphabet has resulted in challenges connected to teaching literacy, addressing a rare combination of research hypotheses and technical objectives about language learning. Teachers are not necessarily trained to teach the new alphabet, and this could result in a challenge for children with learning difficulties. Prior research studies in Human-Robot Interaction (HRI) have proposed the use of a robot to teach handwriting to children (Hood et al., 2015; Lemaignan et al., 2016). Drawing on the Kazakhstani case, our study takes an interdisciplinary approach by bringing together smart solutions from robotics, computer vision areas, and educational frameworks, language, and cognitive studies that will benefit diverse groups of stakeholders. In this study, a human-robot interaction application is designed to help primary school children learn both a newly-adopted script and also its handwriting system. The setup involved an experiment with 62 children between the ages of 7–9 years old, across three conditions: a robot and a tablet, a tablet only, and a teacher. Based on the paradigm—learning by teaching—the study showed that children improved their knowledge of the Latin script by interacting with a robot. Findings reported that children gained similar knowledge of a new script in all three conditions without gender effect. In addition, children&#39;s likeability ratings and positive mood change scores demonstrate significant benefits favoring the robot over a traditional teacher and tablet only approaches.},
  archive      = {J_FROBT},
  author       = {Zhexenova, Zhanel and Amirova, Aida and Abdikarimova, Manshuk and Kudaibergenov, Kuanysh and Baimakhan, Nurakhmet and Tleubayev, Bolat and Asselborn, Thibault and Johal, Wafa and Dillenbourg, Pierre and CohenMiller, Anna and Sandygulova, Anara},
  doi          = {10.3389/frobt.2020.00099},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {555050},
  shortjournal = {Front. Robot. AI},
  title        = {A comparison of social robot to tablet and teacher in a new script learning context},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). BVLOS UAS operations in highly-turbulent volcanic plumes.
<em>FROBT</em>, <em>7</em>, 549716. (<a
href="https://doi.org/10.3389/frobt.2020.549716">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-range, high-altitude Unoccupied Aerial System (UAS) operations now enable in-situ measurements of volcanic gas chemistry at globally-significant active volcanoes. However, the extreme environments encountered within volcanic plumes present significant challenges for both air frame development and in-flight control. As part of a multi-disciplinary field deployment in May 2019, we flew fixed wing UAS Beyond Visual Line of Sight (BVLOS) over Manam volcano, Papua New Guinea, to measure real-time gas concentrations within the volcanic plume. By integrating aerial gas measurements with ground- and satellite-based sensors, our aim was to collect data that would constrain the emission rate of environmentally-important volcanic gases, such as carbon dioxide, whilst providing critical insight into the state of the subsurface volcanic system. Here, we present a detailed analysis of three BVLOS flights into the plume of Manam volcano and discuss the challenges involved in operating in highly turbulent volcanic plumes. Specifically, we report a detailed description of the system, including ground and air components, and flight plans. We present logged flight data for two successful flights to evaluate the aircraft performance under the atmospheric conditions experienced during plume traverses. Further, by reconstructing the sequence of events that led to the failure of the third flight, we identify a number of lessons learned and propose appropriate recommendations to reduce risk in future flight operations.},
  archive      = {J_FROBT},
  author       = {Wood, Kieran and Liu, Emma J. and Richardson, Tom and Clarke, Robert and Freer, Jim and Aiuppa, Alessandro and Giudice, Gaetano and Bitetto, Marcello and Mulina, Kila and Itikarai, Ima},
  doi          = {10.3389/frobt.2020.549716},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {549716},
  shortjournal = {Front. Robot. AI},
  title        = {BVLOS UAS operations in highly-turbulent volcanic plumes},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The grasp strategy of a robot passer influences performance
and quality of the robot-human object handover. <em>FROBT</em>,
<em>7</em>, 542406. (<a
href="https://doi.org/10.3389/frobt.2020.542406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Task-aware robotic grasping is critical if robots are to successfully cooperate with humans. The choice of a grasp is multi-faceted; however, the task to perform primes this choice in terms of hand shaping and placement on the object. This grasping strategy is particularly important for a robot companion, as it can potentially hinder the success of the collaboration with humans. In this work, we investigate how different grasping strategies of a robot passer influence the performance and the perceptions of the interaction of a human receiver. Our findings suggest that a grasping strategy that accounts for the subsequent task of the receiver improves substantially the performance of the human receiver in executing the subsequent task. The time to complete the task is reduced by eliminating the need of a post-handover re-adjustment of the object. Furthermore, the human perceptions of the interaction improve when a task-oriented grasping strategy is adopted. The influence of the robotic grasp strategy increases as the constraints induced by the object&#39;s affordances become more restrictive. The results of this work can benefit the wider robotics community, with application ranging from industrial to household human-robot interaction for cooperative and collaborative object manipulation.},
  archive      = {J_FROBT},
  author       = {Ortenzi, Valerio and Cini, Francesca and Pardi, Tommaso and Marturi, Naresh and Stolkin, Rustam and Corke, Peter and Controzzi, Marco},
  doi          = {10.3389/frobt.2020.542406},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {542406},
  shortjournal = {Front. Robot. AI},
  title        = {The grasp strategy of a robot passer influences performance and quality of the robot-human object handover},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Passive brain-computer interfaces for enhanced human-robot
interaction. <em>FROBT</em>, <em>7</em>, 540599. (<a
href="https://doi.org/10.3389/frobt.2020.00125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain-computer interfaces (BCIs) have long been seen as control interfaces that translate changes in brain activity, produced either by means of a volitional modulation or in response to an external stimulation. However, recent trends in the BCI and neurofeedback research highlight passive monitoring of a user&#39;s brain activity in order to estimate cognitive load, attention level, perceived errors and emotions. Extraction of such higher order information from brain signals is seen as a gateway for facilitation of interaction between humans and intelligent systems. Particularly in the field of robotics, passive BCIs provide a promising channel for prediction of user&#39;s cognitive and affective state for development of a user-adaptive interaction. In this paper, we first illustrate the state of the art in passive BCI technology and then provide examples of BCI employment in human-robot interaction (HRI). We finally discuss the prospects and challenges in integration of passive BCIs in socially demanding HRI settings. This work intends to inform HRI community of the opportunities offered by passive BCI systems for enhancement of human-robot interaction while recognizing potential pitfalls.},
  archive      = {J_FROBT},
  author       = {Alimardani, Maryam and Hiraki, Kazuo},
  doi          = {10.3389/frobt.2020.00125},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {540599},
  shortjournal = {Front. Robot. AI},
  title        = {Passive brain-computer interfaces for enhanced human-robot interaction},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Environmental regulation using plasticoding for the
evolution of robots. <em>FROBT</em>, <em>7</em>, 537231. (<a
href="https://doi.org/10.3389/frobt.2020.00107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary robot systems are usually affected by the properties of the environment indirectly through selection. In this paper, we present and investigate a system where the environment also has a direct effect—through regulation. We propose a novel robot encoding method where a genotype encodes multiple possible phenotypes, and the incarnation of a robot depends on the environmental conditions taking place in a determined moment of its life. This means that the morphology, controller, and behavior of a robot can change according to the environment. Importantly, this process of development can happen at any moment of a robot&#39;s lifetime, according to its experienced environmental stimuli. We provide an empirical proof-of-concept, and the analysis of the experimental results shows that environmental regulation improves adaptation (task performance) while leading to different evolved morphologies, controllers, and behavior.},
  archive      = {J_FROBT},
  author       = {Miras, Karine and Ferrante, Eliseo and Eiben, A. E.},
  doi          = {10.3389/frobt.2020.00107},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {537231},
  shortjournal = {Front. Robot. AI},
  title        = {Environmental regulation using plasticoding for the evolution of robots},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A socially adaptable framework for human-robot interaction.
<em>FROBT</em>, <em>7</em>, 530587. (<a
href="https://doi.org/10.3389/frobt.2020.00121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In our everyday lives we regularly engage in complex, personalized, and adaptive interactions with our peers. To recreate the same kind of rich, human-like interactions, a social robot should be aware of our needs and affective states and continuously adapt its behavior to them. Our proposed solution is to have the robot learn how to select the behaviors that would maximize the pleasantness of the interaction for its peers. To make the robot autonomous in its decision making, this process could be guided by an internal motivation system. We wish to investigate how an adaptive robotic framework of this kind would function and personalize to different users. We also wish to explore whether the adaptability and personalization would bring any additional richness to the human-robot interaction (HRI), or whether it would instead bring uncertainty and unpredictability that would not be accepted by the robot&#39;s human peers. To this end, we designed a socially adaptive framework for the humanoid robot iCub. As a result, the robot perceives and reuses the affective and interactive signals from the person as input for the adaptation based on internal social motivation. We strive to investigate the value of the generated adaptation in our framework in the context of HRI. In particular, we compare how users will experience interaction with an adaptive versus a non-adaptive social robot. To address these questions, we propose a comparative interaction study with iCub whereby users act as the robot&#39;s caretaker, and iCub&#39;s social adaptation is guided by an internal comfort level that varies with the stimuli that iCub receives from its caretaker. We investigate and compare how iCub&#39;s internal dynamics would be perceived by people, both in a condition when iCub does not personalize its behavior to the person, and in a condition where it is instead adaptive. Finally, we establish the potential benefits that an adaptive framework could bring to the context of repeated interactions with a humanoid robot.},
  archive      = {J_FROBT},
  author       = {Tanevska, Ana and Rea, Francesco and Sandini, Giulio and Cañamero, Lola and Sciutti, Alessandra},
  doi          = {10.3389/frobt.2020.00121},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {530587},
  shortjournal = {Front. Robot. AI},
  title        = {A socially adaptable framework for human-robot interaction},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Proposal and evaluation of visual haptics for manipulation
of remote machine system. <em>FROBT</em>, <em>7</em>, 529040. (<a
href="https://doi.org/10.3389/frobt.2020.529040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote machine systems have drawn a lot of attention owing to accelerations of virtual reality (VR), augmented reality (AR), and the fifth generation (5G) networks. Despite recent trends of developing autonomous systems, the realization of sophisticated dexterous hand that can fully replace human hands is considered to be decades away. It is also extremely difficult to reproduce the sensilla of complex human hands. On the other hand, it is known that humans can perceive haptic information from visual information even without any physical feedback as cross modal sensation between visual and haptics sensations or pseudo haptics. In this paper, we propose a visual haptic technology, where haptic information is visualized in more perceptual images overlaid at the contact points of a remote machine hand. The usability of the proposed visual haptics was evaluated by subject&#39;s brain waves aiming to find out a new approach for quantifying “sense of oneness.” In our proof-of-concept experiments using VR, subjects are asked to operate a virtual arm and hand presented in the VR space, and the performance of the operation with and without visual haptics information as measured with brain wave sensing. Consequently, three results were verified. Firstly, the information flow in the brain were significantly reduced with the proposed visual haptics for the whole α, β, and θ-waves by 45% across nine subjects. This result suggests that superimposing visual effects may be able to reduce the cognitive burden on the operator during the manipulation for the remote machine system. Secondly, high correlation (Pearson correlation factor of 0.795 at a p-value of 0.011) was verified between the subjective usability points and the brainwave measurement results. Finally, the number of the task successes across sessions were improved in the presence of overlaid visual stimulus. It implies that the visual haptics image could also facilitate operators&#39; pre-training to get skillful at manipulating the remote machine interface more quickly.},
  archive      = {J_FROBT},
  author       = {Haruna, Masaki and Ogino, Masaki and Koike-Akino, Toshiaki},
  doi          = {10.3389/frobt.2020.529040},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {529040},
  shortjournal = {Front. Robot. AI},
  title        = {Proposal and evaluation of visual haptics for manipulation of remote machine system},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A framework for sensorimotor cross-perception and
cross-behavior knowledge transfer for object categorization.
<em>FROBT</em>, <em>7</em>, 522141. (<a
href="https://doi.org/10.3389/frobt.2020.522141">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {From an early age, humans learn to develop an intuition for the physical nature of the objects around them by using exploratory behaviors. Such exploration provides observations of how objects feel, sound, look, and move as a result of actions applied on them. Previous works in robotics have shown that robots can also use such behaviors (e.g., lifting, pressing, shaking) to infer object properties that camera input alone cannot detect. Such learned representations are specific to each individual robot and cannot currently be transferred directly to another robot with different sensors and actions. Moreover, sensor failure can cause a robot to lose a specific sensory modality which may prevent it from using perceptual models that require it as input. To address these limitations, we propose a framework for knowledge transfer across behaviors and sensory modalities such that: (1) knowledge can be transferred from one or more robots to another, and, (2) knowledge can be transferred from one or more sensory modalities to another. We propose two different models for transfer based on variational auto-encoders and encoder-decoder networks. The main hypothesis behind our approach is that if two or more robots share multi-sensory object observations of a shared set of objects, then those observations can be used to establish mappings between multiple features spaces, each corresponding to a combination of an exploratory behavior and a sensory modality. We evaluate our approach on a category recognition task using a dataset in which a robot used 9 behaviors, coupled with 4 sensory modalities, performed multiple times on 100 objects. The results indicate that sensorimotor knowledge about objects can be transferred both across behaviors and across sensory modalities, such that a new robot (or the same robot, but with a different set of sensors) can bootstrap its category recognition models without having to exhaustively explore the full set of objects.},
  archive      = {J_FROBT},
  author       = {Tatiya, Gyan and Hosseini, Ramtin and Hughes, Michael C. and Sinapov, Jivko},
  doi          = {10.3389/frobt.2020.522141},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {522141},
  shortjournal = {Front. Robot. AI},
  title        = {A framework for sensorimotor cross-perception and cross-behavior knowledge transfer for object categorization},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Morphological computation increases from lower- to
higher-level of biological motor control hierarchy. <em>FROBT</em>,
<em>7</em>, 511265. (<a
href="https://doi.org/10.3389/frobt.2020.511265">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Voluntary movements, like point-to-point or oscillatory human arm movements, are generated by the interaction of several structures. High-level neuronal circuits in the brain are responsible for planning and initiating a movement. Spinal circuits incorporate proprioceptive feedback to compensate for deviations from the desired movement. Muscle biochemistry and contraction dynamics generate movement driving forces and provide an immediate physical response to external forces, like a low-level decentralized controller. A simple central neuronal command like “initiate a movement” then recruits all these biological structures and processes leading to complex behavior, e.g., generate a stable oscillatory movement in resonance with an external spring-mass system. It has been discussed that the spinal feedback circuits, the biochemical processes, and the biomechanical muscle dynamics contribute to the movement generation, and, thus, take over some parts of the movement generation and stabilization which would otherwise have to be performed by the high-level controller. This contribution is termed morphological computation and can be quantified with information entropy-based approaches. However, it is unknown whether morphological computation actually differs between these different hierarchical levels of the control system. To investigate this, we simulated point-to-point and oscillatory human arm movements with a neuro-musculoskeletal model. We then quantify morphological computation on the different hierarchy levels. The results show that morphological computation is highest for the most central (highest) level of the modeled control hierarchy, where the movement initiation and timing are encoded. Furthermore, they show that the lowest neuronal control layer, the muscle stimulation input, exploits the morphological computation of the biochemical and biophysical muscle characteristics to generate smooth dynamic movements. This study provides evidence that the system&#39;s design in the mechanical as well as in the neurological structure can take over important contributions to control, which would otherwise need to be performed by the higher control levels.},
  archive      = {J_FROBT},
  author       = {Haeufle, Daniel F. B. and Stollenmaier, Katrin and Heinrich, Isabelle and Schmitt, Syn and Ghazi-Zahedi, Keyan},
  doi          = {10.3389/frobt.2020.511265},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {511265},
  shortjournal = {Front. Robot. AI},
  title        = {Morphological computation increases from lower- to higher-level of biological motor control hierarchy},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Developing an integrated VR infrastructure in architectural
design education. <em>FROBT</em>, <em>7</em>, 495468. (<a
href="https://doi.org/10.3389/frobt.2020.495468">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of computer technology, Virtual Reality (VR) became an integral part of design studios in architecture education. Researchers have been exploring how VR-enhanced design studios can be assessed from a student-centered perspective. This paper illustrates the role of teaching architectural design for developing a novel and contextual curriculum based on an analysis of student feedback. The background focuses on the development of VR-based architectural design education. The methodology frames two digital design ecosystems which are experimented in four undergraduate courses. With an ecosystem-based approach discussed in this paper, a medium-oriented and a content-oriented curriculum are offered for testing students&#39; reaction to teaching design in VR. In both ecosystems, students are engaged with advanced digital design methods and techniques, which include 3D form-finding, building information modeling, visual programming, coding, and real-time rendering. The study screens the usage of software solutions for the creation of complex virtual environments, covering Blender, Rhinoceros, Unity, Grasshopper, and Revit. The implementation of a User Experience Questionnaire (UEQ) comparatively demonstrates the performative qualities of both digital design ecosystems. Results indicate that the intensity of interaction varied in two incomparable, but connate, levels of qualities. The findings suggest that the perspicuity aspects of student interaction bare the risk of “complicated” and “confusing” software. The results further demonstrate a conflict between task-related qualities and non-task related qualities. Additionally, interacting with VR tools in architecture design education is found attractive, stimulating, and original despite low scores on the pragmatic qualities of perspicuity, efficiency, and dependability. The data and results obtained from this study give insight into the planning of design studios in architecture education based on the use of VR and digital methods. Therefore, this study contributes to future research in the contextualization of the design teaching efforts.},
  archive      = {J_FROBT},
  author       = {Aydin, Serdar and Aktaş, Begüm},
  doi          = {10.3389/frobt.2020.495468},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {495468},
  shortjournal = {Front. Robot. AI},
  title        = {Developing an integrated VR infrastructure in architectural design education},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The bio-engineering approach for plant investigations and
growing robots. A mini-review. <em>FROBT</em>, <em>7</em>, 573014. (<a
href="https://doi.org/10.3389/frobt.2020.573014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It has been 10 years since the publication of the first article looking at plants as a biomechatronic system and as model for robotics. Now, roboticists have started to look at plants differently and consider them as a model in the field of bioinspired robotics. Despite plants have been seen traditionally as passive entities, in reality they are able to grow, move, sense, and communicate. These features make plants an exceptional example of morphological computation - with probably the highest level of adaptability among all living beings. They are a unique model to design robots that can act in- and adapt to- unstructured, extreme, and dynamically changing environments exposed to sudden or long-term events. Although plant-inspired robotics is still a relatively new field, it has triggered the concept of growing robotics: an emerging area in which systems are designed to create their own body, adapt their morphology, and explore different environments. There is a reciprocal interest between biology and robotics: plants represent an excellent source of inspiration for achieving new robotic abilities, and engineering tools can be used to reveal new biological information. This way, a bidirectional biology-robotics strategy provides mutual benefits for both disciplines. This mini-review offers a brief overview of the fundamental aspects related to a bioengineering approach in plant-inspired robotics. It analyses the works in which both biological and engineering aspects have been investigated, and highlights the key elements of plants that have been milestones in the pioneering field of growing robots.},
  archive      = {J_FROBT},
  author       = {Mazzolai, Barbara and Tramacere, Francesca and Fiorello, Isabella and Margheri, Laura},
  doi          = {10.3389/frobt.2020.573014},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {573014},
  shortjournal = {Front. Robot. AI},
  title        = {The bio-engineering approach for plant investigations and growing robots. a mini-review},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Geometry preserving sampling method based on spectral
decomposition for large-scale environments. <em>FROBT</em>, <em>7</em>,
572054. (<a href="https://doi.org/10.3389/frobt.2020.572054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of 3D mapping, larger and larger point clouds are acquired with lidar sensors. Although pleasing to the eye, dense maps are not necessarily tailored for practical applications. For instance, in a surface inspection scenario, keeping geometric information such as the edges of objects is essential to detect cracks, whereas very dense areas of very little information such as the ground could hinder the main goal of the application. Several strategies exist to address this problem by reducing the number of points. However, they tend to underperform with non-uniform density, large sensor noise, spurious measurements, and large-scale point clouds, which is the case in mobile robotics. This paper presents a novel sampling algorithm based on spectral decomposition analysis to derive local density measures for each geometric primitive. The proposed method, called Spectral Decomposition Filter (SpDF), identifies and preserves geometric information along the topology of point clouds and is able to scale to large environments with a non-uniform density. Finally, qualitative and quantitative experiments verify the feasibility of our method and present a large-scale evaluation of SpDF with other seven point cloud sampling algorithms, in the context of the 3D registration problem using the Iterative Closest Point (ICP) algorithm on real-world datasets. Results show that a compression ratio up to 97 % can be achieved when accepting a registration error within the range accuracy of the sensor, here for large scale environments of less than 2 cm.},
  archive      = {J_FROBT},
  author       = {Labussière, Mathieu and Laconte, Johann and Pomerleau, François},
  doi          = {10.3389/frobt.2020.572054},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {572054},
  shortjournal = {Front. Robot. AI},
  title        = {Geometry preserving sampling method based on spectral decomposition for large-scale environments},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Parallel helix actuators for soft robotic applications.
<em>FROBT</em>, <em>7</em>, 563736. (<a
href="https://doi.org/10.3389/frobt.2020.00119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fabrication of soft pneumatic bending actuators typically involves multiple steps to accommodate the formation of complex internal geometry and the alignment and bonding between soft and inextensible materials. The complexity of these processes intensifies when applied to multi-chamber and small-scale (~10 mm diameter) designs, resulting in poor repeatability. Designs regularly rely on combining multiple prefabricated single chamber actuators or are limited to simple (fixed cross-section) internal chamber geometry, which can result in excessive ballooning and reduced bending efficiency, compelling the addition of constraining materials. In this work, we address existing limitations by presenting a single material molding technique that uses parallel cores with helical features. We demonstrate that through specific orientation and alignment of these internal structures, small diameter actuators may be fabricated with complex internal geometry in a single material—without- additional design-critical steps. The helix design produces wall profiles that restrict radial expansion while allowing compact designs through chamber interlocking, and simplified demolding. We present and evaluate three-chambered designs with varied helical features, demonstrating appreciable bending angles (&amp;gt;180°), three-dimensional workspace coverage, and three-times bodyweight carrying capability. Through application and validation of the constant curvature assumption, forward kinematic models are presented for the actuator and calibrated to account for chamber-specific bending characteristics, resulting in a mean model tip error of 4.1 mm. This simple and inexpensive fabrication technique has potential to be scaled in size and chamber numbers, allowing for application-specific designs for soft, high-mobility actuators especially for surgical, or locomotion applications.},
  archive      = {J_FROBT},
  author       = {Chandler, James H. and Chauhan, Manish and Garbin, Nicolo and Obstein, Keith L. and Valdastri, Pietro},
  doi          = {10.3389/frobt.2020.00119},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {563736},
  shortjournal = {Front. Robot. AI},
  title        = {Parallel helix actuators for soft robotic applications},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Customization methodology for conformable grasping posture
of soft grippers by stiffness patterning. <em>FROBT</em>, <em>7</em>,
562612. (<a href="https://doi.org/10.3389/frobt.2020.00114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft grippers with soft and flexible materials have been widely researched to improve the functionality of grasping. Although grippers that can grasp various objects with different shapes are important, a large number of industrial applications require a gripper that is targeted for a specified object. In this paper, we propose a design methodology for soft grippers that are customized to grasp single dedicated objects. A customized soft gripper can safely and efficiently grasp a dedicated target object with lowered surface contact forces while maintaining a higher lifting force, compared to its non-customized counterpart. A simplified analytical model and a fabrication method that can rapidly customize and fabricate soft grippers are proposed. Stiffness patterns were implemented onto the constraint layers of pneumatic bending actuators to establish actuated postures with irregular bending curvatures in the longitudinal direction. Soft grippers with customized stiffness patterns yielded higher shape conformability to target objects than non-patterned regular soft grippers. The simplified analytical model represents the pneumatically actuated soft finger as a summation of interactions between its air chambers. Geometric approximations and pseudo-rigid-body modeling theory were employed to build the analytical model. The customized soft grippers were compared with non-patterned soft grippers by measuring their lifting forces and contact forces while they grasped objects. Under the identical actuating pressure, the conformable grasping postures enabled customized soft grippers to have almost three times the lifting force than that of non-patterned soft grippers, while the maximum contact force was reduced to two thirds.},
  archive      = {J_FROBT},
  author       = {Lee, Jun-Young and Eom, Jaemin and Yu, Sung Yol and Cho, Kyujin},
  doi          = {10.3389/frobt.2020.00114},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {562612},
  shortjournal = {Front. Robot. AI},
  title        = {Customization methodology for conformable grasping posture of soft grippers by stiffness patterning},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Structure-preserving imitation learning with delayed reward:
An evaluation within the RoboCup soccer 2D simulation environment.
<em>FROBT</em>, <em>7</em>, 560771. (<a
href="https://doi.org/10.3389/frobt.2020.00123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We describe and evaluate a neural network-based architecture aimed to imitate and improve the performance of a fully autonomous soccer team in RoboCup Soccer 2D Simulation environment. The approach utilizes deep Q-network architecture for action determination and a deep neural network for parameter learning. The proposed solution is shown to be feasible for replacing a selected behavioral module in a well-established RoboCup base team, Gliders2d, in which behavioral modules have been evolved with human experts in the loop. Furthermore, we introduce an additional performance-correlated signal (a delayed reward signal), enabling a search for local maxima during a training phase. The extension is compared against a known benchmark. Finally, we investigate the extent to which preserving the structure of expert-designed behaviors affects the performance of a neural network-based solution.},
  archive      = {J_FROBT},
  author       = {Nguyen, Quang Dang and Prokopenko, Mikhail},
  doi          = {10.3389/frobt.2020.00123},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {560771},
  shortjournal = {Front. Robot. AI},
  title        = {Structure-preserving imitation learning with delayed reward: An evaluation within the RoboCup soccer 2D simulation environment},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Portable take-home system enables proportional control and
high-resolution data logging with a multi-degree-of-freedom bionic arm.
<em>FROBT</em>, <em>7</em>, 559034. (<a
href="https://doi.org/10.3389/frobt.2020.559034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper describes a portable, prosthetic control system and the first at-home use of a multi-degree-of-freedom, proportionally controlled bionic arm. The system uses a modified Kalman filter to provide 6 degree-of-freedom, real-time, proportional control. We describe (a) how the system trains motor control algorithms for use with an advanced bionic arm, and (b) the system&#39;s ability to record an unprecedented and comprehensive dataset of EMG, hand positions and force sensor values. Intact participants and a transradial amputee used the system to perform activities-of-daily-living, including bi-manual tasks, in the lab and at home. This technology enables at-home dexterous bionic arm use, and provides a high-temporal resolution description of daily use—essential information to determine clinical relevance and improve future research for advanced bionic arms.},
  archive      = {J_FROBT},
  author       = {Brinton, Mark R. and Barcikowski, Elliott and Davis, Tyler and Paskett, Michael and George, Jacob A. and Clark, Gregory A.},
  doi          = {10.3389/frobt.2020.559034},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {559034},
  shortjournal = {Front. Robot. AI},
  title        = {Portable take-home system enables proportional control and high-resolution data logging with a multi-degree-of-freedom bionic arm},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel user control for lower extremity rehabilitation
exoskeletons. <em>FROBT</em>, <em>7</em>, 557966. (<a
href="https://doi.org/10.3389/frobt.2020.00108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lower extremity exoskeletons offer the potential to restore ambulation to individuals with paraplegia due to spinal cord injury. However, they often rely on preprogrammed gait, initiated by switches, sensors, and/or EEG triggers. Users can exercise only limited independent control over the trajectory of the feet, the speed of walking, and the placement of feet to avoid obstacles. In this paper, we introduce and evaluate a novel approach that naturally decodes a neuromuscular surrogate for a user&#39;s neutrally planned foot control, uses the exoskeleton&#39;s motors to move the user&#39;s legs in real-time, and provides sensory feedback to the user allowing real-time sensation and path correction resulting in gait similar to biological ambulation. Users express their desired gait by applying Cartesian forces via their hands to rigid trekking poles that are connected to the exoskeleton feet through multi-axis force sensors. Using admittance control, the forces applied by the hands are converted into desired foot positions, every 10 milliseconds (ms), to which the exoskeleton is moved by its motors. As the trekking poles reflect the resulting foot movement, users receive sensory feedback of foot kinematics and ground contact that allows on-the-fly force corrections to maintain the desired foot behavior. We present preliminary results showing that our novel control can allow users to produce biologically similar exoskeleton gait.},
  archive      = {J_FROBT},
  author       = {Karunakaran, Kiran K. and Abbruzzese, Kevin and Androwis, Ghaith and Foulds, Richard A.},
  doi          = {10.3389/frobt.2020.00108},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {557966},
  shortjournal = {Front. Robot. AI},
  title        = {A novel user control for lower extremity rehabilitation exoskeletons},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Control architecture for human-like motion with applications
to articulated soft robots. <em>FROBT</em>, <em>7</em>, 557910. (<a
href="https://doi.org/10.3389/frobt.2020.00117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human beings can achieve a high level of motor performance that is still unmatched in robotic systems. These capabilities can be ascribed to two main enabling factors: (i) the physical proprieties of human musculoskeletal system, and (ii) the effectiveness of the control operated by the central nervous system. Regarding point (i), the introduction of compliant elements in the robotic structure can be regarded as an attempt to bridge the gap between the animal body and the robot one. Soft articulated robots aim at replicating the musculoskeletal characteristics of vertebrates. Yet, substantial advancements are still needed under a control point of view, to fully exploit the new possibilities provided by soft robotic bodies. This paper introduces a control framework that ensures natural movements in articulated soft robots, implementing specific functionalities of the human central nervous system, i.e., learning by repetition, after-effect on known and unknown trajectories, anticipatory behavior, its reactive re-planning, and state covariation in precise task execution. The control architecture we propose has a hierarchical structure composed of two levels. The low level deals with dynamic inversion and focuses on trajectory tracking problems. The high level manages the degree of freedom redundancy, and it allows to control the system through a reduced set of variables. The building blocks of this novel control architecture are well-rooted in the control theory, which can furnish an established vocabulary to describe the functional mechanisms underlying the motor control system. The proposed control architecture is validated through simulations and experiments on a bio-mimetic articulated soft robot.},
  archive      = {J_FROBT},
  author       = {Angelini, Franco and Della Santina, Cosimo and Garabini, Manolo and Bianchi, Matteo and Bicchi, Antonio},
  doi          = {10.3389/frobt.2020.00117},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {557910},
  shortjournal = {Front. Robot. AI},
  title        = {Control architecture for human-like motion with applications to articulated soft robots},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). CNNAI: A convolution neural network-based latent
fingerprint matching using the combination of nearest neighbor
arrangement indexing. <em>FROBT</em>, <em>7</em>, 551935. (<a
href="https://doi.org/10.3389/frobt.2020.00113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic fingerprint identification systems (AFIS) make use of global fingerprint information like ridge flow, ridge frequency, and delta or core points for fingerprint alignment, before performing matching. In latent fingerprints, the ridges will be smudged and delta or core points may not be available. It becomes difficult to pre-align fingerprints with such partial fingerprint information. Further, global features are not robust against fingerprint deformations; rotation, scale, and fingerprint matching using global features pose more challenges. We have developed a local minutia-based convolution neural network (CNN) matching model called “Combination of Nearest Neighbor Arrangement Indexing (CNNAI).” This model makes use of a set of “n” local nearest minutiae neighbor features and generates rotation-scale invariant feature vectors. Our proposed system doesn&#39;t depend upon any fingerprint alignment information. In large fingerprint databases, it becomes very difficult to query every fingerprint against every other fingerprint in the database. To address this issue, we make use of hash indexing to reduce the number of retrievals. We have used a residual learning-based CNN model to enhance and extract the minutiae features. Matching was done on FVC2004 and NIST SD27 latent fingerprint databases against 640 and 3,758 gallery fingerprint images, respectively. We obtained a Rank-1 identification rate of 80% for FVC2004 fingerprints and 84.5% for NIST SD27 latent fingerprint databases. The experimental results show improvement in the Rank-1 identification rate compared to the state-of-art algorithms, and the results reveal that the system is robust against rotation and scale.},
  archive      = {J_FROBT},
  author       = {Deshpande, Uttam U. and Malemath, V. S. and Patil, Shivanand M. and Chaugule, Sushma V.},
  doi          = {10.3389/frobt.2020.00113},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {551935},
  shortjournal = {Front. Robot. AI},
  title        = {CNNAI: A convolution neural network-based latent fingerprint matching using the combination of nearest neighbor arrangement indexing},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Visual odometry using pixel processor arrays for unmanned
aerial systems in GPS denied environments. <em>FROBT</em>, <em>7</em>,
541493. (<a href="https://doi.org/10.3389/frobt.2020.00126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Environments in which Global Positioning Systems (GPS), or more generally Global Navigation Satellite System (GNSS), signals are denied or degraded pose problems for the guidance, navigation, and control of autonomous systems. This can make operating in hostile GNSS-Impaired environments, such as indoors, or in urban and natural canyons, impossible or extremely difficult. Pixel Processor Array (PPA) cameras—in conjunction with other on-board sensors—can be used to address this problem, aiding in tracking, localization, and control. In this paper we demonstrate the use of a PPA device—the SCAMP vision chip—combining perception and compute capabilities on the same device for aiding in real-time navigation and control of aerial robots. A PPA consists of an array of Processing Elements (PEs), each of which features light capture, processing, and storage capabilities. This allows various image processing tasks to be efficiently performed directly on the sensor itself. Within this paper we demonstrate visual odometry and target identification running concurrently on-board a single PPA vision chip at a combined frequency in the region of 400 Hz. Results from outdoor multirotor test flights are given along with comparisons against baseline GPS results. The SCAMP PPA&#39;s High Dynamic Range (HDR) and ability to run multiple algorithms at adaptive rates makes the sensor well suited for addressing outdoor flight of small UAS in GNSS challenging or denied environments. HDR allows operation to continue during the transition from indoor to outdoor environments, and in other situations where there are significant variations in light levels. Additionally, the PPA only needs to output specific information such as the optic flow and target position, rather than having to output entire images. This significantly reduces the bandwidth required for communication between the sensor and on-board flight computer, enabling high frame rate, low power operation.},
  archive      = {J_FROBT},
  author       = {McConville, Alexander and Bose, Laurie and Clarke, Robert and Mayol-Cuevas, Walterio and Chen, Jianing and Greatwood, Colin and Carey, Stephen and Dudek, Piotr and Richardson, Tom},
  doi          = {10.3389/frobt.2020.00126},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {541493},
  shortjournal = {Front. Robot. AI},
  title        = {Visual odometry using pixel processor arrays for unmanned aerial systems in GPS denied environments},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Are you still with me? Continuous engagement assessment from
a robot’s point of view. <em>FROBT</em>, <em>7</em>, 541353. (<a
href="https://doi.org/10.3389/frobt.2020.00116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continuously measuring the engagement of users with a robot in a Human-Robot Interaction (HRI) setting paves the way toward in-situ reinforcement learning, improve metrics of interaction quality, and can guide interaction design and behavior optimization. However, engagement is often considered very multi-faceted and difficult to capture in a workable and generic computational model that can serve as an overall measure of engagement. Building upon the intuitive ways humans successfully can assess situation for a degree of engagement when they see it, we propose a novel regression model (utilizing CNN and LSTM networks) enabling robots to compute a single scalar engagement during interactions with humans from standard video streams, obtained from the point of view of an interacting robot. The model is based on a long-term dataset from an autonomous tour guide robot deployed in a public museum, with continuous annotation of a numeric engagement assessment by three independent coders. We show that this model not only can predict engagement very well in our own application domain but show its successful transfer to an entirely different dataset (with different tasks, environment, camera, robot and people). The trained model and the software is available to the HRI community, at https://github.com/LCAS/engagement_detector, as a tool to measure engagement in a variety of settings.},
  archive      = {J_FROBT},
  author       = {Del Duchetto, Francesco and Baxter, Paul and Hanheide, Marc},
  doi          = {10.3389/frobt.2020.00116},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {541353},
  shortjournal = {Front. Robot. AI},
  title        = {Are you still with me? continuous engagement assessment from a robot&#39;s point of view},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modeling of deformable objects for robotic manipulation: A
tutorial and review. <em>FROBT</em>, <em>7</em>, 534750. (<a
href="https://doi.org/10.3389/frobt.2020.00082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manipulation of deformable objects has given rise to an important set of open problems in the field of robotics. Application areas include robotic surgery, household robotics, manufacturing, logistics, and agriculture, to name a few. Related research problems span modeling and estimation of an object&#39;s shape, estimation of an object&#39;s material properties, such as elasticity and plasticity, object tracking and state estimation during manipulation, and manipulation planning and control. In this survey article, we start by providing a tutorial on foundational aspects of models of shape and shape dynamics. We then use this as the basis for a review of existing work on learning and estimation of these models and on motion planning and control to achieve desired deformations. We also discuss potential future lines of work.},
  archive      = {J_FROBT},
  author       = {Arriola-Rios, Veronica E. and Guler, Puren and Ficuciello, Fanny and Kragic, Danica and Siciliano, Bruno and Wyatt, Jeremy L.},
  doi          = {10.3389/frobt.2020.00082},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {534750},
  shortjournal = {Front. Robot. AI},
  title        = {Modeling of deformable objects for robotic manipulation: A tutorial and review},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-channel interactive reinforcement learning for
sequential tasks. <em>FROBT</em>, <em>7</em>, 524581. (<a
href="https://doi.org/10.3389/frobt.2020.00097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ability to learn new tasks by sequencing already known skills is an important requirement for future robots. Reinforcement learning is a powerful tool for this as it allows for a robot to learn and improve on how to combine skills for sequential tasks. However, in real robotic applications, the cost of sample collection and exploration prevent the application of reinforcement learning for a variety of tasks. To overcome these limitations, human input during reinforcement can be beneficial to speed up learning, guide the exploration and prevent the choice of disastrous actions. Nevertheless, there is a lack of experimental evaluations of multi-channel interactive reinforcement learning systems solving robotic tasks with input from inexperienced human users, in particular for cases where human input might be partially wrong. Therefore, in this paper, we present an approach that incorporates multiple human input channels for interactive reinforcement learning in a unified framework and evaluate it on two robotic tasks with 20 inexperienced human subjects. To enable the robot to also handle potentially incorrect human input we incorporate a novel concept for self-confidence, which allows the robot to question human input after an initial learning phase. The second robotic task is specifically designed to investigate if this self-confidence can enable the robot to achieve learning progress even if the human input is partially incorrect. Further, we evaluate how humans react to suggestions of the robot, once the robot notices human input might be wrong. Our experimental evaluations show that our approach can successfully incorporate human input to accelerate the learning process in both robotic tasks even if it is partially wrong. However, not all humans were willing to accept the robot&#39;s suggestions or its questioning of their input, particularly if they do not understand the learning process and the reasons behind the robot&#39;s suggestions. We believe that the findings from this experimental evaluation can be beneficial for the future design of algorithms and interfaces of interactive reinforcement learning systems used by inexperienced users.},
  archive      = {J_FROBT},
  author       = {Koert, Dorothea and Kircher, Maximilian and Salikutluk, Vildan and D&#39;Eramo, Carlo and Peters, Jan},
  doi          = {10.3389/frobt.2020.00097},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {524581},
  shortjournal = {Front. Robot. AI},
  title        = {Multi-channel interactive reinforcement learning for sequential tasks},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). DGCM-net: Dense geometrical correspondence matching network
for incremental experience-based robotic grasping. <em>FROBT</em>,
<em>7</em>, 521387. (<a
href="https://doi.org/10.3389/frobt.2020.00120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a method for grasping novel objects by learning from experience. Successful attempts are remembered and then used to guide future grasps such that more reliable grasping is achieved over time. To transfer the learned experience to unseen objects, we introduce the dense geometric correspondence matching network (DGCM-Net). This applies metric learning to encode objects with similar geometry nearby in feature space. Retrieving relevant experience for an unseen object is thus a nearest neighbor search with the encoded feature maps. DGCM-Net also reconstructs 3D-3D correspondences using the view-dependent normalized object coordinate space to transform grasp configurations from retrieved samples to unseen objects. In comparison to baseline methods, our approach achieves an equivalent grasp success rate. However, the baselines are significantly improved when fusing the knowledge from experience with their grasp proposal strategy. Offline experiments with a grasping dataset highlight the capability to transfer grasps to new instances as well as to improve success rate over time from increasing experience. Lastly, by learning task-relevant grasps, our approach can prioritize grasp configurations that enable the functional use of objects.},
  archive      = {J_FROBT},
  author       = {Patten, Timothy and Park, Kiru and Vincze, Markus},
  doi          = {10.3389/frobt.2020.00120},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {521387},
  shortjournal = {Front. Robot. AI},
  title        = {DGCM-net: Dense geometrical correspondence matching network for incremental experience-based robotic grasping},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Computational intelligence for studying sustainability
challenges: Tools and methods for dealing with deep uncertainty and
complexity. <em>FROBT</em>, <em>7</em>, 512199. (<a
href="https://doi.org/10.3389/frobt.2020.00111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study of sustainability challenges requires the consideration of multiple coupled systems that are often complex and deeply uncertain. As a result, traditional analytical methods offer limited insights with respect to how to best address such challenges. By analyzing the case of global climate change mitigation, this paper shows that the combination of high-performance computing, mathematical modeling, and computational intelligence tools, such as optimization and clustering algorithms, leads to richer analytical insights. The paper concludes by proposing an analytical hierarchy of computational tools that can be applied to other sustainability challenges.},
  archive      = {J_FROBT},
  author       = {Molina-Perez, Edmundo and Esquivel-Flores, Oscar A. and Zamora-Maldonado, Hilda},
  doi          = {10.3389/frobt.2020.00111},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {512199},
  shortjournal = {Front. Robot. AI},
  title        = {Computational intelligence for studying sustainability challenges: Tools and methods for dealing with deep uncertainty and complexity},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Internet of robotic things intelligent connectivity and
platforms. <em>FROBT</em>, <em>7</em>, 509753. (<a
href="https://doi.org/10.3389/frobt.2020.00104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) and Industrial IoT (IIoT) have developed rapidly in the past few years, as both the Internet and “things” have evolved significantly. “Things” now range from simple Radio Frequency Identification (RFID) devices to smart wireless sensors, intelligent wireless sensors and actuators, robotic things, and autonomous vehicles operating in consumer, business, and industrial environments. The emergence of “intelligent things” (static or mobile) in collaborative autonomous fleets requires new architectures, connectivity paradigms, trustworthiness frameworks, and platforms for the integration of applications across different business and industrial domains. These new applications accelerate the development of autonomous system design paradigms and the proliferation of the Internet of Robotic Things (IoRT). In IoRT, collaborative robotic things can communicate with other things, learn autonomously, interact safely with the environment, humans and other things, and gain qualities like self-maintenance, self-awareness, self-healing, and fail-operational behavior. IoRT applications can make use of the individual, collaborative, and collective intelligence of robotic things, as well as information from the infrastructure and operating context to plan, implement and accomplish tasks under different environmental conditions and uncertainties. The continuous, real-time interaction with the environment makes perception, location, communication, cognition, computation, connectivity, propulsion, and integration of federated IoRT and digital platforms important components of new-generation IoRT applications. This paper reviews the taxonomy of the IoRT, emphasizing the IoRT intelligent connectivity, architectures, interoperability, and trustworthiness framework, and surveys the technologies that enable the application of the IoRT across different domains to perform missions more efficiently, productively, and completely. The aim is to provide a novel perspective on the IoRT that involves communication among robotic things and humans and highlights the convergence of several technologies and interactions between different taxonomies used in the literature.},
  archive      = {J_FROBT},
  author       = {Vermesan, Ovidiu and Bahr, Roy and Ottella, Marco and Serrano, Martin and Karlsen, Tore and Wahlstrøm, Terje and Sand, Hans Erik and Ashwathnarayan, Meghashyam and Gamba, Micaela Troglia},
  doi          = {10.3389/frobt.2020.00104},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {509753},
  shortjournal = {Front. Robot. AI},
  title        = {Internet of robotic things intelligent connectivity and platforms},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improving health monitoring with adaptive data movement in
fog computing. <em>FROBT</em>, <em>7</em>, 477829. (<a
href="https://doi.org/10.3389/frobt.2020.00096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pervasive sensing is increasing our ability to monitor the status of patients not only when they are hospitalized but also during home recovery. As a result, lots of data are collected and are available for multiple purposes. If operations can take advantage of timely and detailed data, the huge amount of data collected can also be useful for analytics. However, these data may be unusable for two reasons: data quality and performance problems. First, if the quality of the collected values is low, the processing activities could produce insignificant results. Second, if the system does not guarantee adequate performance, the results may not be delivered at the right time. The goal of this document is to propose a data utility model that considers the impact of the quality of the data sources (e.g., collected data, biographical data, and clinical history) on the expected results and allows for improvement of the performance through utility-driven data management in a Fog environment. Regarding data quality, our approach aims to consider it as a context-dependent problem: a given dataset can be considered useful for one application and inadequate for another application. For this reason, we suggest a context-dependent quality assessment considering dimensions such as accuracy, completeness, consistency, and timeliness, and we argue that different applications have different quality requirements to consider. The management of data in Fog computing also requires particular attention to quality of service requirements. For this reason, we include QoS aspects in the data utility model, such as availability, response time, and latency. Based on the proposed data utility model, we present an approach based on a goal model capable of identifying when one or more dimensions of quality of service or data quality are violated and of suggesting which is the best action to be taken to address this violation. The proposed approach is evaluated with a real and appropriately anonymized dataset, obtained as part of the experimental procedure of a research project in which a device with a set of sensors (inertial, temperature, humidity, and light sensors) is used to collect motion and environmental data associated with the daily physical activities of healthy young volunteers.},
  archive      = {J_FROBT},
  author       = {Cappiello, Cinzia and Meroni, Giovanni and Pernici, Barbara and Plebani, Pierluigi and Salnitri, Mattia and Vitali, Monica and Trojaniello, Diana and Catallo, Ilio and Sanna, Alberto},
  doi          = {10.3389/frobt.2020.00096},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {477829},
  shortjournal = {Front. Robot. AI},
  title        = {Improving health monitoring with adaptive data movement in fog computing},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A semantics-assisted video captioning model trained with
scheduled sampling. <em>FROBT</em>, <em>7</em>, 475767. (<a
href="https://doi.org/10.3389/frobt.2020.475767">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the features of a video, recurrent neural networks can be used to automatically generate a caption for the video. Existing methods for video captioning have at least three limitations. First, semantic information has been widely applied to boost the performance of video captioning models, but existing networks often fail to provide meaningful semantic features. Second, the Teacher Forcing algorithm is often utilized to optimize video captioning models, but during training and inference, different strategies are applied to guide word generation, leading to poor performance. Third, current video captioning models are prone to generate relatively short captions that express video contents inappropriately. Toward resolving these three problems, we suggest three corresponding improvements. First of all, we propose a metric to compare the quality of semantic features, and utilize appropriate features as input for a semantic detection network (SDN) with adequate complexity in order to generate meaningful semantic features for videos. Then, we apply a scheduled sampling strategy that gradually transfers the training phase from a teacher-guided manner toward a more self-teaching manner. Finally, the ordinary logarithm probability loss function is leveraged by sentence length so that the inclination of generating short sentences is alleviated. Our model achieves better results than previous models on the YouTube2Text dataset and is competitive with the previous best model on the MSR-VTT dataset.},
  archive      = {J_FROBT},
  author       = {Chen, Haoran and Lin, Ke and Maye, Alexander and Li, Jianmin and Hu, Xiaolin},
  doi          = {10.3389/frobt.2020.475767},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {475767},
  shortjournal = {Front. Robot. AI},
  title        = {A semantics-assisted video captioning model trained with scheduled sampling},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Editorial: Advances in soft robotics based on outputs from
IROS 2018. <em>FROBT</em>, <em>7</em>, 583796. (<a
href="https://doi.org/10.3389/frobt.2020.00124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Monje, Concepción A. and Laschi, Cecilia},
  doi          = {10.3389/frobt.2020.00124},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {583796},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Advances in soft robotics based on outputs from IROS 2018},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Compact gearboxes for modern robotics: A review.
<em>FROBT</em>, <em>7</em>, 562214. (<a
href="https://doi.org/10.3389/frobt.2020.00103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {On the eve of Human-Robot-Interaction (HRI) becoming customary in our lives, the performance of HRI robotic devices remains strongly conditioned by their gearboxes. In most industrial robots, two relatively unconventional transmission technologies—Harmonic Drives© and Cycloid Drives—are usually found, which are not so broadly used in other industries. Understanding the origin of this singularity provides valuable insights in the search for suitable, future robotic transmission technologies. In this paper we propose an assessment framework strongly conditioned by HRI applications, and we use it to review the performance of conventional and emerging robotic gearbox technologies, for which the design criterion is strongly shifted toward aspects like weight and efficiency. The framework proposes to use virtual power as a suitable way to assess the inherent limitations of a gearbox technologies to achieve high efficiencies. This paper complements the existing research dealing with the complex interaction between gearbox technologies and the actuators, with a new gearbox-centered perspective particularly focused on HRI applications.},
  archive      = {J_FROBT},
  author       = {García, Pablo López and Crispel, Stein and Saerens, Elias and Verstraten, Tom and Lefeber, Dirk},
  doi          = {10.3389/frobt.2020.00103},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {562214},
  shortjournal = {Front. Robot. AI},
  title        = {Compact gearboxes for modern robotics: A review},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mobility skills with exoskeletal-assisted walking in persons
with SCI: Results from a three center randomized clinical trial.
<em>FROBT</em>, <em>7</em>, 558146. (<a
href="https://doi.org/10.3389/frobt.2020.00093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background: Clinical exoskeletal-assisted walking (EAW) programs for individuals with spinal cord injury (SCI) have been established, but many unknown variables remain. These include addressing staffing needs, determining the number of sessions needed to achieve a successful walking velocity milestone for ambulation, distinguishing potential achievement goals according to level of injury, and deciding the number of sessions participants need to perform in order to meet the Food and Drug Administration (FDA) criteria for personal use prescription in the home and community. The primary aim of this study was to determine the number of sessions necessary to achieve adequate EAW skills and velocity milestones, and the percentage of participants able to achieve these skills by 12 sessions and to determine the skill progression over the course of 36 sessions.Methods: A randomized clinical trial (RCT) was conducted across three sites, in persons with chronic (≥6 months) non-ambulatory SCI. Eligible participants were randomized (within site) to either the EAW arm first (Group 1), three times per week for 36 sessions, striving to be completed in 12 weeks or the usual activity arm (UA) first (Group 2), followed by a crossover to the other arm for both groups. The 10-meter walk test seconds (s) (10MWT), 6-min walk test meters (m) (6MWT), and the Timed-Up-and-Go (s) (TUG) were performed at 12, 24, and 36 sessions. To test walking performance in the exoskeletal devices, nominal velocities and distance milestones were chosen prior to study initiation, and were used for the 10MWT (≤ 40s), 6MWT (≥80m), and TUG (≤ 90s). All walking tests were performed with the exoskeletons.Results: A total of 50 participants completed 36 sessions of EAW training. At 12 sessions, 31 (62%), 35 (70%), and 36 (72%) participants achieved the 10MWT, 6MWT, and TUG milestones, respectively. By 36 sessions, 40 (80%), 41 (82%), and 42 (84%) achieved the 10MWT, 6MWT, and TUG criteria, respectively.Conclusions: It is feasible to train chronic non-ambulatory individuals with SCI in performance of EAW sufficiently to achieve reasonable mobility skill outcome milestones.},
  archive      = {J_FROBT},
  author       = {Hong, EunKyoung and Gorman, Peter H. and Forrest, Gail F. and Asselin, Pierre K. and Knezevic, Steven and Scott, William and Wojciehowski, Sandra Buffy and Kornfeld, Stephen and Spungen, Ann M.},
  doi          = {10.3389/frobt.2020.00093},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {558146},
  shortjournal = {Front. Robot. AI},
  title        = {Mobility skills with exoskeletal-assisted walking in persons with SCI: Results from a three center randomized clinical trial},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A general 3D model for growth dynamics of sensory-growth
systems: From plants to robotics. <em>FROBT</em>, <em>7</em>, 552718.
(<a href="https://doi.org/10.3389/frobt.2020.00089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, there has been a rise in interest in the development of self-growing robotics inspired by the moving-by-growing paradigm of plants. In particular, climbing plants capitalize on their slender structures to successfully negotiate unstructured environments while employing a combination of two classes of growth-driven movements: tropic responses, growing toward or away from an external stimulus, and inherent nastic movements, such as periodic circumnutations, which promote exploration. In order to emulate these complex growth dynamics in a 3D environment, a general and rigorous mathematical framework is required. Here, we develop a general 3D model for rod-like organs adopting the Frenet-Serret frame, providing a useful framework from the standpoint of robotics control. Differential growth drives the dynamics of the organ, governed by both internal and external cues while neglecting elastic responses. We describe the numerical method required to implement this model and perform numerical simulations of a number of key scenarios, showcasing the applicability of our model. In the case of responses to external stimuli, we consider a distant stimulus (such as sunlight and gravity), a point stimulus (a point light source), and a line stimulus that emulates twining of a climbing plant around a support. We also simulate circumnutations, the response to an internal oscillatory cue, associated with search processes. Lastly, we also demonstrate the superposition of the response to an external stimulus and circumnutations. In addition, we consider a simple example illustrating the possible use of an optimal control approach in order to recover tropic dynamics in a way that may be relevant for robotics use. In all, the model presented here is general and robust, paving the way for a deeper understanding of plant response dynamics and also for novel control systems for newly developed self-growing robots.},
  archive      = {J_FROBT},
  author       = {Porat, Amir and Tedone, Fabio and Palladino, Michele and Marcati, Pierangelo and Meroz, Yasmine},
  doi          = {10.3389/frobt.2020.00089},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {552718},
  shortjournal = {Front. Robot. AI},
  title        = {A general 3D model for growth dynamics of sensory-growth systems: From plants to robotics},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Engagement in human-agent interaction: An overview.
<em>FROBT</em>, <em>7</em>, 542411. (<a
href="https://doi.org/10.3389/frobt.2020.00092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Engagement is a concept of the utmost importance in human-computer interaction, not only for informing the design and implementation of interfaces, but also for enabling more sophisticated interfaces capable of adapting to users. While the notion of engagement is actively being studied in a diverse set of domains, the term has been used to refer to a number of related, but different concepts. In fact it has been referred to across different disciplines under different names and with different connotations in mind. Therefore, it can be quite difficult to understand what the meaning of engagement is and how one study relates to another one accordingly. Engagement has been studied not only in human-human, but also in human-agent interactions i.e., interactions with physical robots and embodied virtual agents. In this overview article we focus on different factors involved in engagement studies, distinguishing especially between those studies that address task and social engagement, involve children and adults, are conducted in a lab or aimed for long term interaction. We also present models for detecting engagement and for generating multimodal behaviors to show engagement.},
  archive      = {J_FROBT},
  author       = {Oertel, Catharine and Castellano, Ginevra and Chetouani, Mohamed and Nasir, Jauwairia and Obaid, Mohammad and Pelachaud, Catherine and Peters, Christopher},
  doi          = {10.3389/frobt.2020.00092},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {542411},
  shortjournal = {Front. Robot. AI},
  title        = {Engagement in human-agent interaction: An overview},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Searching and intertwining: Climbing plants and GrowBots.
<em>FROBT</em>, <em>7</em>, 541524. (<a
href="https://doi.org/10.3389/frobt.2020.00118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applications in remote inspection and medicine have motivated the recent development of innovative thin, flexible-backboned robots. However, such robots often experience difficulties in maintaining their intended posture under gravitational and other external loadings. Thin-stemmed climbing plants face many of the same problems. One highly effective solution adopted by such plants features the use of tendrils and tendril-like structures, or the intertwining of several individual stems to form braid-like structures. In this paper, we present new plant-inspired robotic tendril-bearing and intertwining stem hardware and corresponding novel attachment strategies for thin continuum robots. These contributions to robotics are motivated by new insights into plant tendril and intertwining mechanics and behavior. The practical applications of the resulting GrowBots is discussed in the context of space exploration and mining operations.},
  archive      = {J_FROBT},
  author       = {Gallentine, James and Wooten, Michael B. and Thielen, Marc and Walker, Ian D. and Speck, Thomas and Niklas, Karl},
  doi          = {10.3389/frobt.2020.00118},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {541524},
  shortjournal = {Front. Robot. AI},
  title        = {Searching and intertwining: Climbing plants and GrowBots},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Effective viscous damping enables morphological computation
in legged locomotion. <em>FROBT</em>, <em>7</em>, 535051. (<a
href="https://doi.org/10.3389/frobt.2020.00110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Muscle models and animal observations suggest that physical damping is beneficial for stabilization. Still, only a few implementations of physical damping exist in compliant robotic legged locomotion. It remains unclear how physical damping can be exploited for locomotion tasks, while its advantages as sensor-free, adaptive force- and negative work-producing actuators are promising. In a simplified numerical leg model, we studied the energy dissipation from viscous and Coulomb damping during vertical drops with ground-level perturbations. A parallel spring- damper is engaged between touch-down and mid-stance, and its damper auto-decouples from mid-stance to takeoff. Our simulations indicate that an adjustable and viscous damper is desired. In hardware we explored effective viscous damping and adjustability, and quantified the dissipated energy. We tested two mechanical, leg-mounted damping mechanisms: a commercial hydraulic damper, and a custom-made pneumatic damper. The pneumatic damper exploits a rolling diaphragm with an adjustable orifice, minimizing Coulomb damping effects while permitting adjustable resistance. Experimental results show that the leg-mounted, hydraulic damper exhibits the most effective viscous damping. Adjusting the orifice setting did not result in substantial changes of dissipated energy per drop, unlike adjusting the damping parameters in the numerical model. Consequently, we also emphasize the importance of characterizing physical dampers during real legged impacts to evaluate their effectiveness for compliant legged locomotion.},
  archive      = {J_FROBT},
  author       = {Mo, An and Izzi, Fabio and Haeufle, Daniel F. B. and Badri-Spröwitz, Alexander},
  doi          = {10.3389/frobt.2020.00110},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {535051},
  shortjournal = {Front. Robot. AI},
  title        = {Effective viscous damping enables morphological computation in legged locomotion},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robotic cane controlled to adapt automatically to its user
gait characteristics. <em>FROBT</em>, <em>7</em>, 528728. (<a
href="https://doi.org/10.3389/frobt.2020.00105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research on robotic assistance devices tries to minimize the risk of falls due to misuse of non-actuated canes. This paper contributes to this research effort by presenting a novel control strategy of a robotic cane that adapts automatically to its user gait characteristics. We verified the proposed control law on a robotic cane sharing the main shape features of a non-actuated cane. It consists of a motorized telescopic shaft mounted on the top of two actuated wheels driven by the same motor. Cane control relies on two Inertial Measurement Units (IMU). One is attached to the cane and the other to the thigh of its user impaired leg. During the swing phase of this leg, the motor of the wheels is controlled to enable the tracking of the impaired leg thigh angle by the cane orientation. The wheels are immobilized during the stance phase to provide motionless mechanical support to the user. The shaft length is continuously adjusted to keep a constant height of the cane handle. The primary goal of this work is to show the feasibility of the cane motion synchronization with its user gait. The control strategy looks promising after several experiments. After further investigations and experiments with end-users, the proposed control law could pave the road toward its use in robotic canes used either as permanent assistance or during rehabilitation.},
  archive      = {J_FROBT},
  author       = {Trujillo-León, Andrés and Ady, Ragou and Reversat, David and Bachta, Wael},
  doi          = {10.3389/frobt.2020.00105},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {528728},
  shortjournal = {Front. Robot. AI},
  title        = {Robotic cane controlled to adapt automatically to its user gait characteristics},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Human movement representation on multivariate time series
for recognition of professional gestures and forecasting their
trajectories. <em>FROBT</em>, <em>7</em>, 518485. (<a
href="https://doi.org/10.3389/frobt.2020.00080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human-centered artificial intelligence is increasingly deployed in professional workplaces in Industry 4.0 to address various challenges related to the collaboration between the operators and the machines, the augmentation of their capabilities, or the improvement of the quality of their work and life in general. Intelligent systems and autonomous machines need to continuously recognize and follow the professional actions and gestures of the operators in order to collaborate with them and anticipate their trajectories for avoiding potential collisions and accidents. Nevertheless, the recognition of patterns of professional gestures is a very challenging task for both research and the industry. There are various types of human movements that the intelligent systems need to perceive, for example, gestural commands to machines and professional actions with or without the use of tools. Moreover, the interclass and intraclass spatiotemporal variances together with the very limited access to annotated human motion data constitute a major research challenge. In this paper, we introduce the Gesture Operational Model, which describes how gestures are performed based on assumptions that focus on the dynamic association of body entities, their synergies, and their serial and non-serial mediations, as well as their transitioning over time from one state to another. Then, the assumptions of the Gesture Operational Model are translated into a simultaneous equation system for each body entity through State-Space modeling. The coefficients of the equation are computed using the Maximum Likelihood Estimation method. The simulation of the model generates a confidence-bounding box for every entity that describes the tolerance of its spatial variance over time. The contribution of our approach is demonstrated for both recognizing gestures and forecasting human motion trajectories. In recognition, it is combined with continuous Hidden Markov Models to boost the recognition accuracy when the likelihoods are not confident. In forecasting, a motion trajectory can be estimated by taking as minimum input two observations only. The performance of the algorithm has been evaluated using four industrial datasets that contain gestures and actions from a TV assembly line, the glassblowing industry, the gestural commands to Automated Guided Vehicles as well as the Human–Robot Collaboration in the automotive assembly lines. The hybrid approach State-Space and HMMs outperforms standard continuous HMMs and a 3DCNN-based end-to-end deep architecture.},
  archive      = {J_FROBT},
  author       = {Manitsaris, Sotiris and Senteri, Gavriela and Makrygiannis, Dimitrios and Glushkova, Alina},
  doi          = {10.3389/frobt.2020.00080},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {518485},
  shortjournal = {Front. Robot. AI},
  title        = {Human movement representation on multivariate time series for recognition of professional gestures and forecasting their trajectories},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The effects of feedback on children’s engagement and
learning outcomes in robot-assisted second language learning.
<em>FROBT</em>, <em>7</em>, 507466. (<a
href="https://doi.org/10.3389/frobt.2020.00101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To investigate how a robot&#39;s use of feedback can influence children&#39;s engagement and support second language learning, we conducted an experiment in which 72 children of 5 years old learned 18 English animal names from a humanoid robot tutor in three different sessions. During each session, children played 24 rounds in an “I spy with my little eye” game with the robot, and in each session the robot provided them with a different type of feedback. These feedback types were based on a questionnaire study that we conducted with student teachers and the outcome of this questionnaire was translated to three within-design conditions: (teacher) preferred feedback, (teacher) dispreferred feedback and no feedback. During the preferred feedback session, among others, the robot varied his feedback and gave children the opportunity to try again (e.g., “Well done! You clicked on the horse.”, “Too bad, you pressed the bird. Try again. Please click on the horse.”); during the dispreferred feedback the robot did not vary the feedback (“Well done!”, “Too bad.”) and children did not receive an extra attempt to try again; and during no feedback the robot did not comment on the children&#39;s performances at all. We measured the children&#39;s engagement with the task and with the robot as well as their learning gain, as a function of condition. Results show that children tended to be more engaged with the robot and task when the robot used preferred feedback than in the two other conditions. However, preferred or dispreferred feedback did not have an influence on learning gain. Children learned on average the same number of words in all conditions. These findings are especially interesting for long-term interactions where engagement of children often drops. Moreover, feedback can become more important for learning when children need to rely more on feedback, for example, when words or language constructions are more complex than in our experiment. The experiment&#39;s method, measurements and main hypotheses were preregistered.},
  archive      = {J_FROBT},
  author       = {de Haas, Mirjam and Vogt, Paul and Krahmer, Emiel},
  doi          = {10.3389/frobt.2020.00101},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {507466},
  shortjournal = {Front. Robot. AI},
  title        = {The effects of feedback on children&#39;s engagement and learning outcomes in robot-assisted second language learning},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Toward accurate visual reasoning with dual-path neural
module networks. <em>FROBT</em>, <em>7</em>, 496621. (<a
href="https://doi.org/10.3389/frobt.2020.00109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual reasoning is a critical stage in visual question answering (Antol et al., 2015), but most of the state-of-the-art methods categorized the VQA tasks as a classification problem without taking the reasoning process into account. Various approaches are proposed to solve this multi-modal task that requires both abilities of comprehension and reasoning. The recently proposed neural module network (Andreas et al., 2016b), which assembles the model with a few primitive modules, is capable of performing a spatial or arithmetical reasoning over the input image to answer the questions. Nevertheless, its performance is not satisfying especially in the real-world datasets (e.g., VQA 1.0&amp;amp; 2.0) due to its limited primitive modules and suboptimal layout. To address these issues, we propose a novel method of Dual-Path Neural Module Network which can implement complex visual reasoning by forming a more flexible layout regularized by the pairwise loss. Specifically, we first use the region proposal network to generate both visual and spatial information, which helps it perform spatial reasoning. Then, we advocate to process a pair of different images along with the same question simultaneously, named as a “complementary pair,” which encourages the model to learn a more reasonable layout by suppressing the overfitting to the language priors. The model can jointly learn the parameters in the primitive module and the layout generation policy, which is further boosted by introducing a novel pairwise reward. Extensive experiments show that our approach significantly improves the performance of neural module networks especially on the real-world datasets.},
  archive      = {J_FROBT},
  author       = {Su, Ke and Su, Hang and Li, Jianguo and Zhu, Jun},
  doi          = {10.3389/frobt.2020.00109},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {496621},
  shortjournal = {Front. Robot. AI},
  title        = {Toward accurate visual reasoning with dual-path neural module networks},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improving CT image tumor segmentation through deep
supervision and attentional gates. <em>FROBT</em>, <em>7</em>, 488789.
(<a href="https://doi.org/10.3389/frobt.2020.00106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer Tomography (CT) is an imaging procedure that combines many X-ray measurements taken from different angles. The segmentation of areas in the CT images provides a valuable aid to physicians and radiologists in order to better provide a patient diagnose. The CT scans of a body torso usually include different neighboring internal body organs. Deep learning has become the state-of-the-art in medical image segmentation. For such techniques, in order to perform a successful segmentation, it is of great importance that the network learns to focus on the organ of interest and surrounding structures and also that the network can detect target regions of different sizes. In this paper, we propose the extension of a popular deep learning methodology, Convolutional Neural Networks (CNN), by including deep supervision and attention gates. Our experimental evaluation shows that the inclusion of attention and deep supervision results in consistent improvement of the tumor prediction accuracy across the different datasets and training sizes while adding minimal computational overhead.},
  archive      = {J_FROBT},
  author       = {Turečková, Alžběta and Tureček, Tomáš and Komínková Oplatková, Zuzana and Rodríguez-Sánchez, Antonio},
  doi          = {10.3389/frobt.2020.00106},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {488789},
  shortjournal = {Front. Robot. AI},
  title        = {Improving CT image tumor segmentation through deep supervision and attentional gates},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A self-aware and scalable solution for efficient
mobile-cloud hybrid robotics. <em>FROBT</em>, <em>7</em>, 473087. (<a
href="https://doi.org/10.3389/frobt.2020.00102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Backed by the virtually unbounded resources of the cloud, battery-powered mobile robotics can also benefit from cloud computing, meeting the demands of even the most computationally and resource-intensive tasks. However, many existing mobile-cloud hybrid (MCH) robotic tasks are inefficient in terms of optimizing trade-offs between simultaneously conflicting objectives, such as minimizing both battery power consumption and network usage. To tackle this problem we propose a novel approach that can be used not only to instrument an MCH robotic task but also to search for its efficient configurations representing compromise solution between the objectives. We introduce a general-purpose MCH framework to measure, at runtime, how well the tasks meet these two objectives. The framework employs these efficient configurations to make decisions at runtime, which are based on: (1) changing of the environment (i.e., WiFi signal level variation), and (2) itself in a changing environment (i.e., actual observed packet loss in the network). Also, we introduce a novel search-based multi-objective optimization (MOO) algorithm, which works in two steps to search for efficient configurations of MCH applications. Analysis of our results shows that: (i) using self-adaptive and self-aware decisions, an MCH foraging task performed by a battery-powered robot can achieve better optimization in a changing environment than using static offloading or running the task only on the robot. However, a self-adaptive decision would fall behind when the change in the environment happens within the system. In such a case, a self-aware system can perform well, in terms of minimizing the two objectives. (ii) The Two-Step algorithm can search for better quality configurations for MCH robotic tasks of having a size from small to medium scale, in terms of the total number of their offloadable modules.},
  archive      = {J_FROBT},
  author       = {Akbar, Aamir and Lewis, Peter R. and Wanner, Elizabeth},
  doi          = {10.3389/frobt.2020.00102},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {473087},
  shortjournal = {Front. Robot. AI},
  title        = {A self-aware and scalable solution for efficient mobile-cloud hybrid robotics},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Using multiple decomposition methods and cluster analysis to
find and categorize typical patterns of EEG activity in motor imagery
brain–computer interface experiments. <em>FROBT</em>, <em>7</em>,
556794. (<a href="https://doi.org/10.3389/frobt.2020.00088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, the sources of EEG activity in motor imagery brain–computer interface (BCI) control experiments were investigated. Sixteen linear decomposition methods for EEG source separation were compared according to different criteria. The criteria were mutual information reduction between the source activities and physiological plausibility. The latter was tested by estimating the dipolarity of the source topographic maps, i.e., the accuracy of approximating the map by potential distribution from a single current dipole, as well as by the specificity of the source activity for different motor imagery tasks. The decomposition methods were also compared according to the number of shared components found. The results indicate that most of the dipolar components are found by the Independent Component Analysis Methods AMICA and PWCICA, which also provided the highest information reduction. These two methods also found the most task-specific EEG patterns of the blind source separation algorithms used. They are outperformed only by non-blind Common Spatial Pattern methods in terms of pattern specificity. The components found by all of the methods were clustered using the Attractor Neural Network with Increasing Activity. The results of the cluster analysis revealed the most frequent patterns of electrical activity occurring in the experiments. The patterns reflect blinking, eye movements, sensorimotor rhythm suppression during the motor imagery, and activations in the precuneus, supplementary motor area, and premotor areas of both hemispheres. Overall, multi-method decomposition with subsequent clustering and task-specificity estimation is a viable and informative procedure for processing the recordings of electrophysiological experiments.},
  archive      = {J_FROBT},
  author       = {Frolov, Alexander and Bobrov, Pavel and Biryukova, Elena and Isaev, Mikhail and Kerechanin, Yaroslav and Bobrov, Dmitry and Lekin, Alexander},
  doi          = {10.3389/frobt.2020.00088},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {556794},
  shortjournal = {Front. Robot. AI},
  title        = {Using multiple decomposition methods and cluster analysis to find and categorize typical patterns of EEG activity in motor imagery Brain–Computer interface experiments},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficacy of modern neuro-evolutionary strategies for
continuous control optimization. <em>FROBT</em>, <em>7</em>, 552641. (<a
href="https://doi.org/10.3389/frobt.2020.00098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze the efficacy of modern neuro-evolutionary strategies for continuous control optimization. Overall, the results collected on a wide variety of qualitatively different benchmark problems indicate that these methods are generally effective and scale well with respect to the number of parameters and the complexity of the problem. Moreover, they are relatively robust with respect to the setting of hyper-parameters. The comparison of the most promising methods indicates that the OpenAI-ES algorithm outperforms or equals the other algorithms on all considered problems. Moreover, we demonstrate how the reward functions optimized for reinforcement learning methods are not necessarily effective for evolutionary strategies and vice versa. This finding can lead to reconsideration of the relative efficacy of the two classes of algorithm since it implies that the comparisons performed to date are biased toward one or the other class.},
  archive      = {J_FROBT},
  author       = {Pagliuca, Paolo and Milano, Nicola and Nolfi, Stefano},
  doi          = {10.3389/frobt.2020.00098},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {552641},
  shortjournal = {Front. Robot. AI},
  title        = {Efficacy of modern neuro-evolutionary strategies for continuous control optimization},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). First-order dynamic modeling and control of soft robots.
<em>FROBT</em>, <em>7</em>, 545625. (<a
href="https://doi.org/10.3389/frobt.2020.00095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling of soft robots is typically performed at the static level or at a second-order fully dynamic level. Controllers developed upon these models have several advantages and disadvantages. Static controllers, based on the kinematic relations tend to be the easiest to develop, but by sacrificing accuracy, efficiency and the natural dynamics. Controllers developed using second-order dynamic models tend to be computationally expensive, but allow optimal control. Here we propose that the dynamic model of a soft robot can be reduced to first-order dynamical equation owing to their high damping and low inertial properties, as typically observed in nature, with minimal loss in accuracy. This paper investigates the validity of this assumption and the advantages it provides to the modeling and control of soft robots. Our results demonstrate that this model approximation is a powerful tool for developing closed-loop task-space dynamic controllers for soft robots by simplifying the planning and sensory feedback process with minimal effects on the controller accuracy.},
  archive      = {J_FROBT},
  author       = {George Thuruthel, Thomas and Renda, Federico and Iida, Fumiya},
  doi          = {10.3389/frobt.2020.00095},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {545625},
  shortjournal = {Front. Robot. AI},
  title        = {First-order dynamic modeling and control of soft robots},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Plant bioinspired ecological robotics. <em>FROBT</em>,
<em>7</em>, 541200. (<a
href="https://doi.org/10.3389/frobt.2020.00079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Plants are movers, but the nature of their movement differs dramatically from that of creatures that move their whole body from point A to point B. Plants grow to where they are going. Bio-inspired robotics sometimes emulates plants&#39; growth-based movement; but growing is part of a broader system of movement guidance and control. We argue that ecological psychology&#39;s conception of “information” and “control” can simultaneously make sense of what it means for a plant to navigate its environment and provide a control scheme for the design of ecological plant-inspired robotics. In this effort, we will outline several control laws and give special consideration to the class of control laws identified by tau theory, such as time to contact.},
  archive      = {J_FROBT},
  author       = {Frazier, P. Adrian and Jamone, Lorenzo and Althoefer, Kaspar and Calvo, Paco},
  doi          = {10.3389/frobt.2020.00079},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {541200},
  shortjournal = {Front. Robot. AI},
  title        = {Plant bioinspired ecological robotics},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Artificial venus flytraps: A research review and outlook on
their importance for novel bioinspired materials systems.
<em>FROBT</em>, <em>7</em>, 538515. (<a
href="https://doi.org/10.3389/frobt.2020.00075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bioinspired and biomimetic soft machines rely on functions and working principles that have been abstracted from biology but that have evolved over 3.5 billion years. So far, few examples from the huge pool of natural models have been examined and transferred to technical applications. Like living organisms, subsequent generations of soft machines will autonomously respond, sense, and adapt to the environment. Plants as concept generators remain relatively unexplored in biomimetic approaches to robotics and related technologies, despite being able to grow, and continuously adapt in response to environmental stimuli. In this research review, we highlight recent developments in plant-inspired soft machine systems based on movement principles. We focus on inspirations taken from fast active movements in the carnivorous Venus flytrap (Dionaea muscipula) and compare current developments in artificial Venus flytraps with their biological role model. The advantages and disadvantages of current systems are also analyzed and discussed, and a new state-of-the-art autonomous system is derived. Incorporation of the basic structural and functional principles of the Venus flytrap into novel autonomous applications in the field of robotics not only will inspire further plant-inspired biomimetic developments but might also advance contemporary plant-inspired robots, leading to fully autonomous systems utilizing bioinspired working concepts.},
  archive      = {J_FROBT},
  author       = {Esser, Falk J. and Auth, Philipp and Speck, Thomas},
  doi          = {10.3389/frobt.2020.00075},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {538515},
  shortjournal = {Front. Robot. AI},
  title        = {Artificial venus flytraps: A research review and outlook on their importance for novel bioinspired materials systems},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A gait pattern generator for closed-loop position control of
a soft walking robot. <em>FROBT</em>, <em>7</em>, 536098. (<a
href="https://doi.org/10.3389/frobt.2020.00087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an approach to control the position of a gecko-inspired soft robot in Cartesian space. By formulating constraints under the assumption of constant curvature, the joint space of the robot is reduced in its dimension from nine to two. The remaining two generalized coordinates describe respectively the walking speed and the rotational speed of the robot and define the so-called velocity space. By means of simulations and experimental validation, the direct kinematics of the entire velocity space (mapping in Cartesian task space) is approximated by a bivariate polynomial. Based on this, an optimization problem is formulated that recursively generates the optimal references to reach a given target position in task space. Finally, we show in simulation and experiment that the robot can master arbitrary obstacle courses by making use of this gait pattern generator.},
  archive      = {J_FROBT},
  author       = {Schiller, Lars and Seibel, Arthur and Schlattmann, Josef},
  doi          = {10.3389/frobt.2020.00087},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {536098},
  shortjournal = {Front. Robot. AI},
  title        = {A gait pattern generator for closed-loop position control of a soft walking robot},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptive foraging in dynamic environments using scale-free
interaction networks. <em>FROBT</em>, <em>7</em>, 522401. (<a
href="https://doi.org/10.3389/frobt.2020.00086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Group interactions are widely observed in nature to optimize a set of critical collective behaviors, most notably sensing and decision making in uncertain environments. Nevertheless, these interactions are commonly modeled using local (proximity) networks, in which individuals interact within a certain spatial range. Recently, other interaction topologies have been revealed to support the emergence of higher levels of scalability and rapid information exchange. One prominent example is scale-free networks. In this study, we aim to examine the impact of scale-free communication when implemented for a swarm foraging task in dynamic environments. We model dynamic (uncertain) environments in terms of changes in food density and analyze the collective response of a simulated swarm with communication topology given by either proximity or scale-free networks. Our results suggest that scale-free networks accelerate the process of building up a rapid collective response to cope with the environment changes. However, this comes at the cost of lower coherence of the collective decision. Moreover, our findings suggest that the use of scale-free networks can improve swarm performance due to two side-effects introduced by using long-range interactions and frequent network regeneration. The former is a topological consequence, while the latter is a necessity due to robot motion. These two effects lead to reduced spatial correlations of a robot&#39;s behavior with its neighborhood and to an enhanced opinion mixing, i.e., more diversified information sampling. These insights were obtained by comparing the swarm performance in presence of scale-free networks to scenarios with alternative network topologies, and proximity networks with and without packet loss.},
  archive      = {J_FROBT},
  author       = {Rausch, Ilja and Simoens, Pieter and Khaluf, Yara},
  doi          = {10.3389/frobt.2020.00086},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {522401},
  shortjournal = {Front. Robot. AI},
  title        = {Adaptive foraging in dynamic environments using scale-free interaction networks},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sparse robot swarms: Moving swarms to real-world
applications. <em>FROBT</em>, <em>7</em>, 521822. (<a
href="https://doi.org/10.3389/frobt.2020.00083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robot swarms are groups of robots that each act autonomously based on only local perception and coordination with neighboring robots. While current swarm implementations can be large in size (e.g., 1,000 robots), they are typically constrained to working in highly controlled indoor environments. Moreover, a common property of swarms is the underlying assumption that the robots act in close proximity of each other (e.g., 10 body lengths apart), and typically employ uninterrupted, situated, close-range communication for coordination. Many real world applications, including environmental monitoring and precision agriculture, however, require scalable groups of robots to act jointly over large distances (e.g., 1,000 body lengths), rendering the use of dense swarms impractical. Using a dense swarm for such applications would be invasive to the environment and unrealistic in terms of mission deployment, maintenance and post-mission recovery. To address this problem, we propose the sparse swarm concept, and illustrate its use in the context of four application scenarios. For one scenario, which requires a group of rovers to traverse, and monitor, a forest environment, we identify the challenges involved at all levels in developing a sparse swarm—from the hardware platform to communication-constrained coordination algorithms—and discuss potential solutions. We outline open questions of theoretical and practical nature, which we hope will bring the concept of sparse swarms to fruition.},
  archive      = {J_FROBT},
  author       = {Tarapore, Danesh and Groß, Roderich and Zauner, Klaus-Peter},
  doi          = {10.3389/frobt.2020.00083},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {521822},
  shortjournal = {Front. Robot. AI},
  title        = {Sparse robot swarms: Moving swarms to real-world applications},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimality and limitations of audio-visual integration for
cognitive systems. <em>FROBT</em>, <em>7</em>, 516605. (<a
href="https://doi.org/10.3389/frobt.2020.00094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal integration is an important process in perceptual decision-making. In humans, this process has often been shown to be statistically optimal, or near optimal: sensory information is combined in a fashion that minimizes the average error in perceptual representation of stimuli. However, sometimes there are costs that come with the optimization, manifesting as illusory percepts. We review audio-visual facilitations and illusions that are products of multisensory integration, and the computational models that account for these phenomena. In particular, the same optimal computational model can lead to illusory percepts, and we suggest that more studies should be needed to detect and mitigate these illusions, as artifacts in artificial cognitive systems. We provide cautionary considerations when designing artificial cognitive systems with the view of avoiding such artifacts. Finally, we suggest avenues of research toward solutions to potential pitfalls in system design. We conclude that detailed understanding of multisensory integration and the mechanisms behind audio-visual illusions can benefit the design of artificial cognitive systems.},
  archive      = {J_FROBT},
  author       = {Boyce, William Paul and Lindsay, Anthony and Zgonnikov, Arkady and Rañó, Iñaki and Wong-Lin, KongFatt},
  doi          = {10.3389/frobt.2020.00094},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {516605},
  shortjournal = {Front. Robot. AI},
  title        = {Optimality and limitations of audio-visual integration for cognitive systems},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stroke affected lower limbs rehabilitation combining virtual
reality with tactile feedback. <em>FROBT</em>, <em>7</em>, 511679. (<a
href="https://doi.org/10.3389/frobt.2020.00081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In our study, we tested a combination of virtual reality (VR) and robotics in the original adjuvant method of post-stroke lower limb walk restoration in acute phase using a simulation with visual and tactile biofeedback based on VR immersion and physical impact to the soles of patients. The duration of adjuvant therapy was 10 daily sessions of 15 min each. The study showed the following significant rehabilitation progress in Control (N = 27) vs. Experimental (N = 35) groups, respectively: 1.56 ± 0.29 (mean ± SD) and 2.51 ± 0.31 points by Rivermead Mobility Index (p = 0.0286); 2.15 ± 0.84 and 6.29 ± 1.20 points by Fugl-Meyer Assessment Lower Extremities scale (p = 0.0127); and 6.19 ± 1.36 and 13.49 ± 2.26 points by Berg Balance scale (p = 0.0163). P-values were obtained by the Mann–Whitney U test. The simple and intuitive mechanism of rehabilitation, including through the use of sensory and semantic components, allows the therapy of a patient with diaschisis and afferent and motor aphasia. Safety of use allows one to apply the proposed method of therapy at the earliest stage of a stroke. We consider the main finding of this study that the application of rehabilitation with implicit interaction with VR environment produced by the robotics action has measurable significant influence on the restoration of the affected motor function of the lower limbs compared with standard rehabilitation therapy.},
  archive      = {J_FROBT},
  author       = {Zakharov, Alexander V. and Bulanov, Vladimir A. and Khivintseva, Elena V. and Kolsanov, Alexander V. and Bushkova, Yulia V. and Ivanova, Galina E.},
  doi          = {10.3389/frobt.2020.00081},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {511679},
  shortjournal = {Front. Robot. AI},
  title        = {Stroke affected lower limbs rehabilitation combining virtual reality with tactile feedback},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Collective computation in animal fission-fusion dynamics.
<em>FROBT</em>, <em>7</em>, 509162. (<a
href="https://doi.org/10.3389/frobt.2020.00090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent work suggests that collective computation of social structure can minimize uncertainty about the social and physical environment, facilitating adaptation. We explore these ideas by studying how fission-fusion social structure arises in spider monkey (Ateles geoffroyi) groups, exploring whether monkeys use social knowledge to collectively compute subgroup size distributions adaptive for foraging in variable environments. We assess whether individual decisions to stay in or leave subgroups are conditioned on strategies based on the presence or absence of others. We search for this evidence in a time series of subgroup membership. We find that individuals have multiple strategies, suggesting that the social knowledge of different individuals is important. These stay-leave strategies provide microscopic inputs to a stochastic model of collective computation encoded in a family of circuits. Each circuit represents an hypothesis for how collectives combine strategies to make decisions, and how these produce various subgroup size distributions. By running these circuits forward in simulation we generate new subgroup size distributions and measure how well they match food abundance in the environment using transfer entropies. We find that spider monkeys decide to stay or go using information from multiple individuals and that they can collectively compute a distribution of subgroup size that makes efficient use of ephemeral sources of nutrition. We are able to artificially tune circuits with subgroup size distributions that are a better fit to the environment than the observed. This suggests that a combination of measurement error, constraint, and adaptive lag are diminishing the power of collective computation in this system. These results are relevant for a more general understanding of the emergence of ordered states in multi-scale social systems with adaptive properties–both natural and engineered.},
  archive      = {J_FROBT},
  author       = {Ramos-Fernandez, Gabriel and Smith Aguilar, Sandra E. and Krakauer, David C. and Flack, Jessica C.},
  doi          = {10.3389/frobt.2020.00090},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {509162},
  shortjournal = {Front. Robot. AI},
  title        = {Collective computation in animal fission-fusion dynamics},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Interoperability among unmanned maritime vehicles: Review
and first in-field experimentation. <em>FROBT</em>, <em>7</em>, 498195.
(<a href="https://doi.org/10.3389/frobt.2020.00091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex maritime missions, both above and below the surface, have traditionally been carried out by manned surface ships and submarines equipped with advanced sensor systems. Unmanned Maritime Vehicles (UMVs) are increasingly demonstrating their potential for improving existing naval capabilities due to their rapid deployability, easy scalability, and high reconfigurability, offering a reduction in both operational time and cost. In addition, they mitigate the risk to personnel by leaving the man far-from-the-risk but in-the-loop of decision making. In the long-term, a clear interoperability framework between unmanned systems, human operators, and legacy platforms will be crucial for effective joint operations planning and execution. However, the present multi-vendor multi-protocol solutions in multi-domain UMVs activities are hard to interoperate without common mission control interfaces and communication protocol schemes. Furthermore, the underwater domain presents significant challenges that cannot be satisfied with the solutions developed for terrestrial networks. In this paper, the interoperability topic is discussed blending a review of the technological growth from 2000 onwards with recent authors&#39; in-field experience; finally, important research directions for the future are given. Within the broad framework of interoperability in general, the paper focuses on the aspect of interoperability among UMVs not neglecting the role of the human operator in the loop. The picture emerging from the review demonstrates that interoperability is currently receiving a high level of attention with a great and diverse deal of effort. Besides, the manuscript describes the experience from a sea trial exercise, where interoperability has been demonstrated by integrating heterogeneous autonomous UMVs into the NATO Centre for Maritime Research and Experimentation (CMRE) network, using different robotic middlewares and acoustic modem technologies to implement a multistatic active sonar system. A perspective for the interoperability in marine robotics missions emerges in the paper, through a discussion of current capabilities, in-field experience and future advanced technologies unique to UMVs. Nonetheless, their application spread is slowed down by the lack of human confidence. In fact, an interoperable system-of-systems of autonomous UMVs will require operators involved only at a supervisory level. As trust develops, endorsed by stable and mature interoperability, human monitoring will be diminished to exploit the tremendous potential of fully autonomous UMVs.},
  archive      = {J_FROBT},
  author       = {Costanzi, Riccardo and Fenucci, Davide and Manzari, Vincenzo and Micheli, Michele and Morlando, Luca and Terracciano, Daniele and Caiti, Andrea and Stifani, Mirko and Tesei, Alessandra},
  doi          = {10.3389/frobt.2020.00091},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {498195},
  shortjournal = {Front. Robot. AI},
  title        = {Interoperability among unmanned maritime vehicles: Review and first in-field experimentation},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey on probabilistic models in human perception and
machines. <em>FROBT</em>, <em>7</em>, 494034. (<a
href="https://doi.org/10.3389/frobt.2020.00085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracting information from noisy signals is of fundamental importance for both biological and artificial perceptual systems. To provide tractable solutions to this challenge, the fields of human perception and machine signal processing (SP) have developed powerful computational models, including Bayesian probabilistic models. However, little true integration between these fields exists in their applications of the probabilistic models for solving analogous problems, such as noise reduction, signal enhancement, and source separation. In this mini review, we briefly introduce and compare selective applications of probabilistic models in machine SP and human psychophysics. We focus on audio and audio-visual processing, using examples of speech enhancement, automatic speech recognition, audio-visual cue integration, source separation, and causal inference to illustrate the basic principles of the probabilistic approach. Our goal is to identify commonalities between probabilistic models addressing brain processes and those aiming at building intelligent machines. These commonalities could constitute the closest points for interdisciplinary convergence.},
  archive      = {J_FROBT},
  author       = {Li, Lux and Rehr, Robert and Bruns, Patrick and Gerkmann, Timo and Röder, Brigitte},
  doi          = {10.3389/frobt.2020.00085},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {494034},
  shortjournal = {Front. Robot. AI},
  title        = {A survey on probabilistic models in human perception and machines},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Symbolic learning and reasoning with noisy data for
probabilistic anchoring. <em>FROBT</em>, <em>7</em>, 478853. (<a
href="https://doi.org/10.3389/frobt.2020.00100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic agents should be able to learn from sub-symbolic sensor data and, at the same time, be able to reason about objects and communicate with humans on a symbolic level. This raises the question of how to overcome the gap between symbolic and sub-symbolic artificial intelligence. We propose a semantic world modeling approach based on bottom-up object anchoring using an object-centered representation of the world. Perceptual anchoring processes continuous perceptual sensor data and maintains a correspondence to a symbolic representation. We extend the definitions of anchoring to handle multi-modal probability distributions and we couple the resulting symbol anchoring system to a probabilistic logic reasoner for performing inference. Furthermore, we use statistical relational learning to enable the anchoring framework to learn symbolic knowledge in the form of a set of probabilistic logic rules of the world from noisy and sub-symbolic sensor input. The resulting framework, which combines perceptual anchoring and statistical relational learning, is able to maintain a semantic world model of all the objects that have been perceived over time, while still exploiting the expressiveness of logical rules to reason about the state of objects which are not directly observed through sensory input data. To validate our approach we demonstrate, on the one hand, the ability of our system to perform probabilistic reasoning over multi-modal probability distributions, and on the other hand, the learning of probabilistic logical rules from anchored objects produced by perceptual observations. The learned logical rules are, subsequently, used to assess our proposed probabilistic anchoring procedure. We demonstrate our system in a setting involving object interactions where object occlusions arise and where probabilistic inference is needed to correctly anchor objects.},
  archive      = {J_FROBT},
  author       = {Zuidberg Dos Martires, Pedro and Kumar, Nitesh and Persson, Andreas and Loutfi, Amy and De Raedt, Luc},
  doi          = {10.3389/frobt.2020.00100},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {478853},
  shortjournal = {Front. Robot. AI},
  title        = {Symbolic learning and reasoning with noisy data for probabilistic anchoring},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robot DE NIRO: A human-centered, autonomous, mobile research
platform for cognitively-enhanced manipulation. <em>FROBT</em>,
<em>7</em>, 466867. (<a
href="https://doi.org/10.3389/frobt.2020.00066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce Robot DE NIRO, an autonomous, collaborative, humanoid robot for mobile manipulation. We built DE NIRO to perform a wide variety of manipulation behaviors, with a focus on pick-and-place tasks. DE NIRO is designed to be used in a domestic environment, especially in support of caregivers working with the elderly. Given this design focus, DE NIRO can interact naturally, reliably, and safely with humans, autonomously navigate through environments on command, intelligently retrieve or move target objects, and avoid collisions efficiently. We describe DE NIRO&#39;s hardware and software, including an extensive vision sensor suite of 2D and 3D LIDARs, a depth camera, and a 360-degree camera rig; two types of custom grippers; and a custom-built exoskeleton called DE VITO. We demonstrate DE NIRO&#39;s manipulation capabilities in three illustrative challenges: First, we have DE NIRO perform a fetch-an-object challenge. Next, we add more cognition to DE NIRO&#39;s object recognition and grasping abilities, confronting it with small objects of unknown shape. Finally, we extend DE NIRO&#39;s capabilities into dual-arm manipulation of larger objects. We put particular emphasis on the features that enable DE NIRO to interact safely and naturally with humans. Our contribution is in sharing how a humanoid robot with complex capabilities can be designed and built quickly with off-the-shelf hardware and open-source software. Supplementary Material including our code, a documentation, videos and the CAD models of several hardware parts are openly available at https://www.imperial.ac.uk/robot-intelligence/software/.},
  archive      = {J_FROBT},
  author       = {Falck, Fabian and Doshi, Sagar and Tormento, Marion and Nersisyan, Gor and Smuts, Nico and Lingi, John and Rants, Kim and Saputra, Roni Permana and Wang, Ke and Kormushev, Petar},
  doi          = {10.3389/frobt.2020.00066},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {466867},
  shortjournal = {Front. Robot. AI},
  title        = {Robot DE NIRO: A human-centered, autonomous, mobile research platform for cognitively-enhanced manipulation},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). From continuous observations to symbolic concepts: A
discrimination-based strategy for grounded concept learning.
<em>FROBT</em>, <em>7</em>, 542050. (<a
href="https://doi.org/10.3389/frobt.2020.00084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous agents perceive the world through streams of continuous sensori-motor data. Yet, in order to reason and communicate about their environment, agents need to be able to distill meaningful concepts from their raw observations. Most current approaches that bridge between the continuous and symbolic domain are using deep learning techniques. While these approaches often achieve high levels of accuracy, they rely on large amounts of training data, and the resulting models lack transparency, generality, and adaptivity. In this paper, we introduce a novel methodology for grounded concept learning. In a tutor-learner scenario, the method allows an agent to construct a conceptual system in which meaningful concepts are formed by discriminative combinations of prototypical values on human-interpretable feature channels. We evaluate our approach on the CLEVR dataset, using features that are either simulated or extracted using computer vision techniques. Through a range of experiments, we show that our method allows for incremental learning, needs few data points, and that the resulting concepts are general enough to be applied to previously unseen objects and can be combined compositionally. These properties make the approach well-suited to be used in robotic agents as the module that maps from continuous sensory input to grounded, symbolic concepts that can then be used for higher-level reasoning tasks.},
  archive      = {J_FROBT},
  author       = {Nevens, Jens and Van Eecke, Paul and Beuls, Katrien},
  doi          = {10.3389/frobt.2020.00084},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {542050},
  shortjournal = {Front. Robot. AI},
  title        = {From continuous observations to symbolic concepts: A discrimination-based strategy for grounded concept learning},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Symbolic representation and learning with hyperdimensional
computing. <em>FROBT</em>, <em>7</em>, 535245. (<a
href="https://doi.org/10.3389/frobt.2020.00063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It has been proposed that machine learning techniques can benefit from symbolic representations and reasoning systems. We describe a method in which the two can be combined in a natural and direct way by use of hyperdimensional vectors and hyperdimensional computing. By using hashing neural networks to produce binary vector representations of images, we show how hyperdimensional vectors can be constructed such that vector-symbolic inference arises naturally out of their output. We design the Hyperdimensional Inference Layer (HIL) to facilitate this process and evaluate its performance compared to baseline hashing networks. In addition to this, we show that separate network outputs can directly be fused at the vector symbolic level within HILs to improve performance and robustness of the overall model. Furthermore, to the best of our knowledge, this is the first instance in which meaningful hyperdimensional representations of images are created on real data, while still maintaining hyperdimensionality.},
  archive      = {J_FROBT},
  author       = {Mitrokhin, Anton and Sutor, Peter and Summers-Stay, Douglas and Fermüller, Cornelia and Aloimonos, Yiannis},
  doi          = {10.3389/frobt.2020.00063},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {535245},
  shortjournal = {Front. Robot. AI},
  title        = {Symbolic representation and learning with hyperdimensional computing},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Editorial: Language representation and learning in cognitive
and artificial intelligence systems. <em>FROBT</em>, <em>7</em>, 534729.
(<a href="https://doi.org/10.3389/frobt.2020.00069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Esposito, Massimo and Masala, Giovanni Luca and Golosio, Bruno and Cangelosi, Angelo},
  doi          = {10.3389/frobt.2020.00069},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {534729},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Language representation and learning in cognitive and artificial intelligence systems},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Augmented reality guided needle biopsy of soft tissue: A
pilot study. <em>FROBT</em>, <em>7</em>, 522073. (<a
href="https://doi.org/10.3389/frobt.2020.00072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Percutaneous biopsies are popular for extracting suspicious tissue formations (primarily for cancer diagnosis purposes) due to the: relatively low cost, minimal invasiveness, quick procedure times, and low risk for the patient. Despite the advantages provided by percutaneous biopsies, poor needle and tumor visualization is a problem that can result in the clinicians classifying the tumor as benign when it was malignant (false negative). The system developed by the authors aims to address the concern of poor needle and tumor visualization through two virtualization setups. This system is designed to track and visualize the needle and tumor in three-dimensional space using an electromagnetic tracking system. User trials were conducted in which the 10 participants, who were not medically trained, performed a total of 6 tests, each guiding the biopsy needle to the desired location. The users guided the biopsy needle to the desired point on an artificial spherical tumor (diameters of 30, 20, and 10 mm) using the 3D augmented reality (AR) overlay for three trials and a projection on a second monitor (TV) for the other three trials. From the randomized trials, it was found that the participants were able to guide the needle tip 6.5 ± 3.3 mm away from the desired position with an angle deviation of 1.96 ± 1.10° in the AR trials, compared to values of 4.5 ± 2.3 mm and 2.70 ± 1.67° in the TV trials. The results indicate that for simple stationary surgical procedures, an AR display is non-inferior a TV display.},
  archive      = {J_FROBT},
  author       = {Asgar-Deen, David and Carriere, Jay and Wiebe, Ericka and Peiris, Lashan and Duha, Aalo and Tavakoli, Mahdi},
  doi          = {10.3389/frobt.2020.00072},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {522073},
  shortjournal = {Front. Robot. AI},
  title        = {Augmented reality guided needle biopsy of soft tissue: A pilot study},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Task feasibility maximization using model-free policy search
and model-based whole-body control. <em>FROBT</em>, <em>7</em>, 521683.
(<a href="https://doi.org/10.3389/frobt.2020.00061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Producing feasible motions for highly redundant robots, such as humanoids, is a complicated and high-dimensional problem. Model-based whole-body control of such robots can generate complex dynamic behaviors through the simultaneous execution of multiple tasks. Unfortunately, tasks are generally planned without close consideration for the underlying controller being used, or the other tasks being executed, and are often infeasible when executed on the robot. Consequently, there is no guarantee that the motion will be accomplished. In this work, we develop a proof-of-concept optimization loop which automatically improves task feasibility using model-free policy search in conjunction with model-based whole-body control. This combination allows problems to be solved, which would be otherwise intractable using simply one or the other. Through experiments on both the simulated and real iCub humanoid robot, we show that by optimizing task feasibility, initially infeasible complex dynamic motions can be realized—specifically, a sit-to-stand transition. These experiments can be viewed in the accompanying Video S1.},
  archive      = {J_FROBT},
  author       = {Lober, Ryan and Sigaud, Olivier and Padois, Vincent},
  doi          = {10.3389/frobt.2020.00061},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {521683},
  shortjournal = {Front. Robot. AI},
  title        = {Task feasibility maximization using model-free policy search and model-based whole-body control},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Blind manipulation of deformable objects based on force
sensing and finite element modeling. <em>FROBT</em>, <em>7</em>, 521462.
(<a href="https://doi.org/10.3389/frobt.2020.00073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a novel pipeline to simultaneously estimate and manipulate the deformation of an object using only force sensing and an FEM model. The pipeline is composed of a sensor model, a deformation model and a pose controller. The sensor model computes the contact forces that are used as input to the deformation model which updates the volumetric mesh of a manipulated object. The controller then deforms the object such that a given pose on the mesh reaches a desired pose. The proposed approach is thoroughly evaluated in real experiments using a robot manipulator and a force-torque sensor to show its accuracy in estimating and manipulating deformations without the use of vision sensors.},
  archive      = {J_FROBT},
  author       = {Sanchez, Jose and Mohy El Dine, Kamal and Corrales, Juan Antonio and Bouzgarrou, Belhassen-Chedli and Mezouar, Youcef},
  doi          = {10.3389/frobt.2020.00073},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {521462},
  shortjournal = {Front. Robot. AI},
  title        = {Blind manipulation of deformable objects based on force sensing and finite element modeling},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The influence of distance and lateral offset of follow me
robots on user perception. <em>FROBT</em>, <em>7</em>, 521396. (<a
href="https://doi.org/10.3389/frobt.2020.00074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots that are designed to work in close proximity to humans are required to move and act in a way that ensures social acceptance by their users. Hence, a robot&#39;s proximal behavior toward a human is a main concern, especially in human-robot interaction that relies on relatively close proximity. This study investigated how the distance and lateral offset of “Follow Me” robots influences how they are perceived by humans. To this end, a Follow Me robot was built and tested in a user study for a number of subjective variables. A total of 18 participants interacted with the robot, with the robot&#39;s lateral offset and distance varied in a within-subject design. After each interaction, participants were asked to rate the movement of the robot on the dimensions of comfort, expectancy conformity, human likeness, safety, trust, and unobtrusiveness. Results show that users generally prefer robot following distances in the social space, without a lateral offset. However, we found a main influence of affinity for technology, as those participants with a high affinity for technology preferred closer following distances than participants with low affinity for technology. The results of this study show the importance of user-adaptiveness in human-robot-interaction.},
  archive      = {J_FROBT},
  author       = {Siebert, Felix Wilhelm and Klein, Jacobe and Rötting, Matthias and Roesler, Eileen},
  doi          = {10.3389/frobt.2020.00074},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {521396},
  shortjournal = {Front. Robot. AI},
  title        = {The influence of distance and lateral offset of follow me robots on user perception},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Elderly fall detection systems: A literature survey.
<em>FROBT</em>, <em>7</em>, 520978. (<a
href="https://doi.org/10.3389/frobt.2020.00071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Falling is among the most damaging event elderly people may experience. With the ever-growing aging population, there is an urgent need for the development of fall detection systems. Thanks to the rapid development of sensor networks and the Internet of Things (IoT), human-computer interaction using sensor fusion has been regarded as an effective method to address the problem of fall detection. In this paper, we provide a literature survey of work conducted on elderly fall detection using sensor networks and IoT. Although there are various existing studies which focus on the fall detection with individual sensors, such as wearable ones and depth cameras, the performance of these systems are still not satisfying as they suffer mostly from high false alarms. Literature shows that fusing the signals of different sensors could result in higher accuracy and lower false alarms, while improving the robustness of such systems. We approach this survey from different perspectives, including data collection, data transmission, sensor fusion, data analysis, security, and privacy. We also review the benchmark data sets available that have been used to quantify the performance of the proposed methods. The survey is meant to provide researchers in the field of elderly fall detection using sensor networks with a summary of progress achieved up to date and to identify areas where further effort would be beneficial.},
  archive      = {J_FROBT},
  author       = {Wang, Xueyi and Ellul, Joshua and Azzopardi, George},
  doi          = {10.3389/frobt.2020.00071},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {520978},
  shortjournal = {Front. Robot. AI},
  title        = {Elderly fall detection systems: A literature survey},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Pronto: A multi-sensor state estimator for legged robots in
real-world scenarios. <em>FROBT</em>, <em>7</em>, 520900. (<a
href="https://doi.org/10.3389/frobt.2020.00068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a modular and flexible state estimation framework for legged robots operating in real-world scenarios, where environmental conditions, such as occlusions, low light, rough terrain, and dynamic obstacles can severely impair estimation performance. At the core of the proposed estimation system, called Pronto, is an Extended Kalman Filter (EKF) that fuses IMU and Leg Odometry sensing for pose and velocity estimation. We also show how Pronto can integrate pose corrections from visual and LIDAR and odometry to correct pose drift in a loosely coupled manner. This allows it to have a real-time proprioceptive estimation thread running at high frequency (250–1,000 Hz) for use in the control loop while taking advantage of occasional (and often delayed) low frequency (1–15 Hz) updates from exteroceptive sources, such as cameras and LIDARs. To demonstrate the robustness and versatility of the approach, we have tested it on a variety of legged platforms, including two humanoid robots (the Boston Dynamics Atlas and NASA Valkyrie) and two dynamic quadruped robots (IIT HyQ and ANYbotics ANYmal) for more than 2 h of total runtime and 1.37 km of distance traveled. The tests were conducted in a number of different field scenarios under the conditions described above. The algorithms presented in this paper are made available to the research community as open-source ROS packages.},
  archive      = {J_FROBT},
  author       = {Camurri, Marco and Ramezani, Milad and Nobili, Simona and Fallon, Maurice},
  doi          = {10.3389/frobt.2020.00068},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {520900},
  shortjournal = {Front. Robot. AI},
  title        = {Pronto: A multi-sensor state estimator for legged robots in real-world scenarios},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mechanical innovations of a climbing cactus: Functional
insights for a new generation of growing robots. <em>FROBT</em>,
<em>7</em>, 520062. (<a
href="https://doi.org/10.3389/frobt.2020.00064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Climbing plants are being increasingly viewed as models for bioinspired growing robots capable of spanning voids and attaching to diverse substrates. We explore the functional traits of the climbing cactus Selenicereus setaceus (Cactaceae) from the Atlantic forest of Brazil and discuss the potential of these traits for robotics applications. The plant is capable of growing through highly unstructured habitats and attaching to variable substrates including soil, leaf litter, tree surfaces, rocks, and fine branches of tree canopies in wind-blown conditions. Stems develop highly variable cross-sectional geometries at different stages of growth. They include cylindrical basal stems, triangular climbing stems and apical star-shaped stems searching for supports. Searcher stems develop relatively rigid properties for a given cross-sectional area and are capable of spanning voids of up to 1 m. Optimization of rigidity in searcher stems provide some potential design ideas for additive engineering technologies where climbing robotic artifacts must limit materials and mass for curbing bending moments and buckling while climbing and searching. A two-step attachment mechanism involves deployment of recurved, multi-angled spines that grapple on to wide ranging surfaces holding the stem in place for more solid attachment via root growth from the stem. The cactus is an instructive example of how light mass searchers with a winged profile and two step attachment strategies can facilitate traversing voids and making reliable attachment to a wide range of supports and surfaces.},
  archive      = {J_FROBT},
  author       = {Soffiatti, Patricia and Rowe, Nick P.},
  doi          = {10.3389/frobt.2020.00064},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {520062},
  shortjournal = {Front. Robot. AI},
  title        = {Mechanical innovations of a climbing cactus: Functional insights for a new generation of growing robots},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Muscles reduce neuronal information load: Quantification of
control effort in biological vs. Robotic pointing and walking.
<em>FROBT</em>, <em>7</em>, 511258. (<a
href="https://doi.org/10.3389/frobt.2020.00077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is hypothesized that the nonlinear muscle characteristic of biomechanical systems simplify control in the sense that the information the nervous system has to process is reduced through off-loading computation to the morphological structure. It has been proposed to quantify the required information with an information-entropy based approach, which evaluates the minimally required information to control a desired movement, i.e., control effort. The key idea is to compare the same movement but generated by different actuators, e.g., muscles and torque actuators, and determine which of the two morphologies requires less information to generate the same movement. In this work, for the first time, we apply this measure to numerical simulations of more complex human movements: point-to-point arm movements and walking. These models consider up to 24 control signals rendering the brute force approach of the previous implementation to search for the minimally required information futile. We therefore propose a novel algorithm based on the pattern search approach specifically designed to solve this constraint optimization problem. We apply this algorithm to numerical models, which include Hill-type muscle-tendon actuation as well as ideal torque sources acting directly on the joints. The controller for the point-to-point movements was obtained by deep reinforcement learning for muscle and torque actuators. Walking was controlled by proprioceptive neural feedback in the muscular system and a PD controller in the torque model. Results show that the neuromuscular models consistently require less information to successfully generate the movement than the torque-driven counterparts. These findings were consistent for all investigated controllers in our experiments, implying that this is a system property, not a controller property. The proposed algorithm to determine the control effort is more efficient than other standard optimization techniques and provided as open source.},
  archive      = {J_FROBT},
  author       = {Haeufle, Daniel F. B. and Wochner, Isabell and Holzmüller, David and Driess, Danny and Günther, Michael and Schmitt, Syn},
  doi          = {10.3389/frobt.2020.00077},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {511258},
  shortjournal = {Front. Robot. AI},
  title        = {Muscles reduce neuronal information load: Quantification of control effort in biological vs. robotic pointing and walking},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Educational robotics to foster and assess social relations
in students’ groups. <em>FROBT</em>, <em>7</em>, 501513. (<a
href="https://doi.org/10.3389/frobt.2020.00078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotics has gained, in recent years, a significant role in educational processes that take place in formal, non-formal, and informal contexts, mainly in the subjects related to STEM (science, technology, engineering, and mathematics). Indeed, educational robotics (ER) can be fruitfully applied also to soft skills, as it allows promoting social links between students, if it is proposed as a group activity. Working in a group to solve a problem or to accomplish a task in the robotics field allows fostering new relations and overcoming the constraints of the established links associated to the school context. Together with this aspect, ER offers an environment where it is possible to assess group dynamics by means of sociometric tools. In this paper, we will describe an example of how ER can be used to foster and assess social relations in students&#39; group. In particular, we report a study that compares: (1) a laboratory with robots, (2) a laboratory with Scratch for coding, and (3) a control group. This study involved Italian students attending middle school. As the focus of this experiment was to study relations in students&#39; group, we used the sociometric tools proposed by Moreno. Results show that involving students in a robotics lab can effectively foster relations between students and, jointly with sociometric tools, can be employed to portrait group dynamics in a synthetic and manageable way.},
  archive      = {J_FROBT},
  author       = {Ponticorvo, Michela and Rubinacci, Franco and Marocco, Davide and Truglio, Federica and Miglino, Orazio},
  doi          = {10.3389/frobt.2020.00078},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {501513},
  shortjournal = {Front. Robot. AI},
  title        = {Educational robotics to foster and assess social relations in students&#39; groups},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). In search of trustworthy and transparent intelligent systems
with human-like cognitive and reasoning capabilities. <em>FROBT</em>,
<em>7</em>, 439984. (<a
href="https://doi.org/10.3389/frobt.2020.00076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present we are witnessing a tremendous interest in Artificial Intelligence (AI), particularly in Deep Learning (DL)/Deep Neural Networks (DNNs). One of the reasons appears to be the unmatched performance achieved by such systems. This has resulted in an enormous hope on such techniques and often these are viewed as all—cure solutions. But most of these systems cannot explain why a particular decision is made (black box) and sometimes miserably fail in cases where other systems would not. Consequently, in critical applications such as healthcare and defense practitioners do not like to trust such systems. Although an AI system is often designed taking inspiration from the brain, there is not much attempt to exploit cues from the brain in true sense. In our opinion, to realize intelligent systems with human like reasoning ability, we need to exploit knowledge from the brain science. Here we discuss a few findings in brain science that may help designing intelligent systems. We explain the relevance of transparency, explainability, learning from a few examples, and the trustworthiness of an AI system. We also discuss a few ways that may help to achieve these attributes in a learning system.},
  archive      = {J_FROBT},
  author       = {Pal, Nikhil R.},
  doi          = {10.3389/frobt.2020.00076},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {439984},
  shortjournal = {Front. Robot. AI},
  title        = {In search of trustworthy and transparent intelligent systems with human-like cognitive and reasoning capabilities},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Corrigendum: Toward an automated measure of social
engagement for children with autism spectrum disorder—a personalized
computational modeling approach. <em>FROBT</em>, <em>7</em>, 554807. (<a
href="https://doi.org/10.3389/frobt.2020.00067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Javed, Hifza and Lee, WonHyong and Park, Chung Hyuk},
  doi          = {10.3389/frobt.2020.00067},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {554807},
  shortjournal = {Front. Robot. AI},
  title        = {Corrigendum: Toward an automated measure of social engagement for children with autism spectrum Disorder—A personalized computational modeling approach},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Flange-based hand-eye calibration using a 3D camera with
high resolution, accuracy, and frame rate. <em>FROBT</em>, <em>7</em>,
537294. (<a href="https://doi.org/10.3389/frobt.2020.00065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point cloud data provides three-dimensional (3D) measurement of the geometric details in the physical world, which relies heavily on the quality of the machine vision system. In this paper, we explore the potentials of a 3D scanner of high quality (15 million points per second), accuracy (up to 0.150 mm), and frame rate (up to 20 FPS) during static and dynamic measurements of the robot flange for direct hand-eye calibration and trajectory error tracking. With the availability of high-quality point cloud data, we can exploit the standardized geometric features on the robot flange for 3D measurement, which are directly accessible for hand-eye calibration problems. In the meanwhile, we tested the proposed flange-based calibration methods in a dynamic setting to capture point cloud data in a high frame rate. We found that our proposed method works robustly even in dynamic environments, enabling a versatile hand-eye calibration during motion. Furthermore, capturing high-quality point cloud data in real-time opens new doors for the use of 3D scanners, capable of detecting sensitive anomalies of refined details even in motion trajectories. Codes and sample data of this calibration method is provided at Github (https://github.com/ancorasir/flange_handeye_calibration).},
  archive      = {J_FROBT},
  author       = {Wan, Fang and Song, Chaoyang},
  doi          = {10.3389/frobt.2020.00065},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {537294},
  shortjournal = {Front. Robot. AI},
  title        = {Flange-based hand-eye calibration using a 3D camera with high resolution, accuracy, and frame rate},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Trustable environmental monitoring by means of sensors
networks on swarming autonomous marine vessels and distributed ledger
technology. <em>FROBT</em>, <em>7</em>, 515978. (<a
href="https://doi.org/10.3389/frobt.2020.00070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The article describes a highly trustable environmental monitoring system employing a small scalable swarm of small-sized marine vessels equipped with compact sensors and intended for the monitoring of water resources and infrastructures. The technological foundation of the process which guarantees that any third party can not alter the samples taken by the robot swarm is based on the Robonomics platform. This platform provides encrypted decentralized technologies based on distributed ledger tools, and market mechanisms for organizing the work of heterogeneous multi-vendor cyber-physical systems when automated economical transactions are needed. A small swarm of robots follows the autonomous ship, which is in charge of maintaining the secure transactions. The swarm implements a version of Reynolds&#39; Boids model based on the Belief Space Planning approach. The main contributions of our work consist of: (1) the deployment of a secure sample certification and logging platform based on the blockchain with a small-sized swarm of autonomous vessels performing maneuvers to measure chemical parameters of water in automatic mode; (2) the coordination of a leader-follower framework for the small platoon of robots by means of a Reynolds&#39; Boids model based on a Belief Space Planning approach. In addition, the article describes the process of measuring the chemical parameters of water by using sensors located on the vessels. Both technology testing on experimental vessel and environmental measurements are detailed. The results have been obtained through real world experiments of an autonomous vessel, which was integrated as the “leader” into a mixed reality simulation of a swarm of simulated smaller vessels.The design of the experimental vessel physically deployed in the Volga river to demonstrate the practical viability of the proposed methods is shortly described.},
  archive      = {J_FROBT},
  author       = {Berman, Ivan and Zereik, Enrica and Kapitonov, Aleksandr and Bonsignorio, Fabio and Khassanov, Alisher and Oripova, Aziza and Lonshakov, Sergei and Bulatov, Vitaly},
  doi          = {10.3389/frobt.2020.00070},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {515978},
  shortjournal = {Front. Robot. AI},
  title        = {Trustable environmental monitoring by means of sensors networks on swarming autonomous marine vessels and distributed ledger technology},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Blockchain technology secures robot swarms: A comparison of
consensus protocols and their resilience to byzantine robots.
<em>FROBT</em>, <em>7</em>, 513470. (<a
href="https://doi.org/10.3389/frobt.2020.00054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consensus achievement is a crucial capability for robot swarms, for example, for path selection, spatial aggregation, or collective sensing. However, the presence of malfunctioning and malicious robots (Byzantine robots) can make it impossible to achieve consensus using classical consensus protocols. In this work, we show how a swarm of robots can achieve consensus even in the presence of Byzantine robots by exploiting blockchain technology. Bitcoin and later blockchain frameworks, such as Ethereum, have revolutionized financial transactions. These frameworks are based on decentralized databases (blockchains) that can achieve secure consensus in peer-to-peer networks. We illustrate our approach in a collective sensing scenario where robots in a swarm are controlled via blockchain-based smart contracts (decentralized protocols executed via blockchain technology) that serve as “meta-controllers” and we compare it to state-of-the-art consensus protocols using a robot swarm simulator. Additionally, we show that our blockchain-based approach can prevent attacks where robots forge a large number of identities (Sybil attacks). The developed robot-blockchain interface is released as open-source software in order to facilitate future research in blockchain-controlled robot swarms. Besides increasing security, we expect the presented approach to be important for data analysis, digital forensics, and robot-to-robot financial transactions in robot swarms.},
  archive      = {J_FROBT},
  author       = {Strobel, Volker and Castelló Ferrer, Eduardo and Dorigo, Marco},
  doi          = {10.3389/frobt.2020.00054},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {513470},
  shortjournal = {Front. Robot. AI},
  title        = {Blockchain technology secures robot swarms: A comparison of consensus protocols and their resilience to byzantine robots},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Simultaneous material segmentation and 3D reconstruction in
industrial scenarios. <em>FROBT</em>, <em>7</em>, 513062. (<a
href="https://doi.org/10.3389/frobt.2020.00052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recognizing material categories is one of the core challenges in robotic nuclear waste decommissioning. All nuclear waste should be sorted and segregated according to its materials, and then different disposal post-process can be applied. In this paper, we propose a novel transfer learning approach to learn boundary-aware material segmentation from a meta-dataset and weakly annotated data. The proposed method is data-efficient, leveraging a publically available dataset for general computer vision tasks and coarsely labeled material recognition data, with only a limited number of fine pixel-wise annotations required. Importantly, our approach is integrated with a Simultaneous Localization and Mapping (SLAM) system to fuse the per-frame understanding delicately into a 3D global semantic map to facilitate robot manipulation in self-occluded object heaps or robot navigation in disaster zones. We evaluate the proposed method on the Materials in Context dataset over 23 categories and that our integrated system delivers quasi-real-time 3D semantic mapping with high-resolution images. The trained model is also verified in an industrial environment as part of the EU RoMaNs project, and promising qualitative results are presented. A video demo and the newly generated data can be found at the project website1 (Supplementary Material).},
  archive      = {J_FROBT},
  author       = {Zhao, Cheng and Sun, Li and Stolkin, Rustam},
  doi          = {10.3389/frobt.2020.00052},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {513062},
  shortjournal = {Front. Robot. AI},
  title        = {Simultaneous material segmentation and 3D reconstruction in industrial scenarios},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimus primed: Media cultivation of robot mental models and
social judgments. <em>FROBT</em>, <em>7</em>, 501412. (<a
href="https://doi.org/10.3389/frobt.2020.00062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Media influence people&#39;s perceptions of reality broadly and of technology in particular. Robot villains and heroes—from Ultron to Wall-E—have been shown to serve a specific cultivation function, shaping people&#39;s perceptions of those embodied social technologies, especially when individuals do not have direct experience with them. To date, however, little is understood about the nature of the conceptions people hold for what robots are, how they work, and how they may function in society, as well as the media antecedents and relational effects of those cognitive structures. This study takes a step toward bridging that gap by exploring relationships among individuals&#39; recall of robot characters from popular media, their mental models for actual robots, and social evaluations of an actual robot. Findings indicate that mental models consist of a small set of common and tightly linked components (beyond which there is a good deal of individual difference), but robot character recall and evaluation have little association with whether people hold any of those components. Instead, data are interpreted to suggest that cumulative sympathetic evaluations of robot media characters may form heuristics that are primed by and engaged in social evaluations of actual robots, while technical content in mental models is associated with a more utilitarian approach to actual robots.},
  archive      = {J_FROBT},
  author       = {Banks, Jaime},
  doi          = {10.3389/frobt.2020.00062},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {501412},
  shortjournal = {Front. Robot. AI},
  title        = {Optimus primed: Media cultivation of robot mental models and social judgments},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Detecting differences of fluorescent markers distribution in
single cell microscopy: Textural or pointillist feature space?
<em>FROBT</em>, <em>7</em>, 488190. (<a
href="https://doi.org/10.3389/frobt.2020.00039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the detection of change in spatial distribution of fluorescent markers inside cells imaged by single cell microscopy. Such problems are important in bioimaging since the density of these markers can reflect the healthy or pathological state of cells, the spatial organization of DNA, or cell cycle stage. With the new super-resolved microscopes and associated microfluidic devices, bio-markers can be detected in single cells individually or collectively as a texture depending on the quality of the microscope impulse response. In this work, we propose, via numerical simulations, to address detection of changes in spatial density or in spatial clustering with an individual (pointillist) or collective (textural) approach by comparing their performances according to the size of the impulse response of the microscope. Pointillist approaches show good performances for small impulse response sizes only, while all textural approaches are found to overcome pointillist approaches with small as well as with large impulse response sizes. These results are validated with real fluorescence microscopy images with conventional resolution. This, a priori non-intuitive result in the perspective of the quest of super-resolution, demonstrates that, for difference detection tasks in single cell microscopy, super-resolved microscopes may not be mandatory and that lower cost, sub-resolved, microscopes can be sufficient.},
  archive      = {J_FROBT},
  author       = {Ahmad, Ali and Frindel, Carole and Rousseau, David},
  doi          = {10.3389/frobt.2020.00039},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {488190},
  shortjournal = {Front. Robot. AI},
  title        = {Detecting differences of fluorescent markers distribution in single cell microscopy: Textural or pointillist feature space?},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). From design to deployment: Decentralized coordination of
heterogeneous robotic teams. <em>FROBT</em>, <em>7</em>, 485199. (<a
href="https://doi.org/10.3389/frobt.2020.00051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many applications benefit from the use of multiple robots, but their scalability and applicability are fundamentally limited when relying on a central control station. Getting beyond the centralized approach can increase the complexity of the embedded software, the sensitivity to the network topology, and render the deployment on physical devices tedious and error-prone. This work introduces a software-based solution to cope with these challenges on commercial hardware. We bring together our previous work on Buzz, the swarm-oriented programming language, and the many contributions of the Robotic Operating System (ROS) community into a reliable workflow, from rapid prototyping of decentralized behaviors up to robust field deployment. The Buzz programming language is a hardware independent, domain-specific (swarm-oriented), and composable language. From simulation to the field, a Buzz script can stay unmodified and almost seamlessly applicable to all units of a heterogeneous robotic team. We present the software structure of our solution, and the swarm-oriented paradigms it encompasses. While the design of a new behavior can be achieved on a lightweight simulator, we show how our security mechanisms enhance field deployment robustness. In addition, developers can update their scripts in the field using a safe software release mechanism. Integrating Buzz in ROS, adding safety mechanisms and granting field updates are core contributions essential to swarm robotics deployment: from simulation to the field. We show the applicability of our work with the implementation of two practical decentralized scenarios: a robust generic task allocation strategy and an optimized area coverage algorithm. Both behaviors are explained and tested with simulations, then experimented with heterogeneous ground-and-air robotic teams.},
  archive      = {J_FROBT},
  author       = {St-Onge, David and Varadharajan, Vivek Shankar and Švogor, Ivan and Beltrame, Giovanni},
  doi          = {10.3389/frobt.2020.00051},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {485199},
  shortjournal = {Front. Robot. AI},
  title        = {From design to deployment: Decentralized coordination of heterogeneous robotic teams},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Learning to avoid obstacles with minimal intervention
control. <em>FROBT</em>, <em>7</em>, 471957. (<a
href="https://doi.org/10.3389/frobt.2020.00060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Programming by demonstration has received much attention as it offers a general framework which allows robots to efficiently acquire novel motor skills from a human teacher. While traditional imitation learning that only focuses on either Cartesian or joint space might become inappropriate in situations where both spaces are equally important (e.g., writing or striking task), hybrid imitation learning of skills in both Cartesian and joint spaces simultaneously has been studied recently. However, an important issue which often arises in dynamical or unstructured environments is overlooked, namely how can a robot avoid obstacles? In this paper, we aim to address the problem of avoiding obstacles in the context of hybrid imitation learning. Specifically, we propose to tackle three subproblems: (i) designing a proper potential field so as to bypass obstacles, (ii) guaranteeing joint limits are respected when adjusting trajectories in the process of avoiding obstacles, and (iii) determining proper control commands for robots such that potential human-robot interaction is safe. By solving the aforementioned subproblems, the robot is capable of generalizing observed skills to new situations featuring obstacles in a feasible and safe manner. The effectiveness of the proposed method is validated through a toy example as well as a real transportation experiment on the iCub humanoid robot.},
  archive      = {J_FROBT},
  author       = {Duan, Anqing and Camoriano, Raffaello and Ferigo, Diego and Huang, Yanlong and Calandriello, Daniele and Rosasco, Lorenzo and Pucci, Daniele},
  doi          = {10.3389/frobt.2020.00060},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {471957},
  shortjournal = {Front. Robot. AI},
  title        = {Learning to avoid obstacles with minimal intervention control},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Editorial: Current advances in soft robotics: Best papers
from RoboSoft 2018. <em>FROBT</em>, <em>7</em>, 545672. (<a
href="https://doi.org/10.3389/frobt.2020.00056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Sadati, S. M. Hadi and Maiolino, Perla and Iida, Fumiya and Nanayakkara, Thrishantha and Hauser, Helmut},
  doi          = {10.3389/frobt.2020.00056},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {545672},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: current advances in soft robotics: best papers from RoboSoft 2018},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Editorial: Computational approaches for human-human and
human-robot social interactions. <em>FROBT</em>, <em>7</em>, 538450. (<a
href="https://doi.org/10.3389/frobt.2020.00055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Beyan, Cigdem and Murino, Vittorio and Venture, Gentiane and Wykowska, Agnieszka},
  doi          = {10.3389/frobt.2020.00055},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {538450},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Computational approaches for human-human and human-robot social interactions},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Development of a rigidity tunable flexible joint using
magneto-rheological compounds—toward a multijoint manipulator for
laparoscopic surgery. <em>FROBT</em>, <em>7</em>, 525635. (<a
href="https://doi.org/10.3389/frobt.2020.00059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Laparoscopic surgery is a representative operative method of minimally invasive surgery. However, most laparoscopic hand instruments consist of rigid and straight structures, which have serious limitations such as interference by the instruments and limited field of view of the endoscope. To improve the flexibility and dexterity of these instruments, we propose a new concept of a multijoint manipulator using a variable stiffness mechanism. The manipulator uses a magneto-rheological compound (MRC) whose rheological properties can be tuned by an external magnetic field. In this study, we changed the shape of the electromagnet and MRC to improve the performance of the variable stiffness joint we previously fabricated; further, we fabricated a prototype and performed basic evaluation of the joint using this prototype. The MRC was fabricated by mixing carbonyl iron particles and glycerol. The prototype single joint was assembled by combining MRC and electromagnets. The configuration of the joint indicates that it has a closed magnetic circuit. To examine the basic properties of the joint, we conducted preliminary experiments such as elastic modulus measurement and rigidity evaluation. We confirmed that the elastic modulus increased when a magnetic field was applied. The rigidity of the joint was also verified under bending conditions. Our results confirmed that the stiffness of the new joint changed significantly compared with the old joint depending on the presence or absence of a magnetic field, and the performance of the new joint also improved.},
  archive      = {J_FROBT},
  author       = {Kitano, Sousaku and Komatsuzaki, Toshihiko and Suzuki, Ikuto and Nogawa, Masamichi and Naito, Hisashi and Tanaka, Shinobu},
  doi          = {10.3389/frobt.2020.00059},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {525635},
  shortjournal = {Front. Robot. AI},
  title        = {Development of a rigidity tunable flexible joint using magneto-rheological Compounds—Toward a multijoint manipulator for laparoscopic surgery},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Unsupervised learning facilitates neural coordination across
the functional clusters of the c. Elegans connectome. <em>FROBT</em>,
<em>7</em>, 517903. (<a
href="https://doi.org/10.3389/frobt.2020.00040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling of complex adaptive systems has revealed a still poorly understood benefit of unsupervised learning: when neural networks are enabled to form an associative memory of a large set of their own attractor configurations, they begin to reorganize their connectivity in a direction that minimizes the coordination constraints posed by the initial network architecture. This self-optimization process has been replicated in various neural network formalisms, but it is still unclear whether it can be applied to biologically more realistic network topologies and scaled up to larger networks. Here we continue our efforts to respond to these challenges by demonstrating the process on the connectome of the widely studied nematode worm C. elegans. We extend our previous work by considering the contributions made by hierarchical partitions of the connectome that form functional clusters, and we explore possible beneficial effects of inter-cluster inhibitory connections. We conclude that the self-optimization process can be applied to neural network topologies characterized by greater biological realism, and that long-range inhibitory connections can facilitate the generalization capacity of the process.},
  archive      = {J_FROBT},
  author       = {Morales, Alejandro and Froese, Tom},
  doi          = {10.3389/frobt.2020.00040},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {517903},
  shortjournal = {Front. Robot. AI},
  title        = {Unsupervised learning facilitates neural coordination across the functional clusters of the c. elegans connectome},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mutual shaping in swarm robotics: User studies in fire and
rescue, storage organization, and bridge inspection. <em>FROBT</em>,
<em>7</em>, 513589. (<a
href="https://doi.org/10.3389/frobt.2020.00053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real-world applications have been suggested in the swarm robotics literature. However, there is a general lack of understanding of what needs to be done for robot swarms to be useful and trusted by users in reality. This paper aims to investigate user perception of robot swarms in the workplace, and inform design principles for the deployment of future swarms in real-world applications. Three qualitative studies with a total of 37 participants were done across three sectors: fire and rescue, storage organization, and bridge inspection. Each study examined the users&#39; perceptions using focus groups and interviews. In this paper, we describe our findings regarding: the current processes and tools used in these professions and their main challenges; attitudes toward robot swarms assisting them; and the requirements that would encourage them to use robot swarms. We found that there was a generally positive reaction to robot swarms for information gathering and automation of simple processes. Furthermore, a human in the loop is preferred when it comes to decision making. Recommendations to increase trust and acceptance are related to transparency, accountability, safety, reliability, ease of maintenance, and ease of use. Finally, we found that mutual shaping, a methodology to create a bidirectional relationship between users and technology developers to incorporate societal choices in all stages of research and development, is a valid approach to increase knowledge and acceptance of swarm robotics. This paper contributes to the creation of such a culture of mutual shaping between researchers and users, toward increasing the chances of a successful deployment of robot swarms in the physical realm.},
  archive      = {J_FROBT},
  author       = {Carrillo-Zapata, Daniel and Milner, Emma and Hird, Julian and Tzoumas, Georgios and Vardanega, Paul J. and Sooriyabandara, Mahesh and Giuliani, Manuel and Winfield, Alan F. T. and Hauert, Sabine},
  doi          = {10.3389/frobt.2020.00053},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {513589},
  shortjournal = {Front. Robot. AI},
  title        = {Mutual shaping in swarm robotics: User studies in fire and rescue, storage organization, and bridge inspection},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Trouble and repair in child–robot interaction: A study of
complex interactions with a robot tutee in a primary school classroom.
<em>FROBT</em>, <em>7</em>, 513015. (<a
href="https://doi.org/10.3389/frobt.2020.00046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today, robots are studied and expected to be used in a range of social roles within classrooms. Yet, due to a number of limitations in social robots, robot interactions should be expected to occasionally suffer from troublesome situations and breakdowns. In this paper, we explore this issue by studying how children handle interaction trouble with a robot tutee in a classroom setting. The findings have implications not only for the design of robots, but also for evaluating their benefit in, and for, educational contexts. In this study, we conducted video analysis of children&#39;s group interactions with a robot tutee in a classroom setting, in order to explore the nature of these troubles in the wild. Within each group, children took turns acting as the primary interaction partner for the robot within the context of a mathematics game. Specifically, we examined what types of situations constitute trouble in these child–robot interactions, the strategies that individual children employ to cope with this trouble, as well as the strategies employed by other actors witnessing the trouble. By means of Interaction Analysis, we studied the video recordings of nine group interaction sessions (n = 33 children) in primary school grades 2 and 4. We found that sources of trouble related to the robot&#39;s social norm violations, which could be either active or passive. In terms of strategies, the children either persisted in their attempts at interacting with the robot by adapting their behavior in different ways, distanced themselves from the robot, or sought the help of present adults (i.e., a researcher in a teacher role, or an experimenter) or their peers (i.e., the child&#39;s classmates in each group). In terms of the witnessing actors, they addressed the trouble by providing guidance directed at the child interacting with the robot, or by intervening in the interaction. These findings reveal the unspoken rules by which children orient toward social robots, the complexities of child–robot interaction in the wild, and provide insights on children&#39;s perspectives and expectations of social robots in classroom contexts.},
  archive      = {J_FROBT},
  author       = {Serholt, Sofia and Pareto, Lena and Ekström, Sara and Ljungblad, Sara},
  doi          = {10.3389/frobt.2020.00046},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {513015},
  shortjournal = {Front. Robot. AI},
  title        = {Trouble and repair in Child–Robot interaction: A study of complex interactions with a robot tutee in a primary school classroom},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Guiding the self-organization of cyber-physical systems.
<em>FROBT</em>, <em>7</em>, 512610. (<a
href="https://doi.org/10.3389/frobt.2020.00041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-organization offers a promising approach for designing adaptive systems. Given the inherent complexity of most cyber-physical systems, adaptivity is desired, as predictability is limited. Here I summarize different concepts and approaches that can facilitate self-organization in cyber-physical systems, and thus be exploited for design. Then I mention real-world examples of systems where self-organization has managed to provide solutions that outperform classical approaches, in particular related to urban mobility. Finally, I identify when a centralized, distributed, or self-organizing control is more appropriate.},
  archive      = {J_FROBT},
  author       = {Gershenson, Carlos},
  doi          = {10.3389/frobt.2020.00041},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {512610},
  shortjournal = {Front. Robot. AI},
  title        = {Guiding the self-organization of cyber-physical systems},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An optimization-based locomotion controller for quadruped
robots leveraging cartesian impedance control. <em>FROBT</em>,
<em>7</em>, 512460. (<a
href="https://doi.org/10.3389/frobt.2020.00048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quadruped robots require compliance to handle unexpected external forces, such as impulsive contact forces from rough terrain, or from physical human-robot interaction. This paper presents a locomotion controller using Cartesian impedance control to coordinate tracking performance and desired compliance, along with Quadratic Programming (QP) to satisfy friction cone constraints, unilateral constraints, and torque limits. First, we resort to projected inverse-dynamics to derive an analytical control law of Cartesian impedance control for constrained and underactuated systems (typically a quadruped robot). Second, we formulate a QP to compute the optimal torques that are as close as possible to the desired values resulting from Cartesian impedance control while satisfying all of the physical constraints. When the desired motion torques lead to violation of physical constraints, the QP will result in a trade-off solution that sacrifices motion performance to ensure physical constraints. The proposed algorithm gives us more insight into the system that benefits from an analytical derivation and more efficient computation compared to hierarchical QP (HQP) controllers that typically require a solution of three QPs or more. Experiments applied on the ANYmal robot with various challenging terrains show the efficiency and performance of our controller.},
  archive      = {J_FROBT},
  author       = {Xin, Guiyang and Wolfslag, Wouter and Lin, Hsiu-Chin and Tiseo, Carlo and Mistry, Michael},
  doi          = {10.3389/frobt.2020.00048},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {512460},
  shortjournal = {Front. Robot. AI},
  title        = {An optimization-based locomotion controller for quadruped robots leveraging cartesian impedance control},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Swarm robotic behaviors and current applications.
<em>FROBT</em>, <em>7</em>, 512421. (<a
href="https://doi.org/10.3389/frobt.2020.00036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In swarm robotics multiple robots collectively solve problems by forming advantageous structures and behaviors similar to the ones observed in natural systems, such as swarms of bees, birds, or fish. However, the step to industrial applications has not yet been made successfully. Literature is light on real-world swarm applications that apply actual swarm algorithms. Typically, only parts of swarm algorithms are used which we refer to as basic swarm behaviors. In this paper we collect and categorize these behaviors into spatial organization, navigation, decision making, and miscellaneous. This taxonomy is then applied to categorize a number of existing swarm robotic applications from research and industrial domains. Along with the classification, we give a comprehensive overview of research platforms that can be used for testing and evaluating swarm behavior, systems that are already on the market, and projects that target a specific market. Results from this survey show that swarm robotic applications are still rare today. Many industrial projects still rely on centralized control, and even though a solution with multiple robots is employed, the principal idea of swarm robotics of distributed decision making is neglected. We identified mainly following reasons: First of all, swarm behavior emerging from local interactions is hard to predict and a proof of its eligibility for applications in an industrial context is difficult to provide. Second, current communication architectures often do not match requirements for swarm communication, which often leads to a system with a centralized communication infrastructure. Finally, testing swarms for real industrial applications is an issue, since deployment in a productive environment is typically too risky and simulations of a target system may not be sufficiently accurate. In contrast, the research platforms present a means for transforming swarm robotics solutions from theory to prototype industrial systems.},
  archive      = {J_FROBT},
  author       = {Schranz, Melanie and Umlauft, Martina and Sende, Micha and Elmenreich, Wilfried},
  doi          = {10.3389/frobt.2020.00036},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {512421},
  shortjournal = {Front. Robot. AI},
  title        = {Swarm robotic behaviors and current applications},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Scalable and robust fabrication, operation, and control of
compliant modular robots. <em>FROBT</em>, <em>7</em>, 511523. (<a
href="https://doi.org/10.3389/frobt.2020.00044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A major goal of autonomous robot collectives is to robustly perform complex tasks in unstructured environments by leveraging hardware redundancy and the emergent ability to adapt to perturbations. In such collectives, large numbers is a major contributor to system-level robustness. Designing robot collectives, however, requires more than isolated development of hardware and software that supports large scales. Rather, to support scalability, we must also incorporate robust constituents and weigh interrelated design choices that span fabrication, operation, and control with an explicit focus on achieving system-level robustness. Following this philosophy, we present the first iteration of a new framework toward a scalable and robust, planar, modular robot collective capable of gradient tracking in cluttered environments. To support co-design, our framework consists of hardware, low-level motion primitives, and control algorithms validated through a kinematic simulation environment. We discuss how modules made primarily of flexible printed circuit boards enable inexpensive, rapid, low-precision manufacturing; safe interactions between modules and their environment; and large-scale lattice structures beyond what manufacturing tolerances allow using rigid parts. To support redundancy, our proposed modules have on-board processing, sensing, and communication. To lower wear and consequently maintenance, modules have no internally moving parts, and instead move collaboratively via switchable magnets on their perimeter. These magnets can be in any of three states enabling a large range of module configurations and motion primitives, in turn supporting higher system adaptability. We introduce and compare several controllers that can plan in the collective&#39;s configuration space without restricting motion to a discrete occupancy grid as has been done in many past planners. We show how we can incentively redundant connections to prevent single-module failures from causing collective-wide failure, explore bad configurations which impede progress as a result of the motion constraints, and discuss an alternative “naive” planner with improved performance in both clutter-free and cluttered environments. This dedicated focus on system-level robustness over all parts of a complete design cycle, advances the state-of-the-art robots capable of long-term exploration.},
  archive      = {J_FROBT},
  author       = {Wilson, Nialah Jenae and Ceron, Steven and Horowitz, Logan and Petersen, Kirstin},
  doi          = {10.3389/frobt.2020.00044},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {511523},
  shortjournal = {Front. Robot. AI},
  title        = {Scalable and robust fabrication, operation, and control of compliant modular robots},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). How could future AI help tackle global complex problems?
<em>FROBT</em>, <em>7</em>, 509614. (<a
href="https://doi.org/10.3389/frobt.2020.00050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How does AI need to evolve in order to better support more effective decision-making in managing the many complex problems we face at every scale, from global climate change, collapsing ecosystems, international conflicts and extremism, through to all the dimensions of public policy, economics, and governance that affect human well-being? Research in complex decision-making at an individual human level (understanding of what constitutes more, and less, effective decision-making behaviors, and in particular the many pathways to failures in dealing with complex problems), informs a discussion about the potential for AI to aid in mitigating those failures and enabling a more robust and adaptive (and therefore more effective) decision-making framework, calling for AI to move well-beyond the current envelope of competencies.},
  archive      = {J_FROBT},
  author       = {Grisogono, Anne-Marie},
  doi          = {10.3389/frobt.2020.00050},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {509614},
  shortjournal = {Front. Robot. AI},
  title        = {How could future AI help tackle global complex problems?},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improving the robustness of online social networks: A
simulation approach of network interventions. <em>FROBT</em>,
<em>7</em>, 509376. (<a
href="https://doi.org/10.3389/frobt.2020.00057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online social networks (OSN) are prime examples of socio-technical systems in which individuals interact via a technical platform. OSN are very volatile because users enter and exit and frequently change their interactions. This makes the robustness of such systems difficult to measure and to control. To quantify robustness, we propose a coreness value obtained from the directed interaction network. We study the emergence of large drop-out cascades of users leaving the OSN by means of an agent-based model. For agents, we define a utility function that depends on their relative reputation and their costs for interactions. The decision of agents to leave the OSN depends on this utility. Our aim is to prevent drop-out cascades by influencing specific agents with low utility. We identify strategies to control agents in the core and the periphery of the OSN such that drop-out cascades are significantly reduced, and the robustness of the OSN is increased.},
  archive      = {J_FROBT},
  author       = {Casiraghi, Giona and Schweitzer, Frank},
  doi          = {10.3389/frobt.2020.00057},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {509376},
  shortjournal = {Front. Robot. AI},
  title        = {Improving the robustness of online social networks: A simulation approach of network interventions},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Imitating by generating: Deep generative models for
imitation of interactive tasks. <em>FROBT</em>, <em>7</em>, 508859. (<a
href="https://doi.org/10.3389/frobt.2020.00047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To coordinate actions with an interaction partner requires a constant exchange of sensorimotor signals. Humans acquire these skills in infancy and early childhood mostly by imitation learning and active engagement with a skilled partner. They require the ability to predict and adapt to one&#39;s partner during an interaction. In this work we want to explore these ideas in a human-robot interaction setting in which a robot is required to learn interactive tasks from a combination of observational and kinesthetic learning. To this end, we propose a deep learning framework consisting of a number of components for (1) human and robot motion embedding, (2) motion prediction of the human partner, and (3) generation of robot joint trajectories matching the human motion. As long-term motion prediction methods often suffer from the problem of regression to the mean, our technical contribution here is a novel probabilistic latent variable model which does not predict in joint space but in latent space. To test the proposed method, we collect human-human interaction data and human-robot interaction data of four interactive tasks “hand-shake,” “hand-wave,” “parachute fist-bump,” and “rocket fist-bump.” We demonstrate experimentally the importance of predictive and adaptive components as well as low-level abstractions to successfully learn to imitate human behavior in interactive social tasks.},
  archive      = {J_FROBT},
  author       = {Bütepage, Judith and Ghadirzadeh, Ali and Öztimur Karadaǧ, Özge and Björkman, Mårten and Kragic, Danica},
  doi          = {10.3389/frobt.2020.00047},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {508859},
  shortjournal = {Front. Robot. AI},
  title        = {Imitating by generating: Deep generative models for imitation of interactive tasks},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Investigating the hand ownership illusion with two views
merged in. <em>FROBT</em>, <em>7</em>, 493927. (<a
href="https://doi.org/10.3389/frobt.2020.00049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Researchers investigating virtual/augmented reality have shown humans&#39; marked adaptability, especially regarding our sense of body ownership; their cumulative findings have expanded the concept of what it means to have a body. Herein, we report the hand ownership illusion during “two views merged in.” In our experiment, participants were presented two first-person perspective views of their arm overlapped, one was the live feed from a camera and the other was a playback video of the same situation, slightly shifted toward one side. The relative visibility of these two views and synchrony of tactile stimulation were manipulated. Participants&#39; level of embodiment was evaluated using a questionnaire and proprioceptive drift. The results show that the likelihood of embodying the virtual hand is affected by the relative visibility of the two views and synchrony of the tactile events. We observed especially strong hand ownership of the virtual hand in the context of high virtual hand visibility with synchronous tactile stimulation.},
  archive      = {J_FROBT},
  author       = {Okumura, Keisuke and Ora, Hiroki and Miyake, Yoshihiro},
  doi          = {10.3389/frobt.2020.00049},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {493927},
  shortjournal = {Front. Robot. AI},
  title        = {Investigating the hand ownership illusion with two views merged in},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Toward an automated measure of social engagement for
children with autism spectrum disorder—a personalized computational
modeling approach. <em>FROBT</em>, <em>7</em>, 485929. (<a
href="https://doi.org/10.3389/frobt.2020.00043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social engagement is a key indicator of an individual&#39;s socio-emotional and cognitive states. For a child with Autism Spectrum Disorder (ASD), this serves as an important factor in assessing the quality of the interactions and interventions. So far, qualitative measures of social engagement have been used extensively in research and in practice, but a reliable, objective, and quantitative measure is yet to be widely accepted and utilized. In this paper, we present our work on the development of a framework for the automated measurement of social engagement in children with ASD that can be utilized in real-world settings for the long-term clinical monitoring of a child&#39;s social behaviors as well as for the evaluation of the intervention methods being used. We present a computational modeling approach to derive the social engagement metric based on a user study with children between the ages of 4 and 12 years. The study was conducted within a child-robot interaction setting that targets sensory processing skills in children. We collected video, audio and motion-tracking data from the subjects and used them to generate personalized models of social engagement by training a multi-channel and multi-layer convolutional neural network. We then evaluated the performance of this network by comparing it with traditional classifiers and assessed its limitations, followed by discussions on the next steps toward finding a comprehensive and accurate metric for social engagement in ASD.},
  archive      = {J_FROBT},
  author       = {Javed, Hifza and Lee, WonHyong and Park, Chung Hyuk},
  doi          = {10.3389/frobt.2020.00043},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {485929},
  shortjournal = {Front. Robot. AI},
  title        = {Toward an automated measure of social engagement for children with autism spectrum Disorder—A personalized computational modeling approach},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). In the wild HRI scenario: Influence of regulatory focus
theory. <em>FROBT</em>, <em>7</em>, 472683. (<a
href="https://doi.org/10.3389/frobt.2020.00058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research related to regulatory focus theory has shown that the way in which a message is conveyed can increase the effectiveness of the message. While different research fields have used this theory, in human-robot interaction (HRI), no real attention has been given to this theory. In this paper, we investigate it in an in the wild scenario. More specifically, we are interested in how individuals react when a robot suddenly appears at their office doors. Will they interact with it or will they ignore it? We report the results from our experimental study in which the robot approaches 42 individuals. Twenty-nine of them interacted with the robot, while the others either ignored it or avoided any interaction with it. The robot displayed two types of behavior (i.e., promotion or prevention). Our results show that individuals that interacted with a robot that matched their regulatory focus type interacted with it significantly longer than individuals that did not experience regulatory fit. Other qualitative results are also reported, together with some reactions from the participants.},
  archive      = {J_FROBT},
  author       = {Agrigoroaie, Roxana and Ciocirlan, Stefan-Dan and Tapus, Adriana},
  doi          = {10.3389/frobt.2020.00058},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {472683},
  shortjournal = {Front. Robot. AI},
  title        = {In the wild HRI scenario: Influence of regulatory focus theory},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Skill learning by autonomous robotic playing using active
learning and exploratory behavior composition. <em>FROBT</em>,
<em>7</em>, 467223. (<a
href="https://doi.org/10.3389/frobt.2020.00042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of autonomous acquisition of manipulation skills where problem-solving strategies are initially available only for a narrow range of situations. We propose to extend the range of solvable situations by autonomous play with the object. By applying previously-trained skills and behaviors, the robot learns how to prepare situations for which a successful strategy is already known. The information gathered during autonomous play is additionally used to train an environment model. This model is exploited for active learning and the generation of novel preparatory behaviors compositions. We apply our approach to a wide range of different manipulation tasks, e.g., book grasping, grasping of objects of different sizes by selecting different grasping strategies, placement on shelves, and tower disassembly. We show that the composite behavior generation mechanism enables the robot to solve previously-unsolvable tasks, e.g., tower disassembly. We use success statistics gained during real-world experiments to simulate the convergence behavior of our system. Simulation experiments show that the learning speed can be improved by around 30% by using active learning.},
  archive      = {J_FROBT},
  author       = {Hangl, Simon and Dunjko, Vedran and Briegel, Hans J. and Piater, Justus},
  doi          = {10.3389/frobt.2020.00042},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {467223},
  shortjournal = {Front. Robot. AI},
  title        = {Skill learning by autonomous robotic playing using active learning and exploratory behavior composition},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evolution of complex niche-constructing behaviors and
ecological inheritance of adaptive structures in a physically grounded
environment. <em>FROBT</em>, <em>7</em>, 434137. (<a
href="https://doi.org/10.3389/frobt.2020.00045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Niche construction is a process in which organisms modify the selection pressures on themselves and others through their ecological activities, and ecological inheritance is the consequence of niche construction inherited through generations. However, it is still unclear how such mutual interactions between robots or embodied agents and their physical environments can yield complex and divergent evolutionary processes or an open-ended evolution. Our purpose is to clarify what kind of complex and various niche-constructing behaviors evolve in a physically grounded environment under various conditions of ecological inheritance of constructed structures and spatial relationships. We focus on a predator-prey relationship, and constructed an evolutionary model in which a prey creature has to avoid predation through the construction of a structure composed of objects in a 2D physically simulated environment supported by a physics engine. We used a deep auto-encoder to extract the defining feature of adaptive structures automatically. The results in the case of no ecological inheritance revealed that the number of available resources can affect the diversity of emerging adaptive structures. Also, in the case with ecological inheritance, it was found that combinations of two types of ecological inheritance, which are the inheritance of adaptive structures and birthplace, can have strong effects on the diversity of emerging structures and the adaptivity of the population. We expect that findings in evolutionary simulations of niche-constructing behavior might contribute to evolutionary design of robotic builders or robot fabrication, especially when we assume physically simulated environments.},
  archive      = {J_FROBT},
  author       = {Chiba, Naoaki and Suzuki, Reiji and Arita, Takaya},
  doi          = {10.3389/frobt.2020.00045},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {434137},
  shortjournal = {Front. Robot. AI},
  title        = {Evolution of complex niche-constructing behaviors and ecological inheritance of adaptive structures in a physically grounded environment},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A robust screen-free brain-computer interface for robotic
object selection. <em>FROBT</em>, <em>7</em>, 516978. (<a
href="https://doi.org/10.3389/frobt.2020.00038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain signals represent a communication modality that can allow users of assistive robots to specify high-level goals, such as the object to fetch and deliver. In this paper, we consider a screen-free Brain-Computer Interface (BCI), where the robot highlights candidate objects in the environment using a laser pointer, and the user goal is decoded from the evoked responses in the electroencephalogram (EEG). Having the robot present stimuli in the environment allows for more direct commands than traditional BCIs that require the use of graphical user interfaces. Yet bypassing a screen entails less control over stimulus appearances. In realistic environments, this leads to heterogeneous brain responses for dissimilar objects—posing a challenge for reliable EEG classification. We model object instances as subclasses to train specialized classifiers in the Riemannian tangent space, each of which is regularized by incorporating data from other objects. In multiple experiments with a total of 19 healthy participants, we show that our approach not only increases classification performance but is also robust to both heterogeneous and homogeneous objects. While especially useful in the case of a screen-free BCI, our approach can naturally be applied to other experimental paradigms with potential subclass structure.},
  archive      = {J_FROBT},
  author       = {Kolkhorst, Henrich and Veit, Joseline and Burgard, Wolfram and Tangermann, Michael},
  doi          = {10.3389/frobt.2020.00038},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {516978},
  shortjournal = {Front. Robot. AI},
  title        = {A robust screen-free brain-computer interface for robotic object selection},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Iterative design and evaluation of a tangible robot-assisted
handwriting activity for special education. <em>FROBT</em>, <em>7</em>,
515673. (<a href="https://doi.org/10.3389/frobt.2020.00029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article we investigate the role of interactive haptic-enabled tangible robots in supporting the learning of cursive letter writing for children with attention and visuomotor coordination issues. We focus on the two principal aspects of handwriting that are linked to these issues: Visual perception and visuomotor coordination. These aspects, respectively, enhance two features of letter representation in the learner&#39;s mind in particular, namely the shape (grapheme) and the dynamics (ductus) of the letter, which constitute the central learning goals in our activity. Building upon an initial design tested with 17 healthy children in a preliminary school, we iteratively ported the activity to an occupational therapy context in 2 different therapy centers, in the context of 3 different summer school camps involving a total of 12 children having writing difficulties. The various iterations allowed us to uncover insights about the design of robot-enhanced writing activities for special education, specifically highlighting the importance of ease of modification of the duration of an activity as well as of adaptable frequency, content, flow and game-play and of providing a range of evaluation test alternatives. Results show that the use of robot-assisted handwriting activities could have a positive impact on the learning of the representation of letters in the context of occupational therapy (V = 1, 449, p &amp;lt; 0.001, r = 0.42). Results also highlight how the design changes made across the iterations affected the outcomes of the handwriting sessions, such as the evaluation of the performances, monitoring of the performances, and the connectedness of the handwriting.},
  archive      = {J_FROBT},
  author       = {Guneysu Ozgur, Arzu and Özgür, Ayberk and Asselborn, Thibault and Johal, Wafa and Yadollahi, Elmira and Bruno, Barbara and Skweres, Melissa and Dillenbourg, Pierre},
  doi          = {10.3389/frobt.2020.00029},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {515673},
  shortjournal = {Front. Robot. AI},
  title        = {Iterative design and evaluation of a tangible robot-assisted handwriting activity for special education},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Phenotypic plasticity provides a bioinspiration framework
for minimal field swarm robotics. <em>FROBT</em>, <em>7</em>, 514211.
(<a href="https://doi.org/10.3389/frobt.2020.00023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The real world is highly variable and unpredictable, and so fine-tuned robot controllers that successfully result in group-level “emergence” of swarm capabilities indoors may quickly become inadequate outside. One response to unpredictability could be greater robot complexity and cost, but this seems counter to the “swarm philosophy” of deploying (very) large numbers of simple agents. Instead, here I argue that bioinspiration in swarm robotics has considerable untapped potential in relation to the phenomenon of phenotypic plasticity: when a genotype can produce a range of distinctive changes in organismal behavior, physiology and morphology in response to different environments. This commonly arises following a natural history of variable conditions; implying the need for more diverse and hazardous simulated environments in offline, pre-deployment optimization of swarms. This will generate—indicate the need for—plasticity. Biological plasticity is sometimes irreversible; yet this characteristic remains relevant in the context of minimal swarms, where robots may become mass-producible. Plasticity can be introduced through the greater use of adaptive threshold-based behaviors; more fundamentally, it can link to emerging technologies such as smart materials, which can adapt form and function to environmental conditions. Moreover, in social animals, individual heterogeneity is increasingly recognized as functional for the group. Phenotypic plasticity can provide meaningful diversity “for free” based on early, local sensory experience, contributing toward better collective decision-making and resistance against adversarial agents, for example. Nature has already solved the challenge of resilient self-organisation in the physical realm through phenotypic plasticity: swarm engineers can follow this lead.},
  archive      = {J_FROBT},
  author       = {Hunt, Edmund R.},
  doi          = {10.3389/frobt.2020.00023},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {514211},
  shortjournal = {Front. Robot. AI},
  title        = {Phenotypic plasticity provides a bioinspiration framework for minimal field swarm robotics},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Attraction, dynamics, and phase transitions in fire ant
tower-building. <em>FROBT</em>, <em>7</em>, 513608. (<a
href="https://doi.org/10.3389/frobt.2020.00025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many insect species, and even some vertebrates, assemble their bodies to form multi-functional materials that combine sensing, computation, and actuation. The tower-building behavior of red imported fire ants, Solenopsis invicta, presents a key example of this phenomenon of collective construction. While biological studies of collective construction focus on behavioral assays to measure the dynamics of formation and studies of swarm robotics focus on developing hardware that can assemble and interact, algorithms for designing such collective aggregations have been mostly overlooked. We address this gap by formulating an agent-based model for collective tower-building with a set of behavioral rules that incorporate local sensing of neighboring agents. We find that an attractive force makes tower building possible. Next, we explore the trade-offs between attraction and random motion to characterize the dynamics and phase transition of the tower building process. Lastly, we provide an optimization tool that may be used to design towers of specific shapes, mechanical loads, and dynamical properties, such as mechanical stability and mobility of the center of mass.},
  archive      = {J_FROBT},
  author       = {Nave, Gary K. and Mitchell, Nelson T. and Chan Dick, Jordan A. and Schuessler, Tyler and Lagarrigue, Joaquin A. and Peleg, Orit},
  doi          = {10.3389/frobt.2020.00025},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {513608},
  shortjournal = {Front. Robot. AI},
  title        = {Attraction, dynamics, and phase transitions in fire ant tower-building},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Reinforcement learning-based tracking control of USVs in
varying operational conditions. <em>FROBT</em>, <em>7</em>, 510571. (<a
href="https://doi.org/10.3389/frobt.2020.00032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a reinforcement learning-based (RL) control scheme for trajectory tracking of fully-actuated surface vessels. The proposed method learns online both a model-based feedforward controller, as well an optimizing feedback policy in order to follow a desired trajectory under the influence of environmental forces. The method&#39;s efficiency is evaluated via simulations and sea trials, with the unmanned surface vehicle (USV) ReVolt performing three different tracking tasks: The four corner DP test, straight-path tracking and curved-path tracking. The results demonstrate the method&#39;s ability to accomplish the control objectives and a good agreement between the performance achieved in the Revolt Digital Twin and the sea trials. Finally, we include an section with considerations about assurance for RL-based methods and where our approach stands in terms of the main challenges.},
  archive      = {J_FROBT},
  author       = {Martinsen, Andreas B. and Lekkas, Anastasios M. and Gros, Sébastien and Glomsrud, Jon Arne and Pedersen, Tom Arne},
  doi          = {10.3389/frobt.2020.00032},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {510571},
  shortjournal = {Front. Robot. AI},
  title        = {Reinforcement learning-based tracking control of USVs in varying operational conditions},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Differences in spontaneous interactions of autistic children
in an interaction with an adult and humanoid robot. <em>FROBT</em>,
<em>7</em>, 510293. (<a
href="https://doi.org/10.3389/frobt.2020.00028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots are promising tools for promoting engagement of autistic children in interventions and thereby increasing the amount of learning opportunities. However, designing deliberate robot behavior aimed at engaging autistic children remains challenging. Our current understanding of what interactions with a robot, or facilitated by a robot, are particularly motivating to autistic children is limited to qualitative reports with small sample sizes. Translating insights from these reports to design is difficult due to the large individual differences among autistic children in their needs, interests, and abilities. To address these issues, we conducted a descriptive study and report on an analysis of how 31 autistic children spontaneously interacted with a humanoid robot and an adult within the context of a robot-assisted intervention, as well as which individual characteristics were associated with the observed interactions. For this analysis, we used video recordings of autistic children engaged in a robot-assisted intervention that were recorded as part of the DE-ENIGMA database. The results showed that the autistic children frequently engaged in exploratory and functional interactions with the robot spontaneously, as well as in interactions with the adult that were elicited by the robot. In particular, we observed autistic children frequently initiating interactions aimed at making the robot do a certain action. Autistic children with stronger language ability, social functioning, and fewer autism spectrum-related symptoms, initiated more functional interactions with the robot and more robot-elicited interactions with the adult. We conclude that the children&#39;s individual characteristics, in particular the child&#39;s language ability, can be indicative of which types of interaction they are more likely to find interesting. Taking these into account for the design of deliberate robot behavior, coupled with providing more autonomy over the robot&#39;s behavior to the autistic children, appears promising for promoting engagement and facilitating more learning opportunities.},
  archive      = {J_FROBT},
  author       = {Schadenberg, Bob R. and Reidsma, Dennis and Heylen, Dirk K. J. and Evers, Vanessa},
  doi          = {10.3389/frobt.2020.00028},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {510293},
  shortjournal = {Front. Robot. AI},
  title        = {Differences in spontaneous interactions of autistic children in an interaction with an adult and humanoid robot},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Haptic rendering of diverse tool-tissue contact constraints
during dental implantation procedures. <em>FROBT</em>, <em>7</em>,
505435. (<a href="https://doi.org/10.3389/frobt.2020.00035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motor skill learning of dental implantation surgery is difficult for novices because it involves fine manipulation of different dental tools to fulfill a strictly pre-defined procedure. Haptics-enabled virtual reality training systems provide a promising tool for surgical skill learning. In this paper, we introduce a haptic rendering algorithm for simulating diverse tool-tissue contact constraints during dental implantation. Motion forms of an implant tool can be summarized as the high degree of freedom (H-DoF) motion and the low degree of freedom (L-DoF) motion. During the H-DoF state, the tool can move freely on bone surface and in free space with 6 DoF. While during the L-DoF state, the motion degrees are restrained due to the constraints imposed by the implant bed. We propose a state switching framework to simplify the simulation workload by rendering the H-DoF motion state and the L-DoF motion state separately, and seamless switch between the two states by defining an implant criteria as the switching judgment. We also propose the virtual constraint method to render the L-DoF motion, which are different from ordinary drilling procedures as the tools should obey different axial constraint forms including sliding, drilling, screwing and perforating. The virtual constraint method shows efficiency and accuracy in adapting to different kinds of constraint forms, and consists of three core steps, including defining the movement axis, projecting the configuration difference, and deriving the movement control ratio. The H-DoF motion on bone surface and in free space is simulated through the previously proposed virtual coupling method. Experimental results illustrated that the proposed method could simulate the 16 different phases of the complete implant procedures of the Straumann® Bone Level(BL) Implants Φ4.8–L12 mm. According to the output force curve, different contact constraints could be rendered with steady and continuous output force during the operation procedures.},
  archive      = {J_FROBT},
  author       = {Zhao, Xiaohan and Zhu, Zhuoli and Cong, Yu and Zhao, Yongtao and Zhang, Yuru and Wang, Dangxiao},
  doi          = {10.3389/frobt.2020.00035},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {505435},
  shortjournal = {Front. Robot. AI},
  title        = {Haptic rendering of diverse tool-tissue contact constraints during dental implantation procedures},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A playful experiential learning system with educational
robotics. <em>FROBT</em>, <em>7</em>, 501912. (<a
href="https://doi.org/10.3389/frobt.2020.00033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article reports on two studies that aimed to evaluate the effective impact of educational robotics in learning concepts related to Physics and Geography. The reported studies involved two courses from an upper secondary school and two courses from a lower secondary school. Upper secondary school classes studied topics of motion physics, and lower secondary school classes explored issues related to geography. In each grade, there was an “experimental group” that carried out their study using robotics and cooperative learning and a “control group” that studied the same concepts without robots. Students in both classes were subjected to tests before and after the robotics laboratory, to check their knowledge in the topics covered. Our initial hypothesis was that classes involving educational robotics and cooperative learning are more effective in improving learning and stimulating the interest and motivation of students. As expected, the results showed that students in the experimental groups had a far better understanding of concepts and higher participation to the activities than students in the control groups.},
  archive      = {J_FROBT},
  author       = {D&#39;Amico, Antonella and Guastella, Domenico and Chella, Antonio},
  doi          = {10.3389/frobt.2020.00033},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {501912},
  shortjournal = {Front. Robot. AI},
  title        = {A playful experiential learning system with educational robotics},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Identification of the students learning process during
education robotics activities. <em>FROBT</em>, <em>7</em>, 501398. (<a
href="https://doi.org/10.3389/frobt.2020.00021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the design of an assessment process and its outcomes to investigate the impact of Educational Robotics activities on students&#39; learning. Through data analytics techniques, the authors will explore the activities&#39; output from a pedagogical and quantitative point of view. Sensors are utilized in the context of an Educational Robotics activity to obtain a more effective robot–environment interaction. Pupils work on specific exercises to make their robot smarter and to carry out more complex and inspirational projects: the integration of sensors on a robotic prototype is crucial, and learners have to comprehend how to use them. In the presented study, the potential of Educational Data Mining is used to investigate how a group of primary and secondary school students, using visual programming (Lego Mindstorms EV3 Education software), design programming sequences while they are solving an exercise related to an ultrasonic sensor mounted on their robotic artifact. For this purpose, a tracking system has been designed so that every programming attempt performed by students&#39; teams is registered on a log file and stored in an SD card installed in the Lego Mindstorms EV3 brick. These log files are then analyzed using machine learning techniques (k-means clustering) in order to extract different patterns in the creation of the sequences and extract various problem-solving pathways performed by students. The difference between problem-solving pathways with respect to an indicator of early achievement is studied.},
  archive      = {J_FROBT},
  author       = {Scaradozzi, David and Cesaretti, Lorenzo and Screpanti, Laura and Mangina, Eleni},
  doi          = {10.3389/frobt.2020.00021},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {501398},
  shortjournal = {Front. Robot. AI},
  title        = {Identification of the students learning process during education robotics activities},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Collaborative research project: Developing and testing a
robot-assisted intervention for children with autism. <em>FROBT</em>,
<em>7</em>, 499682. (<a
href="https://doi.org/10.3389/frobt.2020.00037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present work is a collaborative research aimed at testing the effectiveness of the robot-assisted intervention administered in real clinical settings by real educators. Social robots dedicated to assisting persons with autism spectrum disorder (ASD) are rarely used in clinics. In a collaborative effort to bridge the gap between innovation in research and clinical practice, a team of engineers, clinicians and researchers working in the field of psychology developed and tested a robot-assisted educational intervention for children with low-functioning ASD (N = 20) A total of 14 lessons targeting requesting and turn-taking were elaborated, based on the Pivotal Training Method and principles of Applied Analysis of Behavior. Results showed that sensory rewards provided by the robot elicited more positive reactions than verbal praises from humans. The robot was of greatest benefit to children with a low level of disability. The educators were quite enthusiastic about children&#39;s progress in learning basic psychosocial skills from interactions with the robot. The robot nonetheless failed to act as a social mediator, as more prosocial behaviors were observed in the control condition, where instead of interacting with the robot children played with a ball. We discuss how to program robots to the distinct needs of individuals with ASD, how to harness robots&#39; likability in order to enhance social skill learning, and how to arrive at a consensus about the standards of excellence that need to be met in interdisciplinary co-creation research. Our intuition is that robotic assistance, obviously judged as to be positive by educators, may contribute to the dissemination of innovative evidence-based practice for individuals with ASD.},
  archive      = {J_FROBT},
  author       = {Kostrubiec, Viviane and Kruck, Jeanne},
  doi          = {10.3389/frobt.2020.00037},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {499682},
  shortjournal = {Front. Robot. AI},
  title        = {Collaborative research project: Developing and testing a robot-assisted intervention for children with autism},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Which body would you like to have? The impact of embodied
perspective on body perception and body evaluation in immersive virtual
reality. <em>FROBT</em>, <em>7</em>, 492886. (<a
href="https://doi.org/10.3389/frobt.2020.00031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this experiment, we aimed to measure the conscious internal representation of one&#39;s body appearance and allow the participants to compare this to their ideal body appearance and to their real body appearance. We created a virtual representation of the internal image participants had of their own body shape. We also created a virtual body corresponding to the internal representation they had of their ideal body shape, and we built another virtual body based on their real body measures. Participants saw the three different virtual bodies from an embodied first-person perspective and from a third-person perspective and had to evaluate the appearance of those virtual bodies. We observed that female participants evaluated their real body as more attractive when they saw it from a third-person perspective, and that their level of body dissatisfaction was lower after the experimental procedure. We believe that third-person perspective allowed female participants to perceive their real body shape without applying the negative prior beliefs usually associated to the “self”, and that this resulted in a more positive evaluation of their body shape. We speculate that this method could be applied with patients suffering from eating disorders, by making their body perception more realistic and therefore improve their body satisfaction.},
  archive      = {J_FROBT},
  author       = {Neyret, Solène and Bellido Rivas, Anna I. and Navarro, Xavi and Slater, Mel},
  doi          = {10.3389/frobt.2020.00031},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {492886},
  shortjournal = {Front. Robot. AI},
  title        = {Which body would you like to have? the impact of embodied perspective on body perception and body evaluation in immersive virtual reality},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Examining the use of temporal-difference incremental
delta-bar-delta for real-world predictive knowledge architectures.
<em>FROBT</em>, <em>7</em>, 491871. (<a
href="https://doi.org/10.3389/frobt.2020.00034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predictions and predictive knowledge have seen recent success in improving not only robot control but also other applications ranging from industrial process control to rehabilitation. A property that makes these predictive approaches well-suited for robotics is that they can be learned online and incrementally through interaction with the environment. However, a remaining challenge for many prediction-learning approaches is an appropriate choice of prediction-learning parameters, especially parameters that control the magnitude of a learning machine&#39;s updates to its predictions (the learning rates or step sizes). Typically, these parameters are chosen based on an extensive parameter search—an approach that neither scales well nor is well-suited for tasks that require changing step sizes due to non-stationarity. To begin to address this challenge, we examine the use of online step-size adaptation using the Modular Prosthetic Limb: a sensor-rich robotic arm intended for use by persons with amputations. Our method of choice, Temporal-Difference Incremental Delta-Bar-Delta (TIDBD), learns and adapts step sizes on a feature level; importantly, TIDBD allows step-size tuning and representation learning to occur at the same time. As a first contribution, we show that TIDBD is a practical alternative for classic Temporal-Difference (TD) learning via an extensive parameter search. Both approaches perform comparably in terms of predicting future aspects of a robotic data stream, but TD only achieves comparable performance with a carefully hand-tuned learning rate, while TIDBD uses a robust meta-parameter and tunes its own learning rates. Secondly, our results show that for this particular application TIDBD allows the system to automatically detect patterns characteristic of sensor failures common to a number of robotic applications. As a third contribution, we investigate the sensitivity of classic TD and TIDBD with respect to the initial step-size values on our robotic data set, reaffirming the robustness of TIDBD as shown in previous papers. Together, these results promise to improve the ability of robotic devices to learn from interactions with their environments in a robust way, providing key capabilities for autonomous agents and robots.},
  archive      = {J_FROBT},
  author       = {Günther, Johannes and Ady, Nadia M. and Kearney, Alex and Dawson, Michael R. and Pilarski, Patrick M.},
  doi          = {10.3389/frobt.2020.00034},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {491871},
  shortjournal = {Front. Robot. AI},
  title        = {Examining the use of temporal-difference incremental delta-bar-delta for real-world predictive knowledge architectures},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Test bench for evaluation of a soft robotic link.
<em>FROBT</em>, <em>7</em>, 483221. (<a
href="https://doi.org/10.3389/frobt.2020.00027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we describe the control approaches tested in the improved version of an existing soft robotic neck with two Degrees Of Freedom (DOF), able to achieve flexion, extension, and lateral bending movements similar to those of a human neck. The design is based on a cable-driven mechanism consisting of a spring acting as a cervical spine and three servomotor actuated tendons that let the neck to reach all desired postures. The prototype was manufactured using a 3D printer. Two control approaches are proposed and tested experimentally: a motor position approach using encoder feedback and a tip position approach using Inertial Measurement Unit (IMU) feedback, both applying fractional-order controllers. The platform operation is tested for different load configurations so that the robustness of the system can be checked.},
  archive      = {J_FROBT},
  author       = {Mena, Lisbeth and Monje, Concepción A. and Nagua, Luis and Muñoz, Jorge and Balaguer, Carlos},
  doi          = {10.3389/frobt.2020.00027},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {483221},
  shortjournal = {Front. Robot. AI},
  title        = {Test bench for evaluation of a soft robotic link},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Re-association of body parts: Illusory ownership of a
virtual arm associated with the contralateral real finger by visuo-motor
synchrony. <em>FROBT</em>, <em>7</em>, 474473. (<a
href="https://doi.org/10.3389/frobt.2020.00026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Illusory ownership can be induced in a virtual body by visuo-motor synchrony. Our aim was to test the possibility of a re-association of the right thumb with a virtual left arm and express the illusory body ownership of the re-associated arm through a synchronous or asynchronous movement of the body parts through action and vision. Participants felt that their right thumb was the virtual left arm more strongly in the synchronous condition than in the asynchronous one, and the feeling of ownership of the virtual arm was also stronger in the synchronous condition. We did not find a significant difference in the startle responses to a sudden knife appearance to the virtual arm between the two synchrony conditions, as there was no proprioceptive drift of the thumb. These results suggest that a re-association of the right thumb with the virtual left arm could be induced by visuo-motor synchronization; however, it may be weaker than the natural association.},
  archive      = {J_FROBT},
  author       = {Kondo, Ryota and Tani, Yamato and Sugimoto, Maki and Minamizawa, Kouta and Inami, Masahiko and Kitazaki, Michiteru},
  doi          = {10.3389/frobt.2020.00026},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {474473},
  shortjournal = {Front. Robot. AI},
  title        = {Re-association of body parts: Illusory ownership of a virtual arm associated with the contralateral real finger by visuo-motor synchrony},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Corrigendum: Radiological mapping of post-disaster nuclear
environments using fixed-wing unmanned aerial systems: A study from
chornobyl. <em>FROBT</em>, <em>7</em>, 534114. (<a
href="https://doi.org/10.3389/frobt.2020.00030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Connor, Dean T. and Wood, Kieran and Martin, Peter G. and Goren, Sevda and Megson-Smith, David and Verbelen, Yannick and Chyzhevskyi, Igor and Kirieiev, Serhii and Smith, Nick T. and Richardson, Tom and Scott, Thomas B.},
  doi          = {10.3389/frobt.2020.00030},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {534114},
  shortjournal = {Front. Robot. AI},
  title        = {Corrigendum: radiological mapping of post-disaster nuclear environments using fixed-wing unmanned aerial systems: a study from chornobyl},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Pneumatic coiling actuator inspired by the awns of erodium
cicutarium. <em>FROBT</em>, <em>7</em>, 516958. (<a
href="https://doi.org/10.3389/frobt.2020.00017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study examines the coiling and uncoiling motions of a soft pneumatic actuator inspired by the awn tissue of Erodium cicutarium. These tissues have embedded cellulose fibers distributed in a tilted helical pattern, which induces hygroscopic coiling and uncoiling in response to the daily changes in ambient humidity. Such sophisticated motions can eventually “drill” the seed at the tip of awn tissue into the soil: a drill bit in the plant kingdom. Through finite element simulation and experimental testing, this study examines a soft pneumatic actuator that has a similar reinforcing fiber layout to the Erodium plant tissue. This actuator, in essence, is a thin-walled elastomeric cylinder covered by tilted helical Kevlar fibers. Upon internal pressurization, it can exhibit a coiling motion by a combination of simultaneous twisting, bending, and extension. Parametric analyses show that the coiling motion characteristics are directly related to the geometry of tilted helical fibers. Notably, a moderate tilt in the reinforcing helical fiber leads to many coils of small radius, while a significant tilt gives fewer coils of larger radius. The results of this study can offer guidelines for constructing plant-inspired robotic manipulators that can achieve complicated motions with simple designs.},
  archive      = {J_FROBT},
  author       = {Geer, Ryan and Iannucci, Steven and Li, Suyi},
  doi          = {10.3389/frobt.2020.00017},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {516958},
  shortjournal = {Front. Robot. AI},
  title        = {Pneumatic coiling actuator inspired by the awns of erodium cicutarium},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey on swarming with micro air vehicles: Fundamental
challenges and constraints. <em>FROBT</em>, <em>7</em>, 513001. (<a
href="https://doi.org/10.3389/frobt.2020.00018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a review and discussion of the challenges that must be solved in order to successfully develop swarms of Micro Air Vehicles (MAVs) for real world operations. From the discussion, we extract constraints and links that relate the local level MAV capabilities to the global operations of the swarm. These should be taken into account when designing swarm behaviors in order to maximize the utility of the group. At the lowest level, each MAV should operate safely. Robustness is often hailed as a pillar of swarm robotics, and a minimum level of local reliability is needed for it to propagate to the global level. An MAV must be capable of autonomous navigation within an environment with sufficient trustworthiness before the system can be scaled up. Once the operations of the single MAV are sufficiently secured for a task, the subsequent challenge is to allow the MAVs to sense one another within a neighborhood of interest. Relative localization of neighbors is a fundamental part of self-organizing robotic systems, enabling behaviors ranging from basic relative collision avoidance to higher level coordination. This ability, at times taken for granted, also must be sufficiently reliable. Moreover, herein lies a constraint: the design choice of the relative localization sensor has a direct link to the behaviors that the swarm can (and should) perform. Vision-based systems, for instance, force MAVs to fly within the field of view of their camera. Range or communication-based solutions, alternatively, provide omni-directional relative localization, yet can be victim to unobservable conditions under certain flight behaviors, such as parallel flight, and require constant relative excitation. At the swarm level, the final outcome is thus intrinsically influenced by the on-board abilities and sensors of the individual. The real-world behavior and operations of an MAV swarm intrinsically follow in a bottom-up fashion as a result of the local level limitations in cognition, relative knowledge, communication, power, and safety. Taking these local limitations into account when designing a global swarm behavior is key in order to take full advantage of the system, enabling local limitations to become true strengths of the swarm.},
  archive      = {J_FROBT},
  author       = {Coppola, Mario and McGuire, Kimberly N. and De Wagter, Christophe and de Croon, Guido C. H. E.},
  doi          = {10.3389/frobt.2020.00018},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {513001},
  shortjournal = {Front. Robot. AI},
  title        = {A survey on swarming with micro air vehicles: Fundamental challenges and constraints},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Editorial: AI for robot modeling, path planning, and
intelligent control. <em>FROBT</em>, <em>7</em>, 502966. (<a
href="https://doi.org/10.3389/frobt.2020.00019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Pan, Yongping and Al-Hadithi, Basil M. and Yang, Chenguang},
  doi          = {10.3389/frobt.2020.00019},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {502966},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: AI for robot modeling, path planning, and intelligent control},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Language evolution in swarm robotics: A perspective.
<em>FROBT</em>, <em>7</em>, 502953. (<a
href="https://doi.org/10.3389/frobt.2020.00012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While direct local communication is very important for the organization of robot swarms, so far it has mostly been used for relatively simple tasks such as signaling robots preferences or states. Inspired by the emergence of meaning found in natural languages, more complex communication skills could allow robot swarms to tackle novel situations in ways that may not be a priori obvious to the experimenter. This would pave the way for the design of robot swarms with higher autonomy and adaptivity. The state of the art regarding the emergence of communication for robot swarms has mostly focused on offline evolutionary approaches, which showed that signaling and communication can emerge spontaneously even when not explicitly promoted. However, these approaches do not lead to complex, language-like communication skills, and signals are tightly linked to environmental and/or sensory-motor states that are specific to the task for which communication was evolved. To move beyond current practice, we advocate an approach to emergent communication in robot swarms based on language games. Thanks to language games, previous studies showed that cultural self-organization—rather than biological evolution—can be responsible for the complexity and expressive power of language. We suggest that swarm robotics can be an ideal test-bed to advance research on the emergence of language-like communication. The latter can be key to provide robot swarms with additional skills to support self-organization and adaptivity, enabling the design of more complex collective behaviors.},
  archive      = {J_FROBT},
  author       = {Cambier, Nicolas and Miletitch, Roman and Frémont, Vincent and Dorigo, Marco and Ferrante, Eliseo and Trianni, Vito},
  doi          = {10.3389/frobt.2020.00012},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {502953},
  shortjournal = {Front. Robot. AI},
  title        = {Language evolution in swarm robotics: A perspective},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Child-robot collaborative problem-solving and the importance
of child’s voluntary interaction: A developmental perspective.
<em>FROBT</em>, <em>7</em>, 501934. (<a
href="https://doi.org/10.3389/frobt.2020.00015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence and development of cognitive strategies for the transition from exploratory actions towards intentional problem-solving in children is a key question for the understanding of the development of human cognition. Researchers in developmental psychology have studied cognitive strategies and have highlighted the catalytic role of the social environment. However, it is not yet adequately understood how this capacity emerges and develops in biological systems when they perform a problem-solving task in collaboration with a robotic social agent. This paper presents an empirical study in a human-robot interaction (HRI) setting which investigates children&#39;s problem-solving from a developmental perspective. In order to theoretically conceptualize children&#39;s developmental process of problem-solving in HRI context, we use principles based on the intuitive theory and we take into consideration existing research on executive functions with a focus on inhibitory control. We considered the paradigm of the Tower of Hanoi and we conducted an HRI behavioral experiment to evaluate task performance. We designed two types of robot interventions, “voluntary” and “turn-taking”—manipulating exclusively the timing of the intervention. Our results indicate that the children who participated in the voluntary interaction setting showed a better performance in the problem solving activity during the evaluation session despite their large variability in the frequency of self-initiated interactions with the robot. Additionally, we present a detailed description of the problem-solving trajectory for a representative single case-study, which reveals specific developmental patterns in the context of the specific task. Implications and future work are discussed regarding the development of intelligent robotic systems that allow child-initiated interaction as well as targeted and not constant robot interventions.},
  archive      = {J_FROBT},
  author       = {Charisi, Vicky and Gomez, Emilia and Mier, Gonzalo and Merino, Luis and Gomez, Randy},
  doi          = {10.3389/frobt.2020.00015},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {501934},
  shortjournal = {Front. Robot. AI},
  title        = {Child-robot collaborative problem-solving and the importance of child&#39;s voluntary interaction: A developmental perspective},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Developing self-awareness in robots via inner speech.
<em>FROBT</em>, <em>7</em>, 500941. (<a
href="https://doi.org/10.3389/frobt.2020.00016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The experience of inner speech is a common one. Such a dialogue accompanies the introspection of mental life and fulfills essential roles in human behavior, such as self-restructuring, self-regulation, and re-focusing on attentional resources. Although the underpinning of inner speech is mostly investigated in psychological and philosophical fields, the research in robotics generally does not address such a form of self-aware behavior. Existing models of inner speech inspire computational tools to provide a robot with this form of self-awareness. Here, the widespread psychological models of inner speech are reviewed, and a cognitive architecture for a robot implementing such a capability is outlined in a simplified setup.},
  archive      = {J_FROBT},
  author       = {Chella, Antonio and Pipitone, Arianna and Morin, Alain and Racy, Famira},
  doi          = {10.3389/frobt.2020.00016},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {500941},
  shortjournal = {Front. Robot. AI},
  title        = {Developing self-awareness in robots via inner speech},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Radiation tolerance testing methodology of robotic
manipulator prior to nuclear waste handling. <em>FROBT</em>, <em>7</em>,
499048. (<a href="https://doi.org/10.3389/frobt.2020.00006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dramatic cost savings, safety improvements and accelerated nuclear decommissioning are all possible through the application of robotic solutions. Remotely-controlled systems with modern sensing capabilities, actuators and cutting tools have the potential for use in extremely hazardous environments, but operation in facilities used for handling radioactive material presents complex challenges for electronic components. We present a methodology and results obtained from testing in a radiation cell in which we demonstrate the operation of a robotic arm controlled using modern electronics exposed at 10 Gy/h to simulate radioactive conditions in the most hazardous nuclear waste handling facilities.},
  archive      = {J_FROBT},
  author       = {Zhang, Kaiqiang and Hutson, Chris and Knighton, James and Herrmann, Guido and Scott, Tom},
  doi          = {10.3389/frobt.2020.00006},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {499048},
  shortjournal = {Front. Robot. AI},
  title        = {Radiation tolerance testing methodology of robotic manipulator prior to nuclear waste handling},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A worm-like biomimetic crawling robot based on cylindrical
dielectric elastomer actuators. <em>FROBT</em>, <em>7</em>, 496367. (<a
href="https://doi.org/10.3389/frobt.2020.00009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years the field of soft robotics has gained a lot of interest both in academia and industry. In contrast to rigid robots, which are potentially very powerful and precise, soft robots are composed of compliant materials like gels or elastomers (Rich et al., 2018; Majidi, 2019). Their exclusive composition of nearly entirely soft materials offers the potential to extend the use of robotics to fields like healthcare (Burgner-Kahrs et al., 2015; Banerjee et al., 2018) and advance the emerging domain of cooperative human-machine interaction (Asbeck et al., 2014). One material class used frequently in soft robotics as actuators are electroactive polymers (EAPs). Especially dielectric elastomer actuators (DEAs) consisting of a thin elastomer membrane sandwiched between two compliant electrodes offer promising characteristics for actuator drives (Pelrine et al., 2000). Under an applied electric field, the resulting electrostatic pressure leads to a reduction in thickness and an expansion in the free spatial directions. The resulting expansion can reach strain levels of more than 300% (Bar-Cohen, 2004). This paper presents a bioinspired worm-like crawling robot based on DEAs with additional textile reinforcement in its silicone structures. A special focus is set on the developed cylindrical actuator segments that act as linear actuators.},
  archive      = {J_FROBT},
  author       = {Pfeil, Sascha and Henke, Markus and Katzer, Konrad and Zimmermann, Martina and Gerlach, Gerald},
  doi          = {10.3389/frobt.2020.00009},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {496367},
  shortjournal = {Front. Robot. AI},
  title        = {A worm-like biomimetic crawling robot based on cylindrical dielectric elastomer actuators},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Audio in VR: Effects of a soundscape and movement-triggered
step sounds on presence. <em>FROBT</em>, <em>7</em>, 494828. (<a
href="https://doi.org/10.3389/frobt.2020.00020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For effective virtual realities, “presence,” the feeling of “being there” in a virtual environment (VR), is deemed an essential prerequisite. Several studies have assessed the effect of the (non-)availability of auditory stimulation on presence, but due to differences in study design (e.g., virtual realities used, types of sounds included, rendering technologies employed), generalizing the results and estimating the effect of the auditory component is difficult. In two experiments, the influence of an ambient nature soundscape and movement-triggered step sounds were investigated regarding their effects on presence. In each experiment, approximately forty participants walked on a treadmill, thereby strolling through a virtual park environment reproduced via a stereoscopic head-mounted display (HMD), while the acoustical environment was delivered via noise-canceling headphones. In Experiment 1, conditions with the ambient soundscape and the step sounds either present or absent were combined in a 2 × 2 within-subjects design, supplemented with an additional “no-headphones” control condition. For the synchronous playback of step sounds, the probability of a step being taken was estimated by an algorithm using the HMD&#39;s sensor data. The results of Experiment 1 show that questionnaire-based measures of presence and realism were influenced by the soundscape but not by the reproduction of steps, which might be confounded with the fact that the perceived synchronicity of the sensor-triggered step sounds was rated rather low. Therefore, in Experiment 2, the step-reproduction algorithm was improved and judged to be more synchronous by participants. Consequently, large and statistically significant effects of both kinds of audio manipulations on perceived presence and realism were observed, with the effect of the soundscape being larger than that of including footstep sounds, possibly due to the remaining imperfections in the reproduction of steps. Including an appropriate soundscape or self-triggered footsteps had differential effects on subscales of presence, in that both affected overall presence and realism, while involvement was improved and distraction reduced by the ambient soundscape only.},
  archive      = {J_FROBT},
  author       = {Kern, Angelika C. and Ellermeier, Wolfgang},
  doi          = {10.3389/frobt.2020.00020},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {494828},
  shortjournal = {Front. Robot. AI},
  title        = {Audio in VR: Effects of a soundscape and movement-triggered step sounds on presence},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Human lower limb joint biomechanics in daily life
activities: A literature based requirement analysis for anthropomorphic
robot design. <em>FROBT</em>, <em>7</em>, 492132. (<a
href="https://doi.org/10.3389/frobt.2020.00013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Daily human activity is characterized by a broad variety of movement tasks. This work summarizes the sagittal hip, knee, and ankle joint biomechanics for a broad range of daily movements, based on previously published literature, to identify requirements for robotic design. Maximum joint power, moment, angular velocity, and angular acceleration, as well as the movement-related range of motion and the mean absolute power were extracted, compared, and analyzed for essential and sportive movement tasks. We found that the full human range of motion is required to mimic human like performance and versatility. In general, sportive movements were found to exhibit the highest joint requirements in angular velocity, angular acceleration, moment, power, and mean absolute power. However, at the hip, essential movements, such as recovery, had comparable or even higher requirements. Further, we found that the moment and power demands were generally higher in stance, while the angular velocity and angular acceleration were mostly higher or equal in swing compared to stance for locomotion tasks. The extracted requirements provide a novel comprehensive overview that can help with the dimensioning of actuators enabling tailored assistance or rehabilitation for wearable lower limb robots, and to achieve essential, sportive or augmented performances that exceed natural human capabilities with humanoid robots.},
  archive      = {J_FROBT},
  author       = {Grimmer, Martin and Elshamanhory, Ahmed A. and Beckerle, Philipp},
  doi          = {10.3389/frobt.2020.00013},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {492132},
  shortjournal = {Front. Robot. AI},
  title        = {Human lower limb joint biomechanics in daily life activities: A literature based requirement analysis for anthropomorphic robot design},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Altering one’s body-perception through e-textiles and haptic
metaphors. <em>FROBT</em>, <em>7</em>, 491632. (<a
href="https://doi.org/10.3389/frobt.2020.00007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Technologies change rapidly our perception of reality, moving from augmented to virtual to magical. While e-textiles are a key component in exergame or space suits, the transformative potential of the internal side of garments to create embodied experiences still remains largely unexplored. This paper is the result from an art-science collaborative project that combines recent neuroscience findings, body-centered design principles and 2D vibrotactile array-based fabrics to alter one&#39;s body perception. We describe an iterative design process intertwined with two user studies on the effects on body-perceptions and emotional responses of various vibration patterns within textile that were designed as spatial haptic metaphors. Our results show potential in considering materials (e.g., rocks) as sensations to design for body perceptions (e.g., being heavy, strong) and emotional responses. We discuss these results in terms of sensory effects on body perception and synergetic impact to research on embodiment in virtual environments, human-computer interaction, and e-textile design. The work brings a new perspective to the sensorial design of embodied experiences which is based on “material perception” and haptic metaphors, and highlights potential opportunities opened by haptic clothing to change body-perception.},
  archive      = {J_FROBT},
  author       = {Tajadura-Jiménez, Ana and Väljamäe, Aleksander and Kuusk, Kristi},
  doi          = {10.3389/frobt.2020.00007},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {491632},
  shortjournal = {Front. Robot. AI},
  title        = {Altering one&#39;s body-perception through E-textiles and haptic metaphors},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A self-guiding tool to conduct research with embodiment
technologies responsibly. <em>FROBT</em>, <em>7</em>, 491552. (<a
href="https://doi.org/10.3389/frobt.2020.00022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The extension of the sense of self to the avatar during experiences of avatar embodiment requires thorough ethical and legal consideration, especially in light of potential scenarios involving physical or psychological harm caused to, or by, embodied avatars. We provide researchers and developers working in the field of virtual and robot embodiment technologies with a self-guidance tool based on the principles of Responsible Research and Innovation (RRI). This tool will help them engage in ethical and responsible research and innovation in the area of embodiment technologies in a way that guarantees all the rights of the embodied users and their interactors, including safety, privacy, autonomy, and dignity.},
  archive      = {J_FROBT},
  author       = {Aymerich-Franch, Laura and Fosch-Villaronga, Eduard},
  doi          = {10.3389/frobt.2020.00022},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {491552},
  shortjournal = {Front. Robot. AI},
  title        = {A self-guiding tool to conduct research with embodiment technologies responsibly},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Toward enhanced teleoperation through embodiment.
<em>FROBT</em>, <em>7</em>, 489336. (<a
href="https://doi.org/10.3389/frobt.2020.00014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Telerobotics aims to transfer human manipulation skills and dexterity over an arbitrary distance and at an arbitrary scale to a remote workplace. A telerobotic system that is transparent enables a natural and intuitive interaction. We postulate that embodiment (with three sub-components: sense of ownership, agency, and self-location) of the robotic system leads to optimal perceptual transparency and increases task performance. However, this has not yet been investigated directly. We reason along four premises and present findings from the literature that substantiate each of them: (1) the brain can embody non-bodily objects (e.g., robotic hands), (2) embodiment can be elicited with mediated sensorimotor interaction, (3) embodiment is robust against inconsistencies between the robotic system and the operator&#39;s body, and (4) embodiment positively correlates to dexterous task performance. We use the predictive encoding theory as a framework to interpret and discuss the results reported in the literature. Numerous previous studies have shown that it is possible to induce embodiment over a wide range of virtual and real extracorporeal objects (including artificial limbs, avatars, and android robots) through mediated sensorimotor interaction. Also, embodiment can occur for non-human morphologies including for elongated arms and a tail. In accordance with the predictive encoding theory, none of the sensory modalities is critical in establishing ownership, and discrepancies in multisensory signals do not necessarily lead to loss of embodiment. However, large discrepancies in terms of multisensory synchrony or visual likeness can prohibit embodiment from occurring. The literature provides less extensive support for the link between embodiment and (dexterous) task performance. However, data gathered with prosthetic hands do indicate a positive correlation. We conclude that all four premises are supported by direct or indirect evidence in the literature, suggesting that embodiment of a remote manipulator may improve dexterous performance in telerobotics. This warrants further implementation testing of embodiment in telerobotics. We formulate a first set of guidelines to apply embodiment in telerobotics and identify some important research topics.},
  archive      = {J_FROBT},
  author       = {Toet, Alexander and Kuling, Irene A. and Krom, Bouke N. and van Erp, Jan B. F.},
  doi          = {10.3389/frobt.2020.00014},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {489336},
  shortjournal = {Front. Robot. AI},
  title        = {Toward enhanced teleoperation through embodiment},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Exploring teens as robot operators, users and witnesses in
the wild. <em>FROBT</em>, <em>7</em>, 478682. (<a
href="https://doi.org/10.3389/frobt.2020.00005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As social robots continue to show promise as assistive technologies, the exploration of appropriate and impactful robot behaviors is key to their eventual success. Teens are a unique population given their vulnerability to stress leading to both mental and physical illness. Much of teen stress stems from school, making the school environment an ideal location for a stress reducing technology. The goal of this mixed-methods study was to understand teens&#39; operation of, and responsiveness to, a robot only capable of movement compared to a robot only capable of speech. Stemming from a human-centered approach, we introduce a Participatory Wizard of Oz (PWoz) interaction method that engaged teens as operators, users, and witnesses in a uniquely transparent interaction. In this paper, we illustrate the use of the PWoz interaction method as well as how it helps identify engaging robot interactions. Using this technique, we present results from a study with 62 teens that includes details of the complexity of teen stress and a significant reduction in negative attitudes toward robots after interactions. We analyzed the teens&#39; interactions with both the verbal and non-verbal robots and identified strong themes of (1) authenticity, (2) empathy, (3) emotional engagement, and (4) imperfection creates connection. Finally, we reflect on the benefits and limitations of the PWoz method and our study to identify next steps toward the design and development of our social robot.},
  archive      = {J_FROBT},
  author       = {Björling, Elin A. and Thomas, Kyle and Rose, Emma J. and Cakmak, Maya},
  doi          = {10.3389/frobt.2020.00005},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {478682},
  shortjournal = {Front. Robot. AI},
  title        = {Exploring teens as robot operators, users and witnesses in the wild},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hybrid collision avoidance for ASVs compliant with COLREGs
rules 8 and 13–17. <em>FROBT</em>, <em>7</em>, 475020. (<a
href="https://doi.org/10.3389/frobt.2020.00011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a three-layered hybrid collision avoidance (COLAV) system for autonomous surface vehicles, compliant with rules 8 and 13–17 of the International Regulations for Preventing Collisions at Sea (COLREGs). The COLAV system consists of a high-level planner producing an energy-optimized trajectory, a model-predictive-control-based mid-level COLAV algorithm considering moving obstacles and the COLREGs, and the branching-course model predictive control algorithm for short-term COLAV handling emergency situations in accordance with the COLREGs. Previously developed algorithms by the authors are used for the high-level planner and short-term COLAV, while we in this paper further develop the mid-level algorithm to make it comply with COLREGs rules 13–17. This includes developing a state machine for classifying obstacle vessels using a combination of the geometrical situation, the distance and time to the closest point of approach (CPA) and a new CPA-like measure. The performance of the hybrid COLAV system is tested through numerical simulations for three scenarios representing a range of different challenges, including multi-obstacle situations with multiple simultaneously active COLREGs rules, and also obstacles ignoring the COLREGs. The COLAV system avoids collision in all the scenarios, and follows the energy-optimized trajectory when the obstacles do not interfere with it.},
  archive      = {J_FROBT},
  author       = {Eriksen, Bjørn-Olav H. and Bitar, Glenn and Breivik, Morten and Lekkas, Anastasios M.},
  doi          = {10.3389/frobt.2020.00011},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {475020},
  shortjournal = {Front. Robot. AI},
  title        = {Hybrid collision avoidance for ASVs compliant with COLREGs rules 8 and 13–17},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A perspective on innovating the chemistry lab bench.
<em>FROBT</em>, <em>7</em>, 474177. (<a
href="https://doi.org/10.3389/frobt.2020.00024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Innovating on the design and function of the chemical bench remains a quintessential challenge of the ages. It requires a deep understanding of the important role chemistry plays in scientific discovery as well a first principles approach to addressing the gaps in how work gets done at the bench. This perspective examines how one might explore designing and creating a sustainable new standard for advancing automated chemistry bench itself. We propose how this might be done by leveraging recent advances in laboratory automation whereby integrating the latest synthetic, analytical and information technologies, and AI/ML algorithms within a standardized framework, maximizes the value of the data generated and the broader utility of such systems. Although the context of this perspective focuses on the design of advancing molecule of potential therapeutic value, it would not be a stretch to contemplate how such systems could be applied to other applied disciplines like advanced materials, foodstuffs, or agricultural product development.},
  archive      = {J_FROBT},
  author       = {Godfrey, Alexander G. and Michael, Samuel G. and Sittampalam, Gurusingham Sitta and Zahoránszky-Köhalmi, Gergely},
  doi          = {10.3389/frobt.2020.00024},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {474177},
  shortjournal = {Front. Robot. AI},
  title        = {A perspective on innovating the chemistry lab bench},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Synchronized tactile stimulation on upper limbs using a
wearable robot for gait assistance in patients with parkinson’s disease.
<em>FROBT</em>, <em>7</em>, 463707. (<a
href="https://doi.org/10.3389/frobt.2020.00010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aimed to investigate whether using a wearable robot applying interactive rhythmic stimulation on the upper limbs of patients with Parkinson&#39;s disease (PD) could affect their gait. The wearable robot presented tactile stimuli on the patients&#39; upper limbs, which was mutually synchronized with the swing of their upper limbs. We conducted an evaluation experiment with PD patients (n = 30, Modified Hoehn-Yahr = 1–3, on-state) to investigate the assistance effect by the robot and the immediate after-effect of intervention. The participants were instructed to walk 30 m under four different conditions: (1) not wearing the robot before the intervention (Pre-condition), (2) wearing the robot without the rhythm assistance (RwoA condition), (3) wearing the robot with rhythm assistance (RwA condition), and (4) not wearing the robot immediately after the intervention (Post-condition). These conditions were conducted in this order over a single day. The third condition was performed three times and the others, once. The arm swing amplitude, stride length, and velocity were increased in the RwA condition compared to the RwoA condition. The coefficient of variance (CV) of the stride duration was decreased in the RwA condition compared to the RwoA condition. These results revealed that the assistance by the robot increased the gait performance of PD patients. In addition, the stride length and velocity were increased and the stride duration CV was decreased in the Post-condition compared to the Pre-condition. These results show that the effect of robot assistance on the patient&#39;s gait remained immediately after the intervention. These findings suggest that synchronized rhythmic stimulation on the upper limbs could influence the gait of PD patients and that the robot may assist with gait rehabilitation in these patients.},
  archive      = {J_FROBT},
  author       = {Kishi, Takayuki and Ogata, Taiki and Ora, Hiroki and Shigeyama, Ryo and Nakayama, Masayuki and Seki, Masatoshi and Orimo, Satoshi and Miyake, Yoshihiro},
  doi          = {10.3389/frobt.2020.00010},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {463707},
  shortjournal = {Front. Robot. AI},
  title        = {Synchronized tactile stimulation on upper limbs using a wearable robot for gait assistance in patients with parkinson&#39;s disease},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Let’s push things forward: A survey on robot pushing.
<em>FROBT</em>, <em>7</em>, 456522. (<a
href="https://doi.org/10.3389/frobt.2020.00008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As robots make their way out of factories into human environments, outer space, and beyond, they require the skill to manipulate their environment in multifarious, unforeseeable circumstances. With this regard, pushing is an essential motion primitive that dramatically extends a robot&#39;s manipulation repertoire. In this work, we review the robotic pushing literature. While focusing on work concerned with predicting the motion of pushed objects, we also cover relevant applications of pushing for planning and control. Beginning with analytical approaches, under which we also subsume physics engines, we then proceed to discuss work on learning models from data. In doing so, we dedicate a separate section to deep learning approaches which have seen a recent upsurge in the literature. Concluding remarks and further research perspectives are given at the end of the paper.},
  archive      = {J_FROBT},
  author       = {Stüber, Jochen and Zito, Claudio and Stolkin, Rustam},
  doi          = {10.3389/frobt.2020.00008},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {456522},
  shortjournal = {Front. Robot. AI},
  title        = {Let&#39;s push things forward: A survey on robot pushing},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Designing ethical social robots—a longitudinal field study
with older adults. <em>FROBT</em>, <em>7</em>, 484969. (<a
href="https://doi.org/10.3389/frobt.2020.00001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotional deception and emotional attachment are regarded as ethical concerns in human-robot interaction. Considering these concerns is essential, particularly as little is known about longitudinal effects of interactions with social robots. We ran a longitudinal user study with older adults in two retirement villages, where people interacted with a robot in a didactic setting for eight sessions over a period of 4 weeks. The robot would show either non-emotive or emotive behavior during these interactions in order to investigate emotional deception. Questionnaires were given to investigate participants&#39; acceptance of the robot, perception of the social interactions with the robot and attachment to the robot. Results show that the robot&#39;s behavior did not seem to influence participants&#39; acceptance of the robot, perception of the interaction or attachment to the robot. Time did not appear to influence participants&#39; level of attachment to the robot, which ranged from low to medium. The perceived ease of using the robot significantly increased over time. These findings indicate that a robot showing emotions—and perhaps resulting in users being deceived—in a didactic setting may not by default negatively influence participants&#39; acceptance and perception of the robot, and that older adults may not become distressed if the robot would break or be taken away from them, as attachment to the robot in this didactic setting was not high. However, more research is required as there may be other factors influencing these ethical concerns, and support through other measurements than questionnaires is required to be able to draw conclusions regarding these concerns.},
  archive      = {J_FROBT},
  author       = {van Maris, Anouk and Zook, Nancy and Caleb-Solly, Praminda and Studley, Matthew and Winfield, Alan and Dogramadzi, Sanja},
  doi          = {10.3389/frobt.2020.00001},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {484969},
  shortjournal = {Front. Robot. AI},
  title        = {Designing ethical social Robots—A longitudinal field study with older adults},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Virtual reality is sexist: But it does not have to be.
<em>FROBT</em>, <em>7</em>, 476417. (<a
href="https://doi.org/10.3389/frobt.2020.00004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this study was to assess what drives gender-based differences in the experience of cybersickness within virtual environments. In general, those who have studied cybersickness (i.e., motion sickness associated with virtual reality [VR] exposure), oftentimes report that females are more susceptible than males. As there are many individual factors that could contribute to gender differences, understanding the biggest drivers could help point to solutions. Two experiments were conducted in which males and females were exposed for 20 min to a virtual rollercoaster. In the first experiment, individual factors that may contribute to cybersickness were assessed via self-report, body measurements, and surveys. Cybersickness was measured via the simulator sickness questionnaire and physiological sensor data. Interpupillary distance (IPD) non-fit was found to be the primary driver of gender differences in cybersickness, with motion sickness susceptibility identified as a secondary driver. Females whose IPD could not be properly fit to the VR headset and had a high motion sickness history suffered the most cybersickness and did not fully recover within 1 h post exposure. A follow-on experiment demonstrated that when females could properly fit their IPD to the VR headset, they experienced cybersickness in a manner similar to males, with high cybersickness immediately upon cessation of VR exposure but recovery within 1 h post exposure. Taken together, the results suggest that gender differences in cybersickness may be largely contingent on whether or not the VR display can be fit to the IPD of the user; with a substantially greater proportion of females unable to achieve a good fit. VR displays may need to be redesigned to have a wider IPD adjustable range in order to reduce cybersickness rates, especially among females.},
  archive      = {J_FROBT},
  author       = {Stanney, Kay and Fidopiastis, Cali and Foster, Linda},
  doi          = {10.3389/frobt.2020.00004},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {476417},
  shortjournal = {Front. Robot. AI},
  title        = {Virtual reality is sexist: But it does not have to be},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Marine applications of the fast marching method.
<em>FROBT</em>, <em>7</em>, 470076. (<a
href="https://doi.org/10.3389/frobt.2020.00002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Path planning is general problem of mobile robots, which has special characteristics when applied to marine applications. In addition to avoid colliding with obstacles, in marine scenarios, environment conditions such as water currents or wind need to be taken into account in the path planning process. In this paper, several solutions based on the Fast Marching Method are proposed. The basic method focus on collision avoidance and optimal planning and, later on, using the same underlying method, the influence of marine currents in the optimal path planning is detailed. Finally, the application of these methods to consider marine robot formations is presented.},
  archive      = {J_FROBT},
  author       = {Garrido, Santiago and Alvarez, David and Moreno, Luis E.},
  doi          = {10.3389/frobt.2020.00002},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {470076},
  shortjournal = {Front. Robot. AI},
  title        = {Marine applications of the fast marching method},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Underwater robotics competitions: The european robotics
league emergency robots experience with FeelHippo AUV. <em>FROBT</em>,
<em>7</em>, 467732. (<a
href="https://doi.org/10.3389/frobt.2020.00003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater robots are nowadays employed for many different applications; during the last decades, a wide variety of robotic vehicles have been developed by both companies and research institutes, different in shape, size, navigation system, and payload. While the market needs to constitute the real benchmark for commercial vehicles, novel approaches developed during research projects represent the standard for academia and research bodies. An interesting opportunity for the performance comparison of autonomous vehicles lies in robotics competitions, which serve as an useful testbed for state-of-the-art underwater technologies and a chance for the constructive evaluation of strengths and weaknesses of the participating platforms. In this framework, over the last few years, the Department of Industrial Engineering of the University of Florence participated in multiple robotics competitions, employing different vehicles. In particular, in September 2017 the team from the University of Florence took part in the European Robotics League Emergency Robots competition held in Piombino (Italy) using FeelHippo AUV, a compact and lightweight Autonomous Underwater Vehicle (AUV). Despite its size, FeelHippo AUV possesses a complete navigation system, able to offer good navigation accuracy, and diverse payload acquisition and analysis capabilities. This paper reports the main field results obtained by the team during the competition, with the aim of showing how it is possible to achieve satisfying performance (in terms of both navigation precision and payload data acquisition and processing) even with small-size vehicles such as FeelHippo AUV.},
  archive      = {J_FROBT},
  author       = {Franchi, Matteo and Fanelli, Francesco and Bianchi, Matteo and Ridolfi, Alessandro and Allotta, Benedetto},
  doi          = {10.3389/frobt.2020.00003},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {467732},
  shortjournal = {Front. Robot. AI},
  title        = {Underwater robotics competitions: The european robotics league emergency robots experience with FeelHippo AUV},
  volume       = {7},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptive prior selection for repertoire-based online
adaptation in robotics. <em>FROBT</em>, <em>6</em>, 506891. (<a
href="https://doi.org/10.3389/frobt.2019.00151">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Repertoire-based learning is a data-efficient adaptation approach based on a two-step process in which (1) a large and diverse set of policies is learned in simulation, and (2) a planning or learning algorithm chooses the most appropriate policies according to the current situation (e.g., a damaged robot, a new object, etc.). In this paper, we relax the assumption of previous works that a single repertoire is enough for adaptation. Instead, we generate repertoires for many different situations (e.g., with a missing leg, on different floors, etc.) and let our algorithm selects the most useful prior. Our main contribution is an algorithm, APROL (Adaptive Prior selection for Repertoire-based Online Learning) to plan the next action by incorporating these priors when the robot has no information about the current situation. We evaluate APROL on two simulated tasks: (1) pushing unknown objects of various shapes and sizes with a robotic arm and (2) a goal reaching task with a damaged hexapod robot. We compare with “Reset-free Trial and Error” (RTE) and various single repertoire-based baselines. The results show that APROL solves both the tasks in less interaction time than the baselines. Additionally, we demonstrate APROL on a real, damaged hexapod that quickly learns to pick compensatory policies to reach a goal by avoiding obstacles in the path.},
  archive      = {J_FROBT},
  author       = {Kaushik, Rituraj and Desreumaux, Pierre and Mouret, Jean-Baptiste},
  doi          = {10.3389/frobt.2019.00151},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {506891},
  shortjournal = {Front. Robot. AI},
  title        = {Adaptive prior selection for repertoire-based online adaptation in robotics},
  volume       = {6},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Electrically-driven soft fluidic actuators combining
stretchable pumps with thin McKibben muscles. <em>FROBT</em>,
<em>6</em>, 504552. (<a
href="https://doi.org/10.3389/frobt.2019.00146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft wearable robots could provide support for lower and upper limbs, increase weight lifting ability, decrease energy required for walking and running, and even provide haptic feedback. However, to date most of wearable robots are based on electromagnetic motors or fluidic actuators, the former being rigid and bulky, the latter requiring external pumps or compressors, greatly limiting integration and portability. Here we describe a new class of electrically-driven soft fluidic muscles combining thin, fiber-like McKibben actuators with fully Stretchable Pumps. These pumps rely on ElectroHydroDynamics, a solid-state pumping mechanism that directly accelerates liquid molecules by means of an electric field. Requiring no moving parts, these pumps are silent and can be bent and stretched while operating. Each electrically-driven fluidic muscle consists of one Stretchable Pump and one thin McKibben actuator, resulting in a slender soft device weighing 2 g. We characterized the response of these devices, obtaining a blocked force of 0.84 N and a maximum stroke of 4 mm. Future work will focus on decreasing the response time and increasing the energy efficiency. Modular and straightforward to integrate in textiles, these electrically-driven fluidic muscles will enable soft smart clothing with multi-functional capabilities for human assistance and augmentation.},
  archive      = {J_FROBT},
  author       = {Cacucciolo, Vito and Nabae, Hiroyuki and Suzumori, Koichi and Shea, Herbert},
  doi          = {10.3389/frobt.2019.00146},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {504552},
  shortjournal = {Front. Robot. AI},
  title        = {Electrically-driven soft fluidic actuators combining stretchable pumps with thin McKibben muscles},
  volume       = {6},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robot-supported collaborative learning (RSCL): Social robots
as teaching assistants for higher education small group facilitation.
<em>FROBT</em>, <em>6</em>, 501372. (<a
href="https://doi.org/10.3389/frobt.2019.00148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Acknowledging the benefits of active learning and the importance of collaboration skills, the higher education system has started to transform toward utilization of group activities into lecture hall culture. In this study, a novel interaction has been introduced, wherein a social robot facilitated a small collaborative group activity of students in higher education. Thirty-six students completed a 3 h activity that covered the main content of a course in Human Computer Interaction. In this within-subject study, the students worked in groups of four on three activities, moving between three conditions: instructor facilitation of several groups using pen and paper for the activity; tablets facilitation, also used for the activity; and robot facilitation, using tablets for the activity. The robot facilitated the activity by introducing the different tasks, ensuring proper time management, and encouraging discussion among the students. This study examined the effects of facilitation type on attitudes toward the activity facilitation, the group activity, and the robot, using quantitative, and qualitative measures. Overall students perceived the robot positively, as friendly and responsive, even though the robot did not directly respond to the students&#39; verbal communications. While most survey items did not convey significant differences between the robot, tablet, or instructor, we found significant correlations between perceptions of the robot, and attitudes toward the activity facilitation, and the group activity. Qualitative data revealed the drawbacks and benefits of the robot, as well as its relative perceived advantages over a human facilitator, such as better time management, objectivity, and efficiency. These results suggest that the robot&#39;s complementary characteristics enable a higher quality learning environment, that corresponds with students&#39; requirements and that a Robot Supportive Collaborative Learning (RSCL) is a promising novel paradigm for higher education.},
  archive      = {J_FROBT},
  author       = {Rosenberg-Kima, Rinat B. and Koren, Yaacov and Gordon, Goren},
  doi          = {10.3389/frobt.2019.00148},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {501372},
  shortjournal = {Front. Robot. AI},
  title        = {Robot-supported collaborative learning (RSCL): Social robots as teaching assistants for higher education small group facilitation},
  volume       = {6},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Radiological mapping of post-disaster nuclear environments
using fixed-wing unmanned aerial systems: A study from chornobyl.
<em>FROBT</em>, <em>6</em>, 498995. (<a
href="https://doi.org/10.3389/frobt.2019.00149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the immediate aftermath following a large-scale release of radioactive material into the environment, it is necessary to determine the spatial distribution of radioactivity quickly. At present, this is conducted by utilizing manned aircraft equipped with large-volume radiation detection systems. Whilst these are capable of mapping large areas quickly, they suffer from a low spatial resolution due to the operating altitude of the aircraft. They are also expensive to deploy and their manned nature means that the operators are still at risk of exposure to potentially harmful ionizing radiation. Previous studies have identified the feasibility of utilizing unmanned aerial systems (UASs) in monitoring radiation in post-disaster environments. However, the majority of these systems suffer from a limited range or are too heavy to be easily integrated into regulatory restrictions that exist on the deployment of UASs worldwide. This study presents a new radiation mapping UAS based on a lightweight (8 kg) fixed-wing unmanned aircraft and tests its suitability to mapping post-disaster radiation in the Chornobyl Exclusion Zone (CEZ). The system is capable of continuous flight for more than 1 h and can resolve small scale changes in dose-rate in high resolution (sub-20 m). It is envisaged that with some minor development, these systems could be utilized to map large areas of hazardous land without exposing a single operator to a harmful dose of ionizing radiation.},
  archive      = {J_FROBT},
  author       = {Connor, Dean T. and Wood, Kieran and Martin, Peter G. and Goren, Sevda and Megson-Smith, David and Verbelen, Yannick and Chyzhevskyi, Igor and Kirieiev, Serhii and Smith, Nick T. and Richardson, Tom and Scott, Thomas B.},
  doi          = {10.3389/frobt.2019.00149},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {498995},
  shortjournal = {Front. Robot. AI},
  title        = {Radiological mapping of post-disaster nuclear environments using fixed-wing unmanned aerial systems: A study from chornobyl},
  volume       = {6},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Self-assembled 3D actuator using the resilience of an
elastomeric material. <em>FROBT</em>, <em>6</em>, 498457. (<a
href="https://doi.org/10.3389/frobt.2019.00152">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-folding technologies have been studied by many researchers for applications to various engineering fields. Most of the self-folding methods that use the physical properties of materials require complex preparation, and usually take time to complete. In order to solve these problems, we focus on the elasticity of a material, and propose a model for forming a 3D structure using its characteristics. Our proposed model achieves high-speed and high-precision self-folding with a simple structure, by attaching rigid frames to a stretchable elastomer. The self-folded structure is applied to introduce a self-assembled actuator by exploiting a dielectric elastomer actuator (DEA). We develop the self-assembled actuator driven with the voltage application by attaching stretchable electrodes on the both side of the elastomer. We attempt several experiments to investigate the basic characteristics of the actuator. We also propose an application of the self-assembled actuator as a gripper based on the experimental results. The gripper has three joints with the angle of 120°, and successfully grabs objects by switching the voltage.},
  archive      = {J_FROBT},
  author       = {Hashimoto, Naoki and Shigemune, Hiroki and Minaminosono, Ayato and Maeda, Shingo and Sawada, Hideyuki},
  doi          = {10.3389/frobt.2019.00152},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {498457},
  shortjournal = {Front. Robot. AI},
  title        = {Self-assembled 3D actuator using the resilience of an elastomeric material},
  volume       = {6},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modeling and design optimization of a rotational soft
robotic system driven by double cone dielectric elastomer actuators.
<em>FROBT</em>, <em>6</em>, 494721. (<a
href="https://doi.org/10.3389/frobt.2019.00150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dielectric elastomers (DEs) consist of highly compliant electrostatic transducers which can be operated as actuators, by converting an applied high voltage into motion, and as sensors, since capacitive changes can be related to displacement information. Due to large achievable deformation (on the order of 100%) and high flexibility, DEs appear as highly suitable for the design of soft robotic systems. An important requirement for robotic systems is the possibility of generating a multi degree-of-freedom (MDOF) actuation. By means of DE technology, a controllable motion along several directions can be made possible by combining different membrane actuators in protagonist-antagonist configurations, as well as by designing electrode patterns which allow independent activation of different sections of a single membrane. However, despite several concepts of DE soft robots have been presented in the recent literature, up to date there is still a lack of systematic studies targeted at optimizing the design of the system. To properly understand how different parameters influence the complex motion of DE soft robots, this paper presents an experimental study on how geometry scaling affects the performance of a specific MDOF actuator configuration. The system under investigation consists of two cone DE membranes rigidly connected along the outer diameter, and pre-compressed out-of-plane against each other via a rigid spacer. The electrodes of both membranes are partitioned in four sections that can be activated separately, thus allowing the desired MDOF actuation feature. Different prototypes are assembled and tested to study the influence of the inner radius as well as the length of the rigid spacer on the achievable motion range. For the first experimental study presented here, we focus our analysis on a single actuation variable, i.e., the rotation of the rigid spacer about a fixed axis. A physics-based model is then developed and validated based on the collected experimental measurements. A model-based investigation is subsequently performed, with the aim of studying the influence of the regarded parameters on the rotation angle. Finally, based on the results of the performed study, a model-based optimization of the prototype geometry is performed.},
  archive      = {J_FROBT},
  author       = {Nalbach, Sophie and Banda, Rukmini Manoz and Croce, Sipontina and Rizzello, Gianluca and Naso, David and Seelecke, Stefan},
  doi          = {10.3389/frobt.2019.00150},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {494721},
  shortjournal = {Front. Robot. AI},
  title        = {Modeling and design optimization of a rotational soft robotic system driven by double cone dielectric elastomer actuators},
  volume       = {6},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust understanding of robot-directed speech commands using
sequence to sequence with noise injection. <em>FROBT</em>, <em>6</em>,
487230. (<a href="https://doi.org/10.3389/frobt.2019.00144">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper describes a new method that enables a service robot to understand spoken commands in a robust manner using off-the-shelf automatic speech recognition (ASR) systems and an encoder-decoder neural network with noise injection. In numerous instances, the understanding of spoken commands in the area of service robotics is modeled as a mapping of speech signals to a sequence of commands that can be understood and performed by a robot. In a conventional approach, speech signals are recognized, and semantic parsing is applied to infer the command sequence from the utterance. However, if errors occur during the process of speech recognition, a conventional semantic parsing method cannot be appropriately applied because most natural language processing methods do not recognize such errors. We propose the use of encoder-decoder neural networks, e.g., sequence to sequence, with noise injection. The noise is injected into phoneme sequences during the training phase of encoder-decoder neural network-based semantic parsing systems. We demonstrate that the use of neural networks with a noise injection can mitigate the negative effects of speech recognition errors in understanding robot-directed speech commands i.e., increase the performance of semantic parsing. We implemented the method and evaluated it using the commands given during a general purpose service robot (GPSR) task, such as a task applied in RoboCup@Home, which is a standard service robot competition for the testing of service robots. The results of the experiment show that the proposed method, namely, sequence to sequence with noise injection (Seq2Seq-NI), outperforms the baseline methods. In addition, Seq2Seq-NI enables a robot to understand a spoken command even when the speech recognition by an off-the-shelf ASR system contains recognition errors. Moreover, in this paper we describe an experiment conducted to evaluate the influence of the injected noise and provide a discussion of the results.},
  archive      = {J_FROBT},
  author       = {Tada, Yuuki and Hagiwara, Yoshinobu and Tanaka, Hiroki and Taniguchi, Tadahiro},
  doi          = {10.3389/frobt.2019.00144},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {487230},
  shortjournal = {Front. Robot. AI},
  title        = {Robust understanding of robot-directed speech commands using sequence to sequence with noise injection},
  volume       = {6},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evaluation of a virtual reality percutaneous nephrolithotomy
(PCNL) surgical simulator. <em>FROBT</em>, <em>6</em>, 486021. (<a
href="https://doi.org/10.3389/frobt.2019.00145">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Percutaneous Nephrolithotomy is the standard surgical procedure used to remove large kidney stones. PCNL procedures have a steep learning curve; a physician needs to complete between 36 and 60 procedures, to achieve clinical proficiency. Marion Surgical K181 is a virtual reality surgical simulator, which emulates the PCNL procedures without compromising the well-being of patients. The simulator uses a VR headset to place a user in a realistic and immersive operating theater, and haptic force-feedback robots to render physical interactions between surgical tools and the virtual patient. The simulator has two modules for two different aspects of PCNL kidney stone removal procedure: kidney access module where the user must insert a needle into the kidney of the patient, and a kidney stone removal module where the user removes the individual stones from the organ. In this paper, we present user trials to validate the face and construct validity of the simulator. The results, based on the data gathered from 4 groups of users independently, indicate that Marion&#39;s surgical simulator is a useful tool for teaching and practicing PCNL procedures. The kidney stone removal module of the simulator has proven construct validity by identifying the skill level of different users based on their tool path. We plan to continue evaluating the simulator with a larger sample of users to reinforce our findings.},
  archive      = {J_FROBT},
  author       = {Sainsbury, Ben and Łącki, Maciej and Shahait, Mohammed and Goldenberg, Mitchell and Baghdadi, Amir and Cavuoto, Lora and Ren, Jing and Green, Mark and Lee, Jason and Averch, Timothy D. and Rossa, Carlos},
  doi          = {10.3389/frobt.2019.00145},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {486021},
  shortjournal = {Front. Robot. AI},
  title        = {Evaluation of a virtual reality percutaneous nephrolithotomy (PCNL) surgical simulator},
  volume       = {6},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). System to evaluate the skill of operating hydraulic
excavators using a remote controlled excavator and virtual reality.
<em>FROBT</em>, <em>6</em>, 485765. (<a
href="https://doi.org/10.3389/frobt.2019.00142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We developed a system to evaluate the skill of operating a hydraulic excavator. The system employs a remotely controlled (RC) excavator and virtual reality (VR) technology. We remodeled the RC excavator so that it can be operated in the same manner as a real excavator and proceeded to measure the excavator&#39;s state. To evaluate the skill of operating this system, we calculated several indices from the data recorded during excavation work and compared the indices obtained for expert and non-expert operators. The results revealed that it is possible to distinguish whether an expert or non-expert is operating the RC excavator. We calculated the same indices from the data recorded during excavation with a real excavator and verified that there exists a high correlation between the indices of the RC excavator and those of the real excavator. Thus, we confirmed that the indices of the real excavator and those of the simulator exhibited similar trends. This suggests that it is possible to partly evaluate the operation characteristics of a real excavator by using an RC excavator with different dynamics compared with a real excavator.},
  archive      = {J_FROBT},
  author       = {Sekizuka, Ryota and Ito, Masaru and Saiki, Seiji and Yamazaki, Yoichiro and Kurita, Yuichi},
  doi          = {10.3389/frobt.2019.00142},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {485765},
  shortjournal = {Front. Robot. AI},
  title        = {System to evaluate the skill of operating hydraulic excavators using a remote controlled excavator and virtual reality},
  volume       = {6},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hands in the real world. <em>FROBT</em>, <em>6</em>, 480351.
(<a href="https://doi.org/10.3389/frobt.2019.00147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots face a rapidly expanding range of potential applications beyond controlled environments, from remote exploration and search-and-rescue to household assistance and agriculture. The focus of physical interaction is typically delegated to end-effectors—fixtures, grippers or hands—as these machines perform manual tasks. Yet, effective deployment of versatile robot hands in the real world is still limited to few examples, despite decades of dedicated research. In this paper we review hands that found application in the field, aiming to discuss open challenges with more articulated designs, discussing novel trends and perspectives. We hope to encourage swift development of capable robotic hands for long-term use in varied real world settings. The first part of the paper centers around progress in artificial hand design, identifying key functions for a variety of environments. The final part focuses on the overall trends in hand mechanics, sensors and control, and how performance and resiliency are qualified for real world deployment.},
  archive      = {J_FROBT},
  author       = {Negrello, Francesca and Stuart, Hannah S. and Catalano, Manuel G.},
  doi          = {10.3389/frobt.2019.00147},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {480351},
  shortjournal = {Front. Robot. AI},
  title        = {Hands in the real world},
  volume       = {6},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Exploring novel biologically-relevant chemical space through
artificial intelligence: The NCATS ASPIRE program. <em>FROBT</em>,
<em>6</em>, 471946. (<a
href="https://doi.org/10.3389/frobt.2019.00143">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, artificial intelligence (AI)/machine learning (ML; a subset of AI) have become increasingly important to the biomedical research community. These technologies, coupled to big data and cheminformatics, have tremendous potential to improve the design of novel therapeutics and to provide safe and effective drugs to patients. A National Center for Advancing Translational Sciences (NCATS) program called A Specialized Platform for Innovative Research Exploration (ASPIRE) leverages advances in AI/ML, automated synthetic chemistry, and high-throughput biology, and seeks to enable translation and drug development by catalyzing exploration of biologically active chemical space. Here we discuss the opportunities and challenges surrounding the application of AI/ML to the exploration of novel biologically relevant chemical space as part of ASPIRE.},
  archive      = {J_FROBT},
  author       = {Duncan, Katharine K. and Rudnicki, Dobrila D. and Austin, Christopher P. and Tagle, Danilo A.},
  doi          = {10.3389/frobt.2019.00143},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {471946},
  shortjournal = {Front. Robot. AI},
  title        = {Exploring novel biologically-relevant chemical space through artificial intelligence: The NCATS ASPIRE program},
  volume       = {6},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). CLASH—a compliant sensorized hand for handling delicate
objects. <em>FROBT</em>, <em>6</em>, 468772. (<a
href="https://doi.org/10.3389/frobt.2019.00138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automation of logistic tasks, such as object picking and placing, is currently one of the most active areas of research in robotics. Handling delicate objects, such as fruits and vegetables, both in warehouses and in plantations, is a big challenge due to the delicacy and precision required for the task. This paper presents the CLASH hand, a Compliant Low-Cost Antagonistic Servo Hand, whose kinematics was specifically designed for handling groceries. The main feature of the hand is its variable stiffness, which allows it to withstand collisions with the environment and also to adapt the passive stiffness to the object weight while relying on a modular design using off-the-shelf low-cost components. Due to the implementation of differentially coupled flexors, the hand can be actuated like an underactuated hand but can also be driven with different stiffness levels to planned grasp poses, i.e., it can serve for both model-based grasp planning and for underactuated or model-free grasping. The hand also includes self-checking and logging processes, which enable more robust performance during grasping actions. This paper presents key aspects of the hand design, examines the robustness of the hand in impact tests, and uses a standardized fruit benchmarking test to verify the behavior of the hand when different actuator and sensor failures occur and are compensated for autonomously by the hand.},
  archive      = {J_FROBT},
  author       = {Friedl, Werner and Roa, Máximo A.},
  doi          = {10.3389/frobt.2019.00138},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {468772},
  shortjournal = {Front. Robot. AI},
  title        = {CLASH—A compliant sensorized hand for handling delicate objects},
  volume       = {6},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the illumination influence for object learning on robot
companions. <em>FROBT</em>, <em>6</em>, 467500. (<a
href="https://doi.org/10.3389/frobt.2019.00154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most collaborative tasks require interaction with everyday objects (e.g., utensils while cooking). Thus, robots must perceive everyday objects in an effective and efficient way. This highlights the necessity of understanding environmental factors and their impact on visual perception, such as illumination changes throughout the day on robotic systems in the real world. In object recognition, two of these factors are changes due to illumination of the scene and differences in the sensors capturing it. In this paper, we will present data augmentations for object recognition that enhance a deep learning architecture. We will show how simple linear and non-linear illumination models and feature concatenation can be used to improve deep learning-based approaches. The aim of this work is to allow for more realistic Human-Robot Interaction scenarios with a small amount of training data in combination with incremental interactive object learning. This will benefit the interaction with the robot to maximize object learning for long-term and location-independent learning in unshaped environments. With our model-based analysis, we showed that changes in illumination affect recognition approaches that use Deep Convolutional Neural Network to encode features for object recognition. Using data augmentation, we were able to show that such a system can be modified toward a more robust recognition without retraining the network. Additionally, we have shown that using simple brightness change models can help to improve the recognition across all training set sizes.},
  archive      = {J_FROBT},
  author       = {Keller, Ingo and Lohan, Katrin S.},
  doi          = {10.3389/frobt.2019.00154},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {467500},
  shortjournal = {Front. Robot. AI},
  title        = {On the illumination influence for object learning on robot companions},
  volume       = {6},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deployable, variable stiffness, cable driven robot for
minimally invasive surgery. <em>FROBT</em>, <em>6</em>, 464207. (<a
href="https://doi.org/10.3389/frobt.2019.00141">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Minimally Invasive Surgery (MIS) imposes a trade-off between non-invasive access and surgical capability. Treatment of early gastric cancers over 20 mm in diameter can be achieved by performing Endoscopic Submucosal Dissection (ESD) with a flexible endoscope; however, this procedure is technically challenging, suffers from extended operation times and requires extensive training. To facilitate the ESD procedure, we have created a deployable cable driven robot that increases the surgical capabilities of the flexible endoscope while attempting to minimize the impact on the access that they offer. Using a low-profile inflatable support structure in the shape of a hollow hexagonal prism, our robot can fold around the flexible endoscope and, when the target site has been reached, achieve a 73.16% increase in volume and increase its radial stiffness. A sheath around the variable stiffness structure delivers a series of force transmission cables that connect to two independent tubular end-effectors through which standard flexible endoscopic instruments can pass and be anchored. Using a simple control scheme based on the length of each cable, the pose of the two instruments can be controlled by haptic controllers in each hand of the user. The forces exerted by a single instrument were measured, and a maximum magnitude of 8.29 N observed along a single axis. The working channels and tip control of the flexible endoscope remain in use in conjunction with our robot and were used during a procedure imitating the demands of ESD was successfully carried out by a novice user. Not only does this robot facilitate difficult surgical techniques, but it can be easily customized and rapidly produced at low cost due to a programmatic design approach.},
  archive      = {J_FROBT},
  author       = {Runciman, Mark and Avery, James and Zhao, Ming and Darzi, Ara and Mylonas, George P.},
  doi          = {10.3389/frobt.2019.00141},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {464207},
  shortjournal = {Front. Robot. AI},
  title        = {Deployable, variable stiffness, cable driven robot for minimally invasive surgery},
  volume       = {6},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Symbolic, distributed, and distributional representations
for natural language processing in the era of deep learning: A survey.
<em>FROBT</em>, <em>6</em>, 458535. (<a
href="https://doi.org/10.3389/frobt.2019.00153">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural language is inherently a discrete symbolic representation of human knowledge. Recent advances in machine learning (ML) and in natural language processing (NLP) seem to contradict the above intuition: discrete symbols are fading away, erased by vectors or tensors called distributed and distributional representations. However, there is a strict link between distributed/distributional representations and discrete symbols, being the first an approximation of the second. A clearer understanding of the strict link between distributed/distributional representations and symbols may certainly lead to radically new deep learning networks. In this paper we make a survey that aims to renew the link between symbolic representations and distributed/distributional representations. This is the right time to revitalize the area of interpreting how discrete symbols are represented inside neural networks.},
  archive      = {J_FROBT},
  author       = {Ferrone, Lorenzo and Zanzotto, Fabio Massimo},
  doi          = {10.3389/frobt.2019.00153},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {458535},
  shortjournal = {Front. Robot. AI},
  title        = {Symbolic, distributed, and distributional representations for natural language processing in the era of deep learning: A survey},
  volume       = {6},
  year         = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
