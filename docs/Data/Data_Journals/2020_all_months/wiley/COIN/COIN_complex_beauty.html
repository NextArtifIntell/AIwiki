<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>COIN_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="coin---82">COIN - 82</h2>
<ul>
<li><details>
<summary>
(2020). Smart grid data access control scheme based on blockchain.
<em>COIN</em>, <em>36</em>(4), 1773–1784. (<a
href="https://doi.org/10.1111/coin.12385">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The smart grid communication parties need to process the data by the trusted central node, which will lead to security issues such as single-point attacks and data tampering. This paper proposes a smart grid data access control scheme based on blockchain, the user completes the registration of the smart meter by three encryptions. After the registration is completed, the registration information will be uploaded to the blockchain. In the data access phase, the verification center verifies the user&#39;s data access request, the database will accept the user&#39;s request for data if the verification is passed, and that will be broadcasted on the entire network and uploaded to the blockchain. The security of the scheme is analyzed by using a random oracle model. Analysis shows that this scheme can resist public key replacement attacks and malicious key generation center (KGC) attacks. Compared with the existing scheme, this scheme can more effectively resist more types of attacks. It shows that the smart grid data access control scheme proposed in this paper is safe, reliable and efficient.},
  archive      = {J_COIN},
  author       = {Lihua Zhang and Jingjing Li and Fangzhou Hu and Yang Huang and Jiayi Bai},
  doi          = {10.1111/coin.12385},
  journal      = {Computational Intelligence},
  month        = {11},
  number       = {4},
  pages        = {1773-1784},
  shortjournal = {Comput. Intell.},
  title        = {Smart grid data access control scheme based on blockchain},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Traffic wave model based on vehicle-infrastructure
cooperative and vehicle communication data. <em>COIN</em>,
<em>36</em>(4), 1755–1772. (<a
href="https://doi.org/10.1111/coin.12346">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Urban trunk road system undertakes the main traffic trip, and congestion occurs frequently in rush hours. In order to clearly describe the propagation process of traffic waves in signalized intersections, and then optimize phase difference. This article proposes a kinematic model for the traffic wave based on the physical mechanism of car-following and the kinematic characteristics of the traffic wave propagation. The actual road traffic monitoring data was extracted from the vehicle-infrastructure cooperative system and vehicle internal communication system. Then we obtained the values of the stop-and-start wave velocity. Compared with the measured data, the results showed that the calculation of the wave velocity of the traffic wave model had a relative error of up to 5% vs the measured data, confirming the validity of the model. Through the analysis of the model, we obtained the difference in the effects on traffic wave velocity of the vehicle speed and the space headway. Our findings provide a theoretical basis for coordinated control and management of urban trunk road traffic and phase difference optimization of signalized intersections. Meanwhile, the research results also provide a theoretical basis for alleviating traffic congestion during the rush hour.},
  archive      = {J_COIN},
  author       = {Huazhi Yuan and Hongjia Zhang and Xuelian Liu and Xinlong Jiao},
  doi          = {10.1111/coin.12346},
  journal      = {Computational Intelligence},
  month        = {11},
  number       = {4},
  pages        = {1755-1772},
  shortjournal = {Comput. Intell.},
  title        = {Traffic wave model based on vehicle-infrastructure cooperative and vehicle communication data},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Internet of things assisted condition-based support for
smart manufacturing industry using learning technique. <em>COIN</em>,
<em>36</em>(4), 1737–1754. (<a
href="https://doi.org/10.1111/coin.12319">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, countless industrial IIoT contraptions and sensors are conveyed a sharp plant to gather tremendous information regarding system conditions and a computerized bodily framework for handling industrial plant&#39;s mist point of convergence by using keen assembling projects. By then, the system utilizes an array of condition-based support model (CBM) procedures to predict when devices begin to unusually work and to keep them up or supplant their fragments ahead of time to avoid assembling colossal investigator items in smart manufacturing industries. CBM experiences problems of floating ideas (ie, conveying examples of deficiencies can change extra time) and information of lop-sidedness (ie, information with issues represents a minority of all things considered). The condition-based support assisted learning technique by the group that coordinates the assorted variety of numerous classifiers provides an elite response to address these issues. Therefore, in this work the proposed work classifies offline three-organized CBM with floats of ideas and awkwardness data, using an improved Dynamic AdaBoost for preparing a group classifier and an enhanced linear four rates (LFR) methodology is used by the classifier of nominal and continuous (NC) with synthetic minority oversampling technique (SMOTE) method to tackle inconsistent information in recognizing concept floats in lop-sidedness information. The investigational results scheduled datasets by varying notches anomaly demonstration that the future strategy has a high degree of accuracy in the identifiable evidence of minority knowledge, which is over 96%.},
  archive      = {J_COIN},
  author       = {Jing Li and Hai Tao and Liu Shuhong and Sinan Q. Salih and Jasni Mohamad Zain and Liu Yankun and G. N. Vivekananda and M. Thanjaivadel},
  doi          = {10.1111/coin.12319},
  journal      = {Computational Intelligence},
  month        = {11},
  number       = {4},
  pages        = {1737-1754},
  shortjournal = {Comput. Intell.},
  title        = {Internet of things assisted condition-based support for smart manufacturing industry using learning technique},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A computational method based on gustafson-kessel fuzzy
clustering for a novel islanding detection for grid connected devices
and sensors. <em>COIN</em>, <em>36</em>(4), 1723–1736. (<a
href="https://doi.org/10.1111/coin.12311">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy Clustering-based (G-K) Gustafson-Kessel is used to create the fuzzy rule-based classifier in a grid connected photovoltaic (PV) system where it is tested using specific features in a grid connected PV inverter for detecting islanding condition. It is detected when harmonic content of voltages at the Point of Common Coupling and inverter increases beyond a threshold value. If islanding is not detected, distribution lines are rendered unsafe. The present study uses G-K fuzzy clustering to categorize islanding and nonislanding incidents. Two features based on Total Harmonic Distortion are extracted and used as inputs for the G-K fuzzy clustering classifier. The proposed technique is tested using nonlinear loads and its performance is verified by simulation using MATLAB Simulink. A hardware test set-up is developed to validate the proposed antiislanding technique and the results obtained are discussed.},
  archive      = {J_COIN},
  author       = {B. Ponmudi and G. Balasubramanian},
  doi          = {10.1111/coin.12311},
  journal      = {Computational Intelligence},
  month        = {11},
  number       = {4},
  pages        = {1723-1736},
  shortjournal = {Comput. Intell.},
  title        = {A computational method based on gustafson-kessel fuzzy clustering for a novel islanding detection for grid connected devices and sensors},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sequence recommendation based on deep learning.
<em>COIN</em>, <em>36</em>(4), 1704–1722. (<a
href="https://doi.org/10.1111/coin.12307">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to solve the cold start problem of traditional recommendation algorithm, the sequence change of user interaction information and deep learning are gradually considered as a key feature of commodity recommendation system. However, most of the existing recommendation methods based on the sequence changes assume that all the interaction information of users is equally important for recommendation, which is not always applicable in real scenarios, because the interaction process of user items is full of randomness and contingency. In this article, we study how to reduce the randomness and contingency between session sequences, make full use of the association between session sequences in the interaction process of users by Deep Learning. In order to better simulate the change of session sequence in the real scene, we adopt sequence sampling methods to transform the single classification problem into sequence modeling problem. And attention mechanism is added to reduce the interference of the recommendation model in the sequence due to the contingency and randomness of the user in the shopping. Finally, through the verification of real data, the MRR@20 index of the improved model is 20% higher than the benchmark level.},
  archive      = {J_COIN},
  author       = {Dong Guo and Chuantao Wang},
  doi          = {10.1111/coin.12307},
  journal      = {Computational Intelligence},
  month        = {11},
  number       = {4},
  pages        = {1704-1722},
  shortjournal = {Comput. Intell.},
  title        = {Sequence recommendation based on deep learning},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Knowledge mapping of supply chain risk research based on
CiteSpace. <em>COIN</em>, <em>36</em>(4), 1686–1703. (<a
href="https://doi.org/10.1111/coin.12306">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supply chain risk is a relatively new research field, and research results have been published in journals, and in master and doctoral articles. In this article, we first performed a quantitative analysis of existing literature on supply chain risk indexed in Web of Science (WOS). Then, we analyzed the author, institution, keywords, research hotspot, and cocited literature of existing publications in the research field of supply chain risk by using CiteSpace. The aim of this study is to investigate the trend, geographical distribution, author distribution, research field, keywords, keyword clustering, and other features of scientific articles on supply chain risk published in global journals, using the most advanced bibliometric analysis tools. The results of this study can be used to determine the most influential research institutions and authors in the research field of supply chain risk, as well as the research hotspots in different periods, and different research directions in this field.},
  archive      = {J_COIN},
  author       = {Ling Sun and Xu Xu and Yanbin Yang and Wei Liu and Jiahao Jin},
  doi          = {10.1111/coin.12306},
  journal      = {Computational Intelligence},
  month        = {11},
  number       = {4},
  pages        = {1686-1703},
  shortjournal = {Comput. Intell.},
  title        = {Knowledge mapping of supply chain risk research based on CiteSpace},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Lossless data transmission for internet of things
application over wireless multimedia sensor networks using enhanced and
optimal path scheduling approach to maximizing the quality of service.
<em>COIN</em>, <em>36</em>(4), 1672–1685. (<a
href="https://doi.org/10.1111/coin.12305">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The congestion of packet forwarding between a source and destination is challenging on downlink transmission in the entire file (ex. Audio and Video). Whenever file is been uploaded to the server, a user requests for file where server transmits it without knowledge of user&#39;s bandwidth, which is a major, cause of packet loss or time duration in the receiver end. To accumulate the better solution, Enhanced and Optimal Path Scheduling Approach (EOPSA) designs to find optimal path scheduling for multimedia data transmission in multimedia sensor network over cloud server using IoT devices. EOPSA studied the multisource video-on-demand streaming in multimedia sensor networks. The method introduced a heuristic distributed protocol to find optimal route for multimedia data transmissions. Efficient way to identify the bandwidth before the transmission ensures link establishment between sender and receiver. Here, the capture of bandwidth helps to check user&#39;s system capability to forward requested media data. Based on experiment evaluation, EOPSA improves 0.20 packet delivery ratio, 130 throughput, 0.20 second average delay and 14 communication overhead for 15, 25, 50, 75, and 100 nodes compared than conventional methods.},
  archive      = {J_COIN},
  author       = {Abdulrahman S. Alqahtani},
  doi          = {10.1111/coin.12305},
  journal      = {Computational Intelligence},
  month        = {11},
  number       = {4},
  pages        = {1672-1685},
  shortjournal = {Comput. Intell.},
  title        = {Lossless data transmission for internet of things application over wireless multimedia sensor networks using enhanced and optimal path scheduling approach to maximizing the quality of service},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Study on the algorithm for smart community sensor network
routing with adaptive optimization via cluster head election.
<em>COIN</em>, <em>36</em>(4), 1663–1671. (<a
href="https://doi.org/10.1111/coin.12304">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To reduce the uneven energy consumption for the data transmission and extend network life of intelligent community sensor network, an adaptive routing optimized algorithm for intelligent community sensor networks with cluster head election is proposed. In this algorithm, a three-dimensional clustering method adapted to the structure of intelligent community sensor network is proposed. The three-dimensional clustering method uses the cluster head election mechanism based on minimizing the total transmission loss to optimize the energy of the intelligent community sensor network. Second, an adaptive ant colony propagation method is proposed to solve the problem of intercluster data propagation after clustering. With the best path finding algorithm of ant colony algorithm, energy balance routing with lower energy loss and lower packet error rate is proposed. Finally, the simulation results show that the algorithm has better performance in reducing energy consumption and delay, improving transmission efficiency and node survival time.},
  archive      = {J_COIN},
  author       = {He Yongqiang},
  doi          = {10.1111/coin.12304},
  journal      = {Computational Intelligence},
  month        = {11},
  number       = {4},
  pages        = {1663-1671},
  shortjournal = {Comput. Intell.},
  title        = {Study on the algorithm for smart community sensor network routing with adaptive optimization via cluster head election},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Web service composition on IoT reliability test based on
cross entropy. <em>COIN</em>, <em>36</em>(4), 1650–1662. (<a
href="https://doi.org/10.1111/coin.12302">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Web service has developed the managed IoT application to let connected devices easily and securely interact with cloud applications and other devices. As an important factor for web service, the reliability of web services refers to the probability of web service running success. For modeling web service composition, we should abstract the process of web service composition. Due to the diversity and complexity of web service composition, it is unlikely to do exhaustive testing. In order to improve the quality of web service composition test cases and find out which path leads to the greatest probability of service combination failure, heuristic test case generation method is adopted to obtain the optimal test path. First, the web service composition test is abstracted into the MDP model. The QoS of the web service composition is taken as the software test optimization goal, and the cross-entropy strategy is used to optimize the test case. The experimental results show that the test profile given by the cross-strategy is better than the random test strategy. Detect and exclude the same number of software defects. Cross-entropy strategy can significantly reduce the number of test cases, reduce test costs, and improve defect detection efficiency.},
  archive      = {J_COIN},
  author       = {Yang Song and Yun-Zhan Gong},
  doi          = {10.1111/coin.12302},
  journal      = {Computational Intelligence},
  month        = {11},
  number       = {4},
  pages        = {1650-1662},
  shortjournal = {Comput. Intell.},
  title        = {Web service composition on IoT reliability test based on cross entropy},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Integrated kitchen design and optimization based on the
improved particle swarm intelligent algorithm. <em>COIN</em>,
<em>36</em>(4), 1638–1649. (<a
href="https://doi.org/10.1111/coin.12301">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The layout and design of the integrated kitchen can affect the efficiency of people&#39;s cooking work greatly. An excellent integrated kitchen design requires each kitchen cabinet module to meet certain constraints and reach the highest work efficiency in a certain space. In this article, we proposed an improved particle swarm intelligence algorithm (IPSO, for short) method by initializing the population chaos, dynamically improving the inertia weight and adjusting the acceleration factor, and applied in the kitchen design and optimization. This method combines the mathematical intelligent algorithm with the integrated kitchen design for the first time, and further selects the optimal design scheme from the preliminary schemes according to the fitness curve of the kitchen mathematical model, which provides the theoretical basis for the refined design of kitchen products. The method can also be used in home design, interior design, and other related areas.},
  archive      = {J_COIN},
  author       = {Xin Sun and Xiaomin Ji},
  doi          = {10.1111/coin.12301},
  journal      = {Computational Intelligence},
  month        = {11},
  number       = {4},
  pages        = {1638-1649},
  shortjournal = {Comput. Intell.},
  title        = {Integrated kitchen design and optimization based on the improved particle swarm intelligent algorithm},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Parallel genetic algorithm for n-queens problem based on
message passing interface-compute unified device architecture.
<em>COIN</em>, <em>36</em>(4), 1621–1637. (<a
href="https://doi.org/10.1111/coin.12300">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {N-Queens problem derives three variants: obtaining a specific solution, obtaining a set of solutions and obtaining all solutions. The purpose of the variant I is to find a constructive solution, which has been solved. Variant III is aiming to find all solutions and the largest number of queens currently being resolved is 26. Variant II whose purpose is to obtain a set of solutions for larger-scale problems relies on various intelligent algorithms. In this paper, we use a master-slave model genetic algorithm that combines the idea of the evolutionary algorithm and simulated annealing algorithm to solve Variant III, and use a parallel fitness function based on compute unified device architecture. Experimental results show that our scheme achieved a maximum 60-fold speedup over the single-CPU counterpart. On this basis, a two-level parallel genetic algorithm based on the island model and master-slave model is implemented on the GPU cluster by using message passing interface technology. Using two-node and three-node GPU cluster, speedup of 1.46 and 2.01 are obtained on average over single-node, respectively. Compared with the sequential genetic algorithm, the two-level parallel genetic algorithm makes full use of the parallel computing power of GPU cluster in solving N-Queen variant II and improves the performance by 99.19 times in the best case.},
  archive      = {J_COIN},
  author       = {Cao Jianli and Chen Zhikui and Wang Yuxin and Guo He},
  doi          = {10.1111/coin.12300},
  journal      = {Computational Intelligence},
  month        = {11},
  number       = {4},
  pages        = {1621-1637},
  shortjournal = {Comput. Intell.},
  title        = {Parallel genetic algorithm for N-queens problem based on message passing interface-compute unified device architecture},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Research on the clustering algorithm of ocean big data based
on self-organizing neural network. <em>COIN</em>, <em>36</em>(4),
1609–1620. (<a href="https://doi.org/10.1111/coin.12299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the construction of a smart marine, marine big data mining has a significant impact on the growing maritime industry in the Beibu Gulf. Clustering is the key technology of marine big data mining, but the conventional clustering algorithm cannot achieve the efficient clustering of marine data. According to the characteristics of marine big data, a marine big data clustering scheme based on self-organizing neural network (SOM) algorithm is proposed. First, the working principle of SOM algorithm is analyzed, and the algorithm&#39;s two-dimensional network model, similarity model and competitive learning model are focused. Secondly, combining with the working principle of algorithm, the marine big data clustering process and algorithm achievement based on SOM algorithm are developed; finally, experiments show that all vectors in marine big data clustering are stable, and the neurons in the output layer of clustering result have obvious consistency with the data itself, which shows the effectiveness of SOM algorithm in marine big data clustering.},
  archive      = {J_COIN},
  author       = {Yongyi Li and Zhongqiang Yang and Kaixu Han},
  doi          = {10.1111/coin.12299},
  journal      = {Computational Intelligence},
  month        = {11},
  number       = {4},
  pages        = {1609-1620},
  shortjournal = {Comput. Intell.},
  title        = {Research on the clustering algorithm of ocean big data based on self-organizing neural network},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Energy-efficient routing technique for reliable data
transmission under the background of big data for disaster region.
<em>COIN</em>, <em>36</em>(4), 1593–1608. (<a
href="https://doi.org/10.1111/coin.12294">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Big data analysis and cloud computing are gaining much interest in various applications including disaster management. One of the major difficulties in the process of exchanging environmental data in the disaster affected areas has been considered as one of the emerging areas of research. This research focuses on maintaining the environmental data information management of the disaster affected areas, where the intermediate node has been used to transmit the information during transmission and an optimized routing has been used to create efficient data transmission, such as temperature, pressure, humidity, and the level of pollution within the network. The intermediate node may also be hacked during data processing. In this article, the efficient big data-based clustering technique has been proposed. In this research, the information is grouped into a cluster in every comparable node and the energy consumption has been efficiently managed with the hybrid metaheuristic optimization-based effective routing technique. The system excellence has been evaluated using the energy utilization factor, packet delivery ratio, and attack-free routing effectiveness metrics to handle environmental information on disaster affected areas.},
  archive      = {J_COIN},
  author       = {Xiaobo Peng and Yanfen Chang},
  doi          = {10.1111/coin.12294},
  journal      = {Computational Intelligence},
  month        = {11},
  number       = {4},
  pages        = {1593-1608},
  shortjournal = {Comput. Intell.},
  title        = {Energy-efficient routing technique for reliable data transmission under the background of big data for disaster region},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Security challenges in internet of things: Distributed
denial of service attack detection using support vector machine-based
expert systems. <em>COIN</em>, <em>36</em>(4), 1580–1592. (<a
href="https://doi.org/10.1111/coin.12293">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of internet of things (IoT) is to be the next generation of the IoT devices are a simple target for attackers due to the lack of security. Attackers can easily hack the IoT devices that can be used to form botnets, which can be used to launch distributed denial of service (DDoS) attack against networks. Botnets are the most dangerous threat to the security systems. Software-defined networking (SDN) is one of the developing filed, which introduce the capacity of dynamic program to the network. Use the flexibility and multidimensional characteristics of SDN used to prevent DDoS attacks. The DDoS attack is the major attack to the network, which makes the entire network down, so that normal users might not avail the services from the server. In this article, we proposed the DDoS attack detection model based on SDN environment by combining support vector machine classification algorithm is used to collect flow table values in sampling time periods. From the flow table values, the five-tuple characteristic values extracted and based on it the DDoS attack can be detected. Based on the experimental results, we found the average accuracy rate is 96.23% with a normal amount of traffic flow. Proposed research offers a better DDoS detection rate on SDN.},
  archive      = {J_COIN},
  author       = {Azath Mubarakali and Karthik Srinivasan and Reham Mukhalid and Subash C. B. Jaganathan and Ninoslav Marina},
  doi          = {10.1111/coin.12293},
  journal      = {Computational Intelligence},
  month        = {11},
  number       = {4},
  pages        = {1580-1592},
  shortjournal = {Comput. Intell.},
  title        = {Security challenges in internet of things: Distributed denial of service attack detection using support vector machine-based expert systems},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). L1 norm based pedestrian detection using video analytics
technique. <em>COIN</em>, <em>36</em>(4), 1569–1579. (<a
href="https://doi.org/10.1111/coin.12292">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pedestrian detection from images of the visible spectrum is a high relevant area of research given its potential impact in the design of pedestrian protection systems. In general, detection is made with two different phases, feature extraction and classification. Also, features for detection of pedestrian are already are available such as optimal feature model. But still required is an improvement in detection by reducing the execution time and false positive. The proposed model has three different phases, that is, background subtraction, feature extraction, and classification. In spite of giving entire information into feature extraction, the system gives only a useful information (foreground image) by twin background model. Then the foreground image moves to the feature extraction and classifies the pedestrian. For feature extraction, histogram of orientation gradient (HOG) L 1 normalization has been used. This will increase the detection accuracy and reduce the computation time of a process. In addition, false positive rate has been minimized.},
  archive      = {J_COIN},
  author       = {Anandamurugan Selvaraj and Jeeva Selvaraj and Sivabalakrishnan Maruthaiappan and Gokulnath Chandra Babu and Priyan Malarvizhi Kumar},
  doi          = {10.1111/coin.12292},
  journal      = {Computational Intelligence},
  month        = {11},
  number       = {4},
  pages        = {1569-1579},
  shortjournal = {Comput. Intell.},
  title        = {L1 norm based pedestrian detection using video analytics technique},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Neural network prediction of bioleaching of metals from
waste computer printed circuit boards using levenberg-marquardt
algorithm. <em>COIN</em>, <em>36</em>(4), 1548–1568. (<a
href="https://doi.org/10.1111/coin.12288">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The applicability of artificial neural network (ANN) to predict the bioleaching of metals using from computer printed circuit boards (CPCB) and the influence of process parameters were studied. The influence of process parameters initial pH (1.6-2.4), pulp density (2%-13%), and the initial volume of Inoculum (5%-25%) were investigated on the rate of bioleaching of metals from CPCB. Network inputs were fed as initial pH, pulp density, and inoculum volume and with the extraction of Cu, Ag, and Au as output. The ANN was developed using the Levenberg-Marquardt algorithm and trained for modeling and prediction. The most fitting architectures for Cu, Ag, and Au were [4-5-5-2-1], [4-7-5-2-1], [4-7-1-1-1] trained with Levenberg-Marquardt algorithm, respectively. The R values were observed to be 0.996, 0.997, and 0.993 for Cu, Ag, and Au extraction predictions, respectively. The genetic algorithm model defined by ANN was used to achieve maximum extraction rates for Cu, Au, and Ag. The predicted data showed that there is a great capability of using ANN for the prediction of Cu, Ag, and Au extraction from CPCB through bioleaching process. Hence, the ANN model can be used to control the operational conditions for improved metals extraction through bioleaching.},
  archive      = {J_COIN},
  author       = {Mohan Annamalai and Kalaichelvan Gurumurthy},
  doi          = {10.1111/coin.12288},
  journal      = {Computational Intelligence},
  month        = {11},
  number       = {4},
  pages        = {1548-1568},
  shortjournal = {Comput. Intell.},
  title        = {Neural network prediction of bioleaching of metals from waste computer printed circuit boards using levenberg-marquardt algorithm},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improving quality-of-service in fog computing through
efficient resource allocation. <em>COIN</em>, <em>36</em>(4), 1527–1547.
(<a href="https://doi.org/10.1111/coin.12285">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today&#39;s world, large group migration of applications to the fog computing is registered in the information technology world. The main issue in fog computing is providing enhanced quality of service (QoS). QoS management consists of various method used for allocating fog-user applications in the virtual environment and selecting suitable method for allocating virtual resources to physical resource. The resources allocation in effective manner in the fog environment is also a major problem in fog computing; it occurs when the infrastructure is build using light-weight computing devices. In this article, the allocation of task and placement of virtual machine problems is explained in the single fog computing environment. The experiment is done and the result shows that the proposed framework improves QoS in fog environment.},
  archive      = {J_COIN},
  author       = {Sathish Kumar Mani and Iyapparaja Meenakshisundaram},
  doi          = {10.1111/coin.12285},
  journal      = {Computational Intelligence},
  month        = {11},
  number       = {4},
  pages        = {1527-1547},
  shortjournal = {Comput. Intell.},
  title        = {Improving quality-of-service in fog computing through efficient resource allocation},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A computing method-based rearrangement of network protocols
to improvise quality factors of FACTS devices and sensors using
newton-raphson technique. <em>COIN</em>, <em>36</em>(4), 1512–1526. (<a
href="https://doi.org/10.1111/coin.12284">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The load flow analysis project was carried out using the Newton-Raphson&#39;s iteration technique and a multiobjective method was suggested to minimize power loss, increase bus voltage, reduce operating costs, and controlling the flexible AC transmission system (FACTS) controllers. The key focus is to improvise the load sustainability subjected to controlling of system safety, integrity, and stability margins within specified limits by acquiring optimum place, installation expenses for FACTS controllers. It is important to analyze the benefits and architect the FACTS devices for the power steady state analysis. For effective modeling, the five bus standard is analyzed without the FACTS end devices and with the FACTS controllers. Transient voltage is critical which requires accurate and quick response to avoid the voltage collapse and instability issues. The Newton-Raphson&#39;s method of load flow analysis is an iterative method which approximates the set of nonlinear simultaneous load flow equations to a set of linear simultaneous load flow equations using Taylor&#39;s series expansion and the terms are limited to first order approximation. The variations in voltage are within 5% for a well designated power system. If it exceeds the specified limit then the performance of equipment will be poor and the life of equipment will reduce. Hence the voltage control is very important to improvise the quality factor of the FACTS controllers and devices in power system. The voltage variations in a bus or node are related to reactive power. If the reactive power is injected to a bus is less than reactive power drawn from the FACTS devices, the voltage instability becomes infinite issue causes damage to the controllers and devices. In a load flow problem, two quantities are specified for each bus and the remaining quantities are obtained by the load flow equation analysis using Newton-Raphson method. This method has been tested for IEEE 30 bus system and then the values are compared and analyzed with MATLAB.},
  archive      = {J_COIN},
  author       = {V. Sundaravazhuthi and A. Alli Rani and M. Manoj Kumar},
  doi          = {10.1111/coin.12284},
  journal      = {Computational Intelligence},
  month        = {11},
  number       = {4},
  pages        = {1512-1526},
  shortjournal = {Comput. Intell.},
  title        = {A computing method-based rearrangement of network protocols to improvise quality factors of FACTS devices and sensors using newton-raphson technique},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A computational algorithm based on biogeography-based
optimization method for computing power system security constrains with
multi FACTS devices. <em>COIN</em>, <em>36</em>(4), 1493–1511. (<a
href="https://doi.org/10.1111/coin.12282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A major role is played by the analysis of power system security in heightening system security and in system collapse condition avoidance. This article presents a cutting edge mechanism which is devised applying transmission line loadings as well as variance in bus voltage magnitude. The use of flexible alternating current transmission systems devices improves the objectives of generation fuel charges in addition to the severity index proposed which were investigated considering the contingency circumstances of generator(s) or/and transmission channel(s). To boost system security in spite of contingency circumstances in the existence of unified power flow controller or UPFC, it would be most appropriate to pinpoint a most advantageous position to install aforementioned device. We propose a model of UPFC where power insertion is done by using voltage source. Also a procedure to incorporate the same and a strategy to find optimum position has been proposed which uses line overload sensitivity indices. This work mainly focused on establishment of available transfer capability on the heavily congested line. The proposed congestion management scheme alleviates the heavy stress in transmission line and provides an ample corridor for the power to flow. Biogeography-based optimization or BBO in short, is a technique which is a growing recognized optimization method which has been lucratively engaged in solving intricate optimization problem in dissimilar fields. The BBO provides better results than the metaheuristic counter parts such as Genetic Algorithm and Particle Swarm Optimization. The effectiveness of proposed BBO has been tested on standard IEEE 30 bus system and the results are compared with classic methods and other metaheuristic methods. This is established through the MATLAB package. Improved bus voltage profile was also attained and it can be inferred from the outcome that the prospective approach can drastically enhance security of power system when comparing with other optimization methods.},
  archive      = {J_COIN},
  author       = {M. Manoj Kumar and A. Alli Rani and V. Sundaravazhuthi},
  doi          = {10.1111/coin.12282},
  journal      = {Computational Intelligence},
  month        = {11},
  number       = {4},
  pages        = {1493-1511},
  shortjournal = {Comput. Intell.},
  title        = {A computational algorithm based on biogeography-based optimization method for computing power system security constrains with multi FACTS devices},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Feature selection and classification using support vector
machine and decision tree. <em>COIN</em>, <em>36</em>(4), 1480–1492. (<a
href="https://doi.org/10.1111/coin.12280">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer is one of the human threats which cause morbidity and mortality worldwide. The death rate can be reduced by advanced diagnosis. The objective of this article is to select the reduced number of features the help in diagnosing breast cancer in Wisconsin Diagnostic Breast Cancer (WDBC). This proposed model depicts women who all have no cancer cells or in benign stage later develop into malignant (metastases). Due to the dynamic nature of the big data framework, the proposed method ensures high confidence and low execution time. Moreover, healthcare information growth chases an exponential pattern, and current database systems cannot adequately manage the massive amount of data. So, it is requisite to adopt the “big data” solution for healthcare information.},
  archive      = {J_COIN},
  author       = {B. Durgalakshmi and V. Vijayakumar},
  doi          = {10.1111/coin.12280},
  journal      = {Computational Intelligence},
  month        = {11},
  number       = {4},
  pages        = {1480-1492},
  shortjournal = {Comput. Intell.},
  title        = {Feature selection and classification using support vector machine and decision tree},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Intelligent document-filling system on mobile devices by
document classification and electronization. <em>COIN</em>,
<em>36</em>(4), 1463–1479. (<a
href="https://doi.org/10.1111/coin.12279">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Both of an automatic classification method for original documents based on image feature and a layout analysis method based on rule hypothesis tree are proposed. Then an intelligent document-filling system by electronizing the original documents, which can be applied to cellphones and pads is designed. When users are filling documents online, information can be automatically input to the financial information system merely by taking photos of the original documents. By this means can not only save time but also ensure the accuracy between the data online and that on the original documents. Experiments show that the accuracy of document classification is 88.38%, the accuracy of document-filling is 87.22%, and it takes 5.042 seconds dealing with per document. The system can be applied to financial, government, libraries, electric power, enterprises and many other industries, which has high economic and application value.},
  archive      = {J_COIN},
  author       = {Jing Lu and Shihong Wu and Zhiyu Xiang and Hanlei Cheng},
  doi          = {10.1111/coin.12279},
  journal      = {Computational Intelligence},
  month        = {11},
  number       = {4},
  pages        = {1463-1479},
  shortjournal = {Comput. Intell.},
  title        = {Intelligent document-filling system on mobile devices by document classification and electronization},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Forest optimization algorithm-based feature selection using
classifier ensemble. <em>COIN</em>, <em>36</em>(4), 1445–1462. (<a
href="https://doi.org/10.1111/coin.12265">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Features selection is the process of choosing the relevant subset of features from the high-dimensional dataset to enhance the performance of the classifier. Much research has been carried out in the present world for the process of feature selection. Algorithms such as Naïve Bayes (NB), decision tree, and genetic algorithm are applied to the high-dimensional dataset to select the relevant features and also to increase the computational speed. The proposed model presents a solution for selection of features using ensemble classifier algorithms. The proposed algorithm is the combination of minimum redundancy and maximum relevance (mRMR) and forest optimization algorithm (FOA). Ensemble-based algorithms such as support vector machine (SVM), K-nearest neighbor (KNN), and NB is further used to enhance the performance of the classifier algorithm. The mRMR-FOA is used to select the relevant features from the various datasets and 21% to 24% improvement is recorded in the feature selection. The ensemble classifier algorithms further improves the performance of the algorithm and provides accuracy of 96%.},
  archive      = {J_COIN},
  author       = {Usha Moorthy and Usha Devi Gandhi},
  doi          = {10.1111/coin.12265},
  journal      = {Computational Intelligence},
  month        = {11},
  number       = {4},
  pages        = {1445-1462},
  shortjournal = {Comput. Intell.},
  title        = {Forest optimization algorithm-based feature selection using classifier ensemble},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Conditional preference networks with user’s genuine
decisions. <em>COIN</em>, <em>36</em>(3), 1414–1442. (<a
href="https://doi.org/10.1111/coin.12386">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User&#39;s choices involve habitual behavior and genuine decision. Habitual behavior is often expressed using preferences. In a multiattribute case, the Conditional Preference Network (CP-net) is a graphical model to represent user&#39;s conditional ceteris paribus (all else being equal) preference statements. Indeed, the CP-net induces a strict partial order over the outcomes. By contrast, we argue that genuine decisions are environmentally influenced and introduce the notion of “comfort” to represent this type of choices. In this article, we propose an extension of the CP-net model that we call the CP-net with Comfort (CPC-net) to represent a user&#39;s comfort with preferences. Given that preference and comfort might be two conflicting objectives, we define the Pareto optimality of outcomes when achieving outcome optimization with respect to a given CPC-net. Then, we propose a backtrack search algorithm to find the Pareto optimal outcomes. On the other hand, two outcomes can stand in one of six possible relations with respect to a CPC-net. The exact relation can be obtained by performing dominance testing in the corresponding CP-net and comparing the numeric comforts.},
  archive      = {J_COIN},
  author       = {Sultan Ahmed and Malek Mouhoub},
  doi          = {10.1111/coin.12386},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1414-1442},
  shortjournal = {Comput. Intell.},
  title        = {Conditional preference networks with user&#39;s genuine decisions},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Intelligent forecasting of time series based on evolving
distributed neuro-fuzzy network. <em>COIN</em>, <em>36</em>(3),
1394–1413. (<a href="https://doi.org/10.1111/coin.12383">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An evolving methodology based on Neuro-Fuzzy Takagi-Sugeno network (NF-TS) for distributed forecasting of univariate time series, is proposed. First, the unobservable components, or hidden patterns, are extracted from experimental data of the time series. Then, a distributed forecasting is performed separately for each component, considering an evolving NF-TS associated with each extracted pattern. The evolving NF-TS uses components data to adapt and adjust its structure, as the number of fuzzy rules increases or decreases according the behavior of the unobservable components. A recursive version of singular spectral analysis (SSA) technique is formulated, as one of the main contributions of this article, and it is applied to extract the components. The efficiency of proposed methodology is illustrated from results of comparison to others state-of-the-art techniques for forecasting of various univariate time series.},
  archive      = {J_COIN},
  author       = {Selmo Eduardo Rodrigues Júnior and Ginalber Luiz de Oliveira Serra},
  doi          = {10.1111/coin.12383},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1394-1413},
  shortjournal = {Comput. Intell.},
  title        = {Intelligent forecasting of time series based on evolving distributed neuro-fuzzy network},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fault diagnosis in wireless sensor network using negative
selection algorithm and support vector machine. <em>COIN</em>,
<em>36</em>(3), 1374–1393. (<a
href="https://doi.org/10.1111/coin.12380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, an improved negative selection algorithm (INSA) has been proposed to identify faulty sensor nodes in wireless sensor network (WSN) and then the faults are classified into soft permanent, soft intermittent, and soft transient fault using the support vector machine technique. The performance metrics such as fault detection accuracy, false alarm rate, false positive rate, diagnosis latency (DL), energy consumption, fault classification accuracy (FCA), and false classification rate (FCR) are used to evaluate the performance of the proposed INSA. The simulation result shows that the INSA gives better result as compared to the existing algorithms in terms of performance metrics. The fault classification performance is measured by FCA and FCR. It has also seen that the proposed algorithm gives less DL and consumes less energy than that of existing algorithms proposed by Mohapatra et al, Zhang et al, and Panda et al for WSN.},
  archive      = {J_COIN},
  author       = {Santoshinee Mohapatra and Pabitra Mohan Khilar},
  doi          = {10.1111/coin.12380},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1374-1393},
  shortjournal = {Comput. Intell.},
  title        = {Fault diagnosis in wireless sensor network using negative selection algorithm and support vector machine},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Research on personalized recommendation hybrid algorithm for
interactive experience equipment. <em>COIN</em>, <em>36</em>(3),
1348–1373. (<a href="https://doi.org/10.1111/coin.12375">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interactive calligraphy experience equipment has the characteristics of a large amount of data, various types, and strong homogeneity, which makes it difficult for users to find interesting resources. In this article, a hybrid personalized recommendation algorithm is proposed, which uses collaborative filtering and content-based recommendation methods in turn to make recommendations. In the initial recommendation, Latent Dirichlet Allocation (LDA) topic model is used to reduce the dimension of high-dimensional user behavior data and establish a user-writing theme matrix to reduce inaccurate recommendation caused by high sparsity data in collaborative filtering algorithm. The user interest list is obtained by calculating the similarity between users. Then, on the basis of the preliminary recommendation results, VGG16 model is used to extract the feature vector of the calligraphy image and calculate the similarity between the user&#39;s calligraphy words and the primary recommended calligraphy words, thus obtaining the final recommendation results. The experimental results verify the effectiveness and accuracy of the recommendation algorithm, which are better than other recommendation algorithms on the whole, and have important engineering guiding significance.},
  archive      = {J_COIN},
  author       = {Shuai Chen and Ling Huang and Zhiwen Lei and Shen Wang},
  doi          = {10.1111/coin.12375},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1348-1373},
  shortjournal = {Comput. Intell.},
  title        = {Research on personalized recommendation hybrid algorithm for interactive experience equipment},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Capacitated single-allocation hub location model for a flood
relief distribution network. <em>COIN</em>, <em>36</em>(3), 1320–1347.
(<a href="https://doi.org/10.1111/coin.12374">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In disaster management, the logistics for disaster relief must deal with uncontrolled variables, including transportation difficulties, limited resources, and demand variations. In this work, an optimization model based on the capacitated single-allocation hub location problem is proposed to determine an optimal location of flood relief facilities with the advantage of economies of scale to transport commodities during a disaster. The objective is to minimize the total transportation cost, which depends on the flood severity. The travel time is bounded to ensure that survival packages will be delivered to victims in a reasonable time. Owing to complexity of the problem, a hybrid algorithm is developed based on a variable neighborhood search and tabu search (VNS-TS). The computational results show that the VNS found the optimal solutions within a 2% gap, while the proposed VNS-TS found the optimal solution with a 0% gap. A case study of severe flooding in Thailand is presented with consideration of related parameters such as water level, hub capacity, and discount factors. Sensitivity analyses on the number of flows, discount factors, capacity, and bound length are provided. The results indicated that demand variation has an impact on the transportation cost, number of hubs, and route patterns.},
  archive      = {J_COIN},
  author       = {Ornurai Sangsawang and Sunarin Chanta},
  doi          = {10.1111/coin.12374},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1320-1347},
  shortjournal = {Comput. Intell.},
  title        = {Capacitated single-allocation hub location model for a flood relief distribution network},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A robust similarity based deep siamese convolutional neural
network for gait recognition across views. <em>COIN</em>,
<em>36</em>(3), 1290–1319. (<a
href="https://doi.org/10.1111/coin.12361">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gait recognition has been considered as the emerging biometric technology for identifying the walking behaviors of humans. The major challenges addressed in this article is significant variation caused by covariate factors such as clothing, carrying conditions and view angle variations will undesirably affect the recognition performance of gait. In recent years, deep learning technique has produced a phenomenal performance accuracy on various challenging problems based on classification. Due to an enormous amount of data in the real world, convolutional neural network will approximate complex nonlinear functions in models to develop a generalized deep convolutional neural network (DCNN) architecture for gait recognition. DCNN can handle relatively large multiview datasets with or without using any data augmentation and fine-tuning techniques. This article proposes a color-mapped contour gait image as gait feature for addressing the variations caused by the cofactors and gait recognition across views. We have also compared the various edge detection algorithms for gait template generation and chosen the best from among them. The databases considered for our work includes the most widely used CASIA-B dataset and OULP database. Our experiments show significant improvement in the gait recognition for fixed-view, crossview, and multiview compared with the recent methodologies.},
  archive      = {J_COIN},
  author       = {Merlin Linda George and Themozhi Govindarajan and Kavitha Angamuthu Rajasekaran and Sudheer Reddy Bandi},
  doi          = {10.1111/coin.12361},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1290-1319},
  shortjournal = {Comput. Intell.},
  title        = {A robust similarity based deep siamese convolutional neural network for gait recognition across views},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A robust image steganography using teaching learning based
optimization based edge detection model for smart cities. <em>COIN</em>,
<em>36</em>(3), 1275–1289. (<a
href="https://doi.org/10.1111/coin.12348">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Internet becomes a most common medium for transferring critical data and the security of the transmitted data gains maximum priority. Image steganography has been developed as a well-known model of data hiding which verifies the security level of the transferred data. The images offer high capacity, and the occurrence of accessibility over the Internet is more. An effective steganography model is required for achieving better embedding capacity and also maintaining the other variables in an acceptable value. This article introduces a new robust image steganography using Teaching Learning Based Optimization (TLBO) edge detection model. The TBLO is basically a metaheuristic algorithm which is inspired from the teaching and learning procedure in classrooms. The former stage indicates the learning from the teacher and the latter phase represents the interaction among the learners. The experimental validation takes place in a comprehensive way under several views and the outcome pointed out the superior results of the presented model.},
  archive      = {J_COIN},
  author       = {K. Dhanasekaran and P. Anandan and N. Kumaratharan},
  doi          = {10.1111/coin.12348},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1275-1289},
  shortjournal = {Comput. Intell.},
  title        = {A robust image steganography using teaching learning based optimization based edge detection model for smart cities},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improved gait recognition through gait energy image
partitioning. <em>COIN</em>, <em>36</em>(3), 1261–1274. (<a
href="https://doi.org/10.1111/coin.12340">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, human gait pattern has turned into an essential biometric feature to recognize an individual remotely. Gait as a feature becomes challenging owing to variation in appearance under different covariate conditions (eg, shoe, surface, haul, viewpoint and attire). The covariates may alter few fragment of gait while other fragment stay unaltered, leading to lower the probability of correct identification. To overcome such variation, an improved gait recognition strategy is proposed in this article by gait energy image partitioning and selection processing. Our method involves pre-processing of raw video for silhouette extraction, gait cycle detection, segmentation into different regions, and histogram of gradients feature extraction from selected segments. In this way, the specific features across complete gait cycles are extracted precisely. Finally, recognition is done by using K-NN. The proposed strategy has been assessed using the CASIA B gait database. Our outcomes shows a particular proposed strategy accomplishes high recognition rate and outperforms the advanced gait recognition mechanism.},
  archive      = {J_COIN},
  author       = {G. Premalatha and Premanand V Chandramani},
  doi          = {10.1111/coin.12340},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1261-1274},
  shortjournal = {Comput. Intell.},
  title        = {Improved gait recognition through gait energy image partitioning},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Water-body segmentation from satellite images using kapur’s
entropy-based thresholding method. <em>COIN</em>, <em>36</em>(3),
1242–1260. (<a href="https://doi.org/10.1111/coin.12339">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Water body segmentation helps in extracting water bodies like lake, pond, river, and reservoir from high resolution satellite images. This also helps in discovering new water bodies. But, extraction of water bodies from satellite images is much complicated, mainly due to the severe disparity in size, shape, and appearance of the water bodies. In this article, Kapur&#39;s entropy-based thresholding method is proposed for the segmentation of water bodies from Very High Resolution (VHR) satellite images. The dataset used in this article is AIRS (Aerial Imagery for Roof Segmentation) dataset, with VHR satellite images, from which only the images with water bodies are considered. Experimental results show that the proposed method yields better segmentation performance with an overall accuracy of 98.43% and Structural Similarity Index rate of 0.9712.},
  archive      = {J_COIN},
  author       = {A Aalan Babu and V Mary Anita Rajam},
  doi          = {10.1111/coin.12339},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1242-1260},
  shortjournal = {Comput. Intell.},
  title        = {Water-body segmentation from satellite images using kapur&#39;s entropy-based thresholding method},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bio-PUF-MAC authenticated encryption for iris biometrics.
<em>COIN</em>, <em>36</em>(3), 1221–1241. (<a
href="https://doi.org/10.1111/coin.12332">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biometrics is one of the ways for human authentication. Fabrication of biometrics by intruders, limits the accuracy of authentication. The user-specific keys (ie,) pseudo-random numbers give more security for biometric template protection and increase the accuracy of authentication also. The user-specific token or keys can also be fabricated by intruders by any of the prediction methods. To avoid the creation of fake biometric and fake user-specific keys, a device-specific Physical Unclonable Function (PUF) is proposed. In this article, iris authentication is provided by unclonable PUF-based true random numbers to enhance the unique authentication. Nonreversible Message Authentication Codes (MAC) are developed using PUF and Discrete Wavelet Transform features of iris biometrics. Systematically, MAC codes also created with, encryption algorithm. Encryption is additionally providing confidentiality in the individual iris. Experiments are done with CUHK Iris Image Dataset. Proposed Bio-PUF system has significant functional advantages in point of view of the unclonable pseudo-random number from PUF. Experimentally, Avalanche effect, entropy, NCPR, and UACI parameters are analyzed with PUF-based crypt functions. For 75% of matching with the Bio-PUF-MAC codes with enrolment, the accuracy for correct identification is 77.73%.},
  archive      = {J_COIN},
  author       = {Sivasankari Narasimhan and Muthukumar Arunachalam},
  doi          = {10.1111/coin.12332},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1221-1241},
  shortjournal = {Comput. Intell.},
  title        = {Bio-PUF-MAC authenticated encryption for iris biometrics},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A two-level authentication scheme for clone node detection
in smart cities using internet of things. <em>COIN</em>, <em>36</em>(3),
1200–1220. (<a href="https://doi.org/10.1111/coin.12330">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clone node attack in IoT sensor devices remains a grave security concern as it paves the way for sinkhole, wormhole, and selective forwarding attacks. In this paper, a two-level authentication scheme named Fingerprint-based Zero-Knowledge Authentication (FZKA) algorithm is proposed to improve the detection rate of clone node among the sensor devices. In the fingerprint generation phase, the base station calculates a distinct fingerprint value for each and every node in the network by gathering neighborhood information, represented in the form of superimposed s-disjunct code matrix. The calculated fingerprint is considered as a secret value and distributed to each cluster nodes for the process of authentication. The FZKA algorithm improves the cloned node detection accuracy with minimal detection time. The simulation results highlight the cloned node detection rate of the proposed scheme by a margin of 92.5% against the existing Exponential Smoothing Algorithm (ETS), Position Verification Method, and Message Verification and Passing algorithms.},
  archive      = {J_COIN},
  author       = {Anitha Shanmugam and Jayanthi Paramasivam},
  doi          = {10.1111/coin.12330},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1200-1220},
  shortjournal = {Comput. Intell.},
  title        = {A two-level authentication scheme for clone node detection in smart cities using internet of things},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Automatic traditional chinese painting classification: A
benchmarking analysis. <em>COIN</em>, <em>36</em>(3), 1183–1199. (<a
href="https://doi.org/10.1111/coin.12328">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the recent years, there is a growing trend toward digitization of cultural heritage for better accessibility and preservation. For instance, the development of image processing techniques in traditional Chinese painting (TCP) has begun to attract researchers&#39; attention in the computer vision field. TCP is one of the representative of Chinese traditional arts. Evidenced by the successes of development in image processing techniques in various applications, this article aim to apply the deep learning approach on TCP for several purposes, which include automatic establishment of unified image library, facilitating update-to-date data in the database, reduction of cost required for image classification and retrieval. First, a unified database is established, that consists of more than a thousand of images from six major TCP themes. Then, several deep learning algorithms that are based on mathematical models are applied to examine the classification performance. In addition, the salient regions that denote significant features are identified, by adopting the instance segmentation technique. As a result, the modified pretrained neural network is capable to achieve 99.66% recognition accuracy. Qualitative results are also presented to demonstrate the effectiveness of the proposed method. We also note that this is the first work that performs multiclass classification on six categories in this domain. Furthermore, a 10-class classification result of 96% is obtained when performing on one of the painting types, namely, ghost-and-god.},
  archive      = {J_COIN},
  author       = {Sze-Teng Liong and Yen-Chang Huang and Shumeng Li and Zhongkai Huang and Jingyang Ma and Yee Siang Gan},
  doi          = {10.1111/coin.12328},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1183-1199},
  shortjournal = {Comput. Intell.},
  title        = {Automatic traditional chinese painting classification: A benchmarking analysis},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Aspect category detection using statistical and semantic
association. <em>COIN</em>, <em>36</em>(3), 1161–1182. (<a
href="https://doi.org/10.1111/coin.12327">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect category detection (ACD) is an important subtask of aspect-based sentiment analysis (ABSA). It is a challenging problem due to subjectivity involved in categorization, as well as the existence of overlapping classes. Among various approaches that have been applied to ACD include rule-based approaches along with other machine learning approaches, and most of them are statistical in nature. In this article, we have used an association rule-based approach. To deal with the statistical limitation of association rules, we proposed a hybridized rule-based approach that combines association rules with the semantic association. For semantic associations, we have used the notion of word-embeddings. Experiments were performed on SemEval dataset, a standard benchmark dataset for aspect categorization in the restaurant domain. We observed that semantic associations can complement statistical association and improve the accuracy of classification. The proposed method performs better than several state-of-the-art methods.},
  archive      = {J_COIN},
  author       = {Ashish Kumar and Mayank Saini and Aditi Sharan},
  doi          = {10.1111/coin.12327},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1161-1182},
  shortjournal = {Comput. Intell.},
  title        = {Aspect category detection using statistical and semantic association},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Selecting effective features on prediction of delay in
servicing ships arriving to ports using a combination of clonal
selection and grey wolf optimization algorithms—case study: Shahid
rajaee port in bandar abbas. <em>COIN</em>, <em>36</em>(3), 1140–1160.
(<a href="https://doi.org/10.1111/coin.12323">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting the delay in servicing incoming ships to ports is crucial for maritime transportation. In this study, we use support vector regression (SVR) in order to accurately predict this delay for ships arriving to the terminal No. 1 of Shahid Rajaee&#39;s port in Bandar Abbas. To achieve this goal, a combination of Clonal Selection and Grey Wolf Optimization algorithms (named as CLOGWO) is used for two purposes: (i) selecting the most important features among the features that affect prediction of this delay and (ii) optimizing SVR parameters for a more accurate prediction. Performance of the proposed method was compared with Genetic Algorithm (GA), Clonal Selection (CS), Grey Wolf Optimization (GWO), and Particle Swarm Optimization (PSO) algorithms on the following metrics: correlation, rate of feature reduction, root mean square error (RMSE), and normalized RMSE (NRMSE). Evaluations on Shahid Rajaee dataset showed that the mean value of these metrics in 10 independent runs of the proposed method were 0.867, 74.45%, 0.080, and 9.02, respectively. These results and evaluations on standard datasets indicate that the proposed method provides competitive results with other evolutionary algorithms.},
  archive      = {J_COIN},
  author       = {Shahram Golzari and Mojtaba Shabani Haji and Abdullah Khalili},
  doi          = {10.1111/coin.12323},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1140-1160},
  shortjournal = {Comput. Intell.},
  title        = {Selecting effective features on prediction of delay in servicing ships arriving to ports using a combination of clonal selection and grey wolf optimization algorithms—Case study: Shahid rajaee port in bandar abbas},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A study of deep neural networks for human activity
recognition. <em>COIN</em>, <em>36</em>(3), 1113–1139. (<a
href="https://doi.org/10.1111/coin.12318">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human activity recognition and deep learning are two fields that have attracted attention in recent years. The former due to its relevance in many application domains, such as ambient assisted living or health monitoring, and the latter for its recent and excellent performance achievements in different domains of application such as image and speech recognition. In this article, an extensive analysis among the most suited deep learning architectures for activity recognition is conducted to compare its performance in terms of accuracy, speed, and memory requirements. In particular, convolutional neural networks (CNN), long short-term memory networks (LSTM), bidirectional LSTM (biLSTM), gated recurrent unit networks (GRU), and deep belief networks (DBN) have been tested on a total of 10 publicly available datasets, with different sensors, sets of activities, and sampling rates. All tests have been designed under a multimodal approach to take advantage of synchronized raw sensor&#39; signals. Results show that CNNs are efficient at capturing local temporal dependencies of activity signals, as well as at identifying correlations among sensors. Their performance in activity classification is comparable with, and in most cases better than, the performance of recurrent models. Their faster response and lower memory footprint make them the architecture of choice for wearable and IoT devices.},
  archive      = {J_COIN},
  author       = {Emilio Sansano and Raúl Montoliu and Óscar Belmonte Fernández},
  doi          = {10.1111/coin.12318},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1113-1139},
  shortjournal = {Comput. Intell.},
  title        = {A study of deep neural networks for human activity recognition},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On viability of detecting malwares online using ensemble
classification method with performance metrics. <em>COIN</em>,
<em>36</em>(3), 1097–1112. (<a
href="https://doi.org/10.1111/coin.12314">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, most of the services from cloud are protuberant within the all commercial, public, and private areas. A primary difficulty of cloud computing system is making a virtualized environment safe from all intruders. The existing system uses signature-based methods, which cannot provide accurate detection of malware. This paper put forward an approach to detect the malware by using the approach based on feature extraction and various classification techniques. Initially the clean files and malware files are extracted. The feature selection includes gain ratio to provide subset features. The classification is used to predict any malware that has been entered in the mobile device. In this paper, it is proposed to use the ensemble classifier which contains different kinds of classifiers such as Support Vector Machine, K-Nearest Neighbor, and Naïve Bayes classification. These together are known as a meta classifier. These three classification methods had been used for proposed work and get the results with higher accuracy. This measures the correctness of the prediction happened using ensemble method with high precision and recall values which is specifically identifies the quality of the techniques used.},
  archive      = {J_COIN},
  author       = {N. Saranya and V. Manikandan},
  doi          = {10.1111/coin.12314},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1097-1112},
  shortjournal = {Comput. Intell.},
  title        = {On viability of detecting malwares online using ensemble classification method with performance metrics},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multiobjective optimal power flow using interior search
algorithm: A case study on a real-time electrical network.
<em>COIN</em>, <em>36</em>(3), 1078–1096. (<a
href="https://doi.org/10.1111/coin.12312">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal power flow (OPF) is a vital concern in an electrical network. In consequence of the intricacy of the power systems, the conventional formulations are not adequate for current situation. Hence, in this study, the multiobjective OPF (MOOPF) problem has been modeled to diminish the production cost, environmental emission, and losses and to enhance the voltage stability and voltage profile simultaneously. This study proposes the application of interior search algorithm (ISA) for resolving MOOPF problem. The simulations have been carried out on three various test systems such as IEEE 30-bus system, IEEE 57-bus system, and Tamil Nadu Generation and Distribution Corporation Limited, as a real part of 62 bus Indian utility system (IUS) to infer the efficacy of ISA in solving the OPF problems. The simulation results have been compared with other techniques. The comparison shows that ISA is used in resolving MOOPF problems.},
  archive      = {J_COIN},
  author       = {Shilaja Chandrasekaran},
  doi          = {10.1111/coin.12312},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1078-1096},
  shortjournal = {Comput. Intell.},
  title        = {Multiobjective optimal power flow using interior search algorithm: A case study on a real-time electrical network},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Novel recommendation system based on long-term composition
for adaptive web services. <em>COIN</em>, <em>36</em>(3), 1063–1077. (<a
href="https://doi.org/10.1111/coin.12309">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of digital web services, composition of features on the fly is inevitable. The Long-term Composed Service (LCS) entertains the composition of features to any extent, since it has an open-ended lifetime. In the proposed research work, we have intended to provide service support to run the business toward a long time commitment. Structure-based recommended system for LCSs (RS-LCSs) is proposed, where user queries and recent updation/requirements are considered for exhibiting the response through the system. In the proposed system, business has been regulated according to the time constraints. We have tested our proposed system on the standard benchmark dataset and quantitative metrics show our proposed method has performed well against the compared methods. The forecasting of business has been done through our model to address the recent queries and new requirements issues to provide an adaptive web service for the business development.},
  archive      = {J_COIN},
  author       = {P Kirubanantham and G Vijayakumar},
  doi          = {10.1111/coin.12309},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1063-1077},
  shortjournal = {Comput. Intell.},
  title        = {Novel recommendation system based on long-term composition for adaptive web services},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The long road from performing word sense disambiguation to
successfully using it in information retrieval: An overview of the
unsupervised approach. <em>COIN</em>, <em>36</em>(3), 1026–1062. (<a
href="https://doi.org/10.1111/coin.12303">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The issue of whether or not word sense disambiguation (WSD) can improve information retrieval (IR) results has been intensely debated over the years, with many inconclusive or contradictory results and a majority of skeptical opinions. All three classes of WSD methods (supervised, unsupervised, and knowledge-based) have been considered by the literature with respect to IR. We hereby survey the unsupervised approach which, although relatively rarely used, has provided positive results at a large scale. Unsupervised WSD has already made proof of its utility in IR and it is our belief that it still holds a promise for this field. The two main existing types of unsupervised methods for IR, which are of completely different natures, are presented, within the scientific context in which they were born, and are compared. Regardless of the gap in time between these central approaches, we are of the opinion that the unsupervised solution to the discussed problem remains the most significant for IR applications. By surveying what we consider the most promising existing approach to usage of WSD in IR, and by discussing its possible extensions, we hope to stimulate continuation of this line of research, possibly at an even more successful level.},
  archive      = {J_COIN},
  author       = {Florentina Hristea and Mihaela Colhon},
  doi          = {10.1111/coin.12303},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1026-1062},
  shortjournal = {Comput. Intell.},
  title        = {The long road from performing word sense disambiguation to successfully using it in information retrieval: An overview of the unsupervised approach},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modified online newton step based on elementwise
multiplication. <em>COIN</em>, <em>36</em>(3), 1010–1025. (<a
href="https://doi.org/10.1111/coin.12298">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The second-order method using a Newton step is a suitable technique in online learning to guarantee a regret bound. The large data are a challenge in the Newton method to store second-order matrices such as the hessian. In this article, we have proposed a modified online Newton step that stores first- and second-order matrices of dimension m (classes) by d (features). We have used elementwise arithmetic operations to maintain the size of matrices. The modified second-order matrix size results in faster computations. Also, the mistake rate is on par with respect to popular methods in the literature. The experimental outcome indicates that proposed method could be helpful to handle large multiclass datasets on common desktop machines using second-order method as the Newton step.},
  archive      = {J_COIN},
  author       = {Charanjeet Singh and Anuj Sharma},
  doi          = {10.1111/coin.12298},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1010-1025},
  shortjournal = {Comput. Intell.},
  title        = {Modified online newton step based on elementwise multiplication},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Computationally efficient and secure anonymous
authentication scheme for IoT-based mobile pay-TV systems.
<em>COIN</em>, <em>36</em>(3), 994–1009. (<a
href="https://doi.org/10.1111/coin.12295">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the next few years, the mobile pay-TV systems will be very popular due to their extensive applications. Providing security and privacy are the most challenging issues in the secure development of mobile pay-TV systems. To avoid unauthorized access to mobile pay-TV services, it is very important to authenticate the mobile users and the head end system (HES) in an anonymous manner. Even though several authentication schemes were proposed to provide anonymous authentication, the previously proposed schemes are not fit for mobile pay-TV applications due to their high computational complexity. Hence, a computationally efficient anonymous authentication scheme is proposed in this article for secure service provision in mobile pay-TV systems. The proposed authentication scheme can effectively authenticate both the mobile users and the HES with low computational cost in an anonymous manner. In addition, an anonymous batch authentication scheme is also proposed in this article to authenticate a batch of users in the subscription phase to alleviate the authentication burden of the HES. The security analysis section shows that the proposed scheme is more efficient in terms of security and the performance analysis section shows the strength of this article in terms of computational cost, while performing anonymous authentication in mobile pay-TV systems.},
  archive      = {J_COIN},
  author       = {Ramesh Kumaravelu and Rajakumar Sadaiyandi and Anandamurugan Selvaraj and Jeeva Selvaraj and Gayathiri Karthick},
  doi          = {10.1111/coin.12295},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {994-1009},
  shortjournal = {Comput. Intell.},
  title        = {Computationally efficient and secure anonymous authentication scheme for IoT-based mobile pay-TV systems},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An improved long short-term memory networks with
takagi-sugeno fuzzy for traffic speed prediction considering abnormal
traffic situation. <em>COIN</em>, <em>36</em>(3), 964–993. (<a
href="https://doi.org/10.1111/coin.12291">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic speed prediction is an emerging paradigm for achieving a better transportation system in smart cities and improving the heavy traffic management in the intelligent transportation system (ITS). The accurate traffic speed prediction is affected by many contextual factors such as abnormal traffic conditions, traffic incidents, lane closures due to construction or events, and traffic congestion. To overcome these problems, we propose a new method named fuzzy optimized long short-term memory (FOLSTM) neural network for long-term traffic speed prediction. FOLSTM technique is a hybrid method composed of computational intelligence (CI), machine learning (ML), and metaheuristic techniques, capable of predicting the speed for macroscopic traffic key parameters. First, the proposed hybrid unsupervised learning method, agglomerated hierarchical K -means (AHK) clustering, divides the input samples into a group of clusters. Second, based on parameters the Gaussian bell-shaped fuzzy membership function calculates the degree of membership (high, low, and medium) for each cluster using Takagi-Sugeno fuzzy rules. Finally, the whale optimization algorithm (WOA) is used in LSTM to optimize the parameters obtained by fuzzy rules and calculate the optimal weight value. FOLSTM evaluates the accurate traffic speed from the abnormal traffic data to overcome the nonlinear characteristics. Experimental results demonstrated that our proposed method outperforms the state-of-the-art approaches in terms of metrics such as mean square error (MSE), root mean square error (RMSE), mean absolute error (MAE), and mean absolute percentage error (MAPE).},
  archive      = {J_COIN},
  author       = {Shiju George and Ajit Kumar Santra},
  doi          = {10.1111/coin.12291},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {964-993},
  shortjournal = {Comput. Intell.},
  title        = {An improved long short-term memory networks with takagi-sugeno fuzzy for traffic speed prediction considering abnormal traffic situation},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Taylor-AMS features and deep convolutional neural network
for converting nonaudible murmur to normal speech. <em>COIN</em>,
<em>36</em>(3), 940–963. (<a
href="https://doi.org/10.1111/coin.12281">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Communication becomes effective when the speech signal arrives with the profound characteristics. This insisted the researchers to develop an automatic system of recognizing the speech signals from the murmurs. Some of the traditional automatic recognition systems are unfit for the silent environments imposing a need for an effective recognition system. Also, the traditional automatic recognition methods, like Neural Networks, render poor performance in the presence of the murmurs. Thus, this article proposes a method for automatic whisper recognition using the Deep Convolutional Neural Network (DCNN). The training of the DCNN is performed using the proposed Stochastic-Whale Optimization Algorithm (Stochastic-WOA), which is designed by the integration of Stochastic Gradient Descent algorithm with WOA. The input to the classifier is the features that include pitch chroma, spectral centroid, spectral skewness, and Taylor-Amplitude Modulation Spectrogram (Taylor-AMS), which is obtained by combining Taylor series and Amplitude Modulation Spectrogram (AMS) features, of the preprocessed input speech signal. The experimentation of the method is performed using the real database and the analysis proves that the proposed method acquired a maximal accuracy of 0.9723, minimal False Positive Rate of 0.0257, and maximal True Positive Rate of 0.9981, respectively.},
  archive      = {J_COIN},
  author       = {T. Rajesh Kumar and G. R Suresh and S. Kanaga Subaraja and C. Karthikeyan},
  doi          = {10.1111/coin.12281},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {940-963},
  shortjournal = {Comput. Intell.},
  title        = {Taylor-AMS features and deep convolutional neural network for converting nonaudible murmur to normal speech},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Reduced-gate convolutional long short-term memory using
predictive coding for spatiotemporal prediction. <em>COIN</em>,
<em>36</em>(3), 910–939. (<a
href="https://doi.org/10.1111/coin.12277">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatiotemporal sequence prediction is an important problem in deep learning. We study next-frame(s) video prediction using a deep-learning-based predictive coding framework that uses convolutional LSTM (convLSTM) modules. We introduce a novel rgcLSTM architecture that requires a significantly lower parameter budget than a comparable convLSTM. By using a single multifunction gate, our reduced-gate model achieves equal or better next-frame(s) prediction accuracy than the original convolutional LSTM while using a smaller parameter budget, thereby reducing training time and memory requirements. We tested our reduced gate modules within a predictive coding architecture on the moving MNIST and KITTI datasets. We found that our reduced-gate model has a significant reduction of approximately 40% of the total number of training parameters and a 25% reduction in elapsed training time in comparison with the standard convolutional LSTM model. The performance accuracy of the new model was also improved. This makes our model more attractive for hardware implementation, especially on small devices. We also explored a space of 20 different gated architectures to get insight into how our rgcLSTM fits into that space.},
  archive      = {J_COIN},
  author       = {Nelly Elsayed and Anthony S. Maida and Magdy Bayoumi},
  doi          = {10.1111/coin.12277},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {910-939},
  shortjournal = {Comput. Intell.},
  title        = {Reduced-gate convolutional long short-term memory using predictive coding for spatiotemporal prediction},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A hybrid multi-objective tour route optimization algorithm
based on particle swarm optimization and artificial bee colony
optimization. <em>COIN</em>, <em>36</em>(3), 884–909. (<a
href="https://doi.org/10.1111/coin.12276">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational intelligence techniques have widespread applications in the field of engineering process optimization, which typically comprises of multiple conflicting objectives. An efficient hybrid algorithm for solving multi-objective optimization, based on particle swarm optimization (PSO) and artificial bee colony optimization (ABCO) has been proposed in this paper. The novelty of this algorithm lies in allocating random initial solutions to the scout bees in the ABCO phase which are subsequently optimized in the PSO phase with respect to the velocity vector. The last phase involves loyalty decision-making for the uncommitted bees based on the waggle dance phase of ABCO. This procedure continues for multiple generations yielding optimum results. The algorithm is applied to a real life problem of intercity route optimization comprising of conflicting objectives like minimization of travel cost, maximization of the number of tourist spots visited and minimization of the deviation from desired tour duration. Solutions have been obtained using both pareto optimality and the classical weighted sum technique. The proposed algorithm, when compared analytically and graphically with the existing ABCO algorithm, has displayed consistently better performance for fitness values as well as for standard benchmark functions and performance metrics for convergence and coverage.},
  archive      = {J_COIN},
  author       = {Romit Beed and Arindam Roy and Sunita Sarkar and Durba Bhattacharya},
  doi          = {10.1111/coin.12276},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {884-909},
  shortjournal = {Comput. Intell.},
  title        = {A hybrid multi-objective tour route optimization algorithm based on particle swarm optimization and artificial bee colony optimization},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-level feature optimization and multimodal contextual
fusion for sentiment analysis and emotion classification. <em>COIN</em>,
<em>36</em>(2), 861–881. (<a
href="https://doi.org/10.1111/coin.12274">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The availability of the humongous amount of multimodal content on the internet, the multimodal sentiment classification, and emotion detection has become the most researched topic. The feature selection, context extraction, and multi-modal fusion are the most important challenges in multimodal sentiment classification and affective computing. To address these challenges this paper presents multilevel feature optimization and multimodal contextual fusion technique. The evolutionary computing based feature selection models extract a subset of features from multiple modalities. The contextual information between the neighboring utterances is extracted using bidirectional long-short-term-memory at multiple levels. Initially, bimodal fusion is performed by fusing a combination of two unimodal modalities at a time and finally, trimodal fusion is performed by fusing all three modalities. The result of the proposed method is demonstrated using two publically available datasets such as CMU-MOSI for sentiment classification and IEMOCAP for affective computing. Incorporating a subset of features and contextual information, the proposed model obtains better classification accuracy than the two standard baselines by over 3% and 6% in sentiment and emotion classification, respectively.},
  archive      = {J_COIN},
  author       = {Mahesh G. Huddar and Sanjeev S. Sannakki and Vijay S. Rajpurohit},
  doi          = {10.1111/coin.12274},
  journal      = {Computational Intelligence},
  month        = {5},
  number       = {2},
  pages        = {861-881},
  shortjournal = {Comput. Intell.},
  title        = {Multi-level feature optimization and multimodal contextual fusion for sentiment analysis and emotion classification},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Detecting community structure in complex networks using
genetic algorithm based on object migrating automata. <em>COIN</em>,
<em>36</em>(2), 824–860. (<a
href="https://doi.org/10.1111/coin.12273">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community structure is an important topological feature of complex networks. Detecting community structure is a highly challenging problem in analyzing complex networks and has great importance in understanding the function and organization of networks. Up until now, numerous algorithms have been proposed for detecting community structure in complex networks. A wide range of these algorithms use the maximization of a quality function called modularity . In this article, three different algorithms, namely, MEM-net, OMA-net, and GAOMA-net, have been proposed for detecting community structure in complex networks. In GAOMA-net algorithm, which is the main proposed algorithm of this article, the combination of genetic algorithm (GA) and object migrating automata (OMA) has been used. In GAOMA-net algorithm, the MEM-net algorithm has been used as a heuristic to generate a portion of the initial population. The experiments on both real-world and synthetic benchmark networks indicate that GAOMA-net algorithm is efficient for detecting community structure in complex networks.},
  archive      = {J_COIN},
  author       = {Bagher Zarei and Mohammad Reza Meybodi},
  doi          = {10.1111/coin.12273},
  journal      = {Computational Intelligence},
  month        = {5},
  number       = {2},
  pages        = {824-860},
  shortjournal = {Comput. Intell.},
  title        = {Detecting community structure in complex networks using genetic algorithm based on object migrating automata},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improvement of battery lifetime in software-defined network
using particle swarm optimization based cluster-head gateway switch
routing protocol with fuzzy rules. <em>COIN</em>, <em>36</em>(2),
813–823. (<a href="https://doi.org/10.1111/coin.12271">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The software-defined network (SDN) is one of the network architectures, in which the data plane and control plane is divided from each other, and the network can be handled using a sensibly centralized controller and this method is adopted to reconfigure the wireless sensor network automatically. In this article, to implement the SDN in MANET, in which control nodes can be chosen in SDN dynamically for the activation of MANET function to allocate the works to other mobile nodes to the base station. However, in the field of mobile ad hoc networks, the network lifetime, and battery lifetime is one of the major problems and the energy consumption can play a significant rule for the transmission of data in the SDN. Therefore, in this article, particle swarm optimization (PSO) based CGSR (cluster-head gateway switch routing protocol) algorithm with fuzzy rules is proposed to increase the network lifetime of battery powered mobile nodes by reducing the energy consumptions of each node in software-defined MANET. In this proposed method, a routing method that can permit various mobile nodes with low battery power to transmits the data from source node to base station. We design a PSO based CGSR routing protocol by selecting the routing mobile nodes using fuzzy rules for packet transmission. In CGSR process, the formation of cluster and selection of cluster head is executed depending on the particle swarm optimization method. This proposed routing protocol can be used to enhance the battery lifetime by extension of the network lifetime with numerical analysis for efficient route node selection.},
  archive      = {J_COIN},
  author       = {Maria Antony Sahaya Sheela and Rajendran Prabakaran},
  doi          = {10.1111/coin.12271},
  journal      = {Computational Intelligence},
  month        = {5},
  number       = {2},
  pages        = {813-823},
  shortjournal = {Comput. Intell.},
  title        = {Improvement of battery lifetime in software-defined network using particle swarm optimization based cluster-head gateway switch routing protocol with fuzzy rules},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The combination of term relations analysis and weighted
frequent itemset model for multidocument summarization. <em>COIN</em>,
<em>36</em>(2), 783–812. (<a
href="https://doi.org/10.1111/coin.12270">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, it is necessary that users have access to information in a concise form without losing any critical information. Document summarization is an automatic process of generating a short form from a document. In itemset-based document summarization, the weights of all terms are considered the same. In this paper, a new approach is proposed for multidocument summarization based on weighted patterns and term association measures. In the present study, the weights of the terms are not equal in the context and are computed based on weighted frequent itemset mining. Indeed, the proposed method enriches frequent itemset mining by weighting the terms in the corpus. In addition, the relationships among the terms in the corpus have been considered using term association measures. Also, the statistical features such as sentence length and sentence position have been modified and matched to generate a summary based on the greedy method. Based on the results of the DUC 2002 and DUC 2004 datasets obtained by the ROUGE toolkit, the proposed approach can outperform the state-of-the-art approaches significantly.},
  archive      = {J_COIN},
  author       = {Arash Chaghari and Mohammad-Reza Feizi-Derakhshi and Mohammad-Ali Balafar},
  doi          = {10.1111/coin.12270},
  journal      = {Computational Intelligence},
  month        = {5},
  number       = {2},
  pages        = {783-812},
  shortjournal = {Comput. Intell.},
  title        = {The combination of term relations analysis and weighted frequent itemset model for multidocument summarization},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improved fuzzy weighted-iterative association rule based
ontology postprocessing in data mining for query recommendation
applications. <em>COIN</em>, <em>36</em>(2), 773–782. (<a
href="https://doi.org/10.1111/coin.12269">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The usage of association rules is playing a vital role in the field of knowledge data discovery. Numerous rules have to be processed and plot based on the ranges on the schema. The step in this process depends on the user&#39;s queries. Previously, several projects have been proposed to reduce work and improve filtration processes. However, they have some limitations in preprocessing time and filtration rate. In this article, an improved fuzzy weighted-iterative concept is introduced to overcome the limitation based on the user request and visualization of discovering rules. The initial step includes the mix of client learning with posthandling to use the semantics. The above advance was trailed by surrounding rule schemas to fulfill and anticipate unpredictable guidelines dependent on client desires. Preparing the above developments can be imagined by the use of yet another clever method of study. Standards on guidelines are recognized by the average learning professionals.},
  archive      = {J_COIN},
  author       = {G. Sumathi and J. Akilandeswari},
  doi          = {10.1111/coin.12269},
  journal      = {Computational Intelligence},
  month        = {5},
  number       = {2},
  pages        = {773-782},
  shortjournal = {Comput. Intell.},
  title        = {Improved fuzzy weighted-iterative association rule based ontology postprocessing in data mining for query recommendation applications},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Leveraging active learning to reduce human effort in the
generation of ground-truth for entity resolution. <em>COIN</em>,
<em>36</em>(2), 743–772. (<a
href="https://doi.org/10.1111/coin.12268">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several methods of entity resolution (ER) have been developed in academia and industry over the years, with the intention to identify duplicate entities (eg, records) in datasets. To evaluate the efficacy of such methods, it is necessary to compare their results with a ground-truth, which consists of a document containing all known duplicate record pairs in a dataset. In general, the generation of ground-truths for real datasets is performed manually from the inspection of all combinations of pairs of records in a dataset. This is subject to error and presents quadratic complexity, with respect to the size(s) of the dataset(s), requiring a long time to be performed. In this context, some works present (semi)automatic approaches for the generation of ground-truths for the ER task. However, such approaches are either not applicable to several domains or still present a considerable manual effort. In this work, we propose GTGenERAL, a semiautomatic approach that combines results from multiple algorithms of ER together with active learning to generate accurate ground-truths employing reduced manual effort. Experiments using real datasets show that, with great manual effort reduction, GTGenERAL is able to generate ground-truths close to those generated by the state-of-the-art approach.},
  archive      = {J_COIN},
  author       = {Diego Fernandes de Araújo and Carlos Eduardo Santos Pires and Dimas Cassimiro Nascimento},
  doi          = {10.1111/coin.12268},
  journal      = {Computational Intelligence},
  month        = {5},
  number       = {2},
  pages        = {743-772},
  shortjournal = {Comput. Intell.},
  title        = {Leveraging active learning to reduce human effort in the generation of ground-truth for entity resolution},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Distributed autonomy and trade-offs in online multiobject
k-coverage. <em>COIN</em>, <em>36</em>(2), 720–742. (<a
href="https://doi.org/10.1111/coin.12264">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we explore the online multiobject k -coverage problem in visual sensor networks. This problem combines k -coverage and the cooperative multirobot observation of multiple moving targets problem, and thereby captures key features of rapidly deployed camera networks, including redundancy and team-based tracking of evasive or unpredictable targets. The benefits of using mobile cameras are demonstrated and we explore the balance of autonomy between cameras generating new subgoals, and those responders able to fulfill them. We show that higher performance against global goals is achieved when decisions are delegated to potential responders who treat subgoals as optional, rather than as obligations that override existing goals without question. This is because responders have up-to-date knowledge of their own state and progress toward goals where they are situated, which is typically old or incomplete at locations remote from them. Examining the extent to which approaches overprovision or underprovision coverage, we find that being well suited for achieving 1-coverage does not imply good performance at k -coverage. Depending on the structure of the environment, the problems of 1-coverage and k -coverage are not necessarily aligned and that there is often a trade-off to be made between standard coverage maximization and achieving k -coverage.},
  archive      = {J_COIN},
  author       = {Lukas Esterle and Peter R. Lewis},
  doi          = {10.1111/coin.12264},
  journal      = {Computational Intelligence},
  month        = {5},
  number       = {2},
  pages        = {720-742},
  shortjournal = {Comput. Intell.},
  title        = {Distributed autonomy and trade-offs in online multiobject k-coverage},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Antiperiodic dynamical behaviors of discontinuous
neutral-type cohen-grossberg neural networks with mixed time delays.
<em>COIN</em>, <em>36</em>(2), 698–719. (<a
href="https://doi.org/10.1111/coin.12262">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a class of neutral-type Cohen-Grossberg neural networks with discontinuous activations and mixed time delays. Based on the functional differential inclusions theory, inequality technique, and nonsmooth analysis theory with Lyapunovlike approach, some new sufficient criteria are given to ascertain the existence, uniqueness, and globally exponential stability of the antiperiodic solution. Finally, two topical numerical examples and the corresponding computer simulations are delineated to substantiate the correctness of our theoretical predictions. The obtained results of this article are new and complement some related earlier works.},
  archive      = {J_COIN},
  author       = {Fanchao Kong and Quanxin Zhu},
  doi          = {10.1111/coin.12262},
  journal      = {Computational Intelligence},
  month        = {5},
  number       = {2},
  pages        = {698-719},
  shortjournal = {Comput. Intell.},
  title        = {Antiperiodic dynamical behaviors of discontinuous neutral-type cohen-grossberg neural networks with mixed time delays},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Routing using reinforcement learning in vehicular ad hoc
networks. <em>COIN</em>, <em>36</em>(2), 682–697. (<a
href="https://doi.org/10.1111/coin.12261">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In vehicular ad hoc networks (VANETs), the frequent change in vehicle mobility creates dynamic changes in communication link and topology of the network. Hence, the key challenge is to address and resolve longer transmission delays and reduced transmission stability. During the establishment of routing path, the focus of entire research is on traffic detection and road selection with high traffic density for increased packet transmission. This reduces the transmission delays and avoids carry-and-forward scenarios; however, these techniques fail in obtaining accurate traffic density in real-time scenario due to rapid change in traffic density. Thus, it is necessary to create a model that efficiently monitors the traffic density and assist VANETs in route selection in an automated way with increased accuracy. In this article, a novel machine learning architecture using deep reinforcement learning (DRL) model is proposed to monitor and estimate the data essential for the routing protocol. In this model, the roadside unit maintains the traffic information on roads using DRL. The DRL predicts the movement of the vehicle and makes a suitable routing path for transmitting the packets with improved transmission capacity. It further uses predicted transmission delays and the destination location to choose the forwarding directions between two road safety units (RSUs). The application of DRL over VANETs yields increased network performance, which provides on-demand routing information. The simulation results show that the DRL-based routing is effective in routing the data packets between the source and destination vehicles than other existing method.},
  archive      = {J_COIN},
  author       = {M. Saravanan and P. Ganeshkumar},
  doi          = {10.1111/coin.12261},
  journal      = {Computational Intelligence},
  month        = {5},
  number       = {2},
  pages        = {682-697},
  shortjournal = {Comput. Intell.},
  title        = {Routing using reinforcement learning in vehicular ad hoc networks},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Elite artificial bees’ colony algorithm to solve robot’s
fuzzy constrained routing problem. <em>COIN</em>, <em>36</em>(2),
659–681. (<a href="https://doi.org/10.1111/coin.12258">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the fundamental challenges of the robotics field is robot&#39;s movement. That is, why route planning is an eminent issue of robotics research and it is used to enhance autonomy of moving robots in complex environments. The objective of route planning problem is to find the shortest route without collide from initiation point to destination point so that the amount of energy consumption by robot would not exceed a predefined amount. Because neither the amount of energy consumption nor the robot&#39;s passed distance index cannot be measured precisely due to environmental conditions, and fuzzy data is used for modeling the problem and the problem would be called “Robot Fuzzy Constrained shortest Route” problem. The main contributions of this study are fivefold: (i) The mathematical model of fuzzy constrained shortest route problem (FCSRP) is formulated; (ii) An elite artificial bees&#39; colony (EABC) algorithm is used to solve the robot&#39;s FSCRP; (iii) The proposed EABC algorithm is simulated with two fuzzy networks; (iv) The performance of the proposed approach is compared with the performance of genetic algorithm and particle swarm optimization algorithm; and (v) The results show the convergence speed of the EABC algorithm is higher than the existing algorithms.},
  archive      = {J_COIN},
  author       = {Ali Abbaszadeh Sori and Ali Ebrahimnejad and Homayun Motameni},
  doi          = {10.1111/coin.12258},
  journal      = {Computational Intelligence},
  month        = {5},
  number       = {2},
  pages        = {659-681},
  shortjournal = {Comput. Intell.},
  title        = {Elite artificial bees&#39; colony algorithm to solve robot&#39;s fuzzy constrained routing problem},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Lie detection using extreme learning machine: A concealed
information test based on short-time fourier transform and binary bat
optimization using a novel fitness function. <em>COIN</em>,
<em>36</em>(2), 637–658. (<a
href="https://doi.org/10.1111/coin.12256">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lie detection is one of the major challenges that is being faced by the forensic sciences. Identification of lie on the basis of a person&#39;s mental behavior is a tedious task. Brain-computer interface is one such medium which provides a solution to this problem by displaying visual stimuli and recording subject&#39;s brain responses. A P300 response is elicited whenever a person comes across a familiar stimuli in a series of rare stimuli. This P300 response is used for the lie detection method. In the proposed concealed information test, acquired signals are preprocessed to discard noise. Then, short-time Fourier transform method is applied to extract features from the preprocessed electroencephalogram signals. To avoid the curse of dimensionality and to reduce computational overhead, binary bat algorithm is applied, which helps in choosing optimal subset of features. The obtained set of features is given as an input to the extreme learning machine classifier for training of guilty and innocent samples. The performance of the system is assessed using 10-fold cross-validation. The resultant accuracy obtained from the proposed lie detection system is 88.3%. The system has provided efficient results in contrast with most of the state-of-the-art lie detection methods.},
  archive      = {J_COIN},
  author       = {Shubham Dodia and Damodar R. Edla and Annushree Bablani and Ramalingaswamy Cheruku},
  doi          = {10.1111/coin.12256},
  journal      = {Computational Intelligence},
  month        = {5},
  number       = {2},
  pages        = {637-658},
  shortjournal = {Comput. Intell.},
  title        = {Lie detection using extreme learning machine: A concealed information test based on short-time fourier transform and binary bat optimization using a novel fitness function},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimization of material removal rate in wire EDM by
polynomial neural network models. <em>COIN</em>, <em>36</em>(2),
613–636. (<a href="https://doi.org/10.1111/coin.12255">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maximization of material removal rate may yield impractical results if the cost for generation of removal rate is not included in the optimization. Presently, there are many studies which have applied different linear, nonlinear, and metaheuristics optimization techniques to maximize material removal rate but none of the approaches have the capability of self-adaptation. In none of these studies impact of cost on removal rate was considered. That is why, in the present study, the Group Method of Data Handling which is a technique to develop polynomial neural network (PNN) models was utilized for the first time to maximize material removal rate with the help of the on- and off-stage current as the design variables constrained by the operating costs. The PNN architecture is widely used in many fields of technology and science. However, application of this architecture is scarce in case of optimization of material removal rate. According to the results the accuracy level and time of convergence in case of PNN was found to be better compared to that from artificial neural network and linear models both of which were utilized for estimation of the output variable.},
  archive      = {J_COIN},
  author       = {Prasenjit Dutta and Mrinmoy Majumder and Subhash Chandra Panja},
  doi          = {10.1111/coin.12255},
  journal      = {Computational Intelligence},
  month        = {5},
  number       = {2},
  pages        = {613-636},
  shortjournal = {Comput. Intell.},
  title        = {Optimization of material removal rate in wire EDM by polynomial neural network models},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evolutionary subspace clustering using variable genome
length. <em>COIN</em>, <em>36</em>(2), 574–612. (<a
href="https://doi.org/10.1111/coin.12254">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subspace clustering is a data-mining task that groups similar data objects and at the same time searches the subspaces where similarities appear. For this reason, subspace clustering is recognized as more general and complicated than standard clustering. In this article, we present ChameleoClust+, a bioinspired evolutionary subspace clustering algorithm that takes advantage of an evolvable genome structure to detect various numbers of clusters located in different subspaces. ChameleoClust+ incorporates several biolike features such as a variable genome length, both functional and nonfunctional elements, and mutation operators including large rearrangements. It was assessed and compared with the state-of-the-art methods on a reference benchmark using both real-world and synthetic data sets. Although other algorithms may need complex parameter settings, ChameleoClust+ needs to set only one subspace clustering ad hoc and intuitive parameter: the maximal number of clusters. The remaining parameters of ChameleoClust+ are related to the evolution strategy (eg, population size, mutation rate), and a single setting for all of them turned out to be effective for all the benchmark data sets. A sensitivity analysis has also been carried out to study the impact of each parameter on the subspace clustering quality.},
  archive      = {J_COIN},
  author       = {Sergio Peignier and Christophe Rigotti and Guillaume Beslon},
  doi          = {10.1111/coin.12254},
  journal      = {Computational Intelligence},
  month        = {5},
  number       = {2},
  pages        = {574-612},
  shortjournal = {Comput. Intell.},
  title        = {Evolutionary subspace clustering using variable genome length},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A steganographic method based on optimized audio embedding
technique for secure data communication in the internet of things.
<em>COIN</em>, <em>36</em>(2), 557–573. (<a
href="https://doi.org/10.1111/coin.12253">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of the internet and the internet of things (IoT) refers to the next phase of information revolution whose context involves billions of smart devices and sensors interconnected to facilitate speedy information and data exchange under soft real-time constraints. Digital information revolution has caused significant changes in the data communication. This data communication may require private, secure, and sometimes malicious communication. Competent secrecy can be accomplished by applying novel and inventive audio steganography. This article focuses on the secret message followed by shuffled embedded bit substitution in original audio stream by adopting optimized audio embedding technique (OAET) from the technological observation. To hide the information in the deeper layer of the audio stream, this method uses a new elevated bit range least significant bit (LSB) audio steganography technique that decreases distortion and improves the robustness of the embedded audio stream. The proposed technique proves that the perceptual quality of audio steganography is better than the previous standard LSB technique. Experiment results proved that the cladding of the OAET provides high-level security to the universal cyber data. The interpretation of results shows that embedding data in audio enhances the level of security when used as IoT smart speakers, where the attackers could not distinguish between the original audio and the embedded audio streams.},
  archive      = {J_COIN},
  author       = {Anguraj S and Shantharajah S P and Jeba Emilyn J},
  doi          = {10.1111/coin.12253},
  journal      = {Computational Intelligence},
  month        = {5},
  number       = {2},
  pages        = {557-573},
  shortjournal = {Comput. Intell.},
  title        = {A steganographic method based on optimized audio embedding technique for secure data communication in the internet of things},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). CSBF: A static ensemble fusion method based on the
centrality score of complex networks. <em>COIN</em>, <em>36</em>(2),
522–556. (<a href="https://doi.org/10.1111/coin.12249">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensemble of classifiers can improve classification accuracy by combining several models. The fusion method plays an important role in the ensemble performance. Usually, a criterion for weighting the decision of each ensemble member is adopted. Frequently, this can be done using some heuristic based on accuracy or confidence. Then, the used fusion rule must consider the established criterion for providing a most reliable ensemble output through a kind of competition among the ensemble members. This article presents a new ensemble fusion method, named centrality score-based fusion, which uses the centrality concept in the context of social network analysis (SNA) as a criterion for the ensemble decision. Centrality measures have been applied in the SNA to measure the importance of each person inside of a social network, taking into account the relationship of each person with all others. Thus, the idea is to derive the classifier weight considering the overall classifier prominence inside the ensemble network, which reflects the relationships among pairs of classifiers. We hypothesized that the prominent position of a classifier based on its pairwise relationship with the other ensemble members could be its weight in the fusion process. A robust experimental protocol has confirmed that centrality measures represent a promising strategy to weight the classifiers of an ensemble, showing that the proposed fusion method performed well against the literature.},
  archive      = {J_COIN},
  author       = {Ronan Assumpção Silva and Alceu de Souza Britto Jr and Fabricio Enembreck and Robert Sabourin and Luiz E. S. de Oliveira},
  doi          = {10.1111/coin.12249},
  journal      = {Computational Intelligence},
  month        = {5},
  number       = {2},
  pages        = {522-556},
  shortjournal = {Comput. Intell.},
  title        = {CSBF: A static ensemble fusion method based on the centrality score of complex networks},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A topic-based term frequency normalization framework to
enhance probabilistic information retrieval. <em>COIN</em>,
<em>36</em>(2), 486–521. (<a
href="https://doi.org/10.1111/coin.12248">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many well-known probabilistic information retrieval models have shown promise for use in document ranking, especially BM25. Nevertheless, it is observed that the control parameters in BM25 usually need to be adjusted to achieve improved performance on different data sets; additionally, the assumption in BM25 on the bag-of-words model prevents its direct utilization of rich information that lies at the sentence or document level. Inspired by the above challenges with respect to BM25, we first propose a new normalization method on the term frequency in BM25 (called BM25 QL in this paper); in addition, the method is incorporated into CRTER 2 , a recent BM25-based model, to construct CRTER 2 QL . Then, we incorporate topic modeling and word embedding into BM25 to relax the assumption of the bag-of-words model. In this direction, we propose a topic-based retrieval model, TopTF, for BM25, which is then further incorporated into the language model (LM) and the multiple aspect term frequency (MATF) model. Furthermore, an enhanced topic-based term frequency normalization framework, ETopTF, based on embedding is presented. Experimental studies demonstrate the great effectiveness and performance of these methods. Specifically, on all tested data sets and in terms of the mean average precision (MAP), our proposed models, BM25 QL and CRTER 2 QL , are comparable to BM25 and CRTER 2 with the best b parameter value; the TopTF models significantly outperform the baselines, and the ETopTF models could further improve the TopTF in terms of the MAP.},
  archive      = {J_COIN},
  author       = {Fanghong Jian and Jimmy X. Huang and Jiashu Zhao and Zhiwei Ying and Yuqi Wang},
  doi          = {10.1111/coin.12248},
  journal      = {Computational Intelligence},
  month        = {5},
  number       = {2},
  pages        = {486-521},
  shortjournal = {Comput. Intell.},
  title        = {A topic-based term frequency normalization framework to enhance probabilistic information retrieval},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Proportional data modeling via selection and estimation of a
finite mixture of scaled dirichlet distributions. <em>COIN</em>,
<em>36</em>(2), 459–485. (<a
href="https://doi.org/10.1111/coin.12246">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an unsupervised algorithm for learning a finite mixture of scaled Dirichlet distributions. Parameters estimation is based on the maximum likelihood approach, and the minimum message length (MML) criterion is proposed for selecting the optimal number of components. This research work is motivated by the flexibility issues of the Dirichlet distribution, the widely used model for multivariate proportional data, which has prompted a number of scholars to search for generalizations of the Dirichlet. By introducing the extra parameters of the scaled Dirichlet, several useful statistical models could be obtained. Experimental results are presented using both synthetic and real datasets. Moreover, challenging real-world applications are empirically investigated to evaluate the efficiency of our proposed statistical framework.},
  archive      = {J_COIN},
  author       = {Nuha Zamzami and Rua Alsuroji and Oboh Eromonsele and Nizar Bouguila},
  doi          = {10.1111/coin.12246},
  journal      = {Computational Intelligence},
  month        = {5},
  number       = {2},
  pages        = {459-485},
  shortjournal = {Comput. Intell.},
  title        = {Proportional data modeling via selection and estimation of a finite mixture of scaled dirichlet distributions},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Intelligent methodologies for cardiac sound signals analysis
and characterization in cepstrum and time-scale domains. <em>COIN</em>,
<em>36</em>(2), 427–458. (<a
href="https://doi.org/10.1111/coin.12244">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biometric authentication is the process that allows an individual to be identified based on a set of unique biological features data. In this study, we present different experiments to use the cardiac sound signals (phonocardiogram “PCG”) as a biometric authentication trait. We have applied different features extraction approaches and different classification techniques to use the PCG as a biometric trait. Through all experiments, data acquisition is based on collecting the cardiac sounds from HSCT-11 and PASCAL CHSC2011 datasets, while preprocessing is concerned with de-noising of cardiac sounds using multiresolution-decomposition and multiresolution-reconstruction (MDR-MRR). The de-noised signal is then segmented based on frame-windowing and Shanon energy (SE) methods. For feature extraction, Cepstral (Cp) domain (based on mel-frequency) and time-scale (T-S) domain (based on Wavelet Transform) features are extracted from the de-noised signal after segmentation. The features, extracted from the Cp-domain and the T-S domain, are fed to four different classifiers: Artificial neural networks (ANN), support vector machine (SVM), random forest (RF) and K-nearest neighbor (KNN). The performance of the classifications is assessed based on the k-fold cross validation. The computation complexity of the feature extraction domains is expressed using the Big-O measurements. The T-S features are superior to PCG heart signals in terms of the classification accuracy. The experiments&#39; results give the highest classification accuracy with lowest computation complexity for RF in the Cp domain and SVM and ANN in the T-S domain.},
  archive      = {J_COIN},
  author       = {El-Sayed A. El-Dahshan and Mahmoud M. Bassiouni},
  doi          = {10.1111/coin.12244},
  journal      = {Computational Intelligence},
  month        = {5},
  number       = {2},
  pages        = {427-458},
  shortjournal = {Comput. Intell.},
  title        = {Intelligent methodologies for cardiac sound signals analysis and characterization in cepstrum and time-scale domains},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Credit score classification using spiking extreme learning
machine. <em>COIN</em>, <em>36</em>(2), 402–426. (<a
href="https://doi.org/10.1111/coin.12242">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Credit score classification is a prominent research problem in the banking or financial industry, and its predictive performance is responsible for the profitability of financial industry. This paper addresses how Spiking Extreme Learning Machine (SELM) can be effectively used for credit score classification. A novel spike-generating function is proposed in Leaky Nonlinear Integrate and Fire Model (LNIF). Its interspike period is computed and utilized in the extreme learning machine (ELM) for credit score classification. The proposed model is named as SELM and is validated on five real-world credit scoring datasets namely: Australian, German-categorical, German-numerical, Japanese, and Bankruptcy. Further, results obtained by SELM are compared with back propagation, probabilistic neural network, ELM, voting-based Q -generalized extreme learning machine, Radial basis neural network and ELM with some existing spiking neuron models in terms of classification accuracy, Area under curve (AUC), H -measure and computational time. From the experimental results, it has been noticed that improvement in accuracy and execution time for the proposed SELM is highly statistically important for all aforementioned credit scoring datasets. Thus, integrating a biological spiking function with ELM makes it more efficient for categorization.},
  archive      = {J_COIN},
  author       = {Venkatanareshbabu Kuppili and Diwakar Tripathi and Damodar Reddy Edla},
  doi          = {10.1111/coin.12242},
  journal      = {Computational Intelligence},
  month        = {5},
  number       = {2},
  pages        = {402-426},
  shortjournal = {Comput. Intell.},
  title        = {Credit score classification using spiking extreme learning machine},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Detection and classification of lung nodules in chest x-ray
images using deep convolutional neural networks. <em>COIN</em>,
<em>36</em>(2), 370–401. (<a
href="https://doi.org/10.1111/coin.12241">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lung nodule classification is one of the main topics related to computer-aided detection systems. Although convolutional neural networks (CNNs) have been demonstrated to perform well on many tasks, there are few explorations of their use for classifying lung nodules in chest X-ray (CXR) images. In this work, we proposed and analyzed a pipeline for detecting lung nodules in CXR images that includes lung area segmentation, potential nodule localization, and nodule candidate classification. We presented a method for classifying nodule candidates with a CNN trained from the scratch. The effectiveness of our method relies on the selection of data augmentation parameters, the design of a specialized CNN architecture, the use of dropout regularization on the network, inclusive in convolutional layers, and addressing the lack of nodule samples compared to background samples balancing mini-batches on each stochastic gradient descent iteration. All model selection decisions were taken using a CXR subset of the Lung Image Database Consortium and Image Database Resource Initiative dataset separately. Thus, we used all images with nodules in the Japanese Society of Radiological Technology dataset for evaluation. Our experiments showed that CNNs were capable of achieving competitive results when compared to state-of-the-art methods. Our proposal obtained an area under the free-response receiver operating characteristic curve of 7.76 considering 10 false positives per image (FPPI), and sensitivity values of 73.1% and 79.6% with 2 and 5 FPPI, respectively.},
  archive      = {J_COIN},
  author       = {Julio Mendoza and Helio Pedrini},
  doi          = {10.1111/coin.12241},
  journal      = {Computational Intelligence},
  month        = {5},
  number       = {2},
  pages        = {370-401},
  shortjournal = {Comput. Intell.},
  title        = {Detection and classification of lung nodules in chest X-ray images using deep convolutional neural networks},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Artificial bee colony algorithm for content-based image
retrieval. <em>COIN</em>, <em>36</em>(1), 351–367. (<a
href="https://doi.org/10.1111/coin.12275">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image retrieval is the process of searching for digital images from a large database. There exist two distinctive research groups, which employ the content-based and description-based approaches, respectively. However, research in the content-based domain is currently dominant in the field, while the other approaches are not as widely utilized. Although there are a number of different techniques that are available for image retrieval, the development of more effective methods is still necessary. In recent years, previous research has shown that biologically inspired metaheuristic algorithms have great potential for use in solving problems in many science and engineering domains. The artificial bee colony (ABC) algorithm is one of the more promising biologically inspired metaheuristic approaches used to find optimal solutions as it has the advantages of convenient implementation and efficient performance. In this article, a new efficient method based on a combination of the gray-level cooccurrence matrix (GLCM) with the ABC, referred to as “GLCM-ABC,” is proposed for use in content-based image retrieval (CBIR). The experimental results demonstrate that the proposed approach works well for CBIR and can classify specific types of material surfaces in images with a reasonably high level of accuracy as well as outperform other existing algorithms.},
  archive      = {J_COIN},
  author       = {Anan Banharnsakun},
  doi          = {10.1111/coin.12275},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {351-367},
  shortjournal = {Comput. Intell.},
  title        = {Artificial bee colony algorithm for content-based image retrieval},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improved spotted hyena optimizer with space transformational
search for training pi-sigma higher order neural network. <em>COIN</em>,
<em>36</em>(1), 320–350. (<a
href="https://doi.org/10.1111/coin.12272">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spotted hyena optimizer (SHO) is a recently developed swarm-based algorithm in the field of metaheuristic research, for solving realistic engineering design constraint and unconstrained difficulties. To resolve complicated nonlinear physical world tasks, at times, SHO reveals deprived performance concerning to explorative strength. So, to enhance the explorative strength along with exploitation in the search region, an attempt has been made by proposing the enhanced version of classical SHO. The suggested method is designated as space transformation search (STS)-SHO. In STS-SHO, a new evolutionary technique named as STS technique has been incorporated with original SHO. The suggested method has been assessed by IEEE CEC 2017 benchmark problems. The efficacy of the said method has been proven by using standard measures such as given performance metrics in CEC 2017, complexity analysis, convergence analysis, and statistical implications. Further as real-world application, the said algorithm has been applied to train pi-sigma neural network by means of 13 benchmark datasets considered from UCI depository. From the article it can be concluded that the suggested method STS-SHO is an effective and trustworthy algorithm, which has the ability to resolve real-life optimization complications.},
  archive      = {J_COIN},
  author       = {Nibedan Panda and Santosh Kumar Majhi},
  doi          = {10.1111/coin.12272},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {320-350},
  shortjournal = {Comput. Intell.},
  title        = {Improved spotted hyena optimizer with space transformational search for training pi-sigma higher order neural network},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Ensemble cluster pruning via convex-concave programming.
<em>COIN</em>, <em>36</em>(1), 297–319. (<a
href="https://doi.org/10.1111/coin.12267">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensemble learning is the process of aggregating the decisions of different learners/models. Fundamentally, the performance of the ensemble relies on the degree of accuracy in individual learner predictions and the degree of diversity among the learners. The trade-off between accuracy and diversity within the ensemble needs to be optimized to provide the best grouping of learners as it relates to their performance. In this optimization theory article, we propose a novel ensemble selection algorithm which, focusing specifically on clustering problems, selects the optimal subset of the ensemble that has both accurate and diverse models. Those ensemble selection algorithms work for a given number of the best learners within the subset prior to their selection. The cardinality of a subset of the ensemble changes the prediction accuracy. The proposed algorithm in this study determines both the number of best learners and also the best ones. We compared our prediction results to recent ensemble clustering selection algorithms by the number of cardinalities and best predictions, finding better and approximated results to the optimum solutions.},
  archive      = {J_COIN},
  author       = {Süreyya Özöğür-Akyüz and Buse Çisil Otar and Pınar Karadayı Atas},
  doi          = {10.1111/coin.12267},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {297-319},
  shortjournal = {Comput. Intell.},
  title        = {Ensemble cluster pruning via convex-concave programming},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A multiobjective integrated multiproject scheduling and
multiskilled workforce assignment model considering learning effect
under uncertainty. <em>COIN</em>, <em>36</em>(1), 276–296. (<a
href="https://doi.org/10.1111/coin.12260">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today, organizations try to decline academically expenses using humans and resources in addition to rising managers and operators&#39; satisfaction. Meantime, a very important step in the process of decision is the assignment of human resources, particularly in connection with research and development (R&amp;D) projects in which the system is highly dependent on the capabilities of human resources. In this study, we tried all the assumptions that come true in the real world, considered a model for applied R&amp;D projects to reduce costs and increase the efficiency of projects. Therefore, an integrated multiproject scheduling and multiskill human resource assignment model under uncertainty has developed for R&amp;D projects. Furthermore, it is assumed that the activity processing time is related to human resources assignment that means the learning effect is considered. To demonstrate the proposed model efficiency, the various dimensions instance problem was solved accurately and efficiently in GAMS software, and the results have been reported. In addition, the proposed model is validated through the input parameter sensitivity analysis. The results indicate a suitable performance of the proposed fuzzy mathematical programming model is due to the complexity of the problem.},
  archive      = {J_COIN},
  author       = {Milad Hematian and Mir Mehdi Seyyed Esfahani and Iraj Mahdavi and Nezam Mahdavi-Amiri and Javad Rezaeian},
  doi          = {10.1111/coin.12260},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {276-296},
  shortjournal = {Comput. Intell.},
  title        = {A multiobjective integrated multiproject scheduling and multiskilled workforce assignment model considering learning effect under uncertainty},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Brain tumor diagnosis based on artificial neural network and
a chaos whale optimization algorithm. <em>COIN</em>, <em>36</em>(1),
259–275. (<a href="https://doi.org/10.1111/coin.12259">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and early detection of the brain tumor region has a great impact on the choice of treatment, its success rate, and the follow-up of the disease process over time. This study presents a new bioinspired technique for the early detection of the brain tumor area to improve the chance of completely healing. The study presents a multistep technique to detect the brain tumor area. Herein, after image preprocessing and image feature extraction, an artificial neural network is used to determine the tumor area in the image. The method is based on using an improved version of the whale optimization algorithm for optimal selection of the features and optimizing the artificial neural network weights for classification. Simulation results of the proposed method are applied to FLAIR, T1, and T2 datasets and are compared with different algorithms. Three performance indexes including correct detection rate, false acceptance rate, and false rejection rate are selected for the system performance analysis. Final results showed the superiority of the proposed method toward the other similar methods.},
  archive      = {J_COIN},
  author       = {Shu Gong and Wei Gao and Francis Abza},
  doi          = {10.1111/coin.12259},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {259-275},
  shortjournal = {Comput. Intell.},
  title        = {Brain tumor diagnosis based on artificial neural network and a chaos whale optimization algorithm},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Employing a gaussian particle swarm optimization method for
tuning multi input multi output-fuzzy system as an integrated controller
of a micro-grid with stability analysis. <em>COIN</em>, <em>36</em>(1),
225–258. (<a href="https://doi.org/10.1111/coin.12257">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are mainly two most essential problems in power networks, load frequency control and power flow management, which are grown recently because of growth in dimension/complication of grids. Present work suggests a controller based on fuzzy systems in which controller design is performed in a supervisory manner over a multiagent system aiming to control the frequency variation as well as generation cost minimization in the entire grid. The designing processes for low-frequency controller (LFC) and management are mostly performed separately, which results in the disruption of both outputs. This challenge is tackled in this paper by the integration of them in the designing process. Additionally, stability guarantee is in high importance in the power systems, which is neglected in most of the related works. The Gaussian particle swarm optimization (GPSO) algorithm is applied for determining the optimal values of the decision variables, which can also guarantee the stability of the system by adopting a chaotic map by Gaussian function to balance the seeking abilities of particles that promotes the computation effectiveness without affecting the efficiency of the fuzzy controller. Then, the stability situationof the fuzzy + GPSO method is derived that guarantees a suitable global exploration and rapid convergence, with no require to gradients.},
  archive      = {J_COIN},
  author       = {Mahdi Mir and Mohammad Dayyani and Tole Sutikno and Morteza Mohammadi Zanjireh and Navid Razmjooy},
  doi          = {10.1111/coin.12257},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {225-258},
  shortjournal = {Comput. Intell.},
  title        = {Employing a gaussian particle swarm optimization method for tuning multi input multi output-fuzzy system as an integrated controller of a micro-grid with stability analysis},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). IntelliHome: An internet of things-based system for
electrical energy saving in smart home environment. <em>COIN</em>,
<em>36</em>(1), 203–224. (<a
href="https://doi.org/10.1111/coin.12252">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite there has been an increasing energy price due to factors such as supply, demand, government regulation, among others, users do not like to spend their time to analyze their power consumption and establish actions to save money. Hence, there is a need for smart solutions that help users to save energy at home in an easy way. The smart home concept is attracting the attention of both academia and industry to address this need. Nowadays, high volumes of data are available in the smart home context, facilitated by the growth of internet of things (IoT)-based devices and advanced sensing infrastructure. Therefore, it is necessary to automatically extract useful knowledge from this information to cost-effective use of energy at home. In this sense, this work presents IntelliHome, a smart-home system that aims to reduce electrical energy consumption at home. To this end, IntelliHome uses big data analytics technologies and Machine Learning and statistical techniques to provide users with a meaningful perspective of their electricity consumption habits aiming to actively involve them in the energy-saving process through real-time information and energy-saving recommendations. This work also discusses a case study and an evaluation aligned with the objectives of this work. The obtained results verify the effectiveness of the proposed system regarding electrical energy saving.},
  archive      = {J_COIN},
  author       = {Mario A. Paredes-Valverde and Giner Alor-Hernández and Jorge L. García-Alcaráz and María del Pilar Salas-Zárate and Luis O. Colombo-Mendoza and José L. Sánchez-Cervantes},
  doi          = {10.1111/coin.12252},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {203-224},
  shortjournal = {Comput. Intell.},
  title        = {IntelliHome: An internet of things-based system for electrical energy saving in smart home environment},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficiency analysis for stochastic dynamic facility layout
problem using meta-heuristic, data envelopment analysis and machine
learning. <em>COIN</em>, <em>36</em>(1), 172–202. (<a
href="https://doi.org/10.1111/coin.12251">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The facility layout problem (FLP) is a combinatorial optimization problem. The performance of the layout design is significantly impacted by diverse, multiple factors. The use of algorithmic or procedural design methodology in ranking and identification of efficient layout is ineffective. In this context, this study proposes a three-stage methodology where data envelopment analysis (DEA) is augmented with unsupervised and supervised machine learning (ML). In stage 1, unsupervised ML is used for the clustering of the criteria in which the layouts need to be evaluated using homogeneity. Layouts are generated using simulated annealing, chaotic simulated annealing, and hybrid firefly algorithm/chaotic simulated annealing meta-heuristics. In stage 2, the nonparametric DEA approach is used to identify efficient and inefficient layouts. Finally, supervised ML utilizes the performance frontiers from DEA (efficiency scores) to generate a trained model for getting the unique rankings and predicted efficiency scores of layouts. The proposed methodology overcomes the limitations associated with large datasets that contain many inputs / outputs from the conventional DEA and improves the prediction accuracy of layouts. A Gaussian distribution product demand dataset for time period T = 5 and facility size N = 12 is used to prove the effectiveness of the methodology.},
  archive      = {J_COIN},
  author       = {Akash Tayal and Utku Kose and Arun Solanki and Anand Nayyar and José Antonio Marmolejo Saucedo},
  doi          = {10.1111/coin.12251},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {172-202},
  shortjournal = {Comput. Intell.},
  title        = {Efficiency analysis for stochastic dynamic facility layout problem using meta-heuristic, data envelopment analysis and machine learning},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An intelligent optimization-based traffic information
acquirement approach to software-defined networking. <em>COIN</em>,
<em>36</em>(1), 151–171. (<a
href="https://doi.org/10.1111/coin.12250">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of things (IoT) is a global information infrastructure that supports access to thousands of monitoring devices and user terminals. A large amount of monitoring data generated by IoT is integrated to cloud computing through the network to improve the quality of life of citizens. Fine-grained and accurate traffic information is important for IoT network management. Software-defined networking (SDN) is a centralized control plane as a logical control center, making network management more flexible and efficient. Then, we collect fine-grained traffic information in SDN-based IoT networks to improve network management. To acquire the traffic information with low overhead and high accuracy, first, we collect the statistics of coarse-grained traffic of flows and fine-grained traffic of links, and then we utilize the intelligent optimization methods to estimate the network traffic. To improve the granularity and accuracy of the acquired traffic information, we construct an optimization function with constraints to decrease the estimation errors. As the optimization function of traffic information is a non-deterministic polynomial-hard problem, we present a heuristic algorithm to obtain the optimal solution of the fine-grained measurement. Finally, we conduct some simulations to verify the proposed measurement scheme. Simulation results show that our approach can improve the granularity and accuracy of traffic information with intelligent optimization methods.},
  archive      = {J_COIN},
  author       = {Liuwei Huo and Dingde Jiang and Zhihan Lv and Surjit Singh},
  doi          = {10.1111/coin.12250},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {151-171},
  shortjournal = {Comput. Intell.},
  title        = {An intelligent optimization-based traffic information acquirement approach to software-defined networking},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel hybridized metaheuristic technique in enhancing the
diagnosis of cross-sectional dent damaged offshore platform members.
<em>COIN</em>, <em>36</em>(1), 132–150. (<a
href="https://doi.org/10.1111/coin.12247">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Offshore jacket platforms are widely used for oil and gas extraction as well as transportation in shallow to moderate water depth. Tubular cross-sectional elements are used to construct offshore platforms. Tubular cross sections impart higher resistance against hydrodynamic forces and have high torsional rigidity. During operation, the members can be partially or fully damaged due to lateral impacts. The lateral impacts can be due to ship collisions or through the impact of falling objects. The impact forces can weaken some members that influence the overall performance of the platform. This demonstrates an urgent need to develop a framework that can accurately forecast dent depth as well as dent angle of the affected members. This study investigates the use of an adaptive metaheuristics algorithm to provide automatic detection of denting damage in an offshore structure. The damage information includes dent depth and the dent angle. A model is developed in combination with the percentage of the dent depth of the damaged member and is used to assess the performance of the method. It demonstrates that small changes in stiffness of individual damaged bracing members are detectable from measurements of global structural motion.},
  archive      = {J_COIN},
  author       = {Wonsiri Punurai and Md Samdani Azad and Nantiwat Pholdee and Sujin Bureerat and Chana Sinsabvarodom},
  doi          = {10.1111/coin.12247},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {132-150},
  shortjournal = {Comput. Intell.},
  title        = {A novel hybridized metaheuristic technique in enhancing the diagnosis of cross-sectional dent damaged offshore platform members},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Identification of cancerous gene groups from microarray data
by employing adaptive genetic and support vector machine technique.
<em>COIN</em>, <em>36</em>(1), 102–131. (<a
href="https://doi.org/10.1111/coin.12245">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, microarray gene expression data plays a vital role in tumor classification. However, due to the accessibility of a limited number of tissues compared to large number of genes in genomic data, various existing methods have failed to identify a small subset of discriminative genes. To overcome this limitation, in this paper, we developed a new hybrid technique for gene selection, called ensemble multipopulation adaptive genetic algorithm (EMPAGA) that can overlook the irrelevant genes and classify cancer accurately. The proposed hybrid gene selection algorithm comprises of two phase. In the first phase, an ensemble gene selection (EGS) method used to filter the noisy and redundant genes in high-dimensional datasets by combining multilayer and F -score approaches. Then, an adaptive genetic algorithm based on multipopulation strategy with support vector machine and naïve Bayes (NB) classifiers as a fitness function is applied for gene selection to select the extremely sensible genes from the reduced datasets. The performance of the proposed method is estimated on 10 microarray datasets of numerous tumor. The comprehensive results and various comparisons disclose that EGS has a remarkable impact on the efficacy of the adaptive genetic algorithm with multipopulation strategy and enhance the capability of the proposed approach in terms of convergence rate and solution quality. The experiments results demonstrate the superiority of the proposed method when compared to other standard wrappers regarding classification accuracy and optimal number of genes.},
  archive      = {J_COIN},
  author       = {Alok Kumar Shukla},
  doi          = {10.1111/coin.12245},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {102-131},
  shortjournal = {Comput. Intell.},
  title        = {Identification of cancerous gene groups from microarray data by employing adaptive genetic and support vector machine technique},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A robust green traffic-based routing problem for perishable
products distribution. <em>COIN</em>, <em>36</em>(1), 80–101. (<a
href="https://doi.org/10.1111/coin.12240">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, transportation and logistics are considered as the drivers of economic development in the countries due to their impacts on the main variables of the country&#39;s economy such as production, employment, price, and the cost of living. Statistics indicate that fuel consumption constructs a major part of transportation costs, where its optimization leads to the creation of an energy-efficient and sustainable transportation system. On the other hand, vehicles&#39; traffic is also one of the main criteria affecting the travel time of vehicles between demand nodes in a supply chain, increasing fuel consumption, and, consequently, damaging effects of greenhouse gasses. In this paper, a novel robust mixed-integer linear programming model is developed for a green vehicle routing problem with intermediate depots considering different urban traffic conditions, fuel consumption, time windows of services, and uncertain demand for perishable products. To validate and solve the suggested model, CPLEX solver of GAMS software is employed as an exact method. Finally, a case study problem is investigated to evaluate the applicability of the proposed model and determine the optimal managerial insights and policies in the real-world conditions using sensitivity analyses. Moreover, a novel robustness threshold comparison is conducted to find the optimal level of budget assignment.},
  archive      = {J_COIN},
  author       = {Erfan Babaee Tirkolaee and Shaghayegh Hadian and Gerhard-Wilhelm Weber and Iraj Mahdavi},
  doi          = {10.1111/coin.12240},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {80-101},
  shortjournal = {Comput. Intell.},
  title        = {A robust green traffic-based routing problem for perishable products distribution},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). New optimization method based on energy management in
microgrids based on energy storage systems and combined heat and power.
<em>COIN</em>, <em>36</em>(1), 55–79. (<a
href="https://doi.org/10.1111/coin.12238">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microgrids can be assumed as a solution model for green energy sources, energy storage systems, and combined heat and power (CHP) systems. In this work, the cost and emission minimization based on a demand response (DR) program is considered an optimization problem. To solve the mentioned problem a new multiobjective optimization algorithm (improved particle swarm optimization) is proposed based on a fuzzy mechanism to select the optimal value. The microgrid system includes two CHP units, fuel cell and battery systems, and the heat buffer tank. In this problem, two different feasible operating regions have been assumed in CHPs. Accordingly, to decrease the operational cost, time-of-use, and real-time pricing DR programs have been simulated, and the impacts of the mentioned models are evaluated overload profiles. The effectiveness of proposed models has been applied on different cases studies by different scenarios. The proposed model solved the DR program, time of use-DR and real-time pricing-DR problems. The proposed model could reduce the cost about 10%.},
  archive      = {J_COIN},
  author       = {Xiangyu Zeng and Stephen Berti},
  doi          = {10.1111/coin.12238},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {55-79},
  shortjournal = {Comput. Intell.},
  title        = {New optimization method based on energy management in microgrids based on energy storage systems and combined heat and power},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An approximate optimization strategy using refined hybrid
metamodel. <em>COIN</em>, <em>36</em>(1), 35–54. (<a
href="https://doi.org/10.1111/coin.12237">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An approximate model called metamodel or surrogate model is a mathematical model that numerically approximates response of a system during an engineering simulation process or test. The introduction of a metamodel makes it possible to express response defined in the design problem as a simple mathematical function of design variables. A metamodel can be built with response surface method (RSM), kriging, neural network, radial basis function, and so on. Each method has its advantages and disadvantages. A combined metamodel called hybrid model, ensemble model, or multiple surrogates has been developed to maximize each metamodel&#39;s strength. The hybrid model of this research includes RSM and kriging. Besides, a strategy to refine the hybrid metamodel is implemented by reducing design space. In this process, information related to Hessian is utilized for an unconstrained optimization problem, on the contrary feasibility for a constrained optimization problem. This research presents a new hybrid metamodel-based optimization strategy called refined hybrid metamodel. Five mathematical test problems, two-bar design, spring design, and propeller shaft design problems are solved with the suggested method, verifying its usefulness. Most of the optimal results with the proposed method are closer to exact solutions with smaller function evaluations than existing methods.},
  archive      = {J_COIN},
  author       = {Kwon-Hee Lee and Gyung-Il Jeong and Seong-Hyeong Lee},
  doi          = {10.1111/coin.12237},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {35-54},
  shortjournal = {Comput. Intell.},
  title        = {An approximate optimization strategy using refined hybrid metamodel},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multiobjective fuzzy mathematical model for a financially
constrained closed-loop supply chain with labor employment.
<em>COIN</em>, <em>36</em>(1), 4–34. (<a
href="https://doi.org/10.1111/coin.12228">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the multiobjective, multiproducts and multiperiod closed-loop supply chain network design with uncertain parameters, whose aim is to incorporate the financial flow as the cash flow and debts&#39; constraints and labor employment under fuzzy uncertainty. The objectives of the proposed mathematical model are to maximize the increase in cash flow, maximize the total created jobs in the supply chain, and maximize the reliability of consumed raw materials. To encounter the fuzzy uncertainty in this model, a possibilistic programming approach is used. To solve large-sized problems, the multiobjective simulated annealing algorithm, multiobjective gray wolf optimization, and multiobjective invasive weed optimization are proposed and developed. The numerical results demonstrate that these algorithms solve the problems within about 1% of the required solving time for the augmented ε-constraint and have similar performance and even better in some cases. The multiobjective simulated annealing algorithm with a weak performance takes less time than the other two algorithms. The multiobjective gray wolf optimization and multiobjective invasive weed optimization algorithms are superior based on the multiobjective performance indices.},
  archive      = {J_COIN},
  author       = {Alireza Goli and Hasan Khademi Zare and Reza Tavakkoli-Moghaddam and Ahmad Sadegheih},
  doi          = {10.1111/coin.12228},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {4-34},
  shortjournal = {Comput. Intell.},
  title        = {Multiobjective fuzzy mathematical model for a financially constrained closed-loop supply chain with labor employment},
  volume       = {36},
  year         = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
