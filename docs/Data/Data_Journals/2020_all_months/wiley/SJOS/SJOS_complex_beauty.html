<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>SJOS_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="sjos---52">SJOS - 52</h2>
<ul>
<li><details>
<summary>
(2020). Local asymptotic properties for cox-ingersoll-ross process
with discrete observations. <em>SJOS</em>, <em>47</em>(4), 1401–1464.
(<a href="https://doi.org/10.1111/sjos.12494">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider a one-dimensional Cox-Ingersoll-Ross (CIR) process whose drift coefficient depends on unknown parameters. Considering the process discretely observed at high frequency, we prove the local asymptotic normality property in the subcritical case, the local asymptotic quadraticity in the critical case, and the local asymptotic mixed normality property in the supercritical case. To obtain these results, we use the Malliavin calculus techniques developed recently for CIR process together with the estimation for positive and negative polynomial moments of the CIR process. In this study, we require the same conditions of high frequency and infinite horizon as in the case of ergodic diffusions with globally Lipschitz coefficients studied earlier in the literature. However, in the non-ergodic cases, additional assumptions on the decreasing rate are required due to the fact that the square root diffusion coefficient of the CIR process is not regular enough.},
  archive      = {J_SJOS},
  author       = {Mohamed Ben Alaya and Ahmed Kebaier and Ngoc Khue Tran},
  doi          = {10.1111/sjos.12494},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1401-1464},
  shortjournal = {Scand. J. Statist.},
  title        = {Local asymptotic properties for cox-ingersoll-ross process with discrete observations},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Pseudo likelihood-based estimation and testing of
missingness mechanism function in nonignorable missing data problems.
<em>SJOS</em>, <em>47</em>(4), 1377–1400. (<a
href="https://doi.org/10.1111/sjos.12493">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In nonignorable missing response problems, we study a semiparametric model with unspecified missingness mechanism model and a exponential family model for response conditional density. Even though existing methods are available to estimate the parameters in exponential family, estimation or testing of the missingness mechanism model nonparametrically remains to be an open problem. By defining a “synthesis&quot; density involving the unknown missingness mechanism model and the known baseline “carrier&quot; density in the exponential family model, we treat this “synthesis&quot; density as a legitimate one with biased sampling version. We develop maximum pseudo likelihood estimation procedures and the resultant estimators are consistent and asymptotically normal. Since the “synthesis&quot; cumulative distribution is a functional of the missingness mechanism model and the known carrier density, proposed method can be used to test the correctness of the missingness mechanism model nonparametrically andindirectly. Simulation studies and real example demonstrate the proposed methods perform very well.},
  archive      = {J_SJOS},
  author       = {Xuerong Chen and Guoqing Diao and Jing Qin},
  doi          = {10.1111/sjos.12493},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1377-1400},
  shortjournal = {Scand. J. Statist.},
  title        = {Pseudo likelihood-based estimation and testing of missingness mechanism function in nonignorable missing data problems},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Importance sampling type estimators based on approximate
marginal markov chain monte carlo. <em>SJOS</em>, <em>47</em>(4),
1339–1376. (<a href="https://doi.org/10.1111/sjos.12492">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider importance sampling (IS) type weighted estimators based on Markov chain Monte Carlo (MCMC) targeting an approximate marginal of the target distribution. In the context of Bayesian latent variable models, the MCMC typically operates on the hyperparameters, and the subsequent weighting may be based on IS or sequential Monte Carlo (SMC), but allows for multilevel techniques as well. The IS approach provides a natural alternative to delayed acceptance (DA) pseudo-marginal/particle MCMC, and has many advantages over DA, including a straightforward parallelization and additional flexibility in MCMC implementation. We detail minimal conditions which ensure strong consistency of the suggested estimators, and provide central limit theorems with expressions for asymptotic variances. We demonstrate how our method can make use of SMC in the state space models context, using Laplace approximations and time-discretized diffusions. Our experimental results are promising and show that the IS-type approach can provide substantial gains relative to an analogous DA scheme, and is often competitive even without parallelization.},
  archive      = {J_SJOS},
  author       = {Matti Vihola and Jouni Helske and Jordan Franks},
  doi          = {10.1111/sjos.12492},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1339-1376},
  shortjournal = {Scand. J. Statist.},
  title        = {Importance sampling type estimators based on approximate marginal markov chain monte carlo},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Local quadratic estimation of the curvature in a functional
single index model. <em>SJOS</em>, <em>47</em>(4), 1307–1338. (<a
href="https://doi.org/10.1111/sjos.12481">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The nonlinear responses of species to environmental variability can play an important role in the maintenance of ecological diversity. Nonetheless, many models use parametric nonlinear terms which pre-determine the ecological conclusions. Motivated by this concern, we study the estimate of the second derivative (curvature) of the link function in a functional single index model. Since the coefficient function and the link function are both unknown, the estimate is expressed as a nested optimization. We first estimate the coefficient function by minimizing squared error where the link function is estimated with a Nadaraya-Watson estimator for each candidate coefficient function. The first and second derivatives of the link function are then estimated via local-quadratic regression using the estimated coefficient function. In this paper, we derive a convergence rate for the curvature of the nonlinear response. In addition, we prove that the argument of the linear predictor can be estimated root-nconsistently. However, practical implementation of the method requires solving a nonlinear optimization problem, and our results show that the estimates of the link function and the coefficient function are quite sensitive to the choices of starting values.},
  archive      = {J_SJOS},
  author       = {Zi Ye and Giles Hooker},
  doi          = {10.1111/sjos.12481},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1307-1338},
  shortjournal = {Scand. J. Statist.},
  title        = {Local quadratic estimation of the curvature in a functional single index model},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Linear censored quantile regression: A novel
minimum-distance approach. <em>SJOS</em>, <em>47</em>(4), 1275–1306. (<a
href="https://doi.org/10.1111/sjos.12475">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we investigate a new procedure for the estimation of a linear quantile regression with possibly right-censored responses. Contrary to the main literature on the subject, we propose in this context to circumvent the formulation of conditional quantiles through the so-called “check” loss function that stems from the influential work of Koenker and Bassett (1978). Instead, our suggestion is here to estimate the quantile coefficients by minimizing an alternative measure of distance. In fact, our approach could be qualified as a generalization in a parametric regression framework of the technique consisting in inverting the conditional distribution of the response given the covariates. This is motivated by the knowledge that the main literature for censored data already relies on some nonparametric conditional distribution estimation as well. The ideas of effective dimension reduction are then exploited in order to accommodate for higher dimensional settings as well in this context. Extensive numerical results then suggest that such an approach provides a strongly competitive procedure to the classical approaches based on the check function, in fact both for complete and censored observations. From a theoretical prospect, both consistency and asymptotic normality of the proposed estimator for linear regression are obtained under classical regularity conditions. As a by-product, several asymptotic results on some “double-kernel” version of the conditional Kaplan–Meier distribution estimator based on effective dimension reduction, and its corresponding density estimator, are also obtained and may be of interest on their own. A brief application of our procedure to quasar data then serves to further highlight the relevance of the latter for quantile regression estimation with censored data.},
  archive      = {J_SJOS},
  author       = {Mickaël De Backer and Anouar El Ghouch and Ingrid Van Keilegom},
  doi          = {10.1111/sjos.12475},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1275-1306},
  shortjournal = {Scand. J. Statist.},
  title        = {Linear censored quantile regression: A novel minimum-distance approach},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multiscale change point detection for dependent data.
<em>SJOS</em>, <em>47</em>(4), 1243–1274. (<a
href="https://doi.org/10.1111/sjos.12465">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article we study the theoretical properties of the simultaneous multiscale change point estimator (SMUCE) in piecewise-constant signal models with dependent error processes. Empirical studies suggest that in this case the change point estimate is inconsistent, but it is not known if alternatives suggested in the literature for correlated data are consistent. We propose a modification of SMUCE scaling the basic statistic by the long run variance of the error process, which is estimated by a difference-type variance estimator calculated from local means from different blocks. For this modification we prove model consistency for physical-dependent error processes and illustrate the finite sample performance by means of a simulation study.},
  archive      = {J_SJOS},
  author       = {Holger Dette and Theresa Eckle and Mathias Vetter},
  doi          = {10.1111/sjos.12465},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1243-1274},
  shortjournal = {Scand. J. Statist.},
  title        = {Multiscale change point detection for dependent data},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stratified proportional subdistribution hazards model with
covariate-adjusted censoring weight for case-cohort studies.
<em>SJOS</em>, <em>47</em>(4), 1222–1242. (<a
href="https://doi.org/10.1111/sjos.12461">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The case-cohort study design is widely used to reduce cost when collecting expensive covariates in large cohort studies with survival or competing risks outcomes. A case-cohort study dataset consists of two parts: (a) a random sample and (b) all cases or failures from a specific cause of interest. Clinicians often assess covariate effects on competing risks outcomes. The proportional subdistribution hazards model directly evaluates the effect of a covariate on the cumulative incidence function under the non-covariate-dependent censoring assumption for the full cohort study. However, the non-covariate-dependent censoring assumption is often violated in many biomedical studies. In this article, we propose a proportional subdistribution hazards model for case-cohort studies with stratified data with covariate-adjusted censoring weight. We further propose an efficient estimator when extra information from the other causes is available under case-cohort studies. The proposed estimators are shown to be consistent and asymptotically normal. Simulation studies show (a) the proposed estimator is unbiased when the censoring distribution depends on covariates and (b) the proposed efficient estimator gains estimation efficiency when using extra information from the other causes. We analyze a bone marrow transplant dataset and a coronary heart disease dataset using the proposed method.},
  archive      = {J_SJOS},
  author       = {Soyoung Kim and Yayun Xu and Mei-Jie Zhang and Kwang-Woo Ahn},
  doi          = {10.1111/sjos.12461},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1222-1242},
  shortjournal = {Scand. J. Statist.},
  title        = {Stratified proportional subdistribution hazards model with covariate-adjusted censoring weight for case-cohort studies},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A study on the least squares estimator of multivariate
isotonic regression function. <em>SJOS</em>, <em>47</em>(4), 1192–1221.
(<a href="https://doi.org/10.1111/sjos.12459">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider the problem of pointwise estimation offin a multivariate isotonic regression modelZ=f(X1,…,Xd)+ϵ, whereZis the response variable,fis an unknown nonparametric regression function, which is isotonic with respect to each component, andϵis the error term. In this article, we investigate the behavior of the least squares estimator off. We generalize the greatest convex minorant characterization of isotonic regression estimator for the multivariate case and use it to establish the asymptotic distribution of properly normalized version of the estimator. Moreover, we test whether the multivariate isotonic regression function at a fixed point is larger (or smaller) than a specified value or not based on this estimator, and the consistency of the test is established. The practicability of the estimator and the test are shown on simulated and real data as well.},
  archive      = {J_SJOS},
  author       = {Pramita Bagchi and Subhra Sankar Dhar},
  doi          = {10.1111/sjos.12459},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1192-1221},
  shortjournal = {Scand. J. Statist.},
  title        = {A study on the least squares estimator of multivariate isotonic regression function},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Variable screening for survival data in the presence of
heterogeneous censoring. <em>SJOS</em>, <em>47</em>(4), 1171–1191. (<a
href="https://doi.org/10.1111/sjos.12458">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variable screening for censored survival data is most challenging when both survival and censoring times are correlated with an ultrahigh-dimensional vector of covariates. Existing approaches to handling censoring often make use of inverse probability weighting by assuming independent censoring with both survival time and covariates. This is a convenient but rather restrictive assumption which may be unmet in real applications, especially when the censoring mechanism is complex and the number of covariates is large. To accommodate heterogeneous (covariate-dependent) censoring that is often present in high-dimensional survival data, we propose a Gehan-type rank screening method to select features that are relevant to the survival time. The method is invariant to monotone transformations of the response and of the predictors, and works robustly for a general class of survival models. We establish the sure screening property of the proposed methodology. Simulation studies and a lymphoma data analysis demonstrate its favorable performance and practical utility.},
  archive      = {J_SJOS},
  author       = {Jinfeng Xu and Wai Keung Li and Zhiliang Ying},
  doi          = {10.1111/sjos.12458},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1171-1191},
  shortjournal = {Scand. J. Statist.},
  title        = {Variable screening for survival data in the presence of heterogeneous censoring},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Statistical inference for multiple change-point models.
<em>SJOS</em>, <em>47</em>(4), 1149–1170. (<a
href="https://doi.org/10.1111/sjos.12456">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose a new technique for constructing confidence intervals for the mean of a noisy sequence with multiple change-points. We use the weighted bootstrap to generalize the bootstrap aggregating or bagging estimator. A standard deviation formula for the bagging estimator is introduced, based on which smoothed confidence intervals are constructed. To further improve the performance of the smoothed interval for weak signals, we suggest a strategy of adaptively choosing between the percentile intervals and the smoothed intervals. A new intensity plot is proposed to visualize the pattern of the change-points. We also propose a new change-point estimator based on the intensity plot, which has superior performance in comparison with the state-of-the-art segmentation methods. The finite sample performance of the confidence intervals and the change-point estimator are evaluated through Monte Carlo studies and illustrated with a real data example.},
  archive      = {J_SJOS},
  author       = {Wu Wang and Xuming He and Zhongyi Zhu},
  doi          = {10.1111/sjos.12456},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1149-1170},
  shortjournal = {Scand. J. Statist.},
  title        = {Statistical inference for multiple change-point models},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Post hoc false positive control for structured hypotheses.
<em>SJOS</em>, <em>47</em>(4), 1114–1148. (<a
href="https://doi.org/10.1111/sjos.12453">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a high-dimensional multiple testing framework, we present new confidence bounds on the false positives contained in subsetsSof selected null hypotheses. These bounds are post hoc in the sense that the coverage probability holds simultaneously over allS, possibly chosen depending on the data. This article focuses on the common case of structured null hypotheses, for example, along a tree, a hierarchy, or geometrically (spatially or temporally). Following recent advances in post hoc inference, we build confidence bounds for some prespecified forest-structured subsets and deduce a bound for any subsetSby interpolation. The proposed bounds are shown to improve substantially previous ones when the signal is locally structured. Our findings are supported both by theoretical results and numerical experiments. Moreover, our bounds can be obtained by an algorithm (with complexity bilinear in the sizes of the reference hierarchy and of the selected subset) that is implemented in the open-sourceRpackagesansSouciavailable fromhttps://github.com/pneuvial/sanssouci, making our approach operational.},
  archive      = {J_SJOS},
  author       = {Guillermo Durand and Gilles Blanchard and Pierre Neuvial and Etienne Roquain},
  doi          = {10.1111/sjos.12453},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1114-1148},
  shortjournal = {Scand. J. Statist.},
  title        = {Post hoc false positive control for structured hypotheses},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Computationally efficient familywise error rate control in
genome-wide association studies using score tests for generalized linear
models. <em>SJOS</em>, <em>47</em>(4), 1090–1113. (<a
href="https://doi.org/10.1111/sjos.12451">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In genetic association studies, detecting phenotype–genotype association is a primary goal. We assume that the relationship between the data—phenotype, genetic markers and environmental covariates—can be modeled by a generalized linear model. The number of markers is allowed to be far greater than the number of individuals of the study. A multivariate score statistic is used to test each marker for association with a phenotype. We assume that the test statistics asymptotically follow a multivariate normal distribution under the complete null hypothesis of no phenotype–genotype association. We present the familywise error rate orderkapproximation method to find a local significance level (alternatively, an adjustedp-value) for each test such that the familywise error rate is controlled. The special casek=1 gives the Šidák method. As a by-product, an effective number of independent tests can be defined. Furthermore, if environmental covariates and genetic markers are uncorrelated, or no environmental covariates are present, we show that covariances between score statistics depend on genetic markers alone. This not only leads to more efficient calculations but also to a local significance level that is determined only by the collection of markers used, independent of the phenotypes and environmental covariates of the experiment at hand.},
  archive      = {J_SJOS},
  author       = {Kari Krizak Halle and Øyvind Bakke and Srdjan Djurovic and Anja Bye and Einar Ryeng and Ulrik Wisløff and Ole A. Andreassen and Mette Langaas},
  doi          = {10.1111/sjos.12451},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1090-1113},
  shortjournal = {Scand. J. Statist.},
  title        = {Computationally efficient familywise error rate control in genome-wide association studies using score tests for generalized linear models},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hypothesis testing for quantitative trait locus effects in
both location and scale in genetic backcross studies. <em>SJOS</em>,
<em>47</em>(4), 1064–1089. (<a
href="https://doi.org/10.1111/sjos.12442">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Testing the existence of a quantitative trait locus (QTL) effect is an important task in QTL mapping studies. Most studies concentrate on the case where the phenotype distributions of different QTL groups follow normal distributions with the same unknown variance. In this paper we make a more general assumption that the phenotype distributions come from a location-scale distribution family. We derive the limiting distribution of the likelihood ratio test (LRT) for the existence of the QTL effect in both location and scale in genetic backcross studies. We further identify an explicit representation for this limiting distribution. As a complement, we study the limiting distribution of the LRT and its explicit representation for the existence of the QTL effect in the location only. The asymptotic properties of the LRTs under a local alternative are also investigated. Simulation studies are used to evaluate the asymptotic results, and a real-data example is included for illustration.},
  archive      = {J_SJOS},
  author       = {Guanfu Liu and Pengfei Li and Yukun Liu and Xiaolong Pu},
  doi          = {10.1111/sjos.12442},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1064-1089},
  shortjournal = {Scand. J. Statist.},
  title        = {Hypothesis testing for quantitative trait locus effects in both location and scale in genetic backcross studies},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Failure time studies with intermittent observation and
losses to follow-up. <em>SJOS</em>, <em>47</em>(4), 1035–1063. (<a
href="https://doi.org/10.1111/sjos.12471">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In health research interest often lies in modeling a failure time process but in many cohort studies failure status is only determined at scheduled assessment times. While the assessment times may be fixed upon study entry, individuals may become lost to follow-up and miss visits subsequent to the time of loss to follow-up. We consider a three-state model to characterize a joint failure and loss to follow-up process, and use it to investigate the impact of dependent loss to follow-up on standard parametric, nonparametric, and semiparametric analysis. The effect of dependent loss to follow-up is mitigated by fitting the joint model. The performance of standard methods is studied using the asymptotic theory of misspecified models, and the finite sample performance is examined for the standard and joint analyses through simulation studies. An application to data from a youth smoking prevention study is presented for illustration.},
  archive      = {J_SJOS},
  author       = {Richard J. Cook and Jerald F. Lawless},
  doi          = {10.1111/sjos.12471},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1035-1063},
  shortjournal = {Scand. J. Statist.},
  title        = {Failure time studies with intermittent observation and losses to follow-up},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Orientation relationship in finite dimensional space.
<em>SJOS</em>, <em>47</em>(3), 1011–1034. (<a
href="https://doi.org/10.1111/sjos.12479">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the present article, we discuss the regression of a point on the surface of a unit sphere inddimensions given a point on the surface of a unit sphere inpdimensions, wherepmay not be equal tod. Point projection is added to the rotation and linear transformation for regression link function. The identifiability of the model is proved. Then, parameter estimation in this set up is discussed. Simulation studies and data analyses are done to illustrate the model.},
  archive      = {J_SJOS},
  author       = {Jayant Jha and Atanu Biswas},
  doi          = {10.1111/sjos.12479},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {1011-1034},
  shortjournal = {Scand. J. Statist.},
  title        = {Orientation relationship in finite dimensional space},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Conditional covariance penalties for mixed models.
<em>SJOS</em>, <em>47</em>(3), 990–1010. (<a
href="https://doi.org/10.1111/sjos.12437">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prediction error for mixed models can have a conditional or a marginal perspective depending on the research focus. We introduce a novel conditional version of the optimism theorem for mixed models linking the conditional prediction error to covariance penalties for mixed models. Different possibilities for estimating these conditional covariance penalties are introduced. These are bootstrap methods, cross-validation, and a direct approach calledSteinian. The behavior of the different estimation techniques is assessed in a simulation study for the binomial-, the t-, and the gamma distribution and for different kinds of prediction error. Furthermore, the impact of the estimation techniques on the prediction error is discussed based on an application to undernutrition in Zambia.},
  archive      = {J_SJOS},
  author       = {Benjamin Säfken and Thomas Kneib},
  doi          = {10.1111/sjos.12437},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {990-1010},
  shortjournal = {Scand. J. Statist.},
  title        = {Conditional covariance penalties for mixed models},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Asymptotic normality of generalized maximum spacing
estimators for multivariate observations. <em>SJOS</em>, <em>47</em>(3),
968–989. (<a href="https://doi.org/10.1111/sjos.12436">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the maximum spacing method is considered for multivariate observations. Nearest neighbor balls are used as a multidimensional analogue to univariate spacings. A class of information-type measures is used to generalize the concept of maximum spacing estimators of model parameters. Asymptotic normality of these generalized maximum spacing estimators is proved when the assigned model class is correct, that is, the true density is a member of the model class.},
  archive      = {J_SJOS},
  author       = {Kristi Kuljus and Bo Ranneby},
  doi          = {10.1111/sjos.12436},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {968-989},
  shortjournal = {Scand. J. Statist.},
  title        = {Asymptotic normality of generalized maximum spacing estimators for multivariate observations},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Implementing monte carlo tests with p-value buckets.
<em>SJOS</em>, <em>47</em>(3), 950–967. (<a
href="https://doi.org/10.1111/sjos.12434">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software packages usually report the results of statistical tests using p-values. Users often interpret these values by comparing them with standard thresholds, for example, 0.1, 1, and 5\%, which is sometimes reinforced by a star rating (***, **, and *, respectively). We consider an arbitrary statistical test whose p-valuepis not available explicitly, but can be approximated by Monte Carlo samples, for example, by bootstrap or permutation tests. The standard implementation of such tests usually draws a fixed number of samples to approximatep. However, the probability that the exact and the approximated p-value lie on different sides of a threshold (the resampling risk) can be high, particularly for p-values close to a threshold. We present a method to overcome this. We consider a finite set of user-specified intervals that cover [0, 1] and that can be overlapping. We call these p-value buckets. We present algorithms that, with arbitrarily high probability, return a p-value bucket containingp. We prove that for both a bounded resampling risk and a finite runtime, overlapping buckets need to be employed, and that our methods both bound the resampling risk and guarantee a finite runtime for such overlapping buckets. To interpret decisions with overlapping buckets, we propose an extension of the star rating system. We demonstrate that our methods are suitable for use in standard software, including for low p-value thresholds occurring in multiple testing settings, and that they can be computationally more efficient than standard implementations.},
  archive      = {J_SJOS},
  author       = {Axel Gandy and Georg Hahn and Dong Ding},
  doi          = {10.1111/sjos.12434},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {950-967},
  shortjournal = {Scand. J. Statist.},
  title        = {Implementing monte carlo tests with p-value buckets},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Beyond tail median and conditional tail expectation: Extreme
risk estimation using tail lp-optimization. <em>SJOS</em>,
<em>47</em>(3), 922–949. (<a
href="https://doi.org/10.1111/sjos.12433">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The conditional tail expectation (CTE) is an indicator of tail behavior that takes into account both the frequency and magnitude of a tail event. However, the asymptotic normality of its empirical estimator requires that the underlying distribution possess a finite variance; this can be a strong restriction in actuarial and financial applications. A valuable alternative is the median shortfall (MS), although it only gives information about the frequency of a tail event. We construct a class of tailLp-medians encompassing the MS and CTE. Forpin (1,2), a tailLp-median depends on both the frequency and magnitude of tail events, and its empirical estimator is, within the range of the data, asymptotically normal under a condition weaker than a finite variance. We extrapolate this estimator and another technique to extreme levels using the heavy-tailed framework. The estimators are showcased on a simulation study and on real fire insurance data.},
  archive      = {J_SJOS},
  author       = {Laurent Gardes and Stéphane Girard and Gilles Stupfler},
  doi          = {10.1111/sjos.12433},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {922-949},
  shortjournal = {Scand. J. Statist.},
  title        = {Beyond tail median and conditional tail expectation: Extreme risk estimation using tail lp-optimization},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Geometric consistency of principal component scores for
high-dimensional mixture models and its application. <em>SJOS</em>,
<em>47</em>(3), 899–921. (<a
href="https://doi.org/10.1111/sjos.12432">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we consider clustering based on principal component analysis (PCA) for high-dimensional mixture models. We present theoretical reasons why PCA is effective for clustering high-dimensional data. First, we derive a geometric representation of high-dimension, low-sample-size (HDLSS) data taken from a two-class mixture model. With the help of the geometric representation, we give geometric consistency properties of sample principal component scores in the HDLSS context. We develop ideas of the geometric representation and provide geometric consistency properties for multiclass mixture models. We show that PCA can cluster HDLSS data under certain conditions in a surprisingly explicit way. Finally, we demonstrate the performance of the clustering using gene expression datasets.},
  archive      = {J_SJOS},
  author       = {Kazuyoshi Yata and Makoto Aoshima},
  doi          = {10.1111/sjos.12432},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {899-921},
  shortjournal = {Scand. J. Statist.},
  title        = {Geometric consistency of principal component scores for high-dimensional mixture models and its application},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient volatility estimation in a two-factor model.
<em>SJOS</em>, <em>47</em>(3), 862–898. (<a
href="https://doi.org/10.1111/sjos.12431">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We statistically analyze a multivariate Heath-Jarrow-Morton diffusion model with stochastic volatility. The volatility process of the first factor is left totally unspecified while the volatility of the second factor is the product of an unknown process and an exponential function of time to maturity. This exponential term includes some real parameter measuring the rate of increase of the second factor as time goes to maturity. From historical data, we efficiently estimate the time to maturity parameter in the sense of constructing an estimator that achieves an optimal information bound in a semiparametric setting. We also nonparametrically identify the paths of the volatility processes and achieve minimax bounds. We address the problem of degeneracy that occurs when the dimension of the process is greater than two, and give in particular optimal limit theorems under suitable regularity assumptions on the drift process. We consistently analyze the numerical behavior of our estimators on simulated and real datasets of prices of forward contracts on electricity markets.},
  archive      = {J_SJOS},
  author       = {Olivier Féron and Pierre Gruet and Marc Hoffmann},
  doi          = {10.1111/sjos.12431},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {862-898},
  shortjournal = {Scand. J. Statist.},
  title        = {Efficient volatility estimation in a two-factor model},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Asymptotic theory and inference of predictive mean matching
imputation using a superpopulation model framework. <em>SJOS</em>,
<em>47</em>(3), 839–861. (<a
href="https://doi.org/10.1111/sjos.12429">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predictive mean matching imputation is popular for handling item nonresponse in survey sampling. In this article, we study the asymptotic properties of the predictive mean matching estimator for finite-population inference using a superpopulation model framework. We also clarify conditions for its robustness. For variance estimation, the conventional bootstrap inference is invalid for matching estimators with a fixed number of matches due to the nonsmoothness nature of the matching estimator. We propose a new replication variance estimator, which is asymptotically valid. The key strategy is to construct replicates directly based on the linear terms of the martingale representation for the matching estimator, instead of individual records of variables. Simulation studies confirm that the proposed method provides valid inference.},
  archive      = {J_SJOS},
  author       = {Shu Yang and Jae Kwang Kim},
  doi          = {10.1111/sjos.12429},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {839-861},
  shortjournal = {Scand. J. Statist.},
  title        = {Asymptotic theory and inference of predictive mean matching imputation using a superpopulation model framework},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Confidence intervals for variance component ratios in
unbalanced linear mixed models. <em>SJOS</em>, <em>47</em>(3), 817–838.
(<a href="https://doi.org/10.1111/sjos.12428">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Methods for constructing confidence intervals for variance component ratios in general unbalanced mixed models are developed. The methods are based on inverting the distribution of the signed root of the log-likelihood ratio statistic constructed from either the restricted maximum likelihood or the full likelihood. As this distribution is intractable, the inversion is rather based on using a saddlepoint approximation to its distribution. Apart from Wald&#39;s exact method, the resulting intervals are unrivalled in terms of achieving accuracy in overall coverage, underage, and overage. Issues related to the proper “reference set” with which to judge the coverage as well as issues connected to variance ratios being nonnegative with lower bound 0 are addressed. Applications include an unbalanced nested design and an unbalanced crossed design.},
  archive      = {J_SJOS},
  author       = {Mahesh N. Fernando and Ronald W. Butler},
  doi          = {10.1111/sjos.12428},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {817-838},
  shortjournal = {Scand. J. Statist.},
  title        = {Confidence intervals for variance component ratios in unbalanced linear mixed models},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An autoregressive model based on the generalized hyperbolic
distribution. <em>SJOS</em>, <em>47</em>(3), 787–816. (<a
href="https://doi.org/10.1111/sjos.12427">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We define a nonlinear autoregressive time series model based on the generalized hyperbolic distribution in an attempt to model time series with non-Gaussian features such as skewness and heavy tails. We show that the resulting process has a simple condition for stationarity and it is also ergodic. An empirical example with a forecasting experiment is presented to illustrate the features of the proposed model.},
  archive      = {J_SJOS},
  author       = {Henri Karttunen},
  doi          = {10.1111/sjos.12427},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {787-816},
  shortjournal = {Scand. J. Statist.},
  title        = {An autoregressive model based on the generalized hyperbolic distribution},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Combined multiple testing of multivariate survival times by
censored empirical likelihood. <em>SJOS</em>, <em>47</em>(3), 757–786.
(<a href="https://doi.org/10.1111/sjos.12423">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In each study testing the survival experience of one or more populations, one must not only choose an appropriate class of tests, but further an appropriate weight function. As the optimal choice depends on the true shape of the hazard ratio, one is often not capable of getting the best results with respect to a specific dataset. For the univariate case several methods were proposed to conquer this problem. However, most of the interesting datasets contain multivariate observations nowadays. In this work we propose a multivariate version of a method based on multiple constrained censored empirical likelihood where the constraints are formulated as linear functionals of the cumulative hazard functions. By considering the conditional hazards, we take the correlation between the components into account with the goal of obtaining a test that exhibits a high power irrespective of the shape of the hazard ratio under the alternative hypothesis.},
  archive      = {J_SJOS},
  author       = {Judith H. Parkinson},
  doi          = {10.1111/sjos.12423},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {757-786},
  shortjournal = {Scand. J. Statist.},
  title        = {Combined multiple testing of multivariate survival times by censored empirical likelihood},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The null hypothesis of (common) jumps in case of irregular
and asynchronous observations. <em>SJOS</em>, <em>47</em>(3), 711–756.
(<a href="https://doi.org/10.1111/sjos.12422">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes novel tests for the absence of jumps in a univariate semimartingale and for the absence of common jumps in a bivariate semimartingale. Our methods rely on ratio statistics of power variations based on irregular observations, sampled at different frequencies. We develop central limit theorems for the statistics under the respective null hypotheses and apply bootstrap procedures to assess the limiting distributions. Furthermore, we define corrected statistics to improve the finite sample performance. Simulations show that the test based on our corrected statistic yields good results and even outperforms existing tests in the case of regular observations.},
  archive      = {J_SJOS},
  author       = {Ole Martin and Mathias Vetter},
  doi          = {10.1111/sjos.12422},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {711-756},
  shortjournal = {Scand. J. Statist.},
  title        = {The null hypothesis of (common) jumps in case of irregular and asynchronous observations},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On aggregation of strongly dependent time series.
<em>SJOS</em>, <em>47</em>(3), 690–710. (<a
href="https://doi.org/10.1111/sjos.12421">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider cross-sectional aggregation of time series with long-range dependence. This question arises for instance from the statistical analysis of networks where aggregation is defined via routing matrices. Asymptotically, aggregation turns out to increase dependence substantially, transforming a hyperbolic decay of autocorrelations to a slowly varying rate. This effect has direct consequences for statistical inference. For instance, unusually slow rates of convergence for nonparametric trend estimators and nonstandard formulas for optimal bandwidths are obtained. The situation changes, when time-dependent aggregation is applied. Suitably chosen time-dependent aggregation schemes can preserve a hyperbolic rate or even eliminate autocorrelations completely.},
  archive      = {J_SJOS},
  author       = {Jan Beran and Haiyan Liu and Sucharita Ghosh},
  doi          = {10.1111/sjos.12421},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {690-710},
  shortjournal = {Scand. J. Statist.},
  title        = {On aggregation of strongly dependent time series},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Concordance-based estimation approaches for the optimal
sufficient dimension reduction score. <em>SJOS</em>, <em>47</em>(3),
662–689. (<a href="https://doi.org/10.1111/sjos.12420">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To characterize the dependence of a response on covariates of interest, a monotonic structure is linked to a multivariate polynomial transformation of the central subspace (CS) directions with unknown structural degree and dimension. Under a very general semiparametric model formulation, such a sufficient dimension reduction (SDR) score is shown to enjoy the existence, optimality, and uniqueness up to scale and location in the defined concordance probability function. In light of these properties and its single-index representation, two types of concordance-based generalized Bayesian information criteria are constructed to estimate the optimal SDR score and the maximum concordance index. The estimation criteria are further carried out by effective computational procedures. Generally speaking, the outer product of gradients estimation in the first approach has an advantage in computational efficiency and the parameterization system in the second approach greatly reduces the number of parameters in estimation. Different from most existing SDR approaches, only one CS direction is required to be continuous in the proposals. Moreover, the consistency of structural degree and dimension estimators and the asymptotic normality of the optimal SDR score and maximum concordance index estimators are established under some suitable conditions. The performance and practicality of our methodology are also investigated through simulations and empirical illustrations.},
  archive      = {J_SJOS},
  author       = {Shao-Hsuan Wang and Chin-Tsang Chiang},
  doi          = {10.1111/sjos.12420},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {662-689},
  shortjournal = {Scand. J. Statist.},
  title        = {Concordance-based estimation approaches for the optimal sufficient dimension reduction score},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stochastic functional estimates in longitudinal models with
interval-censored anchoring events. <em>SJOS</em>, <em>47</em>(3),
638–661. (<a href="https://doi.org/10.1111/sjos.12419">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Timelines of longitudinal studies are often anchored by specific events. In the absence of the fully observed anchoring event times, the study timeline becomes undefined, and the traditional longitudinal analysis loses its temporal reference. In this paper, we considered an analytical situation where the anchoring events are interval censored. We demonstrated that by expressing the regression parameter estimators as stochastic functionals of a plug-in estimate of the unknown anchoring event time distribution, the standard longitudinal models could be extended to accommodate the situation of less well-defined timelines. We showed that for a broad class of longitudinal models, the functional parameter estimates are consistent and asymptotically normally distributed with anconvergence rate under mild regularity conditions. Applying the developed theory to linear mixed-effects models, we further proposed a hybrid computational procedure that combines the strengths of the Fisher&#39;s scoring method and the expectation-expectation (EM) algorithm for model parameter estimation. We conducted a simulation study to validate the asymptotic properties and to assess the finite sample performance of the proposed method. A real data example was used to illustrate the proposed method. The method fills in a gap in the existing longitudinal analysis methodology for data with less well-defined timelines.},
  archive      = {J_SJOS},
  author       = {Chenghao Chu and Ying Zhang and Wanzhu Tu},
  doi          = {10.1111/sjos.12419},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {638-661},
  shortjournal = {Scand. J. Statist.},
  title        = {Stochastic functional estimates in longitudinal models with interval-censored anchoring events},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Maximum likelihood drift estimation for a threshold
diffusion. <em>SJOS</em>, <em>47</em>(3), 609–637. (<a
href="https://doi.org/10.1111/sjos.12417">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the maximum likelihood estimator of the drift parameters of a stochastic differential equation, with both drift and diffusion coefficients constant on the positive and negative axis, yet discontinuous at zero. This threshold diffusion is called drifted oscillating Brownian motion. For this continuously observed diffusion, the maximum likelihood estimator coincides with a quasi-likelihood estimator with constant diffusion term. We show that this estimator is the limit, as observations become dense in time, of the (quasi)-maximum likelihood estimator based on discrete observations. In long time, the asymptotic behaviors of the positive and negative occupation times rule the ones of the estimators. Differently from most known results of the literature, we do not restrict ourselves to the ergodic framework: indeed, depending on the signs of the drift, the process may be ergodic, transient, or null recurrent. For each regime, we establish whether or not the estimators are consistent; if they are, we prove the convergence in long time of the properly rescaled difference of the estimators towards a normal or mixed normal distribution. These theoretical results are backed by numerical simulations.},
  archive      = {J_SJOS},
  author       = {Antoine Lejay and Paolo Pigato},
  doi          = {10.1111/sjos.12417},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {609-637},
  shortjournal = {Scand. J. Statist.},
  title        = {Maximum likelihood drift estimation for a threshold diffusion},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Variable selection and estimation for high-dimensional
spatial autoregressive models. <em>SJOS</em>, <em>47</em>(2), 587–607.
(<a href="https://doi.org/10.1111/sjos.12452">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatial regression models are important tools for many scientific disciplines including economics, business, and social science. In this article, we investigate postmodel selection estimators that apply least squares estimation to the model selected by penalized estimation in high-dimensional regression models with spatial autoregressive errors. We show that by separating the model selection and estimation process, the postmodel selection estimator performs at least as well as the simultaneous variable selection and estimation method in terms of the rate of convergence. Moreover, under perfect model selection, theℓ2rate of convergence is the oracle rate ofs/n, compared with the convergence rate ofslogp/nin the general case. Here,nis the sample size andp,sare the model dimension and number of significant covariates, respectively. We further provide the convergence rate of the estimation error in the form ofsupnorm, and ideally the rate can reach as fast aslogs/n.},
  archive      = {J_SJOS},
  author       = {Liqian Cai and Tapabrata Maiti},
  doi          = {10.1111/sjos.12452},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {587-607},
  shortjournal = {Scand. J. Statist.},
  title        = {Variable selection and estimation for high-dimensional spatial autoregressive models},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dynamic inference for non-markov transition probabilities
under random right censoring. <em>SJOS</em>, <em>47</em>(2), 572–586.
(<a href="https://doi.org/10.1111/sjos.12443">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main contribution of this article is the verification of weak convergence of a general non-Markov (NM) state transition probability estimator by Titman, which has not yet been done for any other general NM estimator. A similar theorem is shown for the bootstrap, yielding resampling-based inference methods for statistical functionals. Formulas of the involved covariance functions are presented in detail. Particular applications include the conditional expected length of stay in a specific state, given occupation of another state in the past, and the construction of time-simultaneous confidence bands for the transition probabilities. The expected lengths of stay in a two-sample liver cirrhosis dataset are compared and confidence intervals for their difference are constructed. With borderline significance and in comparison to the placebo group, the treatment group has an elevated expected length of stay in the healthy state given an earlier disease state occupation. In contrast, the Aalen-Johansen (AJ) estimator-based confidence interval, which relies on a Markov assumption, leads to a drastically different conclusion. Also, graphical illustrations of confidence bands for the transition probabilities demonstrate the biasedness of the AJ estimator in this data example. The reliability of these results is assessed in a simulation study.},
  archive      = {J_SJOS},
  author       = {Dennis Dobler and Andrew Titman},
  doi          = {10.1111/sjos.12443},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {572-586},
  shortjournal = {Scand. J. Statist.},
  title        = {Dynamic inference for non-markov transition probabilities under random right censoring},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Semiparametric multiparameter regression survival modeling.
<em>SJOS</em>, <em>47</em>(2), 555–571. (<a
href="https://doi.org/10.1111/sjos.12416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a log-linear model for survival data, where both the location and scale parameters depend on covariates, and the baseline hazard function is completely unspecified. This model provides the flexibility needed to capture many interesting features of survival data at a relatively low cost in model complexity. Estimation procedures are developed, and asymptotic properties of the resulting estimators are derived using empirical process theory. Finally, a resampling procedure is developed to estimate the limiting variances of the estimators. The finite sample properties of the estimators are investigated by way of a simulation study, and a practical application to lung cancer data is illustrated.},
  archive      = {J_SJOS},
  author       = {Kevin Burke and Frank Eriksson and C. B. Pipper},
  doi          = {10.1111/sjos.12416},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {555-571},
  shortjournal = {Scand. J. Statist.},
  title        = {Semiparametric multiparameter regression survival modeling},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Consistent procedures for multiclass classification of
discrete diffusion paths. <em>SJOS</em>, <em>47</em>(2), 516–554. (<a
href="https://doi.org/10.1111/sjos.12415">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent advent of modern technology has generated a large number of datasets which can be frequently modeled as functional data. This paper focuses on the problem of multiclass classification for stochastic diffusion paths. In this context we establish a closed formula for the optimal Bayes rule. We provide new statistical procedures which are built either on theplug-inprinciple or on the empirical risk minimization principle. We show the consistency of these procedures under mild conditions. We apply our methodologies to the parametric case and illustrate their accuracy with a simulation study through examples.},
  archive      = {J_SJOS},
  author       = {Christophe Denis and Charlotte Dion and Miguel Martinez},
  doi          = {10.1111/sjos.12415},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {516-554},
  shortjournal = {Scand. J. Statist.},
  title        = {Consistent procedures for multiclass classification of discrete diffusion paths},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Linear hypothesis testing for weighted functional data with
applications. <em>SJOS</em>, <em>47</em>(2), 493–515. (<a
href="https://doi.org/10.1111/sjos.12414">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In socioeconomic areas, functional observations may be collected with weights, called weighted functional data. In this paper, we deal with a general linear hypothesis testing (GLHT) problem in the framework of functional analysis of variance with weighted functional data. With weights taken into account, we obtain unbiased and consistent estimators of the group mean and covariance functions. For the GLHT problem, we obtain a pointwiseF-test statistic and build two global tests, respectively, via integrating the pointwiseF-test statistic or taking its supremum over an interval of interest. The asymptotic distributions of test statistics under the null and some local alternatives are derived. Methods for approximating their null distributions are discussed. An application of the proposed methods to density function data is also presented. Intensive simulation studies and two real data examples show that the proposed tests outperform the existing competitors substantially in terms of size control and power.},
  archive      = {J_SJOS},
  author       = {Łukasz Smaga and Jin-Ting Zhang},
  doi          = {10.1111/sjos.12414},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {493-515},
  shortjournal = {Scand. J. Statist.},
  title        = {Linear hypothesis testing for weighted functional data with applications},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Decompounding discrete distributions: A nonparametric
bayesian approach. <em>SJOS</em>, <em>47</em>(2), 464–492. (<a
href="https://doi.org/10.1111/sjos.12413">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Suppose that a compound Poisson process is observed discretely in time and assume that its jump distribution is supported on the set of natural numbers. In this paper we propose a nonparametric Bayesian approach to estimate the intensity of the underlying Poisson process and the distribution of the jumps. We provide a Markov chain Monte Carlo scheme for obtaining samples from the posterior. We apply our method on both simulated and real data examples, and compare its performance with the frequentist plug-in estimator proposed by Buchmann and Grübel. On a theoretical side, we study the posterior from the frequentist point of view and prove that as the sample sizen→∞, it contracts around the “true,” data-generating parameters at rate1/n, up to alognfactor.},
  archive      = {J_SJOS},
  author       = {Shota Gugushvili and Ester Mariucci and Frank van der Meulen},
  doi          = {10.1111/sjos.12413},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {464-492},
  shortjournal = {Scand. J. Statist.},
  title        = {Decompounding discrete distributions: A nonparametric bayesian approach},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Change-point detection in a linear model by adaptive fused
quantile method. <em>SJOS</em>, <em>47</em>(2), 425–463. (<a
href="https://doi.org/10.1111/sjos.12412">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel approach to quantile estimation in multivariate linear regression models with change-points is proposed: the change-point detection and the model estimation are both performed automatically, by adopting either the quantile-fused penalty or the adaptive version of the quantile-fused penalty. These two methods combine the idea of the check function used for the quantile estimation and theL1penalization principle known from the signal processing and, unlike some standard approaches, the presented methods go beyond typical assumptions usually required for the model errors, such as sub-Gaussian or normal distribution. They can effectively handle heavy-tailed random error distributions, and, in general, they offer a more complex view on the data as one can obtain any conditional quantile of the target distribution, not just the conditional mean. The consistency of detection is proved and proper convergence rates for the parameter estimates are derived. The empirical performance is investigated via an extensive comparative simulation study and practical utilization is demonstrated using a real data example.},
  archive      = {J_SJOS},
  author       = {Gabriela Ciuperca and Matúš Maciak},
  doi          = {10.1111/sjos.12412},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {425-463},
  shortjournal = {Scand. J. Statist.},
  title        = {Change-point detection in a linear model by adaptive fused quantile method},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). How to ask sensitive multiple-choice questions.
<em>SJOS</em>, <em>47</em>(2), 397–424. (<a
href="https://doi.org/10.1111/sjos.12411">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by recent failures of polling to estimate populist party support, we propose and analyze two methods for asking sensitive multiple-choice questions where the respondent retains some privacy and therefore might answer more truthfully. The first method consists of asking for the true choice along with a choice picked at random. The other method presents a list of choices and asks whether the preferred one is on the list or not. Different respondents are shown different lists. The methods are easy to explain, which makes it likely that the respondent understands how her privacy is protected and may thus entice her to participate in the survey and answer truthfully. The methods are also easy to implement and scale up.},
  archive      = {J_SJOS},
  author       = {Andreas Lagerås and Mathias Lindholm},
  doi          = {10.1111/sjos.12411},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {397-424},
  shortjournal = {Scand. J. Statist.},
  title        = {How to ask sensitive multiple-choice questions},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Parallelizing particle filters with butterfly interactions.
<em>SJOS</em>, <em>47</em>(2), 361–396. (<a
href="https://doi.org/10.1111/sjos.12408">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The bootstrap particle filter (BPF) is the cornerstone of many algorithms used for solving generally intractable inference problems with hidden Markov models. The long-term stability of the BPF arises from particle interactions that typically make parallel implementations of the BPF nontrivial. We propose a method whereby particle interaction is done in several stages. With the proposed method, full interaction can be accomplished even if we allow only pairwise communications between processing elements at each stage. We show that our method preserves the consistency and the long-term stability of the BPF, although our analysis suggests that the constraints on the stagewise interactions introduce errors leading to a lower convergence rate than standard Monte Carlo. The proposed method also suggests a new, more flexible, adaptive resampling scheme, which, according to our numerical experiments, is the method of choice, displaying a notable gain in efficiency in certain parallel computing scenarios.},
  archive      = {J_SJOS},
  author       = {Kari Heine and Nick Whiteley and A.Taylan Cemgil},
  doi          = {10.1111/sjos.12408},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {361-396},
  shortjournal = {Scand. J. Statist.},
  title        = {Parallelizing particle filters with butterfly interactions},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Outlier detection in contingency tables using decomposable
graphical models. <em>SJOS</em>, <em>47</em>(2), 347–360. (<a
href="https://doi.org/10.1111/sjos.12407">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For high-dimensional data, it is a tedious task to determine anomalies such as outliers. We present a novel outlier detection method for high-dimensional contingency tables. We use the class of decomposable graphical models to model the relationship among the variables of interest, which can be depicted by an undirected graph called theinteraction graph. Given an interaction graph, we derive a closed-form expression of the likelihood ratio test (LRT) statistic and an exact distribution for efficient simulation of the test statistic. An observation is declared an outlier if it deviates significantly from the approximated distribution of the test statistic under the null hypothesis. We demonstrate the use of the LRT outlier detection framework on genetic data modeled by Chow–Liu trees.},
  archive      = {J_SJOS},
  author       = {Mads Lindskou and Poul Svante Eriksen and Torben Tvedebrink},
  doi          = {10.1111/sjos.12407},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {347-360},
  shortjournal = {Scand. J. Statist.},
  title        = {Outlier detection in contingency tables using decomposable graphical models},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Contrast function estimation for the drift parameter of
ergodic jump diffusion process. <em>SJOS</em>, <em>47</em>(2), 279–346.
(<a href="https://doi.org/10.1111/sjos.12406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider an ergodic diffusion process with jumps whose drift coefficient depends on an unknown parameter. We suppose that the process is discretely observed. We introduce an estimator based on a contrast function, which is efficient without requiring any conditions on the rate at which the step discretization goes to zero, and where we allow the observed process to have nonsummable jumps. This extends earlier results where the condition on the step discretization was needed and where the process was supposed to have summable jumps. In general situations, our contrast function is not explicit and one has to resort to some approximation. In the case of a finite jump activity, we propose explicit approximations of the contrast function such that the efficient estimation of the drift parameter is feasible. This extends the results obtained by Kessler in the case of continuous processes.},
  archive      = {J_SJOS},
  author       = {Chiara Amorino and Arnaud Gloter},
  doi          = {10.1111/sjos.12406},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {279-346},
  shortjournal = {Scand. J. Statist.},
  title        = {Contrast function estimation for the drift parameter of ergodic jump diffusion process},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multiple-output quantile regression through optimal
quantization. <em>SJOS</em>, <em>47</em>(1), 250–278. (<a
href="https://doi.org/10.1111/sjos.12426">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new nonparametric quantile regression method based on the concept of optimal quantization was developed recently and was showed to provide estimators that often dominate their classical, kernel-type, competitors. In the present work, we extend this method to multiple-output regression problems. We show how quantization allows approximating population multiple-output regression quantiles based on halfspace depth. We prove that this approximation becomes arbitrarily accurate as the size of the quantization grid goes to infinity. We also derive a weak consistency result for a sample version of the proposed regression quantiles. Through simulations, we compare the performances of our estimators with (local constant and local bilinear) kernel competitors. The results reveal that the proposed quantization-based estimators, which are local constant in nature, outperform their kernel counterparts and even often dominate their local bilinear kernel competitors. The various approaches are also compared on artificial and real data.},
  archive      = {J_SJOS},
  author       = {Isabelle Charlier and Davy Paindaveine and Jérôme Saracco},
  doi          = {10.1111/sjos.12426},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {250-278},
  shortjournal = {Scand. J. Statist.},
  title        = {Multiple-output quantile regression through optimal quantization},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Inferactive data analysis. <em>SJOS</em>, <em>47</em>(1),
212–249. (<a href="https://doi.org/10.1111/sjos.12425">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We describeinferactive data analysis, so-named to denote an interactive approach to data analysis with an emphasis on inference after data analysis. Our approach is a compromise between Tukey&#39;s exploratory and confirmatory data analysis allowing also for Bayesian data analysis. We see this as a useful step in concrete providing tools (with statistical guarantees) for current data scientists. The basis of inference we use is (a conditional approach to)selective inference, in particular its randomized form. The relevant reference distributions are constructed from what we call a DAG-DAG—a Data Analysis Generative DAG, and a selective change of variables formula is crucial to any practical implementation of inferactive data analysis via sampling these distributions. We discuss a canonical example of an incomplete cross-validation test statistic to discriminate between black box models, and a real HIV dataset example to illustrate inference after making multiple queries on data.},
  archive      = {J_SJOS},
  author       = {Nan Bi and Jelena Markovic and Lucy Xia and Jonathan Taylor},
  doi          = {10.1111/sjos.12425},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {212-249},
  shortjournal = {Scand. J. Statist.},
  title        = {Inferactive data analysis},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Exact dimensionality selection for bayesian PCA.
<em>SJOS</em>, <em>47</em>(1), 196–211. (<a
href="https://doi.org/10.1111/sjos.12424">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a Bayesian model selection approach to estimate the intrinsic dimensionality of a high-dimensional dataset. To this end, we introduce a novel formulation of the probabilisitic principal component analysis model based on a normal-gamma prior distribution. In this context, we exhibit a closed-form expression of the marginal likelihood which allows to infer an optimal number of components. We also propose a heuristic based on the expected shape of the marginal likelihood curve in order to choose the hyperparameters. In nonasymptotic frameworks, we show on simulated data that this exact dimensionality selection approach is competitive with both Bayesian and frequentist state-of-the-art methods.},
  archive      = {J_SJOS},
  author       = {Charles Bouveyron and Pierre Latouche and Pierre-Alexandre Mattei},
  doi          = {10.1111/sjos.12424},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {196-211},
  shortjournal = {Scand. J. Statist.},
  title        = {Exact dimensionality selection for bayesian PCA},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Local whittle likelihood approach for generalized
divergence. <em>SJOS</em>, <em>47</em>(1), 182–195. (<a
href="https://doi.org/10.1111/sjos.12418">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are many approaches in the estimation of spectral density. With regard to parametric approaches, different divergences are proposed in fitting a certain parametric family of spectral densities. Moreover, nonparametric approaches are also quite common considering the situation when we cannot specify the model of process. In this paper, we develop a local Whittle likelihood approach based on a general score function, with some special cases of which, the approach applies to more applications. This paper highlights the effective asymptotics of our general local Whittle estimator, and presents a comparison with other estimators. Additionally, for a special case, we construct the one-step ahead predictor based on the form of the score function. Subsequently, we show that it has a smaller prediction error than the classical exponentially weighted linear predictor. The provided numerical studies show some interesting features of our local Whittle estimator.},
  archive      = {J_SJOS},
  author       = {Yujie Xue and Masanobu Taniguchi},
  doi          = {10.1111/sjos.12418},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {182-195},
  shortjournal = {Scand. J. Statist.},
  title        = {Local whittle likelihood approach for generalized divergence},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Degree-based goodness-of-fit tests for heterogeneous random
graph models: Independent and exchangeable cases. <em>SJOS</em>,
<em>47</em>(1), 156–181. (<a
href="https://doi.org/10.1111/sjos.12410">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The degrees are a classical and relevant way to study the topology of a network. They can be used to assess the goodness of fit for a given random graph model. In this paper, we introduce goodness-of-fit tests for two classes of models. First, we consider the case of independent graph models such as the heterogeneous Erdös-Rényi model in which the edges have different connection probabilities. Second, we consider a generic model for exchangeable random graphs called theW-graph. The stochastic block model and the expected degree distribution model fall within this framework. We prove the asymptotic normality of the degree mean square under these independent and exchangeable models and derive formal tests. We study the power of the proposed tests and we prove the asymptotic normality under specific sparsity regimes. The tests are illustrated on real networks from social sciences and ecology, and their performances are assessed via a simulation study.},
  archive      = {J_SJOS},
  author       = {Sarah Ouadah and Stéphane Robin and Pierre Latouche},
  doi          = {10.1111/sjos.12410},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {156-181},
  shortjournal = {Scand. J. Statist.},
  title        = {Degree-based goodness-of-fit tests for heterogeneous random graph models: Independent and exchangeable cases},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dimension reduction for the conditional mean and variance
functions in time series. <em>SJOS</em>, <em>47</em>(1), 134–155. (<a
href="https://doi.org/10.1111/sjos.12405">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with the nonparametric estimation of the mean and variance functions of univariate time series data. We propose a nonparametric dimension reduction technique for both mean and variance functions of time series. This method does not require any model specification and instead we seek directions in both the mean and variance functions such that the conditional distribution of the current observation given the vector of past observations is the same as that of the current observation given a few linear combinations of the past observations without loss of inferential information. The directions of the mean and variance functions are estimated by maximizing the Kullback–Leibler distance function. The consistency of the proposed estimators is established. A computational procedure is introduced to detect lags of the conditional mean and variance functions in practice. Numerical examples and simulation studies are performed to illustrate and evaluate the performance of the proposed estimators.},
  archive      = {J_SJOS},
  author       = {Jin-Hong Park and S. Yaser Samadi},
  doi          = {10.1111/sjos.12405},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {134-155},
  shortjournal = {Scand. J. Statist.},
  title        = {Dimension reduction for the conditional mean and variance functions in time series},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Estimation of cyclic long-memory parameters. <em>SJOS</em>,
<em>47</em>(1), 104–133. (<a
href="https://doi.org/10.1111/sjos.12404">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies cyclic long-memory processes with Gegenbauer-type spectral densities. For a semiparametric statistical model, new simultaneous estimates for singularity location and long-memory parameters are proposed. This generalized filtered method-of-moments approach is based on general filter transforms that include wavelet transformations as a particular case. It is proved that the estimates are almost surely convergent to the true values of parameters. Solutions of the estimation equations are studied, and adjusted statistics are proposed. Monte-Carlo study results are presented to confirm the theoretical findings.},
  archive      = {J_SJOS},
  author       = {Huda Mohammed Alomari and Antoine Ayache and Myriam Fradon and Andriy Olenko},
  doi          = {10.1111/sjos.12404},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {104-133},
  shortjournal = {Scand. J. Statist.},
  title        = {Estimation of cyclic long-memory parameters},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Novel criteria to exclude the surrogate paradox and their
optimalities. <em>SJOS</em>, <em>47</em>(1), 84–103. (<a
href="https://doi.org/10.1111/sjos.12398">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When the primary outcome is hard to collect, a surrogate endpoint is typically used as a substitute. However, even when a treatment has a positive average causal effect (ACE) on a surrogate endpoint, which also has a positive ACE on the primary outcome, it is still possible that the treatment has a negative ACE on the primary outcome. Such a phenomenon is called the surrogate paradox and greatly challenges the use of surrogates. In this paper, we provide criteria to exclude the surrogate paradox. Our criteria are optimal in the sense that they are sufficient and “almost necessary” to exclude the paradox: If the conditions are satisfied, the surrogate paradox is guaranteed to be absent, whereas if the conditions fail, there exists a data-generating process with surrogate paradox that can generate the same observed data. That is, our criteria capture all the observed information to exclude the surrogate paradox.},
  archive      = {J_SJOS},
  author       = {Yunjian Yin and Lan Liu and Zhi Geng and Peng Luo},
  doi          = {10.1111/sjos.12398},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {84-103},
  shortjournal = {Scand. J. Statist.},
  title        = {Novel criteria to exclude the surrogate paradox and their optimalities},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Estimation of the marginal expected shortfall under
asymptotic independence. <em>SJOS</em>, <em>47</em>(1), 56–83. (<a
href="https://doi.org/10.1111/sjos.12397">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the asymptotic behavior of the marginal expected shortfall when the two random variables are asymptotic independent but positively associated, which is modeled by the so-called tail dependent coefficient. We construct an estimator of the marginal expected shortfall, which is shown to be asymptotically normal. The finite sample performance of the estimator is investigated in a small simulation study. The method is also applied to estimate the expected amount of rainfall at a weather station given that there is a once every 100 years rainfall at another weather station nearby.},
  archive      = {J_SJOS},
  author       = {Juan-Juan Cai and Eni Musta},
  doi          = {10.1111/sjos.12397},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {56-83},
  shortjournal = {Scand. J. Statist.},
  title        = {Estimation of the marginal expected shortfall under asymptotic independence},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Confidence intervals for extreme pareto-type quantiles.
<em>SJOS</em>, <em>47</em>(1), 36–55. (<a
href="https://doi.org/10.1111/sjos.12396">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we revisit the construction of confidence intervals for extreme quantiles of Pareto-type distributions. A novel asymptotic pivotal quantity is proposed for these quantile estimators, which leads to new asymptotic confidence intervals that exhibit more accurate coverage probability. This pivotal quantity also allows for the construction of a saddle-point approximation, from which a second set of new confidence intervals follows. The small-sample properties and utility of these confidence intervals are studied using simulations and a case study from insurance.},
  archive      = {J_SJOS},
  author       = {Sven Buitendag and Jan Beirlant and Tertius de Wet},
  doi          = {10.1111/sjos.12396},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {36-55},
  shortjournal = {Scand. J. Statist.},
  title        = {Confidence intervals for extreme pareto-type quantiles},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Constructing likelihood functions for interval-valued random
variables. <em>SJOS</em>, <em>47</em>(1), 1–35. (<a
href="https://doi.org/10.1111/sjos.12395">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is a growing need for flexible methods to analyze interval-valued data, which can provide efficient data representations for very large data sets. However, the existing descriptive frameworks to achieve this ignore the process by which interval-valued data are typically constructed, namely, by the aggregation of real-valued data generated from some underlying process. In this paper, we develop the foundations of likelihood-based statistical inference for intervals that directly incorporates the underlying data generating procedure into the analysis. That is, it permits the direct fitting of models for the underlying real-valued data given only the interval-valued summaries. This generative approach overcomes several problems associated with existing methods, including the rarely satisfied assumption of within-interval uniformity. The new methods are illustrated by simulated and real data analyses.},
  archive      = {J_SJOS},
  author       = {X. Zhang and B. Beranger and S. A. Sisson},
  doi          = {10.1111/sjos.12395},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {1-35},
  shortjournal = {Scand. J. Statist.},
  title        = {Constructing likelihood functions for interval-valued random variables},
  volume       = {47},
  year         = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
