<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>INSR_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="insr---75">INSR - 75</h2>
<ul>
<li><details>
<summary>
(2020). Modern strategies for time series regression. <em>INSR</em>,
<em>88</em>(S1), S179–S204. (<a
href="https://doi.org/10.1111/insr.12432">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper discusses several modern approaches to regression analysis involving time series data where some of the predictor variables are also indexed by time. We discuss classical statistical approaches as well as methods that have been proposed recently in the machine learning literature. The approaches are compared and contrasted, and it will be seen that there are advantages and disadvantages to most currently available approaches. There is ample room for methodological developments in this area. The work is motivated by an application involving the prediction of water levels as a function of rainfall and other climate variables in an aquifer in eastern Australia.},
  archive      = {J_INSR},
  author       = {Stephanie Clark and Rob J. Hyndman and Dan Pagendam and Louise M. Ryan},
  doi          = {10.1111/insr.12432},
  journal      = {International Statistical Review},
  month        = {12},
  number       = {S1},
  pages        = {S179-S204},
  shortjournal = {Int. Stat. Rev.},
  title        = {Modern strategies for time series regression},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stable discovery of interpretable subgroups via calibration
in causal studies. <em>INSR</em>, <em>88</em>(S1), S135–S178. (<a
href="https://doi.org/10.1111/insr.12427">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Building on Yu and Kumbier&#39;s predictability, computability and stability (PCS) framework and for randomised experiments, we introduce a novel methodology for Stable Discovery of Interpretable Subgroups via Calibration (StaDISC), with large heterogeneous treatment effects. StaDISC was developed during our re-analysis of the 1999–2000 VIGOR study, an 8076-patient randomised controlled trial that compared the risk of adverse events from a then newly approved drug, rofecoxib (Vioxx), with that from an older drug naproxen. Vioxx was found to, on average and in comparison with naproxen, reduce the risk of gastrointestinal events but increase the risk of thrombotic cardiovascular events. Applying StaDISC, we fit 18 popular conditional average treatment effect (CATE) estimators for both outcomes and use calibration to demonstrate their poor global performance. However, they are locally well-calibrated and stable, enabling the identification of patient groups with larger than (estimated) average treatment effects. In fact, StaDISC discovers three clinically interpretable subgroups each for the gastrointestinal outcome (totalling 29.4% of the study size) and the thrombotic cardiovascular outcome (totalling 11.0%). Complementary analyses of the found subgroups using the 2001–2004 APPROVe study, a separate independently conducted randomised controlled trial with 2587 patients, provide further supporting evidence for the promise of StaDISC.},
  archive      = {J_INSR},
  author       = {Raaz Dwivedi and Yan Shuo Tan and Briton Park and Mian Wei and Kevin Horgan and David Madigan and Bin Yu},
  doi          = {10.1111/insr.12427},
  journal      = {International Statistical Review},
  month        = {12},
  number       = {S1},
  pages        = {S135-S178},
  shortjournal = {Int. Stat. Rev.},
  title        = {Stable discovery of interpretable subgroups via calibration in causal studies},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Rejoinder. <em>INSR</em>, <em>88</em>(S1), S87–S90. (<a
href="https://doi.org/10.1111/insr.12417">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_INSR},
  author       = {Bradley Efron},
  doi          = {10.1111/insr.12417},
  journal      = {International Statistical Review},
  month        = {12},
  number       = {S1},
  pages        = {S87-S90},
  shortjournal = {Int. Stat. Rev.},
  title        = {Rejoinder},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The data science process: One culture. <em>INSR</em>,
<em>88</em>(S1), S83–S86. (<a
href="https://doi.org/10.1111/insr.12416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_INSR},
  author       = {Bin Yu and Rebecca Barter},
  doi          = {10.1111/insr.12416},
  journal      = {International Statistical Review},
  month        = {12},
  number       = {S1},
  pages        = {S83-S86},
  shortjournal = {Int. Stat. Rev.},
  title        = {The data science process: One culture},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Discussion of professor bradley efron’s article on
“prediction, estimation, and attribution.” <em>INSR</em>,
<em>88</em>(S1), S75–S82. (<a
href="https://doi.org/10.1111/insr.12415">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_INSR},
  author       = {Min-ge Xie and Zheshi Zheng},
  doi          = {10.1111/insr.12415},
  journal      = {International Statistical Review},
  month        = {12},
  number       = {S1},
  pages        = {S75-S82},
  shortjournal = {Int. Stat. Rev.},
  title        = {Discussion of professor bradley efron’s article on “Prediction, estimation, and attribution”},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Discussion of “prediction, estimation, and attribution” by
bradley efron. <em>INSR</em>, <em>88</em>(S1), S73–S74. (<a
href="https://doi.org/10.1111/insr.12414">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Professor Efron has presented us with a thought-provoking paper on the relationship between prediction, estimation, and attribution in the modern era of data science. While we appreciate many of his arguments, we see more of a continuum between the old and new methodology, and the opportunity for both to improve through their synergy.},
  archive      = {J_INSR},
  author       = {Jerome Friedman and Trevor Hastie and Robert Tibshirani},
  doi          = {10.1111/insr.12414},
  journal      = {International Statistical Review},
  month        = {12},
  number       = {S1},
  pages        = {S73-S74},
  shortjournal = {Int. Stat. Rev.},
  title        = {Discussion of “Prediction, estimation, and attribution” by bradley efron},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Discussion. <em>INSR</em>, <em>88</em>(S1), S70–S72. (<a
href="https://doi.org/10.1111/insr.12410">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_INSR},
  author       = {A. C. Davison},
  doi          = {10.1111/insr.12410},
  journal      = {International Statistical Review},
  month        = {12},
  number       = {S1},
  pages        = {S70-S72},
  shortjournal = {Int. Stat. Rev.},
  title        = {Discussion},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Comment: When is it data science and when is it data
engineering? <em>INSR</em>, <em>88</em>(S1), S65–S69. (<a
href="https://doi.org/10.1111/insr.12411">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_INSR},
  author       = {Noel Cressie},
  doi          = {10.1111/insr.12411},
  journal      = {International Statistical Review},
  month        = {12},
  number       = {S1},
  pages        = {S65-S69},
  shortjournal = {Int. Stat. Rev.},
  title        = {Comment: When is it data science and when is it data engineering?},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Discussion of paper by brad efron. <em>INSR</em>,
<em>88</em>(S1), S64. (<a
href="https://doi.org/10.1111/insr.12413">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_INSR},
  author       = {D. R. Cox},
  doi          = {10.1111/insr.12413},
  journal      = {International Statistical Review},
  month        = {12},
  number       = {S1},
  pages        = {S64},
  shortjournal = {Int. Stat. Rev.},
  title        = {Discussion of paper by brad efron},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Discussion of the paper “prediction, estimation, and
attribution” by b. efron. <em>INSR</em>, <em>88</em>(S1), S60–S63. (<a
href="https://doi.org/10.1111/insr.12412">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_INSR},
  author       = {Emmanuel Candès and Chiara Sabatti},
  doi          = {10.1111/insr.12412},
  journal      = {International Statistical Review},
  month        = {12},
  number       = {S1},
  pages        = {S60-S63},
  shortjournal = {Int. Stat. Rev.},
  title        = {Discussion of the paper “Prediction, estimation, and attribution” by b. efron},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Prediction, estimation, and attribution. <em>INSR</em>,
<em>88</em>(S1), S28–S59. (<a
href="https://doi.org/10.1111/insr.12409">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The scientific needs and computational limitations of the twentieth century fashioned classical statistical methodology. Both the needs and limitations have changed in the twenty-first, and so has the methodology. Large-scale prediction algorithms—neural nets, deep learning, boosting, support vector machines, random forests—have achieved star status in the popular press. They are recognizable as heirs to the regression tradition, but ones carried out at enormous scale and on titanic datasets. How do these algorithms compare with standard regression techniques such as ordinary least squares or logistic regression? Several key discrepancies will be examined, centering on the differences between prediction and estimation or prediction and attribution (significance testing). Most of the discussion is carried out through small numerical examples.},
  archive      = {J_INSR},
  author       = {Bradley Efron},
  doi          = {10.1111/insr.12409},
  journal      = {International Statistical Review},
  month        = {12},
  number       = {S1},
  pages        = {S28-S59},
  shortjournal = {Int. Stat. Rev.},
  title        = {Prediction, estimation, and attribution},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Reluctant generalised additive modelling. <em>INSR</em>,
<em>88</em>(S1), S205–S224. (<a
href="https://doi.org/10.1111/insr.12429">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse generalised additive models (GAMs) are an extension of sparse generalised linear models that allow a model&#39;s prediction to vary non-linearly with an input variable. This enables the data analyst build more accurate models, especially when the linearity assumption is known to be a poor approximation of reality. Motivated by reluctant interaction modelling, we propose a multi-stage algorithm, called reluctant generalised additive modelling (RGAM) , that can fit sparse GAMs at scale. It is guided by the principle that, if all else is equal, one should prefer a linear feature over a non-linear feature. Unlike existing methods for sparse GAMs, RGAM can be extended easily to binary, count and survival data. We demonstrate the method&#39;s effectiveness on real and simulated examples.},
  archive      = {J_INSR},
  author       = {J. Kenneth Tay and Robert Tibshirani},
  doi          = {10.1111/insr.12429},
  journal      = {International Statistical Review},
  month        = {11},
  number       = {S1},
  pages        = {S205-S224},
  shortjournal = {Int. Stat. Rev.},
  title        = {Reluctant generalised additive modelling},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deconfounding and causal regularisation for stability and
external validity. <em>INSR</em>, <em>88</em>(S1), S114–S134. (<a
href="https://doi.org/10.1111/insr.12426">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We review some recent works on removing hidden confounding and causal regularisation from a unified viewpoint. We describe how simple and user-friendly techniques improve stability, replicability and distributional robustness in heterogeneous data. In this sense, we provide additional thoughts on the issue of concept drift, raised recently by Efron, when the data generating distribution is changing.},
  archive      = {J_INSR},
  author       = {Peter Bühlmann and Domagoj Ćevid},
  doi          = {10.1111/insr.12426},
  journal      = {International Statistical Review},
  month        = {11},
  number       = {S1},
  pages        = {S114-S134},
  shortjournal = {Int. Stat. Rev.},
  title        = {Deconfounding and causal regularisation for stability and external validity},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Double empirical bayes testing. <em>INSR</em>,
<em>88</em>(S1), S91–S113. (<a
href="https://doi.org/10.1111/insr.12430">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analysing data from large-scale, multiexperiment studies requires scientists to both analyse each experiment and to assess the results as a whole. In this article, we develop double empirical Bayes testing (DEBT), an empirical Bayes method for analysing multiexperiment studies when many covariates are gathered per experiment. DEBT is a two-stage method: in the first stage, it reports which experiments yielded significant outcomes and in the second stage, it hypothesises which covariates drive the experimental significance. In both of its stages, DEBT builds on the work of Efron, who laid out an elegant empirical Bayes approach to testing. DEBT enhances this framework by learning a series of black box predictive models to boost power and control the false discovery rate. In Stage 1, it uses a deep neural network prior to report which experiments yielded significant outcomes. In Stage 2, it uses an empirical Bayes version of the knockoff filter to select covariates that have significant predictive power of Stage 1 significance. In both simulated and real data, DEBT increases the proportion of discovered significant outcomes and selects more features when signals are weak. In a real study of cancer cell lines, DEBT selects a robust set of biologically plausible genomic drivers of drug sensitivity and resistance in cancer.},
  archive      = {J_INSR},
  author       = {Wesley Tansey and Yixin Wang and Raul Rabadan and David Blei},
  doi          = {10.1111/insr.12430},
  journal      = {International Statistical Review},
  month        = {11},
  number       = {S1},
  pages        = {S91-S113},
  shortjournal = {Int. Stat. Rev.},
  title        = {Double empirical bayes testing},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An interview with bradley efron. <em>INSR</em>,
<em>88</em>(S1), S2–S27. (<a
href="https://doi.org/10.1111/insr.12428">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_INSR},
  author       = {Balasubramanian Narasimhan},
  doi          = {10.1111/insr.12428},
  journal      = {International Statistical Review},
  month        = {11},
  number       = {S1},
  pages        = {S2-S27},
  shortjournal = {Int. Stat. Rev.},
  title        = {An interview with bradley efron},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Foreword. <em>INSR</em>, <em>88</em>(S1), S1. (<a
href="https://doi.org/10.1111/insr.12433">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_INSR},
  author       = {Scott H. Holan and Nalini Ravishanker},
  doi          = {10.1111/insr.12433},
  journal      = {International Statistical Review},
  month        = {11},
  number       = {S1},
  pages        = {S1},
  shortjournal = {Int. Stat. Rev.},
  title        = {Foreword},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). <em>INSR</em>, <em>88</em>(3), 809–812. (<a
href="https://doi.org/10.1111/insr.12423">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_INSR},
  author       = {Ravi Khattree},
  doi          = {10.1111/insr.12423},
  journal      = {International Statistical Review},
  month        = {12},
  number       = {3},
  pages        = {809-812},
  shortjournal = {Int. Stat. Rev.},
  title        = {End-to-end data science with SAS: a hands-on programming guide james gearheart SAS press, 2020, xiii+363 pages, £ 23.99$29.99, ebook ISBN: 978-1-64295-806-5},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). <em>INSR</em>, <em>88</em>(3), 808–809. (<a
href="https://doi.org/10.1111/insr.12422">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_INSR},
  author       = {Yao Qiwei},
  doi          = {10.1111/insr.12422},
  journal      = {International Statistical Review},
  month        = {12},
  number       = {3},
  pages        = {808-809},
  shortjournal = {Int. Stat. Rev.},
  title        = {Time series: A first course with bootstrap starter tucker s. McElroy and dimitris n. politis CRC press, 2020, xix + 566 pages, £ 74.99/$99.95, hardcover ISBN 978-1-4398-7561-0},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). <em>INSR</em>, <em>88</em>(3), 806–808. (<a
href="https://doi.org/10.1111/insr.12421">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_INSR},
  author       = {Debashis Ghosh},
  doi          = {10.1111/insr.12421},
  journal      = {International Statistical Review},
  month        = {12},
  number       = {3},
  pages        = {806-808},
  shortjournal = {Int. Stat. Rev.},
  title        = {Statistical inference via convex optimization nillas, alice anatoli juditsky and arkadi nemirovski princeton university press, 2020, xiv + 656 pages, £ 70/$85, hardcover ISBN: 978-0-6911-9729-6},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). <em>INSR</em>, <em>88</em>(3), 804–806. (<a
href="https://doi.org/10.1111/insr.12420">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_INSR},
  author       = {Carl M. O&#39;Brien},
  doi          = {10.1111/insr.12420},
  journal      = {International Statistical Review},
  month        = {12},
  number       = {3},
  pages        = {804-806},
  shortjournal = {Int. Stat. Rev.},
  title        = {Sampling and estimation from finite PopulationsYves TilléWiley, 2020, xxviii + 419 pages, £ 65/$100, hardcover ISBN: 978-0-470-68205-0},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). <em>INSR</em>, <em>88</em>(3), 802–804. (<a
href="https://doi.org/10.1111/insr.12419">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_INSR},
  author       = {Bibhas Chakraborty},
  doi          = {10.1111/insr.12419},
  journal      = {International Statistical Review},
  month        = {12},
  number       = {3},
  pages        = {802-804},
  shortjournal = {Int. Stat. Rev.},
  title        = {Statistical remedies for medical researchers peter f. thall springer, 2020, xi + 291 pages, £ 79.99/$109.99, hardcover ISBN: 978-3-030-43713-8},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Response to the letter to the editor on “on quantile-based
asymmetric family of distributions: Properties and inference.”
<em>INSR</em>, <em>88</em>(3), 797–801. (<a
href="https://doi.org/10.1111/insr.12424">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rubio (2020) points out an identification problem for the four-parameter family of two-piece asymmetric densities introduced by Nassiri &amp; Loris (2013). This implies that statistical inference for that family is problematic. Establishing probabilistic properties for this four-parameter family however still makes sense. For the three-parameter family, there is no identification problem. The main contribution in Gijbels et al. (2019a) is to provide asymptotic results for maximum likelihood and method-of-moments estimators for all members of the three-parameter quantile-based asymmetric family of distributions.},
  archive      = {J_INSR},
  author       = {Irène Gijbels and Rezaul Karim and Anneleen Verhasselt},
  doi          = {10.1111/insr.12424},
  journal      = {International Statistical Review},
  month        = {12},
  number       = {3},
  pages        = {797-801},
  shortjournal = {Int. Stat. Rev.},
  title        = {Response to the letter to the editor on ‘On quantile-based asymmetric family of distributions: Properties and inference’},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Letter to the editor: “On quantile-based asymmetric family
of distributions: Properties and inference.” <em>INSR</em>,
<em>88</em>(3), 793–796. (<a
href="https://doi.org/10.1111/insr.12425">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show that the family of asymmetric distributions studied in a recent publication in the International Statistical Review is equivalent to the family of two-piece distributions. Moreover, we show that the location-scale asymmetric family proposed in that publication is non-identifiable (overparameterised), and it coincides with the family of two-piece distributions after removing the redundant parameters.},
  archive      = {J_INSR},
  author       = {Francisco J. Rubio Alvarez},
  doi          = {10.1111/insr.12425},
  journal      = {International Statistical Review},
  month        = {12},
  number       = {3},
  pages        = {793-796},
  shortjournal = {Int. Stat. Rev.},
  title        = {Letter to the editor: ‘On quantile-based asymmetric family of distributions: properties and inference’},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A geometrical interpretation of collinearity: A natural way
to justify ridge regression and its anomalies. <em>INSR</em>,
<em>88</em>(3), 776–792. (<a
href="https://doi.org/10.1111/insr.12381">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Justifying ridge regression from a geometrical perspective is one of the main contributions of this paper. To the best of our knowledge, this question has not been treated previously. This paper shows that ridge regression is a particular case of raising procedures that provide greater flexibility by transforming the matrix X associated with the model. Thus, raising procedures, based on a geometrical idea of the vectorial space associated with the columns of matrix X , lead naturally to ridge regression and justify the presence of the well-known constant k on the main diagonal of matrix X ′ X . This paper also analyses and compares different alternatives to raising with respect to collinearity mitigation. The results are illustrated with an empirical application.},
  archive      = {J_INSR},
  author       = {José García-Pérez and María del Mar López-Martín and Catalina García-García and Román Salmerón-Gómez},
  doi          = {10.1111/insr.12381},
  journal      = {International Statistical Review},
  month        = {12},
  number       = {3},
  pages        = {776-792},
  shortjournal = {Int. Stat. Rev.},
  title        = {A geometrical interpretation of collinearity: A natural way to justify ridge regression and its anomalies},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bayesian model selection of gaussian directed acyclic graph
structures. <em>INSR</em>, <em>88</em>(3), 752–775. (<a
href="https://doi.org/10.1111/insr.12379">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the last years, graphical models have become a popular tool to represent dependencies among variables in many scientific areas. Typically, the objective is to discover dependence relationships that can be represented through a directed acyclic graph (DAG). The set of all conditional independencies encoded by a DAG determines its Markov property. In general, DAGs encoding the same conditional independencies are not distinguishable from observational data and can be collected into equivalence classes, each one represented by a chain graph called essential graph (EG). However, both the DAG and EG space grow super exponentially in the number of variables, and so, graph structural learning requires the adoption of Markov chain Monte Carlo (MCMC) techniques. In this paper, we review some recent results on Bayesian model selection of Gaussian DAG models under a unified framework. These results are based on closed-form expressions for the marginal likelihood of a DAG and EG structure, which is obtained from a few suitable assumptions on the prior for model parameters. We then introduce a general MCMC scheme that can be adopted both for model selection of DAGs and EGs together with a couple of applications on real data sets.},
  archive      = {J_INSR},
  author       = {Federico Castelletti},
  doi          = {10.1111/insr.12379},
  journal      = {International Statistical Review},
  month        = {12},
  number       = {3},
  pages        = {752-775},
  shortjournal = {Int. Stat. Rev.},
  title        = {Bayesian model selection of gaussian directed acyclic graph structures},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Performance measures in dose-finding experiments.
<em>INSR</em>, <em>88</em>(3), 728–751. (<a
href="https://doi.org/10.1111/insr.12363">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the first phase of pharmaceutical development, and assuming that the probability of positive response increases with dose, the main statistical goal is to estimate a percentile of the dose–response function for a given target value Γ . We compare the Maximum Likelihood and centred isotonic regression estimators of the target dose and we discuss several performance criteria to assess inferential precision, the amount of toxicity exposure and the trade-off between them for a set of some exemplary adaptive designs. We compare these designs using graphical tools. Several scenarios are considered using simulation, including the use of several start-up rules, the change of slope of the dose-toxicity function at the target dose and also different theoretical models, as logistic, normal or skew-normal distribution functions.},
  archive      = {J_INSR},
  author       = {Nancy Flournoy and José Moler and Fernando Plo},
  doi          = {10.1111/insr.12363},
  journal      = {International Statistical Review},
  month        = {12},
  number       = {3},
  pages        = {728-751},
  shortjournal = {Int. Stat. Rev.},
  title        = {Performance measures in dose-finding experiments},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A non-proportional hazards model with hazard ratio functions
free from covariate values. <em>INSR</em>, <em>88</em>(3), 715–727. (<a
href="https://doi.org/10.1111/insr.12364">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A brief survey on methods to handle non-proportional hazards in survival analysis is given with emphasis on short-term and long-term hazard ratio modelling. A drawback of the existing model of this nature is that except at time zero or infinity, the hazard ratio for a unit increase in the value of a covariate depends on the starting value. With two or more covariates, the hazard ratio for a unit increase in one covariate with other covariates held fixed depends in an unintended way on the values of the other covariates. We propose an alternative way to model short-term and long-term hazard ratios without the above drawbacks through a judicious choice of covariate-time interactions. Under the new model, it is easier to describe the time-varying effect of each covariate on the hazard. Nonparametric maximum likelihood estimation for the new model can be carried out in the same way as for the existing model. We also propose a product version of the existing model, which overcomes its second drawback but not the first. The advocated covariate–time interaction model provides a better fit to the Veterans Administration lung cancer data set than the original and product versions of the existing model.},
  archive      = {J_INSR},
  author       = {Anthony Y. C. Kuk},
  doi          = {10.1111/insr.12364},
  journal      = {International Statistical Review},
  month        = {12},
  number       = {3},
  pages        = {715-727},
  shortjournal = {Int. Stat. Rev.},
  title        = {A non-proportional hazards model with hazard ratio functions free from covariate values},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Graphical comparison of high-dimensional distributions.
<em>INSR</em>, <em>88</em>(3), 698–714. (<a
href="https://doi.org/10.1111/insr.12358">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider groups of observations in R d and present a simultaneous plot of the empirical cumulative distribution functions of the within and between interpoint distances to visualise and examine the equality of the underlying distribution functions of the observations. We provide several examples to illustrate how such plots can be utilised to envision and canvass the relationship between the two distributions under location, scale, dependence and shape changes. We suggest new statistics for testing the equality of k distributions and extend the simultaneous plots to visualise them. We compare the new statistics to existing tests based on the interpoint distances.},
  archive      = {J_INSR},
  author       = {Reza Modarres},
  doi          = {10.1111/insr.12358},
  journal      = {International Statistical Review},
  month        = {12},
  number       = {3},
  pages        = {698-714},
  shortjournal = {Int. Stat. Rev.},
  title        = {Graphical comparison of high-dimensional distributions},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Tests of normality of functional data. <em>INSR</em>,
<em>88</em>(3), 677–697. (<a
href="https://doi.org/10.1111/insr.12362">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper is concerned with testing normality in samples of curves and error curves estimated from functional regression models. We propose a general paradigm based on the application of multivariate normality tests to vectors of functional principal components scores. We examine finite sample performance of a number of such tests and select the best performing tests. We apply them to several extensively used functional data sets and determine which can be treated as normal, possibly after a suitable transformation. We also offer practical guidance on software implementations of all tests we study and develop large sample justification for tests based on sample skewness and kurtosis of functional principal component scores.},
  archive      = {J_INSR},
  author       = {Tomasz Górecki and Lajos Horváth and Piotr Kokoszka},
  doi          = {10.1111/insr.12362},
  journal      = {International Statistical Review},
  month        = {12},
  number       = {3},
  pages        = {677-697},
  shortjournal = {Int. Stat. Rev.},
  title        = {Tests of normality of functional data},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A review of envelope models. <em>INSR</em>, <em>88</em>(3),
658–676. (<a href="https://doi.org/10.1111/insr.12361">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The envelope model was first introduced as a parsimonious version of multivariate linear regression. It uses dimension reduction techniques to remove immaterial variation in the data and has the potential to gain efficiency in estimation and improve prediction. Many advances have taken place since its introduction, and the envelope model has been applied to many contexts in multivariate analysis, including partial least squares, generalised linear models, Bayesian analysis, variable selection and quantile regression, among others. This article serves as a review of the envelope model and its developments for those who are new to the area.},
  archive      = {J_INSR},
  author       = {Minji Lee and Zhihua Su},
  doi          = {10.1111/insr.12361},
  journal      = {International Statistical Review},
  month        = {12},
  number       = {3},
  pages        = {658-676},
  shortjournal = {Int. Stat. Rev.},
  title        = {A review of envelope models},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Is there a ’safe area’ where the nonresponse rate has only a
modest effect on bias despite non-ignorable nonresponse? <em>INSR</em>,
<em>88</em>(3), 642–657. (<a
href="https://doi.org/10.1111/insr.12359">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rising nonresponse rates in social surveys make the issue of nonresponse bias contentious. There are conflicting messages about the importance of high response rates and the hazards of low rates. Some articles (e.g. Groves and Peytcheva, 2008) suggest that the response rate is in general not a good predictor of survey quality. Equally, it is well known that nonresponse may induce bias and increase data collection costs. We go back in the history of the literature of nonresponse and suggest a possible reason to the notion that even a rather small nonresponse rate makes the quality of a survey debatable. We also explore the relationship between nonresponse rate and bias, assuming non-ignorable nonresponse and focusing on estimates of totals or means. We show that there is a ‘safe area’ enclosed by the response rate on the one hand and the correlation between the response propensity and the study variable on the other hand; in this area, (1) the response rate does not greatly affect the nonresponse bias, and (2) the nonresponse bias is small.},
  archive      = {J_INSR},
  author       = {Dan Hedlin},
  doi          = {10.1111/insr.12359},
  journal      = {International Statistical Review},
  month        = {12},
  number       = {3},
  pages        = {642-657},
  shortjournal = {Int. Stat. Rev.},
  title        = {Is there a &#39;safe area&#39; where the nonresponse rate has only a modest effect on bias despite non-ignorable nonresponse?},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On variable ordination of modified cholesky decomposition
for estimating time-varying covariance matrices. <em>INSR</em>,
<em>88</em>(3), 616–641. (<a
href="https://doi.org/10.1111/insr.12357">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating time-varying covariance matrices of the vector of interest is challenging both computationally and statistically due to a large number of constrained parameters. In this work, we consider an order-averaged Cholesky-log-GARCH (OA-CLGARCH) model for estimating time-varying covariance matrices through the orthogonal transformations of the vector based on the modified Cholesky decomposition. The proposed method is to transform the vector at each time as a linear transformation of uncorrelated latent variables and then to use simple univariate GARCH models to model them separately. But the modified Cholesky decomposition relies on a given order of variables, which is often not available, to sequentially orthogonalize the variables. The proposed method develops an order-averaged strategy for the Cholesky-GARCH method to alleviate the effect of order of variables. The merits of the proposed method are illustrated through simulations and real-data studies.},
  archive      = {J_INSR},
  author       = {Xiaoning Kang and Xinwei Deng and Kam-Wah Tsui and Mohsen Pourahmadi},
  doi          = {10.1111/insr.12357},
  journal      = {International Statistical Review},
  month        = {12},
  number       = {3},
  pages        = {616-641},
  shortjournal = {Int. Stat. Rev.},
  title        = {On variable ordination of modified cholesky decomposition for estimating time-varying covariance matrices},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Likelihood, replicability and robbins’ confidence sequences.
<em>INSR</em>, <em>88</em>(3), 599–615. (<a
href="https://doi.org/10.1111/insr.12355">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widely claimed replicability crisis in science may lead to revised standards of significance. The customary frequentist confidence intervals, calibrated through hypothetical repetitions of the experiment that is supposed to have produced the data at hand, rely on a feeble concept of replicability. In particular, contradictory conclusions may be reached when a substantial enlargement of the study is undertaken. To redefine statistical confidence in such a way that inferential conclusions are non-contradictory, with large enough probability, under enlargements of the sample, we give a new reading of a proposal dating back to the 60s, namely, Robbins&#39; confidence sequences. Directly bounding the probability of reaching, in the future, conclusions that contradict the current ones, Robbins&#39; confidence sequences ensure a clear-cut form of replicability when inference is performed on accumulating data. Their main frequentist property is easy to understand and to prove. We show that Robbins&#39; confidence sequences may be justified under various views of inference: they are likelihood-based, can incorporate prior information and obey the strong likelihood principle. They are easy to compute, even when inference is on a parameter of interest, especially using a closed form approximation from normal asymptotic theory.},
  archive      = {J_INSR},
  author       = {Luigi Pace and Alessandra Salvan},
  doi          = {10.1111/insr.12355},
  journal      = {International Statistical Review},
  month        = {12},
  number       = {3},
  pages        = {599-615},
  shortjournal = {Int. Stat. Rev.},
  title        = {Likelihood, replicability and robbins&#39; confidence sequences},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Smoothing and benchmarking for small area estimation.
<em>INSR</em>, <em>88</em>(3), 580–598. (<a
href="https://doi.org/10.1111/insr.12373">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Small area estimation is concerned with methodology for estimating population parameters associated with a geographic area defined by a cross-classification that may also include non-geographic dimensions. In this paper, we develop constrained estimation methods for small area problems: those requiring smoothness with respect to similarity across areas, such as geographic proximity or clustering by covariates, and benchmarking constraints, requiring weighted means of estimates to agree across levels of aggregation. We develop methods for constrained estimation decision theoretically and discuss their geometric interpretation. The constrained estimators are the solutions to tractable optimisation problems and have closed-form solutions. Mean squared errors of the constrained estimators are calculated via bootstrapping. Our approach assumes the Bayes estimator exists and is applicable to any proposed model. In addition, we give special cases of our techniques under certain distributional assumptions. We illustrate the proposed methodology using web-scraped data on Berlin rents aggregated over areas to ensure privacy.},
  archive      = {J_INSR},
  author       = {Rebecca C. Steorts and Timo Schmid and Nikos Tzavidis},
  doi          = {10.1111/insr.12373},
  journal      = {International Statistical Review},
  month        = {12},
  number       = {3},
  pages        = {580-598},
  shortjournal = {Int. Stat. Rev.},
  title        = {Smoothing and benchmarking for small area estimation},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Advanced multilevel monte carlo methods. <em>INSR</em>,
<em>88</em>(3), 548–579. (<a
href="https://doi.org/10.1111/insr.12365">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article reviews the application of some advanced Monte Carlo techniques in the context of multilevel Monte Carlo (MLMC). MLMC is a strategy employed to compute expectations, which can be biassed in some sense, for instance, by using the discretization of an associated probability law. The MLMC approach works with a hierarchy of biassed approximations, which become progressively more accurate and more expensive. Using a telescoping representation of the most accurate approximation, the method is able to reduce the computational cost for a given level of error versus i.i.d. sampling from this latter approximation. All of these ideas originated for cases where exact sampling from couples in the hierarchy is possible. This article considers the case where such exact sampling is not currently possible. We consider some Markov chain Monte Carlo and sequential Monte Carlo methods, which have been introduced in the literature, and we describe different strategies that facilitate the application of MLMC within these methods.},
  archive      = {J_INSR},
  author       = {Ajay Jasra and Kody Law and Carina Suciu},
  doi          = {10.1111/insr.12365},
  journal      = {International Statistical Review},
  month        = {12},
  number       = {3},
  pages        = {548-579},
  shortjournal = {Int. Stat. Rev.},
  title        = {Advanced multilevel monte carlo methods},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A conversation with paul embrechts. <em>INSR</em>,
<em>88</em>(3), 521–547. (<a
href="https://doi.org/10.1111/insr.12406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Paul Embrechts was born in Schoten, Belgium, on 3 February 1953. He holds a Licentiaat in Mathematics from Universiteit Antwerpen (1975) and a DSc from Katholieke Universiteit Leuven (1979), where he was also a Research Assistant from 1975 to 1983. He then held a lectureship in Statistics at Imperial College, London (1983–1985) and was a Docent at Limburgs Universitair Centrum, Belgium (1985–1989) before joining ETH Zürich as a Full Professor of Mathematics in 1989, where he remained until his retirement as an Emeritus in 2018. A renowned specialist of extreme-value theory and quantitative risk management, he authored or coauthored nearly 200 scientific papers and five books, including the highly influential ‘Modelling of Extremal Events for Insurance and Finance’ (Springer, 1997) and ‘Quantitative Risk Management: Concepts, Techniques and Tools’ (Princeton University Press, 2005, 2015). He served in numerous editorial capacities, notably as Editor-in-Chief of the ASTIN Bulletin (1996–2005). Praised for his natural leadership and exceptional communication skills, he helped to bridge the gap between academia and industry through the foundation of RiskLab Switzerland and his sustained leadership for nearly 20 years. He gave numerous prestigious invited and keynote lectures worldwide and served as a member of the board of, or consultant for, various banks, insurance companies and international regulatory authorities. His work was recognised through several visiting positions, including at the Oxford-Man Institute, and many awards. He is, inter alia, an Elected Fellow of the Institute of Mathematical Statistics (1995) and the American Statistical Association (2014), an Honorary Fellow of the Institute and the Faculty of Actuaries (2000), Honorary Member of the Belgian (2010) and French (2015) Institute of Actuaries and was granted four honorary degrees (University of Waterloo, 2007; Heriot-Watt University, 2011; Université catholique de Louvain, 2012; City, University of London, 2017). The following conversation took place in Paul&#39;s office at ETH Zürich, 17–18 December 2018.},
  archive      = {J_INSR},
  author       = {Christian Genest and Johanna G. Nešlehová},
  doi          = {10.1111/insr.12406},
  journal      = {International Statistical Review},
  month        = {12},
  number       = {3},
  pages        = {521-547},
  shortjournal = {Int. Stat. Rev.},
  title        = {A conversation with paul embrechts},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). <em>INSR</em>, <em>88</em>(2), 520. (<a
href="https://doi.org/10.1111/insr.12387">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_INSR},
  author       = {Jorma K. Merikoski},
  doi          = {10.1111/insr.12387},
  journal      = {International Statistical Review},
  month        = {8},
  number       = {2},
  pages        = {520},
  shortjournal = {Int. Stat. Rev.},
  title        = {Book review: random circulant matrices, arup bose and koushik saha, CRC press, 2019, xix + 192 pages, $174.95, hardcover ISBN: 978-1-1383-5109-7},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Correction to “distribution-free approximate methods for
constructing confidence intervals for quantiles.” <em>INSR</em>,
<em>88</em>(2), 519. (<a
href="https://doi.org/10.1111/insr.12394">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_INSR},
  author       = {Chaitra H. Nagaraja and Haikady N. Nagaraja},
  doi          = {10.1111/insr.12394},
  journal      = {International Statistical Review},
  month        = {8},
  number       = {2},
  pages        = {519},
  shortjournal = {Int. Stat. Rev.},
  title        = {Correction to ‘Distribution-free approximate methods for constructing confidence intervals for quantiles’},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). A concise introduction to machine learning a.c. FaulCRC
press, 2019, 314 pages, £46.99, paperbackISBN: 978-0-8153-8410-6.
<em>INSR</em>, <em>88</em>(2), 517–518. (<a
href="https://doi.org/10.1111/insr.12397">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_INSR},
  author       = {Shuangzhe Liu},
  doi          = {10.1111/insr.12397},
  journal      = {International Statistical Review},
  month        = {8},
  number       = {2},
  pages        = {517-518},
  shortjournal = {Int. Stat. Rev.},
  title        = {A concise introduction to machine learning A.C. FaulCRC press, 2019, 314 pages, £46.99, paperbackISBN: 978-0-8153-8410-6},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Semiparametric regression with r jaroslaw harezlak, david
ruppert and matt p. Wand springer, 2018, xi + 331 pages, €85.39, ebook
ISBN: 978-1-4939-8853-2. <em>INSR</em>, <em>88</em>(2), 516. (<a
href="https://doi.org/10.1111/insr.12384">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_INSR},
  author       = {Tapio Nummi},
  doi          = {10.1111/insr.12384},
  journal      = {International Statistical Review},
  month        = {8},
  number       = {2},
  pages        = {516},
  shortjournal = {Int. Stat. Rev.},
  title        = {Semiparametric regression with r jaroslaw harezlak, david ruppert and matt p. wand springer, 2018, xi + 331 pages, €85.39, ebook ISBN: 978-1-4939-8853-2},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). <em>INSR</em>, <em>88</em>(2), 515–516. (<a
href="https://doi.org/10.1111/insr.12383">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_INSR},
  author       = {Stephen B. Vardeman},
  doi          = {10.1111/insr.12383},
  journal      = {International Statistical Review},
  month        = {8},
  number       = {2},
  pages        = {515-516},
  shortjournal = {Int. Stat. Rev.},
  title        = {Machine learning: a concise introduction steven w. knox john wiley &amp; sons, 2018, 352 pages, $99.95, hardcover ISBN: 978-1-119-43919-6},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). <em>INSR</em>, <em>88</em>(2), 514–515. (<a
href="https://doi.org/10.1111/insr.12382">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_INSR},
  author       = {Carol Joyce Blumberg},
  doi          = {10.1111/insr.12382},
  journal      = {International Statistical Review},
  month        = {8},
  number       = {2},
  pages        = {514-515},
  shortjournal = {Int. Stat. Rev.},
  title        = {Bayesian statistics for beginners: a step-by-step approach therese m. donovan and ruth m. mickey oxford university press, 2019, viii + 419 pages, $100, hardcover ISBN: 978-0-19-884129-6},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A review of multi-compartment infectious disease models.
<em>INSR</em>, <em>88</em>(2), 462–513. (<a
href="https://doi.org/10.1111/insr.12402">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-compartment models have been playing a central role in modelling infectious disease dynamics since the early 20th century. They are a class of mathematical models widely used for describing the mechanism of an evolving epidemic. Integrated with certain sampling schemes, such mechanistic models can be applied to analyse public health surveillance data, such as assessing the effectiveness of preventive measures (e.g. social distancing and quarantine) and forecasting disease spread patterns. This review begins with a nationwide macromechanistic model and related statistical analyses, including model specification, estimation, inference and prediction. Then, it presents a community-level micromodel that enables high-resolution analyses of regional surveillance data to provide current and future risk information useful for local government and residents to make decisions on reopenings of local business and personal travels. r software and scripts are provided whenever appropriate to illustrate the numerical detail of algorithms and calculations. The coronavirus disease 2019 pandemic surveillance data from the state of Michigan are used for the illustration throughout this paper.},
  archive      = {J_INSR},
  author       = {Lu Tang and Yiwang Zhou and Lili Wang and Soumik Purkayastha and Leyao Zhang and Jie He and Fei Wang and Peter X.-K. Song},
  doi          = {10.1111/insr.12402},
  journal      = {International Statistical Review},
  month        = {8},
  number       = {2},
  pages        = {462-513},
  shortjournal = {Int. Stat. Rev.},
  title        = {A review of multi-compartment infectious disease models},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Statistical implementations of agent-based demographic
models. <em>INSR</em>, <em>88</em>(2), 441–461. (<a
href="https://doi.org/10.1111/insr.12399">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A variety of demographic statistical models exist for studying population dynamics when individuals can be tracked over time. In cases where data are missing due to imperfect detection of individuals, the associated measurement error can be accommodated under certain study designs (e.g. those that involve multiple surveys or replication). However, the interaction of the measurement error and the underlying dynamic process can complicate the implementation of statistical agent-based models (ABMs) for population demography. In a Bayesian setting, traditional computational algorithms for fitting hierarchical demographic models can be prohibitively cumbersome to construct. Thus, we discuss a variety of approaches for fitting statistical ABMs to data and demonstrate how to use multi-stage recursive Bayesian computing and statistical emulators to fit models in such a way that alleviates the need to have analytical knowledge of the ABM likelihood. Using two examples, a demographic model for survival and a compartment model for COVID-19, we illustrate statistical procedures for implementing ABMs. The approaches we describe are intuitive and accessible for practitioners and can be parallelised easily for additional computational efficiency.},
  archive      = {J_INSR},
  author       = {Mevin Hooten and Christopher Wikle and Michael Schwob},
  doi          = {10.1111/insr.12399},
  journal      = {International Statistical Review},
  month        = {8},
  number       = {2},
  pages        = {441-461},
  shortjournal = {Int. Stat. Rev.},
  title        = {Statistical implementations of agent-based demographic models},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Statistical network analysis: A review with applications to
the coronavirus disease 2019 pandemic. <em>INSR</em>, <em>88</em>(2),
419–440. (<a href="https://doi.org/10.1111/insr.12398">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the coronavirus disease 2019 outbreak evolves, statistical network analysis is playing an essential role in informing policy decisions. Therefore, researchers who are new to such studies need to understand the techniques available to them. As a field, statistical network analysis aims to develop methods that account for the complex dependencies found in network data. Over the last few decades, the area has rapidly accumulated methods, including techniques for network modelling and simulating the spread of infectious disease. This article reviews these network modelling techniques and their applications to the coronavirus disease 2019 pandemic.},
  archive      = {J_INSR},
  author       = {Joshua Daniel Loyal and Yuguo Chen},
  doi          = {10.1111/insr.12398},
  journal      = {International Statistical Review},
  month        = {8},
  number       = {2},
  pages        = {419-440},
  shortjournal = {Int. Stat. Rev.},
  title        = {Statistical network analysis: A review with applications to the coronavirus disease 2019 pandemic},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Small area estimation for disease prevalence mapping.
<em>INSR</em>, <em>88</em>(2), 398–418. (<a
href="https://doi.org/10.1111/insr.12400">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Small area estimation (SAE) entails estimating characteristics of interest for domains, often geographical areas, in which there may be few or no samples available. SAE has a long history and a wide variety of methods have been suggested, from a bewildering range of philosophical standpoints. We describe design-based and model-based approaches and models that are specified at the area level and at the unit level, focusing on health applications and fully Bayesian spatial models. The use of auxiliary information is a key ingredient for successful inference when response data are sparse, and we discuss a number of approaches that allow the inclusion of covariate data. SAE for HIV prevalence, using data collected from a Demographic Health Survey in Malawi in 2015–2016, is used to illustrate a number of techniques. The potential use of SAE techniques for outcomes related to coronavirus disease 2019 is discussed.},
  archive      = {J_INSR},
  author       = {Jonathan Wakefield and Taylor Okonek and Jon Pedersen},
  doi          = {10.1111/insr.12400},
  journal      = {International Statistical Review},
  month        = {8},
  number       = {2},
  pages        = {398-418},
  shortjournal = {Int. Stat. Rev.},
  title        = {Small area estimation for disease prevalence mapping},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Foreword: COVID-19 mini-issue—statistical primers.
<em>INSR</em>, <em>88</em>(2), 396–397. (<a
href="https://doi.org/10.1111/insr.12401">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_INSR},
  author       = {Scott H. Holan and Nalini Ravishanker and J. Sunil Rao},
  doi          = {10.1111/insr.12401},
  journal      = {International Statistical Review},
  month        = {8},
  number       = {2},
  pages        = {396-397},
  shortjournal = {Int. Stat. Rev.},
  title        = {Foreword: COVID-19 mini-issue—Statistical primers},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Properties of h-likelihood estimators in clustered data.
<em>INSR</em>, <em>88</em>(2), 380–395. (<a
href="https://doi.org/10.1111/insr.12354">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study properties of the maximum h-likelihood estimators for random effects in clustered data. To define optimality in random effects predictions, several foundational concepts of statistics such as likelihood, unbiasedness, consistency, confidence distribution and the Cramer–Rao lower bound are extended. Exact probability statements about interval estimators for random effects can be made asymptotically without a prior assumption. Using the binary-matched pair example, we illustrated that the use of random effects recover information, leading to the boon on estimating treatment effects.},
  archive      = {J_INSR},
  author       = {Lee Youngjo and Gwangsu Kim},
  doi          = {10.1111/insr.12354},
  journal      = {International Statistical Review},
  month        = {8},
  number       = {2},
  pages        = {380-395},
  shortjournal = {Int. Stat. Rev.},
  title        = {Properties of h-likelihood estimators in clustered data},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Re-identification in the absence of common variables for
matching. <em>INSR</em>, <em>88</em>(2), 354–379. (<a
href="https://doi.org/10.1111/insr.12353">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A basic concern in statistical disclosure limitation is the re-identification of individuals in anonymised microdata. Linking against a second dataset that contains identifying information can result in a breach of confidentiality. Almost all linkage approaches are based on comparing the values of variables that are common to both datasets. It is tempting to think that if datasets contain no common variables, then there can be no risk of re-identification. However, linkage has been attempted between such datasets via the extraction of structural information using ordered weighted averaging (OWA) operators. Although this approach has been shown to perform better than randomly pairing records, it is debatable whether it demonstrates a practically significant disclosure risk. This paper reviews some of the main aspects of statistical disclosure limitation. It then goes on to show that a relatively simple, supervised Bayesian approach can consistently outperform OWA linkage. Furthermore, the Bayesian approach demonstrates a significant risk of re-identification for the types of data considered in the OWA record linkage literature.},
  archive      = {J_INSR},
  author       = {Duncan Smith},
  doi          = {10.1111/insr.12353},
  journal      = {International Statistical Review},
  month        = {8},
  number       = {2},
  pages        = {354-379},
  shortjournal = {Int. Stat. Rev.},
  title        = {Re-identification in the absence of common variables for matching},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Combining opinions for use in bayesian networks: A
measurement error approach. <em>INSR</em>, <em>88</em>(2), 335–353. (<a
href="https://doi.org/10.1111/insr.12350">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian networks (BNs) are graphical probabilistic models used for reasoning under uncertainty. These models are becoming increasingly popular in a range of fields including engineering, ecology, computational biology, medical diagnosis and forensics. In most of these cases, the BNs are quantified using information from experts or from users&#39; opinions. While this quantification is straightforward for one expert, there is still debate about how to represent opinions from multiple experts in a BN. This paper proposes the use of a measurement error model to achieve this. The proposed model addresses the issues associated with current methods of combining opinions such as the absence of a coherent probability model, the loss of the conditional independence structure of the BN and the provision of only a point estimate for the consensus. The proposed model is applied to a subnetwork (the three final nodes) of a larger BN about wayfinding in airports. It is shown that the approach performs well than do existing methods of combining opinions.},
  archive      = {J_INSR},
  author       = {A. Charisse Farr and Kerrie Mengersen and Fabrizio Ruggeri and Daniel Simpson and Paul Wu and Prasad Yarlagadda},
  doi          = {10.1111/insr.12350},
  journal      = {International Statistical Review},
  month        = {8},
  number       = {2},
  pages        = {335-353},
  shortjournal = {Int. Stat. Rev.},
  title        = {Combining opinions for use in bayesian networks: A measurement error approach},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Discussion. <em>INSR</em>, <em>88</em>(2), 330–334. (<a
href="https://doi.org/10.1111/insr.12392">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {I thoroughly enjoyed reading the article by Bhadra et. al . (2020) and convey my congratulations to the authors for providing a comprehensive and coherent review of horseshoe-based regularization approaches for machine learning models. I am thankful to the editors for providing this opportunity to write a discussion on this useful article, which I expect will turn out to be a good guide in the future for statisticians and practitioners alike. It is quite amazing to see the rapid progress and the magnitude of work advancing the horseshoe regularization approach since the seminal paper by Carvalho et al. (2010). The current review article is a testimony for this. While I have been primarily working with continuous spike and slab priors for high-dimensional Bayesian modeling, I have been following the literature on horseshoe regularization with a keen interest. For my comments on this article, I will focus on some comparisons between these two approaches particularly in terms of model building and methodology and some computational considerations. I would like to first provide some comments on performing valid inference based on the horsheshoe prior framework.},
  archive      = {J_INSR},
  author       = {Naveen Naidu Narisetty},
  doi          = {10.1111/insr.12392},
  journal      = {International Statistical Review},
  month        = {8},
  number       = {2},
  pages        = {330-334},
  shortjournal = {Int. Stat. Rev.},
  title        = {Discussion},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Discussion. <em>INSR</em>, <em>88</em>(2), 326–329. (<a
href="https://doi.org/10.1111/insr.12385">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_INSR},
  author       = {Robert B. Gramacy},
  doi          = {10.1111/insr.12385},
  journal      = {International Statistical Review},
  month        = {8},
  number       = {2},
  pages        = {326-329},
  shortjournal = {Int. Stat. Rev.},
  title        = {Discussion},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Discussion. <em>INSR</em>, <em>88</em>(2), 324–326. (<a
href="https://doi.org/10.1111/insr.12377">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_INSR},
  author       = {Soumya Ghosh and Finale Doshi-Velez},
  doi          = {10.1111/insr.12377},
  journal      = {International Statistical Review},
  month        = {8},
  number       = {2},
  pages        = {324-326},
  shortjournal = {Int. Stat. Rev.},
  title        = {Discussion},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Discussions. <em>INSR</em>, <em>88</em>(2), 321–324. (<a
href="https://doi.org/10.1111/insr.12375">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_INSR},
  author       = {David Dunson and Theodore Papamarkou},
  doi          = {10.1111/insr.12375},
  journal      = {International Statistical Review},
  month        = {8},
  number       = {2},
  pages        = {321-324},
  shortjournal = {Int. Stat. Rev.},
  title        = {Discussions},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Horseshoe regularisation for machine learning in complex and
deep models1. <em>INSR</em>, <em>88</em>(2), 302–320. (<a
href="https://doi.org/10.1111/insr.12360">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the advent of the horseshoe priors for regularisation, global–local shrinkage methods have proved to be a fertile ground for the development of Bayesian methodology in machine learning, specifically for high-dimensional regression and classification problems. They have achieved remarkable success in computation and enjoy strong theoretical support. Most of the existing literature has focused on the linear Gaussian case; for which systematic surveys are available. The purpose of the current article is to demonstrate that the horseshoe regularisation is useful far more broadly, by reviewing both methodological and computational developments in complex models that are more relevant to machine learning applications. Specifically, we focus on methodological challenges in horseshoe regularisation in non-linear and non-Gaussian models, multivariate models and deep neural networks. We also outline the recent computational developments in horseshoe shrinkage for complex models along with a list of available software implementations that allows one to venture out beyond the comfort zone of the canonical linear regression problems.},
  archive      = {J_INSR},
  author       = {Anindya Bhadra and Jyotishka Datta and Yunfan Li and Nicholas Polson},
  doi          = {10.1111/insr.12360},
  journal      = {International Statistical Review},
  month        = {8},
  number       = {2},
  pages        = {302-320},
  shortjournal = {Int. Stat. Rev.},
  title        = {Horseshoe regularisation for machine learning in complex and deep models1},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Women trailblazers in the statistical profession.
<em>INSR</em>, <em>88</em>(2), 280–301. (<a
href="https://doi.org/10.1111/insr.12386">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A brief historical introduction to nine women who were trailblazers in the statistical sciences is presented. During their times, men dominated the profession. Yet we see how these women in their various ways blazed trails and as such became mentors and inspirations for generations of women practitioners who worked with them and followed in their footsteps.},
  archive      = {J_INSR},
  author       = {Lynne Billard and Katherine K. Wallman},
  doi          = {10.1111/insr.12386},
  journal      = {International Statistical Review},
  month        = {8},
  number       = {2},
  pages        = {280-301},
  shortjournal = {Int. Stat. Rev.},
  title        = {Women trailblazers in the statistical profession},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Interview with professor adrian FM smith. <em>INSR</em>,
<em>88</em>(2), 265–279. (<a
href="https://doi.org/10.1111/insr.12395">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adrian Smith joined The Alan Turing Institute as Institute Director and Chief Executive in September 2018. In May 2020, he was confirmed as President Elect of the Royal Society. He is also a member of the government&#39;s AI Council, which helps boost AI growth in the UK and promote its adoption and ethical use in businesses and organisations across the country. Professor Smith&#39;s previous role was Vice-Chancellor of the University of London where he was in post from 2012. He is a past President of the Royal Statistical Society and was elected a Fellow of the Royal Society in 2001 in recognition of his contribution to statistics. In 2003-04 Professor Smith undertook an inquiry into Post-14 Mathematics Education for the UK Secretary of State for Education and Skills and in 2017, on behalf of Her Majesty&#39;s Treasury and the Department for Education, published a 16-18 Maths Review. In 2006 he completed a report for the UK Home Secretary on the issue of public trust in Crime Statistics. He received a knighthood in the 2011 New Year Honours list. The following conversation took place at the Alan Turing Institute in London, on July 19 2019.},
  archive      = {J_INSR},
  author       = {Petros Dellaportas and David A. Stephens},
  doi          = {10.1111/insr.12395},
  journal      = {International Statistical Review},
  month        = {8},
  number       = {2},
  pages        = {265-279},
  shortjournal = {Int. Stat. Rev.},
  title        = {Interview with professor adrian FM smith},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Model-based clustering and classification for data science,
charles bouveyron, gilles celeux, t. Brendan murphy and adrian e.
Raftery, cambridge university press, 2019, 427 + xvii pages, £59.99,
hardcover, ISBN: 978-1-1084-9420-5. <em>INSR</em>, <em>88</em>(1),
263–264. (<a href="https://doi.org/10.1111/insr.12372">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_INSR},
  author       = {Antony Unwin},
  doi          = {10.1111/insr.12372},
  journal      = {International Statistical Review},
  month        = {4},
  number       = {1},
  pages        = {263-264},
  shortjournal = {Int. Stat. Rev.},
  title        = {Model-based clustering and classification for data science, charles bouveyron, gilles celeux, t. brendan murphy and adrian e. raftery, cambridge university press, 2019, 427 + xvii pages, £59.99, hardcover, ISBN: 978-1-1084-9420-5},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Matrix differential calculus with applications in
statistics and econometrics, 3rd edition, jan r. Magnus and heinz
neudecker, john wiley &amp; sons, 2019, 504 pages, <span
class="math inline">115, <em>h</em><em>a</em><em>r</em><em>d</em><em>c</em><em>o</em><em>v</em><em>e</em><em>r</em>;</span><!-- -->92.99
ebook, ISBN: 978-1-1195-4116-5. <em>INSR</em>, <em>88</em>(1), 261–263.
(<a href="https://doi.org/10.1111/insr.12371">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_INSR},
  author       = {Shuangzhe Liu},
  doi          = {10.1111/insr.12371},
  journal      = {International Statistical Review},
  month        = {4},
  number       = {1},
  pages        = {261-263},
  shortjournal = {Int. Stat. Rev.},
  title        = {Matrix differential calculus with applications in statistics and econometrics, 3rd edition, jan r. magnus and heinz neudecker, john wiley &amp; sons, 2019, 504 pages, $115, hardcover; $92.99 ebook, ISBN: 978-1-1195-4116-5},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). High-dimensional statistics: A non-asymptotic viewpoint,
martin j. Wainwright, cambridge university press, 2019, xvii 552 pages,
£57.99, hardback ISBN: 978-1-1084-9802-9. <em>INSR</em>, <em>88</em>(1),
258–261. (<a href="https://doi.org/10.1111/insr.12370">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_INSR},
  author       = {G. Alastair Young},
  doi          = {10.1111/insr.12370},
  journal      = {International Statistical Review},
  month        = {4},
  number       = {1},
  pages        = {258-261},
  shortjournal = {Int. Stat. Rev.},
  title        = {High-dimensional statistics: a non-asymptotic viewpoint, martin j. wainwright, cambridge university press, 2019, xvii 552 pages, £57.99, hardback ISBN: 978-1-1084-9802-9},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). <em>INSR</em>, <em>88</em>(1), 256–258. (<a
href="https://doi.org/10.1111/insr.12369">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_INSR},
  author       = {Alexander Tsodikov},
  doi          = {10.1111/insr.12369},
  journal      = {International Statistical Review},
  month        = {4},
  number       = {1},
  pages        = {256-258},
  shortjournal = {Int. Stat. Rev.},
  title        = {Causal inference in statistics: a primer, judea pearl, madelyn glymour and nicholas p. jewell, john wiley &amp; sons, 2019, 156 pages, $46.75, paperback ISBN: 978-1-1191-8684-7},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). <em>INSR</em>, <em>88</em>(1), 255–256. (<a
href="https://doi.org/10.1111/insr.12368">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_INSR},
  author       = {Jorma K. Merikoski},
  doi          = {10.1111/insr.12368},
  journal      = {International Statistical Review},
  month        = {4},
  number       = {1},
  pages        = {255-256},
  shortjournal = {Int. Stat. Rev.},
  title        = {Introduction to probability: models and applications, n. balakrishnan, markos v. koutras and konstadinos g. politis, john wiley &amp; sons, 2020, xiii 608 pages, $140.00, hardcover ISBN: 978-1-1181-2334-8},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The road to quality control, homer m. Sarasohn, translated
by n. I. Fisher and y. Tanaka from the original japanese text by kagaku
shinko sha, john wiley &amp; sons, 2019, 160 pages, £89.95, hardcover,
ISBN: 978-1-1195-1493-0. <em>INSR</em>, <em>88</em>(1), 254–255. (<a
href="https://doi.org/10.1111/insr.12367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_INSR},
  author       = {Elsayed Elsayed},
  doi          = {10.1111/insr.12367},
  journal      = {International Statistical Review},
  month        = {4},
  number       = {1},
  pages        = {254-255},
  shortjournal = {Int. Stat. Rev.},
  title        = {The road to quality control, homer m. sarasohn, translated by n. i. fisher and y. tanaka from the original japanese text by kagaku shinko sha, john wiley &amp; sons, 2019, 160 pages, £89.95, hardcover, ISBN: 978-1-1195-1493-0},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020c). <em>INSR</em>, <em>88</em>(1), 252–254. (<a
href="https://doi.org/10.1111/insr.12366">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_INSR},
  author       = {Jorma K. Merikoski},
  doi          = {10.1111/insr.12366},
  journal      = {International Statistical Review},
  month        = {4},
  number       = {1},
  pages        = {252-254},
  shortjournal = {Int. Stat. Rev.},
  title        = {Random circulant matrices, arup bose and koushik saha, CRC press, 2019, xix + 192 pages, $174.95, hardcover ISBN: 978-1-1383-5109-7},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Shrinkage estimation strategies in generalised ridge
regression models: Low/high-dimension regime. <em>INSR</em>,
<em>88</em>(1), 229–251. (<a
href="https://doi.org/10.1111/insr.12351">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we suggest pretest and shrinkage methods based on the generalised ridge regression estimation that is suitable for both multicollinear and high-dimensional problems. We review and develop theoretical results for some of the shrinkage estimators. The relative performance of the shrinkage estimators to some penalty methods is compared and assessed by both simulation and real-data analysis. We show that the suggested methods can be accounted as good competitors to regularisation techniques, by means of a mean squared error of estimation and prediction error. A thorough comparison of pretest and shrinkage estimators based on the maximum likelihood method to the penalty methods. In this paper, we extend the comparison outlined in his work using the least squares method for the generalised ridge regression.},
  archive      = {J_INSR},
  author       = {Bahadır Yüzbaşı and Mohammad Arashi and S. Ejaz Ahmed},
  doi          = {10.1111/insr.12351},
  journal      = {International Statistical Review},
  month        = {4},
  number       = {1},
  pages        = {229-251},
  shortjournal = {Int. Stat. Rev.},
  title        = {Shrinkage estimation strategies in generalised ridge regression models: Low/High-dimension regime},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-source statistics: Basic situations and methods.
<em>INSR</em>, <em>88</em>(1), 203–228. (<a
href="https://doi.org/10.1111/insr.12352">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many National Statistical Institutes (NSIs), especially in Europe, are moving from single-source statistics to multi-source statistics. By combining data sources, NSIs can produce more detailed and more timely statistics and respond more quickly to events in society. By combining survey data with already available administrative data and Big Data, NSIs can save data collection and processing costs and reduce the burden on respondents. However, multi-source statistics come with new problems that need to be overcome before the resulting output quality is sufficiently high and before those statistics can be produced efficiently. What complicates the production of multi-source statistics is that they come in many different varieties as data sets can be combined in many different ways. Given the rapidly increasing importance of producing multi-source statistics in Official Statistics, there has been considerable research activity in this area over the last few years, and some frameworks have been developed for multi-source statistics. Useful as these frameworks are, they generally do not give guidelines to which method could be applied in a certain situation arising in practice. In this paper, we aim to fill that gap, structure the world of multi-source statistics and its problems and provide some guidance to suitable methods for these problems.},
  archive      = {J_INSR},
  author       = {Ton de Waal and Arnout van Delden and Sander Scholtus},
  doi          = {10.1111/insr.12352},
  journal      = {International Statistical Review},
  month        = {4},
  number       = {1},
  pages        = {203-228},
  shortjournal = {Int. Stat. Rev.},
  title        = {Multi-source statistics: Basic situations and methods},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A selective overview and comparison of robust mixture
regression estimators. <em>INSR</em>, <em>88</em>(1), 176–202. (<a
href="https://doi.org/10.1111/insr.12349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mixture regression models have been widely used in business, marketing and social sciences to model mixed regression relationships arising from a clustered and thus heterogeneous population. The unknown mixture regression parameters are usually estimated by maximum likelihood estimators using the expectation–maximisation algorithm based on the normality assumption of component error density. However, it is well known that the normality-based maximum likelihood estimation is very sensitive to outliers or heavy-tailed error distributions. This paper aims to give a selective overview of the recently proposed robust mixture regression methods and compare their performance using simulation studies.},
  archive      = {J_INSR},
  author       = {Chun Yu and Weixin Yao and Guangren Yang},
  doi          = {10.1111/insr.12349},
  journal      = {International Statistical Review},
  month        = {4},
  number       = {1},
  pages        = {176-202},
  shortjournal = {Int. Stat. Rev.},
  title        = {A selective overview and comparison of robust mixture regression estimators},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Measuring discontinuities in time series obtained with
repeated sample surveys. <em>INSR</em>, <em>88</em>(1), 155–175. (<a
href="https://doi.org/10.1111/insr.12347">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A key requirement of repeated surveys conducted by national statistical institutes is the comparability of estimates over time, resulting in uninterrupted time series describing the evolution of finite population parameters. This is often an argument to keep survey processes unchanged as long as possible. It is nevertheless inevitable that a survey process will need to be redesigned from time to time, for example, to improve or update methods or implement more cost-effective data collection procedures. It is important to quantify the systematic effects or discontinuities of a new survey process on the estimates of a repeated survey to avoid a disturbance in the comparability of estimates over time. This paper reviews different statistical methods that can be used to measure discontinuities and manage the risk due to a survey process redesign.},
  archive      = {J_INSR},
  author       = {Jan van den Brakel and Xichuan (Mark) Zhang and Siu-Ming Tam},
  doi          = {10.1111/insr.12347},
  journal      = {International Statistical Review},
  month        = {4},
  number       = {1},
  pages        = {155-175},
  shortjournal = {Int. Stat. Rev.},
  title        = {Measuring discontinuities in time series obtained with repeated sample surveys},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Asymptotics of the non-parametric function for
b-splines-based estimation in partially linear models. <em>INSR</em>,
<em>88</em>(1), 142–154. (<a
href="https://doi.org/10.1111/insr.12346">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider least squares method for partially linear models based on polynomial splines. We derive the asymptotic property for the estimator, focusing on the estimation of the non-parametric function , in particular whether and how the estimation of the linear part will affect the non-parametric part (the converse relation, that is, how the linear part will be affected by the non-parametric part is much better known, which we will also review). One important goal along the way is to clarify the role of projection in semiparametric models, which was nevertheless a classical trick for proving the asymptotic normality of the linear part . A crucial question we try to answer is whether projection plays any role in the estimation of the non-parametric function. The answer is both positive and negative depending on the direction along which to assess asymptotic normality. The style of writing of the paper is somewhat expository, and it also contains several new results not found in the current literature. Finally, we demonstrate in our numerical studies that construction of the pointwise confidence intervals for the non-parametric function motivated by our theory improves upon those constructed by pretending the linear part is known.},
  archive      = {J_INSR},
  author       = {Heng Lian},
  doi          = {10.1111/insr.12346},
  journal      = {International Statistical Review},
  month        = {4},
  number       = {1},
  pages        = {142-154},
  shortjournal = {Int. Stat. Rev.},
  title        = {Asymptotics of the non-parametric function for B-splines-based estimation in partially linear models},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The modal age of statistics. <em>INSR</em>, <em>88</em>(1),
122–141. (<a href="https://doi.org/10.1111/insr.12340">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, a number of statistical problems have found an unexpected solution by inspecting them through a ‘modal point of view&#39;. These include classical tasks such as clustering or regression. This has led to a renewed interest in estimation and inference for the mode. This paper offers an extensive survey of the traditional approaches to mode estimation and explores the consequences of applying this modern modal methodology to other, seemingly unrelated, fields.},
  archive      = {J_INSR},
  author       = {José E. Chacón},
  doi          = {10.1111/insr.12340},
  journal      = {International Statistical Review},
  month        = {4},
  number       = {1},
  pages        = {122-141},
  shortjournal = {Int. Stat. Rev.},
  title        = {The modal age of statistics},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sampling-based randomised designs for causal inference under
the potential outcomes framework. <em>INSR</em>, <em>88</em>(1),
101–121. (<a href="https://doi.org/10.1111/insr.12339">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We establish the inferential properties of the mean-difference estimator for the average treatment effect in randomised experiments where each unit in a population is randomised to one of two treatments and then units within treatment groups are randomly sampled. The properties of this estimator are well understood in the experimental design scenario where first units are randomly sampled and then treatment is randomly assigned but not for the aforementioned scenario where the sampling and treatment assignment stages are reversed. We find that the inferential properties of the mean-difference estimator under this experimental design scenario are identical to those under the more common sample-first-randomise-second design. This finding will bring some clarifications about sampling-based randomised designs for causal inference, particularly for settings where there is a finite super-population. Finally, we explore to what extent pre-treatment measurements can be used to improve upon the mean-difference estimator for this randomise-first-sample-second design. Unfortunately, we find that pre-treatment measurements are often unhelpful in improving the precision of average treatment effect estimators under this design, unless a large number of pre-treatment measurements that are highly associative with the post-treatment measurements can be obtained. We confirm these results using a simulation study based on a real experiment in nanomaterials.},
  archive      = {J_INSR},
  author       = {Zach Branson and Tirthankar Dasgupta},
  doi          = {10.1111/insr.12339},
  journal      = {International Statistical Review},
  month        = {4},
  number       = {1},
  pages        = {101-121},
  shortjournal = {Int. Stat. Rev.},
  title        = {Sampling-based randomised designs for causal inference under the potential outcomes framework},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Distribution-free approximate methods for constructing
confidence intervals for quantiles. <em>INSR</em>, <em>88</em>(1),
75–100. (<a href="https://doi.org/10.1111/insr.12338">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantile estimation is important for a wide range of applications. While point estimates based on one or two order statistics are common, constructing confidence intervals around them, however, is a more difficult problem. This paper has two goals. First, it surveys the numerous distribution-free methods for constructing approximate confidence intervals for quantiles. These techniques can be divided roughly into four categories: using a pivotal quantity, resampling, interpolation, and empirical likelihood methods. Second, a method based on the pivotal quantity that has received limited attention in the past is extended. Comprehensive simulation studies are used to compare performance across methods. The proposed method is simple and performs similarly to linear interpolation methods and a smoothed empirical likelihood method. While the proposed method has slightly wider interval widths, it can be calculated for more extreme quantiles even when there are few observations.},
  archive      = {J_INSR},
  author       = {Chaitra H. Nagaraja and Haikady N. Nagaraja},
  doi          = {10.1111/insr.12338},
  journal      = {International Statistical Review},
  month        = {4},
  number       = {1},
  pages        = {75-100},
  shortjournal = {Int. Stat. Rev.},
  title        = {Distribution-free approximate methods for constructing confidence intervals for quantiles},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Empirical likelihood approach for aligning information from
multiple surveys. <em>INSR</em>, <em>88</em>(1), 54–74. (<a
href="https://doi.org/10.1111/insr.12337">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When two surveys carried out separately in the same population have common variables, it might be desirable to adjust each survey&#39;s weights so that they give equal estimates for the common variables. This problem has been studied extensively and has often been referred to as alignment or numerical consistency . We develop a design-based empirical likelihood approach for alignment and estimation of complex parameters defined by estimating equations. We focus on a general case when a single set of adjusted weights, which can be applied to both common and non-common variables, is produced for each survey. The main contribution of the paper is to show that the impirical log-likelihood ratio statistic is pivotal in the presence of alignment constraints. This pivotal statistic can be used to test hypotheses and derive confidence regions. Hence, the empirical likelihood approach proposed for alignment possesses the self-normalisation property, under a design-based approach. The proposed approach accommodates large sampling fractions, stratification and population level auxiliary information. It is particularly well suited for inference about small domains, when data are skewed. It includes implicit adjustments when the samples considerably differ in size. The confidence regions are constructed without the need for variance estimates, joint-inclusion probabilities, linearisation and re-sampling.},
  archive      = {J_INSR},
  author       = {Yves G. Berger and Ewa Kabzińska},
  doi          = {10.1111/insr.12337},
  journal      = {International Statistical Review},
  month        = {4},
  number       = {1},
  pages        = {54-74},
  shortjournal = {Int. Stat. Rev.},
  title        = {Empirical likelihood approach for aligning information from multiple surveys},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A unifying framework and comparison of algorithms for
non-negative matrix factorisation. <em>INSR</em>, <em>88</em>(1), 29–53.
(<a href="https://doi.org/10.1111/insr.12331">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-negative matrix factorisation (NMF) is an increasingly popular unsupervised learning method. However, parameter estimation in the NMF model is a difficult high-dimensional optimisation problem. We consider algorithms of the alternating least squares type. Solutions to the least squares problem fall in two categories. The first category is iterative algorithms, which include algorithms such as the majorise–minimise (MM) algorithm, coordinate descent, gradient descent and the Févotte-Cemgil expectation–maximisation (FC-EM) algorithm. We introduce a new family of iterative updates based on a generalisation of the FC-EM algorithm. The coordinate descent, gradient descent and FC-EM algorithms are special cases of this new EM family of iterative procedures. Curiously, we show that the MM algorithm is never a member of our general EM algorithm. The second category is based on cone projection. We describe and prove a cone projection algorithm tailored to the non-negative least square problem. We compare the algorithms on a test case and on the problem of identifying mutational signatures in human cancer. We generally find that cone projection is an attractive choice. Furthermore, in the cancer application, we find that a mix-and-match strategy performs better than running each algorithm in isolation.},
  archive      = {J_INSR},
  author       = {Asger Hobolth and Qianyun Guo and Astrid Kousholt and Jens Ledet Jensen},
  doi          = {10.1111/insr.12331},
  journal      = {International Statistical Review},
  month        = {4},
  number       = {1},
  pages        = {29-53},
  shortjournal = {Int. Stat. Rev.},
  title        = {A unifying framework and comparison of algorithms for non-negative matrix factorisation},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multivariate small area estimation of multidimensional
latent economic well-being indicators. <em>INSR</em>, <em>88</em>(1),
1–28. (<a href="https://doi.org/10.1111/insr.12333">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Factor analysis models are used in data dimensionality reduction problems where the variability among observed variables can be described through a smaller number of unobserved latent variables. This approach is often used to estimate the multidimensionality of well-being. We employ factor analysis models and use multivariate empirical best linear unbiased predictor (EBLUP) under a unit-level small area estimation approach to predict a vector of means of factor scores representing well-being for small areas. We compare this approach with the standard approach whereby we use small area estimation (univariate and multivariate) to estimate a dashboard of EBLUPs of the means of the original variables and then averaged. Our simulation study shows that the use of factor scores provides estimates with lower variability than weighted and simple averages of standardised multivariate EBLUPs and univariate EBLUPs. Moreover, we find that when the correlation in the observed data is taken into account before small area estimates are computed, multivariate modelling does not provide large improvements in the precision of the estimates over the univariate modelling. We close with an application using the European Union Statistics on Income and Living Conditions data.},
  archive      = {J_INSR},
  author       = {Angelo Moretti and Natalie Shlomo and Joseph W. Sakshaug},
  doi          = {10.1111/insr.12333},
  journal      = {International Statistical Review},
  month        = {4},
  number       = {1},
  pages        = {1-28},
  shortjournal = {Int. Stat. Rev.},
  title        = {Multivariate small area estimation of multidimensional latent economic well-being indicators},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
