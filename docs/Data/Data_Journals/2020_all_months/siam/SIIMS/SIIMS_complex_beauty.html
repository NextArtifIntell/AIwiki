<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>SIIMS_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="siims---75">SIIMS - 75</h2>
<ul>
<li><details>
<summary>
(2020). Multiview clustering of images with tensor rank minimization
via nonconvex approach. <em>SIIMS</em>, <em>13</em>(4), 2361–2392. (<a
href="https://doi.org/10.1137/20M1318006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the image multiview subspace clustering problem via a nonconvex low-rank representation under the framework of tensors. Most of the recent studies of tensor based multiview subspace clustering use the tensor nuclear norm as a convex surrogate of the tensor rank, i.e., the t-SVD based multiview subspace clustering model. However, since the tensor nuclear norm is linearly proportional to the sum of singular values, the tensor rank approximation by using the tensor nuclear norm may become problematic if the ratios of the nonzero singular values are far from 1. In this paper, a nonconvex tensor log-determinant function is proposed as the objective function regularizer, aiming to achieve a better tensor low-rank approximation. Instead of directly solving the minimization problem in its original setting, the corresponding non-convex optimization is conducted in the Fourier domain, which is shown not only to be feasible but also to be quite effective. A corresponding algorithm associated with the augmented Lagrangian multipliers is established and the constructed convergent sequence to the desirable Karush--Kuhn--Tucker critical point solution is mathematically validated in detail. Extensive simulations on eight benchmark image datasets are provided, along with full comparisons with the latest existing approaches. The obtained results demonstrate that our proposed method significantly outperforms those convex approaches currently available in the literature.},
  archive      = {J_SIIMS},
  author       = {Ming Yang and Qilun Luo and Wen Li and Mingqing Xiao},
  doi          = {10.1137/20M1318006},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {2361-2392},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Multiview clustering of images with tensor rank minimization via nonconvex approach},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An algorithm for second order mumford–shah models based on a
taylor jet formulation. <em>SIIMS</em>, <em>13</em>(4), 2307–2360. (<a
href="https://doi.org/10.1137/19M1300959">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mumford--Shah models are well-established and powerful variational tools for the regularization of noisy data. In the case of images this includes regularizing both the edge set as well as the image values itself. Thus, these models may be used as a basis for a segmentation pipeline or for smoothing the data. In this paper we consider higher order Mumford--Shah functionals which penalize the deviation from piecewise polynomials instead of piecewise constant functions as first order Mumford--Shah functionals do. Minimizing Mumford--Shah functionals, which are nonsmooth and nonconvex functionals, are NP hard problems. Compared with first order Mumford--Shah functionals, numerically solving higher order models is even more challenging, and in contrast to work on more theoretical aspects there are only very few works dealing with the algorithmic side. In this paper, we propose a new algorithmic framework for second order Mumford--Shah regularization. It is based on a proposed reformulation of higher order Mumford--Shah problems in terms of Taylor jets and a corresponding discretization. Using an ADMM approach, we split the discrete jet-based problem into subproblems which we can solve efficiently, noniteratively, and exactly. We derive numerically stable and fast solvers for these subproblems. In summary, we obtain an efficient overall algorithm. Our method requires a priori knowledge on neither the gray or color levels nor the shape of the discontinuity set of a solution. We demonstrate the applicability of the proposed methods in various numerical experiments. In particular, we quantitatively and qualitatively compare the proposed scheme with the algorithms proposed in the literature.},
  archive      = {J_SIIMS},
  author       = {Lukas Kiefer and Martin Storath and Andreas Weinmann},
  doi          = {10.1137/19M1300959},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {2307-2360},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {An algorithm for second order mumford--shah models based on a taylor jet formulation},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal transport driven CycleGAN for unsupervised learning
in inverse problems. <em>SIIMS</em>, <em>13</em>(4), 2281–2306. (<a
href="https://doi.org/10.1137/20M1317992">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To improve the performance of classical generative adversarial networks (GANs), Wasserstein generative adversarial networks (WGANs) were developed as a Kantorovich dual formulation of the optimal transport (OT) problem using Wasserstein-1 distance. However, it was not clear how CycleGAN-type generative models can be derived from the OT theory. Here we show that a novel CycleGAN architecture can be derived as a Kantorovich dual OT formulation if a penalized least squares (PLS) cost with deep learning--based inverse path penalty is used as a transportation cost. One of the most important advantages of this formulation is that depending on the knowledge of the forward problem, distinct variations of CycleGAN architecture can be derived: for example, one with two pairs of generators and discriminators, and the other with only a single pair of generator and discriminator. Even for the two generator cases, we show that the structural knowledge of the forward operator can lead to a simpler generator architecture which significantly simplifies the neural network training. The new CycleGAN formulation, which we call the OT-CycleGAN, has been applied for various biomedical imaging problems, such as accelerated magnetic resonance imaging (MRI), super-resolution microscopy, and low-dose X-ray computed tomography (CT). Experimental results confirm the efficacy and flexibility of the theory.},
  archive      = {J_SIIMS},
  author       = {Byeongsu Sim and Gyutaek Oh and Jeongsol Kim and Chanyong Jung and Jong Chul Ye},
  doi          = {10.1137/20M1317992},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {2281-2306},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Optimal transport driven CycleGAN for unsupervised learning in inverse problems},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Imaging with the elliptic radon transform in three
dimensions from an analytical and numerical perspective. <em>SIIMS</em>,
<em>13</em>(4), 2250–2280. (<a
href="https://doi.org/10.1137/20M1332657">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The three-dimensional elliptic Radon transform (eRT) averages distributions over ellipsoids of revolution. It thus serves as a linear model in seismic imaging where one wants to recover the earth&#39;s interior from reflected wave fields. As there is no inversion formula known for the eRT, approximate formulas have to be used. In this paper we suggest several of those, microlocally analyze their properties, and provide and implement an adapted algorithm whose performance we test by diverse numerical experiments. Our previous results of [Inverse Problems, 34 (2018), 014002, 114001] are thus generalized to three space dimensions.},
  archive      = {J_SIIMS},
  author       = {Christine Grathwohl and Peer Christian Kunstmann and Eric Todd Quinto and Andreas Rieder},
  doi          = {10.1137/20M1332657},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {2250-2280},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Imaging with the elliptic radon transform in three dimensions from an analytical and numerical perspective},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Synthetic aperture imaging and motion estimation using
tensor methods. <em>SIIMS</em>, <em>13</em>(4), 2213–2249. (<a
href="https://doi.org/10.1137/19M1306440">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a synthetic aperture imaging configuration, such as synthetic aperture radar (SAR), where we want to first separate reflections from moving targets from those coming from a stationary background, and then to image separately the moving and the stationary reflectors. For this purpose, we introduce a representation of the data as a third-order tensor formed from data coming from partially overlapping subapertures. We then apply a tensor robust principal component analysis (TRPCA) to the tensor data which separates it into the parts coming from the stationary and moving reflectors. A key feature of the proposed algorithm is the use of a Fourier-based tensor nuclear norm which is well adapted to the SAR data structure. Images are then formed with the separated data sets. Our analysis shows a distinctly improved performance of TRPCA, compared to the usual matrix case. In particular, the tensor decomposition can identify motion features that are undetectable when using the conventional motion estimation methods, including matrix RPCA. We illustrate the performance of the method with numerical simulations in the X-band radar regime.},
  archive      = {J_SIIMS},
  author       = {Matan Leibovich and George Papanicolaou and Chrysoula Tsogka},
  doi          = {10.1137/19M1306440},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {2213-2249},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Synthetic aperture imaging and motion estimation using tensor methods},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Anisotropic adapted meshes for image segmentation:
Application to three-dimensional medical data. <em>SIIMS</em>,
<em>13</em>(4), 2189–2212. (<a
href="https://doi.org/10.1137/20M1348303">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work focuses on a variational approach to image segmentation based on the Ambrosio--Tortorelli functional. We propose an efficient algorithm, which combines the functional minimization with a smart choice of the computational mesh. With this aim, we resort to an anisotropic mesh adaptation procedure driven by an a posteriori recovery-based error analysis. We apply the proposed algorithm to a computed tomography dataset of a fractured pelvis to create a virtual model of the anatomy. The result is verified against a semiautomatic segmentation carried out using the ITK-SNAP tool. Furthermore, a physical replica of the virtual model is produced by means of fused filament fabrication technology to assess the appropriateness of the proposed solution in terms of resolution-quality balance for three-dimensional printing production.},
  archive      = {J_SIIMS},
  author       = {Francesco Clerici and Nicola Ferro and Stefania Marconi and Stefano Micheletti and Erika Negrello and Simona Perotto},
  doi          = {10.1137/20M1348303},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {2189-2212},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Anisotropic adapted meshes for image segmentation: Application to three-dimensional medical data},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). CURE: Curvature regularization for missing data recovery.
<em>SIIMS</em>, <em>13</em>(4), 2169–2188. (<a
href="https://doi.org/10.1137/19M1261845">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Missing data recovery is an important and yet challenging problem in imaging and data science. Successful models often adopt certain carefully chosen regularization. Recently, the low dimensional manifold model (LDMM) was introduced by [S. Osher, Z. Shi, and W. Zhu, Low Dimensional Manifold Model for Image Processing, Technical report, cam report 16-04, UCLA, Los Angeles, CA, 2016] and shown to be effective in image inpainting. The authors of [Low Dimensional Manifold Model for Image Processing, Technical report, cam report 16-04, UCLA, Los Angeles, CA, 2016] observed that enforcing low dimensionality on the image patch manifold serves as a good image regularizer. In this paper, we observe that having only the low dimensional manifold regularization is not enough sometimes, and we need smoothness as well. For that, we introduce a new regularization by combining the low dimensional manifold regularization with a higher order \bf CUrvature \bf REgularization, which we call new regularization CURE for short. The key step of CURE is to solve a biharmonic equation on a manifold. We further introduce a weighted version of CURE, called WeCURE, in a similar manner as the weighted nonlocal Laplacian (WNLL) method [Z. Shi, S. Osher, and W. Zhu, Weighted nonlocal Laplacian on interpolation from sparse data, J. Sci. Comput., 73 (2017), pp. 1164--1177]. Numerical experiments for image inpainting and semisupervised learning show that the proposed CURE and WeCURE significantly outperform LDMM and WNLL, respectively.},
  archive      = {J_SIIMS},
  author       = {Bin Dong and Haocheng Ju and Yiping Lu and Zuoqiang Shi},
  doi          = {10.1137/19M1261845},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {2169-2188},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {CURE: Curvature regularization for missing data recovery},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A nonlocal feature-driven exemplar-based approach for image
inpainting. <em>SIIMS</em>, <em>13</em>(4), 2140–2168. (<a
href="https://doi.org/10.1137/20M1317864">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a nonlocal variational image completion technique which admits simultaneous inpainting of multiple structures and textures in a unified framework. The recovery of geometric structures is achieved by using general convolution operators as a measure of behavior within an image. These are combined with a nonlocal exemplar-based approach to exploit the self-similarity of an image in the selected feature domains and to ensure the inpainting of textures. We also introduce an anisotropic patch distance metric to allow for better control of the feature selection within an image and present a nonlocal energy functional based on this metric. Finally, we derive an optimization algorithm for the proposed variational model and examine its validity experimentally with various test images.},
  archive      = {J_SIIMS},
  author       = {Viktor Reshniak and Jeremy Trageser and Clayton G. Webster},
  doi          = {10.1137/20M1317864},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {2140-2168},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A nonlocal feature-driven exemplar-based approach for image inpainting},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Image segmentation with partial convexity shape prior using
discrete conformality structures. <em>SIIMS</em>, <em>13</em>(4),
2105–2139. (<a href="https://doi.org/10.1137/19M129718X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image segmentation aims to partition an image into meaningful regions and extract important objects therein. In real applications, the given images may contain multiple overlapping objects with noisy background, creating great challenges to the segmentation task. In these cases, prior information of the target object is essential for an accurate and meaningful segmentation result. In this paper, we present a new convexity shape prior segmentation framework to guarantee the segmented region to be fully or partially convex according to the user&#39;s preference. The basic idea is to incorporate a registration-based segmentation model with a specially designed convexity constraint. The convexity constraint is based on the discrete conformality structures of the image mesh. To solve the segmentation model, we propose an iterative scheme, which smoothly deforms a template object to trace the boundary of the target object. A projection is carried out to enforce the convexity constraint. The target object is then captured by a (fully or partially) convex region. Convexity is the only prior information needed for a (fully) convex shape, whereas the location of partial convexity is needed for a partially convex shape. Experiments have been carried out on both synthetic and real images and the results demonstrate the effectiveness of our proposed framework.},
  archive      = {J_SIIMS},
  author       = {Chun Yin Siu and Hei Long Chan and Ronald Lok Ming Lui},
  doi          = {10.1137/19M129718X},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {2105-2139},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Image segmentation with partial convexity shape prior using discrete conformality structures},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Higher-order total directional variation: Imaging
applications. <em>SIIMS</em>, <em>13</em>(4), 2063–2104. (<a
href="https://doi.org/10.1137/19M1239209">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a class of higher-order anisotropic total variation regularizers, which are defined for possibly inhomogeneous, smooth elliptic anisotropies, that extends the total generalized variation regularizer and its variants. We propose a primal-dual hybrid gradient approach to approximating numerically the associated gradient flow. This choice of regularizers allows us to preserve and enhance intrinsic anisotropic features in images. This is illustrated on various examples from different imaging applications: image denoising, wavelet-based image zooming, and reconstruction of surfaces from scattered height measurements.},
  archive      = {J_SIIMS},
  author       = {Simone Parisotto and Jan Lellmann and Simon Masnou and Carola-Bibiane Schönlieb},
  doi          = {10.1137/19M1239209},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {2063-2104},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Higher-order total directional variation: Imaging applications},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Accelerated optimization in the PDE framework formulations
for the active contour case. <em>SIIMS</em>, <em>13</em>(4), 2029–2062.
(<a href="https://doi.org/10.1137/19M1304210">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Following the seminal work of Nesterov, accelerated optimization methods have been used to powerfully boost the performance of first-order, gradient based parameter estimation in scenarios where second-order optimization strategies are either inapplicable or impractical. Not only does accelerated gradient descent converge considerably faster than traditional gradient descent, but it also performs a more robust local search of the parameter space by initially overshooting and then oscillating back as it settles into a final configuration, thereby selecting only local minimizers with a basis of attraction large enough to contain the initial overshoot. This behavior has made accelerated and stochastic gradient search methods particularly popular within the machine learning community. In their recent PNAS 2016 paper, A Variational Perspective on Accelerated Methods in Optimization, Wibisono, Wilson, and Jordan demonstrate how a broad class of accelerated schemes can be cast in a variational framework formulated around the Bregman divergence, leading to continuum limit ODEs. We show how their formulation may be further extended to infinite dimensional manifolds (starting here with the geometric space of curves and surfaces) by substituting the Bregman divergence with inner products on the tangent space and explicitly introducing a distributed mass model which evolves in conjunction with the object of interest during the optimization process. The coevolving mass model, which is introduced purely for the sake of endowing the optimization with helpful dynamics, also links the resulting class of accelerated PDE based optimization schemes to fluid dynamical formulations of optimal mass transport.},
  archive      = {J_SIIMS},
  author       = {Anthony Yezzi and Ganesh Sundaramoorthi and Minas Benyamin},
  doi          = {10.1137/19M1304210},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {2029-2062},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Accelerated optimization in the PDE framework formulations for the active contour case},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Maximum likelihood estimation of regularization parameters
in high-dimensional inverse problems: An empirical bayesian approach.
Part II: Theoretical analysis. <em>SIIMS</em>, <em>13</em>(4),
1990–2028. (<a href="https://doi.org/10.1137/20M1339842">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a detailed theoretical analysis of the three stochastic approximation proximal gradient algorithms proposed in our companion paper [A. F. Vidal et al., SIAM J. Imaging Sci., 13 (2020), pp. 1945--1989] to set regularization parameters by marginal maximum likelihood estimation. We prove the convergence of a more general stochastic approximation scheme that includes the three algorithms of [A. F. Vidal et al., SIAM J. Imaging Sci., 13 (2020), pp. 1945--1989] as special cases. This includes asymptotic and nonasymptotic convergence results with natural and easily verifiable conditions, as well as explicit bounds on the convergence rates. Importantly, the theory is also general in that it can be applied to other intractable optimization problems. A main novelty of the work is that the stochastic gradient estimates of our scheme are constructed from inexact proximal Markov chain Monte Carlo samplers. This allows the use of samplers that scale efficiently to large problems and for which we have precise theoretical guarantees.},
  archive      = {J_SIIMS},
  author       = {Valentin De Bortoli and Alain Durmus and Marcelo Pereyra and Ana Fernandez Vidal},
  doi          = {10.1137/20M1339842},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {1990-2028},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Maximum likelihood estimation of regularization parameters in high-dimensional inverse problems: an empirical bayesian approach. part II: theoretical analysis},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Maximum likelihood estimation of regularization parameters
in high-dimensional inverse problems: An empirical bayesian approach
part i: Methodology and experiments. <em>SIIMS</em>, <em>13</em>(4),
1945–1989. (<a href="https://doi.org/10.1137/20M1339829">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many imaging problems require solving an inverse problem that is ill-conditioned or ill-posed. Imaging methods typically address this difficulty by regularizing the estimation problem to make it well- posed. This often requires setting the value of the so-called regularization parameters that control the amount of regularization enforced. These parameters are notoriously difficult to set a priori and can have a dramatic impact on the recovered estimates. In this work, we propose a general empirical Bayesian method for setting regularization parameters in imaging problems that are convex w.r.t. the unknown image. Our method calibrates regularization parameters directly from the observed data by maximum marginal likelihood estimation and can simultaneously estimate multiple regularization parameters. Furthermore, the proposed algorithm uses the same basic operators as proximal optimization algorithms, namely gradient and proximal operators, and it is therefore straightforward to apply to problems that are currently solved by using proximal optimization techniques. Our methodology is demonstrated with a range of experiments and comparisons with alternative approaches from the literature. The considered experiments include image denoising, nonblind image deconvolution, and hyperspectral unmixing, using synthesis and analysis priors involving the $\ell_1$, total-variation, total-variation and $\ell_1$, and total-generalized-variation pseudonorms. A detailed theoretical analysis of the proposed method is presented in our companion paper [V. De Bortoli et al., SIAM J. Imaging Sci., 13 (2020), pp. 1990--2028].},
  archive      = {J_SIIMS},
  author       = {Ana Fernandez Vidal and Valentin De Bortoli and Marcelo Pereyra and Alain Durmus},
  doi          = {10.1137/20M1339829},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {1945-1989},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Maximum likelihood estimation of regularization parameters in high-dimensional inverse problems: an empirical bayesian approach part i: methodology and experiments},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Common lines ab initio reconstruction of <span
class="math inline"><em>D</em><sub>2</sub></span>-symmetric molecules in
cryo-electron microscopy. <em>SIIMS</em>, <em>13</em>(4), 1898–1944. (<a
href="https://doi.org/10.1137/20M131535X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cryo-electron microscopy is a state-of-the-art method for determining high-resolution three-dimensional models of molecules from their two-dimensional projection images. A key step in this method is estimating a low-resolution model of the investigated molecule using only its projection images without any other prior information. Robust algorithms for this step for molecules without symmetry or with cyclic symmetry have been proposed, typically based on common lines between pairs of images. Deriving a common lines algorithm for molecules with $D_{2}$ symmetry is more challenging, since such molecules are invariant to an arbitrary orientation-preserving permutation of their coordinate system. This invariance also renders previous common lines algorithms inapplicable to $D_{2}$ symmetric molecules. In this work, we present a common lines algorithm for determining the structure of molecules with $D_{2}$ symmetry. We derive the geometry that the $D_{2}$ symmetry group induces on the common lines between pairs of images, develop a procedure for estimating the relative orientation of pairs of images, characterize the ambiguities inherent in these orientations due to the $D_{2}$ symmetry, and describe a robust method for combining all relative orientations into a single consistent assignment of orientations to all images. In contrast to local-search based methods, our procedure is unbiased, reference free, and guaranteed to find a globally consistent solution for the orientation assignment problem. We demonstrate the applicability of our algorithm using experimental cryo-electron microscopy data.},
  archive      = {J_SIIMS},
  author       = {Eitan Rosen and Yoel Shkolnisky},
  doi          = {10.1137/20M131535X},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {1898-1944},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Common lines ab initio reconstruction of $D_{2}$-symmetric molecules in cryo-electron microscopy},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Compressive computed tomography reconstruction through
denoising approximate message passing. <em>SIIMS</em>, <em>13</em>(4),
1860–1897. (<a href="https://doi.org/10.1137/19M1310013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {X-ray computed tomography (CT) reconstruction from a sparse number of views is a useful way to reduce either the radiation dose or the acquisition time, for example in fixed-gantry CT systems; however, this results in an ill-posed inverse problem whose solution is typically computationally demanding. Approximate message passing (AMP) techniques represent the state of the art for solving undersampling compressed sensing problems with random linear measurements, but there are still not clear solutions on how AMP should be modified and how it performs with real world problems. This paper investigates the question of whether we can employ an AMP framework for real sparse view CT imaging. The proposed algorithm for approximate inference in tomographic reconstruction incorporates a number of advances from within the AMP community, resulting in the denoising generalized approximate message passing CT algorithm (D-GAMP-CT). Specifically, this exploits the use of sophisticated image denoisers to regularize the reconstruction. While in order to reduce the probability of divergence the (Radon) system and the Poisson nonlinear noise model are treated separately, exploiting the existence of efficient preconditioners for the former and the generalized noise modeling in GAMP for the latter. Experiments with simulated and real CT baggage scans confirm that the performance of the proposed algorithm outperforms statistical CT optimization solvers.},
  archive      = {J_SIIMS},
  author       = {Alessandro Perelli and Michael Lexa and Ali Can and Mike E. Davies},
  doi          = {10.1137/19M1310013},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {1860-1897},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Compressive computed tomography reconstruction through denoising approximate message passing},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Curvature regularized surface reconstruction from point
clouds. <em>SIIMS</em>, <em>13</em>(4), 1834–1859. (<a
href="https://doi.org/10.1137/20M1314525">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a variational functional with a curvature constraint to reconstruct implicit surfaces from point cloud data. In the point cloud data, only locations are assumed to be given, without any normal direction or any curvature estimation. The minimizing functional balances two terms: the distance function from the point cloud to the surface and the mean curvature of the surface itself. We explore both the $L_1$ and $L_2$ norms for the curvature constraint. With the added curvature constraint, the computation becomes particularly challenging. We propose two efficient algorithms. The first algorithm is a novel operator splitting method. It replaces the original high-order PDEs by a decoupled PDE system, which is solved by a semi-implicit method. We also discuss an approach based on an augmented Lagrangian method. The proposed model shows robustness against noise and recovers concave features and corners better compared to models without curvature constraint. Numerical experiments on two- and three-dimensional data sets, noisy data and sparse data, are presented to validate the model. Experiments show that the operator splitting semi-implicit method is flexible and robust.},
  archive      = {J_SIIMS},
  author       = {Yuchen He and Sung Ha Kang and Hao Liu},
  doi          = {10.1137/20M1314525},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {1834-1859},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Curvature regularized surface reconstruction from point clouds},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Asymptotic expansions for higher order elliptic equations
with an application to quantitative photoacoustic tomography.
<em>SIIMS</em>, <em>13</em>(4), 1781–1833. (<a
href="https://doi.org/10.1137/20M1317062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we derive new asymptotic expansions for the solutions of higher order elliptic equations in the presence of small inclusions. As a byproduct, we derive a topological derivative based algorithm for the reconstruction of piecewise smooth functions. This algorithm can be used for edge detection in imaging, topological optimization, and inverse problems, such as quantitative photoacoustic tomography, for which we demonstrate the effectiveness of our asymptotic expansion method numerically.},
  archive      = {J_SIIMS},
  author       = {Andrea Aspri and Elena Beretta and Otmar Scherzer and Monika Muszkieta},
  doi          = {10.1137/20M1317062},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {1781-1833},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Asymptotic expansions for higher order elliptic equations with an application to quantitative photoacoustic tomography},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A sampling theorem for deconvolution in two dimensions.
<em>SIIMS</em>, <em>13</em>(4), 1754–1780. (<a
href="https://doi.org/10.1137/20M1329615">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work studies the problem of estimating a two-dimensional superposition of point sources or spikes from samples of their convolution with a Gaussian kernel. Our results show that minimizing a continuous counterpart of the $\ell_1$-norm exactly recovers the true spikes if they are sufficiently separated, and the samples are sufficiently dense. In addition, we provide numerical evidence that our results extend to non-Gaussian kernels relevant to microscopy and telescopy.},
  archive      = {J_SIIMS},
  author       = {Joseph McDonald and Brett Bernstein and Carlos Fernandez-Granda},
  doi          = {10.1137/20M1329615},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {1754-1780},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A sampling theorem for deconvolution in two dimensions},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Solving jigsaw puzzles by the graph connection laplacian.
<em>SIIMS</em>, <em>13</em>(4), 1717–1753. (<a
href="https://doi.org/10.1137/19M1290760">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel mathematical framework to address the problem of automatically solving large jigsaw puzzles. This problem assumes a large image, which is cut into equal square pieces that are arbitrarily rotated and shuffled, and asks to recover the original image given the transformed pieces. The main contribution of this work is a method for recovering the rotations of the pieces when both shuffles and rotations are unknown. A major challenge of this procedure is estimating the graph connection Laplacian without the knowledge of shuffles. A careful combination of our proposed method for estimating rotations with any existing method for estimating shuffles results in a practical solution for the jigsaw puzzle problem. Our theory guarantees, in a clean setting, that our basic idea of recovering rotations is robust to some corruption of the connection graph. Numerical experiments demonstrate the competitive accuracy of this solution, its robustness to corruption, and its computational advantage for large puzzles.},
  archive      = {J_SIIMS},
  author       = {Vahan Huroyan and Gilad Lerman and Hau-Tieng Wu},
  doi          = {10.1137/19M1290760},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {1717-1753},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Solving jigsaw puzzles by the graph connection laplacian},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A three-stage variational image segmentation framework
incorporating intensity inhomogeneity information. <em>SIIMS</em>,
<em>13</em>(3), 1692–1715. (<a
href="https://doi.org/10.1137/20M1310618">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a new three-stage segmentation framework based on a convex variant of the Mumford--Shah model and the intensity inhomogeneity information of an image. The first stage in our framework is to perform a dimension lifting method. An intensity inhomogeneity image is added as an additional channel, which results in a vector-valued image. In the second stage, a convex variant of the Mumford--Shah model is applied to each channel of the vector-valued image to obtain a smooth approximation. We use the semi--proximal alternating direction method of multipliers (sPADMM) to solve this model and prove that the sPADMM for solving this convex model has Q-linear convergence rate. In the last stage, we apply a thresholding method to the smoothed vector-valued image to get the final segmentation. Experiments demonstrate clearly that the proposed methods can provide more accurate segmentation results in comparison with five state-of-the-art methods including a deep learning approach.},
  archive      = {J_SIIMS},
  author       = {Xu Li and Xiaoping Yang and Tieyong Zeng},
  doi          = {10.1137/20M1310618},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1692-1715},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A three-stage variational image segmentation framework incorporating intensity inhomogeneity information},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). 3D orientation-preserving variational models for accurate
image registration. <em>SIIMS</em>, <em>13</em>(3), 1653–1691. (<a
href="https://doi.org/10.1137/20M1320006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Beltrami coefficient from complex analysis has recently been found to provide a robust constraint for obtaining orientation-preserving and diffeomorphic transformations for registration of planar images. There exists no such concept of the Beltrami coefficient in three or higher dimensions, although a generalized theory of quasi-conformal maps in high dimensions exists. In this paper, we first propose a new algebraic measure in three dimensions (3D) that mimics the Beltrami concept in two dimensions (2D) and then propose a corresponding registration model based on it. We then establish the existence of solutions for the proposed model and further propose a converging generalized Gauss--Newton iterative method to solve the resulting nonlinear optimization problem. In addition, we also provide another two possible regularizers in 3D. Numerical experiments show that the new model can produce more accurate orientation-preserving transformations than competing state-of-the-art registration models.},
  archive      = {J_SIIMS},
  author       = {Daoping Zhang and Ke Chen},
  doi          = {10.1137/20M1320006},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1653-1691},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {3D orientation-preserving variational models for accurate image registration},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Exact recovery of multichannel sparse blind deconvolution
via gradient descent. <em>SIIMS</em>, <em>13</em>(3), 1630–1652. (<a
href="https://doi.org/10.1137/19M1291327">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the multichannel sparse blind deconvolution (MCS-BD) problem, whose task is to simultaneously recover a kernel $a$ and multiple sparse inputs ${x_i}_{i=1}^p$ from their circulant convolution $y_i = a \;\circledast \;x_i $ ($i=1,\dots,p$). We formulate the task as a nonconvex optimization problem over the sphere. Under mild statistical assumptions of the data, we prove that the vanilla Riemannian gradient descent (RGD) method, with random initializations, provably recovers both the kernel $a$ and the signals ${x_i}_{i=1}^p$ up to a signed shift ambiguity. In comparison with state-of-the-art results, our work shows significant improvements in terms of sample complexity and computational efficiency. Our theoretical results are corroborated by numerical experiments, which demonstrate the superior performance of the proposed approach over the previous methods on both synthetic and real datasets.},
  archive      = {J_SIIMS},
  author       = {Qing Qu and Xiao Li and Zhihui Zhu},
  doi          = {10.1137/19M1291327},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1630-1652},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Exact recovery of multichannel sparse blind deconvolution via gradient descent},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multiplicative noise removal: Nonlocal low-rank model and
its proximal alternating reweighted minimization algorithm.
<em>SIIMS</em>, <em>13</em>(3), 1595–1629. (<a
href="https://doi.org/10.1137/20M1313167">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of this paper is to develop a novel numerical method for efficient multiplicative noise removal. The nonlocal self-similarity of natural images implies that the matrices formed by their nonlocal similar patches are low-rank. By exploiting this low-rank prior with application to multiplicative noise removal, we propose a nonlocal low-rank model for this task and develop a proximal alternating reweighted minimization (PARM) algorithm to solve the optimization problem resulting from the model. Specifically, we utilize a generalized nonconvex surrogate of the rank function to regularize the patch matrices and develop a new nonlocal low-rank model, which is a nonconvex nonsmooth optimization problem having a patchwise data fidelity and a generalized nonlocal low-rank regularization term. To solve this optimization problem, we propose the PARM algorithm, which has a proximal alternating scheme with a reweighted approximation of its subproblem. A theoretical analysis of the proposed PARM algorithm is conducted to guarantee its global convergence to a critical point. Numerical experiments demonstrate that the proposed method for multiplicative noise removal significantly outperforms existing methods, such as the benchmark SAR-BM3D method, in terms of the visual quality of the denoised images, and of the peak-signal-to-noise ratio (PSNR) and the structural similarity index measure (SSIM) values.},
  archive      = {J_SIIMS},
  author       = {Xiaoxia Liu and Jian Lu and Lixin Shen and Chen Xu and Yuesheng Xu},
  doi          = {10.1137/20M1313167},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1595-1629},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Multiplicative noise removal: Nonlocal low-rank model and its proximal alternating reweighted minimization algorithm},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multitaper estimation on arbitrary domains. <em>SIIMS</em>,
<em>13</em>(3), 1565–1594. (<a
href="https://doi.org/10.1137/19M1278338">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multitaper estimators have enjoyed significant success in estimating spectral densities from finite samples using as tapers Slepian functions defined on the acquisition domain. Unfortunately, the numerical calculation of these Slepian tapers is only tractable for certain symmetric domains, such as rectangles or disks. In addition, no performance bounds are currently available for the mean squared error of the spectral density estimate. This situation is inadequate for applications such as cryo-electron microscopy, where noise models must be estimated from irregular domains with small sample sizes. We show that the multitaper estimator only depends on the linear space spanned by the tapers. As a result, Slepian tapers may be replaced by proxy tapers spanning the same subspace (validating the common practice of using partially converged solutions to the Slepian eigenproblem as tapers). These proxies may consequently be calculated using standard numerical algorithms for block diagonalization. We also prove a set of performance bounds for multitaper estimators on arbitrary domains. The method is demonstrated on synthetic and experimental datasets from cryo-electron microscopy, where it reduces the mean squared error by a factor of two or more compared to traditional methods.},
  archive      = {J_SIIMS},
  author       = {Joakim Andén and José Luis Romero},
  doi          = {10.1137/19M1278338},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1565-1594},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Multitaper estimation on arbitrary domains},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new efficient algorithm for volume-preserving
parameterizations of genus-one 3-manifolds. <em>SIIMS</em>,
<em>13</em>(3), 1536–1564. (<a
href="https://doi.org/10.1137/19M1301096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parameterizations of manifolds are widely applied to the fields of numerical partial differential equations and computer graphics. To this end, in recent years several efficient and reliable numerical algorithms have been developed by different research groups for the computation of triangular and tetrahedral mesh parameterizations. However, it is still challenging when the topology of manifolds is nontrivial, e.g., the 3-manifold of a topological solid torus. In this paper, we propose a novel volumetric stretch energy minimization algorithm for volume-preserving parameterizations of toroidal polyhedra with a single boundary being mapped to a standard torus. In addition, the algorithm can also be used to compute the equiareal mapping between a genus-one closed surface and the standard torus. Numerical experiments indicate that the developed algorithm is effective and performs well on the bijectivity of the mapping. Applications on manifold registrations and partitions are demonstrated to show the robustness of our algorithms.},
  archive      = {J_SIIMS},
  author       = {Mei-Heng Yueh and Tiexiang Li and Wen-Wei Lin and Shing-Tung Yau},
  doi          = {10.1137/19M1301096},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1536-1564},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A new efficient algorithm for volume-preserving parameterizations of genus-one 3-manifolds},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Reconstruction of smooth 3D color functions from keypoints:
Application to lossy compression and exemplar-based generation of color
LUTs. <em>SIIMS</em>, <em>13</em>(3), 1511–1535. (<a
href="https://doi.org/10.1137/19M1306798">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-dimensional (3D) CLUTs (color lookup tables) are popular digital models used in artistic image and video processing for color grading, simulation of analog films, and more generally the description and application of generic nonparametric color transformations. The relatively large size of these models leads to high data storage requirements when trying to distribute them on a large scale (e.g., several hundred at a time). In this article, an effective technique based on a multiscale anisotropic diffusion scheme is proposed, for the lossy compression of generic CLUTs regularly sampled on a 3D grid. Our method exhibits high average compression rates, while ensuring visually indistinguishable differences with the original (uncompressed) CLUTs. In a second step, a variation of our algorithm for exemplar-based generation of CLUTs is developed in order to create a complete CLUT from a single pair of before/after images that accounts for the color transformation.},
  archive      = {J_SIIMS},
  author       = {David Tschumperlé and Christine Porquet and Amal Mahboubi},
  doi          = {10.1137/19M1306798},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1511-1535},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Reconstruction of smooth 3D color functions from keypoints: Application to lossy compression and exemplar-based generation of color LUTs},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Superresolution in recovering embedded electromagnetic
sources in high contrast media. <em>SIIMS</em>, <em>13</em>(3),
1467–1510. (<a href="https://doi.org/10.1137/20M1313908">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of this work is to provide a rigorous mathematical analysis of the expected superresolution phenomenon in the time-reversal imaging of electromagnetic (EM) radiating sources embedded in a high contrast medium. It is known that the resolution limit is essentially determined by the sharpness of the imaginary part of the EM Green&#39;s tensor for the associated background. We first establish the close connection between the resolution and the material parameters and the resolvent of the electric integral operator, via the Lippmann--Schwinger representation formula. We then present an insightful characterization of the spectral structure of the integral operator for a general bounded domain and derive the pole-pencil decomposition of its resolvent in the high contrast regime. For the special case of a spherical domain, we provide some quantitative asymptotic behavior of the eigenvalues and eigenfunctions. These mathematical findings shall enable us to provide a concise and rigorous illustration of the superresolution in the EM source reconstruction in high contrast media. Some numerical examples are also presented to verify our main theoretical results.},
  archive      = {J_SIIMS},
  author       = {Habib Ammari and Bowen Li and Jun Zou},
  doi          = {10.1137/20M1313908},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1467-1510},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Superresolution in recovering embedded electromagnetic sources in high contrast media},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A discriminative projection and representation-based
classification framework for face recognition. <em>SIIMS</em>,
<em>13</em>(3), 1446–1466. (<a
href="https://doi.org/10.1137/19M1253873">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sparse representation-based classifier (SRC) has been developed and verified as having great potential for real-world face recognition. In this paper, we propose a discriminative projection and representation-based classification (DPRC) method to enhance the discriminant ability of the SRC. The proposed method first obtains a discriminative projection matrix not only maximizing the ratio of the distance within interclass over the distance within intraclass, but also minimizing the linear approximation error within intraclass. Then it maps the original data onto the discriminative space, and adopts an SRC method to obtain the final solution. An inexact augmented Lagrangian method of multiplier is proposed for finding the optimal representation vector in our framework, and a proximal alternating minimization method is adopted to the iteration subproblems of the proposed method. The proposed method is proven to have the subsequence convergence property. Experimental results on Yale, ORL, and AR face image databases demonstrate that, compared with some existing feature extraction methods based on the SRC, the proposed DPRC method is more efficient.},
  archive      = {J_SIIMS},
  author       = {Kangkang Deng and Zheng Peng and Wenxing Zhu},
  doi          = {10.1137/19M1253873},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1446-1466},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A discriminative projection and representation-based classification framework for face recognition},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Relaxed gauss–newton methods with applications to electrical
impedance tomography. <em>SIIMS</em>, <em>13</em>(3), 1415–1445. (<a
href="https://doi.org/10.1137/20M1321711">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As second-order methods, Gauss--Newton-type methods can be more effective than first-order methods for the solution of nonsmooth optimization problems with expensive-to-evaluate smooth components. Such methods, however, often do not converge. Motivated by nonlinear inverse problems with nonsmooth regularization, we propose a new Gauss--Newton-type method with inexact relaxed steps. We prove that the method converges to a set of disjoint critical points given that the linearization of the forward operator for the inverse problem is sufficiently precise. We extensively evaluate the performance of the method on electrical impedance tomography (EIT).},
  archive      = {J_SIIMS},
  author       = {Jyrki Jauhiainen and Petri Kuusela and Aku Seppänen and Tuomo Valkonen},
  doi          = {10.1137/20M1321711},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1415-1445},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Relaxed gauss--newton methods with applications to electrical impedance tomography},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Overparameterized models for vector fields. <em>SIIMS</em>,
<em>13</em>(3), 1386–1414. (<a
href="https://doi.org/10.1137/19M1280697">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vector fields arise in a variety of quantity measure and visualization techniques, such as fluid flow imaging, motion estimation, deformation measures, and color imaging, leading to a better understanding of physical phenomena. Recent progress in vector field imaging technologies has emphasized the need for efficient noise removal and reconstruction algorithms. A key ingredient in the successful extraction of signals from noisy measurements is prior information, which can often be represented as a parameterized model. In this work, we extend the overparameterization variational framework in order to perform model-based reconstruction of vector fields. The overparameterization methodology combines local modeling of the data with global model parameter regularization. By considering the vector field as a linear combination of basis vector fields and appropriate scale and rotation coefficients, we can reduce the denoising problem to a simpler form of coefficient recovery. We introduce two versions of the overparameterization framework: a total variation-based method and a sparsity-based method, which relies on the cosparse analysis model. We demonstrate the efficiency of the proposed frameworks for two- and three-dimensional vector fields with linear and quadratic overparameterization models.},
  archive      = {J_SIIMS},
  author       = {Keren Rotker and Dafna Ben Bashat and Alex M. Bronstein},
  doi          = {10.1137/19M1280697},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1386-1414},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Overparameterized models for vector fields},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mathematical morphology on the triangular grid: The strict
approach. <em>SIIMS</em>, <em>13</em>(3), 1367–1385. (<a
href="https://doi.org/10.1137/19M128017X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mathematical morphology provides various tools for image analysis. The two basic operations, dilation and erosion, are based on translations with the help of a given structural element (another image of the grid). In contrast to the case of discrete subgroups of $\mathbb R^n$, the triangular grid is not closed under translations; therefore, we use a restriction for the structural elements. Namely, we allow only those trixels (triangle pixels) to be in the structural elements which represent vectors such that the grid is closed under translations by these vectors. We prove that both strict dilation and erosion have nice properties. Strict opening and closing have also been defined by combining strict dilation and erosion.},
  archive      = {J_SIIMS},
  author       = {Mohsen Abdalla and Benedek Nagy},
  doi          = {10.1137/19M128017X},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1367-1385},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Mathematical morphology on the triangular grid: The strict approach},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Generalized correlation-based imaging for satellites.
<em>SIIMS</em>, <em>13</em>(3), 1331–1366. (<a
href="https://doi.org/10.1137/20M1322789">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider imaging of fast moving small objects in space, such as low earth orbit satellites or satellite debris. The imaging system consists of ground based, asynchronous sources of radiation and several passive receivers above the dense atmosphere. We use the cross correlation of the received signals to reduce distortions from ambient medium fluctuations. Imaging with correlations also has the advantage of not requiring any knowledge about the probing pulse and depends weakly on the emitter positions. We account for the target&#39;s orbital velocity by introducing the necessary Doppler compensation. We show that over limited imaging regions, a constant Doppler factor can be used, resulting in an efficient data structure for the correlations of the recorded signals. We then investigate and analyze different imaging methods using the cross-correlation data structure. Specifically, we show that using a generalized two-point migration of the cross-correlation data, the top eigenvector of the migrated data matrix provides superior image resolution compared to the usual single-point migration scheme. We carry out a theoretical analysis that illustrates the role of the two-point migration methods as well as that of the inverse aperture in improving resolution. Extensive numerical simulations support the theoretical results and assess the scope of the imaging methodology.},
  archive      = {J_SIIMS},
  author       = {Matan Leibovich and George Papanicolaou and Chrysoula Tsogka},
  doi          = {10.1137/20M1322789},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1331-1366},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Generalized correlation-based imaging for satellites},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Differential tomography of micromechanical evolution in
elastic materials of unknown micro/macrostructure. <em>SIIMS</em>,
<em>13</em>(3), 1302–1330. (<a
href="https://doi.org/10.1137/19M1305707">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential evolution indicators are introduced for 3D spatiotemporal imaging of micromechanical processes in elastic solids where progressive variations due to manufacturing and/or aging are housed in a highly scattering background of a priori unknown or uncertain structure. In this vein, a three-tier imaging platform is established where (1) the domain is periodically (or continuously) subject to illumination and sensing in an arbitrary configuration; (2) sequential sets of measured data are deployed to distill far-field signatures of the domain&#39;s internal structure through carefully constructed, noniterative solutions to the scattering equation; and (3) the resulting solution sequence is then used to rigorously construct an imaging functional carrying appropriate invariance with respect to the unknown stationary components of the background, e.g., pre-existing interstitial boundaries. This gives birth to differential indicators that specifically recover the 3D support of evolution within a network of unknown scatterers. The direct scattering problem is formulated in the frequency domain where the background consists of a random distribution of monolithic fragments. The constituents are connected through highly heterogeneous interfaces of unknown elasticity and dissipation spanning from perfectly bonded to traction-free contacts which are subject to evolution in time and space. The support of interfacial boundaries is periodically illuminated by a set of incident waves and thus-induced scattered fields are captured over a generic observation surface. The performance of the proposed imaging indicator is illustrated through a set of numerical experiments for sequential reconstruction of evolving damage zones featuring randomly distributed cracks and bubbles.},
  archive      = {J_SIIMS},
  author       = {Fatemeh Pourahmadian and Houssem Haddar},
  doi          = {10.1137/19M1305707},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1302-1330},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Differential tomography of micromechanical evolution in elastic materials of unknown Micro/Macrostructure},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Data driven tight frame for compressed sensing MRI
reconstruction via off-the-grid regularization. <em>SIIMS</em>,
<em>13</em>(3), 1272–1301. (<a
href="https://doi.org/10.1137/19M1298524">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the finite-rate-of-innovation (FRI) based continuous domain regularization is emerging as an alternative to the conventional on-the-grid sparse regularization for compressed sensing (CS) due to its ability to alleviate the basis mismatch between the true support of the shape in the continuous domain and the discrete grid. In this paper, we propose a new off-the-grid regularization for the CS-MRI reconstruction. Following the recent works on two dimensional FRI, we assume that the discontinuities/edges of the image are localized in the zero level set of a band-limited periodic function. This assumption induces the linear dependencies among the Fourier samples of the gradient of the image, which leads to a low rank twofold Hankel matrix. We further observe that the singular value decomposition of a low rank Hankel matrix corresponds to an adaptive tight frame system which can represent the image with sparse canonical coefficients. Based on this observation, we propose a data driven tight frame based off-the-grid regularization model for the CS-MRI reconstruction. To solve the nonconvex and nonsmooth model, a proximal alternating minimization algorithm with a guaranteed global convergence is adopted. Finally, the numerical experiments show that our proposed data driven tight frame based approach outperforms the existing approaches.},
  archive      = {J_SIIMS},
  author       = {Jian-Feng Cai and Jae Kyu Choi and Ke Wei},
  doi          = {10.1137/19M1298524},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1272-1301},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Data driven tight frame for compressed sensing MRI reconstruction via off-the-grid regularization},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A diffeomorphic image registration model with
fractional-order regularization and cauchy–riemann constraint.
<em>SIIMS</em>, <em>13</em>(3), 1240–1271. (<a
href="https://doi.org/10.1137/19M1260621">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to echo with fractional-order smoothness of image texture and eliminate mesh folding in image registration, we propose a diffeomorphic image registration model with fractional-order regularization and Cauchy--Riemann constraint. For the convenience of numerical implementation, a relaxed model is discussed. The existence of solution for the relaxed model is proved. A convex optimization numerical algorithm is presented, and the convergence of minimizing sequence is proved. Moreover, numerical tests are performed to show the efficiency of the proposed algorithm.},
  archive      = {J_SIIMS},
  author       = {Huan Han and Zhengping Wang},
  doi          = {10.1137/19M1260621},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1240-1271},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A diffeomorphic image registration model with fractional-order regularization and cauchy--riemann constraint},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Accelerating sparse recovery by reducing chatter.
<em>SIIMS</em>, <em>13</em>(3), 1211–1239. (<a
href="https://doi.org/10.1137/19M129111X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compressive sensing has driven a resurgence of sparse recovery algorithms with $\ell_1$-norm minimization. While these minimizations are relatively well understood for small underdetermined, possibly inconsistent systems, their behavior for large overdetermined and inconsistent systems has received much less attention. Specifically, we focus on large systems where computational restrictions call for algorithms that use randomized subsets of rows that are touched a limited number of times. In that regime, $\ell_1$-norm minimization algorithms exhibit unwanted fluctuations near the desired solution, and the linear Bregman iterations are no exception. These fluctuations result in uncertainty about the recovery results, forcing increased effort such as longer run times or other additional search efforts. We explain this observed lack of performance in terms of chatter, a well-known phenomenon observed in nonsmooth dynamical systems, where intermediate solutions wander between different states, stifling convergence. By identifying chatter as the culprit, we then reduce it by modifying the Bregman iterations with adaptive elementwise step lengths combined with potential support detection via threshold crossing. We demonstrate the performance of our algorithm on carefully selected stylized examples that mimic real large scale problems and on a realistic seismic imaging problem involving millions of unknowns and matrix-free matrix-vector products that involve expensive wave-equation solves.},
  archive      = {J_SIIMS},
  author       = {Emmanouil Daskalakis and Felix J. Herrmann and Rachel Kuske},
  doi          = {10.1137/19M129111X},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1211-1239},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Accelerating sparse recovery by reducing chatter},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cartoon-texture image decomposition using orientation
characteristics in patch recurrence. <em>SIIMS</em>, <em>13</em>(3),
1179–1210. (<a href="https://doi.org/10.1137/19M128898X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cartoon-texture image decomposition is about decomposing an image into the linear sum of two layers: cartoon and texture, where the key challenge is how to resolve the ambiguity between two layers. It is observed that the recurrence of texture patches occurs along multiple orientations, and the recurrence of cartoon patches only occurs along certain orientations. This paper proposes to separate these two layers by exploiting their orientation characteristics of image patch recurrence, i.e., isotropy property of texture patch recurrence versus anisotropy property of cartoon patch recurrence. Together with the sparsity-based regularizations in the image domain, a variational method is then developed in this paper for cartoon-texture decomposition. The experiments show that the proposed method noticeably outperforms many well-established ones on test images.},
  archive      = {J_SIIMS},
  author       = {Ruotao Xu and Yong Xu and Yuhui Quan and Hui Ji},
  doi          = {10.1137/19M128898X},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1179-1210},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Cartoon-texture image decomposition using orientation characteristics in patch recurrence},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hypergraph clustering using a new laplacian tensor with
applications in image processing. <em>SIIMS</em>, <em>13</em>(3),
1157–1178. (<a href="https://doi.org/10.1137/19M1291601">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the multiclass clustering problem involving a hypergraph model. Fundamentally, we study a new normalized Laplacian tensor of an even-uniform weighted hypergraph. The hypergraph&#39;s connectivity is related with the second smallest Z-eigenvalue of the proposed Laplacian tensor. Particularly, an analogue of fractional Cheeger inequality holds. Next, we generalize the Laplacian tensor based approach from biclustering to multiclass clustering. A tensor optimization model with an orthogonal constraint is established and analyzed. Finally, we apply our hypergraph clustering approach to image segmentation and motion segmentation problems. Experimental results demonstrate that our method is effective.},
  archive      = {J_SIIMS},
  author       = {Jingya Chang and Yannan Chen and Liqun Qi and Hong Yan},
  doi          = {10.1137/19M1291601},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1157-1178},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Hypergraph clustering using a new laplacian tensor with applications in image processing},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Self-assignment flows for unsupervised data labeling on
graphs. <em>SIIMS</em>, <em>13</em>(3), 1113–1156. (<a
href="https://doi.org/10.1137/19M1298639">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper extends the recently introduced assignment flow approach for supervised image labeling to unsupervised scenarios where no labels are given. The resulting self-assignment flow takes a pairwise data affinity matrix as input data and maximizes the correlation with a low-rank matrix that is parametrized by the variables of the assignment flow, which entails an assignment of the data to themselves through the formation of latent labels (feature prototypes). A single user parameter, the neighborhood size for the geometric regularization of assignments, drives the entire process. By smooth geodesic interpolation between different normalizations of self-assignment matrices on the positive definite matrix manifold, a one-parameter family of self-assignment flows is defined. Accordingly, our approach can be characterized from different viewpoints, e.g., as performing spatially regularized, rank-constrained discrete optimal transport, or as computing spatially regularized normalized spectral cuts. Regarding combinatorial optimization, our approach successfully determines completely positive factorizations of self-assignments in large-scale scenarios, subject to spatial regularization. Various experiments, including the unsupervised learning of patch dictionaries using a locally invariant distance function, illustrate the properties of the approach.},
  archive      = {J_SIIMS},
  author       = {Matthias Zisler and Artjom Zern and Stefania Petra and Christoph Schnörr},
  doi          = {10.1137/19M1298639},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1113-1156},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Self-assignment flows for unsupervised data labeling on graphs},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Nonnegative tensor patch dictionary approaches for image
compression and deblurring applications. <em>SIIMS</em>, <em>13</em>(3),
1084–1112. (<a href="https://doi.org/10.1137/19M1297026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent work [S. Soltani, M. Kilmer, and P. C. Hansen, BIT, 56 (2016)], an algorithm for nonnegative tensor patch dictionary learning in the context of X-ray CT imaging and based on a tensor-tensor product called the t-product [M. E. Kilmer and C. D. Martin, Linear Algebra Appl., 435 (2011), pp. 641--658] was presented. Building on that work, in this paper, we use nonnegative tensor patch--based dictionaries trained on other data, such as facial image data, for the purpose of either compression or image deblurring. We begin with an analysis in which we address issues such as suitability of the tensor-based approach relative to a matrix-based approach, dictionary size, and patch size to balance computational efficiency and qualitative representations. Next, we develop an algorithm that is capable of recovering nonnegative tensor coefficients given a nonnegative tensor dictionary. The algorithm is based on a variant of the modified residual norm steepest descent method. We show how to augment the algorithm to enforce sparsity in the tensor coefficients and note that the approach has broader applicability since it can be applied to the matrix case as well. We illustrate the surprising result that dictionaries trained on image data from one class can be successfully used to represent and compress image data from different classes and across different resolutions. Finally, we address the use of nonnegative tensor dictionaries in image deblurring. We show that tensor treatment of the deblurring problem coupled with nonnegative tensor patch dictionaries can give superior restorations as compared to standard treatment of the nonnegativity constrained deblurring problem.},
  archive      = {J_SIIMS},
  author       = {Elizabeth Newman and Misha E. Kilmer},
  doi          = {10.1137/19M1297026},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1084-1112},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Nonnegative tensor patch dictionary approaches for image compression and deblurring applications},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Parallelizable global conformal parameterization of
simply-connected surfaces via partial welding. <em>SIIMS</em>,
<em>13</em>(3), 1049–1083. (<a
href="https://doi.org/10.1137/19M125337X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conformal surface parameterization is useful in graphics, imaging, and visualization, with applications to texture mapping, atlas construction, registration, remeshing, and so on. With the increasing capability in scanning and storing data, dense 3D surface meshes are common nowadays. While meshes with higher resolution better resemble smooth surfaces, they pose computational difficulties for the existing parameterization algorithms. In this work, we propose a novel parallelizable algorithm for computing the global conformal parameterization of simply-connected surfaces via partial welding maps. A given simply-connected surface is first partitioned into smaller subdomains. The local conformal parameterizations of all subdomains are then computed in parallel. The boundaries of the parameterized subdomains are subsequently integrated consistently using a novel technique called partial welding, which is developed based on conformal welding theory. Finally, by solving the Laplace equation for each subdomain using the updated boundary conditions, we obtain a global conformal parameterization of the given surface, with bijectivity guaranteed by quasi-conformal theory. By including additional shape constraints, our method can be easily extended to achieve disk conformal parameterization for simply-connected open surfaces and spherical conformal parameterization for genus-0 closed surfaces. Experimental results are presented to demonstrate the effectiveness of our proposed algorithm. When compared to the state-of-the-art conformal parameterization methods, our method achieves a significant improvement in both computational time and accuracy.},
  archive      = {J_SIIMS},
  author       = {Gary P. T. Choi and Yusan Leung-Liu and Xianfeng Gu and Lok Ming Lui},
  doi          = {10.1137/19M125337X},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1049-1083},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Parallelizable global conformal parameterization of simply-connected surfaces via partial welding},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Spectral embedding norm: Looking deep into the spectrum of
the graph laplacian. <em>SIIMS</em>, <em>13</em>(2), 1015–1048. (<a
href="https://doi.org/10.1137/18M1283160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The extraction of clusters from a dataset which includes multiple clusters and a significant background component is a nontrivial task of practical importance. In image analysis this manifests for example in anomaly detection and target detection. The traditional spectral clustering algorithm, which relies on the leading $K$ eigenvectors to detect $K$ clusters, fails in such cases. In this paper we propose the spectral embedding norm which sums the squared values of the first $I$ normalized eigenvectors, where $I$ can be significantly larger than $K$. We prove that this quantity can be used to separate clusters from the background in unbalanced settings, including extreme cases such as outlier detection. The performance of the algorithm is not sensitive to the choice of $I$, and we demonstrate its application on synthetic and real-world remote sensing and neuroimaging datasets.},
  archive      = {J_SIIMS},
  author       = {Xiuyuan Cheng and Gal Mishne},
  doi          = {10.1137/18M1283160},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {1015-1048},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Spectral embedding norm: Looking deep into the spectrum of the graph laplacian},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On decomposition models in imaging sciences and multi-time
hamilton–jacobi partial differential equations. <em>SIIMS</em>,
<em>13</em>(2), 971–1014. (<a
href="https://doi.org/10.1137/19M1266332">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper provides new theoretical connections between multi-time Hamilton--Jacobi partial differential equations and variational image decomposition models in imaging sciences. We show that the minimal values of these optimization problems are governed by multi-time Hamilton--Jacobi partial differential equations. The minimizers of these optimization problems can be represented using the momentum in the corresponding Hamilton--Jacobi partial differential equation. Moreover, variational behaviors of both the minimizers and the momentum are investigated as the regularization parameters approach zero. In addition, we provide a new perspective from convex analysis to prove the uniqueness of convex solutions to Hamilton--Jacobi equations. Finally, we consider image decomposition models that do not have unique minimizers, and we propose a regularization approach to perform the analysis using multi-time Hamilton--Jacobi partial differential equations.},
  archive      = {J_SIIMS},
  author       = {Jérôme Darbon and Tingwei Meng},
  doi          = {10.1137/19M1266332},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {971-1014},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {On decomposition models in imaging sciences and multi-time hamilton--jacobi partial differential equations},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A wasserstein-type distance in the space of gaussian mixture
models. <em>SIIMS</em>, <em>13</em>(2), 936–970. (<a
href="https://doi.org/10.1137/19M1301047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we introduce a Wasserstein-type distance on the set of Gaussian mixture models. This distance is defined by restricting the set of possible coupling measures in the optimal transport problem to Gaussian mixture models. We derive a very simple discrete formulation for this distance, which makes it suitable for high dimensional problems. We also study the corresponding multi-marginal and barycenter formulations. We show some properties of this Wasserstein-type distance, and we illustrate its practical use with some examples in image processing.},
  archive      = {J_SIIMS},
  author       = {Julie Delon and Agnès Desolneux},
  doi          = {10.1137/19M1301047},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {936-970},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A wasserstein-type distance in the space of gaussian mixture models},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Accelerating proximal markov chain monte carlo by using an
explicit stabilized method. <em>SIIMS</em>, <em>13</em>(2), 905–935. (<a
href="https://doi.org/10.1137/19M1283719">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a highly efficient proximal Markov chain Monte Carlo methodology to perform Bayesian computation in imaging problems. Similarly to previous proximal Monte Carlo approaches, the proposed method is derived from an approximation of the Langevin diffusion. However, instead of the conventional Euler--Maruyama approximation that underpins existing proximal Monte Carlo methods, here we use a state-of-the-art orthogonal Runge--Kutta--Chebyshev stochastic approximation [A. Abdulle, I. Aimuslimani, and G. Vilmart, SIAM/ASA J. Uncertain. Quantif., 6 (2018), pp. 937--964] that combines several gradient evaluations to significantly accelerate its convergence speed, similarly to accelerated gradient optimization methods. The proposed methodology is demonstrated via a range of numerical experiments, including non-blind image deconvolution, hyperspectral unmixing, and tomographic reconstruction, with total-variation and $\ell_1$-type priors. Comparisons with Euler-type proximal Monte Carlo methods confirm that the Markov chains generated with our method exhibit significantly faster convergence speeds, achieve larger effective sample sizes, and produce lower mean-square estimation errors at equal computational budget.},
  archive      = {J_SIIMS},
  author       = {Marcelo Pereyra and Luis Vargas Mieles and Konstantinos C. Zygalakis},
  doi          = {10.1137/19M1283719},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {905-935},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Accelerating proximal markov chain monte carlo by using an explicit stabilized method},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Convexification for a three-dimensional inverse scattering
problem with the moving point source. <em>SIIMS</em>, <em>13</em>(2),
871–904. (<a href="https://doi.org/10.1137/19M1303101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the first time, we develop in this paper the globally convergent convexification numerical method for a coefficient inverse problem for the three-dimensional Helmholtz equation for the case when the backscattering data are generated by a point source running along an interval of a straight line and the wavenumber is fixed. Thus, by varying the wavenumber, one can reconstruct the dielectric constant depending not only on spatial variables but on the wavenumber (i.e., frequency) as well. Our approach relies on a new derivation of a boundary value problem for a system of coupled quasi-linear elliptic partial differential equations. This is done via an application of a special truncated Fourier-like method. First, we prove the Lipschitz stability estimate for this problem via a Carleman estimate. Next, using the Carleman weight function generated by that estimate, we construct a globally strictly convex cost functional and prove the global convergence to the exact solution of the gradient projection method. Finally, our theoretical finding is verified via several numerical tests with computationally simulated data. These tests demonstrate that we can accurately recover all three important components of targets of interest: locations, shapes, and dielectric constants. In particular, large target/background contrasts in dielectric constants (up to 10:1) can be accurately calculated.},
  archive      = {J_SIIMS},
  author       = {Vo Anh Khoa and Michael Victor Klibanov and Loc Hoang Nguyen},
  doi          = {10.1137/19M1303101},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {871-904},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Convexification for a three-dimensional inverse scattering problem with the moving point source},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A gray level indicator-based regularized telegraph diffusion
model: Application to image despeckling. <em>SIIMS</em>, <em>13</em>(2),
844–870. (<a href="https://doi.org/10.1137/19M1283033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, a gray level indicator-based nonlinear telegraph diffusion model is presented for image despeckling. Most of the researchers focus only on diffusion equation-based filter for multiplicative noise removal process. The proposed technique uses the benefit of the combined effect of diffusion equation as well as the wave equation. The wave nature of the system preserves the high oscillatory and texture patterns in an image. In this model, the diffusion coefficient depends not only on the image gradient but also on the gray level of the image, which controls the diffusion process better than only gradient-based diffusion approaches. Moreover, we prove the well-posedness of the present system using the Schauder fixed point theorem. Furthermore, we show the superiority of the proposed method over three recently developed methods on a set of gray level test images corrupted by speckle noise and check the noise removal capability of the present technique over some real SAR images corrupted by speckle noise with different noise levels.},
  archive      = {J_SIIMS},
  author       = {Sudeb Majee and Rajendra K. Ray and Ananta K. Majee},
  doi          = {10.1137/19M1283033},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {844-870},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A gray level indicator-based regularized telegraph diffusion model: Application to image despeckling},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Low-frequency electromagnetic imaging using sensitivity
functions and beamforming. <em>SIIMS</em>, <em>13</em>(2), 807–843. (<a
href="https://doi.org/10.1137/19M1279502">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a computational technique for low-frequency electromagnetic imaging in inhomogeneous media that provides superior three-dimensional resolution over existing techniques. The method is enabled through large-scale, fast (low-complexity) algorithms that we introduce for simulating electromagnetic wave propagation. We numerically study the performance of the technique on various problems including the imaging of a strong finite scatterer located within a thick conductive box.},
  archive      = {J_SIIMS},
  author       = {Pierre-David Letourneau and Mitchell Tong Harris and Matthew Harper Langston and George Papanicolaou},
  doi          = {10.1137/19M1279502},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {807-843},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Low-frequency electromagnetic imaging using sensitivity functions and beamforming},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Reconstruction of the high resolution phase in a closed loop
adaptive optics system. <em>SIIMS</em>, <em>13</em>(2), 775–806. (<a
href="https://doi.org/10.1137/19M1258426">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptive optics is a commonly used technique to correct the phase distortions caused by the Earth&#39;s atmosphere to improve the image quality of the ground-based imaging systems. However, the observed images still suffer from the blur caused by the adaptive optics residual wavefront. In this paper, we propose a model for reconstructing the residual phase in high resolution from a sequence of deformable mirror data. Our model is based on the turbulence statistics and the Taylor frozen flow hypothesis with knowledge of the wind velocities in atmospheric turbulence layers. A tomography problem for the phase distortions from different altitudes is solved in order to get a high quality phase reconstruction. We also consider inexact tomography operators resulting from the uncertainty in the wind velocities. The wind velocities are estimated from the deformable mirror data and, additionally, by including them as unknowns in the objective function. We provide a theoretical analysis on the existence of a minimizer of the objective function. To solve the associated joint optimization problem, we use an alternating minimization method which results in a high resolution reconstruction algorithm with adaptive wind velocities. Numerical simulations are carried out to show the effectiveness of our approach.},
  archive      = {J_SIIMS},
  author       = {Rihuan Ke and Roland Wagner and Ronny Ramlau and Raymond Chan},
  doi          = {10.1137/19M1258426},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {775-806},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Reconstruction of the high resolution phase in a closed loop adaptive optics system},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Microlocal analysis of a compton tomography problem.
<em>SIIMS</em>, <em>13</em>(2), 746–774. (<a
href="https://doi.org/10.1137/19M1251035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Here we present a novel microlocal analysis of a new toric section transform which describes a two-dimensional image reconstruction problem in Compton scattering tomography and airport baggage screening. By an analysis of two separate limited data problems for the circle transform and using microlocal analysis, we show that the canonical relation of the toric section transform is 21. This implies that there are image artifacts in the filtered backprojection reconstruction. We provide explicit expressions for the expected artifacts and demonstrate these by simulations. In addition, we prove injectivity of the forward operator for $L^\infty$ functions supported inside the open unit ball. We present reconstructions from simulated data using a discrete approach and several regularizers with varying levels of added pseudorandom noise.},
  archive      = {J_SIIMS},
  author       = {James W. Webber and Eric Todd Quinto},
  doi          = {10.1137/19M1251035},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {746-774},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Microlocal analysis of a compton tomography problem},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Semisupervised dictionary learning with graph regularized
and active points. <em>SIIMS</em>, <em>13</em>(2), 724–745. (<a
href="https://doi.org/10.1137/19M1285469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supervised dictionary learning has gained much interest in the recent decade and has shown significant performance improvements in image classification. However, in general, supervised learning needs a large number of labelled samples per class to achieve an acceptable result. In order to deal with databases which have just a few labelled samples per class, semisupervised learning, which also exploits unlabelled samples in training phase is used. Indeed, unlabelled samples can help to regularize the learning model, yielding an improvement of classification accuracy. In this paper, we propose a new semisupervised dictionary learning method based on two pillars: on one hand, we enforce manifold structure preservation from the original data into sparse code space using locally linear embedding, which can be considered a regularization of sparse code; on the other hand, we train a semisupervised classifier in sparse code space. We show that our approach provides an improvement over state-of-the-art semisupervised dictionary learning methods.},
  archive      = {J_SIIMS},
  author       = {K. H. Tran and F. M. Ngolè Mboula and J. L. Starck and V. Prost},
  doi          = {10.1137/19M1285469},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {724-745},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Semisupervised dictionary learning with graph regularized and active points},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Reduced order model approach to inverse scattering.
<em>SIIMS</em>, <em>13</em>(2), 685–723. (<a
href="https://doi.org/10.1137/19M1296355">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study an inverse scattering problem for a generic hyperbolic system of equations with an unknown coefficient called the reflectivity. The solution of the system models waves (sound, electromagnetic, or elastic), and the reflectivity models unknown scatterers embedded in a smooth and known medium. The inverse problem is to determine the reflectivity from the time resolved scattering matrix (the data) measured by an array of sensors. We introduce a novel inversion method, based on a reduced order model (ROM) of an operator called a wave propagator, because it maps the wave from one time instant to the next, at an interval corresponding to the discrete time sampling of the data. The wave propagator is unknown in the inverse problem, but the ROM can be computed directly from the data. By construction, the ROM inherits key properties of the wave propagator, which facilitate the estimation of the reflectivity. The ROM was introduced previously and was used for two purposes: (1) to map the scattering matrix to that corresponding to the single scattering (Born) approximation and (2) to image, i.e., obtain a qualitative estimate of the support of the reflectivity. Here we study further the ROM and show that it corresponds to a Galerkin projection of the wave propagator. The Galerkin framework is useful for proving properties of the ROM that are used in the new inversion method which seeks a quantitative estimate of the reflectivity.},
  archive      = {J_SIIMS},
  author       = {Liliana Borcea and Vladimir Druskin and Alexander V. Mamonov and Mikhail Zaslavsky and Jörn Zimmerling},
  doi          = {10.1137/19M1296355},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {685-723},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Reduced order model approach to inverse scattering},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A variational image segmentation model based on normalized
cut with adaptive similarity and spatial regularization. <em>SIIMS</em>,
<em>13</em>(2), 651–684. (<a
href="https://doi.org/10.1137/18M1192366">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image segmentation is a fundamental research topic in image processing and computer vision. In recent decades, researchers developed a large number of segmentation algorithms for various applications. Among these algorithms, the normalized cut (Ncut) segmentation method is widely applied due to its good performance. The Ncut segmentation model is an optimization problem whose energy is defined on a specifically designed graph. Thus, the segmentation results of the existing Ncut method are largely dependent on a preconstructed similarity measure on the graph since this measure is usually given empirically by users. This flaw will lead to some undesirable segmentation results. In this paper, we propose an Ncut-based segmentation algorithm by integrating an adaptive similarity measure and spatial regularization. The proposed model combines the Parzen--Rosenblatt window method, nonlocal weights entropy, Ncut energy, and regularizer of phase field in a variational framework. Our method can adaptively update the similarity measure function by estimating some parameters. This adaptive procedure enables the proposed algorithm to find a better similarity measure for classification than the Ncut method. We provide some mathematical interpretation of the proposed adaptive similarity from multiple viewpoints, such as statistics and convex optimization. In addition, the regularizer of phase field can guarantee that the proposed algorithm has a robust performance in the presence of noise, and it can also rectify the similarity measure with a spatial priori. The well-posed theory such as the existence of the minimizer for the proposed model is given in the paper. Compared with some existing segmentation methods such as the traditional Ncut-based model and the classical Chan--Vese model, the numerical experiments show that our method can provide promising segmentation results.},
  archive      = {J_SIIMS},
  author       = {Faqiang Wang and Cuicui Zhao and Jun Liu and Haiyang Huang},
  doi          = {10.1137/18M1192366},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {651-684},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A variational image segmentation model based on normalized cut with adaptive similarity and spatial regularization},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fixed point analysis of douglas–rachford splitting for
ptychography and phase retrieval. <em>SIIMS</em>, <em>13</em>(2),
609–650. (<a href="https://doi.org/10.1137/19M128781X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Douglas--Rachford splitting (DRS) methods based on the proximal point algorithms for the Poisson and Gaussian log-likelihood functions are proposed for ptychography and phase retrieval. Fixed point analysis shows that the DRS iterated sequences are always bounded explicitly in terms of the step size and that the fixed points are attracting if and only if the fixed points are regular solutions. This alleviates two major drawbacks of the classical Douglas--Rachford algorithm: slow convergence when the feasibility problem is consistent and divergent behavior when the feasibility problem is inconsistent. Fixed point analysis also leads to a simple, explicit expression for the optimal step size in terms of the spectral gap of an underlying matrix. When applied to the challenging problem of blind ptychography, which seeks to recover both the object and the probe simultaneously, alternating minimization with the DRS inner loops, even with a far from optimal step size, converges geometrically under the nearly minimum conditions established in the uniqueness theory.},
  archive      = {J_SIIMS},
  author       = {Albert Fannjiang and Zheqing Zhang},
  doi          = {10.1137/19M128781X},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {609-650},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Fixed point analysis of douglas--rachford splitting for ptychography and phase retrieval},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Explicit inversion formulas for the two-dimensional wave
equation from neumann traces. <em>SIIMS</em>, <em>13</em>(2), 589–608.
(<a href="https://doi.org/10.1137/19M1260517">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article we study the problem of recovering the initial data of the two-dimensional wave equation from Neumann measurements on a convex domain $\Omega\subset\mathbb{R}^2$ with smooth boundary. We derive an explicit inversion formula of a so-called back-projection type and deduce exact inversion formulas for circular and elliptical domains. In addition, for circular domains, we show that the initial data can also be recovered from any linear combination of its solution and its normal derivative on the boundary. Numerical results of our implementation of the derived inversion formulas are presented demonstrating their accuracy and stability.},
  archive      = {J_SIIMS},
  author       = {Florian Dreier and Markus Haltmeier},
  doi          = {10.1137/19M1260517},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {589-608},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Explicit inversion formulas for the two-dimensional wave equation from neumann traces},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Convergence of the time discrete metamorphosis model on
hadamard manifolds. <em>SIIMS</em>, <em>13</em>(2), 557–588. (<a
href="https://doi.org/10.1137/19M1247073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continuous image morphing is a classical task in image processing. The metamorphosis model proposed by Trouvé, Younes, and coworkers [M. I. Miller and L. Younes, Int. J. Comput. Vis., 41 (2001), pp. 61--84; A. Trouvé and L. Younes, Found. Comput. Math., 5 (2005), pp. 173--198] casts this problem in the frame of Riemannian geometry and geodesic paths between images. The associated metric in the space of images incorporates dissipation caused by a viscous flow transporting image intensities and its variations along motion paths. In many applications, images are maps from the image domain into a manifold (e.g., in diffusion tensor imaging (DTI), the manifold of symmetric positive definite matrices with a suitable Riemannian metric). In this paper, we propose a generalized metamorphosis model for manifold-valued images, where the range space is a finite-dimensional Hadamard manifold. A corresponding time discrete version was presented in [S. Neumayer, J. Persch, and G. Steidl, SIAM J. Imaging Sci., 11 (2018), pp. 1898--1930] based on the general variational time discretization proposed in [B. Berkels, A. Effland, and M. Rumpf, SIAM J. Imaging Sci., 8 (2015), pp. 1457--1488]. Here, we prove the Mosco--convergence of the time discrete metamorphosis functional to the proposed manifold-valued metamorphosis model, which implies the convergence of time discrete geodesic paths to a geodesic path in the (time continuous) metamorphosis model. In particular, the existence of geodesic paths is established. In particular, the existence of geodesic paths is established. In fact, images as maps into Hadamard manifold are not only relevant in applications, but it is also shown that the joint convexity of the distance function---which characterizes Hadamard manifolds---is a crucial ingredient to establish existence of the metamorphosis model.},
  archive      = {J_SIIMS},
  author       = {Alexander Effland and Sebastian Neumayer and Martin Rumpf},
  doi          = {10.1137/19M1247073},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {557-588},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Convergence of the time discrete metamorphosis model on hadamard manifolds},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Numerical reconstruction of radiative sources in an
absorbing and nondiffusing scattering medium in two dimensions.
<em>SIIMS</em>, <em>13</em>(1), 535–555. (<a
href="https://doi.org/10.1137/19M1282921">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the two dimensional quantitative imaging problem of recovering a radiative source inside an absorbing and scattering medium from knowledge of the outgoing radiation measured at the boundary. The medium has an anisotropic scattering property that is neither negligible nor large enough for the diffusion approximation to hold. We present the numerical realization of the authors&#39; recently proposed reconstruction method. For scattering kernels of finite Fourier content in the angular variable, the solution is exact. The feasibility of the proposed algorithms is demonstrated in several numerical experiments, including simulated scenarios for parameters meaningful in optical molecular imaging.},
  archive      = {J_SIIMS},
  author       = {Hiroshi Fujiwara and Kamran Sadiq and Alexandru Tamasan},
  doi          = {10.1137/19M1282921},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {535-555},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Numerical reconstruction of radiative sources in an absorbing and nondiffusing scattering medium in two dimensions},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A high-order scheme for image segmentation via a modified
level-set method. <em>SIIMS</em>, <em>13</em>(1), 497–534. (<a
href="https://doi.org/10.1137/18M1231432">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a high-order accurate scheme for image segmentation based on the level-set method. In this approach, the curve evolution is described as the 0-level set of a representation function, but we modify the velocity that drives the curve to the boundary of the object in order to obtain a new velocity with additional properties that are extremely useful to develop a more stable high-order approximation with a small additional cost. The approximation scheme proposed here is the first 2D version of an adaptive “filtered&quot; scheme recently introduced and analyzed by the authors in one dimension. This approach is interesting since the implementation of the filtered scheme is rather efficient and easy. The scheme combines two building blocks (a monotone scheme and a high-order scheme) via a filter function and smoothness indicators that allow one to detect the regularity of the approximate solution adapting the scheme in an automatic way. Some numerical tests on synthetic and real images confirm the accuracy of the proposed method and the advantages given by the new velocity.},
  archive      = {J_SIIMS},
  author       = {Maurizio Falcone and Giulio Paolucci and Silvia Tozza},
  doi          = {10.1137/18M1231432},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {497-534},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A high-order scheme for image segmentation via a modified level-set method},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Higher-order total directional variation: analysis.
<em>SIIMS</em>, <em>13</em>(1), 474–496. (<a
href="https://doi.org/10.1137/19M1239210">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze a new notion of total anisotropic higher-order variation which, differently from total generalized variation in [K. Bredies, K. Kunisch, and T. Pock, SIAM J. Imaging Sci., 3 (2010), pp. 492--526], quantifies for possibly nonsymmetric tensor fields their variations at arbitrary order weighted by possibly inhomogeneous, smooth elliptic anisotropies. We prove some properties of this total variation and of the associated spaces of tensors with finite variations. We show the existence of solutions to a related regularity-fidelity optimization problem. We also prove a decomposition formula which appears to be helpful for the design of numerical schemes, as shown in a companion paper, where several applications to image processing are studied.},
  archive      = {J_SIIMS},
  author       = {Simone Parisotto and Simon Masnou and Carola-Bibiane Schönlieb},
  doi          = {10.1137/19M1239210},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {474-496},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Higher-order total directional variation: Analysis},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Simplifying transforms for general elastic metrics on the
space of plane curves. <em>SIIMS</em>, <em>13</em>(1), 445–473. (<a
href="https://doi.org/10.1137/19M1265132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the shape analysis approach to computer vision problems, one treats shapes as points in an infinite-dimensional Riemannian manifold, thereby facilitating algorithms for statistical calculations such as geodesic distance between shapes and averaging of a collection of shapes. The performance of these algorithms depends heavily on the choice of the Riemannian metric. In the setting of plane curve shapes, attention has largely been focused on a two-parameter family of first order Sobolev metrics, referred to as elastic metrics. They are particularly useful due to the existence of simplifying coordinate transformations for particular parameter values, such as the well-known square-root velocity transform. In this paper, we extend the transformations appearing in the existing literature to a family of isometries, which take any elastic metric to the flat $L^2$ metric. We also extend the transforms to treat piecewise linear curves and demonstrate the existence of optimal matchings over the diffeomorphism group in this setting. We conclude the paper with multiple examples of shape geodesics for open and closed curves. We also show the benefits of our approach in a simple classification experiment.},
  archive      = {J_SIIMS},
  author       = {Tom Needham and Sebastian Kurtek},
  doi          = {10.1137/19M1265132},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {445-473},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Simplifying transforms for general elastic metrics on the space of plane curves},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Extended-sampling-bayesian method for limited aperture
inverse scattering problems. <em>SIIMS</em>, <em>13</em>(1), 422–444.
(<a href="https://doi.org/10.1137/19M1270501">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Limited aperture inverse scattering problems arise in many important applications. In this paper, we propose a new method combining the extended sampling method (ESM) and the Bayesian approach for the inverse acoustic scattering problem to reconstruct the shape of a sound-soft obstacle using the limited aperture data. The problem is formulated as a statistical model using the Bayes formula. The well-posedness is proved in the sense of the Hellinger metric. A modified ESM is proposed to obtain the obstacle location, which is critical to the convergence of the MCMC algorithm. An extensive numerical study is presented to illustrate the performance of the method.},
  archive      = {J_SIIMS},
  author       = {Zhaoxing Li and Zhiliang Deng and Jiguang Sun},
  doi          = {10.1137/19M1270501},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {422-444},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Extended-sampling-bayesian method for limited aperture inverse scattering problems},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Novel proximal gradient methods for nonnegative matrix
factorization with sparsity constraints. <em>SIIMS</em>, <em>13</em>(1),
381–421. (<a href="https://doi.org/10.1137/19M1271750">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the nonnegative matrix factorization (NMF) problem with sparsity constraints formulated as a nonconvex composite minimization problem. We introduce four novel proximal gradient based algorithms proven globally convergent to a critical point and which are applicable to sparsity constrained NMF models. Our approach builds on recent results allowing one to lift the classical global Lipschitz continuity requirement through the use of a non-Euclidean Bregman based distance. Since under the proposed framework we are not restricted by the gradient Lipschitz continuity assumption, we can consider new decomposition settings of the NMF problem. Two of the derived schemes are genuine non-Euclidean proximal methods that tackle nonstandard decompositions of the NMF problem. The two other schemes are novel extensions of the well-known state-of-the-art methods (the multiplicative and hierarchical alternating least squares), thus allowing one to significantly broaden the scope of these algorithms. Numerical experiments illustrate the performance of the proposed methods.},
  archive      = {J_SIIMS},
  author       = {Marc Teboulle and Yakov Vaisbourd},
  doi          = {10.1137/19M1271750},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {381-421},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Novel proximal gradient methods for nonnegative matrix factorization with sparsity constraints},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A variational model dedicated to joint segmentation,
registration, and atlas generation for shape analysis. <em>SIIMS</em>,
<em>13</em>(1), 351–380. (<a
href="https://doi.org/10.1137/19M1271907">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In medical image analysis, constructing an atlas, i.e., a mean representative of an ensemble of images, is a critical task for practitioners to estimate variability of shapes inside a population, and to characterize and understand how structural shape changes have an impact on health. This involves identifying significant shape constituents of a set of images, a process called segmentation, and mapping this group of images to an unknown mean image, a task called registration, making a statistical analysis of the image population possible. To achieve this goal, we propose treating these operations jointly to leverage their positive mutual influence, in a hyperelasticity setting, by viewing the shapes to be matched as Ogden materials. The approach is complemented by novel hard constraints on the $L^\infty$ norm of both the Jacobian and its inverse, ensuring that the deformation is a bi-Lipschitz homeomorphism. Segmentation is based on the Potts model, which allows for a partition into more than two regions, i.e., more than one shape. The connection to the registration problem is ensured by the dissimilarity measure that aims to align the segmented shapes. A representation of the deformation field in a linear space equipped with a scalar product is then computed in order to perform a geometry-driven Principal Component Analysis (PCA) and to extract the main modes of variations inside the image population. Theoretical results emphasizing the mathematical soundness of the model are provided, among which are existence of minimizers, analysis of a numerical method, asymptotic results, and a PCA analysis, as well as numerical simulations demonstrating the ability of the model to produce an atlas exhibiting sharp edges, high contrast, and a consistent shape.},
  archive      = {J_SIIMS},
  author       = {Noémie Debroux and John Aston and Fabien Bonardi and Alistair Forbes and Carole Le Guyader and Marina Romanchikova and Carola-Bibiane Schönlieb},
  doi          = {10.1137/19M1271907},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {351-380},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A variational model dedicated to joint segmentation, registration, and atlas generation for shape analysis},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Trading beams for bandwidth: Imaging with randomized
beamforming. <em>SIIMS</em>, <em>13</em>(1), 317–350. (<a
href="https://doi.org/10.1137/19M1242045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of actively imaging a range-limited far-field scene using an antenna array. We describe how the range limit imposes structure in the measurements across multiple wavelengths. This structure allows us to introduce a novel trade-off: the number of spatial array measurements (i.e., beams that have to be formed) can be reduced to be significantly lower than the number array elements if the scene is illuminated with a broadband source. To take advantage of this trade-off, we use a small number of “generic” linear combinations of the array outputs, instead of the phase offsets used in conventional beamforming. We provide theoretical justification for the proposed trade-off without making any strong structural assumptions on the target scene (such as sparsity) except that it is range-limited. In proving our theoretical results, we take inspiration from the sketching literature. We also provide simulation results to establish the merit of the proposed signal acquisition strategy. Our proposed method results in a reduction in the number of required spatial measurements in an array imaging system and hence can directly impact their speed and cost of operation.},
  archive      = {J_SIIMS},
  author       = {Rakshith Sharma Srinivasa and Mark A. Davenport and Justin Romberg},
  doi          = {10.1137/19M1242045},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {317-350},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Trading beams for bandwidth: Imaging with randomized beamforming},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). High-resolution interferometric synthetic aperture imaging
in scattering media. <em>SIIMS</em>, <em>13</em>(1), 291–316. (<a
href="https://doi.org/10.1137/19M1272470">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of synthetic aperture imaging is to estimate the reflectivity of a remote region of interest by processing data gathered with a moving sensor which emits periodically a signal and records the backscattered wave. We introduce and analyze a high-resolution interferometric method for synthetic aperture imaging through an unknown scattering medium which distorts the wave. The method builds on the coherent interferometric approach which uses empirical cross-correlations of the measurements to mitigate the distortion, at the expense of a loss of resolution of the image. The new method shows that, while mitigating the wave distortion, it is possible to obtain a robust and sharp estimate of the modulus of the Fourier transform of the reflectivity function. A high-resolution image can then be obtained by a phase retrieval algorithm.},
  archive      = {J_SIIMS},
  author       = {Liliana Borcea and Josselin Garnier},
  doi          = {10.1137/19M1272470},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {291-316},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {High-resolution interferometric synthetic aperture imaging in scattering media},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multimodal 3D shape reconstruction under calibration
uncertainty using parametric level set methods. <em>SIIMS</em>,
<em>13</em>(1), 265–290. (<a
href="https://doi.org/10.1137/19M1257895">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of 3D shape reconstruction from multimodal data, given uncertain calibration parameters. Typically, 3D data modalities can come in diverse forms such as sparse point sets, volumetric slices, and 2D photos. To jointly process these data modalities, we exploit a parametric level set method that utilizes ellipsoidal radial basis functions. This method not only allows us to analytically and compactly represent the object; it also confers on us the ability to overcome calibration-related noise that originates from inaccurate acquisition parameters. This essentially implicit regularization leads to a highly robust and scalable reconstruction, surpassing other traditional methods. In our results we first demonstrate the ability of the method to compactly represent complex objects. We then show that our reconstruction method is robust both to a small number of measurements and to noise in the acquisition parameters. Finally, we demonstrate our reconstruction abilities from diverse modalities such as volume slices obtained from liquid displacement (similar to CT scans and X-rays) and visual measurements obtained from shape silhouettes as well as point clouds.},
  archive      = {J_SIIMS},
  author       = {Moshe Eliasof and Andrei Sharf and Eran Treister},
  doi          = {10.1137/19M1257895},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {265-290},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Multimodal 3D shape reconstruction under calibration uncertainty using parametric level set methods},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fisher information matrix for single molecules with
stochastic trajectories. <em>SIIMS</em>, <em>13</em>(1), 234–264. (<a
href="https://doi.org/10.1137/19M1242562">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tracking of objects in cellular environments has become a vital tool in molecular cell biology. A particularly important example is single molecule tracking, which enables the study of the motion of a molecule in cellular environments by locating the molecule over time and provides quantitative information on the behavior of individual molecules in cellular environments, which were not available before through bulk studies. Here, we consider a dynamical system where the motion of an object is modeled by stochastic differential equations (SDEs), and measurements are the detected photons, emitted by the moving fluorescently labeled object, that occur at discrete time points, corresponding to the arrival times of a Poisson process, in contrast to equidistant time points, which have been commonly used in the modeling of dynamical systems. The measurements are distributed according to the optical diffraction theory, and therefore, they would be modeled by different distributions, e.g., an Airy profile for an in-focus and a Born and Wolf profile for an out-of-focus molecule with respect to the detector. For some special circumstances, Gaussian image models have been proposed. In this paper, we introduce a stochastic framework in which we calculate the maximum likelihood estimates of the biophysical parameters of the molecular interactions, e.g., diffusion and drift coefficients. More importantly, we develop a general framework to calculate the Cramér--Rao lower bound (CRLB), given by the inverse of the Fisher information matrix, for the estimation of unknown parameters and use it as a benchmark in the evaluation of the standard deviation of the estimates. There exists no established method, even for Gaussian measurements, to systematically calculate the CRLB for the general motion model that we consider in this paper. We apply the developed methodology to simulated data of a molecule with linear trajectories and show that the standard deviation of the estimates matches well with the square root of the CRLB. We also show that equally sampled and Poisson distributed time points lead to significantly different Fisher information matrices.},
  archive      = {J_SIIMS},
  author       = {Milad R. Vahid and Bernard Hanzon and Raimund J. Ober},
  doi          = {10.1137/19M1242562},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {234-264},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Fisher information matrix for single molecules with stochastic trajectories},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multigrid optimization for large-scale ptychographic phase
retrieval. <em>SIIMS</em>, <em>13</em>(1), 214–233. (<a
href="https://doi.org/10.1137/18M1223915">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ptychography is a popular imaging technique that combines diffractive imaging with scanning microscopy. The technique consists of a coherent beam that is scanned across an object in a series of overlapping positions, leading to reliable and improved reconstructions. Ptychographic microscopes allow for large fields to be imaged at high resolution at the cost of additional computational expense. In this work, we propose a multigrid-based optimization framework to reduce the computational burdens of large-scale ptychographic phase retrieval. Our proposed method exploits the inherent hierarchical structures in ptychography through tailored restriction and prolongation operators for the object and data domains. Our numerical results show that our proposed scheme accelerates the convergence of its underlying solver and outperforms the ptychographical iterative engine, a workhorse in the optics community.},
  archive      = {J_SIIMS},
  author       = {Samy Wu Fung and Zichao Wendy Di},
  doi          = {10.1137/18M1223915},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {214-233},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Multigrid optimization for large-scale ptychographic phase retrieval},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). <span class="math inline"><em>N</em></span>-dimensional
tensor completion for nuclear magnetic resonance relaxometry.
<em>SIIMS</em>, <em>13</em>(1), 176–213. (<a
href="https://doi.org/10.1137/18M1193037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with tensor completion for the solution of multidimensional inverse problems arising in nuclear magnetic resonance (NMR) relaxometry. We study the problem of reconstructing an approximately low-rank tensor from a small number of noisy linear measurements. New recovery guarantees, numerical algorithms, nonuniform sampling strategies, and parameter selection methods are developed in this context. In particular, we derive a fixed point continuation algorithm for tensor completion and prove its convergence. A restricted isometry property-based tensor recovery guarantee is proved. Probabilistic recovery guarantees are obtained for sub-Gaussian measurement operators and for measurements obtained by nonuniform sampling from a Parseval tight frame. The proposed algorithm is then applied to the setting of nuclear magnetic resonance relaxometry, for both simulated and experimental data. We compare our results with basis pursuit as well as with the state-of-the-art nonsubsampled data acquisition and reconstruction approach. Our experiments indicate that tensor recovery promises to significantly accelerate $N$-dimensional NMR relaxometry and related experiments, enabling previously impractical experiments to be performed. Our methods could also be applied to other similar inverse problems arising in machine learning, signal and image processing, and computer vision.},
  archive      = {J_SIIMS},
  author       = {Ariel Hafftka and Wojciech Czaja and Hasan Celik and Richard G. Spencer},
  doi          = {10.1137/18M1193037},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {176-213},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {$N$-dimensional tensor completion for nuclear magnetic resonance relaxometry},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dictionary learning for two-dimensional kendall shapes.
<em>SIIMS</em>, <em>13</em>(1), 141–175. (<a
href="https://doi.org/10.1137/19M126044X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel sparse dictionary learning method for planar shapes in the sense of Kendall, namely configurations of landmarks in the plane considered up to similitudes. Our shape dictionary method provides a good trade-off between algorithmic simplicity and faithfulness with respect to the nonlinear geometric structure of Kendall&#39;s shape space. Remarkably, it boils down to a classical dictionary learning formulation modified using complex weights. Existing dictionary learning methods extended to nonlinear spaces map the manifold either to a reproducing kernel Hilbert space or to a tangent space. The first approach is unnecessarily heavy in the case of Kendall&#39;s shape space and causes the geometrical understanding of shapes to be lost, while the second one induces distortions and theoretical complexity. Our approach does not suffer from these drawbacks. Instead of embedding the shape space into a linear space, we rely on the hyperplane of centered configurations, including preshapes from which shapes are defined as rotation orbits. In this linear space, the dictionary atoms are scaled and rotated using complex weights before summation. Furthermore, our formulation is more general than Kendall&#39;s original one: it applies to discretely defined configurations of landmarks as well as continuously defined interpolating curves. We implemented our algorithm by adapting the method of optimal directions combined to a Cholesky-optimized order recursive matching pursuit. An interesting feature of our shape dictionary is that it produces visually realistic atoms, while guaranteeing reconstruction accuracy. Its efficiency can mostly be attributed to a clear formulation of the framework with complex numbers. We illustrate the strong potential of our approach for the characterization of datasets of shapes up to similitudes and the analysis of patterns in deforming two-dimensional shapes.},
  archive      = {J_SIIMS},
  author       = {Anna Song and Virginie Uhlmann and Julien Fageot and Michael Unser},
  doi          = {10.1137/19M126044X},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {141-175},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Dictionary learning for two-dimensional kendall shapes},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Nonlinear iterative hard thresholding for inverse
scattering. <em>SIIMS</em>, <em>13</em>(1), 108–140. (<a
href="https://doi.org/10.1137/19M1251928">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the inverse scattering problem for sparse scatterers. An image reconstruction algorithm is proposed that is based on a nonlinear generalization of iterative hard thresholding. The convergence and error of the method was analyzed by means of coherence estimates and compared to numerical simulations.},
  archive      = {J_SIIMS},
  author       = {Anna C. Gilbert and Howard W. Levinson and John C. Schotland},
  doi          = {10.1137/19M1251928},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {108-140},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Nonlinear iterative hard thresholding for inverse scattering},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Automatically controlled morphing of 2D shapes with
textures. <em>SIIMS</em>, <em>13</em>(1), 78–107. (<a
href="https://doi.org/10.1137/19M1241581">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with 2D image transformations from a perspective of a 3D heterogeneous shape modeling and computer animation. Shape and image morphing techniques have attracted a lot of attention in artistic design, computer animation, and interactive and streaming applications. We present a novel method for morphing between two topologically arbitrary 2D shapes with sophisticated textures (raster color attributes) using a metamorphosis technique called space-time blending (STB) coupled with space-time transfinite interpolation. The method allows for a smooth transition between source and target objects by generating in-between shapes and associated textures without setting any correspondences between boundary points or features. The method requires no preprocessing and can be applied in 2D animation when position and topology of source and target objects are significantly different. With the conversion of given 2D shapes to signed distance fields, we have detected a number of problems with directly applying STB to them. We propose a set of novel and mathematically substantiated techniques, providing automatic control of the morphing process with STB and an algorithm of applying those techniques in combination. We illustrate our method with applications in 2D animation and interactive applications.},
  archive      = {J_SIIMS},
  author       = {Alexander Tereshin and Valery Adzhiev and Oleg Fryazinov and Felix Marrington-Reeve and Alexander Pasko},
  doi          = {10.1137/19M1241581},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {78-107},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Automatically controlled morphing of 2D shapes with textures},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Computation of circular area and spherical volume invariants
via boundary integrals. <em>SIIMS</em>, <em>13</em>(1), 53–77. (<a
href="https://doi.org/10.1137/19M1260803">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show how to compute the circular area invariant of planar curves, and the spherical volume invariant of surfaces, in terms of line and surface integrals, respectively. We use the divergence theorem to express the area and volume integrals as line and surface integrals, respectively, against particular kernels; our results also extend to higher-dimensional hypersurfaces. The resulting surface integrals are computable analytically on a triangulated mesh. This gives a simple computational algorithm for computing the spherical volume invariant for triangulated surfaces that does not involve discretizing the ambient space. We discuss potential applications to feature detection on broken bone fragments of interest in anthropology.},
  archive      = {J_SIIMS},
  author       = {Riley C. W. O&#39;Neill and Pedro Angulo-Uman͂a and Jeff Calder and Bo Hessburg and Peter J. Olver and Chehrzad Shakiban and Katrina Yezzi-Woodley},
  doi          = {10.1137/19M1260803},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {53-77},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Computation of circular area and spherical volume invariants via boundary integrals},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bayesian inference and uncertainty quantification for
medical image reconstruction with poisson data. <em>SIIMS</em>,
<em>13</em>(1), 29–52. (<a
href="https://doi.org/10.1137/19M1248352">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide a complete framework for performing infinite dimensional Bayesian inference and uncertainty quantification for image reconstruction with Poisson data. In particular, we address the following issues to make the Bayesian framework applicable in practice. We first introduce a positivity-preserving reparametrization, and we prove that under the reparametrization and a hybrid prior, the posterior distribution is well-posed in the infinite dimensional setting. Second, we provide a dimension-independent Markov chain Monte Carlo algorithm, based on the preconditioned Crank--Nicolson Langevin method, in which we use a primal-dual scheme to compute the offset direction. Third, we give a method combining the model discrepancy method and maximum likelihood estimation to determine the regularization parameter in the hybrid prior. Finally we propose to use the obtained posterior distribution to detect artifacts in a recovered image. We provide an example to demonstrate the effectiveness of the proposed method.},
  archive      = {J_SIIMS},
  author       = {Qingping Zhou and Tengchao Yu and Xiaoqun Zhang and Jinglai Li},
  doi          = {10.1137/19M1248352},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {29-52},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Bayesian inference and uncertainty quantification for medical image reconstruction with poisson data},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptive variational model for contrast enhancement of
low-light images. <em>SIIMS</em>, <em>13</em>(1), 1–28. (<a
href="https://doi.org/10.1137/19M1245499">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contrast enhancement plays an important role in image/video processing and computer vision applications. Its main purpose is to adjust the image intensity to enhance the quality and features of the image. In this paper, we propose a simple and efficient adaptive variational model for contrast enhancement for partially shaded low-light images. The key idea of this adaptive approach is to employ the maximum image of the RGB color channels as a classifier to divide the image domain into the relatively bright and dim parts, and then use different fitting terms for each part such that the bright pixels are preserved as close as possible to the original ones while the dim pixels are boosted with brightness and contrast-level parameters to adjust the degree of the strength. With this adaptivity, one can find that the proposed model considerably improves upon the existing variational models in the literature. In this paper, the existence and uniqueness of the minimizer for the variational minimization problem is established. The split Bregman method is used to accomplish an efficient numerical implementation of the adaptive variational model. Moreover, a number of numerical experiments and comparisons with other popular enhancement methods are conducted to demonstrate the high performance of the newly proposed method.},
  archive      = {J_SIIMS},
  author       = {Po-Wen Hsieh and Pei-Chiang Shao and Suh-Yuh Yang},
  doi          = {10.1137/19M1245499},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {1-28},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Adaptive variational model for contrast enhancement of low-light images},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
