<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>SIOPT_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="siopt---128">SIOPT - 128</h2>
<ul>
<li><details>
<summary>
(2020). Generalized subdifferentials of spectral functions over
euclidean jordan algebras. <em>SIOPT</em>, <em>30</em>(4), 3387–3414.
(<a href="https://doi.org/10.1137/19M1245001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is devoted to the study of generalized subdifferentials of spectral functions over Euclidean Jordan algebras. Spectral functions appear often in optimization problems playing the role of “regularizer,” ``barrier,” ``penalty function,” and many others. We provide formulae for the regular, approximate, and horizon subdifferentials of spectral functions. In addition, under local lower semicontinuity, we also furnish a formula for the Clarke subdifferential, thus extending an earlier result by Baes. As application, we compute the generalized subdifferentials of the function that maps an element to its $k$th largest eigenvalue. Furthermore, in connection with recent approaches for nonsmooth optimization, we present a study of the Kurdyka--Łojasiewicz (KL) property for spectral functions and prove a transfer principle for the KL-exponent. In our proofs, we make extensive use of recent tools such as the commutation principle of Ramírez, Seeger, and Sossa and majorization principles developed by Gowda.},
  archive      = {J_SIOPT},
  author       = {Bruno F. Lourenço and Akiko Takeda},
  doi          = {10.1137/19M1245001},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {3387-3414},
  shortjournal = {SIAM J. Optim.},
  title        = {Generalized subdifferentials of spectral functions over euclidean jordan algebras},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Scalable algorithms for the sparse ridge regression.
<em>SIOPT</em>, <em>30</em>(4), 3359–3386. (<a
href="https://doi.org/10.1137/19M1245414">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse regression and variable selection for large-scale data have been rapidly developed in the past decades. This work focuses on sparse ridge regression, which enforces the sparsity by use of the $L_{0}$ norm. We first prove that the continuous relaxation of the mixed integer second order conic (MISOC) reformulation using perspective formulation is equivalent to that of the convex integer formulation proposed in recent work. We also show that the convex hull of the constraint system of the MISOC formulation is equal to its continuous relaxation. Based upon these two formulations (i.e., the MISOC formulation and convex integer formulation), we analyze two scalable algorithms, the greedy and randomized algorithms, for sparse ridge regression with desirable theoretical properties. The proposed algorithms are proved to yield near-optimal solutions under mild conditions. We further propose integrating the greedy algorithm with the randomized algorithm, which can greedily search the features from the nonzero subset identified by the continuous relaxation of the MISOC formulation. The merits of the proposed methods are illustrated through numerical examples in comparison with several existing ones.},
  archive      = {J_SIOPT},
  author       = {Weijun Xie and Xinwei Deng},
  doi          = {10.1137/19M1245414},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {3359-3386},
  shortjournal = {SIAM J. Optim.},
  title        = {Scalable algorithms for the sparse ridge regression},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Solving large-scale cubic regularization by a generalized
eigenvalue problem. <em>SIOPT</em>, <em>30</em>(4), 3345–3358. (<a
href="https://doi.org/10.1137/19M1291388">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cubic regularization methods have several favorable properties. In particular under mild assumptions, they are globally convergent towards critical points with second-order necessary conditions satisfied. Their adoption among practitioners, however, does not yet match the strong theoretical results. One of the reasons for this discrepancy may be the additional implementation complexity needed to solve the cubic regularization subproblems. In this paper we show that this complexity can be decreased significantly by reducing the subproblem to a generalized eigenvalue problem. The resulting algorithm is not only robust, due to existing highly advanced eigenvalue solvers, but also provides a new way of employing second-order methods in the large-scale case.},
  archive      = {J_SIOPT},
  author       = {Felix Lieder},
  doi          = {10.1137/19M1291388},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {3345-3358},
  shortjournal = {SIAM J. Optim.},
  title        = {Solving large-scale cubic regularization by a generalized eigenvalue problem},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stochastic conditional gradient++: (Non)convex minimization
and continuous submodular maximization. <em>SIOPT</em>, <em>30</em>(4),
3315–3344. (<a href="https://doi.org/10.1137/19M1304271">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the general nonoblivious stochastic optimization where the underlying stochasticity may change during the optimization procedure and depends on the point at which the function is evaluated. We develop Stochastic Frank--Wolfe++ (SFW++), an efficient variant of the conditional gradient method for minimizing a smooth nonconvex function subject to a convex body constraint. We show that SFW++ converges to an $\epsilon$-first order stationary point by using $O(1/\epsilon^3)$ stochastic gradients. Once further structures are present, SFW++&#39;s theoretical guarantees, in terms of the convergence rate and quality of its solution, improve. In particular, for minimizing a convex function, SFW++ achieves an $\epsilon$-approximate optimum while using $O(1/\epsilon^2)$ stochastic gradients. It is known that this rate is optimal in terms of stochastic gradient evaluations. Similarly, for maximizing a monotone continuous DR-submodular function, a slightly different form of SFW++, called Stochastic Continuous Greedy++ (SCG++), achieves a tight $[(1-1/e){\text{OPT}} -\epsilon]$ solution while using $O(1/\epsilon^2)$ stochastic gradients. Through an information theoretic argument, we also prove that SCG++&#39;s convergence rate is optimal. Finally, for maximizing a nonmonotone continuous DR-submodular function, we can achieve a $[(1/e){\text{OPT}} -\epsilon]$ solution by using $O(1/\epsilon^2)$ stochastic gradients. We should highlight that our results and our novel variance reduction technique trivially extend to the standard and easier oblivious stochastic optimization settings for (non)convex and continuous submodular settings.},
  archive      = {J_SIOPT},
  author       = {Hamed Hassani and Amin Karbasi and Aryan Mokhtari and Zebang Shen},
  doi          = {10.1137/19M1304271},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {3315-3344},
  shortjournal = {SIAM J. Optim.},
  title        = {Stochastic conditional gradient++: (Non)Convex minimization and continuous submodular maximization},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fair packing and covering on a relative scale.
<em>SIOPT</em>, <em>30</em>(4), 3284–3314. (<a
href="https://doi.org/10.1137/19M1288516">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fair resource allocation is a fundamental optimization problem with applications in operations research, networking, and economic and game theory. Research in these areas has led to the general acceptance of a class of $\alpha$-fair utility functions parameterized by $\alpha \in [0, \infty]$. We consider $\alpha$-fair packing---the problem of maximizing $\alpha$-fair utilities under positive linear constraints---and provide a simple first-order method for solving it with relative-error guarantees. The method has a significantly lower convergence time than the state of the art, and to analyze it, we leverage the approximate duality gap technique, which provides an intuitive interpretation of the convergence argument. Finally, we introduce a natural counterpart of $\alpha$-fairness for minimization problems and motivate its usage in the context of fair task allocation. This generalization yields $\alpha$-fair covering problems, for which we provide the first near-linear-time solvers with relative-error guarantees.},
  archive      = {J_SIOPT},
  author       = {Jelena Diakonikolas and Maryam Fazel and Lorenzo Orecchia},
  doi          = {10.1137/19M1288516},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {3284-3314},
  shortjournal = {SIAM J. Optim.},
  title        = {Fair packing and covering on a relative scale},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Newton-like inertial dynamics and proximal algorithms
governed by maximally monotone operators. <em>SIOPT</em>,
<em>30</em>(4), 3252–3283. (<a
href="https://doi.org/10.1137/20M1333316">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The introduction of the Hessian damping in the continuous version of Nesterov&#39;s accelerated gradient method provides, by temporal discretization, fast proximal gradient algorithms where the oscillations are significantly attenuated. We will extend these results to the maximally monotone case. We rely on the technique introduced by Attouch and Peypouquet [Math. Program., 174 (2019), pp. 391--432], where the maximally monotone operator is replaced by its Yosida approximation with an appropriate adjustment of the regularization parameter. In a general Hilbert framework, we obtain the weak convergence of the iterates to equilibria, and the rapid convergence of the discrete velocities to zero. By specializing these algorithms to convex minimization, we obtain the convergence rate $o(1/k^2)$ of the values, and the rapid convergence of the gradients toward zero.},
  archive      = {J_SIOPT},
  author       = {Hedy Attouch and Szilárd Csaba László},
  doi          = {10.1137/20M1333316},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {3252-3283},
  shortjournal = {SIAM J. Optim.},
  title        = {Newton-like inertial dynamics and proximal algorithms governed by maximally monotone operators},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Convergence rate of <span
class="math inline">𝒪(1/<em>k</em>)</span> for optimistic gradient and
extragradient methods in smooth convex-concave saddle point problems.
<em>SIOPT</em>, <em>30</em>(4), 3230–3251. (<a
href="https://doi.org/10.1137/19M127375X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the iteration complexity of the optimistic gradient descent-ascent (OGDA) method and the extragradient (EG) method for finding a saddle point of a convex-concave unconstrained min-max problem. To do so, we first show that both OGDA and EG can be interpreted as approximate variants of the proximal point method. This is similar to the approach taken in (A. Nemirovski (2004), SIAM J. Optim., 15, pp. 229--251) which analyzes EG as an approximation of the “conceptual mirror prox.” In this paper, we highlight how gradients used in OGDA and EG try to approximate the gradient of the proximal point method. We then exploit this interpretation to show that both algorithms produce iterates that remain within a bounded set. We further show that the primal-dual gap of the averaged iterates generated by both of these algorithms converge with a rate of $\mathcal{O}(1/k)$. Our theoretical analysis is of interest as it provides the first convergence rate estimate for OGDA in the general convex-concave setting. Moreover, it provides a simple convergence analysis for the EG algorithm in terms of function value without using a compactness assumption.},
  archive      = {J_SIOPT},
  author       = {Aryan Mokhtari and Asuman E. Ozdaglar and Sarath Pattathil},
  doi          = {10.1137/19M127375X},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {3230-3251},
  shortjournal = {SIAM J. Optim.},
  title        = {Convergence rate of $\mathcal{O}(1/k)$ for optimistic gradient and extragradient methods in smooth convex-concave saddle point problems},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust spectral risk optimization when information on risk
spectrum is incomplete. <em>SIOPT</em>, <em>30</em>(4), 3198–3229. (<a
href="https://doi.org/10.1137/19M1284270">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A spectral risk measure (SRM) is a weighted average of value at risk where the weighting function (also known as risk spectrum or distortion function) characterizes a decision maker&#39;s risk attitude. In this paper, we consider the case where the decision maker&#39;s risk spectrum is ambiguous and introduce a robust SRM model based on the worst risk spectrum from a ball of risk spectra centered at a nominal risk spectrum. When the ball consists of step-like risk spectra, we show that the robust SRM can be computed by solving a linear programming problem. For the general case, we propose a step-like approximation scheme and derive an error bound for the approximation. As an application, we apply the proposed robust SRM to one-stage stochastic optimization with the objective of minimizing the robust SRM and propose an alternating iterative algorithm for solving the resulting minimax optimization problem. Moreover, to examine stability of the robust spectral risk optimization model with respect to perturbation of observed data from the underlying exogenous uncertainty in data-driven environments, we investigate statistical robustness of the model and derive sufficient conditions for the required stability.},
  archive      = {J_SIOPT},
  author       = {Wei Wang and Huifu Xu},
  doi          = {10.1137/19M1284270},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {3198-3229},
  shortjournal = {SIAM J. Optim.},
  title        = {Robust spectral risk optimization when information on risk spectrum is incomplete},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Globally convergent type-i anderson acceleration for
nonsmooth fixed-point iterations. <em>SIOPT</em>, <em>30</em>(4),
3170–3197. (<a href="https://doi.org/10.1137/18M1232772">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the application of the type-I Anderson acceleration to solving general nonsmooth fixed-point problems. By interleaving with safeguarding steps and employing a Powell-type regularization and a restart checking for strong linear independence of the updates, we propose the first globally convergent variant of Anderson acceleration assuming only that the fixed-point iteration is nonexpansive. We show by extensive numerical experiments that many first order algorithms can be improved, especially in their terminal convergence, with the proposed algorithm. Our proposed method of acceleration is being implemented in SCS 2.1, one of the default solvers used in the convex optimization parser-solver CVXPY 1.0.},
  archive      = {J_SIOPT},
  author       = {Junzi Zhang and Brendan O&#39;Donoghue and Stephen Boyd},
  doi          = {10.1137/18M1232772},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {3170-3197},
  shortjournal = {SIAM J. Optim.},
  title        = {Globally convergent type-I anderson acceleration for nonsmooth fixed-point iterations},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Contracting proximal methods for smooth convex optimization.
<em>SIOPT</em>, <em>30</em>(4), 3146–3169. (<a
href="https://doi.org/10.1137/19M130769X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose new accelerated methods for smooth convex optimization, called contracting proximal methods. At every step of these methods, we need to minimize a contracted version of the objective function augmented by a regularization term in the form of Bregman divergence. We provide global convergence analysis for a general scheme admitting inexactness in solving the auxiliary subproblem. In the case of using for this purpose high-order tensor methods, we demonstrate an acceleration effect for both convex and uniformly convex composite objective functions. Thus, our construction explains acceleration for methods of any order starting from one. The augmentation of the number of calls of oracle due to computing the contracted proximal steps is limited by the logarithmic factor in the worst-case complexity bound.},
  archive      = {J_SIOPT},
  author       = {Nikita Doikov and Yurii Nesterov},
  doi          = {10.1137/19M130769X},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {3146-3169},
  shortjournal = {SIAM J. Optim.},
  title        = {Contracting proximal methods for smooth convex optimization},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Solving multiobjective mixed integer convex optimization
problems. <em>SIOPT</em>, <em>30</em>(4), 3122–3145. (<a
href="https://doi.org/10.1137/19M1264709">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiobjective mixed integer convex optimization refers to mathematical programming problems where more than one convex objective function needs to be optimized simultaneously and some of the variables are constrained to take integer values. We present a branch-and-bound method based on the use of properly defined lower bounds. We do not simply rely on convex relaxations, but we build linear outer approximations of the image set in an adaptive way. We are able to guarantee correctness in terms of detecting both the efficient and the nondominated set of multiobjective mixed integer convex problems according to a prescribed precision. As far as we know, the procedure we present is the first non-scalarization-based deterministic algorithm devised to handle this class of problems. Our numerical experiments show results on biobjective and triobjective mixed integer convex instances.},
  archive      = {J_SIOPT},
  author       = {Marianna De Santis and Gabriele Eichfelder and Julia Niebling and Stefan Rocktäschel},
  doi          = {10.1137/19M1264709},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {3122-3145},
  shortjournal = {SIAM J. Optim.},
  title        = {Solving multiobjective mixed integer convex optimization problems},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Noisy matrix completion: Understanding statistical
guarantees for convex relaxation via nonconvex optimization.
<em>SIOPT</em>, <em>30</em>(4), 3098–3121. (<a
href="https://doi.org/10.1137/19M1290000">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies noisy low-rank matrix completion: given partial and noisy entries of a large low-rank matrix, the goal is to estimate the underlying matrix faithfully and efficiently. Arguably one of the most popular paradigms to tackle this problem is convex relaxation, which achieves remarkable efficacy in practice. However, the theoretical support of this approach is still far from optimal in the noisy setting, falling short of explaining its empirical success. We make progress towards demystifying the practical efficacy of convex relaxation vis-à-vis random noise. When the rank and the condition number of the unknown matrix are bounded by a constant, we demonstrate that the convex programming approach achieves near-optimal estimation errors---in terms of the Euclidean loss, the entrywise loss, and the spectral norm loss---for a wide range of noise levels. All of this is enabled by bridging convex relaxation with the nonconvex Burer--Monteiro approach, a seemingly distinct algorithmic paradigm that is provably robust against noise. More specifically, we show that an approximate critical point of the nonconvex formulation serves as an extremely tight approximation of the convex solution, thus allowing us to transfer the desired statistical guarantees of the nonconvex approach to its convex counterpart.},
  archive      = {J_SIOPT},
  author       = {Yuxin Chen and Yuejie Chi and Jianqing Fan and Cong Ma and Yuling Yan},
  doi          = {10.1137/19M1290000},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {3098-3121},
  shortjournal = {SIAM J. Optim.},
  title        = {Noisy matrix completion: Understanding statistical guarantees for convex relaxation via nonconvex optimization},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Convergence of inexact forward–backward algorithms using the
forward–backward envelope. <em>SIOPT</em>, <em>30</em>(4), 3069–3097.
(<a href="https://doi.org/10.1137/19M1254155">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with a general framework for inexact forward--backward algorithms aimed at minimizing the sum of an analytic function and a lower semicontinuous, subanalytic, convex term. Such a framework relies on an implementable inexactness condition for the computation of the proximal operator and on a linesearch procedure, which is possibly performed whenever a variable metric is allowed into the forward--backward step. The main focus of this work is the convergence of the considered scheme without additional convexity assumptions on the objective function. Toward this aim, we employ the recent concept of forward--backward envelope to define a continuously differentiable surrogate function, which coincides with the objective at its stationary points and satisfies the so-called Kurdyka--Łojasiewicz (KL) property on its domain. We adapt the abstract convergence scheme usually exploited in the KL framework to our inexact forward--backward scheme, prove the convergence of the iterates to a stationary point of the problem, and prove the convergence rates for the function values. Finally, we show the effectiveness and the flexibility of the proposed framework on a large-scale image restoration test problem.},
  archive      = {J_SIOPT},
  author       = {S. Bonettini and M. Prato and S. Rebegoldi},
  doi          = {10.1137/19M1254155},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {3069-3097},
  shortjournal = {SIAM J. Optim.},
  title        = {Convergence of inexact forward--backward algorithms using the forward--backward envelope},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Second-order guarantees of distributed gradient algorithms.
<em>SIOPT</em>, <em>30</em>(4), 3029–3068. (<a
href="https://doi.org/10.1137/18M121784X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider distributed smooth nonconvex unconstrained optimization over net- works, modeled as a connected graph. We examine the behavior of distributed gradient-based algorithms near strict saddle points. Specifically, we establish that (i) the renowned distributed gradient descent algorithm likely converges to a neighborhood of a second-order stationary (SoS) solution; and (ii) the more recent class of distributed algorithms based on gradient tracking---implementable also over digraphs---likely converges to exact SoS solutions, thus avoiding (strict) saddle points. Furthermore, new convergence rate results for first-order critical points is established for the latter class of algorithms.},
  archive      = {J_SIOPT},
  author       = {Amir Daneshmand and Gesualdo Scutari and Vyacheslav Kungurtsev},
  doi          = {10.1137/18M121784X},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {3029-3068},
  shortjournal = {SIAM J. Optim.},
  title        = {Second-order guarantees of distributed gradient algorithms},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Approximate matrix and tensor diagonalization by unitary
transformations: Convergence of jacobi-type algorithms. <em>SIOPT</em>,
<em>30</em>(4), 2998–3028. (<a
href="https://doi.org/10.1137/19M125950X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a gradient-based Jacobi algorithm for a class of maximization problems on the unitary group, with a focus on approximate diagonalization of complex matrices and tensors by unitary transformations. We provide weak convergence results, and prove local linear convergence of this algorithm. The convergence results also apply to the case of real-valued tensors.},
  archive      = {J_SIOPT},
  author       = {Konstantin Usevich and Jianze Li and Pierre Comon},
  doi          = {10.1137/19M125950X},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2998-3028},
  shortjournal = {SIAM J. Optim.},
  title        = {Approximate matrix and tensor diagonalization by unitary transformations: Convergence of jacobi-type algorithms},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The convex hull of a quadratic constraint over a polytope.
<em>SIOPT</em>, <em>30</em>(4), 2983–2997. (<a
href="https://doi.org/10.1137/19M1277333">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A quadratically constrained quadratic program (QCQP) is an optimization problem in which the objective function is a quadratic function and the feasible region is defined by quadratic constraints. Solving nonconvex QCQP to global optimality is a well-known NP-hard problem and a traditional approach is to use convex relaxations and branch-and-bound algorithms. This paper makes a contribution in this direction by showing that the exact convex hull of a general quadratic equation intersected with any bounded polyhedron is second-order cone representable. We present a simple constructive proof and some preliminary applications of this result.},
  archive      = {J_SIOPT},
  author       = {Asteroide Santana and Santanu S. Dey},
  doi          = {10.1137/19M1277333},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2983-2997},
  shortjournal = {SIAM J. Optim.},
  title        = {The convex hull of a quadratic constraint over a polytope},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). New constraint qualifications for optimization problems in
banach spaces based on asymptotic KKT conditions. <em>SIOPT</em>,
<em>30</em>(4), 2956–2982. (<a
href="https://doi.org/10.1137/19M1306804">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimization theory in Banach spaces suffers from a lack of available constraint qualifications. There exist very few constraint qualifications, and these are often violated even in simple applications. This is very much in contrast to finite-dimensional nonlinear programs, where a large number of constraint qualifications is known. Since these constraint qualifications are usually defined using the set of active inequality constraints, it is difficult to extend them to the infinite-dimensional setting. One exception is a recently introduced sequential constraint qualification based on asymptotic KKT conditions. This paper shows that this so-called asymptotic KKT regularity allows suitable extensions to the Banach space setting in order to obtain new constraint qualifications. The relation of these new constraint qualifications to existing ones is discussed in detail. Their usefulness is also shown by several examples as well as an algorithmic application to the class of augmented Lagrangian methods.},
  archive      = {J_SIOPT},
  author       = {Eike Börgens and Christian Kanzow and Patrick Mehlitz and Gerd Wachsmuth},
  doi          = {10.1137/19M1306804},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2956-2982},
  shortjournal = {SIAM J. Optim.},
  title        = {New constraint qualifications for optimization problems in banach spaces based on asymptotic KKT conditions},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An equivalence between critical points for rank constraints
versus low-rank factorizations. <em>SIOPT</em>, <em>30</em>(4),
2927–2955. (<a href="https://doi.org/10.1137/18M1231675">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two common approaches in low-rank optimization problems are either working directly with a rank constraint on the matrix variable or optimizing over a low-rank factorization so that the rank constraint is implicitly ensured. In this paper, we study the natural connection between the rank-constrained and factorized approaches. We show that all second-order stationary points of the factorized objective function correspond to fixed points of projected gradient descent run on the original problem (where the projection step enforces the rank constraint). This result allows us to unify many existing optimization guarantees that have been proved specifically in either the rank-constrained or the factorized setting and leads to new results for certain settings of the problem. We demonstrate application of our results to several concrete low-rank optimization problems arising in matrix inverse problems.},
  archive      = {J_SIOPT},
  author       = {Wooseok Ha and Haoyang Liu and Rina Foygel Barber},
  doi          = {10.1137/18M1231675},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2927-2955},
  shortjournal = {SIAM J. Optim.},
  title        = {An equivalence between critical points for rank constraints versus low-rank factorizations},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A unified adaptive tensor approximation scheme to accelerate
composite convex optimization. <em>SIOPT</em>, <em>30</em>(4),
2897–2926. (<a href="https://doi.org/10.1137/19M1286025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a unified two-phase scheme to accelerate any high-order regularized tensor approximation approach on the smooth part of a composite convex optimization model. The proposed scheme has the advantage of not needing to assume any prior knowledge of the Lipschitz constants for the gradient, the Hessian, and/or high-order derivatives. This is achieved by tuning the parameters used in the algorithm adaptively in its process of progression, which has been successfully incorporated in high-order nonconvex optimization [C. Cartis, N. I. M. Gould, and Ph. L. Toint, Found. Comput. Math., 18 (2018), pp. 1073--1107; E. G. Birgin et al., Math. Program., 163 (2017), pp. 359--368]. By adopting a similar approximate measure of the subproblem in [E. G. Birgin et al., Math. Program., 163 (2017), pp. 359--368] for nonconvex optimization, we establish the overall iteration complexity bounds for three specific algorithms to obtain an $\epsilon$-optimal solution for composite convex problems. In general, we show that the adaptive high-order method has an iteration bound of $O\left( 1 / \epsilon^{1/(p+1)} \right)$ if the first $p$th-order derivative information is used in the approximation, which has the same iteration complexity as in [M. Baes, Estimate Sequence Methods: Extensions and Approximations, Institute for Operations Research, ETH, Zürich, 2009; Y. Nesterov, Math. Program., published online Nov. 21, 2019, https://doi.org/10.1007/s10107-019-01449-1], where the Lipschitz constants are assumed to be known, and the subproblems are assumed to be solved exactly. Thus, our results partially address the problem of incorporating adaptive strategies into the high-order accelerated methods raised by Nesterov in [Math. Program., published online Nov. 21, 2019, https://doi.org/10.1007/s10107-019-01449-1], although our strategies cannot ensure the convexity of the auxiliary problem, and such adaptive strategies are already popular in high-order nonconvex optimization [C. Cartis, N. I. M. Gould, and Ph. L. Toint, Found. Comput. Math., 18 (2018), pp. 1073--1107; E. G. Birgin et al., Math. Program., 163 (2017), pp. 359--368]. Specifically, we show that the gradient method achieves an iteration complexity on the order of $O\left( 1 / \epsilon^{1/2} \right)$, which is known to be best possible (cf. [Y. Nesterov, Lectures on Convex Optimization, 2nd ed., Springer, 2018]), while the adaptive cubic regularization methods with the exact/inexact Hessian matrix achieve an iteration complexity on the order of $O\left( 1 / \epsilon^{1/3} \right)$, which matches that of the original accelerated cubic regularization method presented in [Y. Nesterov, Math. Program., 112 (2008), pp. 159--181]. The results of our numerical experiment clearly show the effect of the acceleration displayed in the adaptive Newton&#39;s method with cubic regularization on a set of regularized logistic regression instances.},
  archive      = {J_SIOPT},
  author       = {Bo Jiang and Tianyi Lin and Shuzhong Zhang},
  doi          = {10.1137/19M1286025},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2897-2926},
  shortjournal = {SIAM J. Optim.},
  title        = {A unified adaptive tensor approximation scheme to accelerate composite convex optimization},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Non-stationary first-order primal-dual algorithms with
faster convergence rates. <em>SIOPT</em>, <em>30</em>(4), 2866–2896. (<a
href="https://doi.org/10.1137/19M1293855">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose two novel non-stationary first-order primal-dual algorithms to solve non-smooth composite convex optimization problems. Unlike existing primal-dual schemes where the parameters are often fixed, our methods use predefined and dynamic sequences for parameters. We prove that our first algorithm can achieve an $\mathcal{O}\left(1/k\right)$ convergence rate on the primal-dual gap, and primal and dual objective residuals, where $k$ is the iteration counter. Our rate is on the non-ergodic (i.e., the last iterate) sequence of the primal problem and on the ergodic (i.e., the averaging) sequence of the dual problem, which we call the semi-ergodic rate. By modifying the step-size update rule, this rate can be boosted even faster on the primal objective residual. When the problem is strongly convex, we develop a second primal-dual algorithm that exhibits an $\mathcal{O}\left(1/k^2\right)$ convergence rate on the same three types of guarantees. Again by modifying the step-size update rule, this rate becomes faster on the primal objective residual. Our primal-dual algorithms are the first ones to achieve such fast convergence rate guarantees under mild assumptions compared to existing works, to the best of our knowledge. As byproducts, we apply our algorithms to solve constrained convex optimization problems and prove the same convergence rates on both the objective residuals and the feasibility violation. We still obtain at least $\mathcal{O}\left(1/k^2\right)$ rates even when the problem is “semi-strongly” convex. We verify our theoretical results via two well-known numerical examples.},
  archive      = {J_SIOPT},
  author       = {Quoc Tran-Dinh and Yuzixuan Zhu},
  doi          = {10.1137/19M1293855},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2866-2896},
  shortjournal = {SIAM J. Optim.},
  title        = {Non-stationary first-order primal-dual algorithms with faster convergence rates},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Distributionally robust stochastic dual dynamic programming.
<em>SIOPT</em>, <em>30</em>(4), 2841–2865. (<a
href="https://doi.org/10.1137/19M1309602">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a multistage stochastic linear program that lends itself to solution by stochastic dual dynamic programming (SDDP). In this context, we consider a distributionally robust variant of the model with a finite number of realizations at each stage. Distributional robustness is with respect to the probability mass function governing these realizations. We describe a computationally tractable variant of SDDP to handle this model using the Wasserstein distance to characterize distributional uncertainty.},
  archive      = {J_SIOPT},
  author       = {Daniel Duque and David P. Morton},
  doi          = {10.1137/19M1309602},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2841-2865},
  shortjournal = {SIAM J. Optim.},
  title        = {Distributionally robust stochastic dual dynamic programming},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Convex analysis in <span
class="math inline">ℤ<sup><em>n</em></sup></span> and applications to
integer linear programming. <em>SIOPT</em>, <em>30</em>(4), 2809–2840.
(<a href="https://doi.org/10.1137/19M1281678">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we compare the definitions of convex sets and convex functions in finite dimensional integer spaces introduced by Adivar and Fang, Borwein, and Giladi, respectively. We show that their definitions of convex sets and convex functions are equivalent. We also provide exact formulations for convex sets, convex cones, affine sets, and convex functions and we analyze the separation between convex sets in finite dimensional integer spaces. As an application, we consider an integer linear programming problem with linear inequality constraints and obtain some necessary or sufficient optimality conditions by employing the image space analysis. We finally provide some computational results based on the above-mentioned optimality conditions.},
  archive      = {J_SIOPT},
  author       = {Jun Li and Giandomenico Mastroeni},
  doi          = {10.1137/19M1281678},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2809-2840},
  shortjournal = {SIAM J. Optim.},
  title        = {Convex analysis in $\mathbb{Z}^n$ and applications to integer linear programming},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Randomized gradient boosting machine. <em>SIOPT</em>,
<em>30</em>(4), 2780–2808. (<a
href="https://doi.org/10.1137/18M1223277">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Gradient Boosting Machine (GBM) introduced by Friedman [J. H. Friedman, Ann. Statist., 29 (2001), pp. 1189--1232] is a powerful supervised learning algorithm that is very widely used in practice---it routinely features as a leading algorithm in machine learning competitions such as Kaggle and the KDDCup. In spite of the usefulness of GBM in practice, our current theoretical understanding of this method is rather limited. In this work, we propose the Randomized Gradient Boosting Machine (RGBM), which leads to substantial computational gains compared to GBM by using a randomization scheme to reduce search in the space of weak learners. We derive novel computational guarantees for RGBM. We also provide a principled guideline towards better step-size selection in RGBM that does not require a line search. Our proposed framework is inspired by a special variant of coordinate descent that combines the benefits of randomized coordinate descent and greedy coordinate descent, and may be of independent interest as an optimization algorithm. As a special case, our results for RGBM lead to superior computational guarantees for GBM. Our computational guarantees depend upon a curious geometric quantity that we call the Minimal Cosine Angle, which relates to the density of weak learners in the prediction space. On a series of numerical experiments on real datasets, we demonstrate the effectiveness of RGBM over GBM in terms of obtaining a model with good training and/or testing data fidelity with a fraction of the computational cost.},
  archive      = {J_SIOPT},
  author       = {Haihao Lu and Rahul Mazumder},
  doi          = {10.1137/18M1223277},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2780-2808},
  shortjournal = {SIAM J. Optim.},
  title        = {Randomized gradient boosting machine},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Tensor methods for minimizing convex functions with hölder
continuous higher-order derivatives. <em>SIOPT</em>, <em>30</em>(4),
2750–2779. (<a href="https://doi.org/10.1137/19M1259432">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study $p$-order methods for unconstrained minimization of convex functions that are $p$-times differentiable ($p\geq 2$) with $\nu$-Hölder continuous $p$th derivatives. We propose tensor schemes with and without acceleration. For the schemes without acceleration, we establish iteration complexity bounds of $\mathcal{O}\left(\epsilon^{-1/(p+\nu-1)}\right)$ for reducing the functional residual below a given $\epsilon\in (0,1)$. Assuming that $\nu$ is known, we obtain an improved complexity bound of $\mathcal{O}\left(\epsilon^{-1/(p+\nu)}\right)$ for the corresponding accelerated scheme. For the case in which $\nu$ is unknown, we present a universal accelerated tensor scheme with iteration complexity of $\mathcal{O}\left(\epsilon^{-p/[(p+1)(p+\nu-1)]}\right)$. A lower complexity bound of $\mathcal{O}\left(\epsilon^{-2/[3(p+\nu)-2]}\right)$ is also obtained for this problem class.},
  archive      = {J_SIOPT},
  author       = {G. N. Grapiglia and Yu. Nesterov},
  doi          = {10.1137/19M1259432},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2750-2779},
  shortjournal = {SIAM J. Optim.},
  title        = {Tensor methods for minimizing convex functions with hölder continuous higher-order derivatives},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stochastic three points method for unconstrained smooth
minimization. <em>SIOPT</em>, <em>30</em>(4), 2726–2749. (<a
href="https://doi.org/10.1137/19M1244378">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we consider the unconstrained minimization problem of a smooth function in $\mathbb{R}^n$ in a setting where only function evaluations are possible. We design a novel randomized derivative-free algorithm---the stochastic three points (STP) method---and analyze its iteration complexity. At each iteration, STP generates a random search direction according to a certain fixed probability law. Our assumptions on this law are very mild: roughly speaking, all laws which do not concentrate all measures on any halfspace passing through the origin will work. For instance, we allow for the uniform distribution on the sphere and also distributions that concentrate all measures on a positive spanning set. Although our approach is designed to not explicitly use derivatives, it covers some first order methods. For instance, if the probability law is chosen to be the Dirac distribution concentrated on the sign of the gradient, then STP recovers the signed gradient descent method. If the probability law is the uniform distribution on the coordinates of the gradient, then STP recovers the randomized coordinate descent method. The complexity of STP depends on the probability law via a simple characteristic closely related to the cosine measure which is used in the analysis of deterministic direct search (DDS) methods. Unlike in DDS, where $O(n)$ ($n$ is the dimension of $x$) function evaluations must be performed in each iteration in the worst case, our method only requires two new function evaluations per iteration. Consequently, while the complexity of DDS depends quadratically on $n$, our method depends linearly on $n$.},
  archive      = {J_SIOPT},
  author       = {El Houcine Bergou and Eduard Gorbunov and Peter Richtárik},
  doi          = {10.1137/19M1244378},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2726-2749},
  shortjournal = {SIAM J. Optim.},
  title        = {Stochastic three points method for unconstrained smooth minimization},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Generalized conditional gradient with augmented lagrangian
for composite minimization. <em>SIOPT</em>, <em>30</em>(4), 2687–2725.
(<a href="https://doi.org/10.1137/19M1240460">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose a splitting scheme which hybridizes the generalized conditional gradient with a proximal step and which we call the CGALP algorithm for minimizing the sum of three proper convex and lower-semicontinuous functions in real Hilbert spaces. The minimization is subject to an affine constraint, that, in particular, allows one to deal with composite problems (a sum of more than three functions) in a separable way by the usual product space technique. While classical conditional gradient methods require Lipschitz continuity of the gradient of the differentiable part of the objective, CGALP needs only differentiability (on an appropriate subset) and hence circumvents the intricate question of Lipschitz continuity of gradients. For the two remaining functions in the objective, we do not require any additional regularity assumption. The second function, possibly nonsmooth, is assumed simple; i.e., the associated proximal mapping is easily computable. For the third function, again nonsmooth, we just assume that its domain is weakly compact and that a linearly perturbed minimization oracle is accessible. In particular, this last function can be chosen to be the indicator of a nonempty bounded closed convex set in order to deal with additional constraints. Finally, the affine constraint is addressed by the augmented Lagrangian approach. Our analysis is carried out for a wide choice of algorithm parameters satisfying so-called open loop rules. As main results, under mild conditions, we show asymptotic feasibility with respect to the affine constraint, weak convergence of the dual multipliers, and convergence of the Lagrangian values to the saddle-point optimal value. We also provide pointwise and ergodic rates of convergence for both the feasibility gap and the Lagrangian values.},
  archive      = {J_SIOPT},
  author       = {Antonio Silveti-Falls and Cesare Molinari and Jalal Fadili},
  doi          = {10.1137/19M1240460},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2687-2725},
  shortjournal = {SIAM J. Optim.},
  title        = {Generalized conditional gradient with augmented lagrangian for composite minimization},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Topology of pareto sets of strongly convex problems.
<em>SIOPT</em>, <em>30</em>(3), 2659–2686. (<a
href="https://doi.org/10.1137/19M1271439">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A multiobjective optimization problem is simplicial if the Pareto set and front are homeomorphic to a simplex and, under the homeomorphisms, each face of the simplex corresponds to the Pareto set and front of a subproblem that treats a subset of objective functions. In this paper, we show that strongly convex problems are simplicial under a mild assumption on the ranks of the differentials of the objective mappings. We further prove that one can make any strongly convex problem satisfy the assumption by a generic linear perturbation, provided that the dimension of the source is sufficiently larger than that of the target. We demonstrate that the location problems, a biological modeling, and the ridge regression can be reduced to multiobjective strongly convex problems via appropriate transformations preserving the Pareto ordering and the topology.},
  archive      = {J_SIOPT},
  author       = {Naoki Hamada and Kenta Hayano and Shunsuke Ichiki and Yutaro Kabata and Hiroshi Teramoto},
  doi          = {10.1137/19M1271439},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2659-2686},
  shortjournal = {SIAM J. Optim.},
  title        = {Topology of pareto sets of strongly convex problems},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Feasible corrector-predictor interior-point algorithm for
<span
class="math inline"><em>P</em><sub>*</sub>(<em>κ</em>)</span>-linear
complementarity problems based on a new search direction.
<em>SIOPT</em>, <em>30</em>(3), 2628–2658. (<a
href="https://doi.org/10.1137/19M1248972">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a new feasible corrector-predictor (CP) interior-point algorithm (IPA), which is suitable for solving linear complementarity problem (LCP) with $P_{*} (\kappa)$-matrices. We use the method of algebraically equivalent transformation (AET) of the nonlinear equation of the system which defines the central path. The AET is based on the function $\varphi(t) = t - \sqrt{t}$ and plays a crucial role in the calculation of the new search direction. We prove that the algorithm has $O((1+2 \kappa) \sqrt{n} \log \frac{9n \mu^0}{8\epsilon} )$ iteration complexity, where $\kappa$ is an upper bound of the handicap of the input matrix. To the best of our knowledge, this is the first CP IPA for $P_*(\kappa)$-LCPs which is based on this search direction. We implement the proposed CP IPA in the C++ programming language with specific parameters and demonstrate its performance on three families of LCPs. The first family consists of LCPs with $P_{*} (\kappa)$-matrices. The second family of LCPs has the $P$-matrix defined by Csizmadia. Eisenberg-Nagy and de Klerk [Math. Program., 129 (2011), pp. 383--402] showed that the handicap of this matrix should be at least $2^{2 n - 8} - \frac14$. Namely, from the known complexity results for $P_{*} (\kappa)$-LCPs it might follow that the computational performance of IPAs on LCPs with the matrix defined by Csizmadia could be very poor. Our preliminary computational study shows that an implemented variant of the theoretical version of the CP IPA (Algorithm 4.1) presented in this paper, finds a $\epsilon$-approximate solution for LCPs with the Csizmadia matrix in a very small number of iterations. The third family of problems consists of the LCPs related to the copositivity test of 88 matrices from [C. Brás, G. Eichfelder, and J. Júdice, Comput. Optim. Appl., 63 (2016), pp. 461--493]. For each of these matrices we create a special LCP and try to solve it using our IPA. If the LCP does not have a solution, then the related matrix is strictly copositive, otherwise it is on the boundary or outside the copositive cone. For these LCPs we do not know whether the underlying matrix is $P_{*} (\kappa)$ or not, but we could reveal the real copositivity status of the input matrices in 83 out of 88 cases (accuracy $\ge 94\%$). The numerical test shows that our CP IPA performs well on the sets of test problems used in the paper.},
  archive      = {J_SIOPT},
  author       = {Zsolt Darvay and Tibor Illés and Janez Povh and Petra Renáta Rigó},
  doi          = {10.1137/19M1248972},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2628-2658},
  shortjournal = {SIAM J. Optim.},
  title        = {Feasible corrector-predictor interior-point algorithm for $P_{*} (\kappa)$-linear complementarity problems based on a new search direction},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new constraint qualification and sharp optimality
conditions for nonsmooth mathematical programming problems in terms of
quasidifferentials. <em>SIOPT</em>, <em>30</em>(3), 2603–2627. (<a
href="https://doi.org/10.1137/19M1293478">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper is devoted to an analysis of a new constraint qualification and a derivation of the strongest existing optimality conditions for nonsmooth mathematical programming problems with equality and inequality constraints in terms of Demyanov--Rubinov--Polyakova quasidifferentials under the minimal possible assumptions. To this end, we obtain a novel description of convex subcones of the contingent cone to a set defined by quasidifferentiable equality and inequality constraints with the use of a new constraint qualification. We utilize this description and constraint qualification to derive the strongest existing optimality conditions for nonsmooth mathematical programming problems in terms of quasidifferentials under less restrictive assumptions than in previous studies. The main feature of the new constraint qualification and related optimality conditions is the fact that they depend on individual elements of quasidifferentials of the objective function and constraints and are not invariant with respect to the choice of quasidifferentials. To illustrate the theoretical results, we present two simple examples in which optimality conditions in terms of various subdifferentials (in fact, any outer semicontinuous/limiting subdifferential) are satisfied at a nonoptimal point, while the optimality conditions obtained in this paper do not hold true at this point; that is, optimality conditions in terms of quasidifferentials, unlike the ones in terms of subdifferentials, detect the nonoptimality of this point.},
  archive      = {J_SIOPT},
  author       = {M. V. Dolgopolik},
  doi          = {10.1137/19M1293478},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2603-2627},
  shortjournal = {SIAM J. Optim.},
  title        = {A new constraint qualification and sharp optimality conditions for nonsmooth mathematical programming problems in terms of quasidifferentials},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Rank optimality for the burer–monteiro factorization.
<em>SIOPT</em>, <em>30</em>(3), 2577–2602. (<a
href="https://doi.org/10.1137/19M1255318">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When solving large-scale semidefinite programs that admit a low-rank solution, an efficient heuristic is the Burer--Monteiro factorization: instead of optimizing over the full matrix, one optimizes over its low-rank factors. This reduces the number of variables to optimize but destroys the convexity of the problem, thus possibly introducing spurious second-order critical points. The article [N. Boumal, V. Voroninski, and A. S. Bandeira, Deterministic Guarantees for Burer-Monteiro Factorizations of Smooth Semidefinite Programs, https://arxiv.org/abs/1804.02008, 2018] shows that when the size of the factors is of the order of the square root of the number of linear constraints, this does not happen: for almost any cost matrix, second-order critical points are global solutions. In this article, we show that this result is essentially tight: for smaller values of the size, second-order critical points are not generically optimal, even when the global solution is rank 1.},
  archive      = {J_SIOPT},
  author       = {Irène Waldspurger and Alden Waters},
  doi          = {10.1137/19M1255318},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2577-2602},
  shortjournal = {SIAM J. Optim.},
  title        = {Rank optimality for the burer--monteiro factorization},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the behavior of the douglas–rachford algorithm for
minimizing a convex function subject to a linear constraint.
<em>SIOPT</em>, <em>30</em>(3), 2559–2576. (<a
href="https://doi.org/10.1137/19M1281538">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Douglas--Rachford algorithm (DRA) is a powerful optimization method for minimizing the sum of two convex (not necessarily smooth) functions. The vast majority of previous research dealt with the case when the sum has at least one minimizer. In the absence of minimizers, it was recently shown that for the case of two indicator functions, the DRA converges to a best approximation solution. In this paper, we present a new convergence result on the DRA applied to the problem of minimizing a convex function subject to a linear constraint. Indeed, a normal solution may be found even when the domain of the objective function and the linear subspace constraint have no point in common. As an important application, a new parallel splitting result is provided. We also illustrate our results through various examples.},
  archive      = {J_SIOPT},
  author       = {Heinz H. Bauschke and Walaa M. Moursi},
  doi          = {10.1137/19M1281538},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2559-2576},
  shortjournal = {SIAM J. Optim.},
  title        = {On the behavior of the douglas--rachford algorithm for minimizing a convex function subject to a linear constraint},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Two-stage stochastic programming with linearly
bi-parameterized quadratic recourse. <em>SIOPT</em>, <em>30</em>(3),
2530–2558. (<a href="https://doi.org/10.1137/19M1276819">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the class of two-stage stochastic programs with a linearly bi-parameterized recourse function defined by a convex quadratic program. A distinguishing feature of this new class of nonconvex stochastic programs is that the objective function in the second stage is linearly parameterized by the first-stage decision variable, in addition to the standard linear parameterization in the constraints. While a recent result has established that the resulting recourse function is of the difference-of-convex (dc) kind, the associated dc decomposition of the recourse function does not provide an easy way to compute a directional stationary solution of the two-stage stochastic program. Based on an implicit convex-concave property of the bi-parameterized recourse function, we introduce the concept of a generalized critical point of such a recourse function and provide a sufficient condition for such a point to be a directional stationary point of the stochastic program. We describe an iterative algorithm that combines regularization, convexification, and sampling and establish the subsequential convergence of the algorithm to a generalized critical point, with probability 1.},
  archive      = {J_SIOPT},
  author       = {Junyi Liu and Ying Cui and Jong-Shi Pang and Suvrajeet Sen},
  doi          = {10.1137/19M1276819},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2530-2558},
  shortjournal = {SIAM J. Optim.},
  title        = {Two-stage stochastic programming with linearly bi-parameterized quadratic recourse},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A trust region method for finding second-order stationarity
in linearly constrained nonconvex optimization. <em>SIOPT</em>,
<em>30</em>(3), 2501–2529. (<a
href="https://doi.org/10.1137/19M1256415">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by the TRACE algorithm [F. E. Curtis, D. P. Robinson, and M. Samadi, Math. Program., 162 (2017), pp. 1--32], we propose a trust region algorithm for finding second-order stationary points of a linearly constrained nonconvex optimization problem. We show the convergence of the proposed algorithm to ($\epsilon_g, \epsilon_H$)-second-order stationary points in $\widetilde{\mathcal{O}}(\max{\epsilon_g^{-3/2}, \epsilon_H^{-3}})$ iterations. This iteration complexity is achieved for general linearly constrained optimization without cubic regularization of the objective function.},
  archive      = {J_SIOPT},
  author       = {Maher Nouiehed and Meisam Razaviyayn},
  doi          = {10.1137/19M1256415},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2501-2529},
  shortjournal = {SIAM J. Optim.},
  title        = {A trust region method for finding second-order stationarity in linearly constrained nonconvex optimization},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Active set complexity of the away-step frank–wolfe
algorithm. <em>SIOPT</em>, <em>30</em>(3), 2470–2500. (<a
href="https://doi.org/10.1137/19M1309419">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study active set identification results for the away-step Frank--Wolfe algorithm in different settings. We first prove a local identification property that we apply, in combination with a convergence hypothesis, to get an active set identification result. We then prove, for nonconvex objectives, a novel $O(1/\sqrt{k})$ convergence rate result and active set identification for different step sizes (under suitable assumptions on the set of stationary points). By exploiting those results, we also give explicit active set complexity bounds for both strongly convex and nonconvex objectives. While we initially consider the probability simplex as feasible set, in an appendix we show how to adapt some of our results to generic polytopes.},
  archive      = {J_SIOPT},
  author       = {Immanuel M. Bomze and Francesco Rinaldi and Damiano Zeffiro},
  doi          = {10.1137/19M1309419},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2470-2500},
  shortjournal = {SIAM J. Optim.},
  title        = {Active set complexity of the away-step frank--wolfe algorithm},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the computation of kantorovich–wasserstein distances
between two-dimensional histograms by uncapacitated minimum cost flows.
<em>SIOPT</em>, <em>30</em>(3), 2441–2469. (<a
href="https://doi.org/10.1137/19M1261195">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we present a method to compute the Kantorovich--Wasserstein distance of order 1 between a pair of two-dimensional histograms. Recent works in computer vision and machine learning have shown the benefits of measuring Wasserstein distances of order 1 between histograms with $n$ bins by solving a classical transportation problem on very large complete bipartite graphs with $n$ nodes and $n^2$ edges. The main contribution of our work is to approximate the original transportation problem by an uncapacitated min cost flow problem on a reduced flow network of size $O(n)$ that exploits the geometric structure of the cost function. More precisely, when the distance among the bin centers is measured with the 1-norm or the $\infty$-norm, our approach provides an optimal solution. When the distance among bins is measured with the 2-norm, (i) we derive a quantitative estimate on the error between optimal and approximate solution; (ii) given the error, we construct a reduced flow network of size $O(n)$.},
  archive      = {J_SIOPT},
  author       = {Federico Bassetti and Stefano Gualandi and Marco Veneroni},
  doi          = {10.1137/19M1261195},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2441-2469},
  shortjournal = {SIAM J. Optim.},
  title        = {On the computation of kantorovich--wasserstein distances between two-dimensional histograms by uncapacitated minimum cost flows},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An asymptotically superlinearly convergent semismooth newton
augmented lagrangian method for linear programming. <em>SIOPT</em>,
<em>30</em>(3), 2410–2440. (<a
href="https://doi.org/10.1137/19M1251795">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Powerful interior-point methods (IPM) based commercial solvers, such as Gurobi and Mosek, have been hugely successful in solving large-scale linear programming (LP) problems. The high efficiency of these solvers depends critically on the sparsity of the problem data and advanced matrix factorization techniques. For a large scale LP problem with data matrix $A$ that is dense (possibly structured) or whose corresponding normal matrix $AA^T$ has a dense Cholesky factor (even with reordering), these solvers may require excessive computational cost and/or extremely heavy memory usage in each interior-point iteration. Unfortunately, the natural remedy, i.e., the use of iterative methods based IPM solvers, although it can avoid the explicit computation of the coefficient matrix and its factorization, is often not practically viable due to the inherent extreme ill-conditioning of the large scale normal equation arising in each interior-point iteration. While recent progress has been made to alleviate the ill-conditioning issue via sophisticated preconditioning techniques, the difficulty remains a challenging one. To provide a better alternative choice for solving large scale LPs with dense data or requiring expensive factorization of its normal equation, we propose a semismooth Newton based inexact proximal augmented Lagrangian (Snipal) method. Different from classical IPMs, in each iteration of Snipal, iterative methods can efficiently be used to solve simpler yet better conditioned semismooth Newton linear systems. Moreover, Snipal not only enjoys a fast asymptotic superlinear convergence but is also proven to enjoy a finite termination property. Numerical comparisons with Gurobi have demonstrated encouraging potential of Snipal for handling large-scale LP problems where the constraint matrix $A$ has a dense representation or $AA^T$ has a dense factorization even with an appropriate reordering. For a few large LP instances arising from correlation clustering, our algorithm can be up to 20--100 times faster than the barrier method implemented in Gurobi for solving the problems to the accuracy of $10^{-8}$ in the relative KKT residual. However, when tested on some large sparse LP problems available in the public domain, our algorithm is not yet practically competitive against the barrier method in Gurobi, especially when the latter can compute the Schur complement matrix and its sparse Cholesky factorization in each iteration cheaply.},
  archive      = {J_SIOPT},
  author       = {Xudong Li and Defeng Sun and Kim-Chuan Toh},
  doi          = {10.1137/19M1251795},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2410-2440},
  shortjournal = {SIAM J. Optim.},
  title        = {An asymptotically superlinearly convergent semismooth newton augmented lagrangian method for linear programming},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Twice epi-differentiability of extended-real-valued
functions with applications in composite optimization. <em>SIOPT</em>,
<em>30</em>(3), 2379–2409. (<a
href="https://doi.org/10.1137/19M1300066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper is devoted to the study of the twice epi-differentiablity of extended-real-valued functions, with an emphasis on functions satisfying a certain composite representation. This will be conducted under parabolic regularity, a second-order regularity condition that was recently utilized in [A. Mohammadi, B. Mordukhovich, and M. E. Sarabi, Parabolic Regularity via Geometric Variational Analysis, preprint, ŭlhttps://arxiv.org/abs/1909.00241, 2019] for second-order variational analysis of constraint systems. Besides justifying the twice epi-differentiablity of composite functions, we obtain precise formulas for their second subderivatives under the metric subregularity constraint qualification. The latter allows us to derive second-order optimality conditions for a large class of composite optimization problems.},
  archive      = {J_SIOPT},
  author       = {Ashkan Mohammadi and M. Ebrahim Sarabi},
  doi          = {10.1137/19M1300066},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2379-2409},
  shortjournal = {SIAM J. Optim.},
  title        = {Twice epi-differentiability of extended-real-valued functions with applications in composite optimization},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Facets of the stochastic network flow problem.
<em>SIOPT</em>, <em>30</em>(3), 2355–2378. (<a
href="https://doi.org/10.1137/19M1286049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a type of network flow problem that we call the minimum-cost F-graph flow problem. This problem generalizes the typical minimum-cost network flow problem by allowing the underlying network to be a directed hypergraph rather than a directed graph. This new problem is pertinent because it can be used to model network flow problems that occur in a dynamic, stochastic environment. We formulate this problem as an integer program, and we study specifically the case where every node has at least one outgoing edge with no capacity constraint. We show that even with this restriction, the problem of finding an integral solution is NP-hard. However, we can show that all of the inequality constraints of our formulation are either facet-defining or redundant.},
  archive      = {J_SIOPT},
  author       = {Alexander S. Estes and Michael O. Ball},
  doi          = {10.1137/19M1286049},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2355-2378},
  shortjournal = {SIAM J. Optim.},
  title        = {Facets of the stochastic network flow problem},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multiscale analysis of accelerated gradient methods.
<em>SIOPT</em>, <em>30</em>(3), 2337–2354. (<a
href="https://doi.org/10.1137/18M1203997">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accelerated gradient descent iterations are widely used in optimization. It is known that, in the continuous-time limit, these iterations converge to a second-order differential equation which we refer to as the accelerated gradient flow. Using geometric singular perturbation theory, we show that, under certain conditions, the accelerated gradient flow possesses an attracting invariant slow manifold to which the trajectories of the flow converge asymptotically. We obtain a general explicit expression in the form of functional series expansions that approximates the slow manifold to any arbitrary order of accuracy. To the leading order, the accelerated gradient flow reduced to this slow manifold coincides with the usual gradient descent. We illustrate the implications of our results on three examples.},
  archive      = {J_SIOPT},
  author       = {Mohammad Farazmand},
  doi          = {10.1137/18M1203997},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2337-2354},
  shortjournal = {SIAM J. Optim.},
  title        = {Multiscale analysis of accelerated gradient methods},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A privacy-preserving method to optimize distributed resource
allocation. <em>SIOPT</em>, <em>30</em>(3), 2303–2336. (<a
href="https://doi.org/10.1137/19M127879X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a resource allocation problem involving a large number of agents with individual constraints subject to privacy, and a central operator whose objective is to optimize a global, possibly nonconvex, cost while satisfying the agents&#39; constraints, for instance, an energy operator in charge of the management of energy consumption flexibilities of many individual consumers. We provide a privacy-preserving algorithm that computes the optimal allocation of resources, and in which each agent&#39;s private information (constraints and individual solution profile) is never revealed either to the central operator or to a third party. Our method relies on an aggregation procedure: we compute iteratively a global allocation of resources, and gradually ensure existence of a disaggregation, that is, individual profiles satisfying agents&#39; private constraints, by a protocol involving the generation of polyhedral cuts and secure multiparty computations. To obtain these cuts, we use an alternate projection method, which is implemented locally by each agent, preserving her privacy needs. We address especially the case in which the local and global constraints define a transportation polytope. Then, we provide theoretical convergence estimates together with numerical results, showing that the algorithm can be effectively used to solve the allocation problem in high dimension, while addressing privacy issues.},
  archive      = {J_SIOPT},
  author       = {Olivier Beaude and Pascal Benchimol and Stéphane Gaubert and Paulin Jacquot and Nadia Oudjane},
  doi          = {10.1137/19M127879X},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2303-2336},
  shortjournal = {SIAM J. Optim.},
  title        = {A privacy-preserving method to optimize distributed resource allocation},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A proximal alternating direction method of multiplier for
linearly constrained nonconvex minimization. <em>SIOPT</em>,
<em>30</em>(3), 2272–2302. (<a
href="https://doi.org/10.1137/19M1242276">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider the minimization of a nonconvex differentiable function over a bounded polyhedron. A popular primal-dual first-order method for this problem is to perform a gradient projection iteration for the augmented Lagrangian function and then update the dual multiplier vector using the constraint residual. However, numerical examples show that this approach can exhibit “oscillation” and may not converge. In this paper, we propose a proximal alternating direction method of multipliers for the multiblock version of this problem. A distinctive feature of this method is the introduction of a “smoothed” (i.e., exponentially weighted) sequence of primal iterates and the inclusion, at each iteration, to the augmented Lagrangian function of a quadratic proximal term centered at the current smoothed primal iterate. The resulting proximal augmented Lagrangian function is inexactly minimized (via a gradient projection step) at each iteration while the dual multiplier vector is updated using the residual of the linear constraints. When the primal and dual stepsizes are chosen sufficiently small, we show that suitable “smoothing” can stabilize the “oscillation,” and the iterates of the new proximal ADMM algorithm converge to a stationary point under some mild regularity conditions. The iteration complexity of our algorithm for finding an $\epsilon$-stationary solution is $\mathcal{O}(1/\epsilon^2)$, which improves the best known complexity of $\mathcal{O}(1/\epsilon^3)$ for the problem under consideration. Furthermore, when the objective function is quadratic, we establish the linear convergence of the algorithm. Our proof is based on a new potential function and a novel use of error bounds.},
  archive      = {J_SIOPT},
  author       = {Jiawei Zhang and Zhi-Quan Luo},
  doi          = {10.1137/19M1242276},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2272-2302},
  shortjournal = {SIAM J. Optim.},
  title        = {A proximal alternating direction method of multiplier for linearly constrained nonconvex minimization},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Operator splitting performance estimation: Tight contraction
factors and optimal parameter selection. <em>SIOPT</em>, <em>30</em>(3),
2251–2271. (<a href="https://doi.org/10.1137/19M1304854">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a methodology for studying the performance of common splitting methods through semidefinite programming. We prove tightness of the methodology and demonstrate its value by presenting two applications of it. First, we use the methodology as a tool for computer-assisted proofs to prove tight analytical contraction factors for Douglas--Rachford splitting that are likely too complicated for a human to find bare-handed. Second, we use the methodology as an algorithmic tool to computationally select the optimal splitting method parameters by solving a series of semidefinite programs.},
  archive      = {J_SIOPT},
  author       = {Ernest K. Ryu and Adrien B. Taylor and Carolina Bergeling and Pontus Giselsson},
  doi          = {10.1137/19M1304854},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2251-2271},
  shortjournal = {SIAM J. Optim.},
  title        = {Operator splitting performance estimation: Tight contraction factors and optimal parameter selection},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Solving chance-constrained problems via a smooth
sample-based nonlinear approximation. <em>SIOPT</em>, <em>30</em>(3),
2221–2250. (<a href="https://doi.org/10.1137/19M1261985">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a new method for solving nonlinear continuous optimization problems with chance constraints. Our method is based on a reformulation of the probabilistic constraint as a quantile function. The quantile function is approximated via a differentiable sample average approximation. We provide theoretical statistical guarantees of the approximation and illustrate empirically that the reformulation can be directly used by standard nonlinear optimization solvers in the case of single chance constraints. Furthermore, we propose an S$\ell_1$QP-type trust-region method to solve instances with joint chance constraints. We demonstrate the performance of the method on several problems and show that it scales well with the sample size and that the smoothing can be used to counteract the bias in the chance constraint approximation induced by the sample approximation.},
  archive      = {J_SIOPT},
  author       = {Alejandra Peña-Ordieres and James R. Luedtke and Andreas Wächter},
  doi          = {10.1137/19M1261985},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2221-2250},
  shortjournal = {SIAM J. Optim.},
  title        = {Solving chance-constrained problems via a smooth sample-based nonlinear approximation},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A proximal point dual newton algorithm for solving group
graphical lasso problems. <em>SIOPT</em>, <em>30</em>(3), 2197–2220. (<a
href="https://doi.org/10.1137/19M1267830">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Undirected graphical models have been especially popular for learning the conditional independence structure among a large number of variables where the observations are drawn independently and identically from the same distribution. However, many modern statistical problems would involve categorical data or time-varying data, which might follow different but related underlying distributions. In order to learn a collection of related graphical models simultaneously, various joint graphical models inducing sparsity in graphs and similarity across graphs have been proposed. In this paper, we aim to propose an implementable proximal point dual Newton algorithm (PPDNA) for solving the group graphical Lasso model, which encourages a shared pattern of sparsity across graphs. Though the group graphical Lasso regularizer is nonpolyhedral, the asymptotic superlinear convergence of our proposed method PPDNA can be obtained by leveraging on the local Lipschitz continuity of the Karush--Kuhn--Tucker solution mapping associated with the group graphical Lasso model. A variety of numerical experiments on real data sets illustrates that the PPDNA for solving the group graphical Lasso model can be highly efficient and robust.},
  archive      = {J_SIOPT},
  author       = {Yangjing Zhang and Ning Zhang and Defeng Sun and Kim-Chuan Toh},
  doi          = {10.1137/19M1267830},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2197-2220},
  shortjournal = {SIAM J. Optim.},
  title        = {A proximal point dual newton algorithm for solving group graphical lasso problems},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A nonsmooth trust-region method for locally lipschitz
functions with application to optimization problems constrained by
variational inequalities. <em>SIOPT</em>, <em>30</em>(3), 2163–2196. (<a
href="https://doi.org/10.1137/18M1164925">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a general trust-region method for the minimization of nonsmooth and nonconvex, locally Lipschitz continuous functions that can be applied, e.g., to optimization problems constrained by elliptic variational inequalities. The convergence of the considered algorithm to C-stationary points is verified in an abstract setting and under suitable assumptions on the involved model functions. For a special instance of a variational inequality constrained problem, we are able to properly characterize the Bouligand subdifferential of the reduced cost function, and, based on this characterization result, we construct a computable trust-region model which satisfies all hypotheses of our general convergence analysis. The article concludes with numerical experiments that illustrate the main properties of the proposed algorithm.},
  archive      = {J_SIOPT},
  author       = {Constantin Christof and Juan Carlos De los Reyes and Christian Meyer},
  doi          = {10.1137/18M1164925},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2163-2196},
  shortjournal = {SIAM J. Optim.},
  title        = {A nonsmooth trust-region method for locally lipschitz functions with application to optimization problems constrained by variational inequalities},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Finite convergence of proximal-gradient inertial algorithms
combining dry friction with hessian-driven damping. <em>SIOPT</em>,
<em>30</em>(3), 2134–2162. (<a
href="https://doi.org/10.1137/19M1307779">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a Hilbert space ${\mathcal H}$, we introduce a new class of proximal-gradient algorithms with finite convergence properties. These algorithms naturally occur as discrete temporal versions of an inertial differential inclusion which is stabilized under the joint action of three dampings: dry friction, viscous friction, and a geometric damping driven by the Hessian. The function $f:{\mathcal H} \to {\mathbb R}$ to be minimized is supposed to be differentiable (not necessarily convex) and enters the algorithm via its gradient. The dry friction damping function $\phi:{\mathcal H} \to {\mathbb R}_+$ is convex with a sharp minimum at the origin (typically $\phi(x) = r \|x\|$ with $r&gt;0$). It enters the algorithm via its proximal mapping, which acts as a soft threshold operator on the velocities. It is the source of stabilization in a finite number of steps. The geometric damping driven by the Hessian intervenes in the dynamics in the form $\nabla^2 f (x(t)) \dot{x} (t)$. By treating this term as the time derivative of $ \nabla f (x (t)) $, this gives, in discretized form, first-order algorithms. The Hessian-driven damping allows one to control and to attenuate the oscillations. The convergence results tolerate the presence of errors, under the sole assumption of their asymptotic convergence to zero. Replacing the potential function $f$ by its Moreau envelope, we extend the results to the case of a nonsmooth convex function $f$. In this case, the algorithm involves the proximal operators of $f$ and $\phi$ separately. Several variants of this algorithm are considered, including the case of the Nesterov accelerated gradient method. We then consider the extension to the case of additive composite optimization, thus leading to splitting methods. Numerical experiments are given for lasso-type problems. The performance profiles, as a comparison tool, highlight the effectiveness of a variant of the Nesterov accelerated method with dry friction and Hessian-driven damping.},
  archive      = {J_SIOPT},
  author       = {Samir Adly and Hedy Attouch},
  doi          = {10.1137/19M1307779},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2134-2162},
  shortjournal = {SIAM J. Optim.},
  title        = {Finite convergence of proximal-gradient inertial algorithms combining dry friction with hessian-driven damping},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sample complexity of sample average approximation for
conditional stochastic optimization. <em>SIOPT</em>, <em>30</em>(3),
2103–2133. (<a href="https://doi.org/10.1137/19M1284865">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study a class of stochastic optimization problems, referred to as the conditional stochastic optimization (CSO), in the form of $\min_{x \in \mathcal{X}} \mathbb{E}_{\xi}f_\xi({\mathbb{E}_{\eta|\xi}[g_\eta(x, \xi)]})$, which finds a wide spectrum of applications including portfolio selection, reinforcement learning, robust learning, and causal inference. Assuming availability of samples from the distribution $\mathbb{P}(\xi)$ and samples from the conditional distribution $\mathbb{P}(\eta|\xi)$, we establish the sample complexity of the sample average approximation (SAA) for CSO, under a variety of structural assumptions, such as Lipschitz continuity, smoothness, and error bound conditions. We show that the total sample complexity improves from $\mathcal{O}(d/\epsilon^4)$ to $\mathcal{O}(d/\epsilon^3)$ when assuming smoothness of the outer function, and further to $\mathcal{O}(1/\epsilon^2)$ when the empirical function satisfies the quadratic growth condition. We also establish the sample complexity of a modified SAA when $\xi$ and $\eta$ are independent. Several numerical experiments further support our theoretical findings.},
  archive      = {J_SIOPT},
  author       = {Yifan Hu and Xin Chen and Niao He},
  doi          = {10.1137/19M1284865},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2103-2133},
  shortjournal = {SIAM J. Optim.},
  title        = {Sample complexity of sample average approximation for conditional stochastic optimization},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Periodical multistage stochastic programs. <em>SIOPT</em>,
<em>30</em>(3), 2083–2102. (<a
href="https://doi.org/10.1137/19M129406X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In some applications the considered multistage stochastic programs have a periodical behavior. We show that in such cases it is possible to drastically reduce the number of stages by introducing a periodical analogue of the so-called Bellman equations for discounted infinite horizon problems used in Markov decision processes and stochastic optimal control. Furthermore, we describe a variant of the stochastic dual dynamic programming algorithm, applied to the constructed periodical Bellman equations, and provide numerical experiments for the Brazilian interconnected power system problem.},
  archive      = {J_SIOPT},
  author       = {Alexander Shapiro and Lingquan Ding},
  doi          = {10.1137/19M129406X},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2083-2102},
  shortjournal = {SIAM J. Optim.},
  title        = {Periodical multistage stochastic programs},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Worst-case convergence analysis of inexact gradient and
newton methods through semidefinite programming performance estimation.
<em>SIOPT</em>, <em>30</em>(3), 2053–2082. (<a
href="https://doi.org/10.1137/19M1281368">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide new tools for worst-case performance analysis of the gradient (or steepest descent) method of Cauchy for smooth strongly convex functions, and Newton&#39;s method for self-concordant functions, including the case of inexact search directions. The analysis uses semidefinite programming performance estimation, as pioneered by Drori and Teboulle [it Math. Program., 145 (2014), pp. 451--482], and extends recent performance estimation results for the method of Cauchy by the authors [it Optim. Lett., 11 (2017), pp. 1185--1199]. To illustrate the applicability of the tools, we demonstrate a novel complexity analysis of short step interior point methods using inexact search directions. As an example in this framework, we sketch how to give a rigorous worst-case complexity analysis of a recent interior point method by Abernethy and Hazan [it PMLR, 48 (2016), pp. 2520--2528].},
  archive      = {J_SIOPT},
  author       = {Etienne De Klerk and François Glineur and Adrien B. Taylor},
  doi          = {10.1137/19M1281368},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2053-2082},
  shortjournal = {SIAM J. Optim.},
  title        = {Worst-case convergence analysis of inexact gradient and newton methods through semidefinite programming performance estimation},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On feasibility of sample average approximation solutions.
<em>SIOPT</em>, <em>30</em>(3), 2026–2052. (<a
href="https://doi.org/10.1137/19M1253447">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When there are infinitely many scenarios, the current studies of two-stage stochastic programming problems rely on the relatively complete recourse assumption. However, such an assumption can be unrealistic for many real-world problems. This motivates us to study general stochastic programming problems where the sample average approximation (SAA) solutions are not necessarily feasible. When the problems are convex and the true solutions lie in the interior of feasible solutions, we show that the portion of infeasible SAA solutions decays exponentially as the sample size increases. We also study functions with chain-constrained domain and show that the portion of SAA solutions having a low degree of feasibility decays exponentially as the sample size increases. This result is then extended to multistage stochastic programming.},
  archive      = {J_SIOPT},
  author       = {Rui Peng Liu},
  doi          = {10.1137/19M1253447},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2026-2052},
  shortjournal = {SIAM J. Optim.},
  title        = {On feasibility of sample average approximation solutions},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An approximation scheme for distributionally robust
nonlinear optimization. <em>SIOPT</em>, <em>30</em>(3), 1996–2025. (<a
href="https://doi.org/10.1137/19M1263121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider distributionally robust optimization problems (DROPs) with nonlinear and nonconcave dependence on uncertain parameters. The DROP can be written as a nonsmooth, nonlinear program with a bilevel structure; the objective function and each of the constraint functions are suprema of expected values of parametric functions taken over an ambiguity set of probability distributions. We define ambiguity sets through moment constraints, and to make the computation of first order stationary points tractable, we approximate nonlinear functions using quadratic expansions w.r.t. parameters, resulting in lower-level problems defined by trust-region problems and semidefinite programs. Subsequently, we construct smoothing functions for the approximate lower level functions which are computationally tractable, employing strong duality for trust-region problems, and show that gradient consistency holds. We formulate smoothed DROPs and apply a homotopy method that dynamically decreases smoothing parameters and establish its convergence to stationary points of the approximate DROP under mild assumptions. Through our scheme, we provide a new approach to robust nonlinear optimization as well. We perform numerical experiments and comparisons to other methods on a well-known test set, assuming design variables are subject to implementation errors, which provides a representative set of numerical examples.},
  archive      = {J_SIOPT},
  author       = {Johannes Milz and Michael Ulbrich},
  doi          = {10.1137/19M1263121},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1996-2025},
  shortjournal = {SIAM J. Optim.},
  title        = {An approximation scheme for distributionally robust nonlinear optimization},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Closing the gap between necessary and sufficient conditions
for local nonglobal minimizer of trust region subproblem.
<em>SIOPT</em>, <em>30</em>(3), 1980–1995. (<a
href="https://doi.org/10.1137/19M1294459">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The trust region subproblem has at most one local nonglobal minimizer. In characterizing this local solution, there is a clear gap between necessary and sufficient conditions. In this paper, we surprisingly show that the sufficient second-order optimality condition remains necessary. As an application, we improve the state-of-the-art algorithm for computing a candidate of the local nonglobal minimizer and then show that finding the local nonglobal minimizer or proving the nonexistence can be done in polynomial time.},
  archive      = {J_SIOPT},
  author       = {Jiulin Wang and Yong Xia},
  doi          = {10.1137/19M1294459},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1980-1995},
  shortjournal = {SIAM J. Optim.},
  title        = {Closing the gap between necessary and sufficient conditions for local nonglobal minimizer of trust region subproblem},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A class of approximate inverse preconditioners based on
krylov-subspace methods for large-scale nonconvex optimization.
<em>SIOPT</em>, <em>30</em>(3), 1954–1979. (<a
href="https://doi.org/10.1137/19M1256907">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a class of positive definite preconditioners for the solution of large symmetric indefinite linear systems or sequences of such systems, in optimization frameworks. The preconditioners are iteratively constructed by collecting information on a reduced eigenspace of the indefinite matrix by means of a Krylov-subspace solver. A spectral analysis of the preconditioned matrix shows the clustering of some eigenvalues and possibly the nonexpansion of its spectrum. Extensive numerical experimentation is carried out on standard difficult linear systems and by embedding the class of preconditioners within truncated Newton methods for large-scale unconstrained optimization (the issue of major interest). Although the Krylov-based method may provide modest information on matrix eigenspaces, the results obtained show that the proposed preconditioners lead to substantial improvements in terms of efficiency and robustness, particularly on very large nonconvex problems.},
  archive      = {J_SIOPT},
  author       = {Mehiddin Al-Baali and Andrea Caliciotti and Giovanni Fasano and Massimo Roma},
  doi          = {10.1137/19M1256907},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1954-1979},
  shortjournal = {SIAM J. Optim.},
  title        = {A class of approximate inverse preconditioners based on krylov-subspace methods for large-scale nonconvex optimization},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient techniques for shape optimization with variational
inequalities using adjoints. <em>SIOPT</em>, <em>30</em>(3), 1922–1953.
(<a href="https://doi.org/10.1137/19M1257226">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In general, standard necessary optimality conditions cannot be formulated in a straightforward manner for semismooth shape optimization problems. In this paper, we consider shape optimization problems constrained by variational inequalities of the first kind, so-called obstacle-type problems. Under appropriate assumptions, we prove existence of adjoints for regularized problems and convergence to adjoints of the unregularized problem. Moreover, we derive shape derivatives for the regularized problem and prove convergence to a limit object. Based on this analysis, an efficient optimization algorithm is devised and tested numerically.},
  archive      = {J_SIOPT},
  author       = {Daniel Luft and Volker H. Schulz and Kathrin Welker},
  doi          = {10.1137/19M1257226},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1922-1953},
  shortjournal = {SIAM J. Optim.},
  title        = {Efficient techniques for shape optimization with variational inequalities using adjoints},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Tight sublinear convergence rate of the proximal point
algorithm for maximal monotone inclusion problems. <em>SIOPT</em>,
<em>30</em>(3), 1905–1921. (<a
href="https://doi.org/10.1137/19M1299049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The tight sublinear convergence rate of the proximal point algorithm for maximal monotone inclusion problems is established based on the squared fixed point residual. By using the performance estimation framework, the tight sublinear convergence rate problem is written as an infinite dimensional nonconvex optimization problem, which is then equivalently reformulated as a finite dimensional semidefinite programming (SDP) problem. By solving the SDP, the exact sublinear rate is computed numerically. Theoretically, by constructing a feasible solution to the dual SDP, an upper bound is obtained for the tight sublinear rate. On the other hand, an example in two dimensional space is constructed to provide a lower bound. The lower bound matches exactly the upper bound obtained from the dual SDP, which also coincides with the numerical rate computed. Hence, we have established the worst case sublinear convergence rate, which is tight in terms of both the order and the constants involved.},
  archive      = {J_SIOPT},
  author       = {Guoyong Gu and Junfeng Yang},
  doi          = {10.1137/19M1299049},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1905-1921},
  shortjournal = {SIAM J. Optim.},
  title        = {Tight sublinear convergence rate of the proximal point algorithm for maximal monotone inclusion problems},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A randomized coordinate descent method with volume sampling.
<em>SIOPT</em>, <em>30</em>(3), 1878–1904. (<a
href="https://doi.org/10.1137/19M125532X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze the coordinate descent method with a new coordinate selection strategy, called volume sampling. This strategy prescribes selecting subsets of variables of certain size proportionally to the determinants of principal submatrices of the matrix, which bounds the curvature of the objective function. In the particular case when the size of the subsets equals one, volume sampling coincides with the well-known strategy of sampling coordinates proportionally to their Lipschitz constants. For the coordinate descent with volume sampling, we establish the convergence rates for both convex and strongly convex problems. Our theoretical results show that, by increasing the size of the subsets, it is possible to accelerate the method up to the factor which depends on the spectral gap between the corresponding largest eigenvalues of the curvature matrix. Several numerical experiments confirm our theoretical conclusions.},
  archive      = {J_SIOPT},
  author       = {Anton Rodomanov and Dmitry Kropotov},
  doi          = {10.1137/19M125532X},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1878-1904},
  shortjournal = {SIAM J. Optim.},
  title        = {A randomized coordinate descent method with volume sampling},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Convergence rates of damped inertial dynamics under
geometric conditions and perturbations. <em>SIOPT</em>, <em>30</em>(3),
1850–1877. (<a href="https://doi.org/10.1137/19M1272767">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article a family of second-order ODEs associated with the inertial gradient descent is studied. These ODEs are widely used to build trajectories converging to a minimizer $x^*$ of a function $F$, possibly convex. This family includes the continuous version of the Nesterov inertial scheme and the continuous heavy ball method. Several damping parameters, not necessarily vanishing, and a perturbation term $g$ are thus considered. The damping parameter is linked to the inertia of the associated inertial scheme and the perturbation term $g$ is linked to the error that can be made on the gradient of the function $F$. This article presents new asymptotic bounds on $F(x(t))-F(x^*)$, where $x$ is a solution of the ODE, when $F$ is convex and satisfies local geometrical properties such as Łojasiewicz properties and under integrability conditions on $g$. Even if geometrical properties and perturbations were already studied for most ODEs of these families, it is the first time they are jointly studied. All these results give an insight on the behavior of these inertial and perturbed algorithms if $F$ satisfies some Łojasiewicz properties especially in the setting of stochastic algorithms.},
  archive      = {J_SIOPT},
  author       = {O. Sebbouh and Ch. Dossal and A. Rondepierre},
  doi          = {10.1137/19M1272767},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1850-1877},
  shortjournal = {SIAM J. Optim.},
  title        = {Convergence rates of damped inertial dynamics under geometric conditions and perturbations},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Inexact sequential quadratic optimization with penalty
parameter updates within the QP solver. <em>SIOPT</em>, <em>30</em>(3),
1822–1849. (<a href="https://doi.org/10.1137/18M1176488">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the design of sequential quadratic optimization (commonly known as SQP) methods for solving large-scale nonlinear optimization problems. The most computationally demanding aspect of such an approach is the computation of the search direction during each iteration, for which we consider the use of matrix-free methods. In particular, we develop a method that requires an inexact solve of a single QP subproblem to establish the convergence of the overall SQP method. It is known that SQP methods can be plagued by poor behavior of the global convergence mechanism. To confront this issue, we propose the use of an exact penalty function with a dynamic penalty parameter updating strategy to be employed within the subproblem solver in such a way that the resulting search direction predicts progress toward both feasibility and optimality. We present our parameter updating strategy and prove that, under reasonable assumptions, the strategy does not modify the penalty parameter unnecessarily. We close the paper with a discussion of the results of numerical experiments that illustrate the benefits of our proposed techniques.},
  archive      = {J_SIOPT},
  author       = {James V. Burke and Frank E. Curtis and Hao Wang and Jiashan Wang},
  doi          = {10.1137/18M1176488},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1822-1849},
  shortjournal = {SIAM J. Optim.},
  title        = {Inexact sequential quadratic optimization with penalty parameter updates within the QP solver},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Revisiting EXTRA for smooth distributed optimization.
<em>SIOPT</em>, <em>30</em>(3), 1795–1821. (<a
href="https://doi.org/10.1137/18M122902X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {EXTRA is a popular method for dencentralized distributed optimization and has broad applications. This paper revisits EXTRA. First, we give a sharp complexity analysis for EXTRA with the improved $O\big(\big(\frac{L}{\mu}+\frac{1}{1-\sigma_2({W})}\big)\log\frac{1}{\epsilon(1-\sigma_2({W}))}\big)$ communication and computation complexities for $\mu$-strongly convex and $L$-smooth problems, where $\sigma_2({W})$ is the second largest singular value of the weight matrix ${W}$. When the strong convexity is absent, we prove the $O\big(\big(\frac{L}{\epsilon}+\frac{1}{1-\sigma_2({W})}\big)\log\frac{1}{1-\sigma_2({W})}\big)$ complexities. Then, we use the Catalyst framework to accelerate EXTRA and obtain the $O\big(\sqrt{\frac{L}{\mu(1-\sigma_2({W}))}}\log\frac{ L}{\mu(1-\sigma_2({W}))}\log\frac{1}{\epsilon}\big)$ communication and computation complexities for strongly convex and smooth problems and the $O\big(\sqrt{\frac{L}{\epsilon(1-\sigma_2({W}))}}\log\frac{1}{\epsilon(1-\sigma_2(\mathbf{W}))}\big)$ complexities for nonstrongly convex ones. Our communication complexities of the accelerated EXTRA are only worse by the factors of $\big(\log\frac{L}{\mu(1-\sigma_2(\mathbf{W}))}\big)$ and $\big(\log\frac{1}{\epsilon(1-\sigma_2({W}))}\big)$ from the lower complexity bounds for strongly convex and nonstrongly convex problems, respectively.},
  archive      = {J_SIOPT},
  author       = {Huan Li and Zhouchen Lin},
  doi          = {10.1137/18M122902X},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1795-1821},
  shortjournal = {SIAM J. Optim.},
  title        = {Revisiting EXTRA for smooth distributed optimization},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Local minimizers of semi-algebraic functions from the
viewpoint of tangencies. <em>SIOPT</em>, <em>30</em>(3), 1777–1794. (<a
href="https://doi.org/10.1137/19M1237466">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider a semialgebraic function $f\colon\mathbb{R}^n \to {\mathbb{R}},$ which is continuous around a point $\bar{x} \in \mathbb{R}^n.$ Using the so-called tangency variety of $f$ at $\bar{x},$ we first provide necessary and sufficient conditions for $\bar{x}$ to be a local minimizer of $f,$ and then in the case where $\bar{x}$ is an isolated local minimizer of $f,$ we define a “tangency exponent” $\alpha_* &gt; 0$ so that for any $\alpha \in \mathbb{R}$ the following four conditions are always equivalent: (i) the inequality $\alpha \ge \alpha_*$ holds, (ii) the point $\bar{x}$ is an $\alpha$th order sharp local minimizer of $f$, (iii) the limiting subdifferential $\partial f$ of $f$ is $(\alpha - 1)$th order strongly metrically subregular at $\bar{x}$ for 0, and (iv) the function $f$ satisfies the Łojaseiwcz gradient inequality at $\bar{x}$ with the exponent $1 - \frac{1}{\alpha}.$ Besides, we also present a counterexample to a conjecture posed by Drusvyatskiy and Ioffe [Math. Program. Ser. A, 153 (2015), pp. 635--653].},
  archive      = {J_SIOPT},
  author       = {Tien-Son Pham},
  doi          = {10.1137/19M1237466},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1777-1794},
  shortjournal = {SIAM J. Optim.},
  title        = {Local minimizers of semi-algebraic functions from the viewpoint of tangencies},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Several classes of stationary points for rank regularized
minimization problems. <em>SIOPT</em>, <em>30</em>(2), 1756–1775. (<a
href="https://doi.org/10.1137/19M1270987">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the rank regularized minimization problem, we introduce several classes of stationary points by the problem itself and its equivalent reformulations including the mathematical program with an equilibrium constraint (MPEC), the global exact penalty of the MPEC, and the difference-of-convex surrogate yielded by eliminating the dual part of the global exact penalty. A clear relation chart is established among these stationary points, which offers guidance to choose an appropriate reformulation for seeking a low-rank solution to this class of problems.},
  archive      = {J_SIOPT},
  author       = {Yulan Liu and Shujun Bi and Shaohua Pan},
  doi          = {10.1137/19M1270987},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1756-1775},
  shortjournal = {SIAM J. Optim.},
  title        = {Several classes of stationary points for rank regularized minimization problems},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Subgradients of marginal functions in parametric control
problems of partial differential equations. <em>SIOPT</em>,
<em>30</em>(2), 1724–1755. (<a
href="https://doi.org/10.1137/18M1200956">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies generalized differentiability properties of the marginal function of parametric optimal control problems governed by semilinear elliptic partial differential equations. We establish some upper estimates for the regular and the limiting subgradients of the marginal function for Hilbert parametric spaces. In addition, we provide sufficient conditions for these upper estimates to be equalities. For the circumstance of parametric bang-bang optimal control problems, under some additional assumptions we show that the solution map of the perturbed optimal control problems has local upper Hölderian selections for both cases of Asplund parametric spaces and non-Asplund parametric spaces. This leads to explicit exact formulas for computing the regular and the limiting subdifferentials of the marginal function for the Asplund parametric spaces as well as lower estimates for the regular and the limiting subdifferentials of the marginal function with respect to the non-Asplund parametric spaces.},
  archive      = {J_SIOPT},
  author       = {Nguyen Thanh Qui and Daniel Wachsmuth},
  doi          = {10.1137/18M1200956},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1724-1755},
  shortjournal = {SIAM J. Optim.},
  title        = {Subgradients of marginal functions in parametric control problems of partial differential equations},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). MultiComposite nonconvex optimization for training deep
neural networks. <em>SIOPT</em>, <em>30</em>(2), 1693–1723. (<a
href="https://doi.org/10.1137/18M1231559">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present in this paper a novel deterministic algorithmic framework that enables the computation of a directional stationary solution of the empirical deep neural network training problem formulated as a multicomposite optimization problem with coupled nonconvexity and nondifferentiability. This is the first time to our knowledge that such a sharp kind of stationary solution is provably computable for a nonsmooth deep neural network. Allowing for arbitrary finite numbers of input samples and training layers, an arbitrary number of neurons within each layer, and arbitrary piecewise activation functions, the proposed approach combines the methods of exact penalization, majorization-minimization, gradient projection with enhancements, and the dual semismooth Newton method, each for a particular purpose in an overall computational scheme. While a routine implementation of the semismooth Newton method would be computationally expensive, we show that careful linear algebraic implementation helps to greatly reduce the computational and storage costs for problems of arbitrary dimensions. Contrary to existing stochastic approaches which provide at best very weak guarantees on the computed solutions obtained in practical implementation, our rigorous deterministic treatment provides guarantee of the stationarity properties of the computed solutions with reference to the optimization problems being solved. Numerical results from a MATLAB implementation demonstrate the effectiveness of the framework for solving reasonably sized networks with a modest number of training samples (in the low thousands).},
  archive      = {J_SIOPT},
  author       = {Ying Cui and Ziyu He and Jong-Shi Pang},
  doi          = {10.1137/18M1231559},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1693-1723},
  shortjournal = {SIAM J. Optim.},
  title        = {MultiComposite nonconvex optimization for training deep neural networks},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Primal-dual stochastic gradient method for convex programs
with many functional constraints. <em>SIOPT</em>, <em>30</em>(2),
1664–1692. (<a href="https://doi.org/10.1137/18M1229869">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stochastic gradient method (SGM) has been popularly applied to solve optimization problems with an objective that is stochastic or an average of many functions. Most existing works on SGMs assume that the underlying problem is unconstrained or has an easy-to-project constraint set. In this paper, we consider problems that have a stochastic objective and also many functional constraints. For such problems, it could be extremely expensive to project a point to the feasible set, or even compute subgradient and/or function value of all constraint functions. To find solutions to these problems, we propose a novel (adaptive) SGM based on the classical augmented Lagrangian function. Within every iteration, it inquires a stochastic subgradient of the objective, and a subgradient and the function value of one randomly sampled constraint function. Hence, the per-iteration complexity is low. We establish its convergence rate for convex problems and also problems with strongly convex objective. It can achieve the optimal $O(1/\sqrt{k})$ convergence rate for the convex case and nearly optimal $O\big((\log k)/k\big)$ rate for the strongly convex case. Numerical experiments on a sample approximation problem of the robust portfolio selection and quadratically constrained quadratic programming are conducted to demonstrate its efficiency.},
  archive      = {J_SIOPT},
  author       = {Yangyang Xu},
  doi          = {10.1137/18M1229869},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1664-1692},
  shortjournal = {SIAM J. Optim.},
  title        = {Primal-dual stochastic gradient method for convex programs with many functional constraints},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An inverse-adjusted best response algorithm for nash
equilibria. <em>SIOPT</em>, <em>30</em>(2), 1638–1663. (<a
href="https://doi.org/10.1137/18M1213701">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regarding the approximation of Nash equilibria in games where the players have a continuum of strategies, there exist various algorithms based on best response dynamics and on its relaxed variants: from one step to the next, a player&#39;s strategy is updated by using explicitly a best response to the strategies of the other players that come from the previous steps. These iterative schemes generate sequences of strategy profiles which are constructed by using continuous optimization techniques and they have been shown to converge in the following situations: in zero-sum games or, in non-zero-sum ones, under contraction assumptions or under linearity of best response functions. In this paper, we propose an algorithm which guarantees the convergence to a Nash equilibrium in two-player non-zero-sum games when the best response functions, called $r_1$ and $r_2$, are not necessarily linear, neither the composition $r_1\circ r_2$ nor $r_2\circ r_1$ is a contraction, and the strategy sets are Hilbert spaces. First, we address the issue of uniqueness of the Nash equilibrium extending to a more general class the result obtained by Caruso, Ceparano, and Morgan [J. Math. Anal. Appl., 459 (2018), pp. 1208--1221] for weighted potential games. Then, we describe a theoretical approximation scheme based on a nonstandard (nonconvex) relaxation of best response iterations which converges to the unique Nash equilibrium of the game. Finally, we define a numerical approximation scheme relying on a derivative-free continuous optimization technique applied in a finite dimensional setting and we provide convergence results and error bounds.},
  archive      = {J_SIOPT},
  author       = {Francesco Caruso and Maria Carmela Ceparano and Jacqueline Morgan},
  doi          = {10.1137/18M1213701},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1638-1663},
  shortjournal = {SIAM J. Optim.},
  title        = {An inverse-adjusted best response algorithm for nash equilibria},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new sequential optimality condition for constrained
nonsmooth optimization. <em>SIOPT</em>, <em>30</em>(2), 1610–1637. (<a
href="https://doi.org/10.1137/18M1228608">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a sequential optimality condition for locally Lipschitz constrained nonsmooth optimization, verifiable just using derivative information, and which holds even in the absence of any constraint qualification. We present a practical algorithm that generates iterates either fulfilling the new necessary optimality condition or converging to stationary points of the infeasibility measure. A main feature of the devised algorithm is to allow a stronger control over the infeasibility of the iterates than usually obtained by exact penalty strategies, ensuring theoretical and practical advantages. Illustrative numerical experiments highlight the potentialities of the algorithm.},
  archive      = {J_SIOPT},
  author       = {Elias S. Helou and Sandra A. Santos and Lucas E. A. Simo͂es},
  doi          = {10.1137/18M1228608},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1610-1637},
  shortjournal = {SIAM J. Optim.},
  title        = {A new sequential optimality condition for constrained nonsmooth optimization},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Strong convex nonlinear relaxations of the pooling problem.
<em>SIOPT</em>, <em>30</em>(2), 1582–1609. (<a
href="https://doi.org/10.1137/18M1174374">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate new convex relaxations for the pooling problem, a classic nonconvex production planning problem in which input materials are mixed in intermediate pools, with the outputs of these pools further mixed to make output products meeting given attribute percentage requirements. Our relaxations are derived by considering a set which arises from the formulation by considering a single product, a single attibute, and a single pool. The convex hull of the resulting nonconvex set is not polyhedral. We derive valid linear and convex nonlinear inequalities for the convex hull and demonstrate that different subsets of these inequalities define the convex hull of the nonconvex set in three cases determined by the parameters of the set. In a preliminary computational study we find that the inequalities can significantly strengthen the convex relaxation of the well-known $pq$-formulation of the pooling problem on one class of test instances, but have limited effect on another class.},
  archive      = {J_SIOPT},
  author       = {James Luedtke and Claudia D&#39;Ambrosio and Jeff Linderoth and Jonas Schweiger},
  doi          = {10.1137/18M1174374},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1582-1609},
  shortjournal = {SIAM J. Optim.},
  title        = {Strong convex nonlinear relaxations of the pooling problem},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adjusting dual iterates in the presence of critical lagrange
multipliers. <em>SIOPT</em>, <em>30</em>(2), 1555–1581. (<a
href="https://doi.org/10.1137/19M1255380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is a well-known phenomenon that the presence of critical Lagrange multipliers in constrained optimization problems may cause a deterioration of the convergence speed of primal-dual Newton-type methods. Regardless of the method under consideration, we develop a new local technique for avoiding convergence to critical Lagrange multipliers of equality-constrained optimization problems. This technique consists of replacing dual iterates of the methods by a special function of primal iterates. Under some natural assumptions, this function yields an approximation of a Lagrange multiplier, whose quality agrees with the distance from the primal iterate to the respective stationary point, while at the same time staying away from the critical multiplier in question. The accelerating effect of this technique is demonstrated by numerical experiments for stabilized sequential quadratic programming, the Levenberg--Marquardt method, and the LP-Newton method.},
  archive      = {J_SIOPT},
  author       = {Andreas Fischer and Alexey F. Izmailov and Wladimir Scheck},
  doi          = {10.1137/19M1255380},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1555-1581},
  shortjournal = {SIAM J. Optim.},
  title        = {Adjusting dual iterates in the presence of critical lagrange multipliers},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Exponential decay in the sensitivity analysis of nonlinear
dynamic programming. <em>SIOPT</em>, <em>30</em>(2), 1527–1554. (<a
href="https://doi.org/10.1137/19M1265065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the sensitivity of discrete-time dynamic programs with nonlinear dynamics and objective to perturbations in the initial conditions and reference parameters. Under uniform controllability and boundedness assumptions for the problem data, we prove that the directional derivative of the optimal state and control at time $k$, $x^*_k$, and $u^*_k$, with respect to the reference signal at time $i$, $d_i$, will have exponential decay in terms of $|k-i|$ with a decay rate $\rho$ independent of the temporal horizon length. The key technical step is to prove that a version of the convexification approach proposed by Verschueren et al. can be applied to the KKT conditions and results in a convex quadratic program with uniformly bounded data. In turn, Riccati techniques can be further employed to obtain the sensitivity result, borne from the observation that the directional derivatives are solutions of quadratic programs with structure similar to the KKT conditions themselves. We validate our findings with numerical experiments on a small nonlinear, nonconvex, dynamic program.},
  archive      = {J_SIOPT},
  author       = {Sen Na and Mihai Anitescu},
  doi          = {10.1137/19M1265065},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1527-1554},
  shortjournal = {SIAM J. Optim.},
  title        = {Exponential decay in the sensitivity analysis of nonlinear dynamic programming},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust optimality and duality in multiobjective optimization
problems under data uncertainty. <em>SIOPT</em>, <em>30</em>(2),
1501–1526. (<a href="https://doi.org/10.1137/19M1251461">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we employ advanced techniques of variational analysis and generalized differentiation to examine robust optimality conditions and robust duality for an uncertain nonsmooth multiobjective optimization problem under arbitrary uncertainty nonempty sets. We establish necessary and sufficient optimality conditions for (local) robust (weakly) efficient solutions of the considered problem. Our problem involves nonsmooth real-valued functions and data uncertainty in both the objective and constraint functions, and its necessary and sufficient optimality conditions are exhibited in terms of multipliers and the Mordukhovich or Clarke subdifferentials of the related functions. Moreover, we formulate a dual multiobjective problem to the underlying program and examine robust weak, strong, and converse duality relations between the primal problem and its dual under assumptions of (strictly) generalized convexity.},
  archive      = {J_SIOPT},
  author       = {Thai Doan Chuong},
  doi          = {10.1137/19M1251461},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1501-1526},
  shortjournal = {SIAM J. Optim.},
  title        = {Robust optimality and duality in multiobjective optimization problems under data uncertainty},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the adaptivity of stochastic gradient-based optimization.
<em>SIOPT</em>, <em>30</em>(2), 1473–1500. (<a
href="https://doi.org/10.1137/19M1256919">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic gradient-based optimization has been a core enabling methodology in applications to large-scale problems in machine learning and related areas. Despite this progress, the gap between theory and practice remains significant, with theoreticians pursuing mathematical optimality at the cost of obtaining specialized procedures in different regimes (e.g., modulus of strong convexity, magnitude of target accuracy, signal-to-noise ratio), and with practitioners not readily able to know which regime is appropriate to their problem, and seeking broadly applicable algorithms that are reasonably close to optimality. To bridge these perspectives it is necessary to study algorithms that are adaptive to different regimes. We present the stochastically controlled stochastic gradient (SCSG) method for composite convex finite-sum optimization problems and show that it is adaptive to both strong convexity and target accuracy. The adaptivity is achieved by batch variance reduction with adaptive batch sizes and a novel technique, which we refer to as geometrization, and which sets the length of each epoch as a geometric random variable. The algorithm achieves strictly better theoretical complexity than other existing adaptive algorithms, while the tuning parameters of the algorithm depend only on the smoothness parameter of the objective.},
  archive      = {J_SIOPT},
  author       = {Lihua Lei and Michael I. Jordan},
  doi          = {10.1137/19M1256919},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1473-1500},
  shortjournal = {SIAM J. Optim.},
  title        = {On the adaptivity of stochastic gradient-based optimization},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A forward-backward splitting method for monotone inclusions
without cocoercivity. <em>SIOPT</em>, <em>30</em>(2), 1451–1472. (<a
href="https://doi.org/10.1137/18M1207260">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we propose a simple modification of the forward-backward splitting method for finding a zero in the sum of two monotone operators. Our method converges under the same assumptions as Tseng&#39;s forward-backward-forward method, namely, it does not require cocoercivity of the single-valued operator. Moreover, each iteration only uses one forward evaluation rather than two as is the case for Tseng&#39;s method. Variants of the method incorporating a linesearch, relaxation and inertia, or a structured three operator inclusion are also discussed.},
  archive      = {J_SIOPT},
  author       = {Yura Malitsky and Matthew K. Tam},
  doi          = {10.1137/18M1207260},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1451-1472},
  shortjournal = {SIAM J. Optim.},
  title        = {A forward-backward splitting method for monotone inclusions without cocoercivity},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the convergence of stochastic gradient descent for
nonlinear ill-posed problems. <em>SIOPT</em>, <em>30</em>(2), 1421–1450.
(<a href="https://doi.org/10.1137/19M1271798">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we analyze the regularizing property of the stochastic gradient descent for the numerical solution of a class of nonlinear ill-posed inverse problems in Hilbert spaces. At each step of the iteration, the method randomly chooses one equation from the nonlinear system to obtain an unbiased stochastic estimate of the gradient and then performs a descent step with the estimated gradient. It is a randomized version of the classical Landweber method for nonlinear inverse problems, and it is highly scalable to the problem size and holds significant potential for solving large-scale inverse problems. Under the canonical tangential cone condition, we prove the regularizing property for a priori stopping rules and then establish the convergence rates under a suitable sourcewise condition and a range invariance condition.},
  archive      = {J_SIOPT},
  author       = {Bangti Jin and Zehui Zhou and Jun Zou},
  doi          = {10.1137/19M1271798},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1421-1450},
  shortjournal = {SIAM J. Optim.},
  title        = {On the convergence of stochastic gradient descent for nonlinear ill-posed problems},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Inertial, corrected, primal-dual proximal splitting.
<em>SIOPT</em>, <em>30</em>(2), 1391–1420. (<a
href="https://doi.org/10.1137/18M1182851">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study inertial versions of primal-dual proximal splitting, also known as the Chambolle--Pock method. Our starting point is the preconditioned proximal point formulation of this method. By adding correctors corresponding to the antisymmetric part of the relevant monotone operator, using a FISTA-style gap unrolling argument, we are able to derive gap estimates instead of merely ergodic gap estimates. Moreover, based on adding a diagonal component to this corrector, we are able to combine strong convexity based acceleration with inertial acceleration. We test our proposed method on image processing and inverse problems, obtaining convergence improvements for sparse Fourier inversion and positron emission tomography.},
  archive      = {J_SIOPT},
  author       = {Tuomo Valkonen},
  doi          = {10.1137/18M1182851},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1391-1420},
  shortjournal = {SIAM J. Optim.},
  title        = {Inertial, corrected, primal-dual proximal splitting},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A proximal average for prox-bounded functions.
<em>SIOPT</em>, <em>30</em>(2), 1366–1390. (<a
href="https://doi.org/10.1137/19M1287419">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We construct a proximal average for two prox-bounded functions, which recovers the classical proximal average for two convex functions. The new proximal average transforms continuously in epi-topology from one proximal hull to the other. When one of the functions is differentiable, the new proximal average is differentiable. We give characterizations for Lipschitz and single-valued proximal mappings and we show that the convex combination of convexified proximal mappings is always a proximal mapping. Subdifferentiability and behaviors of infimal values and minimizers are also studied.},
  archive      = {J_SIOPT},
  author       = {J. Chen and X. Wang and C. Planiden},
  doi          = {10.1137/19M1287419},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1366-1390},
  shortjournal = {SIAM J. Optim.},
  title        = {A proximal average for prox-bounded functions},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Using two-dimensional projections for stronger separation
and propagation of bilinear terms. <em>SIOPT</em>, <em>30</em>(2),
1339–1365. (<a href="https://doi.org/10.1137/19M1249825">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most fundamental ingredients in mixed-integer nonlinear programming solvers is the well-known McCormick relaxation for a product of two variables $x$ and $y$ over a box-constrained domain. The starting point of this paper is the fact that the convex hull of the graph of $xy$ can be much tighter when computed over a strict, nonrectangular subset of the box. In order to exploit this in practice, we propose computing valid linear inequalities for the projection of the feasible region onto the $x$-$y$-space by solving a sequence of linear programs akin to optimization-based bound tightening. These valid inequalities allow us to employ results from the literature to strengthen the classical McCormick relaxation. As a consequence, we obtain a stronger convexification procedure that exploits problem structure and can benefit from supplementary information obtained during the branch-and-bound algorithm such as an objective cutoff. We complement this by a new bound tightening procedure that efficiently computes the best possible bounds for $x$, $y$, and $xy$ over the available projections. Our computational evaluations using the academic solver SCIP exhibit that the proposed methods are applicable to a large portion of the public test library MINLPLib and help to improve performance significantly.},
  archive      = {J_SIOPT},
  author       = {Benjamin Müller and Felipe Serrano and Ambros Gleixner},
  doi          = {10.1137/19M1249825},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1339-1365},
  shortjournal = {SIAM J. Optim.},
  title        = {Using two-dimensional projections for stronger separation and propagation of bilinear terms},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Pathological subgradient dynamics. <em>SIOPT</em>,
<em>30</em>(2), 1327–1338. (<a
href="https://doi.org/10.1137/19M1298147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We construct examples of Lipschitz continuous functions, with pathological subgradient dynamics in both continuous and discrete time. In both settings, the iterates generate bounded trajectories and yet fail to detect any (generalized) critical points of the function.},
  archive      = {J_SIOPT},
  author       = {Aris Daniilidis and Dmitriy Drusvyatskiy},
  doi          = {10.1137/19M1298147},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1327-1338},
  shortjournal = {SIAM J. Optim.},
  title        = {Pathological subgradient dynamics},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Spectral properties of barzilai–borwein rules in solving
singly linearly constrained optimization problems subject to lower and
upper bounds. <em>SIOPT</em>, <em>30</em>(2), 1300–1326. (<a
href="https://doi.org/10.1137/19M1268641">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In 1988, Barzilai and Borwein published a pioneering paper which opened the way to inexpensively accelerate first-order. In more detail, in the framework of unconstrained optimization, Barzilai and Borwein developed two strategies to select the step length in gradient descent methods with the aim of encoding some second-order information of the problem without computing and/or employing the Hessian matrix of the objective function. Starting from these ideas, several efficient step length techniques have been suggested in the last decades in order to make gradient descent methods more and also more appealing for problems which handle large-scale data and require real-time solutions. Typically, these new step length selection rules have been tuned in the quadratic unconstrained framework for sweeping the spectrum of the Hessian matrix, and then applied also to nonquadratic constrained problems, without any substantial modification, by showing them to be very effective anyway. In this paper, we deeply analyze how, in quadratic and nonquadratic minimization problems, the presence of a feasible region, expressed by a single linear equality constraint together with lower and upper bounds, influences the spectral properties of the original Barzilai--Borwein (BB) rules, generalizing recent results provided for box-constrained quadratic problems. This analysis gives rise to modified BB approaches able not only to capture second-order information but also to exploit the nature of the feasible region. We show the benefits gained by the new step length rules on a set of test problems arising also from machine learning and image processing applications.},
  archive      = {J_SIOPT},
  author       = {Serena Crisci and Federica Porta and Valeria Ruggiero and Luca Zanni},
  doi          = {10.1137/19M1268641},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1300-1326},
  shortjournal = {SIAM J. Optim.},
  title        = {Spectral properties of barzilai--borwein rules in solving singly linearly constrained optimization problems subject to lower and upper bounds},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A subgradient-based approach for finding the maximum
feasible subsystem with respect to a set. <em>SIOPT</em>,
<em>30</em>(2), 1274–1299. (<a
href="https://doi.org/10.1137/18M1186320">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a subgradient-based method for finding the maximum feasible subsystem in a collection of closed sets with respect to a given closed set $C$ (MFS$_C$). In this method, we reformulate the MFS$_C$ problem as an $\ell_0$ optimization problem and construct a sequence of continuous optimization problems to approximate it. The objective of each approximation problem is the sum of the composition of a nonnegative nondecreasing continuously differentiable concave function with the squared distance function to a closed set. Although this objective function is nonsmooth in general, a subgradient can be obtained in terms of the projections onto the closed sets. Based on this observation, we adapt a subgradient projection method to solve these approximation problems. Unlike classical subgradient methods, the convergence (clustering to stationary points) of our subgradient method is guaranteed with a nondiminishing stepsize under mild assumptions. This allows us to further study the sequential convergence of the subgradient method under suitable Kurdyka--Łojasiewicz assumptions. Finally, we illustrate our algorithm numerically for solving the MFS$_C$ problems on a collection of halfspaces and a collection of unions of halfspaces, respectively, with respect to the set of $s$-sparse vectors.},
  archive      = {J_SIOPT},
  author       = {Minglu Ye and Ting Kei Pong},
  doi          = {10.1137/18M1186320},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1274-1299},
  shortjournal = {SIAM J. Optim.},
  title        = {A subgradient-based approach for finding the maximum feasible subsystem with respect to a set},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A geometrical analysis on convex conic reformulations of
quadratic and polynomial optimization problems. <em>SIOPT</em>,
<em>30</em>(2), 1251–1273. (<a
href="https://doi.org/10.1137/19M1237715">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a unified geometrical analysis on the completely positive programming (CPP) reformulations of quadratic optimization problems (QOPs) and their extension to polynomial optimization problems (POPs) based on a class of geometrically defined nonconvex conic programs and their convexification. The class of nonconvex conic programs minimize a linear objective function in a vector space $\mathbb{V}$ over the constraint set represented geometrically as the intersection of a nonconvex cone $\mathbb{K} \subset \mathbb{V}$, a face $\mathbb{J}$ of the convex hull of $\mathbb{K}$, and a parallel translation $\mathbb{L}$ of a hyperplane. We show that under moderate assumptions, the original nonconvex conic program can equivalently be reformulated as a convex conic program by replacing the constraint set with the intersection of $\mathbb{J}$ and $\mathbb{L}$. The replacement procedure is applied for deriving the CPP reformulations of QOPs and their extension to POPs.},
  archive      = {J_SIOPT},
  author       = {Sunyoung Kim and Masakazu Kojima and Kim-Chuan Toh},
  doi          = {10.1137/19M1237715},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1251-1273},
  shortjournal = {SIAM J. Optim.},
  title        = {A geometrical analysis on convex conic reformulations of quadratic and polynomial optimization problems},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Exact converging bounds for stochastic dual dynamic
programming via fenchel duality. <em>SIOPT</em>, <em>30</em>(2),
1223–1250. (<a href="https://doi.org/10.1137/19M1258876">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stochastic dual dynamic programming (SDDP) algorithm has become one of the main tools used to address convex multistage stochastic optimal control problems. Recently a large amount of work has been devoted to improving the convergence speed of the algorithm through cut selection and regularization, and to extending the field of applications to nonlinear, integer, or risk-averse problems. However, one of the main downsides of the algorithm remains the difficulty in giving an upper bound of the optimal value, usually estimated through Monte Carlo methods and therefore difficult to use in the stopping criterion of the algorithm. In this paper we present a dual SDDP algorithm that yields a converging exact upper bound for the optimal value of the optimization problem. As an easy consequence of our approach, we show how to compute an alternative control policy based on an inner approximation of Bellman value functions instead of the outer approximation given by the standard SDDP algorithm. We illustrate the approach on an energy production problem involving zones of production and transportation links between the zones. The numerical experiments we carry out on this example show the effectiveness of the method.},
  archive      = {J_SIOPT},
  author       = {Vincent Leclère and Pierre Carpentier and Jean-Philippe Chancelier and Arnaud Lenoir and François Pacaud},
  doi          = {10.1137/19M1258876},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1223-1250},
  shortjournal = {SIAM J. Optim.},
  title        = {Exact converging bounds for stochastic dual dynamic programming via fenchel duality},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Distributed algorithms with finite data rates that solve
linear equations. <em>SIOPT</em>, <em>30</em>(2), 1191–1222. (<a
href="https://doi.org/10.1137/19M1258864">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study network linear equations subject to digital communications with a finite data rate, where each node is associated with one equation from a system of linear equations. Each node holds a dynamic state and interacts with its neighbors through an undirected connected graph, where along each link the pair of nodes share information. Due to the data rate constraint, each node builds an encoder/decoder pair, with which it produces transmitted messages with a zooming-in finite-level uniform quantizer and also generates estimates of its neighbors&#39; states from the received signals. We then propose a distributed quantized algorithm and show that when the network linear equations admit a unique solution, each node&#39;s state is driven to that solution exponentially fast. We further analyze the asymptotic rate of convergence and show that a larger number of quantization levels leads to a faster convergence rate although the rate is still fundamentally bounded by the inherent network structure and the linear equations. In addition, we establish a bound on the total number of communication bits required to obtain a solution with a prescribed accuracy. When a unique least-squares solution exists, we show that the algorithm can compute such a solution with a suitably selected time-varying step-size inherited from the encoder and zooming-in quantizer dynamics. In both cases, a minimal data rate is shown to be enough for guaranteeing the desired convergence when the algorithm parameters are properly chosen. These results ensure the applicability of various network linear equation solvers when peer-to-peer communication is digital.},
  archive      = {J_SIOPT},
  author       = {Jinlong Lei and Peng Yi and Guodong Shi and Brian D. O. Anderson},
  doi          = {10.1137/19M1258864},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1191-1222},
  shortjournal = {SIAM J. Optim.},
  title        = {Distributed algorithms with finite data rates that solve linear equations},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Subset selection in sparse matrices. <em>SIOPT</em>,
<em>30</em>(2), 1173–1190. (<a
href="https://doi.org/10.1137/18M1219266">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In subset selection we search for the best linear predictor that involves a small subset of variables. From a computational complexity viewpoint, subset selection is NP-hard and few classes are known to be solvable in polynomial time. Using mainly tools from discrete geometry, we show that some sparsity conditions on the original data matrix allow us to solve the problem in polynomial time.},
  archive      = {J_SIOPT},
  author       = {Alberto Del Pia and Santanu S. Dey and Robert Weismantel},
  doi          = {10.1137/18M1219266},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1173-1190},
  shortjournal = {SIAM J. Optim.},
  title        = {Subset selection in sparse matrices},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On stochastic and deterministic quasi-newton methods for
nonstrongly convex optimization: Asymptotic convergence and rate
analysis. <em>SIOPT</em>, <em>30</em>(2), 1144–1172. (<a
href="https://doi.org/10.1137/17M1152474">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by applications arising from large-scale optimization and machine learning, we consider stochastic quasi-Newton (SQN) methods for solving unconstrained convex optimization problems. Much of the convergence analysis of SQN methods, in both full and limited-memory regimes, requires the objective function to be strongly convex. However, this assumption is fairly restrictive and does not hold in many applications. To the best of our knowledge, no rate statements currently exist for SQN methods in the absence of such an assumption. Furthermore, among the existing first-order methods for addressing stochastic optimization problems with merely convex objectives, techniques equipped with provable convergence rates employ averaging. However, this averaging technique has a detrimental impact on inducing sparsity. Motivated by these gaps, we consider optimization problems with non-strongly convex objectives with Lipschitz but possibly unbounded gradients. The main contributions of the paper are as follows: (i) To address large-scale stochastic optimization problems, we develop an iteratively regularized stochastic limited-memory BFGS (IRS-LBFGS) algorithm, where the step size, regularization parameter, and the Hessian inverse approximation are updated iteratively. We establish convergence of the iterates (with no averaging) to an optimal solution of the original problem both in an almost-sure sense and in a mean sense. The convergence rate is derived in terms of the objective function value and is shown to be $\mathcal{O}(1/k^{({1}/{3}-\epsilon)})$, where $\epsilon$ is an arbitrary small positive scalar. (ii) In deterministic regimes, we show that the algorithm displays a rate $\mathcal{O}({1}/{k^{1-\epsilon}})$. We present numerical experiments performed on a large-scale text classification problem and compare IRS-LBFGS with standard SQN methods as well as first-order methods such as SAGA and IAG.},
  archive      = {J_SIOPT},
  author       = {Farzad Yousefian and Angelia Nedić and Uday V. Shanbhag},
  doi          = {10.1137/17M1152474},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1144-1172},
  shortjournal = {SIAM J. Optim.},
  title        = {On stochastic and deterministic quasi-newton methods for nonstrongly convex optimization: Asymptotic convergence and rate analysis},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Scenario approach for minmax optimization with emphasis on
the nonconvex case: Positive results and caveats. <em>SIOPT</em>,
<em>30</em>(2), 1119–1143. (<a
href="https://doi.org/10.1137/19M1271026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We treat the so-called scenario approach, a popular probabilistic approximation method for robust minmax optimization problems via independent and identically distributed (i.i.d.) sampling from the uncertainty set, from various perspectives. The scenario approach is well studied in the important case of convex robust optimization problems, and here we examine how the phenomenon of concentration of measures affects the i.i.d. sampling aspect of the scenario approach in high dimensions and its relation with the optimal values. Moreover, we perform a detailed study of both the asymptotic behavior (consistency) and finite time behavior of the scenario approach in the more general setting of nonconvex minmax optimization problems. In the direction of the asymptotic behavior of the scenario approach, we present an obstruction to consistency that arises when the decision set is noncompact. In the direction of finite sample guarantees, we establish a general methodology for extracting “probably approximately correct&#39;&#39;-type estimates for the finite sample behavior of the scenario approach for a large class of nonconvex problems.},
  archive      = {J_SIOPT},
  author       = {Mishal Assif and Debasish Chatterjee and Ravi Banavar},
  doi          = {10.1137/19M1271026},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1119-1143},
  shortjournal = {SIAM J. Optim.},
  title        = {Scenario approach for minmax optimization with emphasis on the nonconvex case: Positive results and caveats},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Duality gap estimation via a refined shapley–folkman lemma.
<em>SIOPT</em>, <em>30</em>(2), 1094–1118. (<a
href="https://doi.org/10.1137/18M1174805">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on concepts like the $k$th convex hull and finer characterization of nonconvexity of a function, we propose a refinement of the Shapley--Folkman lemma and derive a new estimate for the duality gap of nonconvex optimization problems with separable objective functions. We apply our result to the network utility maximization problem in networking and the dynamic spectrum management problem in communication as examples to demonstrate that the new bound can be qualitatively tighter than the existing ones. The idea is also applicable to cases with general nonconvex constraints.},
  archive      = {J_SIOPT},
  author       = {Yingjie Bi and Ao Tang},
  doi          = {10.1137/18M1174805},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1094-1118},
  shortjournal = {SIAM J. Optim.},
  title        = {Duality gap estimation via a refined shapley--folkman lemma},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A shifted primal-dual penalty-barrier method for nonlinear
optimization. <em>SIOPT</em>, <em>30</em>(2), 1067–1093. (<a
href="https://doi.org/10.1137/19M1247425">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In nonlinearly constrained optimization, penalty methods provide an effective strategy for handling equality constraints, while barrier methods provide an effective approach for the treatment of inequality constraints. A new algorithm for nonlinear optimization is proposed based on minimizing a shifted primal-dual penalty-barrier function. Certain global convergence properties are established. In particular, it is shown that a limit point of the sequence of iterates may always be found that is either an infeasible stationary point or a complementary approximate Karush--Kuhn--Tucker point; i.e., it satisfies reasonable stopping criteria and is a Karush--Kuhn--Tucker point under a regularity condition that is the weakest constraint qualification associated with sequential optimality conditions. It is also shown that under suitable additional assumptions, the method is equivalent to a shifted variant of the primal-dual path-following method in the neighborhood of a solution. Numerical examples are provided that illustrate the performance of the method compared to a widely used conventional interior-point method.},
  archive      = {J_SIOPT},
  author       = {Philip E. Gill and Vyacheslav Kungurtsev and Daniel P. Robinson},
  doi          = {10.1137/19M1247425},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1067-1093},
  shortjournal = {SIAM J. Optim.},
  title        = {A shifted primal-dual penalty-barrier method for nonlinear optimization},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A data-independent distance to infeasibility for linear
conic systems. <em>SIOPT</em>, <em>30</em>(2), 1049–1066. (<a
href="https://doi.org/10.1137/18M1189464">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We offer a unified treatment of distinct measures of well-posedness for homogeneous conic systems. To that end, we introduce a distance to infeasibility based entirely on geometric considerations of the elements defining the conic system. Our approach sheds new light on and connects several well-known condition measures for conic systems, including Renegar&#39;s distance to infeasibility, the Grassmannian condition measure, a measure of the most interior solution, and other geometric measures of symmetry and of depth of the conic system.},
  archive      = {J_SIOPT},
  author       = {Javier Pen͂a and Vera Roshchina},
  doi          = {10.1137/18M1189464},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1049-1066},
  shortjournal = {SIAM J. Optim.},
  title        = {A data-independent distance to infeasibility for linear conic systems},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Erratum: A faster algorithm solving a generalization of
isotonic median regression and a class of fused lasso problems.
<em>SIOPT</em>, <em>30</em>(1), 1048. (<a
href="https://doi.org/10.1137/18M1175495">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {On page 2568 of our paper A faster algorithm solving a generalization of isotonic median regression and a class of fused lasso problems, we stated the following: \beginquote Note that Kolmogorov, Pock, and Rolinek in Total variation on a tree also claimed an $O(n\log \log n)$ algorithm for the PL-wFL-O(1) problem. However, the divide-and-conquer technique used in the algorithm requires the sorting of the breakpoints, which adds to the complexity $O(n \log n)$. \endquote This erratum retracts our statement quoted above and corrects the entry relating to this problem in Table 1 of paper A faster algorithm solving a generalization of isotonic median regression and a class of fused lasso problems to read that the run time of the algorithm of paper Total variation on a tree is $O(n\log \log n)$.},
  archive      = {J_SIOPT},
  author       = {Dorit S. Hochbaum and Cheng Lu},
  doi          = {10.1137/18M1175495},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {1048},
  shortjournal = {SIAM J. Optim.},
  title        = {Erratum: A faster algorithm solving a generalization of isotonic median regression and a class of fused lasso problems},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Limitations on the expressive power of convex cones without
long chains of faces. <em>SIOPT</em>, <em>30</em>(1), 1033–1047. (<a
href="https://doi.org/10.1137/19M1245670">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A convex optimization problem in conic form involves minimizing a linear functional over the intersection of a convex cone and an affine subspace. In some cases, it is possible to replace a conic formulation using a certain cone, with a “lifted” conic formulation using another cone that is higher-dimensional, but simpler, in some sense. One situation in which this can be computationally advantageous is when the higher-dimensional cone is a Cartesian product of many “low-complexity” cones, such as second-order cones, or small positive semidefinite cones. This paper studies obstructions to a convex cone having a lifted representation with such a product structure. The main result says that whenever a convex cone has a certain neighborliness property, then it does not have a lifted representation using a finite product of cones, each of which has only short chains of faces. This is a generalization of recent work of Averkov [SIAM J. Appl. Alg. Geom., 3 (2019), pp. 128--151], which considers only lifted representations using products of positive semidefinite cones of bounded size. Among the consequences of the main result is that various cones related to nonnegative polynomials do not have lifted representations using products of “low-complexity” cones, such as smooth cones, the exponential cone, and cones defined by hyperbolic polynomials of low degree.},
  archive      = {J_SIOPT},
  author       = {James Saunderson},
  doi          = {10.1137/19M1245670},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {1033-1047},
  shortjournal = {SIAM J. Optim.},
  title        = {Limitations on the expressive power of convex cones without long chains of faces},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Projective cutting-planes. <em>SIOPT</em>, <em>30</em>(1),
1007–1032. (<a href="https://doi.org/10.1137/19M1272652">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a polytope $\mathcal P$, an interior point ${x}\in\mathcal P$, and a direction ${d}\in\mathbb{R}^n$, the projection of ${x}$ along ${d}$ asks to find the maximum step length $t^*$ such that ${x}+t^*{d}\in\mathcal P$; we say ${x}+t^*{d}$ is the pierce point obtained by projection. In [D. Porumbel, Math. Program., 155 (2016), pp. 147--197], we solely explored the idea of projecting the origin $0_n$ along integer directions only, focusing on dual polytopes $\mathcal P$ in Column Generation models. This work addresses a more general projection subproblem, considering arbitrary interior points ${x}\in\mathcal P$ and arbitrary noninteger directions ${d}\in\mathbb{R}^n$, in areas beyond Column Generation.The projection subproblem generalizes the separation subproblem of the well-known Cutting-Planes. We propose a new algorithm, Projective Cutting-Planes, that relies on this projection subproblem to optimize over polytopes $\mathcal P$ with prohibitively many constraints. At each iteration, this new algorithm selects a point ${x}_{new}$ on the segment joining the points ${x}$ and ${x}+t^*{d}$ determined at the previous iteration. Then, it projects ${x}_{new}$ along the direction ${d}_{new}$ pointing towards the current optimal (outer) solution (of the current outer approximation of $\mathcal P$), so as to generate a new pierce point ${x}_{new}+t^*_{new} {d}_{new}$ and a new constraint of $\mathcal P$. By reoptimizing the linear program enriched with this new constraint, the algorithm finds a new current optimal (outer) solution and moves to the next iteration by updating ${x}={x}_{new}$ and ${d}={d}_{new}$. Compared to Cutting-Planes, the main advantage of Projective Cutting-Planes is that it has a built-in functionality to generate a feasible inner solution ${new}+t^*{d}$ at each iteration. These inner solutions converge iteratively to an optimal solution ${opt}(\mathcal P)$, and so Projective Cutting-Planes is more similar to an interior point method than to the Simplex method. Numerical experiments in different optimization settings confirm the potential of the proposed ideas.},
  archive      = {J_SIOPT},
  author       = {Daniel Porumbel},
  doi          = {10.1137/19M1272652},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {1007-1032},
  shortjournal = {SIAM J. Optim.},
  title        = {Projective cutting-planes},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The boosted difference of convex functions algorithm for
nonsmooth functions. <em>SIOPT</em>, <em>30</em>(1), 980–1006. (<a
href="https://doi.org/10.1137/18M123339X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The boosted difference of convex functions algorithm (BDCA) was recently proposed for minimizing smooth difference of convex (DC) functions. BDCA accelerates the convergence of the classical difference of convex functions algorithm (DCA) thanks to an additional line search step. The purpose of this paper is twofold. First, we show that this scheme can be generalized and successfully applied to certain types of nonsmooth DC functions, namely, those that can be expressed as the difference of a smooth function and a possibly nonsmooth one. Second, we show that there is complete freedom in the choice of the trial step size for the line search, which is something that can further improve its performance. We prove that any limit point of the BDCA iterative sequence is a critical point of the problem under consideration and that the corresponding objective value is monotonically decreasing and convergent. The global convergence and convergence rate of the iterations are obtained under the Kurdyka--Łojasiewicz property. Applications and numerical experiments for two problems in data science are presented, demonstrating that BDCA outperforms DCA. Specifically, for the minimum sum-of-squares clustering problem, BDCA was on average 16 times faster than DCA, and for the multidimensional scaling problem, BDCA was 3 times faster than DCA.},
  archive      = {J_SIOPT},
  author       = {Francisco J. Aragón Artacho and Phan T. Vuong},
  doi          = {10.1137/18M123339X},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {980-1006},
  shortjournal = {SIAM J. Optim.},
  title        = {The boosted difference of convex functions algorithm for nonsmooth functions},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A single timescale stochastic approximation method for
nested stochastic optimization. <em>SIOPT</em>, <em>30</em>(1), 960–979.
(<a href="https://doi.org/10.1137/18M1230542">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study constrained nested stochastic optimization problems in which the objective function is a composition of two smooth functions whose exact values and derivatives are not available. We propose a single timescale stochastic approximation algorithm, which we call the nested averaged stochastic approximation (NASA), to find an approximate stationary point of the problem. The algorithm has two auxiliary averaged sequences (filters) which estimate the gradient of the composite objective function and the inner function value. By using a special Lyapunov function, we show that the NASA achieves the sample complexity of ${\cal O}(1/\epsilon^{2})$ for finding an $\epsilon$-approximate stationary point, thus outperforming all extant methods for nested stochastic approximation. Our method and its analysis are the same for both unconstrained and constrained problems, without any need of batch samples for constrained nonconvex stochastic optimization. We also present a simplified parameter-free variant of the NASA method for solving constrained single-level stochastic optimization problems, and we prove the same complexity result for both unconstrained and constrained problems.},
  archive      = {J_SIOPT},
  author       = {Saeed Ghadimi and Andrzej Ruszczyński and Mengdi Wang},
  doi          = {10.1137/18M1230542},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {960-979},
  shortjournal = {SIAM J. Optim.},
  title        = {A single timescale stochastic approximation method for nested stochastic optimization},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A distributed flexible delay-tolerant proximal gradient
algorithm. <em>SIOPT</em>, <em>30</em>(1), 933–959. (<a
href="https://doi.org/10.1137/18M1194699">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop and analyze an asynchronous algorithm for distributed convex optimization when the objective can be written as a sum of smooth functions, local to each worker, and a nonsmooth function. Unlike many existing methods, our distributed algorithm is adjustable to various levels of communication cost, delays, machines&#39; computational power, and functions&#39; smoothness. A unique feature is that the step sizes do not depend on communication delays nor number of machines, which is highly desirable for scalability. We prove that the algorithm converges linearly in the strongly convex case, and provide guarantees of convergence for the non-strongly convex case. The obtained rates are the same as the vanilla proximal gradient algorithm over some introduced epoch sequence that subsumes the delays of the system. We provide numerical results on large-scale machine learning problems to demonstrate the merits of the proposed method.},
  archive      = {J_SIOPT},
  author       = {Konstantin Mishchenko and Franck Iutzeler and Jérôme Malick},
  doi          = {10.1137/18M1194699},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {933-959},
  shortjournal = {SIAM J. Optim.},
  title        = {A distributed flexible delay-tolerant proximal gradient algorithm},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A linear-time algorithm for generalized trust region
subproblems. <em>SIOPT</em>, <em>30</em>(1), 915–932. (<a
href="https://doi.org/10.1137/18M1215165">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we provide the first provable linear-time (in terms of the number of nonzero entries of the input) algorithm for approximately solving the generalized trust region subproblem (GTRS) of minimizing a quadratic function over a quadratic constraint under some regularity condition. Our algorithm is motivated by and extends a recent linear-time algorithm for the trust region subproblem by Hazan and Koren [Math. Program., 158 (2016), pp. 363--381]. However, due to the nonconvexity and noncompactness of the feasible region, such an extension is nontrivial. Our main contribution is to demonstrate that under some regularity condition, the optimal solution is in a compact and convex set and lower and upper bounds of the optimal value can be computed in linear time. Using these properties, we develop a linear-time algorithm for the GTRS.},
  archive      = {J_SIOPT},
  author       = {Rujun Jiang and Duan Li},
  doi          = {10.1137/18M1215165},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {915-932},
  shortjournal = {SIAM J. Optim.},
  title        = {A linear-time algorithm for generalized trust region subproblems},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Complexity and approximability of optimal resource
allocation and nash equilibrium over networks. <em>SIOPT</em>,
<em>30</em>(1), 885–914. (<a
href="https://doi.org/10.1137/19M1242525">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by emerging resource allocation and data placement problems such as web caches and peer-to-peer systems, we consider and study a class of resource allocation problems over a network of agents (nodes). In this model, which can be viewed as a homogeneous data placement problem, nodes can store only a limited number of resources while accessing the remaining ones through their closest neighbors. We consider this problem under both optimization and game-theoretic frameworks. In the case of optimal resource allocation, we will first show that when there are only $k=2$ resources, the optimal allocation can be found efficiently in $O(n^2\log n)$ steps, where $n$ denotes the total number of nodes. However, for $k\ge 3$ this problem becomes NP-hard with no polynomial-time approximation algorithm with a performance guarantee better than $1+\frac{1}{102k^2}$, even under metric access costs. We then provide a $3$-approximation algorithm for the optimal resource allocation which runs only in $O(kn^2)$. Subsequently, we look at this problem under a selfish setting formulated as a noncooperative game and provide a $3$-approximation algorithm for obtaining its pure Nash equilibria under metric access costs. We then establish an equivalence between the set of pure Nash equilibria and flip-optimal solutions of the Max-$k$-Cut problem over a specific weighted complete graph. While this reduction suggests that finding a pure Nash equilibrium using best response dynamics might be PLS-hard, it allows us to use tools from complementary slackness and quadratic programming to devise systematic and more efficient algorithms towards obtaining Nash equilibrium points.},
  archive      = {J_SIOPT},
  author       = {S. Rasoul Etesami},
  doi          = {10.1137/19M1242525},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {885-914},
  shortjournal = {SIAM J. Optim.},
  title        = {Complexity and approximability of optimal resource allocation and nash equilibrium over networks},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Calculus identities for generalized simplex gradients: Rules
and applications. <em>SIOPT</em>, <em>30</em>(1), 853–884. (<a
href="https://doi.org/10.1137/18M1215864">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simplex gradients, essentially the gradient of a linear approximation, are a popular tool in derivative-free optimization (DFO). In 2015, a product rule, a quotient rule, and a sum rule for simplex gradients were introduced by Regis [Optim. Lett., 9 (2015), pp. 845--865]. Unfortunately, those calculus rules only work under a restrictive set of assumptions. The purpose of this paper is to provide new calculus rules that work in a wider setting. The rules place minimal assumptions on the functions involved and the interpolation sets. The rules further lead to an alternative approach to gradient approximation in situations where the rules could be applied. We analyze the new approach, provide error bounds, and include some preliminary testing on numerical stability and accuracy.},
  archive      = {J_SIOPT},
  author       = {Warren Hare and Gabriel Jarry-Bolduc},
  doi          = {10.1137/18M1215864},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {853-884},
  shortjournal = {SIAM J. Optim.},
  title        = {Calculus identities for generalized simplex gradients: Rules and applications},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Asymptotic results of stochastic decomposition for two-stage
stochastic quadratic programming. <em>SIOPT</em>, <em>30</em>(1),
823–852. (<a href="https://doi.org/10.1137/19M1247796">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the stochastic decomposition (SD) algorithms for two classes of stochastic programming problems: (1) two-stage stochastic quadratic-linear programming (SQLP) in which a quadratic program defines the objective function in the first stage and a linear program defines the value function in the second stage and (2) two-stage stochastic quadratic-quadratic programming (SQQP) which has quadratic programming problems in both stages. Similar to their stochastic linear programming (SLP) predecessor, these iterative schemes in SD approximate the objective function using piecewise affine/quadratic minorants and then apply a stochastic proximal mapping to obtain the next iterate. In this paper we show that under some assumptions, the proximal mapping applied in SD obeys a contraction mapping property even though the approximations are based on sequential random samples. Following that, we demonstrate that under those assumptions, SD can provide a sequence of solutions converging to the optimal solution with a sublinear convergence rate in both SQLP and SQQP problems. Finally, we present an “in-sample” stopping rule to assess the optimality gap by constructing consistent bootstrap estimators.},
  archive      = {J_SIOPT},
  author       = {Junyi Liu and Suvrajeet Sen},
  doi          = {10.1137/19M1247796},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {823-852},
  shortjournal = {SIAM J. Optim.},
  title        = {Asymptotic results of stochastic decomposition for two-stage stochastic quadratic programming},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). High degree sum of squares proofs, bienstock–zuckerberg
hierarchy, and chvátal–gomory cuts. <em>SIOPT</em>, <em>30</em>(1),
798–822. (<a href="https://doi.org/10.1137/17M1150712">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chvátal--Gomory cuts (CG-cuts) and the Bienstock--Zuckerberg hierarchy capture useful linear programs that the standard bounded degree sum-of-squares (SoS) hierarchy fails to capture. In this paper we present a novel polynomial time SoS hierarchy for 0/1 problems with a custom subspace of high degree polynomials (not the standard subspace of low degree polynomials). We show that the new SoS hierarchy recovers the Bienstock--Zuckerberg hierarchy. Our result implies a linear program that reproduces the Bienstock--Zuckerberg hierarchy as a polynomial-sized, efficiently constructible extended formulation that satisfies all constant pitch inequalities. The construction is also very simple, and it is fully defined by giving the supporting polynomials. Moreover, for a class of polytopes (e.g., set cover and packing problems), the resulting SoS hierarchy optimizes in polynomial time over the polytope resulting from any constant rounds of CG-cuts, up to an arbitrarily small error in the solution value. Arguably, this is the first example where different basis functions can be useful in asymmetric situations to obtain a hierarchy of relaxations.},
  archive      = {J_SIOPT},
  author       = {Monaldo Mastrolilli},
  doi          = {10.1137/17M1150712},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {798-822},
  shortjournal = {SIAM J. Optim.},
  title        = {High degree sum of squares proofs, bienstock--zuckerberg hierarchy, and chvátal--gomory cuts},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Exact augmented lagrangian duality for mixed integer
quadratic programming. <em>SIOPT</em>, <em>30</em>(1), 781–797. (<a
href="https://doi.org/10.1137/19M1271695">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mixed integer quadratic programming (MIQP) is the problem of minimizing a quadratic function over mixed integer points in a rational polyhedron. This paper focuses on the augmented Lagrangian dual (ALD) for MIQP. ALD augments the usual Lagrangian dual with a weighted nonlinear penalty on the dualized constraints. We first prove that ALD will reach a zero duality gap asymptotically as the weight on the penalty goes to infinity under some mild conditions on the penalty function. We next show that a finite penalty weight is enough for a zero gap when we use any norm as the penalty function. Finally, we prove a polynomial bound on the weight on the penalty term to obtain a zero gap.},
  archive      = {J_SIOPT},
  author       = {Xiaoyi Gu and Shabbir Ahmed and Santanu S. Dey},
  doi          = {10.1137/19M1271695},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {781-797},
  shortjournal = {SIAM J. Optim.},
  title        = {Exact augmented lagrangian duality for mixed integer quadratic programming},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stability and error analysis for optimization and
generalized equations. <em>SIOPT</em>, <em>30</em>(1), 752–780. (<a
href="https://doi.org/10.1137/19M1251424">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stability and error analysis remain challenging for problems that lack regularity properties near solutions, are subject to large perturbations, and might be infinite-dimensional. We consider nonconvex optimization and generalized equations defined on metric spaces and develop bounds on solution errors using the truncated Hausdorff distance applied to graphs and epigraphs of the underlying set-valued mappings and functions. In the process, we extend the calculus of such distances to cover compositions and other constructions that arise in nonconvex problems. The results are applied to constrained problems with feasible sets that might have empty interiors, solution of KKT systems, and optimality conditions for difference-of-convex functions and composite functions.},
  archive      = {J_SIOPT},
  author       = {Johannes O. Royset},
  doi          = {10.1137/19M1251424},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {752-780},
  shortjournal = {SIAM J. Optim.},
  title        = {Stability and error analysis for optimization and generalized equations},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust accelerated gradient methods for smooth strongly
convex functions. <em>SIOPT</em>, <em>30</em>(1), 717–751. (<a
href="https://doi.org/10.1137/19M1244925">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the trade-offs between convergence rate and robustness to gradient errors in designing a first-order algorithm. We focus on gradient descent and accelerated gradient (AG) methods for minimizing strongly convex functions when the gradient has random errors in the form of additive white noise. With gradient errors, the function values of the iterates need not converge to the optimal value; hence, we define the robustness of an algorithm to noise as the asymptotic expected suboptimality of the iterate sequence to input noise power. For this robustness measure, we provide exact expressions for the quadratic case using tools from robust control theory and tight upper bounds for the smooth strongly convex case using Lyapunov functions certified through matrix inequalities. We use these characterizations within an optimization problem which selects parameters of each algorithm to achieve a particular trade-off between rate and robustness. Our results show that AG can achieve acceleration while being more robust to random gradient errors. This behavior is quite different than previously reported in the deterministic gradient noise setting. We also establish some connections between the robustness of an algorithm and how quickly it can converge back to the optimal solution if it is perturbed from the optimal point with deterministic noise. Our framework also leads to practical algorithms that can perform better than other state-of-the-art methods in the presence of random gradient noise.},
  archive      = {J_SIOPT},
  author       = {Necdet Serhat Aybat and Alireza Fallah and Mert Gürbüzbalaban and Asuman Ozdaglar},
  doi          = {10.1137/19M1244925},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {717-751},
  shortjournal = {SIAM J. Optim.},
  title        = {Robust accelerated gradient methods for smooth strongly convex functions},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the convergence of mirror descent beyond stochastic
convex programming. <em>SIOPT</em>, <em>30</em>(1), 687–716. (<a
href="https://doi.org/10.1137/17M1134925">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we examine the convergence of mirror descent in a class of stochastic optimization problems that are not necessarily convex (or even quasi-convex) and which we call variationally coherent. Since the standard technique of “ergodic averaging” offers no tangible benefits beyond convex programming, we focus directly on the algorithm&#39;s last generated sample (its “last iterate&#39;&#39;), and we show that it converges with probabiility 1 if the underlying problem is coherent. We further consider a localized version of variational coherence which ensures local convergence of Stochastic mirror descent (SMD) with high probability. These results contribute to the landscape of nonconvex stochastic optimization by showing that (quasi-)convexity is not essential for convergence to a global minimum: rather, variational coherence, a much weaker requirement, suffices. Finally, building on the above, we reveal an interesting insight regarding the convergence speed of SMD: in problems with sharp minima (such as generic linear programs or concave minimization problems), SMD reaches a minimum point in a finite number of steps (a.s.), even in the presence of persistent gradient noise. This result is to be contrasted with existing black-box convergence rate estimates that are only asymptotic.},
  archive      = {J_SIOPT},
  author       = {Zhengyuan Zhou and Panayotis Mertikopoulos and Nicholas Bambos and Stephen P. Boyd and Peter W. Glynn},
  doi          = {10.1137/17M1134925},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {687-716},
  shortjournal = {SIAM J. Optim.},
  title        = {On the convergence of mirror descent beyond stochastic convex programming},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Nonconvex robust low-rank matrix recovery. <em>SIOPT</em>,
<em>30</em>(1), 660–686. (<a
href="https://doi.org/10.1137/18M1224738">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the problem of recovering a low-rank matrix from a number of random linear measurements that are corrupted by outliers taking arbitrary values. We consider a nonsmooth nonconvex formulation of the problem, in which we explicitly enforce the low-rank property of the solution by using a factored representation of the matrix variable and employ an $\ell_1$-loss function to robustify the solution against outliers. We show that even when a constant fraction (which can be up to almost half) of the measurements are arbitrarily corrupted, as long as certain measurement operators arising from the measurement model satisfy the so-called $\ell_1/\ell_2$-restricted isometry property, the ground-truth matrix can be exactly recovered from any global minimum of the resulting optimization problem. Furthermore, we show that the objective function of the optimization problem is sharp and weakly convex. Consequently, a subgradient method (SubGM) with geometrically diminishing step sizes will converge linearly to the ground-truth matrix when suitably initialized. We demonstrate the efficacy of the SubGM for the nonconvex robust low-rank matrix recovery problem with various numerical experiments.},
  archive      = {J_SIOPT},
  author       = {Xiao Li and Zhihui Zhu and Anthony Man-Cho So and René Vidal},
  doi          = {10.1137/18M1224738},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {660-686},
  shortjournal = {SIAM J. Optim.},
  title        = {Nonconvex robust low-rank matrix recovery},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Spectral operators of matrices: Semismoothness and
characterizations of the generalized jacobian. <em>SIOPT</em>,
<em>30</em>(1), 630–659. (<a
href="https://doi.org/10.1137/18M1222235">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spectral operators of matrices proposed recently in [C. Ding, D. F. Sun, J. Sun, and K. C. Toh, Math. Program., 168 (2018), pp. 509--531] are a class of matrix-valued functions, which map matrices to matrices by applying a vector-to-vector function to all eigenvalues/singular values of the underlying matrices. Spectral operators play a crucial role in the study of various applications involving matrices such as matrix optimization problems that include semidefinite programming as one of most important example classes. In this paper, we will study more fundamental first- and second-order properties of spectral operators, including the Lipschitz continuity, $\rho$-order B(ouligand)-differentiability ($0&lt;\rho\le 1$), $\rho$-order G-semismoothness ($0&lt;\rho\le 1$), and characterization of generalized Jacobians.},
  archive      = {J_SIOPT},
  author       = {Chao Ding and Defeng Sun and Jie Sun and Kim-Chuan Toh},
  doi          = {10.1137/18M1222235},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {630-659},
  shortjournal = {SIAM J. Optim.},
  title        = {Spectral operators of matrices: Semismoothness and characterizations of the generalized jacobian},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Covering on a convex set in the absence of robinson’s
regularity. <em>SIOPT</em>, <em>30</em>(1), 604–629. (<a
href="https://doi.org/10.1137/19M1256634">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study stability properties of a given solution of a constrained equation, where the constraint has the form of the inclusion into an arbitrary closed convex set. We are mostly interested in those cases when Robinson&#39;s regularity condition does not hold, and we obtain weaker conditions ensuring stability of a given solution subject to wide classes of perturbations, or, in other words, ensuring covering of a “large&quot; set. Unlike previous developments of this kind, here we do not employ any necessary conicity assumptions on the constraint set, thus allowing for a much wider area of potential applications.},
  archive      = {J_SIOPT},
  author       = {Aram V. Arutyunov and Alexey F. Izmailov},
  doi          = {10.1137/19M1256634},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {604-629},
  shortjournal = {SIAM J. Optim.},
  title        = {Covering on a convex set in the absence of robinson&#39;s regularity},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Critical cones for sufficient second order conditions in PDE
constrained optimization. <em>SIOPT</em>, <em>30</em>(1), 585–603. (<a
href="https://doi.org/10.1137/19M1258244">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we analyze optimal control problems governed by semilinear parabolic equations. Box constraints for the controls are imposed, and the cost functional involves the state and possibly a sparsity-promoting term, but not a Tikhonov regularization term. Unlike finite dimensional optimization or control problems involving Tikhonov regularization, second order sufficient optimality conditions for the control problems we deal with must be imposed in a cone larger than the one used to obtain necessary conditions. Different extensions of this cone have been proposed in the literature for different kinds of minima: strong or weak minimizers for optimal control problems. After a discussion on these extensions, we propose a new extended cone smaller than those considered until now. We prove that a second order condition based on this new cone is sufficient for a strong local minimum.},
  archive      = {J_SIOPT},
  author       = {Eduardo Casas and Mariano Mateos},
  doi          = {10.1137/19M1258244},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {585-603},
  shortjournal = {SIAM J. Optim.},
  title        = {Critical cones for sufficient second order conditions in PDE constrained optimization},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Convergence analysis of the relaxed douglas–rachford
algorithm. <em>SIOPT</em>, <em>30</em>(1), 542–584. (<a
href="https://doi.org/10.1137/18M1229638">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by nonconvex, inconsistent feasibility problems in imaging, the relaxed alternating averaged reflections algorithm, or relaxed Douglas--Rachford algorithm (DR$\lambda$), was first proposed over a decade ago. Convergence results for this algorithm are limited to either convex feasibility or consistent nonconvex feasibility with strong assumptions on the regularity of the underlying sets. Using an analytical framework depending only on metric subregularity and pointwise almost averagedness, we analyze the convergence behavior of DR$\lambda$ for feasibility problems that are both nonconvex and inconsistent. We introduce a new type of regularity of sets, called superregular at a distance, to establish sufficient conditions for local linear convergence of the corresponding sequence. These results subsume and extend existing results for this algorithm.},
  archive      = {J_SIOPT},
  author       = {D. Russell Luke and Anna-Lena Martins},
  doi          = {10.1137/18M1229638},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {542-584},
  shortjournal = {SIAM J. Optim.},
  title        = {Convergence analysis of the relaxed douglas--rachford algorithm},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sharp worst-case evaluation complexity bounds for
arbitrary-order nonconvex optimization with inexpensive constraints.
<em>SIOPT</em>, <em>30</em>(1), 513–541. (<a
href="https://doi.org/10.1137/17M1144854">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide sharp worst-case evaluation complexity bounds for nonconvex minimization problems with general inexpensive constraints, i.e., problems where the cost of evaluating/enforcing of the (possibly nonconvex or even disconnected) constraints, if any, is negligible compared to that of evaluating the objective function. These bounds unify, extend, or improve all known upper and lower complexity bounds for nonconvex unconstrained and convexly constrained problems. It is shown that, given an accuracy level $\epsilon$, a degree of highest available Lipschitz continuous derivatives $p$, and a desired optimality order $q$ between one and $p$, a conceptual regularization algorithm requires no more than $O(\epsilon^{-\frac{p+1}{p-q+1}})$ evaluations of the objective function and its derivatives to compute a suitably approximate $q$th order minimizer. With an appropriate choice of the regularization, a similar result also holds if the $p$th derivative is merely Hölder rather than Lipschitz continuous. We provide an example that shows that the above complexity bound is sharp for unconstrained and a wide class of constrained problems; we also give reasons for the optimality of regularization methods from a worst-case complexity point of view, within a large class of algorithms that use the same derivative information.},
  archive      = {J_SIOPT},
  author       = {Coralia Cartis and Nicholas I. M. Gould and Philippe L. Toint},
  doi          = {10.1137/17M1144854},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {513-541},
  shortjournal = {SIAM J. Optim.},
  title        = {Sharp worst-case evaluation complexity bounds for arbitrary-order nonconvex optimization with inexpensive constraints},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Well-posed solvability of convex optimization problems on a
differentiable or continuous closed convex set. <em>SIOPT</em>,
<em>30</em>(1), 490–512. (<a
href="https://doi.org/10.1137/19M1251989">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a closed convex set A in a Banach space X, this paper considers the continuity and differentiability of A. The continuity of a closed convex set was introduced and studied by Gale and Klee [Math. Scand., 7 (1959), pp. 370--391] in terms of its support functional, and the differentiability of a closed convex set is a new notion introduced again in terms of its support functional. Using the technique of variational analysis, we prove that A is differentiable if and only if for every continuous linear (or convex) function f:X rightarrow R bounded below on A the corresponding optimization problem inf_x in Af(x) is well-posed solvable. In the reflexive space case, we prove that A is continuous if and only if for every continuous linear (or convex) function f:X rightarrow R bounded below on A the corresponding optimization problem inf_x in Af(x) is weakly well-posed solvable. We also prove that if the conjugate function f^* of a given continuous convex function f on X is Fréchet differentiable (resp., continuous) on dom(f^*), then for every closed convex set K in X with inf_x in Kf(x)&gt;-infty the corresponding optimization problem with objective f and constraint set K is well-posed (resp., weakly well-posed) solvable. In the framework of finite-dimensional spaces, several sharper results are established.},
  archive      = {J_SIOPT},
  author       = {Xi Yin Zheng},
  doi          = {10.1137/19M1251989},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {490-512},
  shortjournal = {SIAM J. Optim.},
  title        = {Well-posed solvability of convex optimization problems on a differentiable or continuous closed convex set},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Payoffs-beliefs duality and the value of information.
<em>SIOPT</em>, <em>30</em>(1), 464–489. (<a
href="https://doi.org/10.1137/18M1230049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In decision problems under incomplete information, actions (identified to payoff vectors indexed by states of nature) and beliefs are naturally paired by bilinear duality. We exploit this duality to analyze the value of information, using concepts and tools from convex analysis. We define the value function as the support function of the set of available actions: the subdifferential at a belief is the set of optimal actions at this belief; the set of beliefs at which an action is optimal is the normal cone of the set of available actions at this point. Our main results are (1) a necessary and sufficient condition for positive value of information and (2) global estimates of the value of information of any information structure from local properties of the value function and of the set of optimal actions taken at the prior belief only. We apply our results to the marginal value of information at the null, that is, when the agent is close to receiving no information at all, and we provide conditions under which the marginal value of information is infinite, null, or positive and finite.},
  archive      = {J_SIOPT},
  author       = {Michel De Lara and Olivier Gossner},
  doi          = {10.1137/18M1230049},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {464-489},
  shortjournal = {SIAM J. Optim.},
  title        = {Payoffs-beliefs duality and the value of information},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Principal component analysis by optimization of symmetric
functions has no spurious local optima. <em>SIOPT</em>, <em>30</em>(1),
439–463. (<a href="https://doi.org/10.1137/18M1188495">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Principal component analysis (PCA) finds the best linear representation of data and is an indispensable tool in many learning and inference tasks. Classically, principal components of a dataset are interpreted as the directions that preserve most of its “energy,” an interpretation that is theoretically underpinned by the celebrated Eckart--Young--Mirsky theorem. This paper introduces many other ways of performing PCA, with various geometric interpretations, and proves that the corresponding family of nonconvex programs has no spurious local optima, while possessing only strict saddle points. These programs therefore loosely behave like convex problems and can be efficiently solved to global optimality, for example, with certain variants of the stochastic gradient descent. Beyond providing new geometric interpretations and enhancing our theoretical understanding of PCA, our findings might pave the way for entirely new approaches to structured dimensionality reduction, such as sparse PCA and nonnegative matrix factorization. More specifically, we study an unconstrained formulation of PCA using determinant optimization that might provide an elegant alternative to the deflating scheme commonly used in sparse PCA.},
  archive      = {J_SIOPT},
  author       = {Armin Eftekhari and Raphael A. Hauser},
  doi          = {10.1137/18M1188495},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {439-463},
  shortjournal = {SIAM J. Optim.},
  title        = {Principal component analysis by optimization of symmetric functions has no spurious local optima},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Inexact cuts in stochastic dual dynamic programming.
<em>SIOPT</em>, <em>30</em>(1), 407–438. (<a
href="https://doi.org/10.1137/18M1211799">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce an extension of stochastic dual dynamic programming (SDDP) to solve stochastic convex dynamic programming equations. This extension applies when some or all primal and dual subproblems to be solved along the forward and backward passes of the method are solved with bounded errors (inexactly). This inexact variant of SDDP is described for both linear problems (the corresponding variant being denoted by ISDDP-LP) and nonlinear problems (the corresponding variant being denoted by ISDDP-NLP). We prove convergence theorems for ISDDP-LP and ISDDP-NLP for both bounded and asymptotically vanishing errors. Finally, we present the results of numerical experiments comparing SDDP and ISDDP-LP on a portfolio problem with direct transaction costs modeled as a multistage stochastic linear optimization problem. In these experiments, ISDDP-LP allows us to strike a different balance between policy quality and computing time, trading off the former for the latter.},
  archive      = {J_SIOPT},
  author       = {Vincent Guigues},
  doi          = {10.1137/18M1211799},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {407-438},
  shortjournal = {SIAM J. Optim.},
  title        = {Inexact cuts in stochastic dual dynamic programming},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Risk-averse models in bilevel stochastic linear programming.
<em>SIOPT</em>, <em>30</em>(1), 377–406. (<a
href="https://doi.org/10.1137/19M1242240">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a two-stage stochastic bilevel linear program where the leader contemplates the follower&#39;s reaction at the second stage optimistically. In this setting, the leader&#39;s objective function value can be modeled by a random variable, which we evaluate based on some law-invariant (quasi-)convex risk measure. After establishing Lipschitzian properties and existence results, we derive sufficient conditions for differentiability when the choice function is a Lipschitzian transformation of the expectation. This allows us to formulate first-order necessary optimality conditions for models involving certainty equivalents or expected disutilities. Moreover, a qualitative stability result under perturbation of the underlying probability distribution is presented. Finally, for finite discrete distributions, we reformulate the bilevel stochastic problems as standard bilevel problems and propose a regularization scheme for solving a deterministic bilevel programming problem.},
  archive      = {J_SIOPT},
  author       = {Johanna Burtscheidt and Matthias Claus and Stephan Dempe},
  doi          = {10.1137/19M1242240},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {377-406},
  shortjournal = {SIAM J. Optim.},
  title        = {Risk-averse models in bilevel stochastic linear programming},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A stochastic line search method with expected complexity
analysis. <em>SIOPT</em>, <em>30</em>(1), 349–376. (<a
href="https://doi.org/10.1137/18M1216250">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For deterministic optimization, line search methods augment algorithms by providing stability and improved efficiency. Here we adapt a classical backtracking Armijo line search to the stochastic optimization setting. While traditional line search relies on exact computations of the gradient and values of the objective function, our method assumes that these values are available up to some dynamically adjusted accuracy which holds with some sufficiently large, but fixed, probability. We bound the expected number of iterations to reach a desired first-order accuracy in the nonconvex, convex, and strongly convex cases and show that this bound matches the complexity bound of deterministic gradient descent up to constants.},
  archive      = {J_SIOPT},
  author       = {Courtney Paquette and Katya Scheinberg},
  doi          = {10.1137/18M1216250},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {349-376},
  shortjournal = {SIAM J. Optim.},
  title        = {A stochastic line search method with expected complexity analysis},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Existence of lagrange multipliers under gâteaux
differentiable data with applications to stochastic optimal control
problems. <em>SIOPT</em>, <em>30</em>(1), 319–348. (<a
href="https://doi.org/10.1137/18M1223411">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main objective of this work is to study the existence of Lagrange multipliers for infinite dimensional problems under Gâteaux differentiability assumptions on the data. Our investigation follows two main steps: the proof of the existence of Lagrange multipliers under a calmness assumption on the constraints and the study of sufficient conditions, which only use the Gâteaux derivative of the function defining the constraint, that ensure this assumption. We apply the abstract results to show directly the existence of Lagrange multipliers of two classes of standard stochastic optimal control problems.},
  archive      = {J_SIOPT},
  author       = {A. Jourani and F. J. Silva},
  doi          = {10.1137/18M1223411},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {319-348},
  shortjournal = {SIAM J. Optim.},
  title        = {Existence of lagrange multipliers under gâteaux differentiable data with applications to stochastic optimal control problems},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Gradient-based solution algorithms for a class of bilevel
optimization and optimal control problems with a nonsmooth lower level.
<em>SIOPT</em>, <em>30</em>(1), 290–318. (<a
href="https://doi.org/10.1137/18M1225707">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this paper is to explore a peculiar regularization effect that occurs in the sensitivity analysis of certain elliptic variational inequalities of the second kind. The effect causes the solution operator of the variational inequality at hand to be continuously Fréchet differentiable, although the problem itself contains nondifferentiable terms. Our analysis shows in particular that standard gradient-based algorithms can be used to solve bilevel optimization and optimal control problems that are governed by elliptic variational inequalities of the considered type---all without regularizing the nondifferentiable terms in the lower-level problem and without losing desirable properties of the solution such as, e.g., sparsity. Our results can, for instance, be used in the optimal control of Casson fluids and in bilevel optimization approaches for parameter learning in total variation image denoising models.},
  archive      = {J_SIOPT},
  author       = {Constantin Christof},
  doi          = {10.1137/18M1225707},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {290-318},
  shortjournal = {SIAM J. Optim.},
  title        = {Gradient-based solution algorithms for a class of bilevel optimization and optimal control problems with a nonsmooth lower level},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sharpness, restart, and acceleration. <em>SIOPT</em>,
<em>30</em>(1), 262–289. (<a
href="https://doi.org/10.1137/18M1224568">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Łojasiewicz inequality shows that sharpness bounds on the minimum of convex optimization problems hold almost generically. Sharpness directly controls the performance of restart schemes, as observed by Nemirovskii and Nesterov [USSR Comput. Math. Math. Phys., 25 (1985), pp. 21--30]. The constants quantifying these sharpness bounds are of course unobservable, but we show that optimal restart strategies are robust, and searching for the best scheme only increases the complexity by a logarithmic factor compared to the optimal bound. Overall then, restart schemes generically accelerate accelerated methods.},
  archive      = {J_SIOPT},
  author       = {Vincent Roulet and Alexandre d&#39;Aspremont},
  doi          = {10.1137/18M1224568},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {262-289},
  shortjournal = {SIAM J. Optim.},
  title        = {Sharpness, restart, and acceleration},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A matrix positivstellensatz with lifting polynomials.
<em>SIOPT</em>, <em>30</em>(1), 240–261. (<a
href="https://doi.org/10.1137/18M1203183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the projections of two semialgebraic sets defined by polynomial matrix inequalities, it is in general difficult to determine whether one is contained in the other. To address this issue we propose a new matrix Positivstellensatz that uses lifting polynomials. Under some general assumptions (e.g., the archimedeanness, nonempty interior, convexity), we prove that such a containment holds if and only if the proposed matrix Positivstellensatz is satisfied. The corresponding certificate can be searched for by solving a semidefinite program. An important application is to certify when a spectrahedrop (i.e., the projection of a spectrahedron) is contained in another one.},
  archive      = {J_SIOPT},
  author       = {Igor Klep and Jiawang Nie},
  doi          = {10.1137/18M1203183},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {240-261},
  shortjournal = {SIAM J. Optim.},
  title        = {A matrix positivstellensatz with lifting polynomials},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Proximal gradient method for nonsmooth optimization over the
stiefel manifold. <em>SIOPT</em>, <em>30</em>(1), 210–239. (<a
href="https://doi.org/10.1137/18M122457X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider optimization problems over the Stiefel manifold whose objective function is the summation of a smooth function and a nonsmooth function. Existing methods for solving this kind of problem can be classified into three categories. Algorithms in the first category rely on information of the subgradients of the objective function and thus tend to converge slowly in practice. Algorithms in the second category are proximal point algorithms, which involve subproblems that can be as difficult as the original problem. Algorithms in the third category are based on operator-splitting techniques, but they usually lack rigorous convergence guarantees. In this paper, we propose a retraction-based proximal gradient method for solving this class of problems. We prove that the proposed method globally converges to a stationary point. Iteration complexity for obtaining an $\epsilon$-stationary solution is also analyzed. Numerical results on solving sparse PCA and compressed modes problems are reported to demonstrate the advantages of the proposed method.},
  archive      = {J_SIOPT},
  author       = {Shixiang Chen and Shiqian Ma and Anthony Man-Cho So and Tong Zhang},
  doi          = {10.1137/18M122457X},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {210-239},
  shortjournal = {SIAM J. Optim.},
  title        = {Proximal gradient method for nonsmooth optimization over the stiefel manifold},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Analysis of the BFGS method with errors. <em>SIOPT</em>,
<em>30</em>(1), 182–209. (<a
href="https://doi.org/10.1137/19M1240794">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classical convergence analysis of quasi-Newton methods assumes that function and gradient evaluations are exact. In this paper, we consider the case when there are (bounded) errors in both computations and establish conditions under which a slight modification of the BFGS algorithm with an Armijo--Wolfe line search converges to a neighborhood of the solution that is determined by the size of the errors. One of our results is an extension of the analysis presented in [R. H. Byrd and J. Nocedal, SIAM J. Numer. Anal., 26 (1989), pp. 727--739], which establishes that, for strongly convex functions, a fraction of the BFGS iterates are good iterates. We present numerical results illustrating the performance of the new BFGS method in the presence of noise.},
  archive      = {J_SIOPT},
  author       = {Yuchen Xie and Richard H. Byrd and Jorge Nocedal},
  doi          = {10.1137/19M1240794},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {182-209},
  shortjournal = {SIAM J. Optim.},
  title        = {Analysis of the BFGS method with errors},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Douglas–rachford splitting and ADMM for nonconvex
optimization: Tight convergence results. <em>SIOPT</em>, <em>30</em>(1),
149–181. (<a href="https://doi.org/10.1137/18M1163993">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although originally designed and analyzed for convex problems, the alternating direction method of multipliers (ADMM) and its close relatives, Douglas--Rachford splitting (DRS) and Peaceman--Rachford splitting (PRS), have been observed to perform remarkably well when applied to certain classes of structured nonconvex optimization problems. However, partial global convergence results in the nonconvex setting have only recently emerged. In this paper we show how the Douglas--Rachford envelope, introduced in 2014, can be employed to unify and considerably simplify the theory for devising global convergence guarantees for ADMM, DRS, and PRS applied to nonconvex problems under less restrictive conditions, larger prox-stepsizes, and overrelaxation parameters than previously known. In fact, our bounds are tight whenever the overrelaxation parameter ranges in ((0,2]). The analysis of ADMM uses a universal primal equivalence with DRS that generalizes the known duality of the algorithms.},
  archive      = {J_SIOPT},
  author       = {Andreas Themelis and Panagiotis Patrinos},
  doi          = {10.1137/18M1163993},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {149-181},
  shortjournal = {SIAM J. Optim.},
  title        = {Douglas--rachford splitting and ADMM for nonconvex optimization: Tight convergence results},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A note on the nonemptiness and compactness of solution sets
of weakly homogeneous variational inequalities. <em>SIOPT</em>,
<em>30</em>(1), 132–148. (<a
href="https://doi.org/10.1137/19M1237478">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Gowda and Sossa studied weakly homogeneous variational inequalities (VIs), which contain the polynomial complementarity problem (PCP) as a special case. A lot of good theoretical results were obtained, and one of the important results is about the nonemptiness and compactness of the solution set of the concerned problem under the copositivity of the involved mapping and some additional conditions. In this note, we aim to generalize such a result. We obtain that the solution set of the weakly homogeneous VI is nonempty and compact when the involved mapping is a generalized copositive mapping and some additional conditions are satisfied. Such a result is a genuine generalization of the corresponding one achieved by Gowda and Sossa in the sense that one of their conditions is removed and every other condition is improved. We give some discussions on the conditions we used and obtain several related results which generalize the corresponding ones for the PCP. Moreover, we also investigate the relationships between the well-known coercivity condition and the conditions used in our main result.},
  archive      = {J_SIOPT},
  author       = {Xiao-Xiao Ma and Meng-Meng Zheng and Zheng-Hai Huang},
  doi          = {10.1137/19M1237478},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {132-148},
  shortjournal = {SIAM J. Optim.},
  title        = {A note on the nonemptiness and compactness of solution sets of weakly homogeneous variational inequalities},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Data-driven nonsmooth optimization. <em>SIOPT</em>,
<em>30</em>(1), 102–131. (<a
href="https://doi.org/10.1137/18M1207685">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we consider methods for solving large-scale optimization problems with a possibly nonsmooth objective function. The key idea is to first parametrize a class of optimization methods using a generic iterative scheme involving only linear operations and applications of proximal operators. This scheme contains some modern primal-dual first-order algorithms like the Douglas--Rachford and hybrid gradient methods as special cases. Moreover, we show weak convergence of the iterates to an optimal point for a new method which also belongs to this class. Next, we interpret the generic scheme as a neural network and use unsupervised training to learn the best set of parameters for a specific class of objective functions while imposing a fixed number of iterations. In contrast to other approaches of “learning to optimize,&quot; we present an approach which learns parameters only in the set of convergent schemes. Finally, we illustrate the approach on optimization problems arising in tomographic reconstruction and image deconvolution, and train optimization algorithms for optimal performance given a fixed number of iterations.},
  archive      = {J_SIOPT},
  author       = {Sebastian Banert and Axel Ringh and Jonas Adler and Johan Karlsson and Ozan Öktem},
  doi          = {10.1137/18M1207685},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {102-131},
  shortjournal = {SIAM J. Optim.},
  title        = {Data-driven nonsmooth optimization},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the complexity of an inexact restoration method for
constrained optimization. <em>SIOPT</em>, <em>30</em>(1), 80–101. (<a
href="https://doi.org/10.1137/18M1216146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent papers indicate that some algorithms for constrained optimization may exhibit worst-case complexity bounds that are very similar to those of unconstrained optimization algorithms. A natural question is whether well-established practical algorithms, perhaps with small variations, may enjoy analogous complexity results. In the present paper we show that the answer is positive with respect to inexact restoration algorithms in which first-order approximations are employed for defining the subproblems.},
  archive      = {J_SIOPT},
  author       = {Luís Felipe Bueno and José Mario Martínez},
  doi          = {10.1137/18M1216146},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {80-101},
  shortjournal = {SIAM J. Optim.},
  title        = {On the complexity of an inexact restoration method for constrained optimization},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the convergence to stationary points of deterministic and
randomized feasible descent directions methods. <em>SIOPT</em>,
<em>30</em>(1), 56–79. (<a
href="https://doi.org/10.1137/18M1217760">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the class of nonsmooth nonconvex problems in which the difference between a continuously differentiable function and a convex nonsmooth function is minimized over linear constraints. Our goal is to attain a point satisfying the stationarity necessary optimality condition, defined as the lack of feasible descent directions. Although elementary in smooth optimization, this condition is nontrivial when the objective function is nonsmooth, and, correspondingly, there are very few methods that obtain stationary points in such settings. We prove that stationarity in our model can be characterized by a finite number of directions and develop two methods, one deterministic and one random, that use these directions to obtain stationary points. Numerical experiments illustrate the benefit of obtaining a stationary point and the advantage of using the random method to do so.},
  archive      = {J_SIOPT},
  author       = {Amir Beck and Nadav Hallak},
  doi          = {10.1137/18M1217760},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {56-79},
  shortjournal = {SIAM J. Optim.},
  title        = {On the convergence to stationary points of deterministic and randomized feasible descent directions methods},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal <span
class="math inline"><em>k</em></span>-thresholding algorithms for sparse
optimization problems. <em>SIOPT</em>, <em>30</em>(1), 31–55. (<a
href="https://doi.org/10.1137/18M1219187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The simulations indicate that the existing hard thresholding technique independent of the residual function may cause a dramatic increase or numerical oscillation of the residual. This inherent drawback of the hard thresholding renders the traditional thresholding algorithms unstable and thus generally inefficient for solving practical sparse optimization problems. How to overcome this weakness and develop a truly efficient thresholding method is a fundamental question in this field. The aim of this paper is to address this question by proposing a new thresholding technique based on the notion of optimal $k$-thresholding. The central idea for this new development is to connect the $k$-thresholding directly to the residual reduction during the course of algorithms. This leads to a natural design principle for the efficient thresholding methods. Under the restricted isometry property, we prove that the optimal thresholding based algorithms are globally convergent to the solution of sparse optimization problems. The numerical experiments demonstrate that when solving sparse optimization problems, the traditional hard thresholding methods have been significantly transcended by the proposed algorithms which can even outperform the classic $\ell_1$-minimization method in many situations.},
  archive      = {J_SIOPT},
  author       = {Yun-Bin Zhao},
  doi          = {10.1137/18M1219187},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {31-55},
  shortjournal = {SIAM J. Optim.},
  title        = {Optimal $k$-thresholding algorithms for sparse optimization problems},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A smoothing active set method for linearly constrained
non-lipschitz nonconvex optimization. <em>SIOPT</em>, <em>30</em>(1),
1–30. (<a href="https://doi.org/10.1137/18M119611X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel smoothing active set method for linearly constrained non-Lipschitz nonconvex problems. At each step of the proposed method, we approximate the objective function by a smooth function with a fixed smoothing parameter and employ a new active set method for minimizing the smooth function over the original feasible set, until a special updating rule for the smoothing parameter meets. The updating rule is always satisfied within a finite number of iterations since the new active set method for smooth problems proposed in this paper forces at least one subsequence of projected gradients to zero. Any accumulation point of the smoothing active set method is a stationary point associated with the smoothing function used in the method, which is necessary for local optimality of the original problem. And any accumulation point for the $\ell_2-\ell_p$ $(0&lt;p&lt;1)$ sparse optimization model is a limiting stationary point, which is a local minimizer under a certain second-order condition. Numerical experiments demonstrate the efficiency and effectiveness of our smoothing active set method for hyperspectral unmixing on a 3 dimensional image cube of large size.},
  archive      = {J_SIOPT},
  author       = {Chao Zhang and Xiaojun Chen},
  doi          = {10.1137/18M119611X},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {1-30},
  shortjournal = {SIAM J. Optim.},
  title        = {A smoothing active set method for linearly constrained non-lipschitz nonconvex optimization},
  volume       = {30},
  year         = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
