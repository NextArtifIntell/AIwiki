<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>SISC_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="sisc---239">SISC - 239</h2>
<ul>
<li><details>
<summary>
(2020). A generic finite element framework on parallel tree-based
adaptive meshes. <em>SISC</em>, <em>42</em>(6), C436–C468. (<a
href="https://doi.org/10.1137/20M1328786">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work we formally derive and prove the correctness of the algorithms and data structures in a parallel, distributed-memory, generic finite element framework that supports $h$-adaptivity on computational domains represented as forest-of-trees. The framework is grounded on a rich representation of the adaptive mesh suitable for generic finite elements that is built on top of a low-level, light-weight forest-of-trees data structure handled by a specialized, highly parallel adaptive meshing engine, for which we have identified the requirements it must fulfill to be coupled into our framework. Atop this two-layered mesh representation, we build the rest of the data structures required for the numerical integration and assembly of the discrete system of linear equations. We consider algorithms that are suitable for both subassembled and fully assembled distributed data layouts of linear system matrices. The proposed framework has been implemented within the FEMPAR scientific software library, using p4est as a practical forest-of-octrees demonstrator. A strong scaling study of this implementation when applied to Poisson and Maxwell problems reveals remarkable scalability up to 32.2K CPU cores and 482.2M degrees of freedom. Besides, a comparative performance study of FEMPAR and the state-of-the-art deal.II finite element software shows at least comparative performance, and at most a factor of 2--3 improvement in the $h$-adaptive approximation of a Poisson problem with first- and second-order Lagrangian finite elements, respectively.},
  archive      = {J_SISC},
  author       = {Santiago Badia and Alberto F. Martín and Eric Neiva and Francesc Verdugo},
  doi          = {10.1137/20M1328786},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {6},
  pages        = {C436-C468},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A generic finite element framework on parallel tree-based adaptive meshes},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A domain decomposition rayleigh–ritz algorithm for symmetric
generalized eigenvalue problems. <em>SISC</em>, <em>42</em>(6),
C410–C435. (<a href="https://doi.org/10.1137/19M1280004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a parallel domain decomposition Rayleigh--Ritz projection scheme to compute a selected number of eigenvalues (and, optionally, associated eigenvectors) of large and sparse symmetric pencils. The projection subspace associated with interface variables is built by computing a few of the eigenvectors and associated leading derivatives of a zeroth-order approximation of the nonlinear matrix-valued interface operator. On the other hand, the projection subspace associated with interior variables is built independently in each subdomain by exploiting local eigenmodes and matrix resolvent approximations. The sought eigenpairs are then approximated by a Rayleigh--Ritz projection onto the subspace formed by the union of these two subspaces. Several theoretical and practical details are discussed, and upper bounds of the approximation errors are provided. Our numerical experiments demonstrate the efficiency of the proposed technique on sequential/distributed memory architectures as well as its competitiveness against schemes such as shift-and-invert Lanczos and automated multilevel substructuring combined with $p$-way vertex-based partitionings.},
  archive      = {J_SISC},
  author       = {Vassilis Kalantzis},
  doi          = {10.1137/19M1280004},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {6},
  pages        = {C410-C435},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A domain decomposition rayleigh--ritz algorithm for symmetric generalized eigenvalue problems},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Scalable asynchronous domain decomposition solvers.
<em>SISC</em>, <em>42</em>(6), C384–C409. (<a
href="https://doi.org/10.1137/19M1291303">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parallel implementations of linear iterative solvers generally alternate between phases of data exchange and phases of local computation. Increasingly large problem sizes and more heterogeneous compute architectures make load balancing and the design of low latency network interconnects that are able to satisfy the communication requirements of linear solvers very challenging tasks. In particular, global communication patterns such as inner products become increasingly limiting at scale. We explore the use of asynchronous communication based on one-sided Message Passing Interface primitives in the context of domain decomposition solvers. In particular, a scalable asynchronous two-level Schwarz method is presented. We discuss practical issues encountered in the development of a scalable solver and show experimental results obtained on a state-of-the-art supercomputer system that illustrate the benefits of asynchronous solvers in load balanced as well as load imbalanced scenarios. Using the novel method, we can observe speedups of up to four times over its classical synchronous equivalent.},
  archive      = {J_SISC},
  author       = {Christian Glusa and Erik G. Boman and Edmond Chow and Sivasankaran Rajamanickam and Daniel B. Szyld},
  doi          = {10.1137/19M1291303},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {6},
  pages        = {C384-C409},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Scalable asynchronous domain decomposition solvers},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multilevel BDDC for incompressible navier–stokes equations.
<em>SISC</em>, <em>42</em>(6), C359–C383. (<a
href="https://doi.org/10.1137/19M1276479">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an approach to the numerical solution of steady Navier--Stokes equations. Approximation by the finite element method (FEM) leads to a nonlinear saddle-point system. The system is linearized by the Picard iteration, which leads to a sequence of linear saddle-point systems with nonsymmetric matrices. In this paper, we study the application of Balancing Domain Decomposition based on Constraints (BDDC) to these systems. In particular, we formulate the multilevel BDDC method and explore its applicability for the benchmark problem of lid-driven cavity. Another contribution of the paper is describing the development and application of our BDDC solver to real-world problems of oil flow in hydrostatic bearings.},
  archive      = {J_SISC},
  author       = {Martin Hanek and Jakub Šístek and Pavel Burda},
  doi          = {10.1137/19M1276479},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {6},
  pages        = {C359-C383},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Multilevel BDDC for incompressible navier--stokes equations},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On soft errors in the conjugate gradient method: Sensitivity
and robust numerical detection. <em>SISC</em>, <em>42</em>(6),
C335–C358. (<a href="https://doi.org/10.1137/18M122858X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The conjugate gradient (CG) method is the most widely used iterative scheme for the solution of large sparse systems of linear equations when the matrix is symmetric positive definite. Although more than 60 years old, it is still a serious candidate for extreme-scale computations on large computing platforms. On the technological side, the continuous shrinking of transistor geometry and the increasing complexity of these devices affect dramatically their sensitivity to natural radiation and thus diminish their reliability. One of the most common effects produced by natural radiation is the single event upset which consists in a bit-flip in a memory cell producing unexpected results at the application level. Consequently, future extreme-scale computing facilities will be more prone to errors of any kind, including bit-flips, during their calculations. These numerical and technological observations are the main motivations for this work, where we first investigate through extensive numerical experiments the sensitivity of CG to bit-flips in its main computationally intensive kernels, namely the matrix-vector product and the preconditioner application. We further propose numerical criteria to detect the occurrence of such soft errors and assess their robustness through extensive numerical experiments.},
  archive      = {J_SISC},
  author       = {Emmanuel Agullo and Siegfried Cools and Emrullah Fatih Yetkin and Luc Giraud and Nick Schenkels and Wim Vanroose},
  doi          = {10.1137/18M122858X},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {6},
  pages        = {C335-C358},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {On soft errors in the conjugate gradient method: Sensitivity and robust numerical detection},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Parallel QR factorization of block-tridiagonal matrices.
<em>SISC</em>, <em>42</em>(6), C313–C334. (<a
href="https://doi.org/10.1137/19M1306166">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we deal with the $QR$ factorization of block-tridiagonal matrices, where the blocks are dense and rectangular. This work is motivated by a novel method for computing geodesics over Riemannian manifolds. If blocks are reduced sequentially along the diagonal, only limited parallelism is available. We propose a matrix permutation approach based on the nested dissection method which improves parallelism at the cost of additional computations and storage. We show how operations can be arranged to keep this extra cost as low as possible. We provide a detailed analysis of the approach showing that this extra cost is bounded. Finally, we present an implementation for shared memory systems which relies on task parallelism and makes use of a runtime system. Experimental results support the conclusions of our analysis and show that the proposed approach leads to good performance and scalability.},
  archive      = {J_SISC},
  author       = {Alfredo Buttari and Søren Hauberg and Costy Kodsi},
  doi          = {10.1137/19M1306166},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {6},
  pages        = {C313-C334},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Parallel QR factorization of block-tridiagonal matrices},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the approximate solution and modeling of the kernel of
nonlinear breakage population balance equation. <em>SISC</em>,
<em>42</em>(6), B1570–B1598. (<a
href="https://doi.org/10.1137/19M1301266">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study of collision-induced nonlinear breakage phenomenon is mostly unexplored but is important in the area of particulate processes. In this work, the volume and time dependent collisional breakage kernel function is modeled based on the population balance modeling approach. To solve the nonlinear breakage population balance equation, the weighted finite volume scheme for linear breakage process from Kumar, Saha, and Tsotsas [SIAM J. Numer. Anal., 53 (2015), pp. 1672--1689] is extended for the case of collision-induced breakage process. The weighted finite volume scheme is developed in such a way that it conserves the total mass of the system while preserving the total number of particles in the system. Moreover, an event-driven constant number Monte Carlo simulation algorithm is presented, and the simulation results are used as an alternative to experimental results. The volume dependency of the collisional breakage kernel is incorporated successfully in the Monte Carlo simulation for the first time while selecting particles for collision events. Some essential properties of any particulate process, such as the total number of particles and the size distribution of particles, are validated successfully for several breakage distribution functions using the Monte Carlo results. This offers new insights into the estimation and interpretation of collision-induced nonlinear breakage kinetics.},
  archive      = {J_SISC},
  author       = {Ashok Das and Jitendra Kumar and Maksym Dosta and Stefan Heinrich},
  doi          = {10.1137/19M1301266},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {6},
  pages        = {B1570-B1598},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {On the approximate solution and modeling of the kernel of nonlinear breakage population balance equation},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A variational lagrangian scheme for a phase-field model: A
discrete energetic variational approach. <em>SISC</em>, <em>42</em>(6),
B1541–B1569. (<a href="https://doi.org/10.1137/20M1326684">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a variational Lagrangian scheme for a modified phase-field model, which can compute the equilibrium states of the original Allen--Cahn type model. Our discretization is based on a prescribed energy-dissipation law in terms of the flow map. By employing a discrete energetic variational approach, this scheme preserves the variational structure of the continuous energy-dissipation law and is energy stable. Plentiful numerical tests show that, by choosing the initial value properly, our method can compute the desired equilibrium state and capture the thin diffuse interface with a small number of mesh points.},
  archive      = {J_SISC},
  author       = {Chun Liu and Yiwei Wang},
  doi          = {10.1137/20M1326684},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {6},
  pages        = {B1541-B1569},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A variational lagrangian scheme for a phase-field model: A discrete energetic variational approach},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fast convergence and asymptotic preserving of the general
synthetic iterative scheme. <em>SISC</em>, <em>42</em>(6), B1517–B1540.
(<a href="https://doi.org/10.1137/20M132691X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently the general synthetic iteration scheme (GSIS) was proposed for the Boltzmann equation [W. Su et al., J. Comput. Phys., 407 (2020), 109245], where various numerical simulations have shown that (i) the steady-state solution can be found within dozens of iterations at any Knudsen number $K$, and (ii) the solution is accurate even when the spatial cell size in the bulk region is much larger than the molecular mean free path, i.e., the Navier--Stokes solutions are recovered at coarse grids. The first property indicates that the error decay rate between two consecutive iterations decreases to zero along with $K$, while the second one implies that the GSIS asymptotically preserves the Navier--Stokes limit when $K$ approaches zero. This paper is first dedicated to the rigorous proof of both properties. Second, several numerically challenging cases (especially the two-dimensional thermal edge flow) are used to further demonstrate the accuracy and efficiency of GSIS.},
  archive      = {J_SISC},
  author       = {Wei Su and Lianhua Zhu and Lei Wu},
  doi          = {10.1137/20M132691X},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {6},
  pages        = {B1517-B1540},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Fast convergence and asymptotic preserving of the general synthetic iterative scheme},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An effective finite element iterative solver for a
poisson–nernst–planck ion channel model with periodic boundary
conditions. <em>SISC</em>, <em>42</em>(6), B1490–B1516. (<a
href="https://doi.org/10.1137/19M1297099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A system of Poisson--Nernst--Planck equations (PNP) is an important dielectric continuum model for simulating ion transport across biological membrane. In this paper, a PNP ion channel model with periodic boundary value conditions, denoted by PNPic, is presented and solved numerically with an effective finite element iterative method. In particular, the periodic boundary value conditions are used to mimic an infinitely large ion channel membrane, and the PNPic finite element solver includes (1) a PNPic solution decomposition scheme for overcoming the singularity difficulty caused by atomic charges, (2) Slotboom variables for transforming each related Nernst--Planck equation to avoid gradient calculation for any electrostatic potential function, (3) an efficient modified Newton iterative algorithm for solving each related nonlinear finite element equation, and (4) communication operators for carrying out functions operations between different finite element function spaces. This effective PNPic solver is implemented as a software package based on the state-of-the-art finite element library from the FEniCS project and an ion channel mesh generation package developed in Lu&#39;s group. Numerical results demonstrate the convergence of the PNPic finite element iterative solver and the performance of the PNPic software package. Moreover, the PNPic model is validated by the cation selectivity property and electric current experimental data of an ion channel protein.},
  archive      = {J_SISC},
  author       = {Dexuan Xie and Benzhuo Lu},
  doi          = {10.1137/19M1297099},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {6},
  pages        = {B1490-B1516},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {An effective finite element iterative solver for a poisson--nernst--planck ion channel model with periodic boundary conditions},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Semidefinite relaxation of multimarginal optimal transport
for strictly correlated electrons in second quantization. <em>SISC</em>,
<em>42</em>(6), B1462–B1489. (<a
href="https://doi.org/10.1137/20M1310977">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the strictly correlated electron (SCE) limit of the fermionic quantum many-body problem in the second-quantized formalism. This limit gives rise to a multimarginal optimal transport (MMOT) problem. Here the marginal state space for our MMOT problem is the binary set 0,1, and the number of marginals is the number L of sites in the model. The costs of storing and computing the exact solution of the MMOT problem both scale exponentially with respect to L. We propose an efficient convex relaxation to the MMOT which can be solved by semidefinite programming (SDP). In particular, the semidefinite constraint is only of size 2L X 2L. We further prove that the SDP has dual attainment, in spite of the lack of Slater&#39;s condition (i.e., the primal SDP does not have any strictly feasible point). In the context of determining the lowest energy of electrons via density functional theory, such dual attainment implies the existence of an effective potential needed to solve a nonlinear Schrödinger equation via self-consistent field iteration. We demonstrate the effectiveness of our methods on computing the ground state energy of spinless and spinful Hubbard-type models. Numerical results indicate that our SDP formulation yields comparable results when using the unrelaxed MMOT formulation. We also describe how our relaxation methods generalize to arbitrary MMOT problems with pairwise cost functions.},
  archive      = {J_SISC},
  author       = {Yuehaw Khoo and Lin Lin and Michael Lindsey and Lexing Ying},
  doi          = {10.1137/20M1310977},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {6},
  pages        = {B1462-B1489},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Semidefinite relaxation of multimarginal optimal transport for strictly correlated electrons in second quantization},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stencil scaling for vector-valued PDEs on hybrid grids with
applications to generalized newtonian fluids. <em>SISC</em>,
<em>42</em>(6), B1429–B1461. (<a
href="https://doi.org/10.1137/19M1267891">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Matrix-free finite element implementations for large applications provide an attractive alternative to standard sparse matrix data formats due to the significantly reduced memory consumption. Here, we show that they are also competitive with respect to the run-time in the low-order case if combined with suitable stencil scaling techniques. We focus on variable coefficient vector-valued partial differential equations as they arise in many physical applications. The presented method is based on scaling constant reference stencils originating from a linear finite element discretization instead of evaluating the bilinear forms on the fly. This method assumes the usage of hierarchical hybrid grids, and it may be applied to vector-valued second-order elliptic partial differential equations directly or as a part of more complicated problems. We provide theoretical and experimental performance estimates showing the advantages of this new approach compared to the traditional on-the-fly integration and stored matrix approaches. In our numerical experiments, we consider two specific mathematical models, namely, linear elastostatics and incompressible Stokes flow. The final example considers a nonlinear shear-thinning generalized Newtonian fluid. For this type of nonlinearity, we present an efficient approach for computing a regularized strain rate which is then used to define the nodewise viscosity. Depending on the compute architecture, we could observe maximum speedups of 64\% and 122\% compared to the on-the-fly integration. The largest considered example involved solving a Stokes problem with 12288 compute cores on the state-of-the-art supercomputer SuperMUC-NG.},
  archive      = {J_SISC},
  author       = {Daniel Drzisga and Ulrich Rüde and Barbara Wohlmuth},
  doi          = {10.1137/19M1267891},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {6},
  pages        = {B1429-B1461},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Stencil scaling for vector-valued PDEs on hybrid grids with applications to generalized newtonian fluids},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A multilayer nonlinear elimination preconditioned inexact
newton method for steady-state incompressible flow problems in three
dimensions. <em>SISC</em>, <em>42</em>(6), B1404–B1428. (<a
href="https://doi.org/10.1137/19M1307184">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a multilayer nonlinear elimination preconditioned inexact Newton method for a nonlinear algebraic system of equations, and a target application is the three-dimensional steady-state incompressible Navier--Stokes equations at high Reynolds numbers. Nonlinear steady-state problems are often more difficult to solve than time-dependent problems because the Jacobian matrix is less diagonally dominant, and a good initial guess from the previous time step is not available. For such problems, Newton-like methods may suffer from slow convergence or stagnation even with globalization techniques such as line search. In this paper, we introduce a cascadic multilayer nonlinear elimination approach based on feedback from intermediate solutions to improve the convergence of Newton iteration. Numerical experiments show that the proposed algorithm is superior to the classical inexact Newton method and other single layer nonlinear elimination approaches in terms of the robustness and efficiency. Using the proposed nonlinear preconditioner with a highly parallel domain decomposition framework, we demonstrate that steady solutions of the Navier--Stokes equations with Reynolds numbers as large as 7,500 can be obtained for the lid-driven cavity flow problem in three dimensions without the use of any continuation methods.},
  archive      = {J_SISC},
  author       = {Li Luo and Xiao-Chuan Cai and Zhengzheng Yan and Lei Xu and David E. Keyes},
  doi          = {10.1137/19M1307184},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {6},
  pages        = {B1404-B1428},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A multilayer nonlinear elimination preconditioned inexact newton method for steady-state incompressible flow problems in three dimensions},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Malliavin–mancino estimators implemented with nonuniform
fast fourier transforms. <em>SISC</em>, <em>42</em>(6), B1378–B1403. (<a
href="https://doi.org/10.1137/20M1325903">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We implement and test kernel averaging nonuniform fast Fourier transform (NUFFT) methods to enhance the performance of correlation and covariance estimation on asynchronously sampled event data using the Malliavin--Mancino Fourier estimator. The methods are benchmarked for Dirichlet and Fejér Fourier basis kernels. We consider test cases formed from geometric Brownian motions to replicate synchronous and asynchronous data for benchmarking purposes. We consider three standard averaging kernels to convolve the event data for synchronization via oversampling for use with the FFT: the Gaussian kernel, the Kaiser--Bessel kernel, and the exponential of semicircle kernel. First, this allows us to demonstrate the performance of the estimator with different combinations of basis kernels and averaging kernels. Second, we investigate and compare the impact of the averaging scales explicit in each averaging kernel and its relationship with the time-scale averaging implicit in the Malliavin--Mancino estimator. Third, we compare the relationship between time-scale averaging based on the number of Fourier coefficients used in the estimator to a theoretical model of the Epps effect. We briefly demonstrate the methods on trade-and-quote (TAQ) data from the Johannesburg Stock Exchange to make an initial visualization of the correlation dynamics for various time scales under market microstructure.},
  archive      = {J_SISC},
  author       = {Patrick Chang and Etienne Pienaar and Tim Gebbie},
  doi          = {10.1137/20M1325903},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {6},
  pages        = {B1378-B1403},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Malliavin--mancino estimators implemented with nonuniform fast fourier transforms},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient numerical methods for computing the stationary
states of phase field crystal models. <em>SISC</em>, <em>42</em>(6),
B1350–B1377. (<a href="https://doi.org/10.1137/20M1321176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding the stationary states of a free energy functional is an important problem in phase field crystal (PFC) models. Many efforts have been devoted to designing numerical schemes with energy dissipation and mass conservation properties. However, most existing approaches are time-consuming due to the requirement of small effective step sizes. In this paper, we discretize the energy functional and propose efficient numerical algorithms for solving the constrained nonconvex minimization problem. A class of gradient-based approaches, which are the so-called adaptive accelerated Bregman proximal gradient (AA-BPG) methods, is proposed, and the convergence property is established without the global Lipschitz constant requirements. A practical Newton method is also designed to further accelerate the local convergence with convergence guarantee. One key feature of our algorithms is that the energy dissipation and mass conservation properties hold during the iteration process. Moreover, we develop a hybrid acceleration framework to accelerate the AA-BPG methods and most of the existing approaches through coupling with the practical Newton method. Extensive numerical experiments, including two three-dimensional periodic crystals in the Landau--Brazovskii (LB) model and a two-dimensional quasicrystal in the Lifshitz--Petrich (LP) model, demonstrate that our approaches have adaptive step sizes which lead to a significant acceleration over many existing methods when computing complex structures.},
  archive      = {J_SISC},
  author       = {Kai Jiang and Wei Si and Chang Chen and Chenglong Bao},
  doi          = {10.1137/20M1321176},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {6},
  pages        = {B1350-B1377},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Efficient numerical methods for computing the stationary states of phase field crystal models},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An augmented lagrangian preconditioner for implicitly
constituted non-newtonian incompressible flow. <em>SISC</em>,
<em>42</em>(6), B1329–B1349. (<a
href="https://doi.org/10.1137/20M1336618">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an augmented Lagrangian preconditioner for a three-field stress-velocity-pressure discretization of stationary non-Newtonian incompressible flow with an implicit constitutive relation of power-law type. The discretization employed makes use of the divergence-free Scott--Vogelius pair for the velocity and pressure. The preconditioner builds on the work [P. E. Farrell, L. Mitchell, and F. Wechsung, SIAM J. Sci. Comput., 41 (2019), pp. A3073--A3096], where a Reynolds-robust preconditioner for the three-dimensional Newtonian system was introduced. The preconditioner employs a specialized multigrid method for the stress-velocity block that involves a divergence-capturing space decomposition and a custom prolongation operator. The solver exhibits excellent robustness with respect to the parameters arising in the constitutive relation, allowing for the simulation of a wide range of materials.},
  archive      = {J_SISC},
  author       = {P. E. Farrell and P. A. Gazca-Orozco},
  doi          = {10.1137/20M1336618},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {6},
  pages        = {B1329-B1349},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {An augmented lagrangian preconditioner for implicitly constituted non-newtonian incompressible flow},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Three-precision GMRES-based iterative refinement for least
squares problems. <em>SISC</em>, <em>42</em>(6), A4063–A4083. (<a
href="https://doi.org/10.1137/20M1316822">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The standard iterative refinement procedure for improving an approximate solution to the least squares problem $\min_x\|b - Ax\|_2$, where $A\in\mathbb{R}^{m\times n}$ with $m \ge n$ has full rank, is based on solving the $(m+n)\times (m+n)$ augmented system with the aid of a QR factorization. In order to exploit multiprecision arithmetic, iterative refinement can be formulated to use three precisions, but the resulting algorithm converges only for a limited range of problems. We build an iterative refinement algorithm called GMRES-LSIR, analogous to the GMRES-IR algorithm developed for linear systems [E. Carson and N. J. Higham, SIAM J. Sci. Comput., 40 (2018), pp. A817--A847], that solves the augmented system using GMRES preconditioned by a matrix based on the computed QR factors. We explore two left preconditioners; the first has full off-diagonal blocks, and the second is block diagonal and can be applied in either left-sided or split form. We prove that for a wide range of problems the first preconditioner yields backward and forward errors for the augmented system of order the working precision under suitable assumptions on the precisions and the problem conditioning. Our proof does not extend to the block diagonal preconditioner, but our numerical experiments show that with this preconditioner the algorithm performs about as well in practice. The experiments also show that if we use MINRES in place of GMRES then the convergence is similar for sufficiently well conditioned problems but worse for the most ill conditioned ones.},
  archive      = {J_SISC},
  author       = {Erin Carson and Nicholas J. Higham and Srikara Pranesh},
  doi          = {10.1137/20M1316822},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {6},
  pages        = {A4063-A4083},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Three-precision GMRES-based iterative refinement for least squares problems},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Recursive, parameter-free, explicitly defined interpolation
nodes for simplices. <em>SISC</em>, <em>42</em>(6), A4046–A4062. (<a
href="https://doi.org/10.1137/20M1321802">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A rule for constructing interpolation nodes for (n)th degree polynomials on the simplex is presented. These nodes are simple to define recursively from families of 1D node sets, such as the Lobatto--Gauss--Legendre (LGL) nodes. The resulting nodes have attractive properties: they are fully symmetric, they match the 1D family used in construction on the edges of the simplex, and the nodes constructed for the ((d-1))-simplex are the boundary traces of the nodes constructed for the (d)-simplex. When compared using the Lebesgue constant to other explicit rules for defining interpolation nodes, the nodes recursively constructed from LGL nodes are nearly as good as the warp &amp; blend nodes of Warburton [J. Engrg. Math., 56 (2006), pp. 247--262] in 2D (which, though defined differently, are very similar) and in 3D are better than other known explicit rules by increasing margins for (n &gt; 6). By that same measure, these recursively defined nodes are not as good as implicitly defined nodes found by optimizing the Lebesgue constant or related functions, but such optimal node sets have yet to be computed for the tetrahedron. A reference Python implementation has been distributed as the recursivenodes package, but the simplicity of the recursive construction makes them easy to implement.},
  archive      = {J_SISC},
  author       = {Tobin Isaac},
  doi          = {10.1137/20M1321802},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {6},
  pages        = {A4046-A4062},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Recursive, parameter-free, explicitly defined interpolation nodes for simplices},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). <span class="math inline">ℋ<sub>2</sub></span>-optimal model
reduction using projected nonlinear least squares. <em>SISC</em>,
<em>42</em>(6), A4017–A4045. (<a
href="https://doi.org/10.1137/19M1247863">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many applications throughout science and engineering, model reduction plays an important role replacing expensive large-scale linear dynamical systems by inexpensive reduced order models that capture key features of the original, full order model. One approach to model reduction finds reduced order models that are locally optimal approximations in the $\mathcal{H}_2$-norm, an approach taken by the iterative rational Krylov algorithm (IRKA), among others. Here we introduce a new approach for $\mathcal{H}_2$-optimal model reduction using the projected nonlinear least squares framework previously introduced in [J. M. Hokanson, SIAM J. Sci. Comput., 39 (2017), pp. A3107--A3128]. At each iteration, we project the $\mathcal{H}_2$ optimization problem onto a finite-dimensional subspace yielding a weighted least squares rational approximation problem. Subsequent iterations append this subspace such that the least squares rational approximant asymptotically satisfies the first order necessary conditions of the original, $\mathcal{H}_2$ optimization problem. This enables us to build reduced order models with similar error in the $\mathcal{H}_2$-norm but using far fewer evaluations of the expensive, full order model compared to competing methods. Moreover, our new algorithm only requires access to the transfer function of the full order model, unlike IRKA, which requires a state-space representation, or TF-IRKA, which requires both the transfer function and its derivative. Applying the projected nonlinear least squares framework to the $\mathcal{H}_2$-optimal model reduction problem opens new avenues for related model reduction problems.},
  archive      = {J_SISC},
  author       = {Jeffrey M. Hokanson and Caleb C. Magruder},
  doi          = {10.1137/19M1247863},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {6},
  pages        = {A4017-A4045},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {$\mathcal{H}_2$-optimal model reduction using projected nonlinear least squares},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Convergence analysis of inexact randomized iterative
methods. <em>SISC</em>, <em>42</em>(6), A3979–A4016. (<a
href="https://doi.org/10.1137/19M125248X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we present a convergence rate analysis of inexact variants of several randomized iterative methods for solving three closely related problems: a convex stochastic quadratic optimization problem, a best approximation problem, and its dual, a concave quadratic maximization problem. Among the methods studied are stochastic gradient descent, stochastic Newton, stochastic proximal point, and stochastic subspace ascent. A common feature of these methods is that in their update rule a certain subproblem needs to be solved exactly. We relax this requirement by allowing for the subproblem to be solved inexactly. We provide iteration complexity results under several assumptions on the inexactness error. Inexact variants of many popular and some more exotic methods, including randomized block Kaczmarz, Gaussian block Kaczmarz, and randomized block coordinate descent, can be cast as special cases. Numerical experiments demonstrate the benefits of allowing inexactness.},
  archive      = {J_SISC},
  author       = {Nicolas Loizou and Peter Richtárik},
  doi          = {10.1137/19M125248X},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {6},
  pages        = {A3979-A4016},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Convergence analysis of inexact randomized iterative methods},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Arbitrarily high-order exponential cut-off methods for
preserving maximum principle of parabolic equations. <em>SISC</em>,
<em>42</em>(6), A3957–A3978. (<a
href="https://doi.org/10.1137/20M1333456">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new class of high-order maximum principle preserving numerical methods is proposed for solving parabolic equations, with application to the semilinear Allen--Cahn equation. The proposed method consists of a $k$th-order multistep exponential integrator in time and a lumped mass finite element method in space with piecewise $r$th-order polynomials and Gauss--Lobatto quadrature. At every time level, the extra values violating the maximum principle are eliminated at the finite element nodal points by a cut-off operation. The remaining values at the nodal points satisfy the maximum principle and are proved to be convergent with an error bound of $O(\tau^k+h^r)$. The accuracy can be made arbitrarily high-order by choosing large $k$ and $r$. Extensive numerical results are provided to illustrate the accuracy of the proposed method and the effectiveness in capturing the pattern of phase-field problems.},
  archive      = {J_SISC},
  author       = {Buyang Li and Jiang Yang and Zhi Zhou},
  doi          = {10.1137/20M1333456},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {6},
  pages        = {A3957-A3978},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Arbitrarily high-order exponential cut-off methods for preserving maximum principle of parabolic equations},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fifth-order a-WENO finite-difference schemes based on a new
adaptive diffusion central numerical flux. <em>SISC</em>,
<em>42</em>(6), A3932–A3956. (<a
href="https://doi.org/10.1137/20M1327926">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new adaptive diffusion central numerical flux within the framework of fifth-order characteristicwise alternative WENO-Z finite-difference schemes (A-WENO) with a modified local Lax--Friedrichs (LLF) flux for the Euler equations of gas dynamics is introduced. The new numerical flux adaptively adjusts the numerical diffusion coefficient present in the LLF flux. The coefficient is estimated by a suitable Rankine--Hugoniot condition, which gives a more accurate estimation of the local speed of propagation. To ensure robustness, lower and upper bounds of the coefficient are obtained with the help of the convection-pressure splitting of the Jacobian. The proposed adaptive A-WENO scheme is tested on several one- and two-dimensional benchmarks. The obtained results demonstrate that the use of the adaptive diffusion central numerical flux enhances the resolution of contact waves and improves significantly the resolution of fine-scale structures in the smooth areas of the solution while capturing shocks and high gradients in an essentially nonoscillatory manner.},
  archive      = {J_SISC},
  author       = {Bao-Shan Wang and Wai Sun Don and Naveen K. Garg and Alexander Kurganov},
  doi          = {10.1137/20M1327926},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {6},
  pages        = {A3932-A3956},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Fifth-order A-WENO finite-difference schemes based on a new adaptive diffusion central numerical flux},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sparse hierarchical preconditioners using piecewise smooth
approximations of eigenvectors. <em>SISC</em>, <em>42</em>(6),
A3907–A3931. (<a href="https://doi.org/10.1137/20M1315683">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When solving linear systems arising from PDE discretizations, iterative methods (such as conjugate gradient (CG), GMRES, or MINRES) are often the only practical choice. To converge in a small number of iterations, however, they have to be coupled with an efficient preconditioner. One approach to preconditioning is provided by the hierarchical approximate factorization methods. However, to guarantee sufficient accuracy on the eigenvectors corresponding to the smallest eigenvalues, these methods typically have to be performed at very stringent accuracies, making the preconditioner expensive to apply. On the other hand, for a large class of problems, including many elliptic equations, the eigenvectors corresponding to small eigenvalues are smooth functions of the PDE grid. In this paper, we describe a hierarchical approximate factorization approach which focuses on improving accuracy on the smooth eigenvectors. The improved accuracy is achieved by preserving the action of the factorized matrix on piecewise polynomial functions of the grid. Based on the factorization, we propose a family of sparse preconditioners with $\mathcal{O}({n})$ or $\mathcal{O}({n \log{n}})$ construction complexities. Our methods exhibit rapid convergence of CG in benchmarks run on large elliptic problems, arising for example in flow or mechanical simulations. In the case of the linear elasticity equation the preconditioners are exact on the near-kernel rigid body modes.},
  archive      = {J_SISC},
  author       = {Bazyli Klockiewicz and Eric Darve},
  doi          = {10.1137/20M1315683},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {6},
  pages        = {A3907-A3931},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Sparse hierarchical preconditioners using piecewise smooth approximations of eigenvectors},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bayesian mesh adaptation for estimating distributed
parameters. <em>SISC</em>, <em>42</em>(6), A3878–A3906. (<a
href="https://doi.org/10.1137/20M1326222">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of estimating numerically a distributed parameter from indirect measurements arises in many applications, and in that context the choice of the discretization plays an important role. In fact, guaranteeing a certain level of accuracy of the forward model that maps the unknown to the observations may require a fine discretization, adding to the complexity of the problem and to the computational cost. On the other hand, reducing the complexity of the problem by adopting a coarser discretization may increase the modeling error and can be very detrimental for ill-posed inverse problems. To balance accuracy and complexity, we propose an adaptive algorithm for adjusting the discretization level automatically and dynamically while estimating the unknown distributed parameter by an iterative scheme. In the Bayesian paradigm, all unknowns, including the metric that defines the discretization, are modeled as random variables. Our approach couples the discretization with a Bayesian hierarchical hyperparameter that is estimated simultaneously with the unknown parameter of primary interest. The viability of the proposed algorithm, the Bayesian mesh adaptation (BMA) is assessed on two test cases: a fan-beam X-ray tomography problem and an inverse source problem for a Darcy flow model.},
  archive      = {J_SISC},
  author       = {Daniela Calvetti and Anna Cosmo and Simona Perotto and Erkki Somersalo},
  doi          = {10.1137/20M1326222},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {6},
  pages        = {A3878-A3906},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Bayesian mesh adaptation for estimating distributed parameters},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Simple curl-curl-conforming finite elements in two
dimensions. <em>SISC</em>, <em>42</em>(6), A3859–A3877. (<a
href="https://doi.org/10.1137/20M1333390">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We construct smooth finite element de Rham complexes in two space dimensions. This leads to three families of curl-curl-conforming finite elements, two of which contain two existing families. The simplest triangular and rectangular finite elements have only six and eight degrees of freedom, respectively. Numerical experiments for each family demonstrate the convergence and efficiency of the elements for solving the quad-curl problem.},
  archive      = {J_SISC},
  author       = {Kaibo Hu and Qian Zhang and Zhimin Zhang},
  doi          = {10.1137/20M1333390},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {6},
  pages        = {A3859-A3877},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Simple curl-curl-conforming finite elements in two dimensions},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A combined-mode fourier analysis of DG methods for linear
parabolic problems. <em>SISC</em>, <em>42</em>(6), A3825–A3858. (<a
href="https://doi.org/10.1137/20M1316962">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fourier analysis has been shown to provide valuable insight into the dispersion and dissipation characteristics of numerical schemes for PDEs. Applying Fourier analysis to discontinuous Galerkin (DG) methods results in an eigenvalue problem with multiple eigenmodes. It was often relied on one of these modes, the so-called physical-mode, for studying the dispersion and dissipation behavior. The effect of the other modes was considered spurious and typically neglected. Recently, a new approach, the combined-mode approach, was proposed for the linear wave equation, in which all modes are considered. In this paper, we apply the combined-mode approach to a number of DG methods for diffusion. We show that for the linear parabolic heat equation, the physical-mode behavior is completely different than the exact diffusion, over a wide range of wavenumbers, and sometimes nondissipative. In contrast, the combined-mode behavior is more consistent and sufficiently accurate in comparison with the exact diffusion for the whole wavenumber range. This approach also revealed that short time and long time diffusion behaviors are very different for high-order multi--degrees of freedom methods. Additionally, using this approach we conduct a comparative diffusion analysis between a number of popular DG methods for diffusion in one and two dimensions. We also provide a study on the influence of the penalty parameter on their behavior. The considered methods include the symmetric interior penalty, Bassi and Rebay, and the local and compact DG methods. The results are verified numerically through several test cases.},
  archive      = {J_SISC},
  author       = {Mohammad Alhawwary and Zhijian Wang},
  doi          = {10.1137/20M1316962},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {6},
  pages        = {A3825-A3858},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A combined-mode fourier analysis of DG methods for linear parabolic problems},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Tensor completion via gaussian process–based initialization.
<em>SISC</em>, <em>42</em>(6), A3812–A3824. (<a
href="https://doi.org/10.1137/19M1306518">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the tensor completion problem representing the solution in the tensor train (TT) format. It is assumed that the tensor is of high order, and tensor values are generated by an unknown smooth function. The assumption allows us to develop an efficient initialization scheme based on Gaussian process regression and the TT-cross approximation technique. The proposed approach can be used in conjunction with any optimization algorithm that is usually utilized in tensor completion problems. We empirically justify that in this case the reconstruction error improves compared to the tensor completion with random initialization. As an additional benefit, our technique automatically selects rank thanks to using the TT-cross approximation technique.},
  archive      = {J_SISC},
  author       = {Yermek Kapushev and Ivan Oseledets and Evgeny Burnaev},
  doi          = {10.1137/19M1306518},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {6},
  pages        = {A3812-A3824},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Tensor completion via gaussian process--based initialization},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A continuous analysis of neumann–neumann methods:
Scalability and new coarse spaces. <em>SISC</em>, <em>42</em>(6),
A3785–A3811. (<a href="https://doi.org/10.1137/20M1316317">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a new coarse space correction for the iterative Neumann--Neumann method. We describe the method for general elliptic partial differential equations and perform the analysis for the case of the Poisson and screened Poisson equation (sometimes also called the positive definite Helmholtz equation). We prove that the new two-level Neumann--Neumann method converges after one iteration, at both the continuous and discrete levels, which means the new coarse space is optimal in the sense of best possible, and it makes the two-level method a direct solver. In two and three space dimensions, the new coarse space is too high dimensional in practice, and we introduce a spectral approximation, which transforms a divergent iterative Neumann--Neumann method into a convergent one. We also identify what the optimized choice of coarse space functions is in the approximation. Our new coarse space thus also addresses convergence or robustness problems of the underlying domain decomposition iteration, similarly to the new coarse spaces GenEO, SHEM, and ACMS, which were designed to treat different convergence difficulties of the underlying domain decomposition method, namely the presence of high contrast media. Several numerical experiments are carried out to demonstrate the performance of this new coarse space correction, also including decompositions with cross points.},
  archive      = {J_SISC},
  author       = {Faycal Chaouqui and Martin J. Gander and Kévin Santugini-Repiquet},
  doi          = {10.1137/20M1316317},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {6},
  pages        = {A3785-A3811},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A continuous analysis of neumann--neumann methods: Scalability and new coarse spaces},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sparsity promoting hybrid solvers for hierarchical bayesian
inverse problems. <em>SISC</em>, <em>42</em>(6), A3761–A3784. (<a
href="https://doi.org/10.1137/20M1326246">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recovery of sparse generative models from few noisy measurements is an important and challenging problem. Many deterministic algorithms rely on some form of $\ell_1$-$\ell_2$ minimization to combine the computational convenience of the $\ell_2$ penalty and the sparsity promotion of the $\ell_1$. It was recently shown within the Bayesian framework that sparsity promotion and computational efficiency can be attained with hierarchical models with conditionally Gaussian priors and gamma hyperpriors. The related Gibbs energy function is a convex functional, and its minimizer, which is the maximum a posteriori (MAP) estimate of the posterior, can be computed efficiently with the globally convergent Iterated Alternating Sequential (IAS) algorithm [D. Calvetti, E. Somersalo, and A. Strang, Inverse Problems, 35 (2019), 035003]. Generalization of the hyperpriors for these sparsity promoting hierarchical models to a generalized gamma family either yield globally convex Gibbs energy functionals or can exhibit local convexity for some choices for the hyperparameters [D. Calvetti et al., Inverse Problems, 36 (2020), 025010]. The main problem in computing the MAP solution for greedy hyperpriors that strongly promote sparsity is the presence of local minima. To overcome the premature stopping at a spurious local minimizer, we propose two hybrid algorithms that first exploit the global convergence associated with gamma hyperpriors to arrive in a neighborhood of the unique minimizer and then adopt a generalized gamma hyperprior that promotes sparsity more strongly. The performance of the two algorithms is illustrated with computed examples.},
  archive      = {J_SISC},
  author       = {Daniela Calvetti and Monica Pragliola and Erkki Somersalo},
  doi          = {10.1137/20M1326246},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {6},
  pages        = {A3761-A3784},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Sparsity promoting hybrid solvers for hierarchical bayesian inverse problems},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A high-order, conservative integrator with local
time-stepping. <em>SISC</em>, <em>42</em>(6), A3730–A3760. (<a
href="https://doi.org/10.1137/19M1292692">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a family of multistep integrators based on the Adams--Bashforth methods. These schemes can be constructed for arbitrary convergence order with arbitrary step size variation. The step size can differ between different subdomains of the system. It can also change with time within a given subdomain. The methods are linearly conservative, preserving a wide class of analytically constant quantities to numerical roundoff, even when numerical truncation error is significantly higher. These methods are intended for use in solving conservative PDEs in discontinuous Galerkin formulations or in finite-difference methods with compact stencils. A numerical test demonstrates these properties and shows that significant speed improvements over the standard Adams--Bashforth schemes can be obtained.},
  archive      = {J_SISC},
  author       = {William Throwe and Saul Teukolsky},
  doi          = {10.1137/19M1292692},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {6},
  pages        = {A3730-A3760},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A high-order, conservative integrator with local time-stepping},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Structure-preserving method for reconstructing unknown
hamiltonian systems from trajectory data. <em>SISC</em>, <em>42</em>(6),
A3704–A3729. (<a href="https://doi.org/10.1137/19M1264011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a numerical approach for approximating unknown Hamiltonian systems using observational data. A distinct feature of the proposed method is that it is structure-preserving, in the sense that it enforces the conservation of the reconstructed Hamiltonian. This is achieved by directly approximating the underlying unknown Hamiltonian, rather than the right-hand side of the governing equations. We present the technical details of the proposed algorithm and its error estimate in a special case, along with a practical denoising procedure to cope with noisy data. A set of numerical examples is presented to demonstrate the structure-preserving property and effectiveness of the algorithm.},
  archive      = {J_SISC},
  author       = {Kailiang Wu and Tong Qin and Dongbin Xiu},
  doi          = {10.1137/19M1264011},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {6},
  pages        = {A3704-A3729},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Structure-preserving method for reconstructing unknown hamiltonian systems from trajectory data},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A stabilized DG cut cell method for discretizing the linear
transport equation. <em>SISC</em>, <em>42</em>(6), A3677–A3703. (<a
href="https://doi.org/10.1137/19M1268318">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present new stabilization terms for solving the linear transport equation on a cut cell mesh using the discontinuous Galerkin (DG) method in two dimensions with piecewise linear polynomials. The goal is to allow for explicit time stepping schemes despite the presence of cut cells. Using a method of lines approach, we start with a standard upwind DG discretization for the background mesh and add penalty terms that stabilize the solution on small cut cells in a conservative way. Then one can use explicit time stepping, even on cut cells, with a time step length that is appropriate for the background mesh. In one dimension, we show monotonicity of the proposed scheme with a constant basis and total variation diminishing in the means stability for piecewise linear polynomials. We also present numerical results in one and two dimensions that support our theoretical findings.},
  archive      = {J_SISC},
  author       = {Christian Engwer and Sandra May and Andreas Nüßing and Florian Streitbürger},
  doi          = {10.1137/19M1268318},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {6},
  pages        = {A3677-A3703},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A stabilized DG cut cell method for discretizing the linear transport equation},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Primal-dual reduced basis methods for convex minimization
variational problems: Robust true solution a posteriori error
certification and adaptive greedy algorithms. <em>SISC</em>,
<em>42</em>(6), A3638–A3676. (<a
href="https://doi.org/10.1137/19M1281551">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The a posteriori error estimate and greedy algorithms play central roles in the reduced basis method (RBM). In [M. Yano, Comput. Methods Appl. Mech. Engrg., 287 (2015), pp. 290--309; ESAIM Math. Model. Numer. Anal., 50 (2016), pp. 163--185; SIAM J. Sci. Comput., 40 (2018), pp. A388--A420], several versions of RBMs based on exact error certifications and greedy algorithms with spatio-parameter adaptivities are developed. In this paper, with the parametric symmetric coercive elliptic boundary value problem as an example of the primal-dual variational problems satisfying the strong duality, we develop primal-dual RBMs (PD-RBM) with robust true error certifications and discuss three versions of greedy algorithms to balance the finite element error, the exact RB error, and the adaptive mesh refinements. For a class of convex minimization variational problems which has corresponding dual problems satisfying the strong duality, the primal-dual gap between the primal and dual functionals can be used as an a posteriori error estimator. This primal-dual gap error estimator is robust with respect to the parameters of the problem, and it can be used for both mesh refinements of finite element methods and the true RB error certification. With the help of an integration by parts formula, the primal-dual variational theory is developed for the symmetric coercive elliptic boundary value problems with nonhomogeneous boundary conditions by both the conjugate function and Lagrangian theories. A generalized Prager--Synge identity, which is the primal-dual gap error representation for this specific problem, is developed. RBMs for both the primal and dual problems with robust error estimates are developed. The dual variational problem often can be viewed as a constraint optimization problem. In the paper, different from the standard saddle-point finite element approximation, the dual RBM is treated as a Galerkin projection by constructing RB spaces satisfying the homogeneous constraint. Inspired by the greedy algorithm with spatio-parameter adaptivity of [M. Yano, SIAM J. Sci. Comput., 40 (2018), pp. A388--A420], adaptive balanced greedy algorithms with primal-dual finite element and RB error estimators are discussed. Numerical tests are presented to test the PD-RBM with adaptive balanced greedy algorithms.},
  archive      = {J_SISC},
  author       = {Shun Zhang},
  doi          = {10.1137/19M1281551},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {6},
  pages        = {A3638-A3676},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Primal-dual reduced basis methods for convex minimization variational problems: Robust true solution a posteriori error certification and adaptive greedy algorithms},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A robust numerical path tracking algorithm for polynomial
homotopy continuation. <em>SISC</em>, <em>42</em>(6), A3610–A3637. (<a
href="https://doi.org/10.1137/19M1288036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new algorithm for numerical path tracking in polynomial homotopy continuation. The algorithm is “robust” in the sense that it is designed to prevent path jumping, and in many cases it can be used in (only) double precision arithmetic. It is based on an adaptive stepsize predictor that uses Padé techniques to detect local difficulties for function approximation and danger for path jumping. We show the potential of the new path tracking algorithm through several numerical examples and compare it with existing implementations.},
  archive      = {J_SISC},
  author       = {Simon Telen and Marc Van Barel and Jan Verschelde},
  doi          = {10.1137/19M1288036},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {6},
  pages        = {A3610-A3637},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A robust numerical path tracking algorithm for polynomial homotopy continuation},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Schwarz solvers and preconditioners for the closest point
method. <em>SISC</em>, <em>42</em>(6), A3584–A3609. (<a
href="https://doi.org/10.1137/19M1288279">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The discretization of surface intrinsic elliptic partial differential equations (PDEs) poses interesting challenges not seen in flat spaces. The discretization of these PDEs typically proceeds by either parametrizing the surface, triangulating the surface, or embedding the surface in a higher dimensional flat space. The closest point method (CPM) is an embedding method that represents surfaces using a function that maps points in the embedding space to their closest points on the surface. In the CPM, this mapping also serves as an extension operator that brings surface intrinsic data onto the embedding space, allowing PDEs to be numerically approximated by standard methods in a narrow tubular neighborhood of the surface. We focus on numerically approximating the positive Helmholtz equation, $\left(c-\Delta_{\mathcal{S}}\right)u=f,~c\in\mathbb{R}^+$, by the CPM paired with finite differences. This yields a large, sparse, and nonsymmetric system to be solved. Herein, we develop restricted additive Schwarz (RAS) and optimized restricted additive Schwarz (ORAS) solvers and preconditioners for this discrete system. In particular, we develop a general strategy for computing overlapping partitions of the computational domain and defining the corresponding Dirichlet and Robin transmission conditions. We demonstrate that the convergence of the ORAS solvers and preconditioners can be improved by using a modified transmission condition where more than two overlapping subdomains meet. Numerical experiments are provided for a variety of analytical and triangulated surfaces. We find that ORAS solvers and preconditioners outperform their RAS counterparts and that, as expected using domain decomposition (DD) as a preconditioner rather than as a solver gives faster convergence. The methods exhibit good parallel scalability over the range of process counts tested.},
  archive      = {J_SISC},
  author       = {Ian C. T. May and Ronald D. Haynes and Steven J. Ruuth},
  doi          = {10.1137/19M1288279},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {6},
  pages        = {A3584-A3609},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Schwarz solvers and preconditioners for the closest point method},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Anderson accelerated douglas–rachford splitting.
<em>SISC</em>, <em>42</em>(6), A3560–A3583. (<a
href="https://doi.org/10.1137/19M1290097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of nonsmooth convex optimization with linear equality constraints, where the objective function is only accessible through its proximal operator. This problem arises in many different fields such as statistical learning, computational imaging, telecommunications, and optimal control. To solve it, we propose an Anderson accelerated Douglas--Rachford splitting (A2DR) algorithm, which we show either globally converges or provides a certificate of infeasibility/unboundedness under very mild conditions. Applied to a block separable objective, A2DR partially decouples so that its steps may be carried out in parallel, yielding an algorithm that is fast and scalable to multiple processors. We describe an open-source implementation and demonstrate its performance on a wide range of examples.},
  archive      = {J_SISC},
  author       = {Anqi Fu and Junzi Zhang and Stephen Boyd},
  doi          = {10.1137/19M1290097},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {6},
  pages        = {A3560-A3583},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Anderson accelerated douglas--rachford splitting},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Randomized extended average block kaczmarz for solving least
squares. <em>SISC</em>, <em>42</em>(6), A3541–A3559. (<a
href="https://doi.org/10.1137/20M1312629">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Randomized iterative algorithms have recently been proposed to solve large-scale linear systems. In this paper, we present a simple randomized extended average block Kaczmarz algorithm that exponentially converges in the mean square to the unique minimum norm least squares solution of a given linear system of equations. The proposed algorithm is pseudoinverse-free and therefore different from the projection-based randomized double block Kaczmarz algorithm of Needell, Zhao, and Zouzias [Linear Algebra Appl., 484 (2015), pp. 322--343]. We emphasize that our method works for all types of linear systems (consistent or inconsistent, overdetermined or underdetermined, full-rank or rank-deficient). Moreover, our approach can be implemented for parallel computation, yielding remarkable improvements in computational time. Numerical examples are given to show the efficiency of the new algorithm.},
  archive      = {J_SISC},
  author       = {Kui Du and Wu-Tao Si and Xiao-Hui Sun},
  doi          = {10.1137/20M1312629},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {6},
  pages        = {A3541-A3559},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Randomized extended average block kaczmarz for solving least squares},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Parallel energy-stable solver for a coupled allen–cahn and
cahn–hilliard system. <em>SISC</em>, <em>42</em>(5), C294–C312. (<a
href="https://doi.org/10.1137/20M1331160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study numerical methods for solving the coupled Allen--Cahn/Cahn--Hilliard system associated with a free energy functional of logarithmic type. To tackle the challenge posed by the special free energy functional, we propose a method to approximate the discrete variational derivatives in polynomial forms, such that the corresponding finite difference scheme is unconditionally energy stable and the energy dissipation law is maintained. To further improve the performance of the algorithm, a modified adaptive time stepping strategy is adopted such that the time step size can be flexibly controlled based on the dynamical evolution of the problem. To achieve high performance on parallel computers, we introduce a domain decomposition based, parallel Newton--Krylov--Schwarz method to solve the nonlinear algebraic system constructed from the discretization at each time step. Numerical experiments show that the proposed algorithm is second-order accurate in both space and time, energy stable with large time steps, and highly scalable to over ten thousands processor cores on the Sunway TaihuLight supercomputer.},
  archive      = {J_SISC},
  author       = {Jizu Huang and Chao Yang and Ying Wei},
  doi          = {10.1137/20M1331160},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {C294-C312},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Parallel energy-stable solver for a coupled allen--cahn and cahn--hilliard system},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The LAPW method with eigendecomposition based on the
hari–zimmermann generalized hyperbolic SVD. <em>SISC</em>,
<em>42</em>(5), C265–C293. (<a
href="https://doi.org/10.1137/19M1277813">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose an accurate, highly parallel algorithm for the generalized eigendecomposition of a matrix pair $(H, S)$, given in a factored form $(F^{\ast} J F, G^{\ast} G)$. Matrices $H$ and $S$ are generally complex and Hermitian, and $S$ is positive definite. This type of matrix emerges from the representation of the Hamiltonian of a quantum mechanical system in terms of an overcomplete set of basis functions. This expansion is part of a class of models within the broad field of density functional theory, which is considered the gold standard in condensed matter physics. The overall algorithm consists of four phases, the second and fourth being optional, where the two last phases are a computation of the generalized hyperbolic singular value decomposition (SVD) of a complex matrix pair $(F,G)$, according to a given matrix $J$ defining the hyperbolic scalar product. If $J = I$, then these two phases compute the generalized SVD (GSVD) in parallel very accurately and efficiently.},
  archive      = {J_SISC},
  author       = {Sanja Singer and Edoardo Di Napoli and Vedran Novaković and Gayatri Čaklović},
  doi          = {10.1137/19M1277813},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {C265-C293},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {The LAPW method with eigendecomposition based on the hari--zimmermann generalized hyperbolic SVD},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A flexible framework for multidimensional DFTs.
<em>SISC</em>, <em>42</em>(5), C245–C264. (<a
href="https://doi.org/10.1137/19M1288401">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multidimensional discrete Fourier transforms (DFTs) are typically decomposed into multiple one-dimensional (1D) transforms. Hence, parallel implementations of any multidimentional DFT focus on parallelizing within or across the 1D DFT. Existing DFT packages exploit the inherent parallelism across the 1D DFTs and offer rigid frameworks, that cannot be extended to incorporate both forms of parallelism and various data layouts to enable some of the parallelism. However, in the era of exascale, where systems have thousand of nodes and intricate network topologies, flexibility and parallel efficiency are key aspects all multidimentional DFT frameworks need to have in order to map and scale the computation appropriately. In this work, we show the need for a versatile parallel framework that facilitates the development of a family of parallel multidimentional DFT algorithms by (1) using different data layouts to distribute the data across the compute nodes, (2) exploiting the two different parallelization schemes to different degrees, and (3) unifying the two parallelization schemes within a single framework. We show that the flexibility of selecting different parallel multidimentional DFT algorithms allows for almost linear strong scaling results for problem sizes of $1024^3$ on two supercomputers, namely, RIKEN&#39;s K-Computer and Oakridge&#39;s Summit.},
  archive      = {J_SISC},
  author       = {Doru Thom Popovici and Martin D. Schatz and Franz Franchetti and Tze Meng Low},
  doi          = {10.1137/19M1288401},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {C245-C264},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A flexible framework for multidimensional DFTs},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Implementing high-performance complex matrix multiplication
via the 1M method. <em>SISC</em>, <em>42</em>(5), C221–C244. (<a
href="https://doi.org/10.1137/19M1282040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Almost all efforts to optimize high-performance matrix-matrix multiplication have been focused on the case where matrices contain real elements. The community&#39;s collective assumption appears to have been that the techniques and methods developed for the real domain carry over directly to the complex domain. As a result, implementors have mostly overlooked a class of methods that compute complex matrix multiplication using only real matrix products. This is the second in a series of articles that investigate these so-called induced methods. In the previous article, we found that algorithms based on the more generally applicable of the two methods---the 4m method---lead to implementations that, for various reasons, often underperform their real domain counterparts. To overcome these limitations, we derive a superior 1m method for expressing complex matrix multiplication, one which addresses virtually all of the shortcomings inherent in 4m. Implementations are developed within the BLIS framework, and testing on microarchitectures by three vendors confirms that the 1m method yields performance that is generally competitive with solutions based on conventionally implemented complex kernels, sometimes even outperforming vendor libraries.},
  archive      = {J_SISC},
  author       = {Field G. Van Zee},
  doi          = {10.1137/19M1282040},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {C221-C244},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Implementing high-performance complex matrix multiplication via the 1M method},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A highly parallel multilevel newton–krylov–schwarz method
with subspace-based coarsening and partition-based balancing for the
multigroup neutron transport equation on three-dimensional unstructured
meshes. <em>SISC</em>, <em>42</em>(5), C193–C220. (<a
href="https://doi.org/10.1137/19M1249060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multigroup neutron transport equation is crucial for studying the motion of neutrons and their interaction with materials. Numerical simulation of the multigroup neutron transport equation is computationally challenging because the equation is defined on a high-dimensional phase space, the computational spatial domain is complex, and the materials are heterogeneous. A scalable parallel solver is required to address such a challenge. In this paper, we study a highly parallel Newton--Krylov--Schwarz (NKS) method consisting of a Newton-based eigenvalue solver, a Krylov subspace method, and a novel multilevel Schwarz preconditioner. The multilevel method is one of the most popular preconditioners for accelerating neutron transport calculations, but the construction of coarse spaces can be expensive and often unscalable when a large number of processors is used. We propose a novel matrix coarsening algorithm in which a multilevel hierarchy is constructed using a single-component matrix instead of the full matrix of the neutron transport equation. This new coarsening algorithm is referred to as “subspace-based coarsening.” Above 8,000 processors, we show a 13x enhancement in multilevel preconditioner setup time when using the subspace-based coarsening method. A partition-based balancing strategy is studied to enhance the parallel efficiency of the NKS algorithm by equalizing the work for each processor. A hierarchical mesh partitioning algorithm is employed to generate a large number of submeshes while minimizing off-node communication. We demonstrate that the proposed algorithm is scalable with more than 10,000 processors for a realistic application on three-dimensional unstructured meshes with a few billion degrees of freedom. Neutron transport calculations using the improved NKS algorithm are twice as fast as those based on the unmodified NKS solver when over 8,000 processors are employed.},
  archive      = {J_SISC},
  author       = {Fande Kong and Yaqi Wang and Derek R. Gaston and Cody J. Permann and Andrew E. Slaughter and Alexander D. Lindsay and Mark D. DeHart and Richard C. Martineau},
  doi          = {10.1137/19M1249060},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {C193-C220},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A highly parallel multilevel newton--krylov--schwarz method with subspace-based coarsening and partition-based balancing for the multigroup neutron transport equation on three-dimensional unstructured meshes},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A holistic algorithmic approach to improving accuracy,
robustness, and computational efficiency for atmospheric dynamics.
<em>SISC</em>, <em>42</em>(5), B1302–B1327. (<a
href="https://doi.org/10.1137/19M128435X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Atmospheric weather and climate models must perform simulations very quickly to be useful. Therefore, modelers have traditionally focused on reducing computations as much as possible. However, in our new era of increasingly compute-capable hardware, data movement is now the prohibiting expense. This study examines the computational benefits of a new algorithmic approach to modeling atmospheric dynamics on scales relevant to weather and climate simulation. Rather than minimizing computations, this new approach considers the larger problem more holistically, including spatial accuracy, temporal accuracy, robustness (i.e., oscillations), on-node efficiency, and internode data transfers together at once. Numerical experiments demonstrate how computations can be strategically increased to simultaneously address each of these constraints while reducing data movement to adapt to modern accelerated hardware. The new algorithm can achieve at times up to 80\% peak floating point throughput in single precision on the Nvidia Tesla V100 GPU, where the traditional approach is shown to only achieve single-digit floating point efficiency. Further, the new algorithm is twice as fast as a standard Runge--Kutta time integrator, and high-order accuracy with Weighted Essentially Non-Oscillatory (WENO) limiting came at less than 30\% additional runtime cost on a GPU, thus increasing the accuracy per degree of freedom.},
  archive      = {J_SISC},
  author       = {Matthew Norman and Jeffrey Larkin},
  doi          = {10.1137/19M128435X},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {B1302-B1327},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A holistic algorithmic approach to improving accuracy, robustness, and computational efficiency for atmospheric dynamics},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Diffusion synthetic acceleration preconditioning for
discontinuous galerkin discretizations of <span
class="math inline"><em>S</em><sub><em>N</em></sub></span> transport on
high-order curved meshes. <em>SISC</em>, <em>42</em>(5), B1271–B1301.
(<a href="https://doi.org/10.1137/19M124993X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper derives and analyzes new diffusion synthetic acceleration (DSA) preconditioners for the $S_N$ transport equation when discretized with a high-order (HO) discontinuous Galerkin (DG) discretization. DSA preconditioners address the need to accelerate the $S_N$ transport equation when the mean free path $\varepsilon$ of particles is small and the condition number of the $S_N$ transport equation scales like $\mathcal{O}( \varepsilon^{-2} )$. By expanding the $S_N$ transport operator in $\varepsilon$ and employing a rigorous singular matrix perturbation analysis, we derive a DSA matrix that reduces to the symmetric interior penalty (SIP) DG discretization of the standard continuum diffusion equation when the mesh is first-order and the total opacity is constant. We prove that preconditioning the HO DG $S_N$ transport equation with the SIP DSA matrix results in an $\mathcal{O}( \varepsilon )$ perturbation of the identity, and fixed-point iteration therefore converges rapidly for optically thick problems. However, the SIP DSA matrix is conditioned like $\mathcal{O}( \varepsilon^{-1} )$, making it difficult to invert for small $\varepsilon$. We further derive a new two-part, additive DSA preconditioner based on a continuous Galerkin discretization of diffusion-reaction, which has a condition number independent of $\varepsilon$, and prove that this DSA variant has the same theoretical efficiency as the SIP DSA preconditioner in the optically thick limit. The analysis is extended to the case of HO (curved) meshes, where so-called mesh cycles can result from elements both being upwind of each other (for a given discrete photon direction). In particular, we prove that performing two additional transport sweeps, with fixed scalar flux, in between DSA steps yields the same theoretical conditioning of fixed-point iterations as in the cycle-free case. Theoretical results are validated by numerical experiments on a HO, highly curved two- and three-dimensional meshes that are generated from an arbitrary Lagrangian--Eulerian hydrodynamics code, where the additional inner sweeps between DSA steps offer up to a 4 x reduction in total number of sweeps required for convergence.},
  archive      = {J_SISC},
  author       = {Terry S. Haut and Ben S. Southworth and Peter G. Maginot and Vladimir Z. Tomov},
  doi          = {10.1137/19M124993X},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {B1271-B1301},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Diffusion synthetic acceleration preconditioning for discontinuous galerkin discretizations of $S_N$ transport on high-order curved meshes},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Vector-type boundary schemes for the lattice boltzmann
method based on vector-BGK models. <em>SISC</em>, <em>42</em>(5),
B1250–B1270. (<a href="https://doi.org/10.1137/19M1308542">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a vector-type bounce-back boundary scheme for the lattice Boltzmann method based on vector-BGK models. The scheme is shown to have second-order accuracy if the boundary is located at the middle of two neighboring lattice nodes. We analyze the numerical stability of the new boundary scheme by using a subtle structural property of the models. Based on the new scheme, we devise a family of parameterized second-order boundary schemes with accuracy independent of the location of the boundary. The accuracy and stability of the boundary schemes above are validated via numerical experiments with both straight and curved boundaries.},
  archive      = {J_SISC},
  author       = {Jin Zhao and Zhimin Zhang and Wen-An Yong},
  doi          = {10.1137/19M1308542},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {B1250-B1270},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Vector-type boundary schemes for the lattice boltzmann method based on vector-BGK models},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An adaptive discontinuous petrov–galerkin method for the
grad–shafranov equation. <em>SISC</em>, <em>42</em>(5), B1227–B1249. (<a
href="https://doi.org/10.1137/19M1309894">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we propose and develop an arbitrary-order adaptive discontinuous Petrov--Galerkin (DPG) method for the nonlinear Grad--Shafranov equation. An ultraweak formulation of the DPG scheme for the equation is given based on a minimal residual method. The DPG scheme has the advantage of providing more accurate gradients compared to conventional finite element methods, which is desired for numerical solutions to the Grad--Shafranov equation. The numerical scheme is augmented with an adaptive mesh refinement approach, and a criterion based on the residual norm in the minimal residual method is developed to achieve dynamic refinement. Nonlinear solvers for the resulting system are explored and a Picard iteration with Anderson acceleration is found to be efficient to solve the system. Finally, the proposed algorithm is implemented in parallel on MFEM using a domain-decomposition approach, and our implementation is general, supporting arbitrary order of accuracy and general meshes. Numerical results are presented to demonstrate the efficiency and accuracy of the proposed algorithm.},
  archive      = {J_SISC},
  author       = {Zhichao Peng and Qi Tang and Xian-Zhu Tang},
  doi          = {10.1137/19M1309894},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {B1227-B1249},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {An adaptive discontinuous petrov--galerkin method for the grad--shafranov equation},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Burnett spectral method for high-speed rarefied gas flows.
<em>SISC</em>, <em>42</em>(5), B1193–B1226. (<a
href="https://doi.org/10.1137/19M1294010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a numerical solver for the spatially inhomogeneous Boltzmann equation using the Burnett spectral method. The modeling and discretization of the collision operator are based on the previous work [Z. Cai, Y. Fan, and Y. Wang, Comput. &amp; Fluids, 200 (2020), 104456], which is the hybridization of the BGK operator for higher moments and the quadratic collision operator for lower moments. To ensure the preservation of the equilibrium state, we introduce an additional term to the discrete collision operator, which equals zero when the number of degrees of freedom tends to infinity. Compared with the previous work [Z. Hu, Z. Cai, and Y. Wang, SIAM J. Sci. Comput., 42 (2020), pp. B105--B134], the computational cost is reduced by one order. Numerical experiments such as shock structure calculation and Fourier flows are carried out to show the efficiency and accuracy of our numerical method.},
  archive      = {J_SISC},
  author       = {Zhicheng Hu and Zhenning Cai},
  doi          = {10.1137/19M1294010},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {B1193-B1226},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Burnett spectral method for high-speed rarefied gas flows},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Numerical solution of a linearized travel time tomography
problem with incomplete data. <em>SISC</em>, <em>42</em>(5),
B1173–B1192. (<a href="https://doi.org/10.1137/19M1299487">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new numerical method to solve the linearized problem of the travel time tomography with incomplete data. Our method is based on the technique of the truncation of the Fourier series with respect to a special basis of $L^{2}$. This way we derive a boundary value problem for a system of coupled PDEs of the first order. This problem is solved by the quasi-reversibility method. The spatially dependent Fourier coefficients of the solution to the linearized eikonal equation are obtained this way. Numerical results for highly noisy data are presented.},
  archive      = {J_SISC},
  author       = {Michael V. Klibanov and Thuy T. Le and Loc H. Nguyen},
  doi          = {10.1137/19M1299487},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {B1173-B1192},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Numerical solution of a linearized travel time tomography problem with incomplete data},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A well-balanced asymptotic preserving scheme for the
two-dimensional shallow water equations over irregular bottom
topography. <em>SISC</em>, <em>42</em>(5), B1136–B1172. (<a
href="https://doi.org/10.1137/19M1262590">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new well-balanced asymptotic preserving scheme for two-dimensional low Froude number shallow water flows over irregular bottom is developed in this study. The bed-slope terms in the low Froude number regime are nontrivial since their stiffness has the same order as the gravity waves, they change the flow behavior in the low Froude number regime, and thus require special treatment when developing a numerical scheme to ensure such terms will not introduce high order numerical diffusion and spurious waves. To this end, the governing system is reformulated to obtain the well-balanced property. Since the system is stiff in the low Froude number flow regime, conventional explicit numerical schemes are extremely inefficient and often impractical. In order to overcome such difficulties, an asymptotic preserving scheme is developed by splitting the flux into a slow nonlinear part and fast linear part first, then approximating the slow dynamics explicitly using an explicit shock capturing scheme while estimating the fast dynamics implicitly. Using in space the linear piecewise reconstruction with minmod limiter for the shock explicit capturing scheme and central difference method for implicit derivatives, and in time the second order implicit-explicit Runge--Kutta methods, the second order accuracy of the proposed scheme is achieved. It is proved that the proposed numerical schemes are asymptotically consistent and stable uniformly with respect to small Froude number. Several numerical experiments are conducted to demonstrate the performance of the proposed asymptotic preserving numerical methods.},
  archive      = {J_SISC},
  author       = {Xin Liu},
  doi          = {10.1137/19M1262590},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {B1136-B1172},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A well-balanced asymptotic preserving scheme for the two-dimensional shallow water equations over irregular bottom topography},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A reduced order modeling technique to study bifurcating
phenomena: Application to the gross–pitaevskii equation. <em>SISC</em>,
<em>42</em>(5), B1115–B1135. (<a
href="https://doi.org/10.1137/20M1313106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a computationally efficient framework to treat nonlinear partial differential equations having bifurcating solutions as one or more physical control parameters are varied. Our focus is on steady bifurcations. Plotting a bifurcation diagram entails computing multiple solutions of a parametrized, nonlinear problem, which can be extremely expensive in terms of computational time. In order to reduce these demanding computational costs, our approach combines a continuation technique and Newton&#39;s method with a reduced order modeling (ROM) technique, suitably supplemented with a hyperreduction method. To demonstrate the effectiveness of our ROM approach, we trace the steady solution branches of a nonlinear Schrödinger equation, called the Gross--Pitaevskii equation, as one or two physical parameters are varied. In the two-parameter study, we show that our approach is 60 times faster in constructing a bifurcation diagram than a standard full order method.},
  archive      = {J_SISC},
  author       = {Federico Pichi and Annalisa Quaini and Gianluigi Rozza},
  doi          = {10.1137/20M1313106},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {B1115-B1135},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A reduced order modeling technique to study bifurcating phenomena: Application to the gross--pitaevskii equation},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Tensor train construction from tensor actions, with
application to compression of large high order derivative tensors.
<em>SISC</em>, <em>42</em>(5), A3516–A3539. (<a
href="https://doi.org/10.1137/20M131936X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a method for converting tensors into the tensor train format based on actions of the tensor as a vector-valued multilinear function. Existing methods for constructing tensor trains require access to “array entries” of the tensor and are therefore inefficient or computationally prohibitive if the tensor is accessible only through its action, especially for high order tensors. Our method permits efficient tensor train compression of large high order derivative tensors for nonlinear mappings that are implicitly defined through the solution of a system of equations. Array entries of these derivative tensors are not directly accessible, but actions of these tensors can be computed efficiently via a procedure that we discuss. Such tensors are often amenable to tensor train compression in theory, but until now no efficient algorithm existed to convert them into tensor train format. We demonstrate our method by compressing a Hilbert tensor of size 41 x 42 x 43 x 44 x 45, and by forming high order (up to fifth order derivatives/sixth order tensors) Taylor series surrogates of the noise-whitened parameter-to-output map for a stochastic partial differential equation with boundary output.},
  archive      = {J_SISC},
  author       = {Nick Alger and Peng Chen and Omar Ghattas},
  doi          = {10.1137/20M131936X},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {A3516-A3539},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Tensor train construction from tensor actions, with application to compression of large high order derivative tensors},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Sampling low-dimensional markovian dynamics for
preasymptotically recovering reduced models from data with operator
inference. <em>SISC</em>, <em>42</em>(5), A3489–A3515. (<a
href="https://doi.org/10.1137/19M1292448">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work introduces a method for learning low-dimensional models from data of high-dimensional black-box dynamical systems. The novelty is that the learned models are exactly the reduced models that are traditionally constructed with classical projection-based model reduction techniques. Thus, the proposed approach learns models that are guaranteed to have the well-studied properties of reduced models known from model reduction, without requiring full knowledge of the governing equations and without requiring the operators of the high-dimensional systems. The key ingredient is a new data sampling scheme to obtain re-projected trajectories of high-dimensional systems that correspond to Markovian dynamics in low-dimensional subspaces. The exact recovery of reduced models from these re-projected trajectories is guaranteed preasymptotically under certain conditions for finite amounts of data and for a large class of systems with polynomial nonlinear terms. Numerical results demonstrate that the low-dimensional models learned with the proposed approach match reduced models from traditional model reduction up to numerical errors in practice. The numerical results further indicate that low-dimensional models fitted to re-projected trajectories are predictive even in situations where models fitted to trajectories without re-projection are inaccurate and unstable.},
  archive      = {J_SISC},
  author       = {Benjamin Peherstorfer},
  doi          = {10.1137/19M1292448},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {A3489-A3515},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Sampling low-dimensional markovian dynamics for preasymptotically recovering reduced models from data with operator inference},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Numerical solution of 3D exterior unsteady wave propagation
problems using boundary operators. <em>SISC</em>, <em>42</em>(5),
A3462–A3488. (<a href="https://doi.org/10.1137/19M1269269">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a boundary method for the numerical simulation of time-dependent waves in three-dimensional (3D) exterior regions. The order of accuracy can be either second or fourth in both space and time. The method reduces a given initial boundary value problem for the wave equation to a set of operator equations at the boundary of the original domain. The reduction is based on a reformulation of the method of difference potentials. The resulting operator equations relate the solution and its normal derivative at the boundary. To solve these equations, one relies on the Huygens&#39; principle. This yields an algorithm that works on a sliding time window of a finite nonincreasing duration. As a result, it allows one to avoid the ever increasing backward dependence of the solution on time. The major advantages of the proposed methodology are its reduced computational complexity (grid-independent on the boundary and sublinear in the volume), the capacity to handle curvilinear geometries using Cartesian finite difference time domain (FDTD) methods, and automatic and exact accounting for the far-field radiation conditions. In addition, the methodology facilitates solution of multiple similar problems al low individual cost per problem and guarantees uniform performance over arbitrarily long time intervals.},
  archive      = {J_SISC},
  author       = {Sergey Petropavlovsky and Semyon V. Tsynkov and Eli Turkel},
  doi          = {10.1137/19M1269269},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {A3462-A3488},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Numerical solution of 3D exterior unsteady wave propagation problems using boundary operators},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A data-driven McMillan degree lower bound. <em>SISC</em>,
<em>42</em>(5), A3447–A3461. (<a
href="https://doi.org/10.1137/18M1194481">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of linear time-invariant systems, the McMillan degree prescribes the smallest possible dimension of a system that reproduces the observed dynamics. When these observations take the form of impulse response measurements where the system evolves without input from an unknown initial condition, a result of Ho and Kalman reveals the McMillan degree as the rank of a Hankel matrix built from these measurements. Unfortunately, using this result in experimental practice is challenging as measurements are invariably contaminated by noise and hence the Hankel matrix will almost surely be full rank. Hence practitioners estimate the rank of this matrix---and thus the McMillan degree---by manually setting a threshold separating large singular values corresponding to the nonzero singular values of the noise-free Hankel matrix and small singular values corresponding to perturbation of zero singular values of the noise-free Hankel matrix. Here we replace this manual threshold with a threshold guided by Weyl&#39;s theorem. Specifically, assuming measurements are perturbed by additive Gaussian noise we construct a probabilistic upper bound on how much the singular values of the noise-free Hankel matrix can be perturbed; this provides a conservative threshold for estimating the rank and hence the McMillan degree. This result follows from a new probabilistic bound on the 2-norm of a random Hankel matrix with normally distributed entries. Unlike existing results for random Hankel matrices, this bound features no unknown constants and, moreover, is within a small factor of the empirically observed bound. This bound on the McMillan degree provides an inexpensive alternative to more general model order selection techniques such as the Akaike information criteria.},
  archive      = {J_SISC},
  author       = {Jeffrey M. Hokanson},
  doi          = {10.1137/18M1194481},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {A3447-A3461},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A data-driven McMillan degree lower bound},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sharper probabilistic backward error analysis for basic
linear algebra kernels with random data. <em>SISC</em>, <em>42</em>(5),
A3427–A3446. (<a href="https://doi.org/10.1137/20M1314355">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Standard backward error analyses for numerical linear algebra algorithms provide worst-case bounds that can significantly overestimate the backward error. Our recent probabilistic error analysis, which assumes rounding errors to be independent random variables [SIAM J. Sci. Comput., 41 (2019), pp. A2815--A2835], contains smaller constants but its bounds can still be pessimistic. We perform a new probabilistic error analysis that assumes both the data and the rounding errors to be random variables and assumes only mean independence. We prove that for data with zero or small mean we can relax the existing probabilistic bounds of order $\sqrt{n}\mkern1muu$ to much sharper bounds of order $u$, which are independent of $n$. Our fundamental result is for summation and we use it to derive results for inner products, matrix--vector products, and matrix--matrix products. The analysis answers the open question of why random data distributed on $[-1,1]$ leads to smaller error growth for these kernels than random data distributed on [0,1]. We also propose a new algorithm for multiplying two matrices that transforms the rows of the first matrix to have zero mean and we show that it can achieve significantly more accurate results than standard matrix multiplication.},
  archive      = {J_SISC},
  author       = {Nicholas J. Higham and Theo Mary},
  doi          = {10.1137/20M1314355},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {A3427-A3446},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Sharper probabilistic backward error analysis for basic linear algebra kernels with random data},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hierarchical matrix approximations of hessians arising in
inverse problems governed by PDEs. <em>SISC</em>, <em>42</em>(5),
A3397–A3426. (<a href="https://doi.org/10.1137/19M1270367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hessian operators arising in inverse problems governed by partial differential equations (PDEs) play a critical role in delivering efficient, dimension-independent convergence for Newton solution of deterministic inverse problems, as well as Markov chain Monte Carlo sampling of posteriors in the Bayesian setting. These methods require the ability to repeatedly perform operations on the Hessian such as multiplication with arbitrary vectors, solving linear systems, inversion, and (inverse) square root. Unfortunately, the Hessian is a (formally) dense, implicitly defined operator that is intractable to form explicitly for practical inverse problems, requiring as many PDE solves as inversion parameters. Low rank approximations are effective when the data contain limited information about the parameters but become prohibitive as the data become more informative. However, the Hessians for many inverse problems arising in practical applications can be well approximated by matrices that have hierarchically low rank structure. Hierarchical matrix representations promise to overcome the high complexity of dense representations and provide effective data structures and matrix operations that have only log-linear complexity. In this work, we describe algorithms for constructing and updating hierarchical matrix approximations of Hessians, and illustrate them on a number of representative inverse problems involving time-dependent diffusion, advection-dominated transport, frequency domain acoustic wave propagation, and low frequency Maxwell equations, demonstrating up to an order of magnitude speedup compared to globally low rank approximations.},
  archive      = {J_SISC},
  author       = {Ilona Ambartsumyan and Wajih Boukaram and Tan Bui-Thanh and Omar Ghattas and David Keyes and Georg Stadler and George Turkiyyah and Stefano Zampini},
  doi          = {10.1137/19M1270367},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {A3397-A3426},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Hierarchical matrix approximations of hessians arising in inverse problems governed by PDEs},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mixed-dimensional auxiliary space preconditioners.
<em>SISC</em>, <em>42</em>(5), A3367–A3396. (<a
href="https://doi.org/10.1137/19M1292618">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work introduces nodal auxiliary space preconditioners for discretizations of mixed-dimensional partial differential equations. We first consider the continuous setting and generalize the regular decomposition to this setting. With the use of conforming mixed finite element spaces, we then expand these results to the discrete case and obtain a decomposition in terms of nodal Lagrange elements. In turn, nodal preconditioners are proposed analogous to the auxiliary space preconditioners of Hiptmair and Xu [SIAM J. Numer. Anal., 45 (2007), pp. 2483--2509]. Numerical experiments show the performance of this preconditioner in the context of flow in fractured porous media.},
  archive      = {J_SISC},
  author       = {Ana Budiša and Wietse M. Boon and Xiaozhe Hu},
  doi          = {10.1137/19M1292618},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {A3367-A3396},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Mixed-dimensional auxiliary space preconditioners},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Geometry of graph partitions via optimal transport.
<em>SISC</em>, <em>42</em>(5), A3340–A3366. (<a
href="https://doi.org/10.1137/19M1295258">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We define a distance metric between partitions of a graph using machinery from optimal transport. Our metric is built from a linear assignment problem that matches partition components, with assignment cost proportional to transport distance over graph edges. We show that our distance can be computed using a single linear program without precomputing pairwise assignment costs and derive several theoretical properties of the metric. Finally, we provide experiments demonstrating these properties empirically, specifically focusing on the metric&#39;s value for new problems in ensemble-based analysis of political districting plans.},
  archive      = {J_SISC},
  author       = {Tara Abrishami and Nestor Guillen and Parker Rule and Zachary Schutzman and Justin Solomon and Thomas Weighill and Si Wu},
  doi          = {10.1137/19M1295258},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {A3340-A3366},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Geometry of graph partitions via optimal transport},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Natural domain decomposition algorithms for the solution of
time-harmonic elastic waves. <em>SISC</em>, <em>42</em>(5), A3313–A3339.
(<a href="https://doi.org/10.1137/19M125858X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study for the first time Schwarz domain decomposition methods for the solution of the Navier equations modeling the propagation of elastic waves. These equations in the time-harmonic regime are difficult to solve by iterative methods, even more so than the Helmholtz equation. We first prove that the classical Schwarz method is not convergent when applied to the Navier equations and can thus not be used as an iterative solver, only as a preconditioner for a Krylov method. We then introduce more natural transmission conditions between the subdomains and show that if the overlap is not too small, this new Schwarz method is convergent. We illustrate our results with numerical experiments, both for situations covered by our technical two subdomain analysis and situations that go far beyond, including many subdomains, cross points, heterogeneous materials in a transmission problem, and Krylov acceleration. Our numerical results show that the Schwarz method with adapted transmission conditions leads systematically to a better solver for the Navier equations than the classical Schwarz method.},
  archive      = {J_SISC},
  author       = {R. Brunet and V. Dolean and M. J. Gander},
  doi          = {10.1137/19M125858X},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {A3313-A3339},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Natural domain decomposition algorithms for the solution of time-harmonic elastic waves},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A phase shift deep neural network for high frequency
approximation and wave problems. <em>SISC</em>, <em>42</em>(5),
A3285–A3312. (<a href="https://doi.org/10.1137/19M1310050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a phase shift deep neural network (PhaseDNN), which provides a uniform wideband convergence in approximating high frequency functions and solutions of wave equations. The PhaseDNN makes use of the fact that common deep neural networks (DNNs) often achieve convergence in the low frequency range first, and constructs a series of moderately sized DNNs trained for selected high frequency ranges. With the help of phase shifts in the frequency domain, each of the DNNs will be trained to approximate the function&#39;s specific high frequency range at the speed of learning for low frequency. As a result, the proposed PhaseDNN is able to convert high frequency learning to low frequency learning, allowing a uniform learning of wideband functions. The PhaseDNN is then applied to learn solutions of high frequency wave problems in inhomogeneous media through the least squares residual of either differential or integral equations. Numerical results have demonstrated the capability of the PhaseDNN as a meshless method in general domains in learning high frequency functions and oscillatory solutions of interior and exterior Helmholtz problems.},
  archive      = {J_SISC},
  author       = {Wei Cai and Xiaoguang Li and Lizuo Liu},
  doi          = {10.1137/19M1310050},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {A3285-A3312},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A phase shift deep neural network for high frequency approximation and wave problems},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On least squares problems with certain
vandermonde–khatri–rao structure with applications to DMD.
<em>SISC</em>, <em>42</em>(5), A3250–A3284. (<a
href="https://doi.org/10.1137/19M1288474">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new computational method for solving the structured least squares problem that arises in the process of identification of coherent structures in dynamic processes, such as, e.g., fluid flows. It is deployed in combination with dynamic mode decomposition (DMD), which provides a nonorthogonal set of modes corresponding to particular temporal frequencies. A selection of these is used to represent time snapshots of the underlying dynamics. The coefficients of the representation are determined from a solution of a structured linear least squares problems with the matrix that involves the Khatri--Rao product of a triangular and a Vandermonde matrix. Such a structure allows for a very efficient normal equation based least squares solution, which is used in state-of-the-art computational fluid dynamics (CFD) tools, such as the sparsity promoting DMD (DMDSP). A new numerical analysis of the normal equations approach provides insights about its applicability and its limitations. Relevant condition numbers that determine numerical robustness are identified and discussed. Further, the paper offers a corrected seminormal solution and the QR factorization based algorithms. It shows how to use the Vandermonde--Khatri--Rao structure to efficiently compute the QR factorization of the least squares coefficient matrix, thus providing a new computational tool for the ill-conditioned cases where the normal equations may fail to compute a sufficiently accurate solution. Altogether, the presented material provides a firm numerical linear algebra framework for a class of structured least squares problems arising in a variety of applications besides the DMD, such as, e.g., multistatic antenna array processing.},
  archive      = {J_SISC},
  author       = {Zlatko Drmač and Igor Mezić and Ryan Mohr},
  doi          = {10.1137/19M1288474},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {A3250-A3284},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {On least squares problems with certain vandermonde--khatri--rao structure with applications to DMD},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An efficient algorithm for the classical least squares
approximation. <em>SISC</em>, <em>42</em>(5), A3233–A3249. (<a
href="https://doi.org/10.1137/19M1259936">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We explore the computational issues concerning a new algorithm for the classical least-squares approximation of $N$ samples by an algebraic polynomial of degree at most $n$ when the number $N$ of the samples is very large. The algorithm is based on a recent idea about accurate numerical approximations of sums with large numbers of terms. For a fixed $n$, the complexity of our algorithm in double precision accuracy is $\mathcal{O}(1)$. It is faster and more precise than the standard algorithm in MATLAB.},
  archive      = {J_SISC},
  author       = {Dimitar K. Dimitrov and Lourenço L. Peixoto},
  doi          = {10.1137/19M1259936},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {A3233-A3249},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {An efficient algorithm for the classical least squares approximation},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Computation of tight enclosures for laplacian eigenvalues.
<em>SISC</em>, <em>42</em>(5), A3210–A3232. (<a
href="https://doi.org/10.1137/20M1326520">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, there has been interest in high precision approximations of the first eigenvalue of the Laplace--Beltrami operator on spherical triangles for combinatorial purposes. We compute improved and certified enclosures to these eigenvalues. This is achieved by applying the method of particular solutions in high precision, the enclosure being obtained by a combination of interval arithmetic and Taylor models. The index of the eigenvalue is certified by exploiting the monotonicity of the eigenvalue with respect to the domain. The classically troublesome case of singular corners is handled by combining expansions at all corners and an expansion from an interior point. In particular, this allows us to compute 100 digits of the fundamental eigenvalue for the three-dimensional Kreweras model that has been the object of previous efforts.},
  archive      = {J_SISC},
  author       = {Joel Dahne and Bruno Salvy},
  doi          = {10.1137/20M1326520},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {A3210-A3232},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Computation of tight enclosures for laplacian eigenvalues},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multilevel optimized schwarz methods. <em>SISC</em>,
<em>42</em>(5), A3180–A3209. (<a
href="https://doi.org/10.1137/19M1259389">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We define a new two-level optimized Schwarz method (OSM), and we provide a convergence analysis both for overlapping and nonoverlapping decompositions. The two-level analysis suggests how to choose the optimized parameters. We also discuss an optimization procedure which relies only on the already studied one-level min-max problems, and we show that these two approaches are asymptotically equivalent. The two-level OSM has mesh independent convergence and it is scalable. We then generalize the two-level method defining a multilevel domain decomposition method which uses the OSM as a smoother. The main advantage of the method consists of its robustness and generality with respect to the equations under study. Thanks to the smoothing properties of the OSM, both with and without overlap, we can define a unique algorithm which can be applied to several equations, both with homogeneous and heterogeneous coefficients. We present extensive numerical results to compare the multilevel OSM, the one-level OSM, and the multigrid scheme. The experiments show that the multilevel OSM inherits robustness from the one-level OSM for heterogeneous elliptic problems, wave problems, and heterogeneous couplings. Finally, we apply the method to design a two-level solver for the heterogeneous Stokes--Darcy system.},
  archive      = {J_SISC},
  author       = {Martin J. Gander and Tommaso Vanzan},
  doi          = {10.1137/19M1259389},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {A3180-A3209},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Multilevel optimized schwarz methods},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An algorithm for real and complex rational minimax
approximation. <em>SISC</em>, <em>42</em>(5), A3157–A3179. (<a
href="https://doi.org/10.1137/19M1281897">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rational minimax approximation of real functions on real intervals is an established topic, but when it comes to complex functions or domains, there appear to be no algorithms currently in use. Such a method is introduced here, the AAA-Lawson algorithm, available in Chebfun. The new algorithm solves a wide range of problems on arbitrary domains by a procedure consisting of two steps. First, the standard AAA algorithm is run to obtain a near-best approximation and a set of support points for a barycentric representation of the rational approximant. Then a “Lawson phase” of iteratively reweighted least-squares adjustment of the barycentric coefficients is carried out to improve the approximation to minimax.},
  archive      = {J_SISC},
  author       = {Yuji Nakatsukasa and Lloyd N. Trefethen},
  doi          = {10.1137/19M1281897},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {A3157-A3179},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {An algorithm for real and complex rational minimax approximation},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). A condensed constrained nonconforming mortar-based approach
for preconditioning finite element discretization problems.
<em>SISC</em>, <em>42</em>(5), A3136–A3156. (<a
href="https://doi.org/10.1137/19M1305690">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents and studies an approach for constructing auxiliary space preconditioners for finite element problems using a constrained nonconforming reformulation that is based on a proposed modified version of the mortar method. The well-known mortar finite element discretization method is modified to admit a local structure, providing an element-by-element or subdomain-by-subdomain assembly property. This is achieved via the introduction of additional trace finite element spaces and degrees of freedom (unknowns) associated with the interfaces between adjacent elements or subdomains. The resulting nonconforming formulation and a reduced-via-static-condensation Schur complement form on the interfaces are used in the construction of auxiliary space preconditioners for a given conforming finite element discretization problem. The properties of these preconditioners are studied and their performance is illustrated on model second order scalar elliptic problems utilizing high order elements.},
  archive      = {J_SISC},
  author       = {Delyan Z. Kalchev and Panayot Vassilevski},
  doi          = {10.1137/19M1305690},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {A3136-A3156},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A condensed constrained nonconforming mortar-based approach for preconditioning finite element discretization problems},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). High-order conservative positivity-preserving
DG-interpolation for deforming meshes and application to moving mesh DG
simulation of radiative transfer. <em>SISC</em>, <em>42</em>(5),
A3109–A3135. (<a href="https://doi.org/10.1137/19M1297907">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solution interpolation between deforming meshes is an important component for several applications in scientific computing, including indirect arbitrary-Lagrangian-Eulerian and rezoning moving mesh methods in numerical solution of PDEs. In this paper, a high-order, conservative, and positivity-preserving interpolation scheme is developed based on the discontinuous Galerkin solution of a linear time-dependent equation on deforming meshes. The scheme works for bounded but otherwise arbitrary mesh deformation from the old mesh to the new one. The cost and positivity preservation (with a linear scaling limiter) of the DG-interpolation are investigated. Numerical examples are presented to demonstrate the properties of the interpolation scheme. The DG-interpolation is applied to the rezoning moving mesh DG solution of the radiative transfer equation, an integro-differential equation modeling the conservation of photons and involving time, space, and angular variables. Numerical results obtained for examples in one and two spatial dimensions with various settings show that the resulting rezoning moving mesh DG method maintains the same convergence order as the standard DG method, is more efficient than the method with a fixed uniform mesh, and is able to preserve the positivity of the radiative intensity.},
  archive      = {J_SISC},
  author       = {Min Zhang and Weizhang Huang and Jianxian Qiu},
  doi          = {10.1137/19M1297907},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {A3109-A3135},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {High-order conservative positivity-preserving DG-interpolation for deforming meshes and application to moving mesh DG simulation of radiative transfer},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Predict-and-recompute conjugate gradient variants.
<em>SISC</em>, <em>42</em>(5), A3084–A3108. (<a
href="https://doi.org/10.1137/19M1276856">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The standard implementation of the conjugate gradient algorithm suffers from communication bottlenecks on parallel architectures, due primarily to the two global reductions required every iteration. In this paper, we study conjugate gradient variants which decrease the runtime per iteration by overlapping global synchronizations, and in the case of pipelined variants, matrix-vector products. Through the use of a predict-and-recompute scheme, whereby recursively updated quantities are first used as a predictor for their true values and then recomputed exactly at a later point in the iteration, these variants are observed to have convergence behavior nearly as good as the standard conjugate gradient implementation on a variety of test problems. We provide a rounding error analysis which provides insight into this observation. It is also verified experimentally that the variants studied do indeed reduce the runtime per iteration in practice and that they scale similarly to previously studied communication-hiding variants. Finally, because these variants achieve good convergence without the use of any additional input parameters, they have the potential to be used in place of the standard conjugate gradient implementation in a range of applications.},
  archive      = {J_SISC},
  author       = {Tyler Chen and Erin Carson},
  doi          = {10.1137/19M1276856},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {A3084-A3108},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Predict-and-recompute conjugate gradient variants},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient low-order refined preconditioners for high-order
matrix-free continuous and discontinuous galerkin methods.
<em>SISC</em>, <em>42</em>(5), A3055–A3083. (<a
href="https://doi.org/10.1137/19M1282052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we design preconditioners for the matrix-free solution of high-order continuous and discontinuous Galerkin discretizations of elliptic problems based on finite element method--spectral element method (FEM-SEM) equivalence and additive Schwarz methods. The high-order operators are applied without forming the system matrix, making use of sum factorization for efficient evaluation. The system is preconditioned using a spectrally equivalent low-order ($p=1$) finite element operator discretization on a refined mesh. The low-order refined mesh is anisotropic and not shape regular in the polynomial degree of the high-order operator, requiring specialized solvers to treat the anisotropy. We make use of an element-structured, geometric multigrid V-cycle with ordered ILU(0) smoothing. The preconditioner is parallelized through an overlapping additive Schwarz method that is robust in $h$ and $p$. The method is extended to interior penalty and Bassi and Rebay (BR2) discontinuous Galerkin discretizations, for which it is also robust in the size of the penalty parameter. Numerical results are presented on a variety of examples, verifying the uniformity of the preconditioner.},
  archive      = {J_SISC},
  author       = {Will Pazner},
  doi          = {10.1137/19M1282052},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {A3055-A3083},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Efficient low-order refined preconditioners for high-order matrix-free continuous and discontinuous galerkin methods},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Spectrally accurate algorithm for points redistribution on
closed curves. <em>SISC</em>, <em>42</em>(5), A3030–A3054. (<a
href="https://doi.org/10.1137/20M1314690">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a novel numerical method that redistributes unevenly given points on an evolving closed curve to satisfy equi-arclength(-like) condition. Without substantial difficulty, it is also capable of remeshing or employing adaptive mesh refinement. The key idea is to find the discrete inverse of the arclength(-like) function in the framework of the Fourier spectral method to obtain overall spectral accuracy. Both equi-arclength and curvature-dependent redistributions are extensively studied, and their spectral accuracy is verified by application to smoothly perturbed points on various curves. We further confirm that our method converges even for the points being perturbed nonsmoothly and randomly. To leverage the robustness of our method, a remeshing technique is applied in which the accuracy is not affected. Application to a periodic planar curve without any modification of our algorithm is also discussed. Then, to show the practical applicability, an evolving curve with large deformation is studied by coupling with point redistribution and remeshing in various flows such as mean curvature flow, Willmore flow, and Stokes flow.},
  archive      = {J_SISC},
  author       = {Yunchang Seol and Ming-Chih Lai},
  doi          = {10.1137/20M1314690},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {A3030-A3054},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Spectrally accurate algorithm for points redistribution on closed curves},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Structure-preserving function approximation via convex
optimization. <em>SISC</em>, <em>42</em>(5), A3006–A3029. (<a
href="https://doi.org/10.1137/19M130128X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Approximations of functions with finite data often do not respect certain “structural” properties of the functions. For example, if a given function is nonnegative, a polynomial approximation of the function is not necessarily also nonnegative. We propose a formalism and algorithms for preserving certain types of such structure in function approximation. In particular, we consider structure corresponding to a convex constraint on the approximant (for which positivity is one example). The approximation problem then converts into a convex feasibility problem, but the feasible set is relatively complicated so that standard convex feasibility algorithms cannot be directly applied. We propose and discuss different algorithms for solving this problem. One of the features of our machinery is flexibility: Relatively complicated constraints, such as simultaneously enforcing positivity, monotonicity, and convexity, are fairly straightforward to implement. We demonstrate the success of our algorithm on several problems in univariate function approximation.},
  archive      = {J_SISC},
  author       = {Vidhi Zala and Mike Kirby and Akil Narayan},
  doi          = {10.1137/19M130128X},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {A3006-A3029},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Structure-preserving function approximation via convex optimization},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Random sampling and efficient algorithms for multiscale
PDEs. <em>SISC</em>, <em>42</em>(5), A2974–A3005. (<a
href="https://doi.org/10.1137/18M1207430">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We describe a numerical framework that uses random sampling to efficiently capture low-rank local solution spaces of multiscale PDE problems arising in domain decomposition. In contrast to existing techniques, our method does not rely on detailed analytical understanding of specific multiscale PDEs, in particular, their asymptotic limits. We present the application of the framework on two examples---a linear kinetic equation and an elliptic equation with rough media. On these two examples, this framework achieves the asymptotic preserving property for the kinetic equations and numerical homogenization for the elliptic equations.},
  archive      = {J_SISC},
  author       = {Ke Chen and Qin Li and Jianfeng Lu and Stephen J. Wright},
  doi          = {10.1137/18M1207430},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {A2974-A3005},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Random sampling and efficient algorithms for multiscale PDEs},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An adaptive multiresolution discontinuous galerkin method
with artificial viscosity for scalar hyperbolic conservation laws in
multidimensions. <em>SISC</em>, <em>42</em>(5), A2943–A2973. (<a
href="https://doi.org/10.1137/19M126565X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we develop an adaptive multiresolution discontinuous Galerkin (DG) scheme for scalar hyperbolic conservation laws in multidimensions. Compared with previous work for linear hyperbolic equations [W. Guo and Y. Cheng, SIAM J. Sci. Comput., 38 (2016), pp. A3381--A3409, W. Guo and Y. Cheng, SIAM J. Sci. Comput., 39 (2017), pp. A2962--A2992], a class of interpolatory multiwavelets are applied to efficiently compute the nonlinear integrals over elements and edges in DG schemes. The resulting algorithm, therefore, can achieve similar computational complexity as the sparse grid DG method for smooth solutions. Theoretical and numerical studies are performed taking into consideration the accuracy and stability with regard to the choice of the interpolatory multiwavelets. Artificial viscosity is added to capture the shock and only acts on the leaf elements taking advantage of the multiresolution representation. Adaptivity is realized by auto error thresholding based on hierarchical surplus. Accuracy and robustness are demonstrated by several numerical tests.},
  archive      = {J_SISC},
  author       = {Juntao Huang and Yingda Cheng},
  doi          = {10.1137/19M126565X},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {A2943-A2973},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {An adaptive multiresolution discontinuous galerkin method with artificial viscosity for scalar hyperbolic conservation laws in multidimensions},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient algorithms for computing multidimensional integral
fractional laplacians via spherical means. <em>SISC</em>,
<em>42</em>(5), A2910–A2942. (<a
href="https://doi.org/10.1137/19M1262358">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop efficient algorithms for computing the multidimensional fractional operator $( -\Delta_{x})^{\frac{\alpha}{2}}$ in the form of hypersingular integral in the entire space, where the operator is the so-called integral fractional Laplacian when $0 &lt; \alpha &lt; 2$. By introducing polar coordinates, we reduce applying the multidimensional integral fractional operator to a function to applying the resulting one-dimensional fractional operator to the spherical mean of the underlying function. We propose two algorithms to compute spherical means of a given function: one by solving standard wave equations and the other by solving Darboux&#39;s equations. We further apply a finite difference numerical quadrature approach to compute the one-dimensional fractional operator. Our methodology is equally applicable to computing the action of the integral fractional Laplacian, the extended integral fractional Laplacian, and the Riesz potential operator, respectively, and the computational complexity for applying each of the three operators is $\mathcal{O}(L^{n+1})$, where $L$ denotes the number of mesh points in each spatial direction and $n$ is the spatial dimension. Numerical examples, including algebraically decaying functions with varying regularities, demonstrate the performance and convergence rates of our new algorithms.},
  archive      = {J_SISC},
  author       = {Boxi Xu and Jin Cheng and Shingyu Leung and Jianliang Qian},
  doi          = {10.1137/19M1262358},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {A2910-A2942},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Efficient algorithms for computing multidimensional integral fractional laplacians via spherical means},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A higher order moment preserving reduction scheme for the
stochastic weighted particle method. <em>SISC</em>, <em>42</em>(5),
A2889–A2909. (<a href="https://doi.org/10.1137/20M1312253">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stochastic weighted particle method (SWPM) is a Monte Carlo technique developed by Rjasanow and Wagner that generalizes Bird&#39;s direct simulation Monte Carlo method for solving the Boltzmann equation. To reduce computational cost due to the gradual increase in the number of stochastic particles in the SWPM, Rjasanow and Wagner proposed several particle reduction schemes designed to preserve specified moments of the velocity distribution. Here, we introduce an improved particle reduction scheme that preserves all moments of the velocity distribution up to the second order, as well as the raw and central heat flux both within each group of particles to be reduced and for the entire system. Furthermore, we demonstrate that with the new reduction scheme the scalar fourth order moment can be computed more accurately at a reduced computational cost.},
  archive      = {J_SISC},
  author       = {Sonam Lama and John Zweck and Matthew Goeckner},
  doi          = {10.1137/20M1312253},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {A2889-A2909},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A higher order moment preserving reduction scheme for the stochastic weighted particle method},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Linearly implicit local and global energy-preserving methods
for PDEs with a cubic hamiltonian. <em>SISC</em>, <em>42</em>(5),
A2865–A2888. (<a href="https://doi.org/10.1137/19M1272688">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present linearly implicit methods that preserve discrete approximations to local and global energy conservation laws for multisymplectic partial differential equations with cubic invariants. The methods are tested on the one-dimensional Korteweg--de Vries equation and the two-dimensional Zakharov--Kuznetsov equation; the numerical simulations confirm the conservative properties of the methods and demonstrate their good stability properties and superior running speed when compared to fully implicit schemes.},
  archive      = {J_SISC},
  author       = {Sølve Eidnes and Lu Li},
  doi          = {10.1137/19M1272688},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {A2865-A2888},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Linearly implicit local and global energy-preserving methods for PDEs with a cubic hamiltonian},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stability of discrete empirical interpolation and gappy
proper orthogonal decomposition with randomized and deterministic
sampling points. <em>SISC</em>, <em>42</em>(5), A2837–A2864. (<a
href="https://doi.org/10.1137/19M1307391">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work investigates the stability of (discrete) empirical interpolation for nonlinear model reduction and state field approximation from measurements. Empirical interpolation derives approximations from a few samples (measurements) via interpolation in low-dimensional spaces. It has been observed that empirical interpolation can become unstable if the samples are perturbed due to, e.g., noise, turbulence, and numerical inaccuracies. The main contribution of this work is a probabilistic analysis that shows that stable approximations are obtained if samples are randomized and if more samples than dimensions of the low-dimensional spaces are used. Oversampling, i.e., taking more sampling points than dimensions of the low-dimensional spaces, leads to approximations via regression and is known under the name of gappy proper orthogonal decomposition. Building on the insights of the probabilistic analysis, a deterministic sampling strategy is presented that aims to achieve lower approximation errors with fewer points than randomized sampling by taking information about the low-dimensional spaces into account. Numerical results of reconstructing velocity fields from noisy measurements of combustion processes and model reduction in the presence of noise demonstrate the instability of empirical interpolation and the stability of gappy proper orthogonal decomposition with oversampling.},
  archive      = {J_SISC},
  author       = {Benjamin Peherstorfer and Zlatko Drmač and Serkan Gugercin},
  doi          = {10.1137/19M1307391},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {A2837-A2864},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Stability of discrete empirical interpolation and gappy proper orthogonal decomposition with randomized and deterministic sampling points},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Model reduction for transport-dominated problems via online
adaptive bases and adaptive sampling. <em>SISC</em>, <em>42</em>(5),
A2803–A2836. (<a href="https://doi.org/10.1137/19M1257275">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a model reduction approach for problems with coherent structures that propagate over time, such as convection-dominated flows and wave-type phenomena. Traditional model reduction methods have difficulties with these transport-dominated problems because propagating coherent structures typically introduce high-dimensional features that require high-dimensional approximation spaces. The approach proposed in this work exploits the locality in space and time of propagating coherent structures to derive efficient reduced models. Full-model solutions are approximated locally in time via local reduced spaces that are adapted with basis updates during time stepping. The basis updates are derived from querying the full model at a few selected spatial coordinates. A core contribution of this work is an adaptive sampling scheme for selecting at which components to query the full model to compute basis updates. The presented analysis shows that, in probability, the more local the coherent structure is in space, the fewer full-model samples are required to adapt the reduced basis with the proposed adaptive sampling scheme. Numerical results on benchmark examples with interacting wave-type structures and time-varying transport speeds and on a model combustor of a single-element rocket engine demonstrate the wide applicability of the proposed approach and runtime speedups of up to one order of magnitude compared to full models and traditional reduced models.},
  archive      = {J_SISC},
  author       = {Benjamin Peherstorfer},
  doi          = {10.1137/19M1257275},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {A2803-A2836},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Model reduction for transport-dominated problems via online adaptive bases and adaptive sampling},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). PARAOPT: A parareal algorithm for optimality systems.
<em>SISC</em>, <em>42</em>(5), A2773–A2802. (<a
href="https://doi.org/10.1137/19M1292291">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The time parallel solution of optimality systems arising in PDE constrained optimization could be achieved by simply applying any time parallel algorithm, such as Parareal, to solve the forward and backward evolution problems arising in the optimization loop. We propose here a different strategy by devising directly a new time parallel algorithm, which we call ParaOpt, for the coupled forward and backward nonlinear partial differential equations. ParaOpt is inspired by the Parareal algorithm for evolution equations and thus is automatically a two-level method. We provide a detailed convergence analysis for the case of linear parabolic PDE constraints. We illustrate the performance of ParaOpt with numerical experiments for both linear and nonlinear optimality systems.},
  archive      = {J_SISC},
  author       = {Martin J. Gander and Felix Kwok and Julien Salomon},
  doi          = {10.1137/19M1292291},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {A2773-A2802},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {PARAOPT: A parareal algorithm for optimality systems},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A stochastic gradient method with mesh refinement for
PDE-constrained optimization under uncertainty. <em>SISC</em>,
<em>42</em>(5), A2750–A2772. (<a
href="https://doi.org/10.1137/19M1263297">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Models incorporating uncertain inputs, such as random forces or material parameters, have been of increasing interest in PDE-constrained optimization. In this paper, we focus on the efficient numerical minimization of a convex and smooth tracking-type functional subject to a linear partial differential equation with random coefficients and box constraints. The approach we take is based on stochastic approximation where, in place of a true gradient, a stochastic gradient is chosen using one sample from a known probability distribution. Feasibility is maintained by performing a projection at each iteration. In the application of this method to PDE-constrained optimization under uncertainty, new challenges arise. We observe the discretization error made by approximating the stochastic gradient using finite elements. Analyzing the interplay between PDE discretization and stochastic error, we develop a mesh refinement strategy coupled with decreasing step sizes. Additionally, we develop a mesh refinement strategy for the modified algorithm using iterate averaging and larger step sizes. The effectiveness of the approach is demonstrated numerically for different random field choices.},
  archive      = {J_SISC},
  author       = {Caroline Geiersbach and Winnifried Wollner},
  doi          = {10.1137/19M1263297},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {A2750-A2772},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A stochastic gradient method with mesh refinement for PDE-constrained optimization under uncertainty},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A multilevel monte carlo estimator for matrix
multiplication. <em>SISC</em>, <em>42</em>(5), A2731–A2749. (<a
href="https://doi.org/10.1137/19M125604X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by recent developments in multilevel Monte Carlo (MLMC) methods and randomized sketching for linear algebra problems, we propose an MLMC estimator for real-time processing of matrix structured random data. Our algorithm is particularly effective in handling high-dimensional inner products and matrix multiplication, and finds applications in computer vision and large-scale supervised learning.},
  archive      = {J_SISC},
  author       = {Yue Wu and Nick Polydorides},
  doi          = {10.1137/19M125604X},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {A2731-A2749},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A multilevel monte carlo estimator for matrix multiplication},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stability analysis of inline ZFP compression for
floating-point data in iterative methods. <em>SISC</em>, <em>42</em>(5),
A2701–A2730. (<a href="https://doi.org/10.1137/19M126904X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, the dominating constraint in many high performance computing applications is data capacity and bandwidth, in both internode communications and even moreso in intranode data motion. A new approach to address this limitation is to make use of data compression in the form of a compressed data array. Storing data in a compressed data array and converting to standard IEEE-754 types as needed during a computation can reduce the pressure on bandwidth and storage. However, repeated conversions (lossy compression and decompression) introduce additional approximation errors, which need to be shown to not significantly affect the simulation results. We extend recent work [J. Diffenderfer et al., SIAM J. Sci. Comput., 41 (2019), pp. A1867--A1898] that analyzed the error of a single use of compression and decompression of the ZFP compressed data array representation [P. Lindstrom, IEEE Trans. Vis. Comput. Graph., 20 (2014), pp. 2674--2683; P. Lindstrom, ZFP version 0.5.5, May 2019] to the case of time-stepping and iterative schemes, where an advancement operator is repeatedly applied in addition to the conversions. We show that the accumulated error for iterative methods involving fixed-point and time evolving iterations is bounded under standard constraints. An upper bound is established on the number of additional iterations required for the convergence of stationary fixed-point iterations. An additional analysis of traditional forward and backward error of stationary iterative methods using ZFP compressed arrays is also presented. The results of several 1D, 2D, and 3D test problems are provided to demonstrate the correctness of the theoretical bounds.},
  archive      = {J_SISC},
  author       = {Alyson Fox and James Diffenderfer and Jeffrey Hittinger and Geoffrey Sanders and Peter Lindstrom},
  doi          = {10.1137/19M126904X},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {A2701-A2730},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Stability analysis of inline ZFP compression for floating-point data in iterative methods},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Numerical stackelberg–nash control for the heat equation.
<em>SISC</em>, <em>42</em>(5), A2678–A2700. (<a
href="https://doi.org/10.1137/19M1253320">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with a strategy to solve numerically control problems of the Stackelberg--Nash kind for heat equations with Dirichlet boundary conditions. We assume that we can act on the system through several controls, respecting an order and a hierarchy: a first control (the leader) is assumed to choose the policy; then, a Nash equilibrium pair, determined by the choice of the leader and corresponding to a noncooperative multiple-objective optimization strategy, is found (these are the followers). Our method relies on a formulation inspired by the work of Fursikov and Imanuvilov. More precisely, we minimize over the class of admissible null controls a functional that involves weighted integrals of the state and the control, with weights that blow up at the final time. The use of the weights is crucial to ensure the existence of the controls and the associated state in a reasonable space. We present several mixed formulations of the problems and, then, associated mixed finite element approximations that are easy to handle. In a final step, we exhibit some numerical experiments making use of the Freefem++ package.},
  archive      = {J_SISC},
  author       = {Pitágoras P. de Carvalho and Enrique Fernández-Cara},
  doi          = {10.1137/19M1253320},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {A2678-A2700},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Numerical stackelberg--nash control for the heat equation},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A parallel augmented subspace method for eigenvalue
problems. <em>SISC</em>, <em>42</em>(5), A2655–A2677. (<a
href="https://doi.org/10.1137/19M128452X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A type of parallel augmented subspace scheme for eigenvalue problems is proposed by using coarse space in the multigrid method. With the help of coarse space in the multigrid method, solving the eigenvalue problem in the finest space is decomposed into solving the standard linear boundary value problems and very-low-dimensional eigenvalue problems. The computational efficiency can be improved since there is no direct eigenvalue solving in the finest space and the multigrid method can act as the solver for the deduced linear boundary value problems. Furthermore, for different eigenvalues, the corresponding boundary value problem and low-dimensional eigenvalue problem can be solved in the parallel way since they are independent of each other and there exists no data exchanging. This property means that we do not need to do the orthogonalization in the highest-dimensional spaces. This is the main aim of this paper since avoiding orthogonalization can improve the scalability of the proposed numerical method. Some numerical examples are provided to validate the proposed parallel augmented subspace method.},
  archive      = {J_SISC},
  author       = {Fei Xu and Hehu Xie and Ning Zhang},
  doi          = {10.1137/19M128452X},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {A2655-A2677},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A parallel augmented subspace method for eigenvalue problems},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stabilized cut discontinuous galerkin methods for
advection-reaction problems. <em>SISC</em>, <em>42</em>(5), A2620–A2654.
(<a href="https://doi.org/10.1137/18M1206461">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop novel stabilized cut discontinuous Galerkin methods for advection-reaction problems. The domain of interest is embedded into a structured, unfitted background mesh in $\mathbb{R}^d$ where the domain boundary can cut through the mesh in an arbitrary fashion. To cope with robustness problems caused by small cut elements, we introduce ghost penalties in the vicinity of the embedded boundary to stabilize certain (semi-)norms associated with the advection and reaction operator. A few abstract assumptions on the ghost penalties are identified enabling us to derive geometrically robust and optimal a priori error and condition number estimates for the stationary advection-reaction problem which hold irrespective of the particular cut configuration. Possible realizations of suitable ghost penalties are discussed. The theoretical results are corroborated by a number of computational studies for various approximation orders and for two- and three-dimensional test problems.},
  archive      = {J_SISC},
  author       = {Ceren Gürkan and Simon Sticko and André Massing},
  doi          = {10.1137/18M1206461},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {A2620-A2654},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Stabilized cut discontinuous galerkin methods for advection-reaction problems},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hermite interpolation and data processing errors on
riemannian matrix manifolds. <em>SISC</em>, <em>42</em>(5), A2593–A2619.
(<a href="https://doi.org/10.1137/19M1282878">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main contribution of this paper is twofold: On the one hand, a general framework for performing Hermite interpolation on Riemannian manifolds is presented. The method is applicable if algorithms for the associated Riemannian exponential and logarithm mappings are available. This includes many of the matrix manifolds that arise in practical Riemannian computing applications such as data analysis and signal processing, computer vision and image processing, structured matrix optimization problems, and model reduction. On the other hand, we expose a natural relation between data processing errors and the sectional curvature of the manifold in question. This provides general error bounds for manifold data processing methods that rely on Riemannian normal coordinates. Numerical experiments are conducted for the compact Stiefel manifold of rectangular column-orthogonal matrices. As use cases, we compute Hermite interpolation curves for orthogonal matrix factorizations such as the singular value decomposition and the QR-decomposition.},
  archive      = {J_SISC},
  author       = {Ralf Zimmermann},
  doi          = {10.1137/19M1282878},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {A2593-A2619},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Hermite interpolation and data processing errors on riemannian matrix manifolds},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Helmholtz scattering by random domains: First-order sparse
boundary element approximation. <em>SISC</em>, <em>42</em>(5),
A2561–A2592. (<a href="https://doi.org/10.1137/19M1279277">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the numerical solution of time-harmonic acoustic scattering by obstacles with uncertain geometries for Dirichlet, Neumann, impedance, and transmission boundary conditions. In particular, we aim to quantify diffracted fields originated by small stochastic perturbations of a given relatively smooth nominal shape. Using first-order shape Taylor expansions, we derive tensor deterministic first-kind boundary integral equations for the statistical moments of the scattering problems considered. These are then approximated by sparse tensor Galerkin discretizations via the combination technique [M. Griebel, M. Schneider, and C. Zenger, A combination technique for the solution of sparse grid problems, in Iterative Methods in Linear Algebra, P. de Groen and P. Beauwens, eds., Elsevier, Amsterdam, 1992, pp. 263--281; H. Harbrecht, M. Peters, and M. Siebenmorgen, J. Comput. Phys., 252 (2013), pp. 128--141]. We supply extensive numerical experiments confirming the predicted error convergence rates with polylogarithmic growth in the number of degrees of freedom and accuracy in approximation of the moments. Moreover, we discuss implementation details such as preconditioning to finally point out further research avenues.},
  archive      = {J_SISC},
  author       = {Paul Escapil-Inchauspé and Carlos Jerez-Hanckes},
  doi          = {10.1137/19M1279277},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {5},
  pages        = {A2561-A2592},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Helmholtz scattering by random domains: First-order sparse boundary element approximation},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Computing with functions in the ball. <em>SISC</em>,
<em>42</em>(4), C169–C191. (<a
href="https://doi.org/10.1137/19M1297063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A collection of algorithms in object-oriented MATLAB is described for numerically computing with smooth functions defined on the unit ball in the Chebfun software. Functions are numerically and adaptively resolved to essentially machine precision by using a three-dimensional analogue of the double Fourier sphere method to form “Ballfun&quot; objects. Operations such as function evaluation, differentiation, integration, fast rotation by an Euler angle, and a Helmholtz solver are designed. Our algorithms are particularly efficient for vector calculus operations, and we describe how to compute the poloidal-toroidal and Helmholtz--Hodge decompositions of a vector field defined on the ball.},
  archive      = {J_SISC},
  author       = {Nicolas Boullé and Alex Townsend},
  doi          = {10.1137/19M1297063},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {4},
  pages        = {C169-C191},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Computing with functions in the ball},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A distributed-memory algorithm for computing a heavy-weight
perfect matching on bipartite graphs. <em>SISC</em>, <em>42</em>(4),
C143–C168. (<a href="https://doi.org/10.1137/18M1189348">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We design and implement an efficient parallel algorithm for finding a perfect matching in a weighted bipartite graph such that weights on the edges of the matching are large. This problem differs from the maximum weight matching problem, for which scalable approximation algorithms are known. It is primarily motivated by finding good pivots in scalable sparse direct solvers before factorization. Due to the lack of scalable alternatives, distributed solvers use sequential implementations of maximum weight perfect matching algorithms, such as those available in MC64. To overcome this limitation, we propose a fully parallel distributed memory algorithm that first generates a perfect matching and then iteratively improves the weight of the perfect matching by searching for weight-increasing cycles of length 4 in parallel. For most practical problems the weights of the perfect matchings generated by our algorithm are very close to the optimum. An efficient implementation of the algorithm scales up to 256 nodes (17,408 cores) on a Cray XC40 supercomputer and can solve instances that are too large to be handled by a single node using the sequential algorithm.},
  archive      = {J_SISC},
  author       = {Ariful Azad and Aydin Buluç and Xiaoye S. Li and Xinliang Wang and Johannes Langguth},
  doi          = {10.1137/18M1189348},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {4},
  pages        = {C143-C168},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A distributed-memory algorithm for computing a heavy-weight perfect matching on bipartite graphs},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Gradient-based two-scale topology optimization with
b-splines on sparse grids. <em>SISC</em>, <em>42</em>(4), B1092–B1114.
(<a href="https://doi.org/10.1137/19M128822X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural optimization searches for the optimal shape and topology of components such that specific physical quantities are optimized, for instance, the stability of the resulting structure. Problems involving multiple scales, i.e., structures on a microscopic and a macroscopic level, can be efficiently solved by homogenization-based two-scale approaches. In each optimization iteration, many computationally expensive tensors $E$ describing the macroscopic behavior of a given microstructure have to be calculated, implying that the solution of one optimization problem can take weeks. The computational complexity can be greatly reduced with surrogates $\tilde{E}$ that are constructed in advance in an offline phase via interpolation and that can be reused for different scenarios. Three main issues arise in this context: First, the curse of dimensionality renders conventional interpolation schemes infeasible even for moderate dimensionalities $&gt; 4$. Therefore, we use sparse grid interpolation combined with a novel problem-tailored boundary treatment to drastically reduce the necessary grid size with only slightly higher approximation errors. Second, common sparse grid bases are not continuously differentiable. Hierarchical B-splines achieve lower approximation errors and supply exact continuous gradients of $\tilde{E}$, which enables gradient-based optimization without approximating gradients of $E$. Third, the interpolated tensors are usually required to be positive definite, which is not fulfilled by common interpolation methods. We are able to preserve positive definiteness of the interpolated tensors by interpolating Cholesky factors instead. Combining these three contributions allows computing optimized structures for two- and three-dimensional optimization scenarios with speedups of up to 86 when compared to non-surrogate-based solutions.},
  archive      = {J_SISC},
  author       = {Julian Valentin and Daniel Hübner and Michael Stingl and Dirk Pflüger},
  doi          = {10.1137/19M128822X},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {4},
  pages        = {B1092-B1114},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Gradient-based two-scale topology optimization with B-splines on sparse grids},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). <span
class="math inline"><em>h</em><em>p</em></span>-multilevel monte carlo
methods for uncertainty quantification of compressible navier–stokes
equations. <em>SISC</em>, <em>42</em>(4), B1067–B1091. (<a
href="https://doi.org/10.1137/18M1210575">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel $hp$-multilevel Monte Carlo method for the quantification of uncertainties in the compressible Navier--Stokes equations, using the discontinuous Galerkin method as deterministic solver. The multilevel approach exploits hierarchies of uniformly refined meshes while simultaneously increasing the polynomial degree of the ansatz space. It allows for a very large range of resolutions in the physical space and thus an efficient decrease of the statistical error. We prove that the overall complexity of the $hp$-multilevel Monte Carlo method to compute the mean field with prescribed accuracy is, in the best case, of quadratic order with respect to the accuracy. We also propose a novel and simple approach to estimate a lower confidence bound for the optimal number of samples per level, which helps to prevent overestimating these quantities. The method is in particular designed for application on queue-based computing systems, where it is desirable to compute a large number of samples during one iteration without overestimating the optimal number of samples. Our theoretical results are verified by numerical experiments for the two-dimensional compressible Navier--Stokes equations. In particular we consider a cavity flow problem from computational acoustics, demonstrating that the method is suitable to handle complex engineering problems.},
  archive      = {J_SISC},
  author       = {Andrea Beck and Jakob Dürrwächter and Thomas Kuhn and Fabian Meyer and Claus-Dieter Munz and Christian Rohde},
  doi          = {10.1137/18M1210575},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {4},
  pages        = {B1067-B1091},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {$hp$-multilevel monte carlo methods for uncertainty quantification of compressible navier--stokes equations},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An FE-FD method for anisotropic elliptic interface problems.
<em>SISC</em>, <em>42</em>(4), B1041–B1066. (<a
href="https://doi.org/10.1137/19M1291030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anisotropic elliptic interface problems are important but hard to solve either analytically or numerically. There is limited literature on numerical methods based on structured meshes. Finite element methods are often used, but the usual average error estimates cannot guarantee accuracy of the solution near or at the interface. For finite difference methods, it is challenging to discretize mixed derivatives and carry out the convergence analysis. In this paper, a new finite element-finite difference (FE-FD) method that combines a finite element discretization (away from the interface) whose coefficient matrix is a symmetric semipositive definite, with a finite difference discretization (near or on the interface) whose coefficient matrix part has properties of an M-matrix, is developed. An interpolation scheme based on the immersed interface method is also applied to compute the normal derivative of solution (or gradient) accurately from each side of the interface. Error analysis and numerical experiments are also presented.},
  archive      = {J_SISC},
  author       = {Baiying Dong and Xiufang Feng and Zhilin Li},
  doi          = {10.1137/19M1291030},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {4},
  pages        = {B1041-B1066},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {An FE-FD method for anisotropic elliptic interface problems},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A constrained pressure-temperature residual (CPTR) method
for non-isothermal multiphase flow in porous media. <em>SISC</em>,
<em>42</em>(4), B1014–B1040. (<a
href="https://doi.org/10.1137/19M1292023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For both isothermal and thermal petroleum reservoir simulation, the constrained pressure residual (CPR) method is the industry-standard preconditioner. This method is a two-stage process involving the solution of a restricted pressure system. While initially designed for the isothermal case, CPR is also the standard for thermal cases. However, its treatment of the energy conservation equation does not incorporate heat diffusion, which is often dominant in thermal cases. In this paper, we present an extension of CPR: the constrained pressure-temperature residual (CPTR) method, where a restricted pressure-temperature system is solved in the first stage. In previous work, we introduced a block preconditioner with an efficient Schur complement approximation for a pressure-temperature system. Here, we extend this method for multiphase flow as the first stage of CPTR. The algorithmic performance of different two-stage preconditioners is evaluated for reservoir simulation test cases.},
  archive      = {J_SISC},
  author       = {Thomas Roy and Tom B. Jönsthövel and Christopher Lemon and Andrew J. Wathen},
  doi          = {10.1137/19M1292023},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {4},
  pages        = {B1014-B1040},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A constrained pressure-temperature residual (CPTR) method for non-isothermal multiphase flow in porous media},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Ground states of spin-<span
class="math inline"><em>F</em></span> bose–einstein condensates.
<em>SISC</em>, <em>42</em>(4), B983–B1013. (<a
href="https://doi.org/10.1137/19M1271117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The computation of the ground states of spin-$F$ Bose--Einstein condensates (BECs) can be formulated as an energy minimization problem with two quadratic constraints. We discretize the energy functional and constraints using the Fourier pseudospectral schemes and view the discretized problem as an optimization problem on manifold. Three different types of retractions to the manifold are designed. They enable us to apply various optimization methods on manifold to solve the problem. Specifically, an adaptive regularized Newton method is used together with a cascadic multigrid technique to accelerate the convergence. Our method is the first applicable algorithm for BECs with an arbitrary integer spin, including the complicated spin-3 BECs. Extensive numerical results on ground states of spin-1, spin-2, and spin-3 BECs with diverse interaction and optical lattice potential in one/two/three dimensions are reported to show the efficiency of our method and to demonstrate interesting physical phenomena.},
  archive      = {J_SISC},
  author       = {Tonghua Tian and Yongyong Cai and Xinming Wu and Zaiwen Wen},
  doi          = {10.1137/19M1271117},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {4},
  pages        = {B983-B1013},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Ground states of spin-$F$ bose--einstein condensates},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A coupled multiphysics model and a decoupled stabilized
finite element method for the closed-loop geothermal system.
<em>SISC</em>, <em>42</em>(4), B951–B982. (<a
href="https://doi.org/10.1137/19M1293533">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of this article is to propose and analyze a new coupled multiphysics model and a decoupled stabilized finite element method for the closed-loop geothermal system, which mainly consists of a network of underground heat exchange pipelines to extract the geothermal heat from the geothermal reservoir. The new mathematical model considers the heat transfer between two different flow regions, namely the porous media flow in the geothermal reservoir and the free flow in the pipes. Darcy&#39;s law and Navier--Stokes equations are considered to govern the flows in these two regions, respectively, while the heat equation is coupled with the flow equations to describe the heat transfer in both regions. Furthermore, on the interface between the two regions, four physically valid interface conditions are considered to describe the continuity of the temperature and the heat flux as well as the no-fluid-communication feature of the closed-loop geothermal system. In the variational formulation, an interface stabilization term with a penalty parameter is added to overcome the difficulty of the possible numerical instability arising from the interface conditions in the finite element discretization. To solve the proposed model accurately and efficiently, we develop a stabilized decoupled finite element method which decouples not only the two flow regions but also the heat field and the flow field in each region. The stability of the proposed method is proved. Four numerical experiments are provided to demonstrate the applicability of the proposed model and the accuracy of the numerical method.},
  archive      = {J_SISC},
  author       = {Md. Abdullah Al Mahbub and Xiaoming He and Nasrin Jahan Nasu and Changxin Qiu and Yifan Wang and Haibiao Zheng},
  doi          = {10.1137/19M1293533},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {4},
  pages        = {B951-B982},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A coupled multiphysics model and a decoupled stabilized finite element method for the closed-loop geothermal system},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). HLLC+: Low-mach shock-stable HLLC-type riemann solver for
all-speed flows. <em>SISC</em>, <em>42</em>(4), B921–B950. (<a
href="https://doi.org/10.1137/18M119032X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The approximate Riemann solver of Harten--Lax--van Leer (HLL) and its variant HLLC (HLL with Contact restoration) solver are widely used as flux functions of finite volume Godunov-type methods for the solution of the gas dynamic Euler equations. However, the HLLC solver suffers from two significant difficulties: an accuracy problem at low-speed flows and shock instability at high-speed flows. To remedy such drawbacks, a novel low-Mach shock-stable HLLC-type scheme called HLLC+ is developed for all speeds. The antidissipation pressure fix is introduced first to overcome the accuracy problem in low Mach number limits. Then, shear viscosity is identified and scaled into the original HLLC scheme to overcome shock instability. A new pressure-based factor function without switching coefficients is devised to prevent shear viscosity from smearing the boundary layer. The new HLLC+ scheme involves no empirical parameters and is easy to implement. Asymptotic analysis and low Mach number test cases show the excellent behaviors of HLLC+ in low Mach number limits: no global cut-off problem, damping pressure checkerboard modes, having expected ${Ma^2}$ scaling of pressure and density fluctuations, and satisfaction of divergence constraint. Furthermore, this work manifests that the accuracy problem is associated with the normal velocity jumps of the flux interface, while shock instability is related to the transverse velocity jumps. Numerical test cases across a wide range of Mach numbers demonstrate the superior performance and potentiality of HLLC+ to simulate all Mach number flows.},
  archive      = {J_SISC},
  author       = {Shusheng Chen and Boxi Lin and Yansu Li and Chao Yan},
  doi          = {10.1137/18M119032X},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {4},
  pages        = {B921-B950},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {HLLC+: Low-mach shock-stable HLLC-type riemann solver for all-speed flows},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient solution of two-dimensional wave propagation
problems by CQ-wavelet BEM: Algorithm and applications. <em>SISC</em>,
<em>42</em>(4), B894–B920. (<a
href="https://doi.org/10.1137/19M1287614">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we consider wave propagation problems in two-dimensional unbounded domains, including dissipative effects, reformulated in terms of space-time boundary integral equations. For their solution, we employ a convolution quadrature (CQ) for the temporal and a Galerkin boundary element method (BEM) for the spatial discretization. It is known that one of the main advantages of the CQ-BEMs is the use of the FFT algorithm to retrieve the discrete time integral operators with an optimal linear complexity in time, up to a logarithmic term. It is also known that a key ingredient for the success of such methods is the efficient and accurate evaluation of all the integrals that define the matrix entries associated to the full space-time discretization. This topic has been successfully addressed when standard Lagrangian basis functions are considered for the space discretization. However, it results that, for such a choice of the basis, the BEM matrices are in general fully populated, a drawback that prevents the application of CQ-BEMs to large-scale problems. In this paper, as a possible remedy to reduce the global complexity of the method, we consider approximant functions of wavelet type. In particular, we propose a numerical procedure that, by taking advantage of the fast wavelet transform, allows us on the one hand to compute the matrix entries associated to the choice of wavelet basis functions by maintaining the accuracy of those associated to the Lagrangian basis ones and, on the other hand, to generate sparse matrices without the need of storing a priori the fully populated ones. Such an approach allows in principle the use of wavelet basis of any type and order, combined with CQ based on any stable ordinary differential equations solver. Several numerical results, showing the accuracy of the solution and the gain in terms of computer memory saving, are presented and discussed.},
  archive      = {J_SISC},
  author       = {Luca Desiderio and Silvia Falletta},
  doi          = {10.1137/19M1287614},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {4},
  pages        = {B894-B920},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Efficient solution of two-dimensional wave propagation problems by CQ-wavelet BEM: Algorithm and applications},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Low-memory, discrete ordinates, discontinuous galerkin
methods for radiative transport. <em>SISC</em>, <em>42</em>(4),
B869–B893. (<a href="https://doi.org/10.1137/19M1271956">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The discrete ordinates discontinuous Galerkin ($S_N$-DG) method is a well-established and practical approach for solving the radiative transport equation. In this paper, we study a low-memory variation of the upwind $S_N$-DG method. The proposed method uses a smaller finite element space that is constructed by coupling spatial unknowns across collocation angles, thereby yielding an approximation with fewer degrees of freedom than the standard method. Like the original $S_N$-DG method, the low-memory variation still preserves the asymptotic diffusion limit and maintains the characteristic structure needed for mesh sweeping algorithms. While we observe second-order convergence in the scattering dominated, diffusive regime, the low-memory method is in general only first-order accurate. To address this issue, we use upwind reconstruction to recover second-order accuracy. For both methods, numerical procedures based on upwind sweeps are proposed to reduce the system dimension in the underlying Krylov solver strategy.},
  archive      = {J_SISC},
  author       = {Zheng Sun and Cory D. Hauck},
  doi          = {10.1137/19M1271956},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {4},
  pages        = {B869-B893},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Low-memory, discrete ordinates, discontinuous galerkin methods for radiative transport},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An immersed boundary method with subgrid resolution and
improved numerical stability applied to slender bodies in stokes flow.
<em>SISC</em>, <em>42</em>(4), B847–B868. (<a
href="https://doi.org/10.1137/19M1280879">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The immersed boundary (IB) method is a numerical and mathematical formulation for solving fluid-structure interaction problems. It relies on solving fluid equations on an Eulerian fluid grid and interpolating the resulting velocity back onto immersed structures. To resolve slender fibers, the grid spacing must be on the order of the fiber radius, and thus the number of required grid points along the filament must be of the same order as the aspect ratio. Simulations of slender bodies using the IB method can therefore be intractable. A technique is presented to address this problem in the context of Stokes flow. The velocity of the structure is split into a component coming from the underlying fluid grid, which is coarser than normally required, and a component proportional to the force (a drag term). The drag coefficient is set so that a single sphere is represented exactly on a grid of arbitrary meshwidth. Implicit treatment of the drag term removes some of the stability restrictions normally associated with the IB method. This comes at a loss of accuracy, although tests are conducted that show 1--2 digits of relative accuracy can be obtained on coarser grids. After its accuracy and stability are tested, the method is applied to two real world examples: fibers in shear flow and a suspension of fibers. These examples show that the method can reproduce existing results and make reasonable predictions about the viscosity of an aligned fiber suspension.},
  archive      = {J_SISC},
  author       = {Ondrej Maxian and Charles S. Peskin},
  doi          = {10.1137/19M1280879},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {4},
  pages        = {B847-B868},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {An immersed boundary method with subgrid resolution and improved numerical stability applied to slender bodies in stokes flow},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Staggered DG methods for the pseudostress-velocity
formulation of the stokes equations on general meshes. <em>SISC</em>,
<em>42</em>(4), A2537–A2560. (<a
href="https://doi.org/10.1137/20M1322170">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce staggered discontinuous Galerkin methods for the stationary Stokes flow on polygonal meshes. The proposed method is based on the pseudostress-velocity formulation. A Lagrange multiplier on dual edges is introduced to impose the continuity of the pseudostress, which reduces the size of the final system via hybridization and eases the construction of the finite element space for the approximation of the pseudostress. The resulting method is stable and optimally convergent even on distorted or concave polygonal meshes. In addition, hanging nodes can be automatically incorporated in the construction of the method, which favors adaptive mesh refinement. Two types of local postprocessing for the velocity field are proposed to obtain one order higher convergence. Numerical experiments are provided to validate the theoretical findings and demonstrate the performance of the proposed method.},
  archive      = {J_SISC},
  author       = {Dohyun Kim and Lina Zhao and Eun-Jae Park},
  doi          = {10.1137/20M1322170},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {4},
  pages        = {A2537-A2560},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Staggered DG methods for the pseudostress-velocity formulation of the stokes equations on general meshes},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A highly efficient and accurate new scalar auxiliary
variable approach for gradient flows. <em>SISC</em>, <em>42</em>(4),
A2514–A2536. (<a href="https://doi.org/10.1137/19M1298627">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present several essential improvements to the powerful scalar auxiliary variable (SAV) approach. Firstly, by using the introduced scalar variable to control both the nonlinear and the explicit linear terms, we are able to reduce the number of linear equations with constant coefficients to be solved at each time step from two to one, so the computational cost of the new SAV approach is essentially half of the original SAV approach while keeping all its other advantages. This technique is also extended to the multiple SAV approach. Secondly, instead of discretizing the dynamical equation for the auxiliary variable, we use a first-order approximation of the energy balance equation, which allows us to construct high-order unconditionally energy-stable SAV schemes with uniform and, more importantly, variable time step sizes, enabling us to construct, for the first time, high-order unconditionally stable adaptive time-stepping backward differentiation formula schemes. Representative numerical examples are provided to demonstrate the improved efficiency and accuracy of the proposed method.},
  archive      = {J_SISC},
  author       = {Fukeng Huang and Jie Shen and Zhiguo Yang},
  doi          = {10.1137/19M1298627},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {4},
  pages        = {A2514-A2536},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A highly efficient and accurate new scalar auxiliary variable approach for gradient flows},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Global constraints preserving scalar auxiliary variable
schemes for gradient flows. <em>SISC</em>, <em>42</em>(4), A2489–A2513.
(<a href="https://doi.org/10.1137/19M1306221">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop several efficient numerical schemes which preserve exactly the global constraints for constrained gradient flows. Our schemes are based on the scalar auxiliary variable (SAV) approach combined with the Lagrangian multiplier approach. They are as efficient as the SAV schemes for unconstrained gradient flows, i.e., only require solving linear equations with constant coefficients at each time step plus an additional nonlinear algebraic system which can be solved at negligible cost, can be unconditionally energy stable, and preserves exactly the global constraints for constrained gradient flows. Ample numerical results for phase-field vesicle membrane and optimal partition models are presented to validate the effectiveness and accuracy of the proposed numerical schemes.},
  archive      = {J_SISC},
  author       = {Qing Cheng and Jie Shen},
  doi          = {10.1137/19M1306221},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {4},
  pages        = {A2489-A2513},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Global constraints preserving scalar auxiliary variable schemes for gradient flows},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Additive and hybrid nonlinear two-level schwarz methods and
energy minimizing coarse spaces for unstructured grids. <em>SISC</em>,
<em>42</em>(4), A2461–A2488. (<a
href="https://doi.org/10.1137/19M1276972">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonlinear domain decomposition (DD) methods, such as ASPIN (additive Schwarz preconditioned inexact Newton), RASPEN (restricted additive Schwarz preconditioned inexact Newton), nonlinear FETI-DP (finite element tearing and interconnecting-dual primal), and nonlinear BDDC (balancing DD by constraints), can be reasonable alternatives to classical Newton--Krylov-DD methods for the solution of sparse nonlinear systems of equations, e.g., arising from a discretization of a nonlinear partial differential equation (PDE). These nonlinear DD approaches are often able to effectively tackle unevenly distributed nonlinearities and outperform Newton&#39;s method with respect to convergence speed as well as global convergence behavior. Furthermore, they often improve parallel scalability due to a superior ratio of local to global work. Nonetheless, as for linear DD methods, it is often necessary to incorporate an appropriate coarse space in a second level to obtain numerical scalability for increasing numbers of subdomains. In addition, an appropriate coarse space can also improve the nonlinear convergence of nonlinear DD methods. In this paper, we introduce four variants for integrating coarse spaces in nonlinear Schwarz methods in an additive or multiplicative way using Galerkin projections. These new variants can be interpreted as natural nonlinear equivalents to well-known linear additive and hybrid two-level Schwarz preconditioners. Furthermore, they facilitate the use of various coarse spaces, e.g., coarse spaces based on energy-minimizing extensions, which can easily be used for irregular DDs, such as, e.g., those obtained by graph partitioners. In particular, multiscale finite element method (MsFEM)-type coarse spaces are considered, and it is shown that they outperform classical approaches for certain heterogeneous nonlinear problems. The new approaches are then compared with classical Newton--Krylov-DD and nonlinear one-level Schwarz approaches for different homogeneous and heterogeneous model problems based on the $p$-Laplace operator.},
  archive      = {J_SISC},
  author       = {Alexander Heinlein and Martin Lanser},
  doi          = {10.1137/19M1276972},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {4},
  pages        = {A2461-A2488},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Additive and hybrid nonlinear two-level schwarz methods and energy minimizing coarse spaces for unstructured grids},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A method for dimensionally adaptive sparse trigonometric
interpolation of periodic functions. <em>SISC</em>, <em>42</em>(4),
A2436–A2460. (<a href="https://doi.org/10.1137/19M1283483">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a method for dimensionally adaptive sparse trigonometric interpolation of multidimensional periodic functions belonging to a smoothness class of finite order. This method targets applications where periodicity must be preserved and the precise anisotropy is not known a priori. To the authors&#39; knowledge, this is the first instance of a dimensionally adaptive sparse interpolation algorithm that uses a trigonometric interpolation basis. The motivating application behind this work is the adaptive approximation of a multi-input model for a molecular potential energy surface (PES) where each input represents an angle of rotation. Our method is based on an anisotropic quasi-optimal estimate for the decay rate of the Fourier coefficients of the model; a least-squares fit to the coefficients of the interpolant is used to estimate the anisotropy. Thus, our adaptive approximation strategy begins with a coarse isotropic interpolant, which is gradually refined using the estimated anisotropic rates. The procedure takes several iterations where ever-more accurate interpolants are used to generate ever-improving anisotropy rates. We present several numerical examples of our algorithm where the adaptive procedure successfully recovers the theoretical “best” convergence rate, including an application to a periodic PES approximation. An open-source implementation of our algorithm resides in the Tasmanian UQ library developed at Oak Ridge National Laboratory.},
  archive      = {J_SISC},
  author       = {Zachary Morrow and Miroslav Stoyanov},
  doi          = {10.1137/19M1283483},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {4},
  pages        = {A2436-A2460},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A method for dimensionally adaptive sparse trigonometric interpolation of periodic functions},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Implicit-explicit multistep methods for hyperbolic systems
with multiscale relaxation. <em>SISC</em>, <em>42</em>(4), A2402–A2435.
(<a href="https://doi.org/10.1137/19M1303290">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the development of high-order space and time numerical methods based on implicit-explicit multistep time integrators for hyperbolic systems with relaxation. More specifically, we consider hyperbolic balance laws in which the convection and the source term may have very different time and space scales. As a consequence, the nature of the asymptotic limit changes completely, passing from a hyperbolic to a parabolic system. From the computational point of view, standard numerical methods designed for the fluid-dynamic scaling of hyperbolic systems with relaxation present several drawbacks and typically lose efficiency in describing the parabolic limit regime. In this work, in the context of implicit-explicit linear multistep methods we construct high-order space-time discretizations which are able to handle all the different scales and to capture the correct asymptotic behavior, independently from its nature, without time step restrictions imposed by the fast scales. Several numerical examples confirm the theoretical analysis.},
  archive      = {J_SISC},
  author       = {Giacomo Albi and Giacomo Dimarco and Lorenzo Pareschi},
  doi          = {10.1137/19M1303290},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {4},
  pages        = {A2402-A2435},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Implicit-explicit multistep methods for hyperbolic systems with multiscale relaxation},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A robust hyperviscosity formulation for stable RBF-FD
discretizations of advection-diffusion-reaction equations on manifolds.
<em>SISC</em>, <em>42</em>(4), A2371–A2401. (<a
href="https://doi.org/10.1137/19M1288747">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a new hyperviscosity formulation for stabilizing radial basis function-finite difference (RBF-FD) discretizations of advection-diffusion-reaction equations on manifolds $\mathbb{M} \subset \mathbb{R}^3$ of codimension 1. Our technique involves automatic addition of artificial hyperviscosity to damp out spurious modes in the differentiation matrices corresponding to surface gradients, in the process overcoming a technical limitation of a recently developed Euclidean formulation. Like the Euclidean formulation, the manifold formulation relies on von Neumann stability analysis performed on auxiliary differential operators that mimic the spurious solution growth induced by RBF-FD differentiation matrices. We demonstrate high-order convergence rates on problems involving surface advection and surface advection-diffusion. Finally, we demonstrate the applicability of our formulation to advection-diffusion-reaction equations on manifolds described purely as point clouds. Our surface discretizations use the recently developed RBF-least orthogonal interpolation method and, with the addition of hyperviscosity, are now empirically high-order accurate, stable, and free of stagnation errors.},
  archive      = {J_SISC},
  author       = {Varun Shankar and Grady B. Wright and Akil Narayan},
  doi          = {10.1137/19M1288747},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {4},
  pages        = {A2371-A2401},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A robust hyperviscosity formulation for stable RBF-FD discretizations of advection-diffusion-reaction equations on manifolds},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Preconditioned nonlinear iterations for overlapping
chebyshev discretizations with independent grids. <em>SISC</em>,
<em>42</em>(4), A2360–A2370. (<a
href="https://doi.org/10.1137/19M1242483">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The additive Schwarz method is usually presented as a preconditioner for a PDE linearization based on overlapping subsets of nodes from a global discretization. It has previously been shown how to apply Schwarz preconditioning to a nonlinear problem. By first replacing the original global PDE with the Schwarz overlapping problem, the global discretization becomes a simple union of subdomain discretizations, and unknowns do not need to be shared. In this way, restrictive-type updates can be avoided, and subdomains need to communicate only via interface interpolations. The resulting preconditioner can be applied linearly or nonlinearly. In the latter case, nonlinear subdomain problems are solved independently in parallel, and the frequency and amount of interprocess communication can be greatly reduced compared to global preconditioning of the sequence of linearized problems.},
  archive      = {J_SISC},
  author       = {Kevin W. Aiton and Tobin A. Driscoll},
  doi          = {10.1137/19M1242483},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {4},
  pages        = {A2360-A2370},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Preconditioned nonlinear iterations for overlapping chebyshev discretizations with independent grids},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). PDE-based multidimensional extrapolation of scalar fields
over interfaces with kinks and high curvatures. <em>SISC</em>,
<em>42</em>(4), A2344–A2359. (<a
href="https://doi.org/10.1137/19M1307883">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a PDE-based approach for the multidimensional extrapolation of smooth scalar quantities across interfaces with kinks and regions of high curvature. Unlike the commonly used method of [T. Aslam, J. Comput. Phys., 193 (2004), pp. 349--355], in which normal derivatives are extrapolated, the proposed approach is based on the extrapolation and weighting of Cartesian derivatives. As a result, second- and third-order accurate extensions in the $L^\infty$ norm are obtained with linear and quadratic extrapolations, respectively, even in the presence of sharp geometric features. The accuracy of the method is demonstrated on a number of examples in two and three spatial dimensions and compared to the approach of [T. Aslam, J. Comput. Phys., 193 (2004), pp. 349--355]. The importance of accurate extrapolation near sharp geometric features is highlighted on an example of solving the diffusion equation on evolving domains.},
  archive      = {J_SISC},
  author       = {Daniil Bochkov and Frederic Gibou},
  doi          = {10.1137/19M1307883},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {4},
  pages        = {A2344-A2359},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {PDE-based multidimensional extrapolation of scalar fields over interfaces with kinks and high curvatures},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Identification of point-like objects with multifrequency
sparse data. <em>SISC</em>, <em>42</em>(4), A2325–A2343. (<a
href="https://doi.org/10.1137/20M1312551">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The inverse acoustic scattering of point objects using multifrequency sparse measurements is studied. The objects may be a sum of point sources or point-like scatterers. We show that the locations and scattering strengths of the point objects can be uniquely identified by the multifrequency near or far fields taken at sparse sensors. Based on the uniqueness analysis, some direct methods have also been proposed for reconstructing the locations and determining the scattering strengths. The numerical examples are conducted to show the validity and robustness of the proposed numerical methods.},
  archive      = {J_SISC},
  author       = {Xia Ji and Xiaodong Liu},
  doi          = {10.1137/20M1312551},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {4},
  pages        = {A2325-A2343},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Identification of point-like objects with multifrequency sparse data},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A hybrid high-order discretization combined with nitsche’s
method for contact and tresca friction in small strain elasticity.
<em>SISC</em>, <em>42</em>(4), A2300–A2324. (<a
href="https://doi.org/10.1137/19M1286499">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We devise and analyze a hybrid high-order (HHO) method to discretize unilateral and bilateral contact problems with Tresca friction in small strain elasticity. The nonlinear frictional contact conditions are enforced weakly by means of a consistent Nitsche technique with symmetric, incomplete, and skew-symmetric variants. The present HHO-Nitsche method supports polyhedral meshes and delivers optimal energy-error estimates for smooth solutions under some minimal thresholds on the penalty parameters for all the symmetry variants. An explicit tracking of the dependency of the penalty parameters on the material coefficients is carried out to identify the robustness of the method in the incompressible limit, showing the more advantageous properties of the skew-symmetric variant. Two- and three-dimensional numerical results, including comparisons to benchmarks from the literature and to solutions obtained with an industrial software, as well as a prototype for an industrial application, illustrate the theoretical results and reveal that in practice the method behaves in a robust manner for all the symmetry variants in Nitsche&#39;s formulation.},
  archive      = {J_SISC},
  author       = {Franz Chouly and Alexandre Ern and Nicolas Pignet},
  doi          = {10.1137/19M1286499},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {4},
  pages        = {A2300-A2324},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A hybrid high-order discretization combined with nitsche&#39;s method for contact and tresca friction in small strain elasticity},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A fast tunable blurring algorithm for scattered data.
<em>SISC</em>, <em>42</em>(4), A2281–A2299. (<a
href="https://doi.org/10.1137/19M1268781">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A blurring algorithm with linear time complexity can reduce the small-scale content of data observed at scattered locations in a spatially extended domain of arbitrary dimension. The method works by forming a Gaussian interpolant of the input data and then convolving the interpolant with a multiresolution Gaussian approximation of the Green function to a differential operator whose spectrum can be tuned for problem-specific considerations. Like conventional blurring algorithms, which the new algorithm generalizes to data measured at locations other than a uniform grid, applications include deblurring and separation of spatial scales. An example illustrates a possible application toward enabling importance sampling approaches to data assimilation of geophysical observations, which are often scattered over a spatial domain, since blurring observations can make particle filters more effective at state estimation of large scales. Another example, motivated by data analysis of dynamics like ocean eddies that have strong separation of spatial scales, uses the algorithm to decompose scattered oceanographic float measurements into large-scale and small-scale components.},
  archive      = {J_SISC},
  author       = {Gregor Robinson and Ian Grooms},
  doi          = {10.1137/19M1268781},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {4},
  pages        = {A2281-A2299},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A fast tunable blurring algorithm for scattered data},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multivariate monte carlo approximation based on scattered
data. <em>SISC</em>, <em>42</em>(4), A2262–A2280. (<a
href="https://doi.org/10.1137/19M1249138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose and study a new multivariate stochastic scattered data quasi-interpolation scheme that is reminiscent of the classical Monte Carlo method for estimating integrals. We first employ a convolution operator to approximate (deterministically) Sobolev space functions and use a result of Cheney, Light, and Xu [On kernels and approximation orders, in Approximation Theory, Lecture Notes in Pure Appl. Math. 138, Dekker, 1992, pp. 227--242] and Cheney and Lei [Quasi-interpolation on irregular points, in Approximation and Computation, Internat. Ser. Numer. Math. 119, Birkhäuser Boston, 1994, pp. 121--135] to obtain an approximation error estimate in terms of moment conditions. We then approximate (stochastically) the convolution integral using a Monte Carlo method and derive the maximal mean squared error (M-MSE) estimate and mean $L^p$-error estimate on bounded domains which are in line with those obtained by the classical Monte Carlo method for estimating multivariate integrals. The introduction of convolution operators is solely for the purpose of facilitating error analysis. The implementation of this scheme does not require any numerical handling of the convolution integral involved. Our final approximant is in the form of scattered data quasi-interpolation. It enjoys a simple construction and optimal convergence rate, yet it provides an efficient tool in various computing environments. Asymptotic normality and confidence interval test results show that the scheme is computationally stable. Numerical simulation results show that the scheme is robust in the presence of noise.},
  archive      = {J_SISC},
  author       = {Wenwu Gao and Xingping Sun and Zongmin Wu and Xuan Zhou},
  doi          = {10.1137/19M1249138},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {4},
  pages        = {A2262-A2280},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Multivariate monte carlo approximation based on scattered data},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Entropy symmetrization and high-order accurate entropy
stable numerical schemes for relativistic MHD equations. <em>SISC</em>,
<em>42</em>(4), A2230–A2261. (<a
href="https://doi.org/10.1137/19M1275590">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents entropy symmetrization and high-order accurate entropy stable schemes for the relativistic magnetohydrodynamic (RMHD) equations. It is shown that the conservative RMHD equations are not symmetrizable and do not admit a thermodynamic entropy pair. To address this issue, a symmetrizable RMHD system, equipped with a convex thermodynamic entropy pair, is first proposed by adding a source term into the equations, providing an analogue to the nonrelativistic Godunov--Powell system. Arbitrarily high-order accurate entropy stable finite difference schemes are developed on Cartesian meshes based on the symmetrizable RMHD system. The crucial ingredients of these schemes include (i) affordable explicit entropy conservative fluxes which are technically derived through carefully selected parameter variables, (ii) a special high-order discretization of the source term in the symmetrizable RMHD system, and (iii) suitable high-order dissipative operators based on essentially nonoscillatory reconstruction to ensure the entropy stability. Several numerical tests demonstrate the accuracy and robustness of the proposed entropy stable schemes.},
  archive      = {J_SISC},
  author       = {Kailiang Wu and Chi-Wang Shu},
  doi          = {10.1137/19M1275590},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {4},
  pages        = {A2230-A2261},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Entropy symmetrization and high-order accurate entropy stable numerical schemes for relativistic MHD equations},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Moving-water equilibria preserving partial relaxation scheme
for the saint-venant system. <em>SISC</em>, <em>42</em>(4), A2206–A2229.
(<a href="https://doi.org/10.1137/19M1258098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a new moving-water equilibria preserving numerical scheme for the Saint-Venant system. The new scheme is designed in two major steps. First, the geometric source term is incorporated into the discharge flux, which results in a hyperbolic system with a global flux. Second, the discharge equation is relaxed so that the nonlinearity is moved into the stiff right-hand side of the added auxiliary equation. The main advantages of the new scheme are that (i) no special treatment of the geometric source term is required, and (ii) no nonlinear (cubic) equations should be solved to obtain the point values of the water depth out of the reconstructed equilibrium variables, as it must be done in the existing alternative methods. We also develop a hybrid numerical flux, which helps to handle various flow regimes in a stable manner. Several numerical experiments are performed to verify that the proposed scheme is capable of exactly preserving general moving-water steady states and accurately capturing their small perturbations.},
  archive      = {J_SISC},
  author       = {Xin Liu and Xi Chen and Shi Jin and Alexander Kurganov and Tong Wu and Hui Yu},
  doi          = {10.1137/19M1258098},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {4},
  pages        = {A2206-A2229},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Moving-water equilibria preserving partial relaxation scheme for the saint-venant system},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Order reduction methods for solving large-scale differential
matrix riccati equations. <em>SISC</em>, <em>42</em>(4), A2182–A2205.
(<a href="https://doi.org/10.1137/19M1264217">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the numerical solution of large-scale symmetric differential matrix Riccati equations. Under certain hypotheses on the data, reduced order methods have recently arisen as a promising class of solution strategies by forming low-rank approximations to the sought after solution at selected timesteps. We show that great computational and memory savings are obtained by a reduction process onto rational Krylov subspaces as opposed to current approaches. By specifically addressing the solution of the reduced differential equation and reliable stopping criteria, we are able to obtain accurate final approximations at low memory and computational requirements. This is obtained by employing a two-phase strategy that separately enhances the accuracy of the algebraic approximation and the time integration. The new method allows us to numerically solve much larger problems than in the current literature. Numerical experiments on benchmark problems illustrate the effectiveness of the procedure with respect to existing solvers.},
  archive      = {J_SISC},
  author       = {Gerhard Kirsten and Valeria Simoncini},
  doi          = {10.1137/19M1264217},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {4},
  pages        = {A2182-A2205},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Order reduction methods for solving large-scale differential matrix riccati equations},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A staggered cell-centered DG method for linear elasticity on
polygonal meshes. <em>SISC</em>, <em>42</em>(4), A2158–A2181. (<a
href="https://doi.org/10.1137/19M1278016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a new numerical method, namely, a locking-free staggered cell-centered discontinuous Galerkin method for linear elasticity on fairly general meshes. The method is well suited for general meshes possibly including hanging nodes; in particular, it does not deteriorate when the mesh becomes highly distorted. There are three unknowns involved in our formulation: stress, displacement, and rotation. The continuities of the three unknowns are staggered on the interelement boundaries. In addition, the symmetry of the stress tensor is imposed weakly by the introduction of Lagrange multipliers. Optimal a priori error estimates covering low regularities in $L^2$ errors of stress, displacement, and rotation are given; in addition, the locking-free error estimates are also investigated. Numerical experiments confirm the theoretical findings and verify the flexibility to rough grids and the locking-free property of the proposed method.},
  archive      = {J_SISC},
  author       = {Lina Zhao and Eun-Jae Park},
  doi          = {10.1137/19M1278016},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {4},
  pages        = {A2158-A2181},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A staggered cell-centered DG method for linear elasticity on polygonal meshes},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal learning with local nonlinear parametric models over
continuous designs. <em>SISC</em>, <em>42</em>(4), A2134–A2157. (<a
href="https://doi.org/10.1137/19M1245608">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of optimizing an unknown function over a multidimensional continuous domain, where function evaluation is noisy and expensive. We assume that a globally accurate model of the function is not available, but there exist some parametric models that can well approximate the function in local regions. In this paper, we propose an algorithm in the optimal learning framework that learns the shape of the function and finds the optimal design with a limited number of measurements. We construct belief functions using a radial basis function--based local approximation technique, and use the knowledge gradient policy to decide where to measure, aiming at maximizing the value of information from each measurement. Experiments on both synthetic test problems and a real materials science application show the strong performance of our algorithm.},
  archive      = {J_SISC},
  author       = {Xinyu He and Kristofer G. Reyes and Warren B. Powell},
  doi          = {10.1137/19M1245608},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {4},
  pages        = {A2134-A2157},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Optimal learning with local nonlinear parametric models over continuous designs},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A computational framework for two-dimensional random walks
with restarts. <em>SISC</em>, <em>42</em>(4), A2108–A2133. (<a
href="https://doi.org/10.1137/19M1304362">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The treatment of two-dimensional random walks in the quarter plane leads to Markov processes which involve semi-infinite matrices having Toeplitz or block Toeplitz structure plus a low-rank correction. We propose an extension of the framework introduced in [D. A. Bini, S. Massei, and B. Meini, Math. Comp., 87 (2018), pp. 2811--2830] which allows us to deal with more general situations such as processes involving restart events. This is motivated by the need for modeling processes that can incur in unexpected failures like computer system reboots. We present a theoretical analysis of an enriched Banach algebra that, combined with appropriate algorithms, enables the numerical treatment of these problems. The results are applied to the solution of bidimensional quasi-birth-death processes with infinitely many phases which model random walks in the quarter plane, relying on the matrix analytic approach. The reliability of our approach is confirmed by extensive numerical experimentation on several case studies.},
  archive      = {J_SISC},
  author       = {Dario A. Bini and Stefano Massei and Beatrice Meini and Leonardo Robol},
  doi          = {10.1137/19M1304362},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {4},
  pages        = {A2108-A2133},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A computational framework for two-dimensional random walks with restarts},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). 3/4-discrete optimal transport. <em>SISC</em>,
<em>42</em>(4), A2088–A2107. (<a
href="https://doi.org/10.1137/19M1252569">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with the 3/4-discrete 2-Wasserstein optimal transport between two measures, where one is supported on a set of line segments and the other is supported on a set of points. We select the most suitable optimization procedure that computes the optimal transport. Then we address the problem of projecting point clouds on the set of measures supported on segments for the optimal transportation distance. We provide numerical examples of approximation of point clouds by segments.},
  archive      = {J_SISC},
  author       = {Léo Lebrat and Frédéric de Gournay and Jonas Kahn},
  doi          = {10.1137/19M1252569},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {4},
  pages        = {A2088-A2107},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {3/4-discrete optimal transport},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multilevel sequential importance sampling for rare event
estimation. <em>SISC</em>, <em>42</em>(4), A2062–A2087. (<a
href="https://doi.org/10.1137/19M1289601">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The estimation of the probability of rare events is an important task in reliability and risk assessment. We consider failure events that are expressed in terms of a limit state function, which depends on the solution of a partial differential equation (PDE). Since numerical evaluations of PDEs are computationally expensive, estimating such probabilities of failure by Monte Carlo sampling is intractable. We develop a novel estimator based on a sequential importance sampler using discretizations of PDE-based limit state functions with different accuracies. A twofold adaptive algorithm ensures that we obtain an estimate based on the desired discretization accuracy. Moreover, we suggest and study the choice of the Markov chain Monte Carlo kernel for use with sequential importance sampling. Instead of the popular adaptive conditional sampling method, we propose a new algorithm that uses independent proposals from an adaptively constructed von Mises--Fisher--Nakagami distribution.},
  archive      = {J_SISC},
  author       = {F. Wagner and J. Latz and I. Papaioannou and E. Ullmann},
  doi          = {10.1137/19M1289601},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {4},
  pages        = {A2062-A2087},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Multilevel sequential importance sampling for rare event estimation},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Transformed snapshot interpolation with high resolution
transforms. <em>SISC</em>, <em>42</em>(4), A2037–A2061. (<a
href="https://doi.org/10.1137/19M126356X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last few years, several methods have been developed to deal with jump singularities in parametric or stochastic hyperbolic PDEs. They typically use some alignment of the jump-sets in physical space before performing well-established reduced order modeling techniques such as reduced basis methods, proper orthogonal decomposition, or simply interpolation. In the current literature, the transforms are typically of low resolution in space, mostly low order polynomials, Fourier modes, or constant shifts. In this paper, we discuss higher resolution transforms in one of the recent methods, the transformed snapshot interpolation. We introduce a new discretization of the transforms with an appropriate behavior near singularities and consider their numerical computation via an optimization procedure.},
  archive      = {J_SISC},
  author       = {G. Welper},
  doi          = {10.1137/19M126356X},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {4},
  pages        = {A2037-A2061},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Transformed snapshot interpolation with high resolution transforms},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Numerical upscaling of perturbed diffusion problems.
<em>SISC</em>, <em>42</em>(4), A2014–A2036. (<a
href="https://doi.org/10.1137/19M1278211">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we study elliptic partial differential equations with rapidly varying diffusion coefficient that can be represented as a perturbation of a reference coefficient. We develop a numerical method for efficiently solving multiple perturbed problems by reusing local computations performed with the reference coefficient. The proposed method is based on the Petrov--Galerkin localized orthogonal decomposition (PG-LOD), which allows for straightforward parallelization with low communication overhead and memory consumption. We focus on two types of perturbations: local defects, which we treat by recomputation of multiscale shape functions, and global mappings of a reference coefficient for which we apply the domain mapping method. We analyze the proposed method for these problem classes and present several numerical examples.},
  archive      = {J_SISC},
  author       = {Fredrik Hellman and Tim Keil and Axel Målqvist},
  doi          = {10.1137/19M1278211},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {4},
  pages        = {A2014-A2036},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Numerical upscaling of perturbed diffusion problems},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Reconciling bayesian and perimeter regularization for binary
inversion. <em>SISC</em>, <em>42</em>(4), A1984–A2013. (<a
href="https://doi.org/10.1137/18M1179559">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A central theme in classical algorithms for the reconstruction of discontinuous functions from observational data is perimeter regularization via the use of total variation. On the other hand, sparse or noisy data often demand a probabilistic approach to the reconstruction of images, to enable uncertainty quantification; the Bayesian approach to inversion, which itself introduces a form of regularization, is a natural framework in which to carry this out. In this paper the link between Bayesian inversion methods and perimeter regularization is explored. In this paper two links are studied: (i) the maximum a posteriori objective function of a suitably chosen Bayesian phase-field approach is shown to be closely related to a least squares plus perimeter regularization objective; (ii) sample paths of a suitably chosen Bayesian level set formulation are shown to possess a finite perimeter and to have the ability to learn about the true perimeter.},
  archive      = {J_SISC},
  author       = {Oliver R. A. Dunbar and Matthew M. Dunlop and Charles M. Elliott and Viet Ha Hoang and Andrew M. Stuart},
  doi          = {10.1137/18M1179559},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {4},
  pages        = {A1984-A2013},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Reconciling bayesian and perimeter regularization for binary inversion},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). WaveHoltz: Iterative solution of the helmholtz equation via
the wave equation. <em>SISC</em>, <em>42</em>(4), A1950–A1983. (<a
href="https://doi.org/10.1137/19M1299062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new iterative method, the WaveHoltz iteration, for solution of the Helmholtz equation is presented. WaveHoltz is a fixed point iteration that filters the solution to the solution of a wave equation with time periodic forcing and boundary data. The WaveHoltz iteration corresponds to a linear and coercive operator which, after discretization, can be recast as a positive definite linear system of equations. The solution to this system of equations approximates the Helmholtz solution and can be accelerated by Krylov subspace techniques. Analysis of the continuous and discrete cases is presented, as are numerical experiments.},
  archive      = {J_SISC},
  author       = {Daniel Appelö and Fortino Garcia and Olof Runborg},
  doi          = {10.1137/19M1299062},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {4},
  pages        = {A1950-A1983},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {WaveHoltz: Iterative solution of the helmholtz equation via the wave equation},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A physically consistent, flexible, and efficient strategy to
convert local boundary conditions into nonlocal volume constraints.
<em>SISC</em>, <em>42</em>(4), A1935–A1949. (<a
href="https://doi.org/10.1137/19M1266617">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonlocal models provide exceptional simulation fidelity for a broad spectrum of scientific and engineering applications. However, wider deployment of nonlocal models is hindered by several modeling and numerical challenges. Among those, we focus on the nontrivial prescription of nonlocal boundary conditions, or volume constraints, that must be provided on a layer surrounding the domain where the nonlocal equations are posed. The challenge arises from the fact that, in general, data are provided on surfaces (as opposed to volumes) in the form of force or pressure data. In this paper we introduce an efficient, flexible, and physically consistent technique for an automatic conversion of surface (local) data into volumetric data that does not have any constraints on the geometry of the domain or on the regularity of the nonlocal solution and that is not tied to any discretization. We show that our formulation is well-posed and that the limit of the nonlocal solution, as the nonlocality vanishes, is the local solution corresponding to the available surface data. Quadratic convergence rates are proved for the strong energy and $L^2$ convergence. We illustrate the theory with one-dimensional numerical tests whose results provide the groundwork for realistic simulations.},
  archive      = {J_SISC},
  author       = {Marta D&#39;Elia and Xiaochuan Tian and Yue Yu},
  doi          = {10.1137/19M1266617},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {4},
  pages        = {A1935-A1949},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A physically consistent, flexible, and efficient strategy to convert local boundary conditions into nonlocal volume constraints},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mixed precision block fused multiply-add: Error analysis and
application to GPU tensor cores. <em>SISC</em>, <em>42</em>(3),
C124–C141. (<a href="https://doi.org/10.1137/19M1289546">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computing units that carry out a fused multiply-add (FMA) operation with matrix arguments, referred to as tensor units by some vendors, have great potential for use in scientific computing. However, these units are inherently mixed precision, and existing rounding error analyses do not support them. We consider a mixed precision block FMA that generalizes both the usual scalar FMA and existing tensor units. We describe how to exploit such a block FMA in the numerical linear algebra kernels of matrix multiplication and LU factorization and give detailed rounding error analyses of both kernels. An important application is to GMRES-based iterative refinement with block FMAs, about which our analysis provides new insight. Our framework is applicable to the tensor core units in the NVIDIA Volta and Turing GPUs. For these we compare matrix multiplication and LU factorization with TC16 and TC32 forms of FMA, which differ in the precision used for the output of the tensor cores. Our experiments on an NVDIA V100 GPU confirm the predictions of the analysis that the TC32 variant is much more accurate than the TC16 one, and they show that the accuracy boost is obtained with almost no performance loss.},
  archive      = {J_SISC},
  author       = {Pierre Blanchard and Nicholas J. Higham and Florent Lopez and Theo Mary and Srikara Pranesh},
  doi          = {10.1137/19M1289546},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {3},
  pages        = {C124-C141},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Mixed precision block fused multiply-add: Error analysis and application to GPU tensor cores},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient matrix-free high-order finite element evaluation
for simplicial elements. <em>SISC</em>, <em>42</em>(3), C97–C123. (<a
href="https://doi.org/10.1137/19M1246523">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the gap between processor clock speeds and memory bandwidth speeds continuing to increase, the use of arithmetically intense schemes, such as high-order finite element methods, continues to be of considerable interest. In particular, the use of matrix-free formulations of finite element operators for tensor-product elements of quadrilaterals in two dimensions and hexahedra in three dimensions, in combination with single-instruction multiple-data instruction sets, is a well-studied topic at present for the efficient implicit solution of elliptic equations. However, a considerable limiting factor for this approach is the use of meshes comprising of only quadrilaterals or hexahedra, the creation of which is still an open problem within the mesh generation community. In this article, we study the efficiency of high-order finite element operators for the Helmholtz equation with a focus on extending this approach to unstructured meshes of triangles, tetrahedra, and prismatic elements using the spectral/$hp$ element method and corresponding tensor-product bases for these element types. We show that although performance is naturally degraded when going from hexahedra to these simplicial elements, efficient implementations can still be obtained that are capable of attaining 50\% through 70\% floating point operations of the peak of processors with both AVX2 and AVX512 instruction sets.},
  archive      = {J_SISC},
  author       = {David Moxey and Roman Amici and Mike Kirby},
  doi          = {10.1137/19M1246523},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {3},
  pages        = {C97-C123},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Efficient matrix-free high-order finite element evaluation for simplicial elements},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Enclave tasking for DG methods on dynamically adaptive
meshes. <em>SISC</em>, <em>42</em>(3), C69–C96. (<a
href="https://doi.org/10.1137/19M1276194">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-order discontinuous Galerkin (DG) methods promise to be an excellent discretization paradigm for hyperbolic differential equation solvers running on supercomputers, since they combine high arithmetic intensity with localized data access, since they straightforwardly translate into nonoverlapping domain decomposition, and since they facilitate dynamic adaptivity without the need for conformal meshes. An efficient parallel evaluation of DG weak formulation in an MPI+X setting, however, remains nontrivial as dependency graphs over dynamically adaptive meshes change with each mesh refinement or coarsening, as resolution transitions yield nontrivial data flow dependencies, and as data sent along domain boundaries through message passing (MPI) have to be triggered in the correct order. Domain decomposition with MPI alone starts to become insufficient if the mesh changes very frequently, if mesh changes cannot be predicted, and if limiters and nonlinear per-cell solves yield unpredictable costs per cell. We introduce enclave tasking as a task invocation technique for shared memory and MPI+X: It does not assemble any task graph; instead the mesh traversal spawns ready tasks directly. A marker-and-cell approach ensures that tasks feeding into MPI or triggering mesh modifications as well as latency-sensitive or bandwidth-demanding tasks are processed with high priority. The remaining cell tasks form enclaves, i.e., groups of tasks that can be processed in the background. Enclave tasking introduces high concurrency which is homogeneously distributed over the mesh traversal, it mixes memory-intensive volumetric DG calculations with compute-bound Riemann solves, and it helps to overlap communication with computations. Our work focuses on ADER-DG and patch-based finite volumes. Yet, we discuss how the paradigm can be generalized to the whole DG family and finite volume stand-alone solvers.},
  archive      = {J_SISC},
  author       = {Dominic Etienne Charrier and Benjamin Hazelwood and Tobias Weinzierl},
  doi          = {10.1137/19M1276194},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {3},
  pages        = {C69-C96},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Enclave tasking for DG methods on dynamically adaptive meshes},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). High order asymptotic preserving deferred correction
implicit-explicit schemes for kinetic models. <em>SISC</em>,
<em>42</em>(3), B816–B845. (<a
href="https://doi.org/10.1137/19M128973X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work introduces an extension of the residual distribution (RD) framework to stiff relaxation problems. The RD is a class of schemes which is used to solve a hyperbolic system of partial differential equations. To our knowledge, it has been used only for systems with mild source terms, such as gravitation problems or shallow water equations. What we propose is an implicit-explicit (IMEX) version of the RD schemes that can resolve stiff source terms, without refining the discretization up to the stiffness scale. This can be particularly useful in various models, where the stiffness is given by topological or physical quantities, e.g., multiphase flows, kinetic models, or viscoelasticity problems. We will focus on kinetic models that are BGK approximation of hyperbolic conservation laws. The extension to more complicated problems will be carried out in future works. The provided scheme is able to catch different relaxation scales automatically, without losing accuracy; we prove that the scheme is asymptotic preserving and this guarantees that, in the relaxation limit, we recast the expected macroscopic behavior. To get a high order accuracy, we use an IMEX time discretization combined with a deferred correction procedure, while naturally RD provides high order space discretization. Finally, we show some numerical tests in one and two dimensions for stiff systems of equations.},
  archive      = {J_SISC},
  author       = {Rémi Abgrall and Davide Torlo},
  doi          = {10.1137/19M128973X},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {3},
  pages        = {B816-B845},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {High order asymptotic preserving deferred correction implicit-explicit schemes for kinetic models},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Approximation to singular quadratic collision model in
fokker–planck–landau equation. <em>SISC</em>, <em>42</em>(3), B792–B815.
(<a href="https://doi.org/10.1137/18M1230268">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a Hermite--Galerkin spectral method to numerically solve the spatially homogeneous Fokker--Planck--Landau equation with a singular quadratic collision model. To overcome the difficulty of the computationally expensive collision model, we adopt a novel approximation formulated by a combination of a simple linear term and a quadratic term very expensive to evaluate. Using the Hermite expansion, the quadratic term is evaluated exactly by calculating the spectral coefficients. To deal with singularities, we make use of Burnett polynomials so that even a very singular collision model can be handled smoothly. Numerical examples demonstrate that our method can capture low-order moments with satisfactory accuracy and performance.},
  archive      = {J_SISC},
  author       = {Ruo Li and Yanli Wang and Yixuan Wang},
  doi          = {10.1137/18M1230268},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {3},
  pages        = {B792-B815},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Approximation to singular quadratic collision model in fokker--planck--landau equation},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust preconditioners for a new stabilized discretization
of the poroelastic equations. <em>SISC</em>, <em>42</em>(3), B761–B791.
(<a href="https://doi.org/10.1137/19M1261250">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present block preconditioners for a stabilized discretization of the poroelastic equations developed in [C. Rodrigo, X. Hu, P. Ohm, J. Adler, F. Gaspar, and L. Zikatanov, Comput. Methods Appl. Mech. Engrg., 341 (2018), pp. 467--484]. The discretization is proved to be well-posed with respect to the physical and discretization parameters and thus provides a framework to develop preconditioners that are robust with respect to such parameters as well. We construct both norm-equivalent (diagonal) and field-of-value-equivalent (triangular) preconditioners for both the stabilized discretization and a perturbation of the stabilized discretization, which leads to a smaller overall problem after static condensation. Numerical tests for both two- and three-dimensional problems confirm the robustness of the block preconditioners with respect to the physical and discretization parameters.},
  archive      = {J_SISC},
  author       = {J. H. Adler and F. J. Gaspar and X. Hu and P. Ohm and C. Rodrigo and L. T. Zikatanov},
  doi          = {10.1137/19M1261250},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {3},
  pages        = {B761-B791},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Robust preconditioners for a new stabilized discretization of the poroelastic equations},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptive second-order crank–nicolson time-stepping schemes
for time-fractional molecular beam epitaxial growth models.
<em>SISC</em>, <em>42</em>(3), B738–B760. (<a
href="https://doi.org/10.1137/19M1259675">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptive second-order Crank--Nicolson time-stepping methods using the recent scalar auxiliary variable (SAV) approach are developed for the time-fractional molecular beam epitaxial models with Caputo&#39;s fractional derivative. Based on the piecewise linear interpolation, the Caputo&#39;s derivative is approximated by a novel second-order formula, which is naturally suitable for a general class of nonuniform meshes and essentially preserves the positive semidefinite property of the integral kernel. The resulting Crank--Nicolson SAV time-stepping schemes are unconditionally energy stable on arbitrary nonuniform time meshes. The fast algorithm and adaptive time strategy are employed to speed up the numerical computation. Ample numerical results show that our methods are computationally efficient in multiscale time simulations and appropriate for accurately resolving the intrinsically initial singularity of the solution and for efficiently capturing the fast dynamics away from the initial time.},
  archive      = {J_SISC},
  author       = {Bingquan Ji and Hong-lin Liao and Yuezheng Gong and Luming Zhang},
  doi          = {10.1137/19M1259675},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {3},
  pages        = {B738-B760},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Adaptive second-order crank--nicolson time-stepping schemes for time-fractional molecular beam epitaxial growth models},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Orthogonality sampling method for the electromagnetic
inverse scattering problem. <em>SISC</em>, <em>42</em>(3), B722–B737.
(<a href="https://doi.org/10.1137/19M129783X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the electromagnetic inverse scattering problem that aims to determine the location and shape of anisotropic scatterers from far field data (at a fixed frequency). We study the orthogonality sampling method, which is a simple, fast, and robust imaging method for solving the inverse scattering problem. We provide a theoretical analysis as well as a stability estimate for the sampling method. An equivalent relation between the orthogonality sampling method and the direct sampling method is also established. The analysis uses the Factorization method for the far field operator, and it plays an important role in the justifications along with the Funk--Hecke integral identity. Finally, we present some numerical examples to validate the performance of the sampling methods for anisotropic scatterers in three dimensions.},
  archive      = {J_SISC},
  author       = {Isaac Harris and Dinh-Liem Nguyen},
  doi          = {10.1137/19M129783X},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {3},
  pages        = {B722-B737},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Orthogonality sampling method for the electromagnetic inverse scattering problem},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Block preconditioning techniques for geophysical
electromagnetics. <em>SISC</em>, <em>42</em>(3), B696–B721. (<a
href="https://doi.org/10.1137/19M1241611">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Geophysical electromagnetic (EM) methods are an important technique for investigating the subsurface of the Earth, particularly when exploring for metallic ore deposits but also when delineating hydrocarbon reserves and in hydrological and geotechnical applications. Geophysical EM methods provide information on subsurface structure from depths of meters to hundreds of kilometers. Quantitative interpretation of the data from such EM methods, whether via trial-and-error forward modeling or inversion, requires the solution of many forward problems, simulating EM fields in candidate models of the Earth&#39;s subsurface. In this paper, we consider the solution of the linear systems of equations that arise from finite-element discretization of such forward problems, in the setting where the Helmholtz decomposition of the electric field intensity is needed for the inversion process. In particular, a block preconditioning framework is proposed for the equivalent real form of the resulting modeling equations. Particular attention is paid to the interaction between inner and outer Krylov iterations in the resulting preconditioner, and numerical results are presented that explore the balance between time-to-solution and iterations of the outer Krylov method.},
  archive      = {J_SISC},
  author       = {H. Bin Zubair Syed and C. Farquharson and S. MacLachlan},
  doi          = {10.1137/19M1241611},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {3},
  pages        = {B696-B721},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Block preconditioning techniques for geophysical electromagnetics},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sparse multidimensional exponential analysis with an
application to radar imaging. <em>SISC</em>, <em>42</em>(3), B675–B695.
(<a href="https://doi.org/10.1137/19M1278004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a $d$-dimensional exponential analysis algorithm that offers a range of advantages compared to other methods. The technique does not suffer the curse of dimensionality and only needs $O((d+1)n)$ samples for the analysis of an $n$-sparse expression. It does not require a prior estimate of the sparsity $n$ of the $d$-variate exponential sum. The method can work with sub-Nyquist sampled data and offers a validation step, which is very useful in low SNR conditions. A favorable computation cost results from the fact that $d$ independent smaller systems are solved instead of one large system incorporating all measurements simultaneously. So the method easily lends itself to a parallel execution. Our motivation to develop the technique comes from 2-D and 3-D radar imaging and is therefore illustrated on such examples.},
  archive      = {J_SISC},
  author       = {Annie Cuyt and Yuan Hou and Ferre Knaepkens and Wen-shin Lee},
  doi          = {10.1137/19M1278004},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {3},
  pages        = {B675-B695},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Sparse multidimensional exponential analysis with an application to radar imaging},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A spectral algorithm for the time-dependent kohn–sham
equations: Accurately treating external potentials based on frozen
gaussian approximations. <em>SISC</em>, <em>42</em>(3), B656–B674. (<a
href="https://doi.org/10.1137/19M1245104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we develop a novel spectral method for solving the time-dependent Kohn--Sham equations in the semiclassical regime. Our strategy is to use a single-step predictor-corrector algorithm, where the propagator is derived using a Fourier integral operator commonly known as the frozen Gaussian approximation (FGA) ansatz. In the case of laser potentials, we derived a simplified FGA to avoid the high dimensional integration. Numerical examples are provided to verify applicability, as well as efficiency and accuracy of the scheme.},
  archive      = {J_SISC},
  author       = {Ricardo Delgadillo and Di Liu},
  doi          = {10.1137/19M1245104},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {3},
  pages        = {B656-B674},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A spectral algorithm for the time-dependent kohn--sham equations: Accurately treating external potentials based on frozen gaussian approximations},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The exponential scalar auxiliary variable (e-SAV) approach
for phase field models and its explicit computing. <em>SISC</em>,
<em>42</em>(3), B630–B655. (<a
href="https://doi.org/10.1137/19M1305914">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider an exponential scalar auxiliary variable (E-SAV) approach to obtain energy stable schemes for a class of phase field models. This novel auxiliary variable method based on the exponential form of the nonlinear free energy potential is more effective and applicable than the traditional SAV method, which is very popular in constructing energy stable schemes. The first contribution is that the auxiliary variable without square root removes the bounded-from-below restriction of the nonlinear free energy potential. Then we prove the unconditional energy stability for semidiscrete schemes carefully and rigorously. Another contribution is that we provide a total and explicit discretization of the auxiliary variable combined with the nonlinear term. Such a modification is very efficient for fast calculations. Furthermore, the positivity preserving property of $r$ can be guaranteed, which is very important and reasonable for the models&#39; equivalence. In addition, for complex phase field models with two or more unknown variables and nonlinear terms, we construct a multiple E-SAV (ME-SAV) approach to enhance the applicability of the proposed E-SAV approach. A comparative study of classical SAV and E-SAV approaches is considered to show the accuracy and efficiency. Finally, we present various 2D numerical simulations to demonstrate the stability and accuracy.},
  archive      = {J_SISC},
  author       = {Zhengguang Liu and Xiaoli Li},
  doi          = {10.1137/19M1305914},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {3},
  pages        = {B630-B655},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {The exponential scalar auxiliary variable (E-SAV) approach for phase field models and its explicit computing},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Pressure robust weak galerkin finite element methods for
stokes problems. <em>SISC</em>, <em>42</em>(3), B608–B629. (<a
href="https://doi.org/10.1137/19M1266320">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we develop a pressure robust weak Galerkin finite element scheme for Stokes equations on polygonal mesh. The major idea for achieving a pressure-independent energy-error estimate is to use a divergence preserving velocity reconstruction operator in the discretization of the right-hand side body force. Our scheme only modifies the body force assembling but remains the same stiffness matrix for Stokes simulation. The optimal convergence results for velocity and pressure have been established in this paper. Finally, numerical examples based on triangular, rectangular, and polygonal meshes are presented for validating the theoretical conclusions.},
  archive      = {J_SISC},
  author       = {Lin Mu},
  doi          = {10.1137/19M1266320},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {3},
  pages        = {B608-B629},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Pressure robust weak galerkin finite element methods for stokes problems},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Computational homogenization of time-harmonic maxwell’s
equations. <em>SISC</em>, <em>42</em>(3), B581–B607. (<a
href="https://doi.org/10.1137/19M1293818">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we consider a numerical homogenization technique for curl-curl problems that is based on the framework of the localized orthogonal decomposition and which was proposed in [D. Gallistl, P. Henning, and B. Verfürth, SIAM J. Numer. Anal., 56 (2018), pp. 1570--1596] for problems with essential boundary conditions. The findings of the aforementioned work establish quantitative homogenization results for the time-harmonic Maxwell&#39;s equations that hold beyond assumptions of periodicity; however, a practical realization of the approach was left open. In this paper, we transfer the findings from essential boundary conditions to natural boundary conditions, and we demonstrate that the approach yields a computable numerical method. We also investigate how boundary values of the source term can affect the computational complexity and accuracy. Our findings will be supported by various numerical experiments, both in 2D and 3D.},
  archive      = {J_SISC},
  author       = {Patrick Henning and Anna Persson},
  doi          = {10.1137/19M1293818},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {3},
  pages        = {B581-B607},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Computational homogenization of time-harmonic maxwell&#39;s equations},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Image-driven biophysical tumor growth model calibration.
<em>SISC</em>, <em>42</em>(3), B549–B580. (<a
href="https://doi.org/10.1137/19M1275280">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a novel formulation for the calibration of a biophysical tumor growth model from a single-time snapshot, multiparametric magnetic resonance imaging (MRI) scan of a glioblastoma patient. Tumor growth models are typically nonlinear parabolic partial differential equations (PDEs). Thus, we have to generate a second snapshot to be able to extract significant information from a single patient snapshot. We create this two-snapshot scenario as follows. We use an atlas (an average of several scans of healthy individuals) as a substitute for an earlier, pretumor, MRI scan of the patient. Then, using the patient scan and the atlas, we combine image-registration algorithms and parameter estimation algorithms to achieve a better estimate of the healthy patient scan and the tumor growth parameters that are consistent with the data. Our scheme is based on our recent work (Scheufele et al., Comput. Methods Appl. Mech. Engrg., to appear), but we apply a different and novel scheme where the tumor growth simulation in contrast to the previous work is executed in the patient brain domain and not in the atlas domain yielding more meaningful patient-specific results. As a basis, we use a PDE-constrained optimization framework. We derive a modified Picard-iteration-type solution strategy in which we alternate between registration and tumor parameter estimation in a new way. In addition, we consider an $\ell_1$ sparsity constraint on the initial condition for the tumor and integrate it with the new joint inversion scheme. We solve the subproblems with a reduced space, inexact Gauss--Newton--Krylov/quasi-Newton method. We present results using real brain data with synthetic tumor data that show that the new scheme reconstructs the tumor parameters in a more accurate and reliable way compared to our earlier scheme.},
  archive      = {J_SISC},
  author       = {Klaudius Scheufele and Shashank Subramanian and Andreas Mang and George Biros and Miriam Mehl},
  doi          = {10.1137/19M1275280},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {3},
  pages        = {B549-B580},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Image-driven biophysical tumor growth model calibration},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Strang splitting method for semilinear parabolic problems
with inhomogeneous boundary conditions: A correction based on the flow
of the nonlinearity. <em>SISC</em>, <em>42</em>(3), A1913–A1934. (<a
href="https://doi.org/10.1137/19M1257081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Strang splitting method, formally of order two, can suffer from order reduction when applied to semilinear parabolic problems with inhomogeneous boundary conditions. The recent work [L. Einkemmer and A. Ostermann, SIAM J. Sci. Comput., 37, 2015; SIAM J. Sci. Comput., 38, 2016] introduces a modification of the method to avoid the reduction of order based on the nonlinearity. In this paper we introduce a new correction constructed directly from the flow of the nonlinearity and which requires no evaluation of the source term or its derivatives. The goal is twofold. One, this new modification requires only one evaluation of the diffusion flow and one evaluation of the source term flow at each step of the algorithm and it reduces the computational effort to construct the correction. Second, numerical experiments suggest it is well suited in the case where the nonlinearity is stiff. We provide a convergence analysis of the method for a smooth nonlinearity and perform numerical experiments to illustrate the performances of the new approach.},
  archive      = {J_SISC},
  author       = {Guillaume Bertoli and Gilles Vilmart},
  doi          = {10.1137/19M1257081},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {3},
  pages        = {A1913-A1934},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Strang splitting method for semilinear parabolic problems with inhomogeneous boundary conditions: A correction based on the flow of the nonlinearity},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Parametric polynomial preserving recovery on manifolds.
<em>SISC</em>, <em>42</em>(3), A1885–A1912. (<a
href="https://doi.org/10.1137/18M1191336">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates gradient recovery schemes for data defined on discretized manifolds. The proposed method, parametric polynomial preserving recovery (PPPR), does not require the tangent spaces of the exact manifolds which have been assumed for some significant gradient recovery methods in the literature. Another advantage of PPPR is that superconvergence is guaranteed without the symmetric condition which is required in the existing techniques. As an application, we show its capability of constructing an asymptotically exact a posteriori error estimator. Several numerical examples on two-dimensional surfaces are presented to support the theoretical results, and comparisons with existing methods are documented, showing that PPPR outperforms the other methods, in particular in the case of high curvature surfaces as well as mildly structured meshes.},
  archive      = {J_SISC},
  author       = {Guozhi Dong and Hailong Guo},
  doi          = {10.1137/18M1191336},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {3},
  pages        = {A1885-A1912},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Parametric polynomial preserving recovery on manifolds},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A posteriori error estimates for the stationary
navier–stokes equations with dirac measures. <em>SISC</em>,
<em>42</em>(3), A1860–A1884. (<a
href="https://doi.org/10.1137/19M1292436">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In two dimensions, we propose and analyze an a posteriori error estimator for finite element approximations of the stationary Navier--Stokes equations with singular sources on Lipschitz, but not necessarily convex, polygonal domains. Under a smallness assumption on the continuous and discrete solutions, we prove that the devised error estimator is reliable and locally efficient. We illustrate the theory with numerical examples.},
  archive      = {J_SISC},
  author       = {Alejandro Allendes and Enrique Otárola and Abner J. Salgado},
  doi          = {10.1137/19M1292436},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {3},
  pages        = {A1860-A1884},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A posteriori error estimates for the stationary navier--stokes equations with dirac measures},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Implementing a smooth exact penalty function for general
constrained nonlinear optimization. <em>SISC</em>, <em>42</em>(3),
A1836–A1859. (<a href="https://doi.org/10.1137/19M1255069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We build upon R. Estrin et al., [SIAM J. Sci. Comput., 42 (2020), pp. A1809--A1835] to develop a general constrained nonlinear optimization algorithm based on a smooth penalty function proposed by R. Fletcher [Integer and Nonlinear Programming, J. Abadie, ed., North-Holland, Amsterdam, (1970), pp. 157--175; Math. Program., 5 (1973), pp. 129--150]. Although Fletcher&#39;s approach has historically been considered impractical, we show that the computational kernels required are no more expensive than those in other widely accepted methods for nonlinear optimization. The main kernel for evaluating the penalty function and its derivatives solves structured linear systems. When the matrices are available explicitly, we store a single factorization each iteration. Otherwise, we obtain a factorization-free optimization algorithm by solving each linear system iteratively. The penalty function shows promise in cases where the linear systems can be solved efficiently, e.g., PDE-constrained optimization problems when efficient preconditioners exist. We demonstrate the merits of the approach, and give numerical results on several PDE-constrained and standard test problems.},
  archive      = {J_SISC},
  author       = {Ron Estrin and Michael P. Friedlander and Dominique Orban and Michael A. Saunders},
  doi          = {10.1137/19M1255069},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {3},
  pages        = {A1836-A1859},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Implementing a smooth exact penalty function for general constrained nonlinear optimization},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Implementing a smooth exact penalty function for
equality-constrained nonlinear optimization. <em>SISC</em>,
<em>42</em>(3), A1809–A1835. (<a
href="https://doi.org/10.1137/19M1238265">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a general equality-constrained nonlinear optimization algorithm based on a smooth penalty function proposed by Fletcher in 1970. Although it was historically considered to be computationally prohibitive in practice, we demonstrate that the computational kernels required are no more expensive than other widely accepted methods for nonlinear optimization. The main kernel required to evaluate the penalty function and its derivatives is solving a structured linear system. We show how to solve this system efficiently by storing a single factorization at each iteration when the matrices are available explicitly. We further show how to adapt the penalty function to the class of factorization-free algorithms by solving the linear system iteratively. The penalty function therefore has promise when the linear system can be solved efficiently, e.g., for PDE-constrained optimization problems where efficient preconditioners exist. We discuss extensions including handling simple constraints explicitly, regularizing the penalty function, and inexact evaluation of the penalty function and its gradients. We demonstrate the merits of the approach and its various features on some nonlinear programs from a standard test set, and some PDE-constrained optimization problems.},
  archive      = {J_SISC},
  author       = {Ron Estrin and Michael P. Friedlander and Dominique Orban and Michael A. Saunders},
  doi          = {10.1137/19M1238265},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {3},
  pages        = {A1809-A1835},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Implementing a smooth exact penalty function for equality-constrained nonlinear optimization},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the numerical solution of fourth-order linear two-point
boundary value problems. <em>SISC</em>, <em>42</em>(3), A1789–A1808. (<a
href="https://doi.org/10.1137/18M1214810">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a fast and numerically stable algorithm for the solution of fourth-order linear boundary value problems on an interval. This type of equation arises in a variety of settings in physics and signal processing. Our method reformulates the equation as a collection of second-kind integral equations defined on local subdomains. Each such equation can be stably discretized and solved. The boundary values of these local solutions are matched by solving a banded linear system. The method of deferred corrections is then used to increase the accuracy of the scheme. Deferred corrections require applying the integral operator to a function on the entire domain, for which we provide an algorithm with linear cost. We illustrate the performance of our method on several numerical examples.},
  archive      = {J_SISC},
  author       = {William Leeb and Vladimir Rokhlin},
  doi          = {10.1137/18M1214810},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {3},
  pages        = {A1789-A1808},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {On the numerical solution of fourth-order linear two-point boundary value problems},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). MALA-within-gibbs samplers for high-dimensional
distributions with sparse conditional structure. <em>SISC</em>,
<em>42</em>(3), A1765–A1788. (<a
href="https://doi.org/10.1137/19M1284014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Markov chain Monte Carlo (MCMC) samplers are numerical methods for drawing samples from a given target probability distribution. We discuss one particular MCMC sampler, the MALA-within-Gibbs sampler, from the theoretical and practical perspectives. We first show that the acceptance ratio and step size of this sampler are independent of the overall problem dimension when (i) the target distribution has sparse conditional structure, and (ii) this structure is reflected in the partial updating strategy of MALA-within-Gibbs. If, in addition, the target density is blockwise log-concave, then the sampler&#39;s convergence rate is independent of dimension. From a practical perspective, we expect that MALA-within-Gibbs is useful for solving high-dimensional Bayesian inference problems where the posterior exhibits sparse conditional structure at least approximately. In this context, a partitioning of the state that correctly reflects the sparse conditional structure must be found, and we illustrate this process in two numerical examples. We also discuss trade-offs between the block size used for partial updating and computational requirements that may increase with the number of blocks.},
  archive      = {J_SISC},
  author       = {X. T. Tong and M. Morzfeld and Y. M. Marzouk},
  doi          = {10.1137/19M1284014},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {3},
  pages        = {A1765-A1788},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {MALA-within-gibbs samplers for high-dimensional distributions with sparse conditional structure},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Auxiliary space preconditioning of finite element equations
using a nonconforming interior penalty reformulation and static
condensation. <em>SISC</em>, <em>42</em>(3), A1741–A1764. (<a
href="https://doi.org/10.1137/19M1286815">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We modify the well-known interior penalty finite element discretization method so that it allows for element-by-element assembly. This is possible due to the introduction of additional unknowns associated with the interfaces between neighboring elements. The resulting bilinear form, and a Schur complement (reduced) version of it, are utilized in a number of auxiliary space preconditioners for the original conforming finite element discretization problem. These preconditioners are analyzed on the fine scale, and their performance is illustrated on model second order scalar elliptic problems discretized with high order elements.},
  archive      = {J_SISC},
  author       = {Delyan Z. Kalchev and Panayot S. Vassilevski},
  doi          = {10.1137/19M1286815},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {3},
  pages        = {A1741-A1764},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Auxiliary space preconditioning of finite element equations using a nonconforming interior penalty reformulation and static condensation},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Randomization and reweighted <span
class="math inline"><em>ℓ</em><sub>1</sub></span>-minimization for
a-optimal design of linear inverse problems. <em>SISC</em>,
<em>42</em>(3), A1714–A1740. (<a
href="https://doi.org/10.1137/19M1267362">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider optimal design of PDE-based Bayesian linear inverse problems with infinite-dimensional parameters. We focus on the A-optimal design criterion, defined as the average posterior variance and quantified by the trace of the posterior covariance operator. We propose using structure exploiting randomized methods to compute the A-optimal objective function and its gradient, and we provide a detailed analysis of the error for the proposed estimators. To ensure sparse and binary design vectors, we develop a novel reweighted $\ell_1$-minimization algorithm. We also introduce a modified A-optimal criterion and present randomized estimators for its efficient computation. We present numerical results illustrating the proposed methods on a model contaminant source identification problem, where the inverse problem seeks to recover the initial state of a contaminant plume using discrete measurements of the contaminant in space and time.},
  archive      = {J_SISC},
  author       = {Elizabeth Herman and Alen Alexanderian and Arvind K. Saibaba},
  doi          = {10.1137/19M1267362},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {3},
  pages        = {A1714-A1740},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Randomization and reweighted $\ell_1$-minimization for A-optimal design of linear inverse problems},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Low-rank matrix iteration using polynomial-filtered subspace
extraction. <em>SISC</em>, <em>42</em>(3), A1686–A1713. (<a
href="https://doi.org/10.1137/19M1259444">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study fixed-point schemes with certain low-rank structures arising from matrix optimization problems. Traditional first-order methods depend on the eigenvalue decomposition at each iteration, which may take most of the computational time. In order to reduce the cost, we propose an inexact algorithmic framework based on a polynomial subspace extraction. The idea is to use an additional polynomial-filtered iteration to extract an approximated eigenspace and to project the iteration matrix on this subspace, followed by an optimization update. The accuracy of the extracted subspace can be controlled by the degree of the polynomial filters. This kind of subspace extraction also enjoys the warm-start property: the subspace of the current iteration is refined from the previous one. Then this framework is instantiated into two algorithms: the polynomial-filtered proximal gradient method and the polynomial-filtered alternating direction method of multipliers. The convergence of the proposed framework is guaranteed if the polynomial degree grows with an order $\mathcal{O}(\log k)$ at the $k$th iteration. If the warm-start property is considered, the degree can be reduced to a constant, independent of the iteration $k$. Preliminary numerical experiments on several matrix optimization problems show that the polynomial-filtered algorithms usually provide multifold speedups.},
  archive      = {J_SISC},
  author       = {Yongfeng Li and Haoyang Liu and Zaiwen Wen and Ya-xiang Yuan},
  doi          = {10.1137/19M1259444},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {3},
  pages        = {A1686-A1713},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Low-rank matrix iteration using polynomial-filtered subspace extraction},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The characteristic mapping method for the linear advection
of arbitrary sets. <em>SISC</em>, <em>42</em>(3), A1663–A1685. (<a
href="https://doi.org/10.1137/18M1234424">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a new numerical method for transporting arbitrary sets in a velocity field. The method computes a deformation mapping of the domain and advects particular sets by function composition with the map. This also allows for the transport of multiple sets at low computational cost. Our strategy is to separate the computation of short time advection from the storage and representation of long time deformation maps, employing appropriate grid resolution for each of these two parts. We show through numerical experiments that the resulting algorithm is accurate and exhibits significant reductions in computational time over other methods. Results are presented in two and three dimensions, and accuracy and efficiency are studied.},
  archive      = {J_SISC},
  author       = {Olivier Mercier and Xi-Yuan Yin and Jean-Christophe Nave},
  doi          = {10.1137/18M1234424},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {3},
  pages        = {A1663-A1685},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {The characteristic mapping method for the linear advection of arbitrary sets},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Prediction accuracy of dynamic mode decomposition.
<em>SISC</em>, <em>42</em>(3), A1639–A1662. (<a
href="https://doi.org/10.1137/19M1259948">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic mode decomposition (DMD), which belongs to the family of singular-value decompositions (SVDs), is a popular tool of data-driven regression. While multiple numerical tests demonstrated the power and efficiency of DMD in representing data (i.e., in the interpolation mode), applications of DMD as a predictive tool (i.e., in the extrapolation mode) are scarce. This is due, in part, to the lack of rigorous error estimators for DMD-based predictions. We provide a theoretical error estimator for DMD extrapolation of numerical solutions to linear and nonlinear parabolic equations. This error analysis allows one to monitor and control the errors associated with DMD-based temporal extrapolation of numerical solutions to parabolic differential equations. We use several computational experiments to verify the robustness of our error estimators and to compare the predictive ability of DMD with that of proper orthogonal decomposition (POD), another member of the SVD family. Our analysis demonstrates the importance of a proper selection of observables, as predicted by the Koopman operator theory. In all the tests considered, DMD outperformed POD in terms of efficiency due to its iteration-free feature. In some of these experiments, POD proved to be more accurate than DMD. This suggests that DMD is preferable for obtaining a fast prediction with slightly lower accuracy, while POD should be used if the accuracy is paramount.},
  archive      = {J_SISC},
  author       = {Hannah Lu and Daniel M. Tartakovsky},
  doi          = {10.1137/19M1259948},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {3},
  pages        = {A1639-A1662},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Prediction accuracy of dynamic mode decomposition},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Coupled multirate infinitesimal GARK schemes for stiff
systems with multiple time scales. <em>SISC</em>, <em>42</em>(3),
A1609–A1638. (<a href="https://doi.org/10.1137/19M1266952">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional time discretization methods use a single timestep for the entire system of interest and can perform poorly when the dynamics of the system exhibits a wide range of time scales. Multirate infinitesimal step (MIS) methods [O. Knoth and R. Wolke, Appl. Numer. Math., 28 (1998), pp. 327--341] offer an elegant and flexible approach to efficiently integrate such systems. The slow components are discretized by a Runge--Kutta method, and the fast components are resolved by solving modified fast differential equations. Sandu [SIAM J. Numer. Anal., 57 (2019), pp. 2300--2327] developed the multirate infinitesimal general-structure additive Runge--Kutta (MRI-GARK) family of methods that includes traditional MIS schemes as a subset. The MRI-GARK framework allowed the construction of the first fourth order MIS schemes. This framework also enabled the introduction of implicit methods, which are decoupled in the sense that any implicitness lies entirely within the fast or slow integrations. It was shown by Sandu that the stability of decoupled implicit MRI-GARK methods has limitations when both the fast and slow components are stiff and interact strongly. This work extends the MRI-GARK framework by introducing coupled implicit methods to solve stiff multiscale systems. The coupled approach has the potential to considerably improve the overall stability of the scheme, at the price of requiring implicit stage calculations over the entire system. Two coupling strategies are considered. The first computes coupled Runge--Kutta stages before solving a single differential equation to refine the fast solution. The second alternates between computing coupled Runge--Kutta stages and solving fast differential equations. We derive order conditions and perform the stability analysis for both strategies. The new coupled methods offer improved stability compared to the decoupled MRI-GARK schemes. The theoretical properties of the new methods are validated with numerical experiments.},
  archive      = {J_SISC},
  author       = {Steven Roberts and Arash Sarshar and Adrian Sandu},
  doi          = {10.1137/19M1266952},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {3},
  pages        = {A1609-A1638},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Coupled multirate infinitesimal GARK schemes for stiff systems with multiple time scales},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Randomized discrete empirical interpolation method for
nonlinear model reduction. <em>SISC</em>, <em>42</em>(3), A1582–A1608.
(<a href="https://doi.org/10.1137/19M1243270">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The discrete empirical interpolation method (DEIM) is a popular technique for nonlinear model reduction, and it has two main ingredients: an interpolating basis that is computed from a collection of snapshots of the solution, and a set of indices which determine the nonlinear components to be simulated. The computation of these two ingredients dominates the overall cost of the DEIM algorithm. To specifically address these two issues, we present randomized versions of the DEIM algorithm. There are three main contributions of this paper. First, we use randomized range finding algorithms to efficiently find an approximate DEIM basis. Second, we develop randomized subset selection tools, based on leverage scores, to efficiently select the nonlinear components. Third, we develop several theoretical results that quantify the accuracy of the randomization on the DEIM approximation. We also present numerical experiments that demonstrate the benefits of the proposed algorithms.},
  archive      = {J_SISC},
  author       = {Arvind K. Saibaba},
  doi          = {10.1137/19M1243270},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {3},
  pages        = {A1582-A1608},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Randomized discrete empirical interpolation method for nonlinear model reduction},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Accelerated piston problem and high order moving boundary
tracking method for compressible fluid flows. <em>SISC</em>,
<em>42</em>(3), A1558–A1581. (<a
href="https://doi.org/10.1137/19M1266599">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reliable tracking of moving boundaries is important for the simulation of compressible fluid flows, and there are a lot of contributions in literature. We recognize from the classical piston problem, a typical moving boundary problem in gas dynamics, that acceleration is a key element in the description of the motion and should be incorporated into the design of a moving boundary tracking method. Technically, the resolution of the accelerated piston problem boils down to a one-sided generalized Riemann problem solver, which is taken as the building block for constructing schemes with high order accuracy in both space and time. In this paper we take this into account, together with the cell-merging approach, to propose a new family of high order accurate moving boundary tracking methods and verify its performance through one- and two-dimensional test problems, along with accuracy analysis.},
  archive      = {J_SISC},
  author       = {Zhifang Du and Jiequan Li},
  doi          = {10.1137/19M1266599},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {3},
  pages        = {A1558-A1581},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Accelerated piston problem and high order moving boundary tracking method for compressible fluid flows},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A class of fast and accurate summation algorithms.
<em>SISC</em>, <em>42</em>(3), A1541–A1557. (<a
href="https://doi.org/10.1137/19M1257780">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The need to sum floating-point numbers is ubiquitous in scientific computing. Standard recursive summation of $n$ summands, often implemented in a blocked form, has a backward error bound proportional to $nu$, where $u$ is the unit roundoff. With the growing interest in low precision floating-point arithmetic and ever increasing $n$ in applications, computed sums are more likely to have insufficient accuracy. We propose a class of summation algorithms called FABsum (for “fast and accurate block summation&#39;&#39;) that applies a fast summation algorithm (such as recursive summation) blockwise and then sums the partial sums using an accurate summation algorithm (such as compensated summation, or recursive summation in higher precision). We give a rounding error analysis to show that FABsum with a fixed block size $b$ has a backward error bound $(b+1)u + O(u^2)$, which is independent of $n$ to first order. Our computational experiments show that with a suitable choice of $b$ (independent of $n$) FABsum can deliver substantially more accurate results than blocked recursive summation, with only a modest drop in performance. FABsum is especially attractive for low precisions, where it can provide correct digits for much larger $n$ than recursive summation.},
  archive      = {J_SISC},
  author       = {Pierre Blanchard and Nicholas J. Higham and Theo Mary},
  doi          = {10.1137/19M1257780},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {3},
  pages        = {A1541-A1557},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A class of fast and accurate summation algorithms},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A parallel-in-time block-circulant preconditioner for
optimal control of wave equations. <em>SISC</em>, <em>42</em>(3),
A1510–A1540. (<a href="https://doi.org/10.1137/19M1289613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a new efficient preconditioner for iteratively solving the large-scale indefinite saddle-point sparse linear system, which arises from discretizing the optimality system in optimal control problems of wave equations with a one-shot second-order finite difference scheme in both space and time. The proposed preconditioner can be implemented in a parallel-in-time (PinT) manner via a carefully designed unitary diagonalization decomposition. Such an explicit unitary diagonalization is rarely seen in the literature. We also analyze the eigenvalue bounds of the preconditioned system, which are shown to be highly clustered around one. Moreover, a simple splitting algorithm that alternates between a linear complementarity problem (LCP) and a quasi-Newton iteration is discussed for handling the case with control constraints. Within the quasi-Newton iteration, our proposed PinT preconditioner can be directly used in preconditioning the Jacobian system of the same structure. Both 1D and 2D numerical examples are given to illustrate the promising convergence performance of our proposed PinT preconditioner in comparison with a recently proposed matching Schur complement (MSC) preconditioner.},
  archive      = {J_SISC},
  author       = {Shu-Lin Wu and Jun Liu},
  doi          = {10.1137/19M1289613},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {3},
  pages        = {A1510-A1540},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A parallel-in-time block-circulant preconditioner for optimal control of wave equations},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A random-batch monte carlo method for many-body systems with
singular kernels. <em>SISC</em>, <em>42</em>(3), A1486–A1509. (<a
href="https://doi.org/10.1137/19M1302077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a fast potential splitting Markov chain Monte Carlo method which costs $O(1)$ time each step for sampling from equilibrium distributions (Gibbs measures) corresponding to particle systems with singular interacting kernels. We decompose the interacting potential into two parts; one is of long range but is smooth, and the other one is of short range but may be singular. To displace a particle, we first evolve a selected particle using the stochastic differential equation (SDE) under the smooth part with the idea of random batches, as commonly used in stochastic gradient Langevin dynamics. Then, we use the short range part to do a Metropolis rejection. Different from the classical Langevin dynamics, we only run the SDE dynamics with a random batch for a short duration of time so that the cost in the first step is $O(p)$, where $p$ is the batch size and is often chosen to be $O(1)$. The cost of the rejection step is $O(1)$ since the interaction used is of short range. We justify the proposed random-batch Monte Carlo method, which combines the random batch and splitting strategies, both in theory and with numerical experiments. While giving comparable results for typical examples of the Dyson Brownian motion and Lennard-Jones fluids, our method can save more time when compared to the classical Metropolis-Hastings algorithm.},
  archive      = {J_SISC},
  author       = {Lei Li and Zhenli Xu and Yue Zhao},
  doi          = {10.1137/19M1302077},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {3},
  pages        = {A1486-A1509},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A random-batch monte carlo method for many-body systems with singular kernels},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Extending hierarchical probing for computing the trace of
matrix inverses. <em>SISC</em>, <em>42</em>(3), A1459–A1485. (<a
href="https://doi.org/10.1137/18M1176427">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present extensions to hierarchical probing, a method developed in [A. Stathopoulos, J. Laeuchli, and K. Orginos, SIAM J. Sci. Comput., 35 (2013), pp. S299--S322] to reduce the variance of the Monte Carlo estimation of the trace or the diagonal of the inverse of a large, sparse matrix. In that context, probing is a method to determine the largest-in-magnitude elements of the matrix inverse and then annihilate their contributions to the variance by solving linear systems with appropriate probing vectors. It typically involves coloring the graph of $A^n$, since this matches the sparsity structure of a polynomial approximation to $A^{-1}$. This is equivalent to distance-$n$ coloring of $A$, i.e., determining which nodes are connected to one other at distance $ \leq n$. For matrices that display a Green&#39;s function decay, $n$ is small, which reduces the number of linear systems to be solved. Our hierarchical probing method was developed for matrices with a lattice structure, where distance-$n$ coloring and the generation of probing vectors can be performed far more efficiently and in a way so that earlier vectors are subsets of vectors generated later in the process, meaning that it is simple to continue probing if additional accuracy is needed. However, this method worked only on lattices with dimension lengths that were powers of two. In this paper we extend the method to work on lattices of arbitrary dimension lengths, which is theoretically more challenging. Additionally, we expand the idea to a multilevel, hierarchical probing heuristic for matrices with any undirected graph structure that matches the performance of classical probing but with tractable memory requirements.},
  archive      = {J_SISC},
  author       = {Jesse Laeuchli and Andreas Stathopoulos},
  doi          = {10.1137/18M1176427},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {3},
  pages        = {A1459-A1485},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Extending hierarchical probing for computing the trace of matrix inverses},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hm-toolbox: MATLAB software for HODLR and HSS matrices.
<em>SISC</em>, <em>42</em>(2), C43–C68. (<a
href="https://doi.org/10.1137/19M1288048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Matrices with hierarchical low-rank structure, including HODLR and HSS matrices, constitute a versatile tool to develop fast algorithms for addressing large-scale problems. While existing software packages for such matrices often focus on linear systems, their scope of applications is in fact much wider and includes, for example, matrix functions and eigenvalue problems. In this work, we present a new MATLAB toolbox called hm-toolbox, which encompasses this versatility with a broad set of tools for HODLR and HSS matrices, unmatched by existing software. While mostly based on algorithms that can be found in the literature, our toolbox also contains a few new algorithms as well as novel auxiliary functions. Being entirely based on MATLAB, our implementation does not strive for optimal performance. Nevertheless, it maintains the favorable complexity of hierarchical low-rank matrices and offers, at the same time, a convenient way of prototyping and experimenting with algorithms. A number of applications illustrate the use of the hm-toolbox.},
  archive      = {J_SISC},
  author       = {Stefano Massei and Leonardo Robol and Daniel Kressner},
  doi          = {10.1137/19M1288048},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {C43-C68},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Hm-toolbox: MATLAB software for HODLR and HSS matrices},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new sparse <span
class="math inline"><em>L</em><em>D</em><em>L</em><sup><em>T</em></sup></span>
solver using a posteriori threshold pivoting. <em>SISC</em>,
<em>42</em>(2), C23–C42. (<a
href="https://doi.org/10.1137/18M1225963">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The factorization of sparse symmetric indefinite systems is particularly challenging since pivoting is required to maintain stability of the factorization. Pivoting techniques generally offer limited parallelism and are associated with significant data movement hindering the scalability of these methods. Variants of the threshold partial pivoting (TPP) algorithm, for example, have often been used because of its numerical robustness but standard implementations exhibit poor parallel performance. On the other hand, some methods trade stability for performance on parallel architectures such as the supernode Bunch--Kaufman used in the PARDISO solver. In this case, however, the factors obtained might not be used to accurately compute the solution of the system. For this reason we have designed a task-based $LDL^{T}$ factorization algorithm based on a new pivoting strategy called a posteriori threshold pivoting (APTP) that is much more suitable for modern multicore architectures and has the same numerical robustness as the TPP strategy. We implemented our algorithm in a new version of the SPRAL sparse symmetric indefinite direct solver, which initially supported GPU-only factorization. We have used OpenMP 4 task features to implement a multifrontal algorithm with dense factorizations using the novel APTP, and we show that it performs favorably compared to the state-of-the-art solvers HSL_MA86, HSL_MA97 and PARDISO both in terms of performance on a multicore machine and in terms of numerical robustness. Finally we show that this new solver is able to make use of GPU devices for accelerating the factorization on heterogeneous architectures.},
  archive      = {J_SISC},
  author       = {Iain Duff and Jonathan Hogg and Florent Lopez},
  doi          = {10.1137/18M1225963},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {C23-C42},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A new sparse $LDL^T$ solver using a posteriori threshold pivoting},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Uniformly accurate methods for three dimensional vlasov
equations under strong magnetic field with varying direction.
<em>SISC</em>, <em>42</em>(2), B520–B547. (<a
href="https://doi.org/10.1137/19M127402X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the three dimensional Vlasov equation with an inhomogeneous, varying direction, strong magnetic field. Whenever the magnetic field has constant intensity, the oscillations generated by the stiff term are periodic. The homogenized model is then derived, and several state-of-the-art multiscale methods, in combination with the particle-in-cell discretization, are proposed for solving the Vlasov--Poisson equation. Their accuracy as much as their computational cost remain essentially independent of the strength of the magnetic field. The proposed schemes thus allow large computational steps, while the full gyro-motion can be restored by a linear interpolation in time. In the linear case, extensions are introduced for a general magnetic field (varying intensity and direction). Eventually, numerical experiments are exposed to illustrate the efficiency of the methods and some long-term simulations are presented.},
  archive      = {J_SISC},
  author       = {Philippe Chartier and Nicolas Crouseilles and Mohammed Lemou and Florian Méhats and Xiaofei Zhao},
  doi          = {10.1137/19M127402X},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {B520-B547},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Uniformly accurate methods for three dimensional vlasov equations under strong magnetic field with varying direction},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Numerical treatment of the nonconservative product in a
multiscale fluid model for plasmas in thermal nonequilibrium:
Application to solar physics. <em>SISC</em>, <em>42</em>(2), B492–B519.
(<a href="https://doi.org/10.1137/18M1194225">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This contribution deals with the modeling of collisional multicomponent magnetized plasmas in thermal and chemical nonequilibrium aiming at simulating and predicting magnetic reconnections in the chromosphere of the sun. We focus on the numerical simulation of a simplified fluid model to investigate the influence on shock solutions of a nonconservative product present in the electron energy equation. Then, we derive jump conditions based on traveling wave solutions and propose an original numerical treatment in order to avoid nonphysical shocks for the solution that remains valid in the case of coarse-resolution simulations. A key element for the numerical scheme proposed is the presence of diffusion in the electron variables, consistent with the physically sound scaling used in the model developed by Graille, Magin, and Massot following a multiscale Chapman--Enskog expansion method [Math. Models Methods Appl. Sci., 19 (2009), pp. 527--599]. The numerical strategy is assessed in the framework of a solar physics test case. The computational method is able to capture the traveling wave solutions in both the highly- and coarsely resolved cases.},
  archive      = {J_SISC},
  author       = {Quentin Wargnier and Sylvain Faure and Benjamin Graille and Thierry Magin and Marc Massot},
  doi          = {10.1137/18M1194225},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {B492-B519},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Numerical treatment of the nonconservative product in a multiscale fluid model for plasmas in thermal nonequilibrium: Application to solar physics},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Shape-driven interpolation with discontinuous kernels: Error
analysis, edge extraction, and applications in magnetic particle
imaging. <em>SISC</em>, <em>42</em>(2), B472–B491. (<a
href="https://doi.org/10.1137/19M1248777">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate interpolation and approximation techniques for functions with discontinuities are key tools in many applications, such as medical imaging. In this paper, we study a radial basis function type of method for scattered data interpolation that incorporates discontinuities via a variable scaling function. For the construction of the discontinuous basis of kernel functions, information on the edges of the interpolated function is necessary. We characterize the native space spanned by these kernel functions and study error bounds in terms of the fill distance of the node set. To extract the location of the discontinuities, we use a segmentation method based on a classification algorithm from machine learning. The results of the conducted numerical experiments are in line with the theoretically derived convergence rates in case that the discontinuities are a priori known. Further, an application to interpolation in magnetic particle imaging shows that the presented method is very promising in order to obtain edge-preserving image reconstructions in which ringing artifacts are reduced.},
  archive      = {J_SISC},
  author       = {S. De Marchi and W. Erb and F. Marchetti and E. Perracchione and M. Rossini},
  doi          = {10.1137/19M1248777},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {B472-B491},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Shape-driven interpolation with discontinuous kernels: Error analysis, edge extraction, and applications in magnetic particle imaging},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Galerkin differences for high-order partial differential
equations. <em>SISC</em>, <em>42</em>(2), B447–B471. (<a
href="https://doi.org/10.1137/19M1259456">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Galerkin differences (GDs) were introduced in [J. W. Banks and T. Hagstrom, J. Comput. Phys., 313 (2016), pp. 310--327; J. W. Banks, T. Hagstrom, and J. Jacangelo, J. Comput. Phys., 372 (2018), pp. 864--892] and employed $C^0$ basis functions in a Galerkin projection to approximate solutions to the wave equation. In those works, the basis was derived by considering standard piecewise continuous polynomial interpolation. The resulting GD approximations were found to have excellent properties in terms of both their accuracy and computational efficiency. In the present work we further extend GD by considering higher derivative operators, such as those commonly found in beam or plate models of solid mechanics. These higher-order PDEs necessitate higher continuity basis functions. To derive this smoother basis, we introduce the difference spline, which is a locally constructed $C^1$ polynomial interpolant using only discrete data at $p+1$ consecutive grid points. We show that the difference spline interpolant is a $p$th-order accurate approximation, and basis functions associated with each grid point are derived. The basis is then used in a standard weak-form finite element approximation of the PDEs, and classical finite element theory shows that the method is $p$th-order accurate in the $L^2$-norm. Numerical convergence studies on the Euler--Bernoulli beam and the Kirchhoff--Love plate are performed and verify the theory.},
  archive      = {J_SISC},
  author       = {J. Jacangelo and J. W. Banks and T. Hagstrom},
  doi          = {10.1137/19M1259456},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {B447-B471},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Galerkin differences for high-order partial differential equations},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On nitsche’s method for elastic contact problems.
<em>SISC</em>, <em>42</em>(2), B425–B446. (<a
href="https://doi.org/10.1137/19M1246869">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show quasi-optimality and a posteriori error estimates for the frictionless contact problem between two elastic bodies with a zero-gap function. The analysis is based on interpreting Nitsche&#39;s method as a stabilized finite element method for which the error estimates can be obtained with minimal regularity assumptions and without the saturation assumption. We present three different Nitsche&#39;s mortaring techniques for the contact boundary, each corresponding to a different stabilizing term. Our numerical experiments show the robustness of Nitsche&#39;s method and corroborate the efficiency of the a posteriori error estimators.},
  archive      = {J_SISC},
  author       = {Tom Gustafsson and Rolf Stenberg and Juha Videman},
  doi          = {10.1137/19M1246869},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {B425-B446},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {On nitsche&#39;s method for elastic contact problems},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the lattice boltzmann deviatoric stress: Analysis,
boundary conditions, and optimal relaxation times. <em>SISC</em>,
<em>42</em>(2), B397–B424. (<a
href="https://doi.org/10.1137/19M1244846">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analytically solve the two-dimensional, nine-velocity, lattice Boltzmann model in planar channel flow and determine its deviatoric stress tensor. The shear component of its stress takes the expected Navier--Stokes form but the tangential component contains second order in Knudsen number contributions that one finds in solutions to the Burnett equations. Boundary conditions that neglect this Burnett contribution cause spurious grid-scale oscillations in the computed stress field within the computational domain. A moment-based boundary condition which considers the nonzero deviatoric stress is analyzed and shown to completely eliminate the spurious oscillations seen in solutions using other boundary conditions. The analysis offers an explanation of previously reported optimal relaxation times in terms of the recurrence relation for the tangential stress and gives them an interpretation in terms of compact finite difference schemes.},
  archive      = {J_SISC},
  author       = {T. Reis},
  doi          = {10.1137/19M1244846},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {B397-B424},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {On the lattice boltzmann deviatoric stress: Analysis, boundary conditions, and optimal relaxation times},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A scalable multigrid reduction framework for multiphase
poromechanics of heterogeneous media. <em>SISC</em>, <em>42</em>(2),
B379–B396. (<a href="https://doi.org/10.1137/19M1256117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simulation of multiphase poromechanics involves solving a multiphysics problem in which multiphase flow and transport are tightly coupled with the porous medium deformation. To capture this dynamic interplay, fully implicit methods, also known as monolithic approaches, are usually preferred. The main bottleneck of a monolithic approach is that it requires solution of large linear systems that result from the discretization and linearization of the governing balance equations. Because such systems are nonsymmetric, indefinite, and highly ill-conditioned, preconditioning is critical for fast convergence. Recently, most efforts in designing efficient preconditioners for multiphase poromechanics have been dominated by physics-based strategies. Current state-of-the-art “black-box” solvers such as algebraic multigrid (AMG) are ineffective because they cannot effectively capture the strong coupling between the mechanics and the flow subproblems, as well as the coupling inherent in the multiphase flow and transport process. In this work, we develop an algebraic framework based on multigrid reduction (MGR) that is suited for tightly coupled systems of PDEs. Using this framework, the decoupling between the equations is done algebraically through defining appropriate interpolation and restriction operators. One can then employ existing solvers for each of the decoupled blocks or design a new solver based on knowledge of the physics. We demonstrate the applicability of our framework when used as a “black-box” solver for multiphase poromechanics. We show that the framework is flexible to accommodate a wide range of scenarios, as well as efficient and scalable for large problems.},
  archive      = {J_SISC},
  author       = {Quan M. Bui and Daniel Osei-Kuffuor and Nicola Castelletto and Joshua A. White},
  doi          = {10.1137/19M1256117},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {B379-B396},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A scalable multigrid reduction framework for multiphase poromechanics of heterogeneous media},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). High order numerical simulations for the binary
fluid–surfactant system using the discontinuous galerkin and spectral
deferred correction methods. <em>SISC</em>, <em>42</em>(2), B353–B378.
(<a href="https://doi.org/10.1137/18M1235405">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a high order numerical scheme to simulate the binary fluid--surfactant system by combining the semi-implicit spectral deferred correction (SDC) method and the energy stable linear scheme, in the framework of discontinuous Galerkin (DG) methods. The linear scheme we develop in this paper is decoupled and unconditionally energy stable, which is based on the combination of the convex-concave splitting principle and the invariant energy quadratization approach. However, the scheme is only first order accurate with respect to time, and the SDC method can be employed to iteratively improve the temporal accuracy. Specially, the SDC scheme can be extremely accurate when coupled with an adaptive time stepping strategy. Our numerical scheme leads to a set of decoupled and linear algebraic equations; at each time step, we apply a multigrid solver to solve the equations efficiently. In particular, due to the local property of the DG methods, the resulting algebraic equations can be solved in an explicit way when coupled with the multigrid solver, which is an attractive advantage of the DG method. Various numerical experiments are performed to illustrate the high order accuracy, capability, and efficiency of the proposed methods when solving the binary fluid--surfactant system.},
  archive      = {J_SISC},
  author       = {Ruihan Guo and Yan Xu},
  doi          = {10.1137/18M1235405},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {B353-B378},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {High order numerical simulations for the binary fluid--surfactant system using the discontinuous galerkin and spectral deferred correction methods},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A discontinuous galerkin method by patch reconstruction for
elliptic interface problem on unfitted mesh. <em>SISC</em>,
<em>42</em>(2), A1428–A1457. (<a
href="https://doi.org/10.1137/19M1290528">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a discontinuous Galerkin (DG) method to approximate the elliptic interface problem on unfitted mesh using a new approximation space. The approximation space is constructed by patch reconstruction with one degree of freedom per element. The optimal error estimates in both the $L^2$ norm and the DG energy norm are obtained, without restrictions on how the interface intersects the elements in the mesh. The stability near the interface is ensured by the patch reconstruction and no special numerical flux is required. The convergence order by numerical results in both two and three dimensions agrees with the error estimates perfectly. More than enjoying the advantages of the DG method, the new method may achieve even better efficiency in number of degrees of freedom than the conforming finite element method as illustrated by our numerical examples.},
  archive      = {J_SISC},
  author       = {Ruo Li and Fanyi Yang},
  doi          = {10.1137/19M1290528},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {A1428-A1457},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A discontinuous galerkin method by patch reconstruction for elliptic interface problem on unfitted mesh},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multilevel techniques for compression and reduction of
scientific data—the unstructured case. <em>SISC</em>, <em>42</em>(2),
A1402–A1427. (<a href="https://doi.org/10.1137/19M1267878">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous work on multilevel techniques for compression and reduction of scientific data is extended to the case of data given on unstructured meshes in two and three dimensions. The centerpiece of the work is a decomposition algorithm which is shown to be optimal, in terms of both storage and operational complexity, applicable to unstructured grids in both two and three dimensions, and which implicitly gives a Riesz basis that can be exploited to reduce the data while maintaining rigorous bounds on the loss incurred. The flexibility of the approach is illustrated by applications to potential flow around an airfoil and the effect of compression on quantities of interest relevant to airfoil design; compression of computational simulation of a nonlinear reaction-diffusion system with special attention given to the problem of time series reduction; and, data from a simulation of magnetically confined plasma in a fusion reactor reduced so as to preserve the electric field computed from the data.},
  archive      = {J_SISC},
  author       = {Mark Ainsworth and Ozan Tugluk and Ben Whitney and Scott Klasky},
  doi          = {10.1137/19M1267878},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {A1402-A1427},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Multilevel techniques for compression and reduction of scientific data---the unstructured case},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A fast boundary integral method for high-order multiscale
mesh generation. <em>SISC</em>, <em>42</em>(2), A1380–A1401. (<a
href="https://doi.org/10.1137/19M1290450">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work we present an algorithm to construct an infinitely differentiable smooth surface from an input consisting of a (rectilinear) triangulation of a surface of arbitrary shape. The original surface can have nontrivial genus and multiscale features, and our algorithm has computational complexity which is linear in the number of input triangles. We use a smoothing kernel to define a function $\Phi$ whose level set defines the surface of interest. Charts are subsequently generated as maps from the original user-specified triangles to $\mathbb R^3$. The degree of smoothness is controlled locally by the kernel to be commensurate with the fineness of the input triangulation. The expression for $\Phi$ can be transformed into a boundary integral, whose evaluation can be accelerated using a fast multipole method. We demonstrate the effectiveness and cost of the algorithm with polyhedral and quadratic skeleton surfaces obtained from computer-aided design and meshing software.},
  archive      = {J_SISC},
  author       = {Felipe Vico and Leslie Greengard and Michael O&#39;Neil and Manas Rachh},
  doi          = {10.1137/19M1290450},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {A1380-A1401},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A fast boundary integral method for high-order multiscale mesh generation},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). High-order, dispersionless “fast-hybrid” wave equation
solver. Part i: O(1) sampling cost via incident-field windowing and
recentering. <em>SISC</em>, <em>42</em>(2), A1348–A1379. (<a
href="https://doi.org/10.1137/19M1251953">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a frequency/time hybrid integral-equation method for the time-dependent wave equation in two- and three-dimensional spatial domains. Relying on Fourier transformation in time, the method utilizes a fixed (time-independent) number of frequency-domain integral-equation solutions to evaluate, with superalgebraically small errors, time-domain solutions for arbitrarily long times. The approach relies on two main elements, namely: (1) a smooth time-windowing methodology that enables accurate band-limited representations for arbitrarily long time signals and (2) a novel Fourier transform approach which, in a time-parallel manner and without causing spurious periodicity effects, delivers numerically dispersionless spectrally accurate solutions. A similar hybrid technique can be obtained on the basis of Laplace transforms instead of Fourier transforms, but we do not consider the Laplace-based method in the present contribution. The algorithm can handle dispersive media, it can tackle complex physical structures, it enables parallelization in time in a straightforward manner, and it allows for time leaping---that is, solution sampling at any given time $T$ at $\mathcal{O}(1)$-bounded sampling cost, for arbitrarily large values of $T$, and without requirement of evaluation of the solution at intermediate times. The proposed frequency-time hybridization strategy, which generalizes to any linear partial differential equation in the time domain for which frequency-domain solutions can be obtained (including, e.g., the time-domain Maxwell equations) and which is applicable in a wide range of scientific and engineering contexts, provides significant advantages over other available alternatives, such as volumetric discretization, time-domain integral equations, and convolution quadrature approaches.},
  archive      = {J_SISC},
  author       = {Thomas G. Anderson and Oscar P. Bruno and Mark Lyon},
  doi          = {10.1137/19M1251953},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {A1348-A1379},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {High-order, dispersionless “Fast-hybrid” wave equation solver. part i: O(1) sampling cost via incident-field windowing and recentering},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Scalable optimization-based sampling on function space.
<em>SISC</em>, <em>42</em>(2), A1317–A1347. (<a
href="https://doi.org/10.1137/19M1245220">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimization-based samplers such as randomize-then-optimize (RTO) [J. M. Bardsley et al., SIAM J. Sci. Comput., 36 (2014), pp. A1895--A1910] provide an efficient and parallellizable approach to solving large-scale Bayesian inverse problems. These methods solve randomly perturbed optimization problems to draw samples from an approximate posterior distribution. “Correcting” these samples, either by Metropolization or importance sampling, enables characterization of the original posterior distribution. This paper focuses on the scalability of RTO to problems with high- or infinite-dimensional parameters. In particular, we introduce a new subspace strategy to reformulate RTO. For problems with intrinsic low-rank structures, this subspace acceleration makes the computational complexity of RTO scale linearly with the parameter dimension. Furthermore, this subspace perspective suggests a natural extension of RTO to a function space setting. We thus formalize a function space version of RTO and establish sufficient conditions for it to produce a valid Metropolis--Hastings proposal, yielding dimension-independent sampling performance. Numerical examples corroborate the dimension independence of RTO and demonstrate sampling performance that is also robust to small observational noise.},
  archive      = {J_SISC},
  author       = {Johnathan M. Bardsley and Tiangang Cui and Youssef M. Marzouk and Zheng Wang},
  doi          = {10.1137/19M1245220},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {A1317-A1347},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Scalable optimization-based sampling on function space},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Trefftz finite elements on curvilinear polygons.
<em>SISC</em>, <em>42</em>(2), A1289–A1316. (<a
href="https://doi.org/10.1137/19M1294046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a Trefftz-type finite element method on meshes consisting of curvilinear polygons. Local basis functions are computed using integral equation techniques that allow for the efficient and accurate evaluation of quantities needed in the formation of local stiffness matrices. To define our local finite element spaces in the presence of curved edges, we must also properly define what it means for a function defined on a curved edge to be “polynomial” of a given degree on that edge. We consider two natural choices, before settling on the one that yields the inclusion of complete polynomial spaces in our local finite element spaces, and discuss how to work with these edge polynomial spaces in practice. An interpolation operator is introduced for the resulting finite elements, and we prove that it provides optimal order convergence for interpolation error under reasonable assumptions. We provide a description of the integral equation approach used for the examples in this paper, which was recently developed precisely with these applications in mind. A few numerical examples illustrate this optimal order convergence of the finite element solution on some families of meshes in which every element has at least one curved edge. We also demonstrate that it is possible to exploit the approximation power of locally singular functions that may exist in our finite element spaces in order to achieve optimal order convergence without the typical adaptive refinement toward singular points.},
  archive      = {J_SISC},
  author       = {Akash Anand and Jeffrey S. Ovall and Samuel E. Reynolds and Steffen Weißer},
  doi          = {10.1137/19M1294046},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {A1289-A1316},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Trefftz finite elements on curvilinear polygons},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). MCMC algorithms for computational UQ of nonnegativity
constrained linear inverse problems. <em>SISC</em>, <em>42</em>(2),
A1269–A1288. (<a href="https://doi.org/10.1137/18M1234588">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many inverse problems, a nonnegativity constraint is natural. Moreover, in some cases, we expect the vector of unknown parameters to have zero components. When a Bayesian approach is taken, this motivates a desire for prior probability density (and hence posterior probability density) functions that have positive mass at the boundary of the set $x$ in\mathbbR^N,|,$x$\geq$0$. Unfortunately, it is difficult to define a prior with this property that yields computationally tractable inference for large-scale inverse problems. In this paper, we use nonnegativity constrained optimization to define such prior and posterior density functions when the measurement error is either Gaussian or Poisson distributed. The numerical optimization methods we use are highly efficient, and hence our approach is computationally tractable even in large-scale cases. We embed our nonnegativity constrained optimization approach within a hierarchical framework, obtaining Gibbs samplers for both Gaussian and Poisson distributed measurement cases. Finally, we test the resulting Markov chain Monte Carlo methods on examples from both image deblurring and positron emission tomography.},
  archive      = {J_SISC},
  author       = {Johnathan M. Bardsley and Per Christian Hansen},
  doi          = {10.1137/18M1234588},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {A1269-A1288},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {MCMC algorithms for computational UQ of nonnegativity constrained linear inverse problems},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new class of high-order methods for multirate differential
equations. <em>SISC</em>, <em>42</em>(2), A1245–A1268. (<a
href="https://doi.org/10.1137/19M125621X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work focuses on the development of a new class of high-order accurate methods for multirate time integration of systems of ordinary differential equations. The proposed methods are based on a specific subset of explicit one-step exponential integrators. More precisely, starting from an explicit exponential Runge--Kutta method of the appropriate form, we derive a multirate algorithm to approximate the action of the matrix exponential through the definition of modified “fast” initial-value problems. These fast problems may be solved using any viable solver, enabling multirate simulations through use of a subcycled method. Due to this structure, we name these multirate exponential Runge--Kutta (MERK) methods. In addition to showing how MERK methods may be derived, we provide rigorous convergence analysis, showing that for an overall method of order $p$, the fast problems corresponding to internal stages may be solved using a method of order $p-1$, while the final fast problem corresponding to the time-evolved solution must use a method of order $p$. Numerical simulations are then provided to demonstrate the convergence and efficiency of MERK methods with orders three through five on a series of multirate test problems.},
  archive      = {J_SISC},
  author       = {Vu Thai Luan and Rujeko Chinomona and Daniel R. Reynolds},
  doi          = {10.1137/19M125621X},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {A1245-A1268},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A new class of high-order methods for multirate differential equations},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Numerical approximation of optimal convex shapes.
<em>SISC</em>, <em>42</em>(2), A1226–A1244. (<a
href="https://doi.org/10.1137/19M1256853">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates the numerical approximation of shape optimization problems with PDE constraint on classes of convex domains. The convexity constraint provides a compactness property which implies well posedness of the problem. Moreover, we prove the convergence of discretizations in two-dimensional situations. A numerical algorithm is devised that iteratively solves the discrete formulation. Numerical experiments show that optimal convex shapes are generally nonsmooth and that three-dimensional problems require an appropriate relaxation of the convexity condition.},
  archive      = {J_SISC},
  author       = {Sören Bartels and Gerd Wachsmuth},
  doi          = {10.1137/19M1256853},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {A1226-A1244},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Numerical approximation of optimal convex shapes},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). First and second order shape optimization based on
restricted mesh deformations. <em>SISC</em>, <em>42</em>(2),
A1200–A1225. (<a href="https://doi.org/10.1137/19M1241465">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider shape optimization problems subject to elliptic partial differential equations. In the context of the finite element method, the geometry to be optimized is represented by the computational mesh, and the optimization proceeds by repeatedly updating the mesh node positions. It is well known that such a procedure eventually may lead to a deterioration of mesh quality, or even an invalidation of the mesh, when interior nodes penetrate neighboring cells. We examine this phenomenon, which can be traced back to the ineptness of the discretized objective when considered over the space of mesh node positions. As a remedy, we propose a restriction in the admissible mesh deformations, inspired by the Hadamard structure theorem. First and second order methods are considered in this setting. Numerical results show that mesh degeneracy can be overcome, avoiding the need for remeshing or other strategies. FEniCS code for the proposed methods is available on GitHub.},
  archive      = {J_SISC},
  author       = {Tommy Etling and Roland Herzog and Estefanía Loayza and Gerd Wachsmuth},
  doi          = {10.1137/19M1241465},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {A1200-A1225},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {First and second order shape optimization based on restricted mesh deformations},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fast factorization update for general elliptic equations
under multiple coefficient updates. <em>SISC</em>, <em>42</em>(2),
A1174–A1199. (<a href="https://doi.org/10.1137/18M1224623">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For discretized elliptic equations, we develop a new factorization update algorithm that is suitable for incorporating coefficient updates with large support and large magnitude in subdomains. When a large number of local updates are involved, in addition to the standard factors in various (interior) subdomains, we precompute some factors in the corresponding exterior subdomains. Exterior boundary maps are constructed hierarchically. The data dependencies among tree-based interior and exterior factors are exploited to enable extensive information reuse. For coefficient updates in a subdomain, only the interior problem in that subdomain needs to be refactorized and there is no need to propagate updates to other tree nodes. The combination of the new interior factors with a chain of existing factors quickly provides the new global factor and thus an effective solution algorithm. The introduction of exterior factors avoids updating higher-level subdomains with large system sizes and makes the idea suitable for handling multiple occurrences of updates. The method can also accommodate the case when the support of updates changes to different subdomains. Numerical tests demonstrate the efficiency and especially the advantage in complexity over a standard factorization update algorithm.},
  archive      = {J_SISC},
  author       = {Xiao Liu and Jianlin Xia and Maarten de Hoop},
  doi          = {10.1137/18M1224623},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {A1174-A1199},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Fast factorization update for general elliptic equations under multiple coefficient updates},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Algebraic multigrid schemes for high-order nodal
discontinuous galerkin methods. <em>SISC</em>, <em>42</em>(2),
A1147–A1173. (<a href="https://doi.org/10.1137/18M1204383">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present algebraic multigrid (AMG) methods for the efficient solution of the linear system of equations stemming from high-order discontinuous Galerkin (DG) discretizations of second-order elliptic problems. For DG methods, standard multigrid approaches cannot be employed because of redundancy of the degrees of freedom associated to the same grid point. We present new aggregation procedures and test them in extensive two-dimensional numerical experiments to demonstrate that the proposed AMG method is uniformly convergent with respect to all of the discretization parameters, namely the mesh-size and the polynomial approximation degree.},
  archive      = {J_SISC},
  author       = {Paola F. Antonietti and Laura Melas},
  doi          = {10.1137/18M1204383},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {A1147-A1173},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Algebraic multigrid schemes for high-order nodal discontinuous galerkin methods},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). SNS: A solution-based nonlinear subspace method for
time-dependent model order reduction. <em>SISC</em>, <em>42</em>(2),
A1116–A1146. (<a href="https://doi.org/10.1137/19M1242963">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several reduced order models have been successfully developed for nonlinear dynamical systems. To achieve a considerable speed-up, a hyper-reduction step is needed to reduce the computational complexity due to nonlinear terms. Many hyper-reduction techniques require the construction of nonlinear term basis, which introduces a computationally expensive offline phase. A novel way of constructing nonlinear term basis within the hyper-reduction process is introduced. In contrast to the traditional hyper-reduction techniques where the collection of nonlinear term snapshots is required, the SNS method avoids collecting the nonlinear term snapshots. Instead, it uses the solution snapshots that are used for building a solution basis, which enables avoiding an extra data compression of nonlinear term snapshots. As a result, the SNS method provides a more efficient offline strategy than the traditional model order reduction techniques, such as the DEIM, GNAT, and ST-GNAT methods. The SNS method is theoretically justified by the conforming subspace condition and the subspace inclusion relation. It is useful for model order reduction of large-scale nonlinear dynamical problems to reduce the offline cost. It is especially useful for ST-GNAT that has shown promising results, such as a good accuracy with a considerable online speed-up for hyperbolic problems in a recent paper by Choi and Carlberg [SIAM J. Sci. Comput., 41 (2019), pp. A26--A58], because ST-GNAT involves an expensive offline cost related to collecting nonlinear term snapshots. Error analysis for the SNS method is presented. Numerical results support that the accuracy of the solution from the SNS method is comparable to the traditional methods and a considerable speed-up (i.e., a factor of two to a hundred) is achieved in the offline phase.},
  archive      = {J_SISC},
  author       = {Youngsoo Choi and Deshawn Coombs and Robert Anderson},
  doi          = {10.1137/19M1242963},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {A1116-A1146},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {SNS: A solution-based nonlinear subspace method for time-dependent model order reduction},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Interpolative decomposition butterfly factorization.
<em>SISC</em>, <em>42</em>(2), A1097–A1115. (<a
href="https://doi.org/10.1137/19M1294873">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a “kernel-independent” interpolative decomposition butterfly factorization (IDBF) as a data-sparse approximation for matrices that satisfy a complementary low-rank property. The IDBF can be constructed in $O(N\log N)$ operations for an $N\times N$ matrix via hierarchical interpolative decompositions (IDs) if matrix entries can be sampled individually and each sample takes $O(1)$ operations. The resulting factorization is a product of $O(\log N)$ sparse matrices, each with $O(N)$ nonzero entries. Hence, it can be applied to a vector rapidly in $O(N\log N)$ operations. IDBF is a general framework for nearly optimal fast matrix-vector multiplication (matvec), which is useful in a wide range of applications, e.g., special function transformation, Fourier integral operators, and high-frequency wave computation. Numerical results are provided to demonstrate the effectiveness of the butterfly factorization and its construction algorithms.},
  archive      = {J_SISC},
  author       = {Qiyuan Pang and Kenneth L. Ho and Haizhao Yang},
  doi          = {10.1137/19M1294873},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {A1097-A1115},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Interpolative decomposition butterfly factorization},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An efficient implementation of mass conserving
characteristic-based schemes in two and three dimensions. <em>SISC</em>,
<em>42</em>(2), A1071–A1096. (<a
href="https://doi.org/10.1137/19M1281812">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we develop the ball-approximated characteristics (B-char) method, which is an algorithm for efficiently implementing characteristic-based schemes in two and three dimensions. Core to the implementation of numerical schemes is the evaluation of integrals, which in the context of characteristic-based schemes with piecewise constant approximations boils down to computing the intersections between two regions. In the literature, these regions are approximated by polytopes (polygons in two dimensions and polyhedra in three dimensions) and, due to this, the implementation in three dimensions is nontrivial. The main novelty in this paper is the approximation of the regions by balls, whose intersections are much cheaper to compute than those of polytopes. Of course, balls cannot fully tessellate a region, and hence some mass may be lost. We perform some adjustments, and also solve an optimization problem, in order to yield a scheme that is both locally and globally mass conserving. This algorithm can achieve results that are similar to those obtained from an implementation which uses polytopal intersections, with a much cheaper computational cost.},
  archive      = {J_SISC},
  author       = {Hanz Martin Cheng and Jérôme Droniou},
  doi          = {10.1137/19M1281812},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {A1071-A1096},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {An efficient implementation of mass conserving characteristic-based schemes in two and three dimensions},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Solving partial differential equations on closed surfaces
with planar cartesian grids. <em>SISC</em>, <em>42</em>(2), A1052–A1070.
(<a href="https://doi.org/10.1137/19M1272135">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a general purpose method for solving partial differential equations on a closed surface, based on a technique for discretizing the surface introduced by Wenjun Ying and Wei-Cheng Wang [J. Comput. Phys., 252 (2013), pp. 606--624] which uses projections on coordinate planes. Assuming it is given as a level set, the surface is represented by a set of points at which it intersects the intervals between grid points in a three-dimensional grid. They are designated as primary or secondary. Discrete functions on the surface have independent values at primary points, with values at secondary points determined by an equilibration process. Each primary point and its neighbors have projections to regular grid points in a coordinate plane where the equilibration is done and finite differences are computed. The solution of a p.d.e. can be reduced to standard methods on Cartesian grids in the coordinate planes, with the equilibration allowing seamless transition from one system to another. We observe second order accuracy in examples with a variety of equations, including surface diffusion determined by the Laplace--Beltrami operator and the shallow water equations on a sphere.},
  archive      = {J_SISC},
  author       = {J. Thomas Beale},
  doi          = {10.1137/19M1272135},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {A1052-A1070},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Solving partial differential equations on closed surfaces with planar cartesian grids},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An efficient third-order WENO scheme with unconditionally
optimal accuracy. <em>SISC</em>, <em>42</em>(2), A1028–A1051. (<a
href="https://doi.org/10.1137/19M1260396">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel scheme, based on third-order weighted essentially nonoscillatory (WENO) reconstructions, is presented. It attains unconditionally optimal accuracy when the data is smooth enough, even in presence of critical points, and second-order accuracy if a discontinuity crosses the data. The key to attribute these properties to this scheme is the inclusion of an additional node in the data stencil, which is only used in the computation of the weights measuring the smoothness. The accuracy properties of this scheme are proven in detail, and several numerical experiments are presented, which show that this scheme is more efficient in terms of the error reduction versus CPU time than its traditional third-order counterparts as well as several higher-order WENO schemes that are found in the literature.},
  archive      = {J_SISC},
  author       = {Antonio Baeza and Raimund Bürger and Pep Mulet and David Zorío},
  doi          = {10.1137/19M1260396},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {A1028-A1051},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {An efficient third-order WENO scheme with unconditionally optimal accuracy},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A registration method for model order reduction: Data
compression and geometry reduction. <em>SISC</em>, <em>42</em>(2),
A997–A1027. (<a href="https://doi.org/10.1137/19M1271270">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a general---i.e., independent of the underlying equation---registration method for parameterized model order reduction. Given the spatial domain $\Omega \subset \mathbb{R}^d$ and the manifold $\mathcal{M}_{u}= { u_{\mu} : \mu \in \mathcal{P} }$ associated with the parameter domain $\mathcal{P} \subset \mathbb{R}^P$ and the parametric field $\mu \mapsto u_{\mu} \in L^2(\Omega)$, the algorithm takes as input a set of snapshots ${ u^k }_{k=1}^{n_{\rm train}} \subset \mathcal{M}_{u}$ and returns a parameter-dependent bijective mapping ${\Phi}: \Omega \times \mathcal{P} \to \mathbb{R}^d$: the mapping is designed to make the mapped manifold ${ u_{\mu} \circ {\Phi}_{\mu}: \, \mu \in \mathcal{P} }$ more suited for linear compression methods. We apply the registration procedure, in combination with a linear compression method, to devise low-dimensional representations of solution manifolds with slowly decaying Kolmogorov $N$-widths; we also consider the application to problems in parameterized geometries. We present a theoretical result to show the mathematical rigor of the registration procedure. We further present numerical results for several two-dimensional problems, to empirically demonstrate the effectivity of our proposal.},
  archive      = {J_SISC},
  author       = {Tommaso Taddei},
  doi          = {10.1137/19M1271270},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {A997-A1027},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A registration method for model order reduction: Data compression and geometry reduction},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A numerical comparison of different solvers for large-scale,
continuous-time algebraic riccati equations and LQR problems.
<em>SISC</em>, <em>42</em>(2), A957–A996. (<a
href="https://doi.org/10.1137/18M1220960">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we discuss numerical methods for solving large-scale continuous-time algebraic Riccati equations. These methods have been the focus of intensive research in recent years, and significant progress has been made in both the theoretical understanding and efficient implementation of various competing algorithms. There are several goals of this manuscript. The first is to gather in one place an overview of different approaches for solving large-scale Riccati equations, and to point to the recent advances in each of them. The second goal is to analyze and compare the main computational ingredients of these algorithms and to detect their strong points and their potential bottlenecks. Finally, we want to compare the effective implementations of all methods on a set of relevant benchmark examples, giving an indication of their relative performance.},
  archive      = {J_SISC},
  author       = {Peter Benner and Zvonimir Bujanović and Patrick Kürschner and Jens Saak},
  doi          = {10.1137/18M1220960},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {A957-A996},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A numerical comparison of different solvers for large-scale, continuous-time algebraic riccati equations and LQR problems},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multifidelity dimension reduction via active subspaces.
<em>SISC</em>, <em>42</em>(2), A929–A956. (<a
href="https://doi.org/10.1137/18M1214123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a multifidelity dimension reduction method to identify a low-dimensional structure present in many engineering models. The structure of interest arises when functions vary primarily on a low-dimensional subspace of the high-dimensional input space, while varying little along the complementary directions. Our approach builds on the gradient-based methodology of active subspaces, and exploits models of different fidelities to reduce the cost of performing dimension reduction through the computation of the active subspace matrix. We provide a nonasymptotic analysis of the number of gradient evaluations sufficient to achieve a prescribed error in the active subspace matrix, both in expectation and with high probability. We show that the sample complexity depends on a notion of intrinsic dimension of the problem, which can be much smaller than the dimension of the input space. We illustrate the benefits of such a multifidelity dimension reduction approach using numerical experiments with input spaces of up to two thousand dimensions.},
  archive      = {J_SISC},
  author       = {Remi R. Lam and Olivier Zahm and Youssef M. Marzouk and Karen E. Willcox},
  doi          = {10.1137/18M1214123},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {A929-A956},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Multifidelity dimension reduction via active subspaces},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Scalable convergence using two-level deflation
preconditioning for the helmholtz equation. <em>SISC</em>,
<em>42</em>(2), A901–A928. (<a
href="https://doi.org/10.1137/18M1192093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research efforts aimed at iteratively solving the Helmholtz equation have focused on incorporating deflation techniques for accelerating the convergence of Krylov subpsace methods. The requisite for these efforts lies in the fact that the widely used and well-acknowledged complex shifted Laplacian preconditioner (CSLP) shifts the eigenvalues of the preconditioned system towards the origin as the wave number increases. The two-level-deflation preconditioner combined with CSLP showed encouraging results in moderating the rate at which the eigenvalues approach the origin. However, for large wave numbers the initial problem resurfaces and the near-zero eigenvalues reappear. Our findings reveal that the reappearance of these near-zero eigenvalues occurs if the near-singular eigenmodes of the fine-grid operator and the coarse-grid operator are not properly aligned. This misalignment is caused by accumulating approximation errors during the inter-grid transfer operations. We propose the use of higher-order approximation schemes to construct the deflation vectors. The results from rigorous Fourier analysis and numerical experiments confirm that our newly proposed scheme outperforms any other deflation-based preconditioner for the Helmholtz problem. In particular, the spectrum of the adjusted preconditioned operator stays fixed near one. These results can be generalized to general shifted indefinite systems with random right-hand sides. For the first time, the convergence properties for very large wave numbers ($k = 10^6$ in one dimension and $k = 10^3$ in two dimensions) have been studied, and the convergence is close to wave number independence. Wave number independence for three dimensions has been obtained for wave numbers up to $k = 75$. The new scheme additionally shows very promising results for the more challenging Marmousi problem. Irrespective of the strongly varying wave number, we obtain a constant number of iterations and a reduction in computational time as the results remain robust without the use of the CSLP preconditioner.},
  archive      = {J_SISC},
  author       = {Vandana Dwarka and Cornelis Vuik},
  doi          = {10.1137/18M1192093},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {A901-A928},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Scalable convergence using two-level deflation preconditioning for the helmholtz equation},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A simple solver for the fractional laplacian in multiple
dimensions. <em>SISC</em>, <em>42</em>(2), A878–A900. (<a
href="https://doi.org/10.1137/18M1170406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a simple discretization scheme for the hypersingular integral representa- tion of the fractional Laplace operator and solver for the corresponding fractional Laplacian problem. Through singularity subtraction, we obtain a regularized integrand that is amenable to the trape- zoidal rule with equispaced nodes, assuming a high degree of regularity in the underlying function (i.e., $u \in C^6({R}^d)$). The resulting quadrature scheme gives a discrete operator on a regular grid that is translation-invariant and thus can be applied quickly with the fast Fourier transform. For discretizations of problems related to space-fractional diffusion on bounded domains, we observe that the underlying linear system can be efficiently solved via preconditioned Krylov methods with a preconditioner based on the finite-difference (nonfractional) Laplacian. We show numerical results illustrating the error of our simple scheme as well the efficiency of our preconditioning approach, both for the elliptic (steady-state) fractional diffusion problem and the time-dependent problem.},
  archive      = {J_SISC},
  author       = {Victor Minden and Lexing Ying},
  doi          = {10.1137/18M1170406},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {A878-A900},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A simple solver for the fractional laplacian in multiple dimensions},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A spectrally accurate approximation to subdiffusion
equations using the log orthogonal functions. <em>SISC</em>,
<em>42</em>(2), A849–A877. (<a
href="https://doi.org/10.1137/19M1281927">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we develop and analyze a spectral-Galerkin method for solving subdiffusion equations, which contain Caputo fractional derivatives with order $\nu\in(0,1)$. The basis functions of our spectral method are constructed by applying a log mapping to Laguerre functions and have already been proved to be suitable to approximate functions with fractional power singularities in [S. Chen and J. Shen, Log Orthogonal Functions: Approximation Properties and Applications, preprint, arXiv:2003.01209[math.NA], 2020]. We provide rigorous regularity and error analysis which show that the scheme is spectrally accurate, i.e., the convergence rate depends only on regularity of problem data. The proof relies on the approximation properties of some reconstruction of the basis functions as well as the sharp regularity estimate in some weighted Sobolev spaces. Numerical experiments fully support the theoretical results and show the efficiency of the proposed spectral-Galerkin method. We also develop a fully discrete scheme with the proposed spectral method in time and the Galerkin finite element method in space, and apply the proposed techniques to subdiffusion equations with time-dependent diffusion coefficients as well as to the nonlinear time-fractional Allen--Cahn equation.},
  archive      = {J_SISC},
  author       = {Sheng Chen and Jie Shen and Zhimin Zhang and Zhi Zhou},
  doi          = {10.1137/19M1281927},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {A849-A877},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A spectrally accurate approximation to subdiffusion equations using the log orthogonal functions},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A TT-based hierarchical framework for decomposing high-order
tensors. <em>SISC</em>, <em>42</em>(2), A822–A848. (<a
href="https://doi.org/10.1137/18M1229973">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of big data, high-order tensor decompositions have to face a new challenge in terms of storage and computational costs. The tensor train (TT) decomposition provides a very useful graph-based model reduction, whose storage cost grows linearly with the tensor order $D$. The computation of the TT-core tensors and TT-ranks can be done in a stable sequential (i.e., noniterative) way thanks to the popular TT-SVD algorithm. In this paper, we exploit the ideas developed for the hierarchical/tree Tucker decomposition in the context of the TT decomposition. Specifically, a new efficient estimation scheme, called TT-HSVD (Tensor-Train Hierarchical SVD), is proposed as a solution to compute the TT decomposition of a high-order tensor. The new algorithm simultaneously delivers the TT-core tensors and their TT-ranks in a hierarchical way. It is a stable (i.e., noniterative) and computationally more efficient algorithm than TT-SVD, which is very important when dealing with large-scale data. The TT-HSVD algorithm uses a new reshaping strategy and a tailored partial SVD, which allows us to deal with smaller matrices compared to those of the TT-SVD. In addition, TT-HSVD is well suited for a parallel processing architecture. An algebraic analysis of the two algorithms is carried out, showing that TT-SVD and TT-HSVD compute the same TT-ranks and TT-core tensors up to specific bases. Simulation results for different tensor orders and dimensions corroborate the effectiveness of the proposed algorithm.},
  archive      = {J_SISC},
  author       = {Yassine Zniyed and Rémy Boyer and André L. F. de Almeida and Gérard Favier},
  doi          = {10.1137/18M1229973},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {A822-A848},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A TT-based hierarchical framework for decomposing high-order tensors},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Asymptotically exact a posteriori error estimates of
eigenvalues by the crouzeix–raviart element and enriched
crouzeix–raviart element. <em>SISC</em>, <em>42</em>(2), A797–A821. (<a
href="https://doi.org/10.1137/19M1261997">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two asymptotically exact a posteriori error estimates are proposed for eigenvalues by the nonconforming Crouzeix--Raviart and enriched Crouzeix--Raviart elements. The main challenge in the design of such error estimators comes from the nonconformity of the finite element spaces used. Such nonconformity causes two difficulties: the first is the construction of high accuracy gradient recovery algorithms, and the second is a computable high accuracy approximation of a consistency error term. The first difficulty was solved for both nonconforming elements in a previous paper. Two methods are proposed to solve the second difficulty in the present paper. In particular, this solution allows the use of high accuracy gradient recovery techniques. Further, a postprocessing algorithm is designed by utilizing asymptotically exact a posteriori error estimators to construct the weights of a combination of two approximate eigenvalues. This algorithm requires solving only one eigenvalue problem and admits high accuracy eigenvalue approximations both theoretically and numerically.},
  archive      = {J_SISC},
  author       = {Jun Hu and Limin Ma},
  doi          = {10.1137/19M1261997},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {A797-A821},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Asymptotically exact a posteriori error estimates of eigenvalues by the crouzeix--raviart element and enriched crouzeix--raviart element},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multilevel convergence analysis of
multigrid-reduction-in-time. <em>SISC</em>, <em>42</em>(2), A771–A796.
(<a href="https://doi.org/10.1137/19M1238812">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a multilevel convergence framework for multigrid-reduction-in-time (MGRIT) as a generalization of previous two-grid estimates. The framework provides a priori upper bounds on the convergence of MGRIT V- and F-cycles, with different relaxation schemes, by deriving the respective residual and error propagation operators. The residual and error operators are functions of the time-stepping operator, analyzed directly and bounded in the norm, both numerically and analytically. We present various upper bounds of different computational cost and varying sharpness. These upper bounds are complemented by proposing analytic formulae for the approximate convergence factor of V-cycle algorithms that take the number of fine grid time points, the temporal coarsening factors, and the eigenvalues of the time-stepping operator as parameters. The paper concludes with supporting numerical investigations of parabolic (anisotropic diffusion) and hyperbolic (wave equation) model problems. We assess the sharpness of the bounds and the quality of the approximate convergence factors. Observations from these numerical investigations demonstrate the value of the proposed multilevel convergence framework for estimating MGRIT convergence a priori and for the design of a convergent algorithm. We further highlight that observations in the literature are captured by the theory, including that two-level Parareal and multilevel MGRIT with F-relaxation do not yield scalable algorithms and the benefit of a stronger relaxation scheme. An important observation is that with increasing numbers of levels MGRIT convergence deteriorates for the hyperbolic model problem, while constant convergence factors can be achieved for the diffusion equation. The theory also indicates that L-stable Runge--Kutta schemes are more amendable to multilevel parallel-in-time integration with MGRIT than A-stable Runge--Kutta schemes.},
  archive      = {J_SISC},
  author       = {Andreas Hessenthaler and Ben S. Southworth and David Nordsletten and Oliver Röhrle and Robert D. Falgout and Jacob B. Schroder},
  doi          = {10.1137/19M1238812},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {A771-A796},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Multilevel convergence analysis of multigrid-reduction-in-time},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimized schwarz methods for spherical interfaces with
application to fluid-structure interaction. <em>SISC</em>,
<em>42</em>(2), A751–A770. (<a
href="https://doi.org/10.1137/19M1272184">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work we consider the optimized Schwarz method designed for computational domains that feature spherical or almost spherical interfaces. In the first part, we consider the diffusion-reaction problem. We provide a convergence analysis of the generalized Schwarz method and, following [G. Gigante and C. Vergara, Numer. Math., 131 (2015), pp. 369--404], we discuss an optimization procedure for constant interface parameters leading to a Robin--Robin scheme. Finally, we present some numerical results both in spherical and in ellipsoidal domains. In the second part of the work, we address the fluid-structure interaction problem. Again, we provide a convergence analysis and discuss optimized choices of constant interface parameters. Finally, we present three-dimensional numerical results inspired by hemodynamic applications, to validate the proposed choices in the presence of large added mass effect. In particular, we consider numerical experiments both in an ideal spherical domain and in a realistic abdominal aortic aneurysm.},
  archive      = {J_SISC},
  author       = {Giacomo Gigante and Giulia Sambataro and Christian Vergara},
  doi          = {10.1137/19M1272184},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {A751-A770},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Optimized schwarz methods for spherical interfaces with application to fluid-structure interaction},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A variable-separation method for nonlinear partial
differential equations with random inputs. <em>SISC</em>,
<em>42</em>(2), A723–A750. (<a
href="https://doi.org/10.1137/19M1262486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider a variable-separation (VS) method to solve the nonlinear partial differential equations (PDEs) with random inputs. The aim of the VS method is to get a sep- arated representation of the Galerkin solution for nonlinear PDEs with random inputs. An essential ingredient of the proposed method is the construction of the optimal stochastic basis functions. The nonlinearity can affect the computation efficiency and may bring challenges for the construction of the optimal stochastic basis functions. In order to overcome the difficulty, we develop the VS method such that the optimal stochastic basis functions are generated in an incremental constructive man- ner. At each enrichment step, a stochastic basis function is determined by the linearized equation deduced from the nonlinear problems at hand. The computation of the VS method decomposes into an offline phase and an online phase. The linearization of the construction for stochastic basis functions can significantly improve the computation efficiency in both offline and online stages. We first describe the VS method for nonlinear stochastic problems in a general framework. Then two nonlinear mod- els with random inputs are considered to formulate the details and methodologies of the proposed method, namely, the nonlinear elliptic equations and the steady Navier--Stokes equations.},
  archive      = {J_SISC},
  author       = {Qiuqi Li and Pingwen Zhang},
  doi          = {10.1137/19M1262486},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {A723-A750},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A variable-separation method for nonlinear partial differential equations with random inputs},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Symmetric and nonsymmetric discontinuous galerkin methods
for a pseudostress formulation of the stokes spectral problem.
<em>SISC</em>, <em>42</em>(2), A698–A722. (<a
href="https://doi.org/10.1137/19M1259535">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we introduce and analyze symmetric and nonsymmetric discontinuous Galerkin (DG) methods for the Stokes eigenvalue problem. The formulation is obtained by introducing the so-called pseudostress tensor, and thanks to the structure of the system, the velocity and pressure variables are eliminated. We propose different DG discretizations to solve the resulting spectral problem and the convergence analysis is based on the abstract spectral theory for noncompact operators. We show that the proposed method is spurious modes free and asymptotic estimates for the eigenvalues and eigenfunctions are proved if the so-called stabilization parameter is sufficiently large and the meshsize is small enough. We report some numerical experiments to assess the performance of the methods.},
  archive      = {J_SISC},
  author       = {Felipe Lepe and David Mora},
  doi          = {10.1137/19M1259535},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {A698-A722},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Symmetric and nonsymmetric discontinuous galerkin methods for a pseudostress formulation of the stokes spectral problem},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Splitting methods for rotations: Application to vlasov
equations. <em>SISC</em>, <em>42</em>(2), A666–A697. (<a
href="https://doi.org/10.1137/19M1273918">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, a splitting strategy is introduced to approximate two-dimensional rotation motions. Unlike standard approaches based on directional splitting which usually lead to a wrong angular velocity and then to large error, the splitting studied here turns out to be exact in time. Combined with spectral methods, the so-obtained numerical method is able to capture the solution to the associated partial differential equation with a very high accuracy. A complete numerical analysis of this method is given in this work. Then, the method is used to design highly accurate time integrators for Vlasov type equations: the Vlasov--Maxwell and the Vlasov-HMF systems. Finally, several numerical illustrations and comparisons with methods from the literature are discussed.},
  archive      = {J_SISC},
  author       = {Joackim Bernier and Fernando Casas and Nicolas Crouseilles},
  doi          = {10.1137/19M1273918},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {A666-A697},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Splitting methods for rotations: Application to vlasov equations},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Learning in modal space: Solving time-dependent stochastic
PDEs using physics-informed neural networks. <em>SISC</em>,
<em>42</em>(2), A639–A665. (<a
href="https://doi.org/10.1137/19M1260141">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the open problems in scientific computing is the long-time integration of nonlinear stochastic partial differential equations (SPDEs), especially with arbitrary initial data. We address this problem by taking advantage of recent advances in scientific machine learning and the spectral dynamically orthogonal (DO) and borthogonal (BO) methods for representing stochastic processes. The recently introduced DO/BO methods reduce the SPDE to solving a system of deterministic PDEs and a system of stochastic ordinary differential equations. Specifically, we propose two new physics-informed neural networks (PINNs) for solving time-dependent SPDEs, namely the neural network (NN)-DO/BO methods. The proposed methods incorporate the DO/BO constraints into the loss function (along with the modal decomposition of the SPDE) with an implicit form instead of generating explicit expressions for the temporal derivatives of the DO/BO modes. Hence, the NN-DO/BO methods can overcome some of the drawbacks of the original DO/BO methods. For example, we do not need the assumption that the covariance matrix of the random coefficients is invertible as in the original DO method, and we can remove the assumption of no eigenvalue crossing as in the original BO method. Moreover, the NN-DO/BO methods can be used to solve time-dependent stochastic inverse problems with the same formulation and same computational complexity as for forward problems. We demonstrate the capability of the proposed methods via several numerical examples, namely: (1) A linear stochastic advection equation with deterministic initial condition: we obtain good results with the proposed methods, while the original DO/BO methods cannot be applied directly in this case. (2) Long-time integration of the stochastic Burgers&#39; equation: we show the good performance of NN-DO/BO methods, especially the effectiveness of the NN-BO approach for such problems with many eigenvalue crossings during the whole time evolution, while the original BO method fails. (3) Nonlinear reaction diffusion equation: we consider both the forward problem and the inverse problems, including very noisy initial point values, to investigate the flexibility of the NN-DO/BO methods in handling inverse and mixed type problems. Taken together, these simulation results demonstrate that the NN-DO/BO methods can be employed to effectively quantify uncertainty propagation in a wide range of physical problems, but future work should address the efficiency issue of PINNs for forward problems.},
  archive      = {J_SISC},
  author       = {Dongkun Zhang and Ling Guo and George Em Karniadakis},
  doi          = {10.1137/19M1260141},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {A639-A665},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Learning in modal space: Solving time-dependent stochastic PDEs using physics-informed neural networks},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Relaxation runge–kutta methods: Fully discrete explicit
entropy-stable schemes for the compressible euler and navier–stokes
equations. <em>SISC</em>, <em>42</em>(2), A612–A638. (<a
href="https://doi.org/10.1137/19M1263480">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The framework of inner product norm preserving relaxation Runge--Kutta methods [D. I. Ketcheson, SIAM J. Numer. Anal., 57 (2019), pp. 2850--2870] is extended to general convex quantities. Conservation, dissipation, or other solution properties with respect to any convex functional are enforced by the addition of a relaxation parameter that multiplies the Runge--Kutta update at each step. Moreover, other desirable stability (such as strong stability preservation) and efficiency (such as low storage requirements) properties are preserved. The technique can be applied to both explicit and implicit Runge--Kutta methods and requires only a small modification to existing implementations. The computational cost at each step is the solution of one additional scalar algebraic equation for which a good initial guess is available. The effectiveness of this approach is proved analytically and demonstrated in several numerical examples, including applications to high order entropy-conservative and entropy-stable semidiscretizations on unstructured grids for the compressible Euler and Navier--Stokes equations.},
  archive      = {J_SISC},
  author       = {Hendrik Ranocha and Mohammed Sayyari and Lisandro Dalcin and Matteo Parsani and David I. Ketcheson},
  doi          = {10.1137/19M1263480},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {A612-A638},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Relaxation runge--kutta methods: Fully discrete explicit entropy-stable schemes for the compressible euler and navier--stokes equations},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Rational spectral methods for PDEs involving fractional
laplacian in unbounded domains. <em>SISC</em>, <em>42</em>(2),
A585–A611. (<a href="https://doi.org/10.1137/19M1244299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many PDEs involving fractional Laplacian are naturally set in unbounded domains with underlying solutions decaying slowly and subject to certain power law. Their numerical solutions are underexplored. This paper aims at developing accurate spectral methods using rational basis (or modified mapped Gegenbauer functions) for such models in unbounded domains. The main building block of the spectral algorithms is the explicit representations for the Fourier transform and fractional Laplacian of the rational basis, derived from some useful integral identities related to modified Bessel functions. With these at our disposal, we can construct rational spectral-Galerkin and direct collocation schemes by precomputing the associated fractional differentiation matrices. We obtain optimal error estimates of rational spectral approximation in the fractional Sobolev spaces and analyze the optimal convergence of the proposed Galerkin scheme. We also provide ample numerical results to show that the rational method outperforms the Hermite function approach.},
  archive      = {J_SISC},
  author       = {Tao Tang and Li-Lian Wang and Huifang Yuan and Tao Zhou},
  doi          = {10.1137/19M1244299},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {2},
  pages        = {A585-A611},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Rational spectral methods for PDEs involving fractional laplacian in unbounded domains},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fast solvers for charge distribution models on shared memory
platforms. <em>SISC</em>, <em>42</em>(1), C1–C22. (<a
href="https://doi.org/10.1137/18M1224684">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Including atom polarizability in molecular dynamics (MD) simulations is important for high-fidelity simulations. Linear solvers for charge models that are used to dynamically determine atom polarizations constitute significant bottlenecks in terms of time-to-solution and the overall scalability of polarizable and reactive force fields. We present properly customized preconditioning techniques to accelerate the iterative solvers used for several charge models and develop their efficient shared memory parallel implementations in the open source PuReMD (Purdue Reactive Molecular Dynamics) software package. With these goals in mind, special attention has been paid to minimizing the mean combined preconditioner construction and solver time. Detailed analysis of how different preconditioning techniques affect solver convergence rate and the overall performance is presented. Incomplete LU/Cholesky and sparse approximate inverse (SAI) based schemes that produce good quality factors with a relatively low number of nonzeros have been observed to yield significant speedups over a baseline Jacobi preconditioner. These results are significant as they can enable efficient simulations of small to moderate-sized systems on multicore computers, but, more importantly, they serve as a basis for distributed memory solvers.},
  archive      = {J_SISC},
  author       = {Kurt A. O&#39;Hearn and Abdullah Alperen and Hasan Metin Aktulga},
  doi          = {10.1137/18M1224684},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {1},
  pages        = {C1-C22},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Fast solvers for charge distribution models on shared memory platforms},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A parametric finite element method for solid-state dewetting
problems in three dimensions. <em>SISC</em>, <em>42</em>(1), B327–B352.
(<a href="https://doi.org/10.1137/19M1281666">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a parametric finite element method (PFEM) for efficiently solving the morphological evolution of solid-state dewetting of thin films on a flat rigid substrate in three dimensions (3D). The interface evolution of the dewetting problem in 3D is described by a sharp-interface model, which includes surface diffusion coupled with contact line migration. A variational formulation of the sharp-interface model is presented, and a PFEM is proposed for spatial discretization. For temporal discretization, at each time step, we first update the position of the contact line according to the relaxed contact angle condition; then, by using the position of the new contact line as the boundary condition, we solve a linear system resulting from the discretization of PFEM to obtain the new surface at the next step. The well-posedness of the solution of the PFEM is also established. Extensive numerical results are reported to demonstrate the accuracy and efficiency of the proposed PFEM and to show the complexities of the dewetting morphology evolution observed in solid-state dewetting experiments.},
  archive      = {J_SISC},
  author       = {Quan Zhao and Wei Jiang and Weizhu Bao},
  doi          = {10.1137/19M1281666},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {1},
  pages        = {B327-B352},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A parametric finite element method for solid-state dewetting problems in three dimensions},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Vlasov–poisson system tackled by particle simulation
utilizing boundary element methods. <em>SISC</em>, <em>42</em>(1),
B299–B326. (<a href="https://doi.org/10.1137/18M1225823">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a grid-free simulation algorithm for the fully three-dimensional Vlasov--Poisson system for collisionless electron plasmas. We employ a standard particle method for the numerical approximation of the distribution function. Whereas the advection of the particles is grid-free by its very nature, the computation of the acceleration involves the solution of the nonlocal Poisson equation. To circumvent a volume mesh, we utilize the fast boundary element method, which reduces the three-dimensional Poisson equation to a system of linear equations on its two-dimensional boundary. This gives rise to fully populated matrices which are approximated by the $\mathcal H^2$-technique, reducing the computational time from quadratic to linear complexity. The approximation scheme based on interpolation has been shown to be robust and flexible, allowing a straightforward generalization to vector-valued functions. In particular, the Coulomb forces acting on the particles are computed in linear complexity. In first numerical tests, we validate our approach with the help of classical nonlinear plasma phenomena. Furthermore, we show that our method is able to simulate electron plasmas in complex three-dimensional domains with mixed boundary conditions in linear complexity.},
  archive      = {J_SISC},
  author       = {Torsten Keßler and Sergej Rjasanow and Steffen Weißer},
  doi          = {10.1137/18M1225823},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {1},
  pages        = {B299-B326},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Vlasov--poisson system tackled by particle simulation utilizing boundary element methods},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Structure-preserving numerical integrators for
hodgkin–huxley-type systems. <em>SISC</em>, <em>42</em>(1), B273–B298.
(<a href="https://doi.org/10.1137/18M123390X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by the Hodgkin--Huxley model of neuronal dynamics, we study explicit numerical integrators for “conditionally linear” systems of ordinary differential equations. We show that splitting and composition methods, when applied to the Van der Pol oscillator and to the Hodgkin--Huxley model, do a better job of preserving limit cycles of these systems for large time steps, compared with the “Euler-type” methods (including Euler&#39;s method, exponential Euler, and semi-implicit Euler) commonly used in computational neuroscience, with no increase in computational cost. These limit cycles are important to preserve, due to their role in neuronal spiking. Splitting methods even compare favorably to the explicit exponential midpoint method, which is twice as expensive per step. The second-order Strang splitting method is seen to perform especially well across a range of nonstiff and stiff dynamics.},
  archive      = {J_SISC},
  author       = {Zhengdao Chen and Baranidharan Raman and Ari Stern},
  doi          = {10.1137/18M123390X},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {1},
  pages        = {B273-B298},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Structure-preserving numerical integrators for hodgkin--huxley-type systems},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal closures in a simple model for turbulent flows.
<em>SISC</em>, <em>42</em>(1), B250–B272. (<a
href="https://doi.org/10.1137/19M1251941">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work we introduce a computational framework for determining optimal closures of the eddy-viscosity type for large-eddy simulations (LESs) of a broad class of PDE models, such as the Navier--Stokes equation. This problem is cast in terms of PDE-constrained optimization where an error functional representing the misfit between the target and predicted observations is minimized with respect to the functional form of the eddy viscosity in the closure relation. Since this leads to a PDE optimization problem with a nonstandard structure, the solution is obtained computationally with a flexible and efficient gradient approach relying on a combination of modified adjoint-based analysis and Sobolev gradients. By formulating this problem in the continuous setting we are able to determine the optimal closure relations in a very general form subject only to some minimal assumptions. The proposed framework is thoroughly tested on a model problem involving the LES of the one-dimensional Kuramoto--Sivashinsky equation, where optimal forms of the eddy viscosity are obtained as generalizations of the standard Smagorinsky model. It is demonstrated that while the solution trajectories corresponding to the direct numerical simulation and LES still diverge exponentially, with such optimal eddy viscosities the rate of divergence is significantly reduced as compared to the Smagorinsky model. By systematically finding optimal forms of the eddy viscosity within a certain general class of closure models, this framework can thus provide insights about the fundamental performance limitations of these models.},
  archive      = {J_SISC},
  author       = {Pritpal Matharu and Bartosz Protas},
  doi          = {10.1137/19M1251941},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {1},
  pages        = {B250-B272},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Optimal closures in a simple model for turbulent flows},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Rotation-based mixed formulations for an
elasticity-poroelasticity interface problem. <em>SISC</em>,
<em>42</em>(1), B225–B249. (<a
href="https://doi.org/10.1137/19M1268343">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we introduce a new formulation for the stationary poroelasticity equations written using the rotation vector and the total fluid-solid pressure as additional unknowns, and we also write an extension to the elasticity-poroelasticity problem. The transmission conditions are imposed naturally in the weak formulation, and the analysis of the effective governing equations is conducted by an application of Fredholm&#39;s alternative. We also propose a monolithically coupled mixed finite element method for the numerical solution of the problem. Its convergence properties are rigorously derived and subsequently confirmed by a set of computational tests that include applications to subsurface flow in reservoirs as well as to dentistry-oriented problems.},
  archive      = {J_SISC},
  author       = {Verónica Anaya and Zoa de Wijn and Bryan Gómez-Vargas and David Mora and Ricardo Ruiz-Baier},
  doi          = {10.1137/19M1268343},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {1},
  pages        = {B225-B249},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Rotation-based mixed formulations for an elasticity-poroelasticity interface problem},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Wave enhancement through optimization of boundary
conditions. <em>SISC</em>, <em>42</em>(1), B207–B224. (<a
href="https://doi.org/10.1137/19M1274651">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a new and efficient approach for optimizing the transmission signal between two points in a cavity at a given frequency, by changing boundary conditions. The proposed approach makes use of recent results on the monotonicity of the eigenvalues of the mixed boundary value problem and on the sensitivity of Green&#39;s function to small changes in the boundary conditions. The switching of the boundary condition from Dirichlet to Neumann can be performed through the use of the recently modeled concept of metasurfaces which are comprised of coupled pairs of Helmholtz resonators. A variety of numerical experiments are presented to show the applicability and the accuracy of the proposed new methodology.},
  archive      = {J_SISC},
  author       = {Habib Ammari and Oscar Bruno and Kthim Imeri and Nilima Nigam},
  doi          = {10.1137/19M1274651},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {1},
  pages        = {B207-B224},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Wave enhancement through optimization of boundary conditions},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Splitting with near-circulant linear systems: Applications
to total variation CT and PET. <em>SISC</em>, <em>42</em>(1), B185–B206.
(<a href="https://doi.org/10.1137/18M1224003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many imaging problems, such as total variation reconstruction of X-ray computed tomography (CT) and positron-emission tomography (PET), are solved via a convex optimization problem with near-circulant, but not actually circulant, linear systems. The popular methods to solve these problems, alternating direction method of multipliers (ADMM) and primal-dual hybrid gradient (PDHG), do not directly utilize this structure. Consequently, ADMM requires a costly matrix inversion as a subroutine, and PDHG takes too many iterations to converge. In this paper, we present near-circulant splitting (NCS), a novel splitting method that leverages the near-circulant structure. We show that NCS can converge with an iteration count close to that of ADMM, while paying a computational cost per iteration close to that of PDHG. Through experiments on a CUDA GPU, we empirically validate the theory and demonstrate that NCS can effectively utilize the parallel computing capabilities of CUDA.},
  archive      = {J_SISC},
  author       = {Ernest K. Ryu and Seyoon Ko and Joong-Ho Won},
  doi          = {10.1137/18M1224003},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {1},
  pages        = {B185-B206},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Splitting with near-circulant linear systems: Applications to total variation CT and PET},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fokker–planck approach of ostwald ripening: Simulation of a
modified lifshitz–slyozov–wagner system with a diffusive correction.
<em>SISC</em>, <em>42</em>(1), B157–B184. (<a
href="https://doi.org/10.1137/18M1234011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a well-balanced scheme for the modified Lifshitz--Slyozov equation, which incorporates a size-diffusion term. The method uses the Fokker--Planck structure of the equation. In turn, large time simulations can be performed with a reduced computational cost, since the time-step constraints are relaxed. The simulations bring out the critical mass threshold and the relaxation to equilibrium, which can be expected from the formal analogies with the Becker--Döring system.},
  archive      = {J_SISC},
  author       = {Thierry Goudon and Laurent Monasse},
  doi          = {10.1137/18M1234011},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {1},
  pages        = {B157-B184},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Fokker--planck approach of ostwald ripening: Simulation of a modified lifshitz--slyozov--wagner system with a diffusive correction},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Arbitrarily high-order unconditionally energy stable schemes
for thermodynamically consistent gradient flow models. <em>SISC</em>,
<em>42</em>(1), B135–B156. (<a
href="https://doi.org/10.1137/18M1213579">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a systematic approach to developing arbitrarily high-order, unconditionally energy stable numerical schemes for thermodynamically consistent gradient flow models that satisfy energy dissipation laws. Utilizing the energy quadratization method, we formulate the gradient flow model into an equivalent form with a corresponding quadratic free energy functional. Based on the equivalent form with a quadratic energy, we propose two classes of energy stable numerical approximations. In the first approach, we use a prediction-correction strategy to improve the accuracy of linear numerical schemes. In the second approach, we adopt the Gaussian collocation method to discretize the equivalent form with a quadratic energy, arriving at an arbitrarily high-order scheme for gradient flow models. Schemes derived using both approaches are proved rigorously to be unconditionally energy stable. The proposed schemes are then implemented in four gradient flow models numerically to demonstrate their accuracy and effectiveness. Detailed numerical comparisons among these schemes are carried out as well. These numerical strategies are rather general so that they can be readily generalized to solve any thermodynamically consistent PDE models.},
  archive      = {J_SISC},
  author       = {Yuezheng Gong and Jia Zhao and Qi Wang},
  doi          = {10.1137/18M1213579},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {1},
  pages        = {B135-B156},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Arbitrarily high-order unconditionally energy stable schemes for thermodynamically consistent gradient flow models},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Numerical simulation of microflows using hermite spectral
methods. <em>SISC</em>, <em>42</em>(1), B105–B134. (<a
href="https://doi.org/10.1137/18M120066X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a Hermite spectral method for the spatially inhomogeneous Boltzmann equation. For the inverse-power-law model, we generalize a class of approximate quadratic collision operators defined in the normalized and dimensionless setting to operators for arbitrary distribution functions. An efficient algorithm with a fast transform is introduced to discretize the new collision operators. The method is tested for one- and two-dimensional benchmark microflow problems.},
  archive      = {J_SISC},
  author       = {Zhicheng Hu and Zhenning Cai and Yanli Wang},
  doi          = {10.1137/18M120066X},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {1},
  pages        = {B105-B134},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Numerical simulation of microflows using hermite spectral methods},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Isogeometric mortar coupling for electromagnetic problems.
<em>SISC</em>, <em>42</em>(1), B80–B104. (<a
href="https://doi.org/10.1137/18M1235211">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper discusses and analyzes two domain decomposition approaches for electromagnetic problems that allow the combination of domains discretized by either Nédélec-type polynomial finite elements or spline-based isogeometric analysis. The first approach is a new isogeometric mortar method and the second one is based on a modal basis for the Lagrange multiplier space, called state-space concatenation in the engineering literature. Spectral correctness and in particular inf-sup stability of both approaches are investigated numerically, and analytical results are obtained for the isogeometric mortar method. The new mortar method is shown to be unconditionally stable. Its construction of the discrete Lagrange multiplier space takes advantage of the high continuity of splines and does not have an analogue for Nédélec finite elements. On the other hand, the approach with modal basis is easier to implement but relies on application knowledge to ensure stability and correctness.},
  archive      = {J_SISC},
  author       = {Annalisa Buffa and Jacopo Corno and Carlo de Falco and Sebastian Schöps and Rafael Vázquez Hernández},
  doi          = {10.1137/18M1235211},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {1},
  pages        = {B80-B104},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Isogeometric mortar coupling for electromagnetic problems},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A scalable approximate inverse block preconditioner for an
incompressible magnetohydrodynamics model problem. <em>SISC</em>,
<em>42</em>(1), B57–B79. (<a
href="https://doi.org/10.1137/19M1255409">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a new approximate inverse preconditioner for a mixed finite element discretization of an incompressible magnetohydrodynamics model problem. The derivation exploits the nullity of the discrete curl-curl operator in the Maxwell subproblem. We show that the inverse of the coefficient matrix contains zero blocks and use discretization considerations to obtain a practical preconditioner based on further sparsification. We demonstrate the viability of our approach with a set of numerical experiments.},
  archive      = {J_SISC},
  author       = {Michael Wathen and Chen Greif},
  doi          = {10.1137/19M1255409},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {1},
  pages        = {B57-B79},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A scalable approximate inverse block preconditioner for an incompressible magnetohydrodynamics model problem},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel energy factorization approach for the
diffuse-interface model with peng–robinson equation of state.
<em>SISC</em>, <em>42</em>(1), B30–B56. (<a
href="https://doi.org/10.1137/19M1251230">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Peng--Robinson equation of state (PR-EoS) has become one of the most extensively applied equations of state in chemical engineering and the petroleum industry due to its excellent accuracy in predicting the thermodynamic properties of a wide variety of materials, especially hydrocarbons. Although great effort has been made to construct efficient numerical methods for the diffuse interface models with PR-EoS, there is still not a linear numerical scheme that can be proved to preserve the original energy dissipation law. In order to pursue such a numerical scheme, we propose a novel energy factorization (EF) approach, which first factorizes an energy function into a product of several factors and then treats the factors using their properties to obtain the semi-implicit linear schemes. We apply the EF approach to deal with the Helmholtz free energy density determined by PR-EoS, and then propose a linear semi-implicit numerical scheme that inherits the original energy dissipation law. Moreover, the proposed scheme is proved to satisfy the maximum principle in both time semidiscrete form and cell-centered finite difference fully discrete form under certain conditions. Numerical results are presented to demonstrate the stability and efficiency of the proposed scheme.},
  archive      = {J_SISC},
  author       = {Jisheng Kou and Shuyu Sun and Xiuhua Wang},
  doi          = {10.1137/19M1251230},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {1},
  pages        = {B30-B56},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A novel energy factorization approach for the diffuse-interface model with peng--robinson equation of state},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The full configuration interaction quantum monte carlo
method through the lens of inexact power iteration. <em>SISC</em>,
<em>42</em>(1), B1–B29. (<a
href="https://doi.org/10.1137/18M1166626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a general analysis framework for inexact power iteration, which can be used to efficiently solve high-dimensional eigenvalue problems arising from quantum many-body problems. Under this framework, we establish the convergence theorems for several recently proposed randomized algorithms, including full configuration interaction quantum Monte Carlo and fast randomized iteration. The analysis is consistent with numerical experiments for physical systems such as the Hubbard model and small chemical molecules. We also compare the algorithms both in convergence analysis and numerical results.},
  archive      = {J_SISC},
  author       = {Jianfeng Lu and Zhe Wang},
  doi          = {10.1137/18M1166626},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {1},
  pages        = {B1-B29},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {The full configuration interaction quantum monte carlo method through the lens of inexact power iteration},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Data-informed method of distributions for hyperbolic
conservation laws. <em>SISC</em>, <em>42</em>(1), A559–A583. (<a
href="https://doi.org/10.1137/19M1260773">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonlinear hyperbolic balance laws with uncertain (random) initial data are ubiquitous in a plethora of transport phenomena that often exhibit shocks. We develop the method of distributions for such problems by adding a model error term to a deterministic equation for the cumulative distribution function (CDF) of the system states. We use two alternative strategies, Newtonian relaxation and neural networks, to infer this term from observations of the system dynamics. The former strategy is amenable to theoretical analysis of its convergence with respect to data sparsity, while the latter offers more flexibility. The CDF equation is exact for linear conservation laws and nonlinear conservation laws with a smooth solution, such that the CDF equation can be used to formulate predictions at times when observations cease to be available. Whenever shocks develop as a result of the nonlinearity, observations are used to detect the discrepancy that emerges as model error. Spatial data density is crucial for good interpolation accuracy, whereas long temporal sequences of observations improve future projections.},
  archive      = {J_SISC},
  author       = {Francesca Boso and Daniel M. Tartakovsky},
  doi          = {10.1137/19M1260773},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {1},
  pages        = {A559-A583},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Data-informed method of distributions for hyperbolic conservation laws},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Gradient-based dimension reduction of multivariate
vector-valued functions. <em>SISC</em>, <em>42</em>(1), A534–A558. (<a
href="https://doi.org/10.1137/18M1221837">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate functions encountered in high-dimensional uncertainty quantification problems often vary most strongly along a few dominant directions in the input parameter space. We propose a gradient-based method for detecting these directions and using them to construct ridge approximations of such functions, in the case where the functions are vector-valued (e.g., taking values in $\mathbb{R}^n$). The methodology consists of minimizing an upper bound on the approximation error, obtained by subspace Poincaré inequalities. We provide a thorough mathematical analysis in the case where the parameter space is equipped with a Gaussian probability measure. The resulting method generalizes the notion of active subspaces associated with scalar-valued functions. A numerical illustration shows that using gradients of the function yields effective dimension reduction. We also show how the choice of norm on the codomain of the function has an impact on the function&#39;s low-dimensional approximation.},
  archive      = {J_SISC},
  author       = {Olivier Zahm and Paul G. Constantine and Clémentine Prieur and Youssef M. Marzouk},
  doi          = {10.1137/18M1221837},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {1},
  pages        = {A534-A558},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Gradient-based dimension reduction of multivariate vector-valued functions},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Asymptotic approximations for the close evaluation of
double-layer potentials. <em>SISC</em>, <em>42</em>(1), A504–A533. (<a
href="https://doi.org/10.1137/18M1218698">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When using boundary integral equation methods to solve a boundary value problem, the evaluation of the solution near the boundary is challenging to compute because the layer potentials that represent the solution are nearly singular integrals. To address this close evaluation problem, we develop a new numerical method by applying an asymptotic analysis of these nearly singular integrals and obtaining an asymptotic approximation. We derive the asymptotic approximation for the case of the double-layer potential in two and three dimensions, representing the solution of the interior Dirichlet problem for Laplace&#39;s equation. By doing so, we obtain an asymptotic approximation given by the Dirichlet data at the boundary point nearest to the interior evaluation point plus a nonlocal correction. We present the numerical methods using this asymptotic approximation, and we demonstrate the efficiency and accuracy of these methods and the asymptotic approximation through several examples. These examples show that the numerical method based on the asymptotic approximation accurately approximates the close evaluation of the double-layer potential while requiring only modest computational resources.},
  archive      = {J_SISC},
  author       = {Camille Carvalho and Shilpa Khatri and Arnold D. Kim},
  doi          = {10.1137/18M1218698},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {1},
  pages        = {A504-A533},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Asymptotic approximations for the close evaluation of double-layer potentials},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Shifted cholesky QR for computing the QR factorization of
ill-conditioned matrices. <em>SISC</em>, <em>42</em>(1), A477–A503. (<a
href="https://doi.org/10.1137/18M1218212">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Cholesky QR algorithm is an efficient communication-minimizing algorithm for computing the QR factorization of a tall-skinny matrix $X\in\mathbb{R}^{m\times n}$, where $m\gg n$. Unfortunately it is inherently unstable and often breaks down when the matrix is ill-conditioned. A recent work [Yamamoto et al., ETNA, 44, pp. 306--326 (2015)] establishes that the instability can be cured by repeating the algorithm twice (called CholeskyQR$2$). However, the applicability of CholeskyQR$2$ is still limited by the requirement that the Cholesky factorization of the Gram matrix $X^{\top} X$ runs to completion, which means that it does not always work for matrices $X$ with the 2-norm condition number $\kappa_2(X)$ roughly greater than ${\bf u}^{-{1}/{2}}$, where ${\bf u}$ is the unit roundoff. In this work we extend the applicability to $\kappa_2(X)=\mathcal{O}({\bf u}^{-1})$ by introducing a shift to the computed Gram matrix so as to guarantee the Cholesky factorization $R^{\top}R= A^{\top}A+sI$ succeeds numerically. We show that the computed $AR^{-1}$ has reduced condition number that is roughly bounded by ${\bf u}^{-{1}/{2}}$, for which CholeskyQR$2$ safely computes the QR factorization, yielding a computed $Q$ of orthogonality $\|Q^{\top}Q-I\|_2$ and residual $\|A-QR\|_F/\|A\|_F$ both of the order of ${\bf u}$. Thus we obtain the required QR factorization by essentially running Cholesky QR thrice. We extensively analyze the resulting algorithm shiftedCholeskyQR3 to reveal its excellent numerical stability. The shiftedCholeskyQR3 algorithm is also highly parallelizable, and applicable and effective also when working with an oblique inner product. We illustrate our findings through experiments, in which we achieve significant speedup over alternative methods.},
  archive      = {J_SISC},
  author       = {Takeshi Fukaya and Ramaseshan Kannan and Yuji Nakatsukasa and Yusaku Yamamoto and Yuka Yanagisawa},
  doi          = {10.1137/18M1218212},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {1},
  pages        = {A477-A503},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Shifted cholesky QR for computing the QR factorization of ill-conditioned matrices},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The computation of multiple roots of a bernstein basis
polynomial. <em>SISC</em>, <em>42</em>(1), A452–A476. (<a
href="https://doi.org/10.1137/18M1219904">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper describes the algorithms of Musser and Gauss for the computation of multiple roots of a theoretically exact Bernstein basis polynomial $\hat{f}(y)$ when the coefficients of its given form $f(y)$ are corrupted by noise. The exact roots of $f(y)$ can therefore be assumed to be simple, and thus the problem reduces to the calculation of multiple roots of a polynomial $\tilde{f}(y)$ that is near $f(y)$, such that the backward error is small. The algorithms require many greatest common divisor (GCD) computations and polynomial deconvolutions, both of which are implemented by a structure-preserving matrix method. The motivation of these algorithms arises from the unstructured and structured condition numbers of a multiple root of a polynomial. These condition numbers have an elegant interpretation in terms of the pejorative manifold of $\hat{f}(y)$, which allows the geometric significance of the GCD computations and polynomial deconvolutions to be considered. A variant of the Sylvester resultant matrix is used for the GCD computations because it yields better results than the standard form of this matrix, and the polynomial deconvolutions can be computed in several different ways, sequentially or simultaneously, and with the inclusion or omission of the preservation of the structure of the coefficient matrix. It is shown that Gauss&#39; algorithm yields better results than Musser&#39;s algorithm, and the reason for these superior results is explained.},
  archive      = {J_SISC},
  author       = {Martin Bourne and Joab Winkler and Yi Su},
  doi          = {10.1137/18M1219904},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {1},
  pages        = {A452-A476},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {The computation of multiple roots of a bernstein basis polynomial},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multilevel adaptive sparse leja approximations for bayesian
inverse problems. <em>SISC</em>, <em>42</em>(1), A424–A451. (<a
href="https://doi.org/10.1137/19M1260293">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deterministic interpolation and quadrature methods are often unsuitable to address Bayesian inverse problems depending on computationally expensive forward mathematical models. While interpolation may give precise posterior approximations, deterministic quadrature is usually unable to efficiently investigate an informative and thus concentrated likelihood. This leads to a large number of required expensive evaluations of the mathematical model. To overcome these challenges, we formulate and test a multilevel adaptive sparse Leja algorithm. At each level, adaptive sparse grid interpolation and quadrature are used to approximate the posterior and perform all quadrature operations, respectively. Specifically, our algorithm uses coarse discretizations of the underlying mathematical model to investigate the parameter space and to identify areas of high posterior probability. Adaptive sparse grid algorithms are then used to place points in these areas and ignore other areas of small posterior probability. The points are weighted Leja points. As the model discretization is coarse, the construction of the sparse grid is computationally efficient. On this sparse grid, the posterior measure can be approximated accurately with few expensive, fine model discretizations. The efficiency of the algorithm can be enhanced further by exploiting more than two discretization levels. We apply the proposed multilevel adaptive sparse Leja algorithm in numerical experiments involving elliptic inverse problems in two- and three-dimensional space, in which we compare it with Markov chain Monte Carlo sampling and a standard multilevel approximation.},
  archive      = {J_SISC},
  author       = {I.-G. Farcaş and J. Latz and E. Ullmann and T. Neckel and H.-J. Bungartz},
  doi          = {10.1137/19M1260293},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {1},
  pages        = {A424-A451},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Multilevel adaptive sparse leja approximations for bayesian inverse problems},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An efficient proximal block coordinate homotopy method for
large-scale sparse least squares problems. <em>SISC</em>,
<em>42</em>(1), A395–A423. (<a
href="https://doi.org/10.1137/19M1243828">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an efficient and robust algorithm framework is presented for large-scale sparse least squares problems. This framework decomposes the original sparse least squares problem into a sequence of small-scale $l_1$-minimization subproblems. Every subproblem is solved by an improved $l_1$-homotopy method which differs from the original $l_1$-homotopy method by adopting a warm-start procedure and an $\varepsilon$-precision verification-correction technique. Moreover, based on a carefully designed block coordinate update strategy, the algorithm framework is proved to converge to a $\tilde \tau$-``precise&quot; solution in a finite number of steps and the value of the objective function linearly converges. Numerical comparisons between the presented algorithms and a number of state-of-the-art algorithms on real and randomly generated data sets demonstrate the robustness and high performance of the presented algorithms. As an example, the presented algorithm only needs 13 seconds to solve an $l_1$-minimization problem with tens of millions of samples and features.},
  archive      = {J_SISC},
  author       = {Guoqiang Wang and Xinyuan Wei and Bo Yu and Lijun Xu},
  doi          = {10.1137/19M1243828},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {1},
  pages        = {A395-A423},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {An efficient proximal block coordinate homotopy method for large-scale sparse least squares problems},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Two-side a posteriori error estimates for the dual-weighted
residual method. <em>SISC</em>, <em>42</em>(1), A371–A394. (<a
href="https://doi.org/10.1137/18M1227275">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we derive two-sided a posteriori error estimates for the dual-weighted residual (DWR) method. We consider both single and multiple goal functionals. Using a saturation assumption, we derive lower bounds yielding the efficiency of the error estimator. These results hold true for both nonlinear partial differential equations and nonlinear functionals of interest. Furthermore, the DWR method employed in this work accounts for balancing the discretization error with the nonlinear iteration error. We also perform careful studies of the remainder term that is usually neglected. Based on these theoretical investigations, several algorithms are designed. Our theoretical findings and algorithmic developments are substantiated with some numerical tests. Specifically, we also provide a counterexample in which the saturation assumption is violated.},
  archive      = {J_SISC},
  author       = {B. Endtmayer and U. Langer and T. Wick},
  doi          = {10.1137/18M1227275},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {1},
  pages        = {A371-A394},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Two-side a posteriori error estimates for the dual-weighted residual method},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multidimensional staggered grid residual distribution scheme
for lagrangian hydrodynamics. <em>SISC</em>, <em>42</em>(1), A343–A370.
(<a href="https://doi.org/10.1137/18M1223939">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present the second-order multidimensional staggered grid hydrodynamics residual distribution (SGH RD) scheme for Lagrangian hydrodynamics. The SGH RD scheme is based on the staggered finite element discretizations as in [V. A. Dobrev, T. V.Kolev, and R. N. Rieben, SIAM J. Sci. Comput. 34 (2012), pp. B606--B641]. However, the advantage of the residual formulation over classical FEM approaches consists in the natural mass matrix diagonalization which allows one to avoid the solution of the linear system with the global sparse mass matrix while retaining the desired order of accuracy. This is achieved by using Bernstein polynomials as finite element shape functions and coupling the space discretization with the deferred correction type timestepping method. Moreover, it can be shown that for the Lagrangian formulation written in nonconservative form, our RD scheme ensures the exact conservation of the mass, momentum, and total energy. In this paper, we also discuss construction of numerical viscosity approximations for the SGH RD scheme, allowing us to reduce the dissipation of the numerical solution. Thanks to the generic formulation of the staggered grid RD scheme, it can be directly applied to both single- and multimaterial and multiphase models. Finally, we demonstrate computational results obtained with the proposed RD scheme for several challenging test problems.},
  archive      = {J_SISC},
  author       = {Rémi Abgrall and Konstantin Lipnikov and Nathaniel Morgan and Svetlana Tokareva},
  doi          = {10.1137/18M1223939},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {1},
  pages        = {A343-A370},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Multidimensional staggered grid residual distribution scheme for lagrangian hydrodynamics},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A multigrid method for unfitted finite element
discretizations of elliptic interface problems. <em>SISC</em>,
<em>42</em>(1), A318–A342. (<a
href="https://doi.org/10.1137/18M1203353">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider discrete Poisson interface problems resulting from linear unfitted finite elements, also called cut finite elements. Three of these unfitted finite element methods, known from the literature, are studied. Two of these are suitable only for small jumps in the diffusion coefficient, and the third one has a robustness property that makes it appropriate also for interface problems with large coefficient jumps. All three methods rely on Nitsche&#39;s method to incorporate the interface conditions. The main topic of the paper is the development of a multigrid method, based on a novel prolongation operator for the unfitted finite element space and an interface smoother that is designed to yield robustness for large jumps in the diffusion coefficients. Numerical results are presented which illustrate efficiency of this multigrid method and demonstrate its robustness properties with respect to variation of the mesh size, location of the interface, and contrast in the diffusion coefficients.},
  archive      = {J_SISC},
  author       = {Thomas Ludescher and Sven Gross and Arnold Reusken},
  doi          = {10.1137/18M1203353},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {1},
  pages        = {A318-A342},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A multigrid method for unfitted finite element discretizations of elliptic interface problems},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Physics-informed generative adversarial networks for
stochastic differential equations. <em>SISC</em>, <em>42</em>(1),
A292–A317. (<a href="https://doi.org/10.1137/18M1225409">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We developed a new class of physics-informed generative adversarial networks (PI-GANs) to solve forward, inverse, and mixed stochastic problems in a unified manner based on a limited number of scattered measurements. Unlike standard GANs relying solely on data for training, here we encoded into the architecture of GANs the governing physical laws in the form of stochastic differential equations (SDEs) using automatic differentiation. In particular, we applied Wasserstein GANs with gradient penalty (WGAN-GP) for its enhanced stability compared to vanilla GANs. We first tested WGAN-GP in approximating Gaussian processes of different correlation lengths based on data realizations collected from simultaneous reads at sparsely placed sensors. We obtained good approximation of the generated stochastic processes to the target ones even if there is a mismatch between the input noise dimensionality and the effective dimensionality of the target stochastic processes. We also studied the overfitting issue for both the discriminator and the generator, and we found that overfitting occurs also in the generator in addition to the discriminator as previously reported. Subsequently, we considered the solution of elliptic SDEs requiring approximations of three stochastic processes, namely the solution, the forcing, and the diffusion coefficient. Here again, we assumed data collected from simultaneous reads at a limited number of sensors for the multiple stochastic processes. Three generators were used for the PI-GANs: two of them were feed forward deep neural networks (DNNs), while the other one was the neural network induced by the SDE. For the case where we have one group of data, we employed one feed forward DNN as the discriminator, while for the case of multiple groups of data we employed multiple discriminators in PI-GANs. We solved forward, inverse, and mixed problems without changing the framework of PI-GANs, obtaining both the means and the standard deviations of the stochastic solution and the diffusion coefficient in good agreement with benchmarks. In this work, we have demonstrated the effectiveness of PI-GANs in solving SDEs for about 120 dimensions. In principle, PI-GANs could tackle very high dimensional problems given more sensor data with low-polynomial growth in computational cost.},
  archive      = {J_SISC},
  author       = {Liu Yang and Dongkun Zhang and George Em Karniadakis},
  doi          = {10.1137/18M1225409},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {1},
  pages        = {A292-A317},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Physics-informed generative adversarial networks for stochastic differential equations},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Reduced basis methods—an application to variational
discretization of parametrized elliptic optimal control problems.
<em>SISC</em>, <em>42</em>(1), A271–A291. (<a
href="https://doi.org/10.1137/18M1227147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a class of parameter dependent optimal control problems of elliptic PDEs with constraints of general type on the control variable. Applying the concept of variational discretization, together with techniques from the reduced basis method, we construct a reduced basis surrogate model for the control problem. We establish estimators for the greedy sampling procedure which only involve the residuals of the state and the adjoint equation, but not of the gradient equation of the optimality system. The estimators are sharp up to a constant, i.e., they are equivalent to the approximation errors in control, state, and adjoint state. Numerical experiments show the performance of our approach.},
  archive      = {J_SISC},
  author       = {Ahmad Ahmad Ali and Michael Hinze},
  doi          = {10.1137/18M1227147},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {1},
  pages        = {A271-A291},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Reduced basis methods---an application to variational discretization of parametrized elliptic optimal control problems},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Parameter recovery for the 2 dimensional navier–stokes
equations via continuous data assimilation. <em>SISC</em>,
<em>42</em>(1), A250–A270. (<a
href="https://doi.org/10.1137/19M1248583">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a continuous data assimilation algorithm proposed by Azouani, Olson, and Titi (AOT) in the context of an unknown viscosity. We determine the large-time error between the true solution of the 2 dimensional Navier--Stokes equations and the assimilated solution due to discrepancy between an approximate viscosity and the physical viscosity. Additionally, we develop an algorithm that can be run in tandem with the AOT algorithm to recover both the true solution and the true viscosity using only spatially discrete velocity measurements.},
  archive      = {J_SISC},
  author       = {Elizabeth Carlson and Joshua Hudson and Adam Larios},
  doi          = {10.1137/19M1248583},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {1},
  pages        = {A250-A270},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Parameter recovery for the 2 dimensional navier--stokes equations via continuous data assimilation},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). When bifidelity meets CoKriging: An efficient
physics-informed MultiFidelity method. <em>SISC</em>, <em>42</em>(1),
A220–A249. (<a href="https://doi.org/10.1137/18M1231353">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we propose a framework that combines approximation-theory-based multifidelity method and Gaussian-process-regression-based multifidelity method to achieve data-model convergence when stochastic simulation models and sparse accurate observation data are available. Specifically, the two types of multifidelity methods we use are the bifidelity method and the cokriging method. The new approach uses the bifidelity method to efficiently estimate the empirical mean and covariance of the stochastic simulation outputs, then it uses these statistics to construct Gaussian process (GP) representing low-fidelity in cokriging. We also combine the bifidelity method with kriging, where the approximated empirical statistics are used to construct the GP as well. We prove that the resulting posterior mean by the new physics-informed approach preserves linear physical constraints up to an error bound. We present numerical examples to demonstrate that using this method, we can obtain accurate construction of the state of interest based on partially a correct physical model and a few accurate observations.},
  archive      = {J_SISC},
  author       = {Xiu Yang and Xueyu Zhu and Jing Li},
  doi          = {10.1137/18M1231353},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {1},
  pages        = {A220-A249},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {When bifidelity meets CoKriging: An efficient physics-informed MultiFidelity method},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). S-step enlarged krylov subspace conjugate gradient methods.
<em>SISC</em>, <em>42</em>(1), A187–A219. (<a
href="https://doi.org/10.1137/18M1182528">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, enlarged Krylov subspace methods, which consist of enlarging the Krylov subspace by a maximum of $t$ vectors per iteration based on the domain decomposition of the graph of $A$, were introduced with the aim of reducing communication when solving systems of linear equations $Ax=b$. In this paper, the s-step enlarged Krylov subspace conjugate gradient methods are introduced, whereby $s$ iterations of the enlarged conjugate gradient methods are merged in one iteration. The numerical stability of these s-step methods is studied, and several numerically stable versions are proposed. Similarly to the enlarged Krylov subspace methods, the s-step enlarged Krylov subspace methods have a faster convergence than Krylov methods, in terms of iterations. Moreover, by computing $st$ basis vectors of the enlarged Krylov subspace $\mathscr{K}_{k,t}(A,r_0)$ at the beginning of each s-step iteration, communication is further reduced. It is shown in this paper that the introduced methods are parallelizable with less communication, with respect to their corresponding enlarged versions and to conjugate gradient.},
  archive      = {J_SISC},
  author       = {Sophie M. Moufawad},
  doi          = {10.1137/18M1182528},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {1},
  pages        = {A187-A219},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {S-step enlarged krylov subspace conjugate gradient methods},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fast coulomb matrix construction via compressing the
interactions between continuous charge distributions. <em>SISC</em>,
<em>42</em>(1), A162–A186. (<a
href="https://doi.org/10.1137/19M1252855">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The continuous fast multipole method (CFMM) is well known for its asymptotically linear complexity for constructing the Coulomb matrix in quantum chemistry. However, in practice, CFMM must evaluate a large number of interactions directly, being unable to utilize multipole expansions for interactions between overlapping continuous charge distributions. Instead of multipole expansions, we propose a technique for compressing the interactions between charge distributions into low-rank form, resulting in far fewer interactions that must be computed directly. The technique is used with an $\mathcal{H}^2$ matrix representation of the electron repulsion integral tensor. Numerical tests on alkane and protein molecules show that our new method requires 5 to 18 times fewer direct interactions to be evaluated than in CFMM, leading to essentially an equal reduction in storage or computation cost.},
  archive      = {J_SISC},
  author       = {Xin Xing and Edmond Chow},
  doi          = {10.1137/19M1252855},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {1},
  pages        = {A162-A186},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Fast coulomb matrix construction via compressing the interactions between continuous charge distributions},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A low-rank tensor method for PDE-constrained optimization
with isogeometric analysis. <em>SISC</em>, <em>42</em>(1), A140–A161.
(<a href="https://doi.org/10.1137/18M1227238">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Isogeometric analysis (IgA) has become one of the most popular methods for the discretization of PDEs, motivated by the use of nonuniform rational B-splines for geometric representations in industry and science. A crucial challenge lies in the solution of the discretized equations, which we discuss in this paper with a particular focus on PDE-constrained optimization discretized using IgA. The discretization results in a system of large mass and stiffness matrices, which are typically very costly to assemble. To reduce the computation time and storage requirements, low-rank tensor methods as proposed in [A. Mantzaflaris, B. Jüttler, B. N. Khoromskij, and U. Langer, Comput. Methods Appl. Mech. Engrg., 316 (2017), pp. 1062--1085] have become a promising approach. We present a framework for the assembly of these matrices in low-rank form using tensor train approximations. Furthermore, our framework allows for the exploitation of the resulting low-rank structure of the mass and stiffness matrices, and it can be used to solve a PDE-constrained optimization problem without assembling the actual system matrices and carries the low-rank format over to the solution. We use the block alternating minimal energy method to efficiently solve the corresponding KKT system of the optimization problem. We show several numerical experiments with three-dimensional geometries to demonstrate that the low-rank assembly and solution drastically reduce the memory demands and computing times, depending on the approximation ranks of the domain.},
  archive      = {J_SISC},
  author       = {Alexandra Bünger and Sergey Dolgov and Martin Stoll},
  doi          = {10.1137/18M1227238},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {1},
  pages        = {A140-A161},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A low-rank tensor method for PDE-constrained optimization with isogeometric analysis},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multirevolution integrators for differential equations with
fast stochastic oscillations. <em>SISC</em>, <em>42</em>(1), A115–A139.
(<a href="https://doi.org/10.1137/19M1243075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a new methodology based on the multirevolution idea for constructing integrators for stochastic differential equations in the situation where the fast oscillations themselves are driven by a Stratonovich noise. Applications include in particular highly oscillatory Kubo oscillators and spatial discretizations of the nonlinear Schrödinger equation with fast white noise dispersion. We construct a method of weak order two with computational cost and accuracy both independent of the stiffness of the oscillations. A geometric modification that conserves exactly quadratic invariants is also presented.},
  archive      = {J_SISC},
  author       = {Adrien Laurent and Gilles Vilmart},
  doi          = {10.1137/19M1243075},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {1},
  pages        = {A115-A139},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Multirevolution integrators for differential equations with fast stochastic oscillations},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Ensemble transform algorithms for nonlinear smoothing
problems. <em>SISC</em>, <em>42</em>(1), A87–A114. (<a
href="https://doi.org/10.1137/19M1239544">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several numerical tools designed to overcome the challenges of smoothing in a nonlinear and non-Gaussian setting are investigated for a class of particle smoothers. The considered family of smoothers is induced by the class of linear ensemble transform filters which contains classical filters such as the stochastic ensemble Kalman filter, the ensemble square root filter, and the recently introduced nonlinear ensemble transform filter. Further the ensemble transform particle smoother is introduced and particularly highlighted as it is consistent in the particle limit and does not require assumptions with respect to the family of the posterior distribution. The linear update pattern of the considered class of linear ensemble transform smoothers allows one to implement important supplementary techniques such as adaptive spread corrections, hybrid formulations, and localization in order to facilitate their application to complex estimation problems. These additional features are derived and numerically investigated for a sequence of increasingly challenging test problems.},
  archive      = {J_SISC},
  author       = {Jana de Wiljes and Sahani Pathiraja and Sebastian Reich},
  doi          = {10.1137/19M1239544},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {1},
  pages        = {A87-A114},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Ensemble transform algorithms for nonlinear smoothing problems},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A discontinuous galerkin method for stochastic conservation
laws. <em>SISC</em>, <em>42</em>(1), A54–A86. (<a
href="https://doi.org/10.1137/19M125710X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we present a discontinuous Galerkin (DG) method to approximate stochastic conservation laws, which is an efficient high-order scheme. We study the stability for the semidiscrete DG methods for fully nonlinear stochastic equations. Error estimates are obtained for smooth solutions of semilinear stochastic equations with variable coefficients. We also establish a derivative-free second-order time discretization scheme for matrix-valued stochastic ordinary differential equations. Numerical experiments are performed to confirm the analytical results.},
  archive      = {J_SISC},
  author       = {Yunzhang Li and Chi-Wang Shu and Shanjian Tang},
  doi          = {10.1137/19M125710X},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {1},
  pages        = {A54-A86},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A discontinuous galerkin method for stochastic conservation laws},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On barrier and modified barrier multigrid methods for
three-dimensional topology optimization. <em>SISC</em>, <em>42</em>(1),
A28–A53. (<a href="https://doi.org/10.1137/19M1254490">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the challenges encountered in optimization of mechanical structures, in particular in what is known as topology optimization, is the size of the problems, which can easily involve millions of variables. A basic example is the minimum compliance formulation of the variable thickness sheet (VTS) problem, which is equivalent to a convex problem. We propose to solve the VTS problem by the penalty-barrier multiplier (PBM) method, introduced by R. Polyak and later studied by Ben-Tal and Zibulevsky and others. The most computationally expensive part of the algorithm is the solution of linear systems arising from the Newton method used to minimize a generalized augmented Lagrangian. We use a special structure of the Hessian of this Lagrangian to reduce the size of the linear system and to convert it to a form suitable for a standard multigrid method. This converted system is solved approximately by a multigrid preconditioned minimal residual method. The proposed PBM algorithm is compared with the optimality criteria method and an interior point method, both using a similar iterative solver setup. We apply all three methods to different loading scenarios. In our experiments, the PBM method clearly outperforms the other methods in terms of computation time required to achieve a certain degree of accuracy.},
  archive      = {J_SISC},
  author       = {Alexander Brune and Michal Kočvara},
  doi          = {10.1137/19M1254490},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {1},
  pages        = {A28-A53},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {On barrier and modified barrier multigrid methods for three-dimensional topology optimization},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A class of exponential integrators based on spectral
deferred correction. <em>SISC</em>, <em>42</em>(1), A1–A27. (<a
href="https://doi.org/10.1137/19M1256166">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a new class of exponential integrators based on spectral deferred correction. These new methods are simple to implement at any order of accuracy and can be used to efficiently solve initial value problems when high precision is desired. We begin by deriving exponential spectral deferred correction (ESDC) methods for solving both partitioned and unpartitioned initial value problems. We then analyze the linear stability properties of these new integrators and show that they are comparable to those of existing semi-implicit spectral deferred correction schemes. Finally, we present five numerical experiments to demonstrate the improved efficiency of our new exponential integrator compared to semi-implicit spectral deferred correction schemes and existing fourth-order exponential Runge--Kutta methods.},
  archive      = {J_SISC},
  author       = {Tommaso Buvoli},
  doi          = {10.1137/19M1256166},
  journal      = {SIAM Journal on Scientific Computing},
  number       = {1},
  pages        = {A1-A27},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A class of exponential integrators based on spectral deferred correction},
  volume       = {42},
  year         = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
