<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>ECJ_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ecj---25">ECJ - 25</h2>
<ul>
<li><details>
<summary>
(2020). Errata: Convergence analysis of evolutionary algorithms that
are based on the paradigm of information geometry. <em>ECJ</em>,
<em>28</em>(4), 709–710. (<a
href="https://doi.org/10.1162/evco_x_00281">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Four lines below Equation (7), page 682, it must correctly read: Q=−12Hf(x)=−12∇∇Tf(x)In Equation (27), page 685, the logarithms are missing, it must correctly read: (27)Iij(θ)=∫∂lnp(x|θ)∂θi∂lnp(x|θ)∂θjp(x|θ)dNx=-∫∂2lnp(x|θ)∂θi∂θjp(x|θ)dNxOn page 687, below Equation (36), the derivations leading to Equation (40) must be corrected1 (the final result in Equation (41) does not change by this correction):Treating the C-related part in (35) using ∂Cab∂Ccd=12δacδbd+δadδbc (here, symmetry of C must be taken into account) yields (37)I(α1α2),(β1β2)=12∑k,l,m,nCkl-1∂Clm∂Cα1α2Cmn-1∂Cnk∂Cβ1β2=18∑k,l,m,nCkl-1(δlα1δmα2+δlα2δmα1)Cmn-1(δnβ1δkβ2+δnβ2δkβ1).Thus, one gets for the C-related part of θ (taking the symmetry of C-1 into account) (38)C:I(α1α2),(β1β2)=14Cα1β1-1Cα2β2-1+Cα1β2-1Cα2β1-1.The non-numbered equation below Equation (40), page 687, must be adopted accordingly:The correctness of (40)C:I(α1α2),(β1β2)-1=2Cα1β2Cβ1α2is proven directly by checking ∑β1,β2I(α1α2),(β1β2)-1I(β1β2),(γ1γ2)=12δα1γ2δα2γ1+δα1γ1δα2γ2.On page 694, the derivation of Equation (83) must be corrected (again without consequences for the result in Equation (84)): (83)∂σf∂Cmn=121σf∂∂Cmn∑i,j,k,l(ai-2x¯kQki)Cij(aj-2x¯lQlj)+2QijCjkQklCli=121σf∑i,j,k,l(ai-2x¯kQki)12(δimδjn+δinδjm)(aj-2x¯lQlj)12+Qij(δjmδkn+δjnδkm)QklCli+QijCjkQkl(δlmδin+δlnδim)=121σf∑k,l(am-2x¯kQkm)(an-2x¯lQln)+4QmkCklQln},
  archive      = {J_ECJ},
  author       = {Beyer, Hans-Georg},
  doi          = {10.1162/evco_x_00281},
  journal      = {Evolutionary Computation},
  number       = {4},
  pages        = {709-710},
  shortjournal = {Evol. Comput.},
  title        = {Errata: Convergence analysis of evolutionary algorithms that are based on the paradigm of information geometry},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evolved transistor array robot controllers. <em>ECJ</em>,
<em>28</em>(4), 677–708. (<a
href="https://doi.org/10.1162/evco_a_00272">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the first time, a field programmable transistor array (FPTA) was used to evolve robot control circuits directly in analog hardware. Controllers were successfully incrementally evolved for a physical robot engaged in a series of visually guided behaviours, including finding a target in a complex environment where the goal was hidden from most locations. Circuits for recognising spoken commands were also evolved and these were used in conjunction with the controllers to enable voice control of the robot, triggering behavioural switching. Poor quality visual sensors were deliberately used to test the ability of evolved analog circuits to deal with noisy uncertain data in realtime. Visual features were coevolved with the controllers to automatically achieve dimensionality reduction and feature extraction and selection in an integrated way. An efficient new method was developed for simulating the robot in its visual environment. This allowed controllers to be evaluated in a simulation connected to the FPTA. The controllers then transferred seamlessly to the real world. The circuit replication issue was also addressed in experiments where circuits were evolved to be able to function correctly in multiple areas of the FPTA. A methodology was developed to analyse the evolved circuits which provided insights into their operation. Comparative experiments demonstrated the superior evolvability of the transistor array medium.},
  archive      = {J_ECJ},
  author       = {Garvie, Michael and Flascher, Ittai and Philippides, Andrew and Thompson, Adrian and Husbands, Phil},
  doi          = {10.1162/evco_a_00272},
  journal      = {Evolutionary Computation},
  number       = {4},
  pages        = {677-708},
  shortjournal = {Evol. Comput.},
  title        = {Evolved transistor array robot controllers},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evolutionary image transition and painting using random
walks. <em>ECJ</em>, <em>28</em>(4), 643–675. (<a
href="https://doi.org/10.1162/evco_a_00270">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a study demonstrating how random walk algorithms can be used for evolutionary image transition. We design different mutation operators based on uniform and biased random walks and study how their combination with a baseline mutation operator can lead to interesting image transition processes in terms of visual effects and artistic features. Using feature-based analysis we investigate the evolutionary image transition behaviour with respect to different features and evaluate the images constructed during the image transition process. Afterwards, we investigate how modifications of our biased random walk approaches can be used for evolutionary image painting. We introduce an evolutionary image painting approach whose underlying biased random walk can be controlled by a parameter influencing the bias of the random walk and thereby creating different artistic painting effects.},
  archive      = {J_ECJ},
  author       = {Neumann, Aneta and Alexander, Bradley and Neumann, Frank},
  doi          = {10.1162/evco_a_00270},
  journal      = {Evolutionary Computation},
  number       = {4},
  pages        = {643-675},
  shortjournal = {Evol. Comput.},
  title        = {Evolutionary image transition and painting using random walks},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Inferring future landscapes: Sampling the local optima
level. <em>ECJ</em>, <em>28</em>(4), 621–641. (<a
href="https://doi.org/10.1162/evco_a_00271">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Connection patterns among Local Optima Networks (LONs) can inform heuristic design for optimisation. LON research has predominantly required complete enumeration of a fitness landscape, thereby restricting analysis to problems diminutive in size compared to real-life situations. LON sampling algorithms are therefore important. In this article, we study LON construction algorithms for the Quadratic Assignment Problem (QAP). Using machine learning, we use estimated LON features to predict search performance for competitive heuristics used in the QAP domain. The results show that by using random forest regression, LON construction algorithms produce fitness landscape features which can explain almost all search variance. We find that LON samples better relate to search than enumerated LONs do. The importance of fitness levels of sampled LONs in search predictions is crystallised. Features from LONs produced by different algorithms are combined in predictions for the first time, with promising results for this “super-sampling”: a model to predict tabu search success explained 99\% of variance. Arguments are made for the use-case of each LON algorithm and for combining the exploitative process of one with the exploratory optimisation of the other.},
  archive      = {J_ECJ},
  author       = {Thomson, Sarah L. and Ochoa, Gabriela and Verel, Sébastien and Veerapen, Nadarajen},
  doi          = {10.1162/evco_a_00271},
  journal      = {Evolutionary Computation},
  number       = {4},
  pages        = {621-641},
  shortjournal = {Evol. Comput.},
  title        = {Inferring future landscapes: Sampling the local optima level},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). High-order entropy-based population diversity measures in
the traveling salesman problem. <em>ECJ</em>, <em>28</em>(4), 595–619.
(<a href="https://doi.org/10.1162/evco_a_00268">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To maintain the population diversity of genetic algorithms (GAs), we are required to employ an appropriate population diversity measure. However, commonly used population diversity measures designed for permutation problems do not consider the dependencies between the variables of the individuals in the population. We propose three types of population diversity measures that address high-order dependencies between the variables to investigate the effectiveness of considering high-order dependencies. The first is formulated as the entropy of the probability distribution of individuals estimated from the population based on an m -th--order Markov model. The second is an extension of the first. The third is similar to the first, but it is based on a variable order Markov model. The proposed population diversity measures are incorporated into the evaluation function of a GA for the traveling salesman problem to maintain population diversity. Experimental results demonstrate the effectiveness of the three types of high-order entropy-based population diversity measures against the commonly used population diversity measures.},
  archive      = {J_ECJ},
  author       = {Nagata, Yuichi},
  doi          = {10.1162/evco_a_00268},
  journal      = {Evolutionary Computation},
  number       = {4},
  pages        = {595-619},
  shortjournal = {Evol. Comput.},
  title        = {High-order entropy-based population diversity measures in the traveling salesman problem},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Genetic programming hyper-heuristics with vehicle
collaboration for uncertain capacitated arc routing problems.
<em>ECJ</em>, <em>28</em>(4), 563–593. (<a
href="https://doi.org/10.1162/evco_a_00267">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to its direct relevance to post-disaster operations, meter reading and civil refuse collection, the Uncertain Capacitated Arc Routing Problem (UCARP) is an important optimisation problem. Stochastic models are critical to study as they more accurately represent the real world than their deterministic counterparts. Although there have been extensive studies in solving routing problems under uncertainty, very few have considered UCARP, and none consider collaboration between vehicles to handle the negative effects of uncertainty. This article proposes a novel Solution Construction Procedure (SCP) that generates solutions to UCARP within a collaborative, multi-vehicle framework. It consists of two types of collaborative activities: one when a vehicle unexpectedly expends capacity ( route failure ), and the other during the refill process. Then, we propose a Genetic Programming Hyper-Heuristic (GPHH) algorithm to evolve the routing policy used within the collaborative framework. The experimental studies show that the new heuristic with vehicle collaboration and GP-evolved routing policy significantly outperforms the compared state-of-the-art algorithms on commonly studied test problems. This is shown to be especially true on instances with larger numbers of tasks and vehicles. This clearly shows the advantage of vehicle collaboration in handling the uncertain environment, and the effectiveness of the newly proposed algorithm.},
  archive      = {J_ECJ},
  author       = {MacLachlan, Jordan and Mei, Yi and Branke, Juergen and Zhang, Mengjie},
  doi          = {10.1162/evco_a_00267},
  journal      = {Evolutionary Computation},
  number       = {4},
  pages        = {563-593},
  shortjournal = {Evol. Comput.},
  title        = {Genetic programming hyper-heuristics with vehicle collaboration for uncertain capacitated arc routing problems},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Genetic programming for evolving similarity functions for
clustering: Representations and analysis. <em>ECJ</em>, <em>28</em>(4),
531–561. (<a href="https://doi.org/10.1162/evco_a_00264">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is a difficult and widely studied data mining task, with many varieties of clustering algorithms proposed in the literature. Nearly all algorithms use a similarity measure such as a distance metric (e.g., Euclidean distance) to decide which instances to assign to the same cluster. These similarity measures are generally predefined and cannot be easily tailored to the properties of a particular dataset, which leads to limitations in the quality and the interpretability of the clusters produced. In this article, we propose a new approach to automatically evolving similarity functions for a given clustering algorithm by using genetic programming. We introduce a new genetic programming-based method which automatically selects a small subset of features (feature selection) and then combines them using a variety of functions (feature construction) to produce dynamic and flexible similarity functions that are specifically designed for a given dataset. We demonstrate how the evolved similarity functions can be used to perform clustering using a graph-based representation. The results of a variety of experiments across a range of large, high-dimensional datasets show that the proposed approach can achieve higher and more consistent performance than the benchmark methods. We further extend the proposed approach to automatically produce multiple complementary similarity functions by using a multi-tree approach, which gives further performance improvements. We also analyse the interpretability and structure of the automatically evolved similarity functions to provide insight into how and why they are superior to standard distance metrics.},
  archive      = {J_ECJ},
  author       = {Lensen, Andrew and Xue, Bing and Zhang, Mengjie},
  doi          = {10.1162/evco_a_00264},
  journal      = {Evolutionary Computation},
  number       = {4},
  pages        = {531-561},
  shortjournal = {Evol. Comput.},
  title        = {Genetic programming for evolving similarity functions for clustering: Representations and analysis},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). EvoComposer: An evolutionary algorithm for 4-voice music
compositions. <em>ECJ</em>, <em>28</em>(3), 489–530. (<a
href="https://doi.org/10.1162/evco_a_00265">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary algorithms mimic evolutionary behaviors in order to solve problems. They have been successfully applied in many areas and appear to have a special relationship with creative problems; such a relationship, over the last two decades, has resulted in a long list of applications, including several in the field of music. In this article, we provide an evolutionary algorithm able to compose music. More specifically we consider the following 4-voice harmonization problem: one of the 4 voices (which are bass, tenor, alto, and soprano) is given as input and the composer has to write the other 3 voices in order to have a complete 4-voice piece of music with a 4-note chord for each input note. Solving such a problem means finding appropriate chords to use for each input note and also finding a placement of the notes within each chord so that melodic concerns are addressed. Such a problem is known as the unfigured harmonization problem . The proposed algorithm for the unfigured harmonization problem, named EvoComposer , uses a novel representation of the solutions in terms of chromosomes (that allows to handle both harmonic and nonharmonic tones), specialized operators (that exploit musical information to improve the quality of the produced individuals), and a novel hybrid multiobjective evaluation function (based on an original statistical analysis of a large corpus of Bach&#39;s music). Moreover EvoComposer is the first evolutionary algorithm for this specific problem. EvoComposer is a multiobjective evolutionary algorithm, based on the well-known NSGA-II strategy, and takes into consideration two objectives: the harmonic objective, that is finding appropriate chords, and the melodic objective, that is finding appropriate melodic lines. The composing process is totally automatic, without any human intervention. We also provide an evaluation study showing that EvoComposer outperforms other metaheuristics by producing better solutions in terms of both well-known measures of performance , such as hypervolume, Δ index, coverage of two sets, and standard measures of music creativity . We conjecture that a similar approach can be useful also for similar musical problems.},
  archive      = {J_ECJ},
  author       = {De Prisco, R. and Zaccagnino, G. and Zaccagnino, R.},
  doi          = {10.1162/evco_a_00265},
  journal      = {Evolutionary Computation},
  number       = {3},
  pages        = {489-530},
  shortjournal = {Evol. Comput.},
  title        = {EvoComposer: An evolutionary algorithm for 4-voice music compositions},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Analysis of the (μ/μI,λ)-CSA-ES with repair by projection
applied to a conically constrained problem. <em>ECJ</em>,
<em>28</em>(3), 463–488. (<a
href="https://doi.org/10.1162/evco_a_00261">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Theoretical analyses of evolution strategies are indispensable for gaining a deep understanding of their inner workings. For constrained problems, rather simple problems are of interest in the current research. This work presents a theoretical analysis of a multi-recombinative evolution strategy with cumulative step size adaptation applied to a conically constrained linear optimization problem. The state of the strategy is modeled by random variables and a stochastic iterative mapping is introduced. For the analytical treatment, fluctuations are neglected and the mean value iterative system is considered. Nonlinear difference equations are derived based on one-generation progress rates. Based on that, expressions for the steady state of the mean value iterative system are derived. By comparison with real algorithm runs, it is shown that for the considered assumptions, the theoretical derivations are able to predict the dynamics and the steady state values of the real runs.},
  archive      = {J_ECJ},
  author       = {Spettel, Patrick and Beyer, Hans-Georg},
  doi          = {10.1162/evco_a_00261},
  journal      = {Evolutionary Computation},
  number       = {3},
  pages        = {463-488},
  shortjournal = {Evol. Comput.},
  title        = {Analysis of the (μ/μI,λ)-CSA-ES with repair by projection applied to a conically constrained problem},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Simple hyper-heuristics control the neighbourhood size of
randomised local search optimally for LeadingOnes. <em>ECJ</em>,
<em>28</em>(3), 437–461. (<a
href="https://doi.org/10.1162/evco_a_00258">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Selection hyper-heuristics (HHs) are randomised search methodologies which choose and execute heuristics during the optimisation process from a set of low-level heuristics. A machine learning mechanism is generally used to decide which low-level heuristic should be applied in each decision step. In this article, we analyse whether sophisticated learning mechanisms are always necessary for HHs to perform well. To this end we consider the most simple HHs from the literature and rigorously analyse their performance for the LeadingOnes benchmark function. Our analysis shows that the standard Simple Random, Permutation, Greedy, and Random Gradient HHs show no signs of learning. While the former HHs do not attempt to learn from the past performance of low-level heuristics, the idea behind the Random Gradient HH is to continue to exploit the currently selected heuristic as long as it is successful. Hence, it is embedded with a reinforcement learning mechanism with the shortest possible memory. However, the probability that a promising heuristic is successful in the next step is relatively low when perturbing a reasonable solution to a combinatorial optimisation problem. We generalise the “simple” Random Gradient HH so success can be measured over a fixed period of time τ ⁠ , instead of a single iteration. For LeadingOnes we prove that the Generalised Random Gradient (GRG) HH can learn to adapt the neighbourhood size of Randomised Local Search to optimality during the run. As a result, we prove it has the best possible performance achievable with the low-level heuristics (Randomised Local Search with different neighbourhood sizes), up to lower-order terms. We also prove that the performance of the HH improves as the number of low-level local search heuristics to choose from increases. In particular, with access to k low-level local search heuristics, it outperforms the best-possible algorithm using any subset of the k heuristics. Finally, we show that the advantages of GRG over Randomised Local Search and Evolutionary Algorithms using standard bit mutation increase if the anytime performance is considered (i.e., the performance gap is larger if approximate solutions are sought rather than exact ones). Experimental analyses confirm these results for different problem sizes (up to n = 10 8 ⁠ ) and shed some light on the best choices for the parameter τ in various situations.},
  archive      = {J_ECJ},
  author       = {Lissovoi, Andrei and Oliveto, Pietro S. and Warwicker, John Alasdair},
  doi          = {10.1162/evco_a_00258},
  journal      = {Evolutionary Computation},
  number       = {3},
  pages        = {437-461},
  shortjournal = {Evol. Comput.},
  title        = {Simple hyper-heuristics control the neighbourhood size of randomised local search optimally for LeadingOnes},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Diagonal acceleration for covariance matrix adaptation
evolution strategies. <em>ECJ</em>, <em>28</em>(3), 405–435. (<a
href="https://doi.org/10.1162/evco_a_00260">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce an acceleration for covariance matrix adaptation evolution strategies (CMA-ES) by means of adaptive diagonal decoding (dd-CMA). This diagonal acceleration endows the default CMA-ES with the advantages of separable CMA-ES without inheriting its drawbacks. Technically, we introduce a diagonal matrix D D that expresses coordinate-wise variances of the sampling distribution in DCD form. The diagonal matrix can learn a rescaling of the problem in the coordinates within a linear number of function evaluations. Diagonal decoding can also exploit separability of the problem, but, crucially, does not compromise the performance on nonseparable problems. The latter is accomplished by modulating the learning rate for the diagonal matrix based on the condition number of the underlying correlation matrix. dd-CMA-ES not only combines the advantages of default and separable CMA-ES, but may achieve overadditive speedup: it improves the performance, and even the scaling, of the better of default and separable CMA-ES on classes of nonseparable test functions that reflect, arguably, a landscape feature commonly observed in practice. The article makes two further secondary contributions: we introduce two different approaches to guarantee positive definiteness of the covariance matrix with active CMA, which is valuable in particular with large population size; we revise the default parameter setting in CMA-ES, proposing accelerated settings in particular for large dimension. All our contributions can be viewed as independent improvements of CMA-ES, yet they are also complementary and can be seamlessly combined. In numerical experiments with dd-CMA-ES up to dimension 5120, we observe remarkable improvements over the original covariance matrix adaptation on functions with coordinate-wise ill-conditioning. The improvement is observed also for large population sizes up to about dimension squared.},
  archive      = {J_ECJ},
  author       = {Akimoto, Y. and Hansen, N.},
  doi          = {10.1162/evco_a_00260},
  journal      = {Evolutionary Computation},
  number       = {3},
  pages        = {405-435},
  shortjournal = {Evol. Comput.},
  title        = {Diagonal acceleration for covariance matrix adaptation evolution strategies},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Generating new space-filling test instances for continuous
black-box optimization. <em>ECJ</em>, <em>28</em>(3), 379–404. (<a
href="https://doi.org/10.1162/evco_a_00262">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a method to generate diverse and challenging new test instances for continuous black-box optimization. Each instance is represented as a feature vector of exploratory landscape analysis measures. By projecting the features into a two-dimensional instance space, the location of existing test instances can be visualized, and their similarities and differences revealed. New instances are generated through genetic programming which evolves functions with controllable characteristics. Convergence to selected target points in the instance space is used to drive the evolutionary process, such that the new instances span the entire space more comprehensively. We demonstrate the method by generating two-dimensional functions to visualize its success, and ten-dimensional functions to test its scalability. We show that the method can recreate existing test functions when target points are co-located with existing functions, and can generate new functions with entirely different characteristics when target points are located in empty regions of the instance space. Moreover, we test the effectiveness of three state-of-the-art algorithms on the new set of instances. The results demonstrate that the new set is not only more diverse than a well-known benchmark set, but also more challenging for the tested algorithms. Hence, the method opens up a new avenue for developing test instances with controllable characteristics, necessary to expose the strengths and weaknesses of algorithms, and drive algorithm development.},
  archive      = {J_ECJ},
  author       = {Muñoz, Mario A. and Smith-Miles, Kate},
  doi          = {10.1162/evco_a_00262},
  journal      = {Evolutionary Computation},
  number       = {3},
  pages        = {379-404},
  shortjournal = {Evol. Comput.},
  title        = {Generating new space-filling test instances for continuous black-box optimization},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Difficulty adjustable and scalable constrained
multiobjective test problem toolkit. <em>ECJ</em>, <em>28</em>(3),
339–378. (<a href="https://doi.org/10.1162/evco_a_00259">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiobjective evolutionary algorithms (MOEAs) have progressed significantly in recent decades, but most of them are designed to solve unconstrained multiobjective optimization problems. In fact, many real-world multiobjective problems contain a number of constraints. To promote research on constrained multiobjective optimization, we first propose a problem classification scheme with three primary types of difficulty, which reflect various types of challenges presented by real-world optimization problems, in order to characterize the constraint functions in constrained multiobjective optimization problems (CMOPs). These are feasibility-hardness, convergence-hardness, and diversity-hardness. We then develop a general toolkit to construct difficulty adjustable and scalable CMOPs (DAS-CMOPs, or DAS-CMaOPs when the number of objectives is greater than three) with three types of parameterized constraint functions developed to capture the three proposed types of difficulty. In fact, the combination of the three primary constraint functions with different parameters allows the construction of a large variety of CMOPs, with difficulty that can be defined by a triplet, with each of its parameters specifying the level of one of the types of primary difficulty. Furthermore, the number of objectives in this toolkit can be scaled beyond three. Based on this toolkit, we suggest nine difficulty adjustable and scalable CMOPs and nine CMaOPs, to be called DAS-CMOP1-9 and DAS-CMaOP1-9, respectively. To evaluate the proposed test problems, two popular CMOEAs—MOEA/D-CDP (MOEA/D with constraint dominance principle) and NSGA-II-CDP (NSGA-II with constraint dominance principle) and two popular constrained many-objective evolutionary algorithms (CMaOEAs)—C-MOEA/DD and C-NSGA-III—are used to compare performance on DAS-CMOP1-9 and DAS-CMaOP1-9 with a variety of difficulty triplets, respectively. The experimental results reveal that mechanisms in MOEA/D-CDP may be more effective in solving convergence-hard DAS-CMOPs, while mechanisms of NSGA-II-CDP may be more effective in solving DAS-CMOPs with simultaneous diversity-, feasibility-, and convergence-hardness. Mechanisms in C-NSGA-III may be more effective in solving feasibility-hard CMaOPs, while mechanisms of C-MOEA/DD may be more effective in solving CMaOPs with convergence-hardness. In addition, none of them can solve these problems efficiently, which stimulates us to continue to develop new CMOEAs and CMaOEAs to solve the suggested DAS-CMOPs and DAS-CMaOPs.},
  archive      = {J_ECJ},
  author       = {Fan, Zhun and Li, Wenji and Cai, Xinye and Li, Hui and Wei, Caimin and Zhang, Qingfu and Deb, Kalyanmoy and Goodman, Erik},
  doi          = {10.1162/evco_a_00259},
  journal      = {Evolutionary Computation},
  number       = {3},
  pages        = {339-378},
  shortjournal = {Evol. Comput.},
  title        = {Difficulty adjustable and scalable constrained multiobjective test problem toolkit},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Learning and searching pseudo-boolean surrogate functions
from small samples. <em>ECJ</em>, <em>28</em>(2), 317–338. (<a
href="https://doi.org/10.1162/evco_a_00257">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When searching for input configurations that optimise the output of a system, it can be useful to build a statistical model of the system being optimised. This is done in approaches such as surrogate model-based optimisation, estimation of distribution algorithms, and linkage learning algorithms. This article presents a method for modelling pseudo-Boolean fitness functions using Walsh bases and an algorithm designed to discover the non-zero coefficients while attempting to minimise the number of fitness function evaluations required. The resulting models reveal linkage structure that can be used to guide a search of the model efficiently. It presents experimental results solving benchmark problems in fewer fitness function evaluations than those reported in the literature for other search methods such as EDAs and linkage learners.},
  archive      = {J_ECJ},
  author       = {Swingler, Kevin},
  doi          = {10.1162/evco_a_00257},
  journal      = {Evolutionary Computation},
  number       = {2},
  pages        = {317-338},
  shortjournal = {Evol. Comput.},
  title        = {Learning and searching pseudo-boolean surrogate functions from small samples},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A predictive-reactive approach with genetic programming and
cooperative coevolution for the uncertain capacitated arc routing
problem. <em>ECJ</em>, <em>28</em>(2), 289–316. (<a
href="https://doi.org/10.1162/evco_a_00256">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The uncertain capacitated arc routing problem is of great significance for its wide applications in the real world. In the uncertain capacitated arc routing problem, variables such as task demands and travel costs are realised in real time. This may cause the predefined solution to become ineffective and/or infeasible. There are two main challenges in solving this problem. One is to obtain a high-quality and robust baseline task sequence , and the other is to design an effective recourse policy to adjust the baseline task sequence when it becomes infeasible and/or ineffective during the execution. Existing studies typically only tackle one challenge (the other being addressed using a naive strategy). No existing work optimises the baseline task sequence and recourse policy simultaneously. To fill this gap, we propose a novel proactive-reactive approach, which represents a solution as a baseline task sequence and a recourse policy. The two components are optimised under a cooperative coevolution framework, in which the baseline task sequence is evolved by an estimation of distribution algorithm, and the recourse policy is evolved by genetic programming. The experimental results show that the proposed algorithm, called Solution-Policy Coevolver, significantly outperforms the state-of-the-art algorithms to the uncertain capacitated arc routing problem for the ugdb and uval benchmark instances. Through further analysis, we discovered that route failure is not always detrimental. Instead, in certain cases (e.g., when the vehicle is on the way back to the depot) allowing route failure can lead to better solutions.},
  archive      = {J_ECJ},
  author       = {Liu, Yuxin and Mei, Yi and Zhang, Mengjie and Zhang, Zili},
  doi          = {10.1162/evco_a_00256},
  journal      = {Evolutionary Computation},
  number       = {2},
  pages        = {289-316},
  shortjournal = {Evol. Comput.},
  title        = {A predictive-reactive approach with genetic programming and cooperative coevolution for the uncertain capacitated arc routing problem},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new generalized partition crossover for the traveling
salesman problem: Tunneling between local optima. <em>ECJ</em>,
<em>28</em>(2), 255–288. (<a
href="https://doi.org/10.1162/evco_a_00254">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generalized Partition Crossover (GPX) is a deterministic recombination operator developed for the Traveling Salesman Problem. Partition crossover operators return the best of 2 k reachable offspring, where k is the number of recombining components. This article introduces a new GPX2 operator, which finds more recombining components than GPX or Iterative Partial Transcription (IPT). We also show that GPX2 has O( ⁠ n ⁠ ) runtime complexity, while also introducing new enhancements to reduce the execution time of GPX2. Finally, we experimentally demonstrate the efficiency of GPX2 when it is used to improve solutions found by the multitrial Lin-Kernighan-Helsgaum (LKH) algorithm. Significant improvements in performance are documented on large ( ⁠ n &gt; 5000 ⁠ ) and very large ( ⁠ n = 100 , 000 ⁠ ) instances of the Traveling Salesman Problem.},
  archive      = {J_ECJ},
  author       = {Tinós, Renato and Whitley, Darrell and Ochoa, Gabriela},
  doi          = {10.1162/evco_a_00254},
  journal      = {Evolutionary Computation},
  number       = {2},
  pages        = {255-288},
  shortjournal = {Evol. Comput.},
  title        = {A new generalized partition crossover for the traveling salesman problem: Tunneling between local optima},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). What weights work for you? Adapting weights for any pareto
front shape in decomposition-based evolutionary multiobjective
optimisation. <em>ECJ</em>, <em>28</em>(2), 227–253. (<a
href="https://doi.org/10.1162/evco_a_00269">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quality of solution sets generated by decomposition-based evolutionary multi-objective optimisation (EMO) algorithms depends heavily on the consistency between a given problem&#39;s Pareto front shape and the specified weights&#39; distribution. A set of weights distributed uniformly in a simplex often leads to a set of well-distributed solutions on a Pareto front with a simplex-like shape, but may fail on other Pareto front shapes. It is an open problem on how to specify a set of appropriate weights without the information of the problem&#39;s Pareto front beforehand. In this article, we propose an approach to adapt weights during the evolutionary process (called AdaW). AdaW progressively seeks a suitable distribution of weights for the given problem by elaborating several key parts in weight adaptation—weight generation, weight addition, weight deletion, and weight update frequency. Experimental results have shown the effectiveness of the proposed approach. AdaW works well for Pareto fronts with very different shapes: 1) the simplex-like, 2) the inverted simplex-like, 3) the highly nonlinear, 4) the disconnect, 5) the degenerate, 6) the scaled, and 7) the high-dimensional.},
  archive      = {J_ECJ},
  author       = {Li, Miqing and Yao, Xin},
  doi          = {10.1162/evco_a_00269},
  journal      = {Evolutionary Computation},
  number       = {2},
  pages        = {227-253},
  shortjournal = {Evol. Comput.},
  title        = {What weights work for you? adapting weights for any pareto front shape in decomposition-based evolutionary multiobjective optimisation},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Automatically designing state-of-the-art multi- and
many-objective evolutionary algorithms. <em>ECJ</em>, <em>28</em>(2),
195–226. (<a href="https://doi.org/10.1162/evco_a_00263">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A recent comparison of well-established multiobjective evolutionary algorithms (MOEAs) has helped better identify the current state-of-the-art by considering (i) parameter tuning through automatic configuration, (ii) a wide range of different setups, and (iii) various performance metrics. Here, we automatically devise MOEAs with verified state-of-the-art performance for multi- and many-objective continuous optimization. Our work is based on two main considerations. The first is that high-performing algorithms can be obtained from a configurable algorithmic framework in an automated way. The second is that multiple performance metrics may be required to guide this automatic design process. In the first part of this work, we extend our previously proposed algorithmic framework, increasing the number of MOEAs, underlying evolutionary algorithms, and search paradigms that it comprises. These components can be combined following a general MOEA template, and an automatic configuration method is used to instantiate high-performing MOEA designs that optimize a given performance metric and present state-of-the-art performance. In the second part, we propose a multiobjective formulation for the automatic MOEA design, which proves critical for the context of many-objective optimization due to the disagreement of established performance metrics. Our proposed formulation leads to an automatically designed MOEA that presents state-of-the-art performance according to a set of metrics, rather than a single one.},
  archive      = {J_ECJ},
  author       = {Bezerra, Leonardo C. T. and López-Ibáñez, Manuel and Stützle, Thomas},
  doi          = {10.1162/evco_a_00263},
  journal      = {Evolutionary Computation},
  number       = {2},
  pages        = {195-226},
  shortjournal = {Evol. Comput.},
  title        = {Automatically designing state-of-the-art multi- and many-objective evolutionary algorithms},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multioracle coevolutionary learning of requirements
specifications from examples in on-the-fly markets. <em>ECJ</em>,
<em>28</em>(2), 165–193. (<a
href="https://doi.org/10.1162/evco_a_00266">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In software engineering, the imprecise requirements of a user are transformed to a formal requirements specification during the requirements elicitation process. This process is usually guided by requirements engineers interviewing the user. We want to partially automate this first step of the software engineering process in order to enable users to specify a desired software system on their own. With our approach, users are only asked to provide exemplary behavioral descriptions. The problem of synthesizing a requirements specification from examples can partially be reduced to the problem of grammatical inference, to which we apply an active coevolutionary learning approach. However, this approach would usually require many feedback queries to be sent to the user. In this work, we extend and generalize our active learning approach to receive knowledge from multiple oracles, also known as proactive learning. The ``user oracle&#39;&#39; represents input received from the user and the “knowledge oracle” represents available, formalized domain knowledge. We call our two-oracle approach the “first apply knowledge then query” (FAKT/Q) algorithm. We compare FAKT/Q to the active learning approach and provide an extensive benchmark evaluation. As result we find that the number of required user queries is reduced and the inference process is sped up significantly. Finally, with so-called On-The-Fly Markets, we present a motivation and an application of our approach where such knowledge is available.},
  archive      = {J_ECJ},
  author       = {Wever, Marcel and van Rooijen, Lorijn and Hamann, Heiko},
  doi          = {10.1162/evco_a_00266},
  journal      = {Evolutionary Computation},
  number       = {2},
  pages        = {165-193},
  shortjournal = {Evol. Comput.},
  title        = {Multioracle coevolutionary learning of requirements specifications from examples in on-the-fly markets},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evolution of deep convolutional neural networks using
cartesian genetic programming. <em>ECJ</em>, <em>28</em>(1), 141–163.
(<a href="https://doi.org/10.1162/evco_a_00253">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The convolutional neural network (CNN), one of the deep learning models, has demonstrated outstanding performance in a variety of computer vision tasks. However, as the network architectures become deeper and more complex, designing CNN architectures requires more expert knowledge and trial and error. In this article, we attempt to automatically construct high-performing CNN architectures for a given task. Our method uses Cartesian genetic programming (CGP) to encode the CNN architectures, adopting highly functional modules such as a convolutional block and tensor concatenation, as the node functions in CGP. The CNN structure and connectivity, represented by the CGP, are optimized to maximize accuracy using the evolutionary algorithm. We also introduce simple techniques to accelerate the architecture search: rich initialization and early network training termination. We evaluated our method on the CIFAR-10 and CIFAR-100 datasets, achieving competitive performance with state-of-the-art models. Remarkably, our method can find competitive architectures with a reasonable computational cost compared to other automatic design methods that require considerably more computational time and machine resources.},
  archive      = {J_ECJ},
  author       = {Suganuma, Masanori and Kobayashi, Masayuki and Shirakawa, Shinichi and Nagao, Tomoharu},
  doi          = {10.1162/evco_a_00253},
  journal      = {Evolutionary Computation},
  number       = {1},
  pages        = {141-163},
  shortjournal = {Evol. Comput.},
  title        = {Evolution of deep convolutional neural networks using cartesian genetic programming},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Guiding neuroevolution with structural objectives.
<em>ECJ</em>, <em>28</em>(1), 115–140. (<a
href="https://doi.org/10.1162/evco_a_00250">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The structure and performance of neural networks are intimately connected, and by use of evolutionary algorithms, neural network structures optimally adapted to a given task can be explored. Guiding such neuroevolution with additional objectives related to network structure has been shown to improve performance in some cases, especially when modular neural networks are beneficial. However, apart from objectives aiming to make networks more modular, such structural objectives have not been widely explored. We propose two new structural objectives and test their ability to guide evolving neural networks on two problems which can benefit from decomposition into subtasks. The first structural objective guides evolution to align neural networks with a user-recommended decomposition pattern. Intuitively, this should be a powerful guiding target for problems where human users can easily identify a structure. The second structural objective guides evolution towards a population with a high diversity in decomposition patterns. This results in exploration of many different ways to decompose a problem, allowing evolution to find good decompositions faster. Tests on our target problems reveal that both methods perform well on a problem with a very clear and decomposable structure. However, on a problem where the optimal decomposition is less obvious, the structural diversity objective is found to outcompete other structural objectives—and this technique can even increase performance on problems without any decomposable structure at all.},
  archive      = {J_ECJ},
  author       = {Ellefsen, Kai Olav and Huizinga, Joost and Torresen, Jim},
  doi          = {10.1162/evco_a_00250},
  journal      = {Evolutionary Computation},
  number       = {1},
  pages        = {115-140},
  shortjournal = {Evol. Comput.},
  title        = {Guiding neuroevolution with structural objectives},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A tandem evolutionary algorithm for identifying causal rules
from complex data. <em>ECJ</em>, <em>28</em>(1), 87–114. (<a
href="https://doi.org/10.1162/evco_a_00252">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new evolutionary approach for discovering causal rules in complex classification problems from batch data. Key aspects include (a) the use of a hypergeometric probability mass function as a principled statistic for assessing fitness that quantifies the probability that the observed association between a given clause and target class is due to chance, taking into account the size of the dataset, the amount of missing data, and the distribution of outcome categories, (b) tandem age-layered evolutionary algorithms for evolving parsimonious archives of conjunctive clauses, and disjunctions of these conjunctions, each of which have probabilistically significant associations with outcome classes, and (c) separate archive bins for clauses of different orders, with dynamically adjusted order-specific thresholds. The method is validated on majority-on and multiplexer benchmark problems exhibiting various combinations of heterogeneity, epistasis, overlap, noise in class associations, missing data, extraneous features, and imbalanced classes. We also validate on a more realistic synthetic genome dataset with heterogeneity, epistasis, extraneous features, and noise. In all synthetic epistatic benchmarks, we consistently recover the true causal rule sets used to generate the data. Finally, we discuss an application to a complex real-world survey dataset designed to inform possible ecohealth interventions for Chagas disease.},
  archive      = {J_ECJ},
  author       = {Hanley, John P. and Rizzo, Donna M. and Buzas, Jeffrey S. and Eppstein, Margaret J.},
  doi          = {10.1162/evco_a_00252},
  journal      = {Evolutionary Computation},
  number       = {1},
  pages        = {87-114},
  shortjournal = {Evol. Comput.},
  title        = {A tandem evolutionary algorithm for identifying causal rules from complex data},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A revisit of infinite population models for evolutionary
algorithms on continuous optimization problems. <em>ECJ</em>,
<em>28</em>(1), 55–85. (<a
href="https://doi.org/10.1162/evco_a_00249">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infinite population models are important tools for studying population dynamics of evolutionary algorithms. They describe how the distributions of populations change between consecutive generations. In general, infinite population models are derived from Markov chains by exploiting symmetries between individuals in the population and analyzing the limit as the population size goes to infinity. In this article, we study the theoretical foundations of infinite population models of evolutionary algorithms on continuous optimization problems. First, we show that the convergence proofs in a widely cited study were in fact problematic and incomplete. We further show that the modeling assumption of exchangeability of individuals cannot yield the transition equation. Then, in order to analyze infinite population models, we build an analytical framework based on convergence in distribution of random elements which take values in the metric space of infinite sequences. The framework is concise and mathematically rigorous. It also provides an infrastructure for studying the convergence of the stacking of operators and of iterating the algorithm which previous studies failed to address. Finally, we use the framework to prove the convergence of infinite population models for the mutation operator and the k -ary recombination operator. We show that these operators can provide accurate predictions for real population dynamics as the population size goes to infinity, provided that the initial population is identically and independently distributed.},
  archive      = {J_ECJ},
  author       = {Song, Bo and Li, Victor O.K.},
  doi          = {10.1162/evco_a_00249},
  journal      = {Evolutionary Computation},
  number       = {1},
  pages        = {55-85},
  shortjournal = {Evol. Comput.},
  title        = {A revisit of infinite population models for evolutionary algorithms on continuous optimization problems},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Global convergence of the (1 + 1) evolution strategy to a
critical point. <em>ECJ</em>, <em>28</em>(1), 27–53. (<a
href="https://doi.org/10.1162/evco_a_00248">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We establish global convergence of the (1 + 1) evolution strategy, that is, convergence to a critical point independent of the initial state. More precisely, we show the existence of a critical limit point, using a suitable extension of the notion of a critical point to measurable functions. At its core, the analysis is based on a novel progress guarantee for elitist, rank-based evolutionary algorithms. By applying it to the (1 + 1) evolution strategy we are able to provide an accurate characterization of whether global convergence is guaranteed with full probability, or whether premature convergence is possible. We illustrate our results on a number of example applications ranging from smooth (non-convex) cases over different types of saddle points and ridge functions to discontinuous and extremely rugged problems.},
  archive      = {J_ECJ},
  author       = {Glasmachers, Tobias},
  doi          = {10.1162/evco_a_00248},
  journal      = {Evolutionary Computation},
  number       = {1},
  pages        = {27-53},
  shortjournal = {Evol. Comput.},
  title        = {Global convergence of the (1 + 1) evolution strategy to a critical point},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A meta-objective approach for many-objective evolutionary
optimization. <em>ECJ</em>, <em>28</em>(1), 1–25. (<a
href="https://doi.org/10.1162/evco_a_00243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pareto-based multi-objective evolutionary algorithms experience grand challenges in solving many-objective optimization problems due to their inability to maintain both convergence and diversity in a high-dimensional objective space. Exiting approaches usually modify the selection criteria to overcome this issue. Different from them, we propose a novel meta-objective (MeO) approach that transforms the many-objective optimization problems in which the new optimization problems become easier to solve by the Pareto-based algorithms. MeO converts a given many-objective optimization problem into a new one, which has the same Pareto optimal solutions and the number of objectives with the original one. Each meta-objective in the new problem consists of two components which measure the convergence and diversity performances of a solution, respectively. Since MeO only converts the problem formulation, it can be readily incorporated within any multi-objective evolutionary algorithms, including those non-Pareto-based ones. Particularly, it can boost the Pareto-based algorithms&#39; ability to solve many-objective optimization problems. Due to separately evaluating the convergence and diversity performances of a solution, the traditional density-based selection criteria, for example, crowding distance, will no longer mistake a solution with poor convergence performance for a solution with low density value. By penalizing a solution in term of its convergence performance in the meta-objective space, the Pareto dominance becomes much more effective for a many-objective optimization problem. Comparative study validates the competitive performance of the proposed meta-objective approach in solving many-objective optimization problems.},
  archive      = {J_ECJ},
  author       = {Gong, Dunwei and Liu, Yiping and Yen, Gary G.},
  doi          = {10.1162/evco_a_00243},
  journal      = {Evolutionary Computation},
  number       = {1},
  pages        = {1-25},
  shortjournal = {Evol. Comput.},
  title        = {A meta-objective approach for many-objective evolutionary optimization},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
