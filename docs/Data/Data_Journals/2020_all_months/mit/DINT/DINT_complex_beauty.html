<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>DINT_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="dint---40">DINT - 40</h2>
<ul>
<li><details>
<summary>
(2020). The open data challenge: An analysis of 124,000 data
availability statements and an ironic lesson about data management
plans. <em>DINT</em>, <em>2</em>(4), 554–568. (<a
href="https://doi.org/10.1162/dint_a_00061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Data availability statements can provide useful information about how researchers actually share research data. We used unsupervised machine learning to analyze 124,000 data availability statements submitted by research authors to 176 Wiley journals between 2013 and 2019. We categorized the data availability statements, and looked at trends over time. We found expected increases in the number of data availability statements submitted over time, and marked increases that correlate with policy changes made by journals. Our open data challenge becomes to use what we have learned to present researchers with relevant and easy options that help them to share and make an impact with new research data.},
  archive      = {J_DINT},
  author       = {Graf, Chris and Flanagan, Dave and Wylie, Lisa and Silver, Deirdre},
  doi          = {10.1162/dint_a_00061},
  journal      = {Data Intelligence},
  number       = {4},
  pages        = {554-568},
  shortjournal = {Data Intell.},
  title        = {The open data challenge: An analysis of 124,000 data availability statements and an ironic lesson about data management plans},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An RDF data set quality assessment mechanism for
decentralized systems. <em>DINT</em>, <em>2</em>(4), 529–553. (<a
href="https://doi.org/10.1162/dint_a_00059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. With the rapid growth of the linked data on the Web, the quality assessment of the RDF data set becomes particularly important, especially for the quality and accessibility of the linked data. In most cases, RDF data sets are shared online, leading to a high maintenance cost for the quality assessment. This also potentially pollutes Internet data. Recently blockchain technology has shown the potential in many applications. Using the blockchain storage quality assessment results can reduce the centralization of the authority, and the quality assessment results have characteristics such as non-tampering. To this end, we propose an RDF data quality assessment model in a decentralized environment, pointing out a new dimension of RDF data quality. We use the blockchain to record the data quality assessment results and design a detailed update strategy for the quality assessment results. We have implemented a system DCQA to test and verify the feasibility of the quality assessment model. The proposed method can provide users with better cost-effective results when knowledge is independently protected.},
  archive      = {J_DINT},
  author       = {Huang, Li and Liu, Zhenzhen and Xu, Fangfang and Gu, Jinguang},
  doi          = {10.1162/dint_a_00059},
  journal      = {Data Intelligence},
  number       = {4},
  pages        = {529-553},
  shortjournal = {Data Intell.},
  title        = {An RDF data set quality assessment mechanism for decentralized systems},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep learning, feature learning, and clustering analysis for
SEM image classification. <em>DINT</em>, <em>2</em>(4), 513–528. (<a
href="https://doi.org/10.1162/dint_a_00062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we report upon our recent work aimed at improving and adapting machine learning algorithms to automatically classify nanoscience images acquired by the Scanning Electron Microscope (SEM). This is done by coupling supervised and unsupervised learning approaches. We first investigate supervised learning on a ten-category data set of images and compare the performance of the different models in terms of training accuracy. Then, we reduce the dimensionality of the features through autoencoders to perform unsupervised learning on a subset of images in a selected range of scales (from 1 μm to 2 μm). Finally, we compare different clustering methods to uncover intrinsic structures in the images.},
  archive      = {J_DINT},
  author       = {Aversa, Rossella and Coronica, Piero and De Nobili, Cristiano and Cozzini, Stefano},
  doi          = {10.1162/dint_a_00062},
  journal      = {Data Intelligence},
  number       = {4},
  pages        = {513-528},
  shortjournal = {Data Intell.},
  title        = {Deep learning, feature learning, and clustering analysis for SEM image classification},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). KnowID: An architecture for efficient knowledge-driven
information and data access. <em>DINT</em>, <em>2</em>(4), 487–512. (<a
href="https://doi.org/10.1162/dint_a_00060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Modern information systems require the orchestration of ontologies, conceptual data modeling techniques, and efficient data management so as to provide a means for better informed decision-making and to keep up with new requirements in organizational needs. A major question in delivering such systems, is which components to design and put together to make up the required “knowledge to data” pipeline, as each component and process has trade-offs. In this paper, we introduce a new knowledge-to-data architecture, KnowID. It pulls together both recently proposed components and we add novel transformation rules between Enhanced Entity-Relationship (EER) and the Abstract Relational Model to complete the pipeline. KnowID&#39;s main distinctive architectural features, compared to other ontology-based data access approaches, are that runtime use can avail of the closed world assumption commonly used in information systems and of full SQL augmented with path queries.},
  archive      = {J_DINT},
  author       = {Fillottrani, Pablo Rubén and Keet, C. Maria},
  doi          = {10.1162/dint_a_00060},
  journal      = {Data Intelligence},
  number       = {4},
  pages        = {487-512},
  shortjournal = {Data Intell.},
  title        = {KnowID: An architecture for efficient knowledge-driven information and data access},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The semantic data dictionary – an approach for describing
and annotating data. <em>DINT</em>, <em>2</em>(4), 443–486. (<a
href="https://doi.org/10.1162/dint_a_00058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. It is common practice for data providers to include text descriptions for each column when publishing data sets in the form of data dictionaries. While these documents are useful in helping an end-user properly interpret the meaning of a column in a data set, existing data dictionaries typically are not machine-readable and do not follow a common specification standard. We introduce the Semantic Data Dictionary, a specification that formalizes the assignment of a semantic representation of data, enabling standardization and harmonization across diverse data sets. In this paper, we present our Semantic Data Dictionary work in the context of our work with biomedical data; however, the approach can and has been used in a wide range of domains. The rendition of data in this form helps promote improved discovery, interoperability, reuse, traceability, and reproducibility. We present the associated research and describe how the Semantic Data Dictionary can help address existing limitations in the related literature. We discuss our approach, present an example by annotating portions of the publicly available National Health and Nutrition Examination Survey data set, present modeling challenges, and describe the use of this approach in sponsored research, including our work on a large National Institutes of Health (NIH)-funded exposure and health data portal and in the RPI-IBM collaborative Health Empowerment by Analytics, Learning, and Semantics project. We evaluate this work in comparison with traditional data dictionaries, mapping languages, and data integration tools.},
  archive      = {J_DINT},
  author       = {Rashid, Sabbir M. and McCusker, James P. and Pinheiro, Paulo and Bax, Marcello P. and Santos, Henrique O. and Stingone, Jeanette A. and Das, Amar K. and McGuinness, Deborah L.},
  doi          = {10.1162/dint_a_00058},
  journal      = {Data Intelligence},
  number       = {4},
  pages        = {443-486},
  shortjournal = {Data Intell.},
  title        = {The semantic data dictionary – an approach for describing and annotating data},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Refining linked data with games with a purpose.
<em>DINT</em>, <em>2</em>(3), 417–442. (<a
href="https://doi.org/10.1162/dint_a_00056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. With the rise of linked data and knowledge graphs, the need becomes compelling to find suitable solutions to increase the coverage and correctness of data sets, to add missing knowledge and to identify and remove errors. Several approaches – mostly relying on machine learning and natural language processing techniques – have been proposed to address this refinement goal; they usually need a partial gold standard, i.e., some “ground truth” to train automatic models. Gold standards are manually constructed, either by involving domain experts or by adopting crowdsourcing and human computation solutions. In this paper, we present an open source software framework to build Games with a Purpose for linked data refinement, i.e., Web applications to crowdsource partial ground truth, by motivating user participation through fun incentive. We detail the impact of this new resource by explaining the specific data linking “purposes” supported by the framework (creation, ranking and validation of links) and by defining the respective crowdsourcing tasks to achieve those goals. We also introduce our approach for incremental truth inference over the contributions provided by players of Games with a Purpose (also abbreviated as GWAP): we motivate the need for such a method with the specificity of GWAP vs. traditional crowdsourcing; we explain and formalize the proposed process, explain its positive consequences and illustrate the results of an experimental comparison with state-of-the-art approaches. To show this resource&#39;s versatility, we describe a set of diverse applications that we built on top of it; to demonstrate its reusability and extensibility potential, we provide references to detailed documentation, including an entire tutorial which in a few hours guides new adopters to customize and adapt the framework to a new use case.},
  archive      = {J_DINT},
  author       = {Celino, Irene and Re Calegari, Gloria and Fiano, Andrea},
  doi          = {10.1162/dint_a_00056},
  journal      = {Data Intelligence},
  number       = {3},
  pages        = {417-442},
  shortjournal = {Data Intell.},
  title        = {Refining linked data with games with a purpose},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The computer science ontology: A comprehensive
automatically-generated taxonomy of research areas. <em>DINT</em>,
<em>2</em>(3), 379–416. (<a
href="https://doi.org/10.1162/dint_a_00055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Ontologies of research areas are important tools for characterizing, exploring, and analyzing the research landscape. Some fields of research are comprehensively described by large-scale taxonomies, e.g., MeSH in Biology and PhySH in Physics. Conversely, current Computer Science taxonomies are coarse-grained and tend to evolve slowly. For instance, the ACM classification scheme contains only about 2K research topics and the last version dates back to 2012. In this paper, we introduce the Computer Science Ontology (CSO), a large-scale, automatically generated ontology of research areas, which includes about 14K topics and 162K semantic relationships. It was created by applying the Klink-2 algorithm on a very large data set of 16M scientific articles. CSO presents two main advantages over the alternatives: i) it includes a very large number of topics that do not appear in other classifications, and ii) it can be updated automatically by running Klink-2 on recent corpora of publications. CSO powers several tools adopted by the editorial team at Springer Nature and has been used to enable a variety of solutions, such as classifying research publications, detecting research communities, and predicting research trends. To facilitate the uptake of CSO, we have also released the CSO Classifier, a tool for automatically classifying research papers, and the CSO Portal, a Web application that enables users to download, explore, and provide granular feedback on CSO. Users can use the portal to navigate and visualize sections of the ontology, rate topics and relationships, and suggest missing ones. The portal will support the publication of and access to regular new releases of CSO, with the aim of providing a comprehensive resource to the various research communities engaged with scholarly data.},
  archive      = {J_DINT},
  author       = {Salatino, Angelo A. and Thanapalasingam, Thiviyan and Mannocci, Andrea and Birukou, Aliaksandr and Osborne, Francesco and Motta, Enrico},
  doi          = {10.1162/dint_a_00055},
  journal      = {Data Intelligence},
  number       = {3},
  pages        = {379-416},
  shortjournal = {Data Intell.},
  title        = {The computer science ontology: A comprehensive automatically-generated taxonomy of research areas},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). GeoLink data set: A complex alignment benchmark from
real-world ontology. <em>DINT</em>, <em>2</em>(3), 353–378. (<a
href="https://doi.org/10.1162/dint_a_00054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Ontology alignment has been studied for over a decade, and over that time many alignment systems and methods have been developed by researchers in order to find simple 1-to-1 equivalence matches between two ontologies. However, very few alignment systems focus on finding complex correspondences. One reason for this limitation may be that there are no widely accepted alignment benchmarks that contain such complex relationships. In this paper, we propose a real-world data set from the GeoLink project as a potential complex ontology alignment benchmark. The data set consists of two ontologies, the GeoLink Base Ontology (GBO) and the GeoLink Modular Ontology (GMO), as well as a manually created reference alignment that was developed in consultation with domain experts from different institutions. The alignment includes 1:1, 1:n, and m:n equivalence and subsumption correspondences, and is available in both Expressive and Declarative Ontology Alignment Language (EDOAL) and rule syntax. The benchmark has been expanded from its original version to contain real-world instance data from seven geoscience data providers that has been published according to both ontologies. This allows it to be used by extensional alignment systems or those that require training data. This benchmark has been incorporated into the Ontology Alignment Evaluation Initiative (OAEI) complex track to help researchers test their automated alignment systems and algorithms. This paper also analyzes the challenges inherent in effectively generating, detecting, and evaluating complex ontology alignments and provides a road map for future work on this topic.},
  archive      = {J_DINT},
  author       = {Zhou, Lu and Cheatham, Michelle and Krisnadhi, Adila and Hitzler, Pascal},
  doi          = {10.1162/dint_a_00054},
  journal      = {Data Intelligence},
  number       = {3},
  pages        = {353-378},
  shortjournal = {Data Intell.},
  title        = {GeoLink data set: A complex alignment benchmark from real-world ontology},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Constructing and cleaning identity graphs in the LOD cloud.
<em>DINT</em>, <em>2</em>(3), 323–352. (<a
href="https://doi.org/10.1162/dint_a_00057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In the absence of a central naming authority on the Semantic Web, it is common for different data sets to refer to the same thing by different names. Whenever multiple names are used to denote the same thing, owl:sameAs statements are needed in order to link the data and foster reuse. Studies that date back as far as 2009, observed that the owl:sameAs property is sometimes used incorrectly. In our previous work, we presented an identity graph containing over 500 million explicit and 35 billion implied owl:sameAs statements, and presented a scalable approach for automatically calculating an error degree for each identity statement. In this paper, we generate subgraphs of the overall identity graph that correspond to certain error degrees. We show that even though the Semantic Web contains many erroneous owl:sameAs statements, it is still possible to use Semantic Web data while at the same time minimising the adverse effects of misusing owl:sameAs.},
  archive      = {J_DINT},
  author       = {Raad, Joe and Beek, Wouter and van Harmelen, Frank and Wielemaker, Jan and Pernelle, Nathalie and Saïs, Fatiha},
  doi          = {10.1162/dint_a_00057},
  journal      = {Data Intelligence},
  number       = {3},
  pages        = {323-352},
  shortjournal = {Data Intell.},
  title        = {Constructing and cleaning identity graphs in the LOD cloud},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Brief introductory statements. <em>DINT</em>,
<em>2</em>(1-2), iii–vi. (<a
href="https://doi.org/10.1162/dint_e_00022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The remarkable resonance of the FAIR principles throughout the scientific community is largely a function of the meaning that we associate with the word “fair” and of the simplicity of the acronym. The four-letter acronym belies the many mechanisms by which the FAIR principles are to be operationalized, but most scientists are content with thinking about their data merely in terms of whether the data are FAIR or not. The enthusiasm for the FAIR principles indeed depends on keeping the details of those principles hidden from view. It is therefore tremendously exciting to see the emergence of new technologies that support data stewardship in a way that helps to ensure FAIR data while keeping the operationalization of the FAIR principles totally transparent. Just as we can browse the Web without thinking about the complex technology stack that makes Internet connectivity possible, we soon will be able to rely on an ecosystem of tools that assure the FAIRness of our data without having to think beyond the word “fair.” The most important measure of progress in open science will be whether we can continue to improve the FAIRness of our data by means of approaches that remain largely invisible to their users.The early implementations of FAIR principles represented in this special issue, and the cross-cutting analysis of best practices emerging from each pioneering community point the way to effective computational research. Taking this progress forward, publishers will be key to the social adoption of the rapid, machineassisted scholarship enabled by research objects. To do this they need to implement two incentives, firstly to publish and celebrate rich metadata for contributor roles, not only for articles, but for datasets, consortia and protocols. Secondly, they should prominently display immediate transparent metrics of the use, transformation and interoperation of research objects and publications alike. These aims will lead us to unburden research articles of unnecessary formatting restrictions and semi-semantic decoration with data links, and in their place to offer models built of research objects together with enough narrative context to aid their examination, understanding and reuse. Provenance, license and metrics metadata are also the way to allow data producers and users to interact transparently and fairly. To permit immediate data reuse that is compatible with creators&#39; rights and their intentions to build institutional capacity, data generators and their institutions must explicitly declare their reasons and purpose for each research object in provenance metadata. Publication conditions can then follow the principles behind copyright and intellectual property protection even as they are instantiated in an open, machine readable license that encourages reuse.The need for machine-actionability of increasingly complex and multi-domain data, and the accompanying algorithms to optimally use these data, is now recognised by the broader scientific community and throughout most disciplines. With its roots in life sciences data, practices aimed at FAIR data and services are now gaining momentum in the humanities as well. We fully align with the FAIR principles as a university and in fact we have the ambition to become “fully FAIR”. Also within my own field of law and victimology, important developments take place to discuss and implement the FAIR principles, taken into account the often sensitive data that is gathered. With some of the authors of the original FAIR paper in our departments, we feel we are in the forefront of this exciting movement, but it is very encouraging to see how pioneering implementations sprout everywhere. In order to maximise reuse of these early good practices, which is an intrinsic aim of the FAIR principles themselves, it is important to present them in a comprehensive way. While this special issue will only be able to cover a small portion of all early endeavours, it will likely inspire other efforts to bundle and expose useful and hopefully reusable solutions. I am also happy to note that efforts spread to non-European countries and especially those that have traditionally been missing out on optimal benefits from science. As the rector of a university, but also in my role a member of the Steering Committee of GO FAIR, I commend this effort to disseminate FAIR related practices and challenges.I whimsically divide the computer era into three parts: the past, of many computers and many datasets; the present, of one computer and many datasets (recall SUN&#39;s marketing slogan, “the network is the computer”); and the future, of one computer and one dataset. That is, I look forward to the solution of the problem of the interoperability of heterogeneous data, just as the Internet provided a solution for the interoperability of heterogeneous networks. No one doubts the changes (mostly benefits) that the Internet age has provided. I conjecture that the coming age of interoperable data will be as revolutionary as the Internet. And the concept of FAIR data has galvanized many in the R&amp;amp;D world to bring on that new world. In the US, a new definition of Open Science has emerged (see Open Science by Design published by the National Academy of Sciences in 2018) and FAIR Data is called out in that report as a requirement to realize that new vision. Also, AI has taken both the scientific and commercial world by storm. All current approaches to AI involve processing massive amounts of data. FAIR data will make an increasing part of the world&#39;s data “AI ready.” It is important to follow the early implementation attempts of the FAIR principles and make them widely known and accessible for potential reuse. Therefore I commend this special issue of Data Intelligence and anticipate that it will be widely read.Data, the precious inputs and productive outputs of scientific research, is the robust engine for nextgeneration open science. However, to make data count, we should go even further. Besides open data, open science still calls for open access, open resources and open data infrastructures as well. Upon all the trends in Science, FAIR makes all these ideas practicable and achievable. FAIR is not only for data, but also for all kinds of resources sharing. So far, FAIR has been implemented in many cases, such as the research in FAIR data metrics, integration into FAIR data platforms as well as FAIR education and other community outreach. In China, the open data boom is taking place especially after the launch of the national-level rules “Measures for Managing Scientific Data”. Country practices include research data sharing at institutional, disciplinary and national level. Open data has been carried out through the window of not only national data centers within domains but also those of interdisciplinary data infrastructures. Data sharing culture and trustworthiness development as well as data metrics all serve as promoters for better and larger scale of data exchanges across borders. Based on all these practices, we welcome and embrace the FAIR principles. However, adhering to FAIR principles is a good start but not enough for all. We shall continue our country practices in all aspects to push the sharing of data and other resources under the umbrella of open science and for the sake of the broader social community.},
  archive      = {J_DINT},
  doi          = {10.1162/dint_e_00022},
  journal      = {Data Intelligence},
  number       = {1-2},
  pages        = {iii-vi},
  shortjournal = {Data Intell.},
  title        = {Brief introductory statements},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Author biography. <em>DINT</em>, <em>2</em>(1-2), 293–322.
(<a href="https://doi.org/10.1162/dint_x_00052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Barend Mons is Professor of BioSemantics at the Human Genetics Department of Leiden University Medical Center and founder of the BioSemantics group. He was elected CODATA President in 2018. Next to his leading role in the research of the group, Barend plays a leading role in the international development of “data stewardship” for biomedical data. For instance, he was head-of-node of ELIXIR-NL at the Dutch Techcentre for Life Sciences (until 2015), is Integrator Life Sciences at the Netherlands eScience Center, and board member of the Leiden Center of Data Science. In 2014, Barend initiated the FAIR data initiative and in 2015, he was appointed Chair of the European Commission&#39;s High Level Expert Group for the “European Open Science Cloud”, from which he retired by the end of 2016. Presently, Barend is co-leading the GO FAIR initiative, an initiative to kick start dvelopments towards the Internet of FAIR data and services, which will also contribute to the implementation of components of the European Open Science Cloud. The focus of the contribution of the BioSemantics group is on developing an interoperability backbone for biomedical applications in general and rare disease in particular.ORCID: 0000-0003-3934-0072Erik Schultes is International Science Coordinator at the GO FAIR International Support and Coordination Office where he has been working with a diverse community of stakeholders to develop FAIR data and services. Erik is also a member of the Leiden Center for Data Science at Leiden University. Erik is an evolutionary biologist with long standing interests in data-intensive research. In addition to private consulting, he has held previous academic appointments at the University of California, Los Angeles, The Whitehead Institute for Biomedical Research at the Massachusetts Institute of Technology, Duke University, and The Santa Fe Institute.ORCID: 0000-0001-8888-635XFenghong Liu an Associate Professor at the National Science Library, Chinese Academy of Sciences (NSLC) and School of Economics and Management, University of Chinese Academy of Sciences. She received PhD degree at the Institute of Botany, CAS (IBCAS) in 2006. Before joining in NSLC in 2015, she had been the head of the library of IBCAS for four years. She is currently the Managing Editor of Data Intelligence (DI) Journal. Her research interests focus on data journals, especially whether and how data journals foster and promote data sharing awareness and culture across communities.ORCID: 0000-0002-3633-1464Annika Jacobsen is a postdoctoral researcher at the BioSemantics group, Human Genetics Department, Leiden University Medical Center, The Netherlands. She obtained her Bachelor and Master degrees at the Technical University of Denmark in 2009 and 2012, and her PhD degree at the Vrije Universiteit Amsterdam in 2019. Her research interests are to create interoperable FAIR rare disease data with the aim to learn more about cause, diagnosis and treatment.ORCID: 0000-0003-4818-2360Ricardo de Miranda Azevedo is an independent and pragmatic researcher with a background in psychology and clinical epidemiology who is happy to work in multidisciplinary settings. He is a great multilingual communicator who is enthusiastic about scientific research but also for computers and teaching different topics. He is often labeled as a creative mind with a problem-solver attitude.ORCID: 0000-0002-7641-6446Nick Juty is a Senior Research Technical Manager in the eScience Lab, based in the Department of Computer Science at The University of Manchester. He is involved in numerous EU projects relating to aspects of FAIR and interoperability, particularly with respect to identifier systems and metadata. Nick previously worked at EMBL-EBI where he helped create the identifiers.org identifier resolution system. Nick holds a PhD in Biochemistry from the University of Southampton.ORCID: 0000-0002-2036-8350Dominique Batista is a young developer specialized in creating tools and software for scientific researchers and academics. His current activities focus on delivering clean, tested and documented open-source code to help structuring metadata over the Web. Dominique&#39;s side activities focus on producing knowledge and scientific papers as well as representing the team in international conferences. He is passionate about computer (hardware, Web), science (biology and physics), video games and much more.ORCID: 0000-0002-2109-489XSimon J. Coles is Professor of Structural Chemistry at the University of Southampton and Director of the UK National Crystallography Service. He has promoted open approaches to research and education in Chemistry for many years and is now also Director of the UK Physical Sciences Data-science Service.ORCID: 0000-0001-8414-9272Ronald Cornet holds a position as associate professor at the department of Medical Informatics in the Amsterdam Public Health Research Institute, Amsterdam UMC. His research focuses on semantic interoperability, both from a technical perspective and from a user&#39;s point of view, including natural language processing. Ronald is involved in health care information standardization, among others as member of the Dutch, European (CEN) and global (ISO) standardization committees on health informatics. He is also involved in SNOMED International, which is responsible for maintenance and further development of SNOMED CT. He chairs the IMIA working group on Language and Meaning in Biomedicine, and participates in various international projects including FAIR4Health and European Joint Programme Rare Diseases (EJP-RD).ORCID: 0000-0002-1704-5980Mélanie Courtot is a Metadata Standards coordinator at EMBL-EBI, where her team designs tools to streamline multi-omics submissions and develops integrated metadata strategies across the institute&#39;s archival resources and other projects such as FAIRPlus and CINECA, focusing on semantic enrichment and harmonization for pharmaceutical and cohort data, respectively. In the context of GA4GH which she joined in 2016, Mélanie co-leads groups working on data access and encoding as well as clinical and phenotypic standards.ORCID: 0000-0002-9551-6370Mercè Crosas is Harvard University&#39;s Research Data Officer, with Harvard University Information Technology (HUIT), and Chief Data Science and Technology Officer at Harvard&#39;s Institute for Quantitative Social Science (IQSS). In her role at HUIT, Dr. Crosas provides leadership to mature Harvard&#39;s data management and governance practices. She works in close collaboration with key constituencies in Research, Information Technology, and the Library to coordinate support for the data lifecycle and guide university policy, process, and procedures for research data. Dr. Crosas brings to this role a wealth of experience in data management architecture and international community data standards as well as the vision to make data more accessible for research while preserving privacy.ORCID: 0000-0003-1304-1939Michel Dumontier is the Distinguished Professor of Data Science at Maastricht University and co-founder of the FAIR (Findable, Accessible, Interoperable and Reusable) data principles. His research focuses on the development of computational methods for scalable and responsible discovery science. Previously at Stanford University, Dr. Dumontier now leads the interfaculty Institute of Data Science at Maastricht University to develop socio-technological systems for accelerating scientific discovery, improving human health and well-being, and empowering communities with ethical data-driven decision making.ORCID: 0000-0003-4727-9435Carole Goble is Professor of Computer Science at The University of Manchester. Over the past 25 years Carole has pursued research interests in the acceleration of FAIR scientific innovation through: distributed computing, workflows and automation; knowledge management and the Semantic Web; social, virtual environments; software engineering for scientific software; and new models of scholarship for data-intensive science. Carole has served on numerous committees and currently serves in the G7 Open Science Working Group as the UK expert. In 2008 she was awarded the Microsoft Jim Gray e-Science award for contributions to e-Science and in 2010 was elected a Fellow of the Royal Academy of Engineering. In 2014 she was awarded the Commander of the Order of the British Empire for services to Science.ORCID: 0000-0003-1219-2137Giancarlo Guizzardi is currently a professor of computer science and head of the Conceptual and Cognitive Modeling Research Group (CORE) at the Free University of Bozen-Bolzano, Italy. He has a PhD in Computer Science (with the highest distinction) from the University of Twente, The Netherlands. He has been working for more than two decades in the interplay between formal and applied ontology, cognitive science, philosophical logics, linguistics, and computer science (in particular, in the areas of conceptual modeling, enterprise modeling and knowledge representation). He has published circa 270 papers, many of which have received best paper awards in important conferences. He has also played a multitude of roles in key conferences in the field (e.g., general chair, program committee chair, and keynote speaker). Finally, he is an associate editor for the Applied Ontology journal, member of a number of international journal editorial boards, and of the Advisory Board of the International Association for Ontology and its Applications (IAOA).ORCID: 0000-0002-3452-553XAli Hasnain is a Lecturer and Researcher at Insight Centre for Data Analytics, National University of Ireland Galway (NUIG). Before joining DERI, Hasnain completed a master&#39;s degree in “Engineering and Management of Information Systems” from Royal Institute of Technology, KTH, Stockholm, Sweden. He received another master&#39;s degree from the same University in “Project Management and Operational Development”. Career spans over five years of experience in Software industry and more than a decade in academia at various positions. It includes work experience as Lecturer, Senior Researcher, Project Manager and lead scientist. Teaching responsibilities at NUI Galway includes mentoring and co-supervising master&#39;s and PhD students. With strong scientific publishing record the list of selected Scientific Publications in the Field of Computing, Data Analytics, Software Engineering and Data Science positively reviewed and published at world renowned Journals and conferences can be seen at: https://goo.gl/eYNoas (around 650 citations). Ali Hasnain is the Program Committee Member of international conferences and workshops e.g, VOILA-ISWC and KESW. He remained involved in organizing workshops and tutorial at K-Cap 2015 and SWAT4LS 2015–2018 for international audiences. His current research interests include: FAIR DATA, Open Data, Big Data, Semantic Models, Data Cataloging/Linking, Visual Interfaces and Data Integration.ORCID: 0000-0003-4014-4394Kristina Hettne, PhD, is a Digital Scholarship Librarian at the Centre for Digital Scholarship, Leiden University Libraries in Leiden, The Netherlands. At the Centre, she helps researchers navigate Open Science and shape the future of research data management. She is the Centre&#39;s liaison with GO FAIR and part of the FAIR Convergence Matrix development team for optimizing the reuse of existing FAIR-related resources. She obtained her PhD degree in bioinformatics of toxicogenomics from the University of Maastricht in 2012. She is a review editor for “Frontiers in Big Data”, member of the Advisory Board of the Wiley journal Genetics &amp;amp; Genomics Next, and co-author of more than 30 research publications.ORCID: 0000-0002-4182-7560Jaap Heringa is full professor of Bioinformatics and director of the Centre for Integrative Bioinformatics (IBIVU) at Vrije Universiteit of Amsterdam, The Netherlands. Heringa has been scientific co-director of the Netherlands Bioinformatics Centre (NBIC) from 2009–2013. He has served as deputy Head of Node of ELIXIR-NL from 2013–2016, and since April 2016 as its Head of Node. Since 2014 he has been director of the Netherlands Bioinformatics and Systems Biology Research School (BioSB) and as of January 2016 he has been scientific lead of the Dutch Techcentre for Life Sciences (DTL). Heringa has been executive editor of Molecular Data Science since 2018 and became head of the Department of Computer Science at Vrije Universiteit in that same year. His areas of research are Bioinformatics and Systems Biology, while current research interests revolve around formal modeling strategies, new sequence analysis strategies, protein structure and interaction prediction, cancer-related data integration, and semantic Web-based data stewardship and data-tools interoperability.ORCID: 0000-0001-8641-4930Rob Hooft is Manager of the Dutch tasks in the European ELIXIR infrastructurefor life science data, at the Dutch Techcenter for Life Sciences (DTL). After working for many years in the industry, Rob moved back to the academic world and joined the Netherlands center for Bioinformatics, NBIC, as CTO for the service-directed program. Via a two-year excursion to the Netherlands eScience Center from where he ran the data program of DTL he is now working for DTL itself. Rob has been building up a body of knowledge on FAIR research data stewardship since early 2014. Rob also represents ELIXIR relations in the Research Data Alliance.ORCID: 0000-0001-6825-9439Melanie Imming authored reports on FAIR Data and Data Stewardship practices in The Netherlands for SURF and the Dutch National Contact Point for Research Data Management, LCRDM. As a consultant with a strong international network in the area of Open Science, FAIR Data and Digital Cultural Heritage, Melanie is experienced in project management and engaging stakeholders from different domains, and a known advocate for Open Science practices.ORCID: 0000-0003-2376-9755Keith Jeffery is an independent consultant working on EPOS, ENVRIplus and ENVRIFAIR as well as on advanced CLOUD computing and Virtual research Environments. He is past Director IT at STFC with 360,000 users, 1,100 servers and 140 staff. Keith holds three honorary visiting professorships, is a Fellow of the Geological Society and the British Computer Society, a Chartered Engineer &amp;amp; IT Professional and an Honorary Fellow of the Irish Computer Society. Keith is past-President of ERCIM and euroCRIS, and serves on international expert groups, conference boards and assessment panels. He had advised government on IT. He chaired the EC Expert Groups on GRIDs and on CLOUD Computing.ORCID: 0000-0003-4053-7825Rajaram Kaliyaperumal was born in Pondicherry, India. He received a B.Tech degree in Biomedical Engineering from Pondicherry University, India in 2008 and an M.Sc degree in Biomedical Engineering from Linköping University, Sweden in 2011. In 2012 he joined the department of Computer and Information Science, Linköping University as a software engineer. During this time he developed methods and tools to align and repair ontologies. In 2013 he joined the Biosemantics group, Leiden, in the Netherlands as a software developer. His current research activities include investigating the use of semantic Web technology in the context of FAIR data and developing prototypes to demonstrate the use of FAIR data.ORCID: 0000-0002-1215-167XMartijn Kersloot is a PhD candidate at the Department of Medical Informatics in the Amsterdam UMC in collaboration with Electronic Data Capture platform Castor EDC. He has a background in Medical Informatics and his research focuses on the creation of a scalable solution that will aid in the standardization of medical research data.ORCID: 0000-0003-3357-3027Tobias Kuhn is an assistant professor at the Computer Science department of the VU University Amsterdam. After receiving his PhD at the Institute of Computational Linguistics of the University of Zurich in 2010, he worked at the University of Malta, Yale University, and ETH Zurich. His research interests span fields including knowledge representation, controlled natural language, socio-technical systems, and scholarly communication. His recent work focuses on the approach of nanopublications, how cryptographic methods and provenance modelling can support trust and reliability, and how this can support the initiatives around the FAIR principles for data management.ORCID: 0000-0002-1267-0234Ignasi Labastida is currently the work at the Head of the Research Unit at the University of Barcelona&#39;s Learning and Research Resources Centre (CRAI) where he also leads the Office for the Dissemination of Knowledge. He is currently chairing the Board of SPARC Europe and he is a member of the Steering Committee of the Info and Open Access Policy Group at the League of European Research Universities (LERU). He is the co-author of the LERU Roadmap for Research Data and the LERU Roadmap on Open Science. He has participated in several research projects including LEARN, a EU H2020 project focused on helping research performing institutions in managing their research data.ORCID: 0000-0001-7030-7030Barbara Magagna holding a master degree in landscape planning and in geoinformatics, has 24 years of experience working in the field of GIS, landscape ecology modelling and database management for projects operating at different scales. Her interests and formation moved in the last years also towards ontology engineering and process facilitation, abilities she could already apply in several national and European semantic projects. She had been working for the University of Natural Resources and Applied Life Sciences, the University of Vienna and since December 2007 for the Federal Environment Agency (Umweltbundesamt GmbH) where she undertakes the function of a semantic analyst and database designer. She was involved in FP7 and H2020 projects as facilitator in the development process of terminologies like SERONTO and EnvThes. She has experience as work package lead related to data management, in the design of UML models and XML schemas in the air quality data reporting area, in the design of semantic models in projects related to Environmental Research Infrastructures (ENVRI).ORCID: 0000-0003-2195-3997Peter McQuilton holds a 1st class BSc (Hons) degree in Genetics from the University of Leeds (2000) and a PhD (2004) in Drosophila neurodevelopment from the University of Cambridge. Peter has spent over 15 years working in the fields of bioinformatics, biocuration and data wrangling, first as a genetic literature curator at FlyBase, the premier database on drosophila genes and genomes, and then as part of the Data Readiness Group at the Oxford e-Research Centre. As part of the Data Readiness Group, Peter leads the FAIRsharing project. FAIRsharing is a manually curated, searchable portal of interlinked standards, databases and policies, from all domains.ORCID: 0000-0003-2687-1982Natalie Meyers is an E-Research librarian at University of Notre Dame&#39;s Navari Family Center for Digital Scholarship where she helps pioneer and provide research data consulting services, including more in-depth data management services in support of grant-funded research. She serves as an ambassador and advisor to groups and individuals regarding data and digital content management. She provides advice &amp;amp; works with units across campus and externally to provide collaborative, team-based support for reproducible research, data management and software preservation needs, as well as data and metadata services for the Navari Center for Digital Scholarship.ORCID: 0000-0001-6441-6716Annalisa Montesanti is the Program Manager at the Health Research Board (HRB). She is responsible for developing and managing a portfolio for health research careers in order to develop a coordinated approach to building capacity in health research in Ireland. She has developed a framework promoting the training, support and career development of academic researchers and health practitioners with the long-term goal of training individuals as collaborative researcher in order to generate ideas and undertake research, drive the integration of research and evidence into policy and practice, thus improving decision-making and, ultimately, health outcomes and creating a wider impact in society. Annalisa is also deeply involved in promoting open science, FAIR data and research data stewardship through several international collaborations. Annalisa had many years of experience in scientific research in in Italy, England and Ireland. She has a BSc from Palermo University in Italy and a PhD in cancer biology from the Institute of Molecular Medicine in Oxford, UK.ORCID: 0000-0003-0413-2003Mirjam van Reisen is Professor International Relations, Innovation and Care at Tilburg University and Professor Computing for Society at Leiden Centre for Data Science, at the University of Leiden. Van Reisen is Research Leader of the Globalization, Accessibility, Innovation and Care (GAIC) network. Van Reisen is the Coordinator of the Go-FAIR Implementation Network Africa. Van Reisen is a member of the Dutch Advisory Council on International Affairs (AIV) and Chair of the Development Assistance Committee (COS). Van Reisen leads the oganisation EEPA in Brussels. She is a member of the Board of Philips Foundation and the SNV Netherlands Development Organisation. Van Reisen received the Golden Image Award in 2012 by President Ellen Johnson Sirleaf.ORCID: 0000-0003-0627-8014Philippe Rocca-Serra, after an engineering degree from University of Rennes, received his PhD in Molecular Genetics from University of Bordeaux. He worked at EMBL-EBI in helping establish the European microarray archive. He has 10 years of practice in data management and has been an active member of several standardization efforts, aiming at promoting open data and open science vision. He is technical coordinator of the ISA project, part of the OBO Foundry editorial board and participates in resource development as part of the OBI project.ORCID: 0000-0001-9853-5668Robert Pergl is an Associate Professor at Department of Software Engineering, Faculty of Information Technologies of Czech Technical University in Prague, Czech Republic, where he founded “Centre for Conceptual Modelling and Implementation”, a group focusing on research, development and applications of methods and tools for ontological engineering, enterprise engineering, software engineering and data stewardship. Robert Pergl is a National Node Committee member of ELIXIR Czech Republic. He is a member of several GO FAIR initiatives and projects and together with Rob Hooft he leads the Data Stewardship Wizard development. Contribution: Leading the authors&#39; team and authoring process, communications author, copy-editing and quality assurance, Data Stewardship Wizard details.ORCID: 0000-0003-2980-4400Susanna-Assunta Sansone is an Associate Director, Associate Professor and Principal Investigator at the Oxford e-Research Centre, part of the Department of Engineering Science at the University of Oxford. She is one of the authors of the FAIR principles and an active contributor to a variety of community-driven FAIR-enabling efforts. Her group researches and develops methods and tools to improve data reuse, for data transparency, research integrity and the evolution of scholarly publishing: https://sansonegroup.eng.ox.ac.uk.ORCID: 0000-0001-5306-5690Luiz Olavo Bonino da Silva Santos is the International Technology Coordinator of the GO FAIR International Support and Coordination Office, and Associate Professor of the BioSemantics group at the Leiden University Medical Centre in Leiden, The Netherlands. His background is in ontology-driven conceptual modelling, semantic interoperability, service-oriented computing, requirements engineering and context-aware computing. In the last five years Luiz has been involved in a number of activities to realize the FAIR principles, including the development of a number of technologies and tools to support making, publishing, indexing, searching and annotating FAIR (meta)data.ORCID: 0000-0002-1164-1351 In a 20-year career specializing in metadata, ontologies and discovery, Juliane Schneider has worked in start-ups, on Wall Street in an insurance library, at New York University medical center, for EBSCO publishing, and at The University California, San Diego in the Research Data Curation Program. Her longest stint at any job was the six years she spent at Countway Library as the Metadata Librarian, and now she has returned to Harvard as the Team Lead/Lead Data Curator for Harvard Catalyst.ORCID: 0000-0002-7664-3331George O. Strawn is currently the director of the Board on Research Data and Information at the National Academies of Sciences, Engineering, and Medicine where he focuses on Open Science and FAIR data. Prior to joining the Academies, Dr. Strawn was the director of the National Coordination Office (NCO) for the Networking and Information Technology Research and Development (NITRD) Program and co-chair of the NITRD interagency committee.ORCID: 0000-0003-4098-0464Mark Thompson is a senior research scientist in the Biosemantics group at the Human Genetics department of Leiden University Medical Centre. He obtained a PhD in Computer Science from the University of Amsterdam in 2012. He has expertise in hardware and software architecture (co-) design, data management, data modeling, FAIR data infrastructure and computational aspects of knowledge discovery.ORCID: 0000-0002-7633-1442Tobias Weigel is working at the German Climate Computing Center (DKRZ) in the area of e-infrastructures. Tobias has worked extensively on Digital Object and Persistent Identifier services in multiple contexts, including community cyberinfrastructures (ESGF, ENVRI) and cross-disciplinary infrastructures (EUDAT, EOSC). He has co-chaired multiple working groups of the Research Data Alliance (RDA) to convene on technical recommendations in the area of identifiers, metadata and related e-infrastructures services. Tobias is editorial board member of the CODATA Data Science Journal and member of the RDA Technical Advisory Board. Tobias holds a PhD from University of Hamburg in computer science.ORCID: 0000-0002-4040-0215Mark D. Wilkinson is Fundacion BBVA Chair in Biotechnology and Isaac Peral Distinguished Researcher at the Center for Plant Biotechnology and Genomics, Technical University of Madrid. For the past 15 years, his laboratory has focused on designing biomedical data/tool representation, discovery, and automated reuse infrastructures – what would now be called “FAIR”. He is lead author of the primary FAIR Data Principles paper, and lead author on the first paper describing a reference implementation of those principles over legacy data. He is a founding member of the FAIR Metrics Authorship Group, tasked with defining the precise, measurable behaviors that FAIR resources should exhibit. Beyond FAIR, his laboratory also studies the application of Artificial Intelligence techniques to the problem of microbiome engineering.ORCID: 0000-0001-6960-357XEgon L. Willighagen is applying cheminformatics and chemometrics to biological questions as Assistant Professor at Maastricht University. He has been promoting Open Science for many years and is Editor-in-Chief of the Journal of Cheminformatics.ORCID: 0000-0001-7542-0286Peter Wittenburg was Executive Director of Research Data Alliance (RDA) Europe, Member of RDA Technical Advisory Board, and Scientific Coordinator of European Data Infrastructure (EUDAT). He set up and led the Technical Group with about 30 experts at Max Planck Institute (MPI) for Psycholinguistics and then led the Language Archiving Group with about 25 experts. Since 2000 he has played leading roles in a variety of European (funded by the European Commission) and national projects (funded by MPS, DFG, BMBF, NWO 23) and ISO initiatives (ISO TC37/SC4). He won the Heinz Billing Award of the MPS for the advancement of scientific computation in 2011 and received an honorary doctorate from University Tübingen in 2013.ORCID: 0000-0003-3538-0106Marco Roos is assistant professor and group leader of the Biosemantics group of the Leiden University Medical Centre (Human Genetics Department). The group is known for co-founding and advocating the FAIR data principles. His research focus is on making state-of-the-art computer science applicable to enhance biomedical research (e-Science), particularly the application of computational knowledge discovery and linked data techniques to address translational research challenges of rare human diseases. At an international level, Marco is focused on the implementation of FAIR principles to create a powerful substrate and worldwide robust infrastructure for knowledge discovery across distributed rare disease data resources.ORCID: 0000-0002-8691-772XSarala Wimalaratne spent the last 10 years at the European Bioinformatics Institute (EMBL-EBI) working with multiple data integration and infrastructure projects. During her time at the EMBL-EBI, she led the Identifiers.org resource, which provides stable identifier resolution for life science data and beyond. She was also involved in the Data Commons Pilot Phase Consortium on globally unique identifiers (GUIDs), the Elixir Interoperability Platform on BioSchemas and Identifiers, the FORCE11 Data Citation Implementation Pilot on Identifiers and the EU FREYA Project on identifier services. From September 2019, she will be joining DataCite as Head of Infrastructure Services.ORCID: 0000-0002-5355-2576Stian Soiland-Reyes is a Technical Architect in the eScience Lab, based in the Department of Computer Science at The University of Manchester. Since 2006 he has worked as a software engineer and researcher focusing on reproducibility, scientific workflows, interoperability, linked data, metadata and open science. He is a persistent advocate of Open Scholarly Communication, and is on the leadership team of the Common Workflow Language and on the Project Management Committee of several open source projects at the Apache Software Foundation. He co-created the Research Object model, contributed to the W3C provenance model PROV-O and multiple Linked Data initiatives. He is co-chair of the Research Object Crate team.ORCID: 0000-0001-9842-9718John Kunze is an Identifier Systems Architect at the California Digital Library. With a background in computer science and mathematics, he wrote BSD Unix software that comes pre-installed with Mac and Linux systems. He created the ARK identifier scheme, the N2T.net scheme-agnostic resolver, and contributed heavily to Internet standards for URLs (RFC1736, RFC1625, RFC2056), archiving (BagIt – RFC8493), Web archiving (WARC), and Dublin Core metadata (RFC2413, RFC2731).ORCID: 0000-0001-7604-8041Tim Clark is Associate Professor of Public Health Sciences, Associate Professor of Neurology (by courtesy), and Associate Research Director for Neuroinformatics in the Data Science Institute, at the University of Virginia. He holds a PhD in Computer Science from The University of Manchester. His research interests include biomedical knowledge representation, computational models of evidence, cloud computing, and neuroscience.ORCID: 0000-0003-4060-7360Ulrich Schwardmann is deputy leader of the eScience working group of the GWDG, a joint compute and IT competence center of the university and the Max Planck Society, and leads there the data management activities of GWDG. He has a doctoral degree in mathematics and has a long lasting background in scientific computing. Ulrich Schwardmann is working with persistent identifiers as enabling technology for research data management since almost ten years. He is speaker of the management board of ePIC, the Persistent Identifier Consortium for eResearch, and is DONA-MPA System Administrator for GWDG. His current research interests include Digital Object Interface Protocol, PID Information Types and Data Type Registration, PID profiles and policies.ORCID: 0000-0001-6337-8674Jens Klump leads the Geoscience Analytics Team in the Mineral Resources Unit of the Commonwealth Scientific and Industrial Research Organization (CSIRO). Jens&#39; work focuses on data in minerals exploration, investigating the digital value chain from data capture to data analysis and decision making. This value chain includes automated data and metadata capture, sensor data integration, both in the field and in the laboratory, data processing workflows, and data analysis by statistical methods, machine learning and numerical modelling. Jens obtained degrees in geology and oceanography from the University of Cape Town, South Africa, and received his PhD in marine geology from the University of Bremen, Germany.ORCID: 0000-0001-5911-6022Sofiane Bendoukha is a computer scientist at the German Climate Computing Center (DKRZ) within the data management group. For years, Sofiane has been working on scientific workflow management systems, service orchestration and workflow modeling. After joining DKRZ, he focused more on the development of software tools for the climate community related to the management of persistent identifiers and Handle servers in the EUDAT project. Currently, Sofiane is a deputy leader in the EOSC-HUB project. He is responsible of designing, implementing and deploying reliable and user-friendly compute services to scientists related to the climate domain. Sofiane holds a PhD in computer science from the University of Hamburg, Germany.ORCID: 0000-0002-8959-2027Rob Quick is the Associate Director of the Science Gateways Research Center with the Pervasive Technology Institute at Indiana University. Rob has been working with interoperability of international cyberinfrastructure for more than 15 years. This includes holding the position of Chief Operations Officer for the Open Science Grid and managing the XSEDE Science Gateways Support Services. In recent years he has turned his focus from interoperability of research computing infrastructure to data interoperability. This includes NSF funding (NSF #1659310 and #1839013) to create and operate the Robust Persistent Identification of Data (RPID) testbed which provides a set of testbed services to allow researcher to implement the FAIR principles within the Digital Object Architecture. Rob holds a degree in Physics from Purdue University.ORCID: 0000-0002-0994-728XAnnalisa Landi, PharmD, II level post-graduate Master in Regulatory Sciences “G. Benzi” at University of Pavia, Researcher at Fondazione per la Ricerca Farmacologica Gianni Benzi Onlus. She is involved in scientific and regulatory activities, in particular related to data protection and confidentiality, plan and management of patient registries and medicine databases management. ENCePP WG3 member.ORCID: 0000-0001-9368-6424Viviana Giannuzzi, PharmD, PhD in pharmacology, post-graduate master in Clinical Research of Medicines, Senior Researcher at Fondazione per la Ricerca Farmacologica Gianni Benzi Onlus and Head of the Research Department. Her main areas of expertise are: ethics and regulatory, non-clinical and clinical research, clinical studies application, pharmacology, orphan medicines and paediatric research. She is patient representative at Paediatric Committee, European Medicine Agency (EMA), and member of WP4 Ethics Working Group of EnprEMA.ORCID: 0000-0002-2534-6783Fedele Bonifazi, Biomedical engineer, II level Master in Health Technology Assessment and Management, President of Fondazione per la Ricerca Farmacologica Gianni Benzi Onlus. Member of the HTA working group of the Regional Agency for Health and Social issues AReSS Puglia; expert of the Health Department of the Basilicata Region. At the Benzi Foundation, he is project manager and WP leader in several research projects and Head of the IT &amp;amp; Research Laboratory.ORCID: 0000-0003-4935-5702Christopher Brewster is a Senior Scientist in the Data Science group at TNO, and Professor of Emerging Technologies at the Institute for Data Science, Maastricht University, The Netherlands. His PhD was in ontology learning from text from the University of Sheffield. His main research interests are the application of semantic technologies and more generally artificial intelligence (AI) to supply chains and the agri-food sector, and the ethical and social implications of the widespread use of data science and AI.ORCID: 0000-0001-6594-9178Barry Nouwt (MSc) is a medior Scientist in semantic technology at TNO within the Data Science department. He obtained a BSc degree in Computer Science from the Saxion University of Applied Sciences and an MSc degree in Artificial Intelligence at Utrecht University in 2008. Until 2015, he worked with SemLab B.V. on commercial applications of natural language processing (NLP) and Semantics, primarily in the Financial and Government domain. At TNO, Barry&#39;s research activities center around ontologies, model-driven development and semantic reasoning with a focus on increasing the value of formalized domain knowledge.ORCID: 0000-0002-9527-6039Stephan Raaijmakers is specialized in machine learning-based natural language processing. He received his PhD on information geometry for kernel machines from Tilburg University in 2009. At TNO, he works on a variety of artificial intelligence-related topics, including explainable deep learning. Recently, he has been appointed as professor in Communicative AI at Leiden University.ORCID: 0000-0003-2984-6889Jack Verhoosel is a Senior Scientist at TNO and is part of the Data Science department within TNO. His group focuses on semantic interoperability, i.e., the efficient and effective use of information technology (IT) for the cooperation and information sharing between organizations. He specializes in semantic technology, artificial intelligence (AI) reasoning and data analytics. Research topics include (1) knowledge modelling in ontologies, (2) semantic Web and reasoning technology for data integration and (3) data analytics technology for big data applications. He applies his knowledge in various industry sectors, among others agriculture, industry, defence and the electronic government domain.ORCID: 0000-0002-0121-636XPaul Groth is Professor of Algorithmic Data Science at the University of Amsterdam where he leads the Intelligent Data Engineering Lab (INDElab). He holds a PhD in Computer Science from the University of Southampton (2007). His research focuses on intelligent systems for dealing with large amounts of diverse contextualized knowledge with a particular focus on Web and science applications.ORCID: 0000-0003-0183-6910Helena Cousijn is DataCite&#39;s Community Engagement and Communications Director. She has committed to DataCite&#39;s mission of enabling data sharing and reuse and is especially passionate about data citation. Before joining DataCite, Helena worked as Senior Product Manager for Research Data Management Solutions at Elsevier. She holds a DPhil in Neuroscience from the University of Oxford.ORCID: 0000-0001-6660-6214Kees Burger is a software engineer associated with the Vrije Universiteit and the Biosemantics group at the Leiden University Medical Center. He has been working with pioneers in data sharing and interoperability standards since 2009, developing expertise in software design and architecture, semantic Web technology, and FAIR data infrastructure. His current activities involve the Personal Health Train (PHT) and broader the Internet of FAIR Data and Services (IFDS).ORCID: 0000-0002-5437-779XOya Beyan is a researcher at Fraunhofer Institute for Applied Information Technology and at the Department of Computer Science at RWTH Aachen University. Her research focuses on methods of data reusability and FAIR data, data-driven transformation and distributed analytics. Her area of expertise is in the semantic Web technologies and application of them in health care and life sciences. She actively contributes to the national and international initiatives to enable the adoption of FAIR principles and develops tools and infrastructures supporting FAIR data. With her interdisciplinary background in informatics, medical informatics and sociology, she developed a focus on societal reflections of data-driven change.ORCID: 0000-0001-7611-3501Ananya Choudhury is a researcher and PhD Student at Clinical Data Science Group, Maastro Clinic, Maastricht University. Her research focuses on methods and infrastructure of privacy preserving distributed learning on clinical data, tools and methods for data FAIR-ification and learning models on FAIR data for improving patient care.ORCID: 0000-0001-9847-8165Johan van Soest holds a PhD from Maastricht University on centralized and distributed learning of prognostic/predictive models in radiation oncology focusing on knowledge representation, methods for validation of existing models and translation into clinical practice. He is currently active as Postdoctoral Researcher in the Department of Radiation Oncology at MAASTRO clinic and the university&#39;s Institute of Data Science.ORCID: 0000-0003-2548-0330Oliver Kohlbacher is a Chair for Applied Bioinformatics at the University of Tübingen, Director of the Institute for Translational Bioinformatics at University Hospital Tübingen, and a Fellow at the Max Planck Institute for Developmental Biology. The lab&#39;s current research focus is on developing methods and tools for the analysis of biomedical high-throughput data and their application in translational research.ORCID: 0000-0003-1739-4598Lukas Zimmermann is a research assistant and software developer at the Institute for Translational Bioinformatics at the University Hospital Tübingen with a background in Bioinformatics. His research interests currently focus on data integration and software design and quality in medical informatics.ORCID: 0000-0002-9596-5432Holger Stenzhorn is working at the Saarland University Medical Center coordinating the development and organizational set-up of a medical data integration center (meDIC) as well as supporting the Tübingen University Hospital in its meDIC work. His particular interest lies on the seamless integration of the multimodal, multilevel and multisource data from the plethora of clinical and research systems found within hospitals and medical centers to facilitate further biomedical research.ORCID: 0000-0001-9744-174XMd. Rezaul Karim is a researcher at Fraunhofer FIT, Germany and a PhD candidate at RWTH Aachen University, Germany. He is working towards developing a distributed knowledge pipeline with knowledge graphs and neural networks towards making them explainable and interpretable. His research interests include machine learning, knowledge graphs, bioinformatics, and explainable artificial intelligence (XAI).ORCID: 0000-0001-6804-9183Stefan Decker is the director of Fraunhofer FIT, Germany and Professor of Computer Science at RWTH Aachen University, Germany. He was the director of Insight Centre for Data Analytics, and professor of informatics at NUI Galway, Ireland between 2006 and 2015. His research interests include Semantic Web and linked data, knowledge representation, and neural networks.ORCID: 0000-0001-6324-7164Andre Dekker is a board-certified medical physicist at MAASTRO Clinic and full professor at Maastricht UMC+ and Maastricht University where he holds the chair “Clinical Data Science”. His research focuses on three main themes: 1) building global FAIR data sharing infrastructures; 2) machine learning outcome prediction models from the data; 3) applying outcome prediction models to improve lives of patients. The main scientific breakthrough has been the development of a Semantic Web and ontology based data sharing and distributed learning infrastructure that does not require data to leave the hospital. This has reduced many of the ethical and other barriers to share data.ORCID: 0000-0002-0422-7996Sarah Cohen-Boulakia is a full Professor at the Laboratoire de Recherche en Informatique at Universite Paris-Sud. She holds a PhD in Computer Science and a Habilitation from the same university. She has been working for fifteen years in multi-disciplinary groups involving computer scientists and biologists of various domains. She spent two years as a postdoctoral researcher at the University of Pennsylvania, USA and 18 months at the Institute of Computational Biology (IBC) of Montpellier, France. Dr. Cohen-Boulakia&#39;s research interests include provenance and design of scientific workflows, reproducibility of scientific experiments, integration, querying and ranking in the context of biological and biomedical databases. She currently co-animates a National working group on reproducibility of scientific experiments and she is involved in the European Research Infrastructure ELIXIR (www.elixir-europe.org/).ORCID: 0000-0002-7439-1441Daniel Garijo is a computer scientist at the Information Sciences Institute of the University of Southern California. His research activities focus on e-Science and the Semantic Web, specifically on how to increase the understandability of software and scientific workflows using their associated provenance, metadata and intermediate results. Daniel was a member of the W3C Provenance Working Group to develop a standard for provenance on the Web, and he is currently collaborating with domain scientists to ease the description and composition of software in environmental and social sciences.ORCID: 0000-0003-0454-7145Yolanda Gil is Director of Knowledge Technologies and Associate Division Director at the Information Sciences Institute of the University of Southern California, and Research Professor in Computer Science and in Spatial Sciences. She is also Associate Director of Interdisciplinary Programs in Data Science at USC. She received her M.S. and PhD degrees in Computer Science from Carnegie Mellon University, with a focus on artificial intelligence. Her research is on intelligent interfaces for knowledge capture and discovery, which she investigates in a variety of projects concerning knowledge-based planning and problem solving, information analysis and assessment of trust, semantic annotation and metadata, and community-wide development of knowledge bases. Dr. Gil collaborates with scientists in different domains on semantic workflows and metadata capture, social knowledge collection, computer-mediated collaboration, and automated discovery. She initiated and chaired the W3C Provenance Group that led to a community standard in this area. Dr. Gil is a Fellow of the Association for Computing Machinery (ACM), and Past Chair of its Special Interest Group in Artificial Intelligence. She is also a Fellow of the Association for the Advancement of Artificial Intelligence (AAAI), and was elected as its 24th President in 2016.ORCID: 0000-0001-8465-8341Michael R. Crusoe is one of the co-founders of the Common Workflow Language project and the CWL Project Lead. His facilitation, technical contributions, and training on behalf of CWL draw from his time as the former lead developer of C. Titus Brown&#39;s k-h-mer project, his previous career as a sysadmin and programmer, and his experiences in various Free and Open Source Software communities. This is not Michael&#39;s first time working on a standards project as he was the technical author of the International Labour Organization&#39;s Seafarers&#39; Identity Card (2003) standard which is in force and ratified by 32 countries. Currently based in Berlin, Germany; Michael has been living in Europe for the last 4 years where he has enjoyed partnering with ELIXIR, ASTRON, and the EOSCPilot to build collaborations across the continent and across the world.ORCID: 0000-0002-2961-9670Kristian Peters is currently working at the Leibniz Institute of Plant Biochemistry. He is part of the Germany network of bioinformatic infrastructures (de.NBI) and is a member of the GoFAIR metabolomics implementation network and the societies NBS and BLAM e.V. which focus on bryophyte biology and ecology. As he has studied both Information Technology and Biology his research focus is mainly on interdisciplinarity and integrating the research fields biochemistry, bioinformatics and ecology. His expertise in data integration covers a wide range of topics, including cloud e-infrastructures, statistics, machine learning, chemical ecology and ecometabolomics, targeted and untargeted metabolomics, plant and vegetation ecology, bryophyte biology, macro- and microscopy and climate change biology. His current research activities focus on the integrative data analysis and characterisation of compound classes of rare species in ecological contexts, creating scientific computational workflows for use cases in ecometabolomics and biomedicine, promoting the reproducibility and interoperability of software tools and the adoption of standardized research objects and formats.ORCID: 0000-0002-4321-0257Daniel Schober, a trained neurobiologist, did his PhD in medical knowledge engineering at Charité Hospital, Berlin. He mainly works in the areas of symbolic artificial intelligence, ontology engineering, policy management and data standard development. Aside his contributions to a multitude of description logics ontologies, he created best practices for the OBO Foundry (naming conventions) and developed open access XML standards for nuclear magnetic resonance data (nmrML). Foundational ontology research is done on the scale-dependency of ontologic top level categories, i.e. towards advanced physics concepts that emerge on the micro- and macrocosmic scale. Currently he investigates the impact of semantic and syntactic data standards in contribution to FAIR Data, in particular to Galaxy computational workflows. He has worked at the European Bioinformatics Institute in Cambridge, UK, then moved to IMBI Freiburg working on medical data integration and until recently, he worked in the mass spectrometry and bioinformatics department of the Leibniz Institute for Plant Biochemistry in Halle, Germany.ORCID: 0000-0001-8014-6648Larry Lannom is Director of Information Services and Vice President at the Corporation for National Research Initiatives (CNRI), where he works with organizations in both the public and private sectors to develop experimental and pilot applications of advanced networking and information management technologies. Mr Lannom&#39;s current work is focused on CNRI&#39;s Digital Object Architecture, which is based on the concept of the digital object, a uniform approach to representing digital information across computing and application environments, both now and into the future. Mr. Lannom joined CNRI in September of 1996. Prior to that, he was a Technical Director at DynCorp, Inc., where he served as an advisor on digital library research for the ISTO, CSTO, and ITO offices of the US Defense Advanced Research Projects Agency (DARPA), including initiating the Computer Science Technical Reports (CS-TR) project, DARPA&#39;s first effort in the digital library area. In addition, he managed the development of internal information systems for DARPA. Originally trained as a librarian, his earlier work included reference book publishing and information retrieval research.ORCID: 0000-0003-1254-7604Dimitris Koureas is currently head of the department for the development of international biodiversity research infrastructures at Naturalis Biodiversity Center, Coordinator of the new pan-European Research Infrastructure DiSSCo and chair of the COST Action Mobilize. He holds a PhD in plant systematics with post-doctoral expertise acquired in biodiversity informatics/e-taxonomy. He participates as a senior manager in many European projects in the areas of biodiversity data and infrastructures. He is former chair of the Biodiversity Information Standards (TDWG) organization and current member of the Technical Advisory Board of the Research Data Alliance (RDA). He is an invited lecturer on biodiversity infrastructures in European universities.ORCID: 0000-0002-4842-6487Alex Hardisty is Director of Informatics Projects in the School of Computer Science and Informatics at Cardiff University, where his leadership contributions in environmental, biodiversity and ecological informatics have spanned engineering of large-scale distributed computing systems (e-Infrastructures), curating scientific information in knowledge infrastructures, virtual research environments, and socio-technical issues of new technology adoption. Alex leads work in the EU Horizon 2020 ICEDIG project on “innovation and consolidation for large scale digitization of natural heritage”, a part of the Distributed System of Scientific Collections (DiSSCo) programme, where he is presently designing the global architecture for Digital Specimens and Collections. As a technical innovator, Alex has previously been responsible for the Biodiversity Virtual e-Laboratory (BioVeL), the Reference Model for research infrastructures for environmental sciences (ENVRI RM), and the “Bari Manifesto” for an interoperability framework for Essential Biodiversity Variables (EBV). Alex is a Chartered Information Systems Professional Fellow of the British Computer Society (BCS) and Member of the Chartered Management Institute (CMI). Prior to joining Cardiff University in 2002, Alex worked as a consultant, systems engineer and software programmer in the telecommunications and defence industries.ORCID: 0000-0002-0767-4310Jeremy G. Frey is a Professor of Physical Chemistry and leads the artificial intelligence (AI) for Scientific Discovery Network. For many years he has investigated and developed e-Science the way digital infrastructure can enhance the intelligent creation, dissemination and analysis of scientific data.ORCID: 0000-0003-0842-4302Stuart J. Chalk is applying semantic data modelling approaches to represent experiment and computational scientific data. He is an advocate of open and FAIR data and a Titular member of the IUPAC Committee on Publications and Chemical Data Standards (CPCDS).ORCID: 0000-0002-0703-7776Shelley Stall is the Senior Director for the American Geophysical Union&#39;s Data Leadership Program. She works with AGU&#39;s members, their organizations, and the broader research community to improve data and digital object practices with the ultimate goal of elevating how research data is managed and valued. Shelley&#39;s recent work includes being the program manager for the Enabling FAIR Data project engaging over 300 stakeholders in the Earth, space, and environmental sciences to make data open and FAIR targeting the publishing and repository communities to change practices by no longer archiving data in the supplemental information of a paper but instead depositing the data supporting the research into a trusted repository where it can be discovered, managed, and preserved.ORCID: 0000-0003-2926-8353Leah R. McEwen is the Chemistry Librarian at Cornell University, where she manages digital library and information services for chemistry and related research and learning communities. She is an active volunteer in many chemistry organizations and is currently chair-elect of the Committee on Publications and Cheminformatics Data Standards of the International Union of Pure and Applied Chemistry. For the past several years, she has been building up a global community of stakeholders involved in chemical data publishing and sharing, including researchers, publishers, librarians, repositories, and software developers. She has worked across sectors and disciplines, connecting with other scientific unions and data initiatives to identify gaps and develop collective workflows to facilitate FAIR data exchange across the chemistry enterprise and beyond.ORCID: 0000-0003-2968-1674Lesley Wyborn is an Adjunct Fellow with the National Computational Infrastructure at the Australian National University and the Australian Research Data Commons. She worked for Geoscience Australia from 1972 to 2014 in both scientific research (geochemistry and mineral systems) and in geoscientific data management. In geoinformatics her main interests are developing international standards that support the integration of Earth science datasets into transdisciplinary research projects and in developing seamless high-performance data sets that can be used in High Performance Computing environments. She is currently Chair of the Australian Academy of Science “National Data in Science Committee”. She was awarded the Australian Government Public Service Medal in 2014, the 2015 Geological Society of America Career Achievement Award in Geoinformatics and the 2019 US Earth Science Information Partners Martha Maiden Award.ORCID: 0000-0001-5976-4943Nancy J. Hoebelheinrich is a founder and principal of Knowledge Motifs LLC, a company focused upon providing consulting, project management / coordination, grant writing and educational / training services to business, non-profit, and governmental organizations needing assistance in organizing, managing, archiving and preserving data. She has been involved in a number of projects focused upon managing data in leadership, coordination, community engagement, and education / training roles as both a volunteer and a contractor. Key projects including the Enabling FAIR Data project where she served as Co-Chair of the Technical Adoption Group for training on FAIR data, and the ESIP-hosted Data Management Training Clearinghouse where she is currently serving as Editor, and as Co-Investigator and Project Coordinator on a 3 year National Leadership Grant from the Institute of Museum and Library Services.ORCID: 0000-0002-6797-7903Ian Bruno is Head of Strategic Partnerships at the Cambridge Crystallographic Data Centre (CCDC) which has been managing and curating scientific data for over 50 years. Ian himself has over 25 years&#39; experience in the world of Chemistry and Informatics. He is an active participant in research data activities and initiatives through the Research Data Alliance and the World Data System and is involved in data-related activities of the International Union of Pure and Applied Chemistry (IUPAC). He is Secretary to the InChI Trust which oversees the maintenance and development of the IUPAC International Chemical Identifier. Ian&#39;s various roles at the CCDC have included software development and management of technical and scientific teams and projects. In his current role, he is responsible for shaping the CCDC&#39;s interactions with wider research data activities and communities.ORCID: 0000-0003-4901-9936Ramon Granell is a researcher at the Oxford e-Research Centre currently working as a knowledge engineer with Professor Susanna-Assunta Sansone in the area of data management for biomedical sciences. He applies data analytic techniques to enrich data/publications repositories and platforms utilised under the FAIR (Findable, Accessible, Interoperable and Reusable) principle. Ramon has been working at the Oxford e-Research Centre since 2010, investigating in different areas such as energy analytics and computational linguistics. Before that, he worked at Department of computer Science, University of Oxford. He holds a Computer Science degree and ML master from the Universidad Politecnica de Valencia (Spain).ORCID: 0000-0001-9572-0972Allyson Lister completed a BA (1997) in Biology and Ancient Mediterranean Civilisations from Rice University, an MSc (1999) in Computational Biology from the University of York and a PhD (2012) in Computer Science from Newcastle University. In 1999, she joined the European Bioinformatics Institute as a Software Engineer for UniProtKB, a protein sequence database. In 2006, she joined Newcastle University as a full-time Research Associate while completing her PhD in semantic data integration. Between 2012 and 2014, she also worked for the University of Manchester on various short-term ontology development projects. Allyson moved to the Oxford e-Research Centre in 2015 where she is currently working on the FAIRsharing project.ORCID: 0000-0002-7702-4495Hugh Shanahan is a Professor of Bioinformatics in Centre for Systems and Synthetic Biology and Department of Computer Science at the University of London, His research interests include the analysis of transcriptomic data and the inference of regulatory gene networks; Protein-DNA interactions; expertise is in computational biology and statistics.ORCID: 0000-0003-1374-6015Milo Thurston is currently one of the developers of BioSharing, as well as working on TeSS in collaboration with colleagues in Manchester. Previously, he developed the OBOE system for managing services to be used by Scratchpads, and prior to that was the Scientific Computing Support Specialist for Climateprediction.net responsible for server maintenance, software and infrastructure development. His scientific background is in biology and bioinformatics, and he is experienced in Linux system administration; he has a degree in microbiology and genetics from Dundee University, a D.Phil. in virology from Oxford University (supervised by the late Bill Hamilton) and previously qualified as an RHCE. Outside his scientific work he is involved in teaching and research into Historical European Martial Arts, having founded a school in 1999 and subsequently written a modern training manual based on Sir William Hope&#39;s 1707 fencing text. He has taught and competed at martial arts events in the UK, US, Canada, Australia, Sweden, Austria and Germany.ORCID: 0000-0002-6468-9260Hana Pergl Sustkova is the Operations Officer at the GO FAIR International Support and Coordination Office (GFISCO). Hana supports key activities of the GFISCO including the FAIR Convergence Matrix coalition coordination. Prior to joining the GFISCO, Hana worked as project manager for the ELIXIR research infrastructure, which marked her transition from an international corporation to the academic sphere. Her background is business administration and management.ORCID: 0000-0002-4462-6465Jan Slifka got his Master&#39;s degree in Software Engineering at the Czech Technical University in Prague. He is now a PhD student there, focusing on evolvable systems and functional programming. He acquired hands-on experience from the industry while working as a senior developer for several startups with a wide range of technologies. He is also a member of ELIXIR-CZ Interoperability Platform where he works as a chief User Interface developer on the Data Stewardship Wizard. He collaborates with GO FAIR, building the FAIR Funding Ecosystem.ORCID: 0000-0002-4941-0575Markus Stocker is Head of the Knowledge Infrastructures Research Group at the TIB Leibniz Information Centre for Science and Technology. He holds a PhD in Environmental Informatics from the University of Eastern Finland; a MSc in Environmental Science from the University of Eastern Finland; and a Diploma (MSc) in Informatics from the University of Zurich, Switzerland. His research interests lie at the intersection between research infrastructures and research communities, and how such infrastructures acquire, maintain, and share scientific knowledge about human and natural worlds.ORCID: 0000-0001-5492-3212Mark Musen is Professor of Biomedical Informatics and of Biomedical Data Science at Stanford University, where he is Director of the Stanford Center for Biomedical Informatics Research. Dr. Musen conducts research related to open science, intelligent systems, computational ontologies and biomedical decision support. His group developed Protégé, the world&#39;s most widely used technology for building and managing terminologies and ontologies. He has served as principal investigator of the National Center for Biomedical Ontology and of the Center for Expanded Data Annotation and Retrieval (CEDAR). Dr. Musen directs the World Health Organization Collaborating Center for Classification, Terminology, and Standards at Stanford University, which has developed much of the information infrastructure for the authoring and management of the 11th edition of the International Classification of Diseases (ICD-11). Dr. Musen was the recipient of the Donald A. B. Lindberg Award for Innovation in Informatics from the American Medical Informatics Association in 2006. He has been elected to the American College of Medical Informatics, the Association of American Physicians, the International Academy of Health Sciences Informatics, and the National Academy of Medicine.ORCID: 0000-0003-3325-793XMargreet Bloemers is project leader for FAIR data &amp;amp; data management at the Netherlands Organization for Health Research and Development (ZonMw). Margreet promotes creating and reusing FAIR data in several contexts: she develops innovative approaches and coordinates procedures for data management in ZonMw&#39;s research programs; at the National Platform Open Science, she is one of the project leaders for introducing open science in academia in the Netherlands. In the field of antimicrobial resistance, she is work package leader for Research Infrastructures at the Joint Programming Initiative Antimicrobial Resistance. Also, she participates in the international consortium VALUE-Dx for innovative diagnostic strategies for more personalized antibiotic therapy in community care settings. Finally, Margreet advises about the implementation of research findings from ZonMw funded projects into policy and practice. Margreet is trained as a biologist, and got her PhD in developmental biology at the Hubrecht Institute in Utrecht, the Netherlands.ORCID: 0000-0003-3710-3188Mark Hahnel is the CEO and founder of Figshare, which he created whilst completing his PhD in stem cell biology at Imperial College London. Figshare currently provides research data infrastructure for institutions, publishers and funders globally. He is passionate about open science and the potential it has to revolutionize the research community. For the last eight years, Mark has been leading the development of research data infrastructure, with the core aim of reusable and interoperable academic data. Mark sits on the board of DataCite and the advisory board for Directory of Open Access Journals (DOAJ). He was on the judging panel for the National Institutes of Health (NIH), Wellcome Trust Open Science prize and acted as an advisor for the SpringerNature masterclasses.ORCID: 0000-0003-4741-0309Dan Valen joined Figshare as its first US-based employee in early 2014 to help researchers and organizations navigate trends in research data management. In his current role, he focuses on the development of Figshare community through engagement, strategic partnerships and educational outreach. Prior to working in the research data space at Figshare, Dan spent over 6 years at one of the largest scientific, technical, engineering and medical (STEM) publishers holding positions in editorial, trade publishing and electronic content licensing.ORCID: 0000-0002-9479-6438Sarah Jones coordinates work on the DCC&#39;s Data Management Planning tool – DMPonline – and undertakes research on data policy and data management planning. Sarah is involved in several European Commission funded projects including, FOSTER+, OpenAIRE and Research Data Alliance Europe 4.0. Her work in a European context focuses primarily on training, data management planning and network building to facilitate open science. She co-chairs the RDA Active DMP Interest Group and the CODATA Working Group on Research Data Science schools. In a personal capacity, she is rapporteur on the European Commission&#39;s FAIR Data Expert Group and a member of the Open Science Transport Research Cloud Expert Group. In previous roles, Sarah led the Data Audit Framework project and Incremental. She worked in HATII at the University of Glasgow from 2006–2017, initially for the AHDS Performing Arts data centre and then for the DCC, and is now based in Glasgow University Library.ORCID: 0000-0002-5094-7126Tomasz Miksa has been working as a researcher at SBA Research since October 2012. He received in 2011 his MSc in systems and computer networks from the Wroclaw University of Technology, Poland. In 2016 he received his PhD in computer science from the TU Wien for his work on verification and validation of scientific workflow re-executions. He was involved in preservation of business processes in the EU-funded FP7 project TIMBUS. Furthermore, he took part in the FP7 4C Project which aimed to clarify the costs of curation of digital assets. Currently, he is a chair of the DMP Common Standards working group at the Research Data Alliance (RDA) and a co-founder of RDA Austria. His research focuses on reproducibility of eScience experiments and machine-actionable data management plans. Topics of interests include, but are not limited to: experiment context modelling, verification and validation, data repository architectures and workflows, digital curation and preservation.ORCID: 0000-0002-4929-7875Robert Samors serves as the Coordination Officer for the Belmont Forum e-Infrastructures &amp;amp; Data Management Project. In that role, he coordinates and liaises with e-I &amp;amp; DM project leads, Action Theme co-leads, stakeholders, Advisory Group and Oversight Committee members, and international partners to encourage the adoption of data principles and best practices, promote effective data planning and stewardship, and develop training curricula to enable practitioners to put those principles and practices into action through Belmont Forum agency activities and funded projects. Prior to joining the Belmont Forum, Mr. Samors served as Senior External Relations Manager for the Group on Earth Observations (GEO) designing and implementing GEO&#39;s engagement strategy. He has worked closely with experts and global leaders in data and information issues across a range of governments and international scientific and technical organizations. His earlier positions have included serving as Associate Vice President for Innovation and Technology Policy at the Association of Public and Land-grant Universities (APLU), as Associate Vice President for Federal Relations for the University of North Carolina System, and as Assistant Vice President for Research at the University of Michigan. He holds a Masters in Public Policy from the Harvard University Kennedy School of Government, and a B.A. in Economics from Brown University.ORCID: 0000-0003-3737-0120Judit Ungvari is an ecologist by training, with expertise in aspects of avian biology in tropical habitats. She studied birds in the Peruvian Amazon region combining both lab- and field-based research and received her PhD degree in Zoology with a certificate and concentration in Tropical Conservation and Development at the University of Florida in 2016. Judit then worked as a postdoctoral scholar at the Smithsonian Institute in Washington, DC, addressing conservation issues in agroecosystems in Colombia. She has become involved in local capacity building and community outreach both in the USA and Latin America and has mentored dozens of students to complete independent research projects. Her interests include increasing diversity and broadening participation in the sciences, sustainability science, science diplomacy, supporting open and reproducible research efforts, and communicating science to the public, especially in museum settings. As a AAAS Science &amp;amp; Tech Policy fellow at the National Science Foundation, Judit is working on various international activities facilitating transdisciplinary global change research, including the advancement of e-infrastructures and data management planning.ORCID: 0000-0002-5180-8048Rowena Davis was a project coordinator for the Belmont Forum e-Infrastructures and Data Management project, a three-year project (2016–2019) facilitating data sharing among teams performing research for the Belmont Forum, a coalition of major and emerging international funders of global environmental change research. She has been co-chair of the EarthCube Liaison Team (2018–2019) and a co-chair of the RDA Mapping the Data Landscape Interest Group (2017–2019).ORCID: 0000-0002-9424-0325Tina Lee was the Principal Investigator for the Belmont Forum&#39;s e-Infrastructures and Data Management Project, a three-year project (2016–2019) whose goal was to make operational the Belmont Forum Open Data Policy &amp;amp; Principles in its collaborative funding program. Funded by the US National Science Foundation and four other international science funding agencies, the e-I&amp;amp;DM project coordinated with numerous international data and research organizations to develop resources for data management planning and training for Belmont Forum&#39;s global environmental change community. She is currently the user engagement officer for the CyVerse project, a cyberinfrastructure platform for life sciences computational research based at the The University of Arizona in Tucson.ORCID: 0000-0002-5284-7751Ron Dekker is the director of CESSDA ERIC, the Consortium of Social Science Data Archives, with its main office in Bergen, Norway. CESSDA is a European Infrastructure with 20 members (countries) and combines the work and expertise of these countries&#39; social science data service providers, see www.cessda.eu. On behalf of CESSDA, he is also the coordinator of the Social Sciences &amp;amp; Humanities Open Cloud project (SSHOC). He is a member of the European Open Science Cloud Executive Board and serves in several strategic advisory boards. Ron studied econometrics and worked for ten years in labour market research at Dutch universities. He was at the national research council for almost twenty years – running a data agency, program committees and in general management (institutes, infrastructure and open science). This included secondment to the Dutch government for project leadership on Open Science of the Dutch EU Presidency in 2016 and as national expert at the European Commission in Brussels in 2017.ORCID: 0000-0003-0989-4963 Associate professor Margareta Hellström is a senior staff member at ICOS Carbon Portal, working with research data management issues such as Open Science, persistent identifiers, data citation and usage statistics and FAIR. She has represented ICOS in several Horizon 2020 projects, including ENVRI-FAIR where she leads the work package on FAIR training and skills development.ORCID: 0000-0002-4154-2610Luana Sales, PhD in Information Science of the Instituto Brasileiro em Informação em Ciěncia e Tecnologia (IBICT). She is a researcher and a professor at the Master and PhD courses in Information Science in IBICT and a professor of the Master Program in Library Science of The Universidade Federal do Estado do Rio de Janeiro (UNIRIO). She is the GO FAIR Brazil coordinator.ORCID: 0000-0002-3614-2356Patrícia Henning, PhD in Sciences-Information and Communication in Health of the Instituto de Comunicação e Informação Científica e Tecnológica (ICICT/FIOCRUZ). Professor of the Master Program in Library Science of The Universidade Federal do Estado do Rio de Janeiro (UNIRIO). She is the representative of the GO FAIR Brazil coordination office in The Netherlands.ORCID: 0000-0003-0739-6442Viviane Veiga, PhD in Sciences – Information and Communication in Health of the Instituto de Comunicação e Informação Científica e Tecnológica (ICICT/FIOCRUZ). She works at Fundação Oswaldo Cruz (FIOCRUZ) coordinating the FIOCRUZ libraries network. She is a professor at ICICT of Maters and PhD program and is the GO FAIR Brazil-Health coordinator.ORCID: 0000-0001-8318-7912Maira Murrieta Costa, PhD in Information Science of the Universidade de Brasilia (UnB). She is the Technologist of the Ministério da Ciěncia, Tecnologia, Inovações e Comunicações (MCTIC). MCTIC Business Intelligence and Information Coordinator. She is responsible for drafting MCTIC Open Data Plan and MCTIC representative for National Open Data Infrastructure.ORCID: 0000-0002-8324-2114Luís Fernando Sayão, PhD in Information Science of the Instituto Brasileiro em Informação em Ciěncia e Tecnologia (IBICT). He works at the Comissão Nacional de Energia Nuclear (CNEN). He is a member of Conselho Nacional de Arquivos (CONARQ). He is Professor of the Master Program in Library Science of the Universidade Federal do Estado do Rio de Janeiro (UNIRIO) and the Program in Memory and Collections of the Fundação Casa de Rui Barbosa.ORCID: 0000-0002-6970-0553Luís Ferreira Pires, PhD in Electrical Engineering of the University of Twente. He is Associate Professor of the Faculty of Electrical Engineering, Mathematics and Computer Science, and member of the Services &amp;amp; Cyber-Security (SCS) group. He has co-authored more than 150 scientific publications and has contributed as PC member to various international conferences and is co-chair of the MODELSWARD conference.ORCID: 0000-0001-7432-7653Mia Stokmans is an Associate Professor at Tilburg University, Tilburg School of Humanities and Digital Sciences. She holds a Master of Science in Economic Psychology as well as Research Methods from Tilburg University and a PhD in Consumer Decision Making from Delft University of Technology. Stokmans is a member of the Research Network Globalisation, Accessibility, Innovation and Care. Her fields are the role of attitudes and emotions in human decision making, social processes for behavioral change and mixed method approaches to research.ORCID: 0000-0002-7593-9632Munyaradzi Mawere is Professor and Research Chair at Great Zimbabwe University&#39;s Simon Muzenda School of Arts, Culture and Heritage Studies. He holds a PhD in Social Anthropology from the University of Cape Town, South Africa. He also holds three Masters Degrees in the areas of Philosophy, Social Anthropology and Development Studies. Mawere has participated in a wide range of research projects which include Culture and Heritage Sustainability in North-west Zimbabwe, Environmental Conservation in Southeastern Zimbabwe, and Health Services Utilisation in Masvingo, among many others. Mawere is an internationally renowned researcher and author, with over 75 books to his credit.ORCID: 0000-0001-8696-9282Mariam Basajja is currently pursuing a PhD in Computer Science at Leiden University Netherlands. Her topic is on “Designing a FAIR Data Point for Digital Health in Uganda”. Her main focus is on how data-integration through FAIR data supports overcoming lack of sustainability of Digital Health Solutions in Uganda. She holds a Master&#39;s degree in Advanced Computing Machine Learning, Data Mining and High Performance Computing from University of Bristol, UK. She also has a Bachelor&#39;s degree in Applied Computer Technology with a concentration of Software Engineering. Mariam is also a member of the African Women In IT Africa (AfricanWIT) Group whose aim is to accelerate the progress of the African Women in the field of Information Technology.ORCID: 0000-0001-7710-8843Antony Otieno Ong&#39;ayo is an academic Researcher at the International Institute of Social Studies of Erasmus University in The Hague. He holds a Bachelor degree in Political Science, a Master degree in Political Science (Politics and development) from the University of Stockholm, respectively and a PhD in Humanities (International Development) from Tilburg University. He is an associate researcher with Globalization, Accessibility, Innovation and Care (GAIC) and member of the Implementation network Go-FAIR Africa. His research interests are in the areas of politics of development, migration and development, digital citizenship and governance.ORCID: 0000-0002-3461-7960Primrose Nakazibwe holds a PhD from Tilburg University, Netherlands where she defended her thesis titled Gender and Commodity Chain Analysis. She holds a Master&#39;s (MA) and a Bachelor&#39;s in Development Studies from Mbarara University of Science and Technology. She is a senior lecturer, Mbarara University of Science and Technology in the Faculty of Interdisciplinary Training and Research, and senior lecturer at the Faculty of Social Sciences, Ndejje University, Uganda. She is a founding head of Department for Gender and Women Health Degree program at Mbarara University of Science and Technology.ORCID: 0000-0003-2758-3106Christine Kirkpatrick oversees the San Diego Supercomputer Center&#39;s (SDSC) Research Data Services division, which manages infrastructure, networking, and services for research projects of regional and national scope. Kirkpatrick is a recognized expert in the implementation of research computing services, with an emphasis on data science workloads, as well as operational cyberinfrastructure (CI) at scale. Kirkpatrick founded and hosts the US GO FAIR Office at SDSC, is the Executive Director of the US National Data Service (NDS), and Co-PI and Deputy Director of the West Big Data Innovation Hub (WBDIH). She co-chairs the All (Big Data) Hub Infrastructure Working Group and is co-PI of the Open Storage Network. Kirkpatrick received her master&#39;s degree from the Jacobs School of Engineering at University of California San Diego. She serves on the Technical Advisory Board (TAB) for the Research Data Alliance (RDA), and the external Advisory Boards for the European Open Science Cloud (EOSC) Hub and EOSC Nordic.ORCID: 0000-0002-4451-8042Kudakwashe Chindoza holds a Master of Commerce degree in Information Systems from Great Zimbabwe University (2015) and a BSc Information Systems Honours degree from Midlands State University (2006), in Zimbabwe. He is currently a lecturer at Great Zimbabwe University in Zimbabwe. His research interests are ICTs for Sustainable Development, Digital Healthcare Data Management, Interoperability of Heterogeneous Systems, and Governance of Web Based Technologies.ORCID: 0000-0002-8346-5211Carsten Baldauf received his PhD in Biochemistry from Leipzig University. After postdoctoral visits to TU Dresden and CAS/MPG-PICB Shanghai, he joined the Theory Department at Fritz Haber Institute of the Max Planck Society in Berlin in 2010. Since 2013, he has been leading a research group that deals with accurate simulations of biomolecular structure and dynamics. Carsten teaches courses at Freie Universität Berlin and Leipzig University. In 2018, he got involved in the process of founding the association “FAIR Data Infrastructure for Physics, Chemistry, Materials Science and Astronomy e.V.” (in short: FAIR-DI, https://fairdi.eu) and has since then developed an interest in data infrastructures and ontologies.ORCID: 0000-0003-2637-6009Paul Trilsbeek is the head of The Language Archive at the Max Planck Institute (MPI) for Psycholinguistics. He studied Sonology at the Royal Conservatory in The Hague, after which he worked as a music technologist within the Music, Mind, Machine research group at Radboud University. In 2003 he started working at the MPI for Psycholinguistics.ORCID: 0000-0001-9502-1960Herman van Vlijmen graduated with a Master&#39;s degree in Bio-Pharmaceutical Sciences at Leiden University in The Netherlands and a PhD degree in Physical Chemistry at Harvard University. He worked nine years at the biotech company Biogen in the Boston area, ultimately as Senior Scientist, in the computational design of small molecule drugs and protein therapeutics. In 2005 he joined Tibotec, a Johnson and Johnson company focusing on infectious diseases, as Director of Computational Drug Design. He is now Head of Computational Chemistry in the Discovery Sciences organization at Janssen, Pharmaceutical companies of Johnson &amp;amp; Johnson, located in Belgium. Since 2008 he is also Adjunct Professor of Computational Drug Discovery at Leiden University. Herman has more than 70 peer reviewed publications and is inventor on eight patents. He is the Industry Project Leader of the IMI FAIRplus project, which is developing best practices in FAIRification of data from IMI projects and internal pharma data.ORCID: 0000-0002-1915-3141Albert Mons is one of the founding partners of Phortos Consultants, a consultancy practice to academic institutions and private companies specializing in FAIR data and services solutions. Over the years Albert and his partners have founded and cofounded a number of start-ups in the field of bio-informatics &amp;amp; semantics, data integration and support, network solutions and big data solutions. One of them is Euretos, a platform provider for AI driven hypothesis generation and InSilico Target/Biomarker Discovery and Validation. Recently, Albert has been appointed International Project Manager GO FAIR running the global Business Development and coordinating the partners in the technical Implementation process lead. In addition he was a member of the writing team for the European Open Science Cloud Implementation movement “GOFAIR”. Albert also provides FAIR trainings focusing on FAIR Data Stewardship, Ontology and Semantic Modeling and related FAIR services. Recently, in collaboration with the GO FAIR Foundation, Albert initiated (and now chairs) the GO FAIR Service Provider Consortium including, amongst others, Accenture, KPMG, Deloitte, and several SME&#39;s providing professional FAIR related consulting and implementations.ORCID: 0000-0001-8038-7572Wouter Franke is a consultant for the Dutch National Health Care Institute with a background in Computer Science and Change Management. He has extensive experience with large implementations of data exchange programs in complex networks of public and private organizations within the Dutch healthcare. Since 2017 he has been working on both research and development of FAIR and the Internet of FAIR Data &amp;amp; Services, and the implementation of FAIR within programs run by the Dutch National Health Care Institute. His goal is to ensure data within healthcare are available to a wide range of stakeholders and can be interpreted by machines. This in turn will greatly increase the value of existing and emerging capabilities in the field of data science, ultimately resulting in better prevention and healthcare systems.ORCID: 0000-0001-5058-3767Arie Baak is one of the co-founders of Euretos, an AI platform used by (pre-)clinical researchers to take a in-silico, systems biology approach to the identification &amp;amp; validation of targets, biomarkers and indications. For the first two decades of his career, Arie has worked in various customer facing strategic innovation roles in the mobile telecoms and Internet infrastructure markets. In this high performance/high volume environment he has been developing analytics solutions that provide actionable insight to end users long before the term “big data analytics” became fashionable. Since 2010 Arie has been applying his expertise to the life sciences where has worked with some of the world&#39;s leading pharma, biotech and academic institutions to develop a data &amp;amp; AI driven approach to life sciences research.ORCID: 0000-0003-2829-6715Bert Meerman is the Director of the GO FAIR Foudation (GFF). GFF supports the International GO FAIR Office, mainly in the area of paving the wave for implementing a coherent certification program. Bert is a senior business executive with a successful track record in Finance, Network, Information and Data technology. Bert has worked in a variety of management roles in different countries, mostly for American software companies. In addition, Bert has been the Secretary General of the International Factors Group, a consortium of finance companies where he implemented a successful worldwide data-exchange platform, based upon agreed network protocols and EDIFACT standards. Bert is a business economist, with an MBA from the Erasmus University in Rotterdam.ORCID: 0000-0002-0071-2660Renger Jellema, PhD, DSM Biotechnology Center (The Netherlands), has a track record of more than 20 years working in the field of chemometrics and data science. His roots are in analytical chemistry for which he obtained a Bachelor&#39;s degree in 1992. Renger studied chemistry at the University of Nijmegen (Radboud University) which he finished in 1995. Subsequently he did his PhD at the University of Amsterdam in a collaboration with the steel company Corus. After a short appointment at the Central Bureau of Statistics (CBS) he obtained a position at TNO Quality of Life, Zeist where he worked in the field of chemometrics as Product Manager of the product group “Analytical Information Sciences” until 2009. In his current employment at DSM, Renger is active in the field of data science where he is involved in several projects to extract more value out of data and implement digital tools within a Biotechnology environment.ORCID: 0000-0003-2435-6178Scott Lusher is Janssen&#39;s business technology leader for cheminformatics systems and Discovery Sciences globally, providing strategic technology partnership for 700 scientists, from medicinal chemistry, computational chemistry, data sciences, screening, compound logistics and Drug Metabolism and Pharmacokinetics. In this role he is responsible for developing and executing strategic plans for data-driven and compute-intensive research practices, initiating new projects and management of the overall portfolio of technology projects to enable small molecule discovery. Prior to joining Janssen, he was director of strategy and applied eScience at the Netherlands eScience Center in Amsterdam, enabling scientific IT approaches across Dutch academia. During this time, he participated in the original FAIR workshop and is a coauthor of the resulting publication setting out the FAIR principles. Scott&#39;s background is computer-aided drug discovery having spent fifteen years applying computational chemistry approaches in pharma and consumer product organizations.ORCID: 0000-0003-2401-4223Derk Arts has over 12 years of experience in medicine, research and data management, and has been involved in several projects integrating complex and diverse data sources. He received his MD from Vrije University in 2011 and his PhD on decision support and machine learning from the University of Amsterdam in 2016. During his MD training, Dr. Arts identified a major problem in medical research. Due to the unavailability of affordable, user-friendly data capture tools, researchers were deviating to non-compliant alternatives that reduce data quality, security, and reusability, and greatly increase waste. To solve these core issues, he founded Castor, a research platform that enables researchers to easily capture, standardize and reuse medical research data. The platform is currently serving thousands of clinical studies, both commercial and academic, and has been integrated with EPIC and other EMR systems, using HL7 FHIR. Castor is capable of generating machine readable data, which is one of the most promising capabilities for eClinical systems.ORCID: 0000-0001-5702-5856Sebastiaan Knijnenburg is Chief Technology Officer at Castor EDC. With a PhD in Medical Informatics and clinical research, Dr. Knijnenburg is dedicated to providing researchers with advanced software to improve healthcare and research quality. He is passionate about data standardization and FAIR data and implementing FHIR in the context of clinical research.ORCID: 0000-0002-2475-6254Rudi Verbeeck, senior IT manager, holds a degree in civil electrotechnical-mechinical engineering (major: electronics) and in civil biomedical engineering from the university of Leuven (Belgium). He obtained a PhD in applied sciences on medical image processing with applications in stereotactic neurosurgery (University hospital Gasthuisberg, Leuven) in 1996, awarded with the IBM Belgium prize for informatics. He continued in the same hospital as a post-doc in the radiotherapy department to establish a stereotactic radiosurgery capability. He joined Janssen Pharmaceutica in 1998 as a project manager in the IT department responsible for projects in bioinformatics, chemoinformatics and statistics for discovery research. He gained experience in clinical data management when he moved to Tibotec in 2008. Recently, he has been involved in the IMI/EMIF project (European Medical Information Framework) where he developed data harmonization methods based on semantic Web technology. He is currently involved with the IMI FAIRplus project and with FAIR data and ontology management implementations in Janssen.ORCID: 0000-0001-5445-6095 Karsten Kryger Hansen is research data management coordinator at Aalborg University, and works with RDM in a broad perspective, covering many aspects of the life cycle of research data. Daily activities ranges from institutional perspectives on data management with the focus of being a change agent, to everyday support for specific research projects.ORCID: 0000-0002-2407-8764},
  archive      = {J_DINT},
  doi          = {10.1162/dint_x_00052},
  journal      = {Data Intelligence},
  number       = {1-2},
  pages        = {293-322},
  shortjournal = {Data Intell.},
  title        = {Author biography},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Considerations for the conduction and interpretation of
FAIRness evaluations. <em>DINT</em>, <em>2</em>(1-2), 285–292. (<a
href="https://doi.org/10.1162/dint_a_00051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The FAIR principles were received with broad acceptance in several scientific communities. However, there is still some degree of uncertainty on how they should be implemented. Several self-report questionnaires have been proposed to assess the implementation of the FAIR principles. Moreover, the FAIRmetrics group released 14, general-purpose maturity for representing FAIRness. Initially, these metrics were conducted as open-answer questionnaires. Recently, these metrics have been implemented into a software that can automatically harvest metadata from metadata providers and generate a principle-specific FAIRness evaluation. With so many different approaches for FAIRness evaluations, we believe that further clarification on their limitations and advantages, as well as on their interpretation and interplay should be considered.},
  archive      = {J_DINT},
  author       = {de Miranda Azevedo, Ricardo and Dumontier, Michel},
  doi          = {10.1162/dint_a_00051},
  journal      = {Data Intelligence},
  number       = {1-2},
  pages        = {285-292},
  shortjournal = {Data Intell.},
  title        = {Considerations for the conduction and interpretation of FAIRness evaluations},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The need of industry to go FAIR. <em>DINT</em>,
<em>2</em>(1-2), 276–284. (<a
href="https://doi.org/10.1162/dint_a_00050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The industry sector is a very large producer and consumer of data, and many companies traditionally focused on production or manufacturing are now relying on the analysis of large amounts of data to develop new products and services. As many of the data sources needed are distributed and outside the company, FAIR data will have a major impact, both by reducing the existing internal data silos and by enabling the efficient integration with external (public and commercial) data. Many companies are still in the early phases of internal data “FAIRification”, providing opportunities for SMEs and academics to apply and develop their expertise on FAIR data in collaborations and public-private partnerships. For a global Internet of FAIR Data &amp;amp; Services to thrive, also involving industry, professional tools and services are essential. FAIR metrics and certifications on individuals, data, organizations, and software, must ensure that data producers and consumers have independent quality metrics on their data. In this opinion article we reflect on some industry specific challenges of FAIR implementation to be dealt with when choices are made regarding “Industry GOing FAIR”.},
  archive      = {J_DINT},
  author       = {van Vlijmen, Herman and Mons, Albert and Waalkens, Arne and Franke, Wouter and Baak, Arie and Ruiter, Gerbrand and Kirkpatrick, Christine and da Silva Santos, Luiz Olavo Bonino and Meerman, Bert and Jellema, Renger and Arts, Derk and Kersloot, Martijn and Knijnenburg, Sebastiaan and Lusher, Scott and Verbeeck, Rudi and Neefs, Jean-Marc},
  doi          = {10.1162/dint_a_00050},
  journal      = {Data Intelligence},
  number       = {1-2},
  pages        = {276-284},
  shortjournal = {Data Intell.},
  title        = {The need of industry to go FAIR},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Towards the tipping point for FAIR implementation.
<em>DINT</em>, <em>2</em>(1-2), 264–275. (<a
href="https://doi.org/10.1162/dint_a_00049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This article explores the global implementation of the FAIR Guiding Principles for scientific management and data stewardship, which provide that data should be findable, accessible, interoperable and reusable. The implementation of these principles is designed to lead to the stewardship of data as FAIR digital objects and the establishment of the Internet of FAIR Data and Services (IFDS). If implementation reaches a tipping point, IFDS has the potential to revolutionize how data is managed by making machine and human readable data discoverable for reuse. Accordingly, this article examines the expansion of the implementation of FAIR Guiding Principles, especially how and in which geographies (locations) and areas (topic domains) implementation is taking place. A literature review of academic articles published between 2016 and 2019 on the use of FAIR Guiding Principles is presented. The investigation also includes an analysis of the domains in the IFDS Implementation Networks (INs). Its uptake has been mainly in the Western hemisphere. The investigation found that implementation of FAIR Guiding Principles has taken firm hold in the domain of bio and natural sciences. To achieve a tipping point for FAIR implementation, it is now time to ensure the inclusion of non-European ascendants and of other scientific domains. Apart from equal opportunity and genuine global partnership issues, a permanent European bias poses challenges with regard to the representativeness and validity of data and could limit the potential of IFDS to reach across continental boundaries. The article concludes that, despite efforts to be inclusive, acceptance of the FAIR Guiding Principles and IFDS in different scientific communities is limited and there is a need to act now to prevent dampening of the momentum in the development and implementation of the IFDS. It is further concluded that policy entrepreneurs and the GO FAIR INs may contribute to making the FAIR Guiding Principles more flexible in including different research epistemologies, especially through its GO CHANGE pillar.},
  archive      = {J_DINT},
  author       = {van Reisen, Mirjam and Stokmans, Mia and Basajja, Mariam and Ong&#39;ayo, Antony Otieno and Kirkpatrick, Christine and Mons, Barend},
  doi          = {10.1162/dint_a_00049},
  journal      = {Data Intelligence},
  number       = {1-2},
  pages        = {264-275},
  shortjournal = {Data Intell.},
  title        = {Towards the tipping point for FAIR implementation},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). FAIR practices in europe. <em>DINT</em>, <em>2</em>(1-2),
257–263. (<a href="https://doi.org/10.1162/dint_a_00048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Institutions driving fundamental research at the cutting edge such as for example from the Max Planck Society (MPS) took steps to optimize data management and stewardship to be able to address new scientific questions. In this paper we selected three institutes from the MPS from the areas of humanities, environmental sciences and natural sciences as examples to indicate the efforts to integrate large amounts of data from collaborators worldwide to create a data space that is ready to be exploited to get new insights based on data intensive science methods. For this integration the typical challenges of fragmentation, bad quality and also social differences had to be overcome. In all three cases, well-managed repositories that are driven by the scientific needs and harmonization principles that have been agreed upon in the community were the core pillars. It is not surprising that these principles are very much aligned with what have now become the FAIR principles. The FAIR principles confirm the correctness of earlier decisions and their clear formulation identified the gaps which the projects need to address.},
  archive      = {J_DINT},
  author       = {Wittenburg, Peter and Lautenschlager, Michael and Thiemann, Hannes and Baldauf, Carsten and Trilsbeek, Paul},
  doi          = {10.1162/dint_a_00048},
  journal      = {Data Intelligence},
  number       = {1-2},
  pages        = {257-263},
  shortjournal = {Data Intell.},
  title        = {FAIR practices in europe},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). FAIR practices in africa. <em>DINT</em>, <em>2</em>(1-2),
246–256. (<a href="https://doi.org/10.1162/dint_a_00047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This article investigates expansion of the Internet of FAIR Data and Services (IFDS) to Africa, through the three GO FAIR pillars: GO CHANGE, GO BUILD and GO TRAIN. Introduction of the IFDS in Africa has a focus on digital health. Two examples of introducing FAIR are compared: a regional initiative for digital health by governments in the East Africa Community (EAC) and an initiative by a local health provider (Solidarmed) in collaboration with Great Zimbabwe University in Zimbabwe. The obstacles to introducing FAIR are identified as underrepresentation of data from Africa in IFDS at this moment, the lack of explicit recognition of situational context of research in FAIR at present and the lack of acceptability of FAIR as a foreign and European invention which affects acceptance. It is envisaged that FAIR has an important contribution to solve fragmentation in digital health in Africa, and that any obstacles concerning African participation, context relevance and acceptance of IFDS need to be removed. This will require involvement of African researchers and ICT-developers so that it is driven by local ownership. Assessment of ecological validity in FAIR principles would ensure that the context specificity of research is reflected in the FAIR principles. This will help enhance the acceptance of the FAIR Guidelines in Africa and will help strengthen digital health research and services.},
  archive      = {J_DINT},
  author       = {van Reisen, Mirjam and Stokmans, Mia and Mawere, Munyaradzi and Basajja, Mariam and Ong&#39;ayo, Antony Otieno and Nakazibwe, Primrose and Kirkpatrick, Christine and Chindoza, Kudakwashe},
  doi          = {10.1162/dint_a_00047},
  journal      = {Data Intelligence},
  number       = {1-2},
  pages        = {246-256},
  shortjournal = {Data Intell.},
  title        = {FAIR practices in africa},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). GO FAIR brazil: A challenge for brazilian data science.
<em>DINT</em>, <em>2</em>(1-2), 238–245. (<a
href="https://doi.org/10.1162/dint_a_00046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The FAIR principles, an acronym for Findable, Accessible, Interoperable and Reusable, are recognised worldwide as key elements for good practice in all data management processes. To understand how the Brazilian scientific community is adhering to these principles, this article reports Brazilian adherence to the GO FAIR initiative through the creation of the GO FAIR Brazil Office and the manner in which they create their implementation networks. To contextualise this understanding, we provide a brief presentation of open data policies in Brazilian research and government, and finally, we describe a model that has been adopted for the GO FAIR Brazil implementation networks. The Brazilian Institute of Information in Science and Technology is responsible for the GO FAIR Brazil Office, which operates in all fields of knowledge and supports thematic implementation networks. Today, GO FAIR Brazil-Health is the first active implementation network in operation, which works in all health domains, serving as a model for other fields like agriculture, nuclear energy, and digital humanities, which are in the process of adherence negotiation. This report demonstrates the strong interest and effort from the Brazilian scientific communities in implementing the FAIR principles in their research data management practices.},
  archive      = {J_DINT},
  author       = {Sales, Luana and Henning, Patrícia and Veiga, Viviane and Costa, Maira Murrieta and Sayão, Luís Fernando and da Silva Santos, Luiz Olavo Bonino and Pires, Luís Ferreira},
  doi          = {10.1162/dint_a_00046},
  journal      = {Data Intelligence},
  number       = {1-2},
  pages        = {238-245},
  shortjournal = {Data Intell.},
  title        = {GO FAIR brazil: A challenge for brazilian data science},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). State of FAIRness in ESFRI projects. <em>DINT</em>,
<em>2</em>(1-2), 230–237. (<a
href="https://doi.org/10.1162/dint_a_00045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Since 2009 initiatives that were selected for the roadmap of the European Strategy Forum on Research Infrastructures started working to build research infrastructures for a wide range of research disciplines. An important result of the strategic discussions was that distributed infrastructure scenarios were now seen as “complex research facilities” in addition to, for example traditional centralised infrastructures such as CERN. In this paper we look at five typical examples of such distributed infrastructures where many researchers working in different centres are contributing data, tools/services and knowledge and where the major task of the research infrastructure initiative is to create a virtually integrated suite of resources allowing researchers to carry out state-of-the-art research. Careful analysis shows that most of these research infrastructures worked on the Findability, Accessibility, Interoperability and Reusability dimensions before the term “FAIR” was actually coined. The definition of the FAIR principles and their wide acceptance can be seen as a confirmation of what these initiatives were doing and it gives new impulse to close still existing gaps. These initiatives also seem to be ready to take up the next steps which will emerge from the definition of FAIR maturity indicators. Experts from these infrastructures should bring in their 10-years&#39; experience in this definition process.},
  archive      = {J_DINT},
  author       = {Wittenburg, Peter and de Jong, Franciska and van Uytvanck, Dieter and Cocco, Massimo and Jeffery, Keith and Lautenschlager, Michael and Thiemann, Hannes and Hellström, Margareta and Asmi, Ari and Holub, Petr},
  doi          = {10.1162/dint_a_00045},
  journal      = {Data Intelligence},
  number       = {1-2},
  pages        = {230-237},
  shortjournal = {Data Intell.},
  title        = {State of FAIRness in ESFRI projects},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Social data: CESSDA best practices. <em>DINT</em>,
<em>2</em>(1-2), 220–229. (<a
href="https://doi.org/10.1162/dint_a_00044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The European Commission report “Turning FAIR into reality” provides an index of 27 FAIR Action Plan recommendations. This index is used for a self-assessment on CESSDA, the Consortium of European Social Science Data Archives. CESSDA is performing well on “Concepts for FAIR implementation”, “Skills for FAIR”, and “Investment in FAIR”; there is work in progress on “FAIR culture”, and work to start up on “FAIR ecosystem” and especially on “Incentives and metrics for FAIR data and services”. Next, an analysis on the FAIR components, reveals that CESSDA has accomplished the “F”, is working on the “A” – considering the sensitivity and security requirements of social data, just started on “I”, and that there is lack of clarity on what should be in “R”. On Findability, the CESSDA Data Catalogue is explained, showing the building blocks that need to be in place before one can produce a catalogue. The article ends with a forward look on CESSDA&#39;s deployment on the FAIR principles.},
  archive      = {J_DINT},
  author       = {Dekker, Ron},
  doi          = {10.1162/dint_a_00044},
  journal      = {Data Intelligence},
  number       = {1-2},
  pages        = {220-229},
  shortjournal = {Data Intell.},
  title        = {Social data: CESSDA best practices},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Data management planning: How requirements and solutions are
beginning to converge. <em>DINT</em>, <em>2</em>(1-2), 208–219. (<a
href="https://doi.org/10.1162/dint_a_00043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Effective stewardship of data is a critical precursor to making data FAIR. The goal of this paper is to bring an overview of current state of the art of data management and data stewardship planning solutions (DMP). We begin by arguing why data management is an important vehicle supporting adoption and implementation of the FAIR principles, we describe the background, context and historical development, as well as major driving forces, being research initiatives and funders. Then we provide an overview of the current leading DMP tools in the form of a table presenting the key characteristics. Next, we elaborate on emerging common standards for DMPs, especially the topic of machine-actionable DMPs. As sound DMP is not only a precursor of FAIR data stewardship, but also an integral part of it, we discuss its positioning in the emerging FAIR tools ecosystem. Capacity building and training activities are an important ingredient in the whole effort. Although not being the primary goal of this paper, we touch also the topic of research workforce support, as tools can be just as much effective as their users are competent to use them properly. We conclude by discussing the relations of DMP to FAIR principles, as there are other important connections than just being a precursor.},
  archive      = {J_DINT},
  author       = {Jones, Sarah and Pergl, Robert and Hooft, Rob and Miksa, Tomasz and Samors, Robert and Ungvari, Judit and Davis, Rowena I. and Lee, Tina},
  doi          = {10.1162/dint_a_00043},
  journal      = {Data Intelligence},
  number       = {1-2},
  pages        = {208-219},
  shortjournal = {Data Intell.},
  title        = {Data management planning: How requirements and solutions are beginning to converge},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Licensing FAIR data for reuse. <em>DINT</em>,
<em>2</em>(1-2), 199–207. (<a
href="https://doi.org/10.1162/dint_a_00042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The last letter of the FAIR acronym stands for Reusability. Data and metadata should be made available with a clear and accessible usage license. But, what are the choices? How can researchers share data and allow reusability? Are all the licenses available for sharing content suitable for data? Data can be covered by different layers of copyright protection making the relationship between data and copyright particularly complex. Some research data can be considered as a work and therefore covered by full copyright while other data can be in the public domain due to their lack of originality. Moreover, a collection of data can be protected by special rights in Europe to acknowledge the investment in time and money in obtaining, presenting, arranging or verifying the data. The need of using a license when sharing data comes from the fact that, under current copyright laws, when rights exist, the absence of any legal notice must be understood as the default “all rights reserved” regime. Unless an exception applies, the authorisation of right holders is necessary for reuse. Right holders could use any text to state the reusability of data but it is advisable to use some of the existing licenses, and especially the ones that are suitable for data and databases. We hope that with this paper we can bring some clarity in relation to the rights involved when sharing research data.},
  archive      = {J_DINT},
  author       = {Labastida, Ignasi and Margoni, Thomas},
  doi          = {10.1162/dint_a_00042},
  journal      = {Data Intelligence},
  number       = {1-2},
  pages        = {199-207},
  shortjournal = {Data Intell.},
  title        = {Licensing FAIR data for reuse},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). How to (easily) extend the FAIRness of existing
repositories. <em>DINT</em>, <em>2</em>(1-2), 192–198. (<a
href="https://doi.org/10.1162/dint_a_00041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Data repository infrastructures for academics have appeared in waves since the dawn of Web technology. These waves are driven by changes in societal needs, archiving needs and the development of cloud computing resources. As such, the data repository landscape has many flavors when it comes to sustainability models, target audiences and feature sets. One thing that links all data repositories is a desire to make the content they host reusable, building on the core principles of cataloging content for economical and research speed efficiency. The FAIR principles are a common goal for all repository infrastructures to aim for. No matter what discipline or infrastructure, the goal of reusable content, for both humans and machines, is a common one. This is the first time that repositories can work toward a common goal that ultimately lends itself to interoperability. The idea that research can move further and faster as we un-silo these fantastic resources is an achievable one. This paper investigates the steps that existing repositories need to take in order to remain useful and relevant in a FAIR research world.},
  archive      = {J_DINT},
  author       = {Hahnel, Mark and Valen, Dan},
  doi          = {10.1162/dint_a_00041},
  journal      = {Data Intelligence},
  number       = {1-2},
  pages        = {192-198},
  shortjournal = {Data Intell.},
  title        = {How to (Easily) extend the FAIRness of existing repositories},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Ontology, ontologies and the “i” of FAIR. <em>DINT</em>,
<em>2</em>(1-2), 181–191. (<a
href="https://doi.org/10.1162/dint_a_00040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. According to the FAIR guiding principles, one of the central attributes for maximizing the added value of information artifacts is interoperability. In this paper, I discuss the importance, and propose a characterization of the notion of Semantic Interoperability. Moreover, I show that a direct consequence of this view is that Semantic Interoperability cannot be achieved without the support of, on one hand, (i) ontologies, as meaning contracts capturing the conceptualizations represented in information artifacts and, on the other hand, of (ii) Ontology, as a discipline proposing formal meth- ods and theories for clarifying these conceptualizations and articulating their representations. In particular, I discuss the fundamental role of formal ontological theories (in the latter sense) to properly ground the construction of representation languages, as well as methodological and computational tools for supporting the engineering of ontologies (in the former sense) in the context of FAIR.},
  archive      = {J_DINT},
  author       = {Guizzardi, Giancarlo},
  doi          = {10.1162/dint_a_00040},
  journal      = {Data Intelligence},
  number       = {1-2},
  pages        = {181-191},
  shortjournal = {Data Intell.},
  title        = {Ontology, ontologies and the “I” of FAIR},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The FAIR funding model: Providing a framework for research
funders to drive the transition toward FAIR data management and
stewardship practices. <em>DINT</em>, <em>2</em>(1-2), 171–180. (<a
href="https://doi.org/10.1162/dint_a_00039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A growing number of research funding organizations (RFOs) are taking responsibility to increase the scientific and social impact of research output. Also reusable research data are recognized as relevant output for gaining impact. RFOs are therefore promoting FAIR research data management and stewardship (RDM) in their research funding cycle. However, the implementation of FAIR RDM still faces important obstacles and challenges. To solve these, stakeholders work together to develop innovative tools and practices. Here we elaborate on the role of RFOs in developing a FAIR funding model to support the FAIR RDM in the funding cycle, integrated with research community specific guidance, criteria and metadata, and enabling automatic assessments of progress and output from RDM. The model facilitates to create research data with a high level of FAIRness that are meaningful for a research community. To fully benefit from the model, RFOs, research institutions and service providers need to implement machine actionability in their FAIR RDM tools and procedures. As many stakeholders still need to get familiar with “human actionable” FAIR data practices, the introduction of the model will be stepwise, with an active role of the RFOs in driving FAIR RDM processes as effectively as possible.},
  archive      = {J_DINT},
  author       = {Bloemers, Margreet and Montesanti, Annalisa},
  doi          = {10.1162/dint_a_00039},
  journal      = {Data Intelligence},
  number       = {1-2},
  pages        = {171-180},
  shortjournal = {Data Intell.},
  title        = {The FAIR funding model: Providing a framework for research funders to drive the transition toward FAIR data management and stewardship practices},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). FAIR convergence matrix: Optimizing the reuse of existing
FAIR-related resources. <em>DINT</em>, <em>2</em>(1-2), 158–170. (<a
href="https://doi.org/10.1162/dint_a_00038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The FAIR principles articulate the behaviors expected from digital artifacts that are Findable, Accessible, Interoperable and Reusable by machines and by people. Although by now widely accepted, the FAIR Principles by design do not explicitly consider actual implementation choices enabling FAIR behaviors. As different communities have their own, often well-established implementation preferences and priorities for data reuse, coordinating a broadly accepted, widely used FAIR implementation approach remains a global challenge. In an effort to accelerate broad community convergence on FAIR implementation options, the GO FAIR community has launched the development of the FAIR Convergence Matrix. The Matrix is a platform that compiles for any community of practice, an inventory of their self-declared FAIR implementation choices and challenges. The Convergence Matrix is itself a FAIR resource, openly available, and encourages voluntary participation by any self-identified community of practice (not only the GO FAIR Implementation Networks). Based on patterns of use and reuse of existing resources, the Convergence Matrix supports the transparent derivation of strategies that optimally coordinate convergence on standards and technologies in the emerging Internet of FAIR Data and Services.},
  archive      = {J_DINT},
  author       = {Sustkova, Hana Pergl and Hettne, Kristina Maria and Wittenburg, Peter and Jacobsen, Annika and Kuhn, Tobias and Pergl, Robert and Slifka, Jan and McQuilton, Peter and Magagna, Barbara and Sansone, Susanna-Assunta and Stocker, Markus and Imming, Melanie and Lannom, Larry and Musen, Mark and Schultes, Erik},
  doi          = {10.1162/dint_a_00038},
  journal      = {Data Intelligence},
  number       = {1-2},
  pages        = {158-170},
  shortjournal = {Data Intell.},
  title        = {FAIR convergence matrix: Optimizing the reuse of existing FAIR-related resources},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Helping the consumers and producers of standards,
repositories and policies to enable FAIR data. <em>DINT</em>,
<em>2</em>(1-2), 151–157. (<a
href="https://doi.org/10.1162/dint_a_00037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Thousands of community-developed (meta)data guidelines, models, ontologies, schemas and formats have been created and implemented by several thousand data repositories and knowledge-bases, across all disciplines. These resources are necessary to meet government, funder and publisher expectations of greater transparency and access to and preservation of data related to research publications. This obligates researchers to ensure their data is FAIR, share their data using the appropriate standards, store their data in sustainable and community-adopted repositories, and to conform to funder and publisher data policies. FAIR data sharing also plays a key role in enabling researchers to evaluate, re-analyse and reproduce each other&#39;s work. We can map the landscape of relationships between community-adopted standards and repositories, and the journal publisher and funder data policies that recommend their use. In this paper, we show how the work of the GO-FAIR FAIR Standards, Repositories and Policies (StRePo) Implementation Network serves as a central integration and cross-fertilisation point for the reuse of FAIR standards, repositories and data policies in general. Pivotal to this effort, the FAIRsharing, an endorsed flagship resource of the Research Data Alliance that maps the landscape of relationships between community-adopted standards and repositories, and the journal publisher and funder data policies that recommend their use. Lastly, we highlight a number of activities around FAIR tools, services and educational efforts to raise awareness and encourage participation.},
  archive      = {J_DINT},
  author       = {McQuilton, Peter and Batista, Dominique and Beyan, Oya and Granell, Ramon and Coles, Simon and Izzo, Massimiliano and Lister, Allyson L. and Pergl, Robert and Rocca-Serra, Philippe and Schaap, Ben and Shanahan, Hugh and Thurston, Milo and Sansone, Susanna-Assunta},
  doi          = {10.1162/dint_a_00037},
  journal      = {Data Intelligence},
  number       = {1-2},
  pages        = {151-157},
  shortjournal = {Data Intell.},
  title        = {Helping the consumers and producers of standards, repositories and policies to enable FAIR data},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Growing the FAIR community at the intersection of the
geosciences and pure and applied chemistry. <em>DINT</em>,
<em>2</em>(1-2), 139–150. (<a
href="https://doi.org/10.1162/dint_a_00036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The geoscience and chemistry communities have numerous common practices and dependency on data standards. Recent efforts from the International Union on Pure and Applied Chemistry (IUPAC) and the American Geophysical Union (AGU) are to explore and collaborate on approaches and sharing lessons learned on efforts to implement the FAIR Guiding Principles as they apply to data in their respective communities. This paper summarizes their efforts-to-date highlighting the importance of existing communities, Scientific Unions, standards bodies and societies in taking deliberate steps to move and encourage researcher adoption of the FAIR tenets.},
  archive      = {J_DINT},
  author       = {Stall, Shelley and McEwen, Leah and Wyborn, Lesley and Hoebelheinrich, Nancy and Bruno, Ian},
  doi          = {10.1162/dint_a_00036},
  journal      = {Data Intelligence},
  number       = {1-2},
  pages        = {139-150},
  shortjournal = {Data Intell.},
  title        = {Growing the FAIR community at the intersection of the geosciences and pure and applied chemistry},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Taking FAIR on the ChIN: The chemistry implementation
network. <em>DINT</em>, <em>2</em>(1-2), 131–138. (<a
href="https://doi.org/10.1162/dint_a_00035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The Chemistry Implementation Network (ChIN) is focused on supporting the FAIR Data needs of the research community regarding chemical related data. An Implementation Network is a consortium drawn from a community, in this case the chemistry discipline, committed to defining and constructing standards, materials and software in the spirit of the FAIR data principles and under the structure of the GO FAIR project. Furthermore, as a core science the ChIN has to reach beyond the chemistry community and support the use of chemical information in other disciplines. This will be facilitated through connections in the GO FAIR ecosystem of Implementation Networks. Examples of the FAIR chemical concepts that need to be supported include molecular and materials structures, chemical reactions, nomenclature and other chemical terminology and conventions. The ChIN aims to drive forward the application of the FAIR Data Principles relating to the full range of chemistry concepts that are key to the transparent and efficient communication of chemical information. Realizing the goal of FAIR chemistry data will require a culture change across the discipline. However this is best addressed once a critical mass of tools and approaches has been developed.},
  archive      = {J_DINT},
  author       = {Coles, Simon J. and Frey, Jeremy G. and Willighagen, Egon L. and Chalk, Stuart J.},
  doi          = {10.1162/dint_a_00035},
  journal      = {Data Intelligence},
  number       = {1-2},
  pages        = {131-138},
  shortjournal = {Data Intell.},
  title        = {Taking FAIR on the ChIN: The chemistry implementation network},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). FAIR data and services in biodiversity science and
geoscience. <em>DINT</em>, <em>2</em>(1-2), 122–130. (<a
href="https://doi.org/10.1162/dint_a_00034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We examine the intersection of the FAIR principles (Findable, Accessible, Interoperable and Reusable), the challenges and opportunities presented by the aggregation of widely distributed and heterogeneous data about biological and geological specimens, and the use of the Digital Object Architecture (DOA) data model and components as an approach to solving those challenges that offers adherence to the FAIR principles as an integral characteristic. This approach will be prototyped in the Distributed System of Scientific Collections (DiSSCo) project, the pan-European Research Infrastructure which aims to unify over 110 natural science collections across 21 countries. We take each of the FAIR principles, discuss them as requirements in the creation of a seamless virtual collection of bio/geo specimen data, and map those requirements to Digital Object components and facilities such as persistent identification, extended data typing, and the use of an additional level of abstraction to normalize existing heterogeneous data structures. The FAIR principles inform and motivate the work and the DO Architecture provides the technical vision to create the seamless virtual collection vitally needed to address scientific questions of societal importance.},
  archive      = {J_DINT},
  author       = {Lannom, Larry and Koureas, Dimitris and Hardisty, Alex R.},
  doi          = {10.1162/dint_a_00034},
  journal      = {Data Intelligence},
  number       = {1-2},
  pages        = {122-130},
  shortjournal = {Data Intell.},
  title        = {FAIR data and services in biodiversity science and geoscience},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). FAIR computational workflows. <em>DINT</em>,
<em>2</em>(1-2), 108–121. (<a
href="https://doi.org/10.1162/dint_a_00033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Computational workflows describe the complex multi-step methods that are used for data collection, data preparation, analytics, predictive modelling, and simulation that lead to new data products. They can inherently contribute to the FAIR data principles: by processing data according to established metadata; by creating metadata themselves during the processing of data; and by tracking and recording data provenance. These properties aid data quality assessment and contribute to secondary data usage. Moreover, workflows are digital objects in their own right. This paper argues that FAIR principles for workflows need to address their specific nature in terms of their composition of executable software steps, their provenance, and their development.},
  archive      = {J_DINT},
  author       = {Goble, Carole and Cohen-Boulakia, Sarah and Soiland-Reyes, Stian and Garijo, Daniel and Gil, Yolanda and Crusoe, Michael R. and Peters, Kristian and Schober, Daniel},
  doi          = {10.1162/dint_a_00033},
  journal      = {Data Intelligence},
  number       = {1-2},
  pages        = {108-121},
  shortjournal = {Data Intell.},
  title        = {FAIR computational workflows},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Distributed analytics on sensitive medical data: The
personal health train. <em>DINT</em>, <em>2</em>(1-2), 96–107. (<a
href="https://doi.org/10.1162/dint_a_00032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In recent years, as newer technologies have evolved around the healthcare ecosystem, more and more data have been generated. Advanced analytics could power the data collected from numerous sources, both from healthcare institutions, or generated by individuals themselves via apps and devices, and lead to innovations in treatment and diagnosis of diseases; improve the care given to the patient; and empower citizens to participate in the decision-making process regarding their own health and well-being. However, the sensitive nature of the health data prohibits healthcare organizations from sharing the data. The Personal Health Train (PHT) is a novel approach, aiming to establish a distributed data analytics infrastructure enabling the (re)use of distributed healthcare data, while data owners stay in control of their own data. The main principle of the PHT is that data remain in their original location, and analytical tasks visit data sources and execute the tasks. The PHT provides a distributed, flexible approach to use data in a network of participants, incorporating the FAIR principles. It facilitates the responsible use of sensitive and/or personal data by adopting international principles and regulations. This paper presents the concepts and main components of the PHT and demonstrates how it complies with FAIR principles.},
  archive      = {J_DINT},
  author       = {Beyan, Oya and Choudhury, Ananya and van Soest, Johan and Kohlbacher, Oliver and Zimmermann, Lukas and Stenzhorn, Holger and Karim, Md. Rezaul and Dumontier, Michel and Decker, Stefan and da Silva Santos, Luiz Olavo Bonino and Dekker, Andre},
  doi          = {10.1162/dint_a_00032},
  journal      = {Data Intelligence},
  number       = {1-2},
  pages        = {96-107},
  shortjournal = {Data Intell.},
  title        = {Distributed analytics on sensitive medical data: The personal health train},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Making FAIR easy with FAIR tools: From creolization to
convergence. <em>DINT</em>, <em>2</em>(1-2), 87–95. (<a
href="https://doi.org/10.1162/dint_a_00031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Since their publication in 2016 we have seen a rapid adoption of the FAIR principles in many scientific disciplines where the inherent value of research data and, therefore, the importance of good data management and data stewardship, is recognized. This has led to many communities asking “What is FAIR?” and “How FAIR are we currently?”, questions which were addressed respectively by a publication revisiting the principles and the emergence of FAIR metrics. However, early adopters of the FAIR principles have already run into the next question: “How can we become (more) FAIR?” This question is more difficult to answer, as the principles do not prescribe any specific standard or implementation. Moreover, there does not yet exist a mature ecosystem of tools, platforms and standards to support human and machine agents to manage, produce, publish and consume FAIR data in a user-friendly and efficient (i.e., “easy”) way. In this paper we will show, however, that there are already many emerging examples of FAIR tools under development. This paper puts forward the position that we are likely already in a creolization phase where FAIR tools and technologies are merging and combining, before converging in a subsequent phase to solutions that make FAIR feasible in daily practice.},
  archive      = {J_DINT},
  author       = {Thompson, Mark and Burger, Kees and Kaliyaperumal, Rajaram and Roos, Marco and da Silva Santos, Luiz Olavo Bonino},
  doi          = {10.1162/dint_a_00031},
  journal      = {Data Intelligence},
  number       = {1-2},
  pages        = {87-95},
  shortjournal = {Data Intell.},
  title        = {Making FAIR easy with FAIR tools: From creolization to convergence},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). FAIR data reuse – the path through data citation.
<em>DINT</em>, <em>2</em>(1-2), 78–86. (<a
href="https://doi.org/10.1162/dint_a_00030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. One of the key goals of the FAIR guiding principles is defined by its final principle – to optimize data sets for reuse by both humans and machines. To do so, data providers need to implement and support consistent machine readable metadata to describe their data sets. This can seem like a daunting task for data providers, whether it is determining what level of detail should be provided in the provenance metadata or figuring out what common shared vocabularies should be used. Additionally, for existing data sets it is often unclear what steps should be taken to enable maximal, appropriate reuse. Data citation already plays an important role in making data findable and accessible, providing persistent and unique identifiers plus metadata on over 16 million data sets. In this paper, we discuss how data citation and its underlying infrastructures, in particular associated metadata, provide an important pathway for enabling FAIR data reuse.},
  archive      = {J_DINT},
  author       = {Groth, Paul and Cousijn, Helena and Clark, Tim and Goble, Carole},
  doi          = {10.1162/dint_a_00030},
  journal      = {Data Intelligence},
  number       = {1-2},
  pages        = {78-86},
  shortjournal = {Data Intell.},
  title        = {FAIR data reuse – the path through data citation},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Ontology-based access control for FAIR data. <em>DINT</em>,
<em>2</em>(1-2), 66–77. (<a
href="https://doi.org/10.1162/dint_a_00029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper focuses on fine-grained, secure access to FAIR data, for which we propose ontology-based data access policies. These policies take into account both the FAIR aspects of the data relevant to access (such as provenance and licence), expressed as metadata, and additional metadata describing users. With this tripartite approach (data, associated metadata expressing FAIR information, and additional metadata about users), secure and controlled access to object data can be obtained. This yields a security dimension to the “A” (accessible) in FAIR, which is clearly needed in domains like security and intelligence. These domains need data to be shared under tight controls, with widely varying individual access rights. In this paper, we propose an approach called Ontology-Based Access Control (OBAC), which utilizes concepts and relations from a data set&#39;s domain ontology. We argue that ontology-based access policies contribute to data reusability and can be reconciled with privacy-aware data access policies. We illustrate our OBAC approach through a proof-of-concept and propose that OBAC to be adopted as a best practice for access management of FAIR data.},
  archive      = {J_DINT},
  author       = {Brewster, Christopher and Nouwt, Barry and Raaijmakers, Stephan and Verhoosel, Jack},
  doi          = {10.1162/dint_a_00029},
  journal      = {Data Intelligence},
  number       = {1-2},
  pages        = {66-77},
  shortjournal = {Data Intell.},
  title        = {Ontology-based access control for FAIR data},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A generic workflow for the data FAIRification process.
<em>DINT</em>, <em>2</em>(1-2), 56–65. (<a
href="https://doi.org/10.1162/dint_a_00028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The FAIR guiding principles aim to enhance the Findability, Accessibility, Interoperability and Reusability of digital resources such as data, for both humans and machines. The process of making data FAIR (“FAIRification”) can be described in multiple steps. In this paper, we describe a generic step-by-step FAIRification workflow to be performed in a multidisciplinary team guided by FAIR data stewards. The FAIRification workflow should be applicable to any type of data and has been developed and used for “Bring Your Own Data” (BYOD) workshops, as well as for the FAIRification of e.g., rare diseases resources. The steps are: 1) identify the FAIRification objective, 2) analyze data, 3) analyze metadata, 4) define semantic model for data (4a) and metadata (4b), 5) make data (5a) and metadata (5b) linkable, 6) host FAIR data, and 7) assess FAIR data. For each step we describe how the data are processed, what expertise is required, which procedures and tools can be used, and which FAIR principles they relate to.},
  archive      = {J_DINT},
  author       = {Jacobsen, Annika and Kaliyaperumal, Rajaram and da Silva Santos, Luiz Olavo Bonino and Mons, Barend and Schultes, Erik and Roos, Marco and Thompson, Mark},
  doi          = {10.1162/dint_a_00028},
  journal      = {Data Intelligence},
  number       = {1-2},
  pages        = {56-65},
  shortjournal = {Data Intell.},
  title        = {A generic workflow for the data FAIRification process},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The “a” of FAIR – as open as possible, as closed as
necessary. <em>DINT</em>, <em>2</em>(1-2), 47–55. (<a
href="https://doi.org/10.1162/dint_a_00027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In order to provide responsible access to health data by reconciling benefits of data sharing with privacy rights and ethical and regulatory requirements, Findable, Accessible, Interoperable and Reusable (FAIR) metadata should be developed. According to the H2020 Program Guidelines on FAIR Data, data should be “as open as possible and as closed as necessary”, “open” in order to foster the reusability and to accelerate research, but at the same time they should be “closed” to safeguard the privacy of the subjects. Additional provisions on the protection of natural persons with regard to the processing of personal data have been endorsed by the European General Data Protection Regulation (GDPR), Reg (EU) 2016/679, that came into force in May 2018. This work aims to solve accessibility problems related to the protection of personal data in the digital era and to achieve a responsible access to and responsible use of health data. We strongly suggest associating each data set with FAIR metadata describing both the type of data collected and the accessibility conditions by considering data protection obligations and ethical and regulatory requirements. Finally, an existing FAIR infrastructure component has been used as an example to explain how FAIR metadata could facilitate data sharing while ensuring protection of individuals.},
  archive      = {J_DINT},
  author       = {Landi, Annalisa and Thompson, Mark and Giannuzzi, Viviana and Bonifazi, Fedele and Labastida, Ignasi and da Silva Santos, Luiz Olavo Bonino and Roos, Marco},
  doi          = {10.1162/dint_a_00027},
  journal      = {Data Intelligence},
  number       = {1-2},
  pages        = {47-55},
  shortjournal = {Data Intell.},
  title        = {The “A” of FAIR – as open as possible, as closed as necessary},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Making data and workflows findable for machines.
<em>DINT</em>, <em>2</em>(1-2), 40–46. (<a
href="https://doi.org/10.1162/dint_a_00026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Research data currently face a huge increase of data objects with an increasing variety of types (data types, formats) and variety of workflows by which objects need to be managed across their lifecycle by data infrastructures. Researchers desire to shorten the workflows from data generation to analysis and publication, and the full workflow needs to become transparent to multiple stakeholders, including research administrators and funders. This poses challenges for research infrastructures and user-oriented data services in terms of not only making data and workflows findable, accessible, interoperable and reusable, but also doing so in a way that leverages machine support for better efficiency. One primary need to be addressed is that of findability, and achieving better findability has benefits for other aspects of data and workflow management. In this article, we describe how machine capabilities can be extended to make workflows more findable, in particular by leveraging the Digital Object Architecture, common object operations and machine learning techniques.},
  archive      = {J_DINT},
  author       = {Weigel, Tobias and Schwardmann, Ulrich and Klump, Jens and Bendoukha, Sofiane and Quick, Robert},
  doi          = {10.1162/dint_a_00026},
  journal      = {Data Intelligence},
  number       = {1-2},
  pages        = {40-46},
  shortjournal = {Data Intell.},
  title        = {Making data and workflows findable for machines},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Unique, persistent, resolvable: Identifiers as the
foundation of FAIR. <em>DINT</em>, <em>2</em>(1-2), 30–39. (<a
href="https://doi.org/10.1162/dint_a_00025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The FAIR principles describe characteristics intended to support access to and reuse of digital artifacts in the scientific research ecosystem. Persistent, globally unique identifiers, resolvable on the Web, and associated with a set of additional descriptive metadata, are foundational to FAIR data. Here we describe some basic principles and exemplars for their design, use and orchestration with other system elements to achieve FAIRness for digital research objects.},
  archive      = {J_DINT},
  author       = {Juty, Nick and Wimalaratne, Sarala M. and Soiland-Reyes, Stian and Kunze, John and Goble, Carole A. and Clark, Tim},
  doi          = {10.1162/dint_a_00025},
  journal      = {Data Intelligence},
  number       = {1-2},
  pages        = {30-39},
  shortjournal = {Data Intell.},
  title        = {Unique, persistent, resolvable: Identifiers as the foundation of FAIR},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). FAIR principles: Interpretations and implementation
considerations. <em>DINT</em>, <em>2</em>(1-2), 10–29. (<a
href="https://doi.org/10.1162/dint_r_00024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The FAIR principles have been widely cited, endorsed and adopted by a broad range of stakeholders since their publication in 2016. By intention, the 15 FAIR guiding principles do not dictate specific technological implementations, but provide guidance for improving Findability, Accessibility, Interoperability and Reusability of digital resources. This has likely contributed to the broad adoption of the FAIR principles, because individual stakeholder communities can implement their own FAIR solutions. However, it has also resulted in inconsistent interpretations that carry the risk of leading to incompatible implementations. Thus, while the FAIR principles are formulated on a high level and may be interpreted and implemented in different ways, for true interoperability we need to support convergence in implementation choices that are widely accessible and (re)-usable. We introduce the concept of FAIR implementation considerations to assist accelerated global participation and convergence towards accessible, robust, widespread and consistent FAIR implementations. Any self-identified stakeholder community may either choose to reuse solutions from existing implementations, or when they spot a gap, accept the challenge to create the needed solution, which, ideally, can be used again by other communities in the future. Here, we provide interpretations and implementation considerations (choices and challenges) for each FAIR principle.},
  archive      = {J_DINT},
  author       = {Jacobsen, Annika and de Miranda Azevedo, Ricardo and Juty, Nick and Batista, Dominique and Coles, Simon and Cornet, Ronald and Courtot, Mélanie and Crosas, Mercè and Dumontier, Michel and Evelo, Chris T. and Goble, Carole and Guizzardi, Giancarlo and Hansen, Karsten Kryger and Hasnain, Ali and Hettne, Kristina and Heringa, Jaap and Hooft, Rob W.W. and Imming, Melanie and Jeffery, Keith G. and Kaliyaperumal, Rajaram and Kersloot, Martijn G. and Kirkpatrick, Christine R. and Kuhn, Tobias and Labastida, Ignasi and Magagna, Barbara and McQuilton, Peter and Meyers, Natalie and Montesanti, Annalisa and van Reisen, Mirjam and Rocca-Serra, Philippe and Pergl, Robert and Sansone, Susanna-Assunta and da Silva Santos, Luiz Olavo Bonino and Schneider, Juliane and Strawn, George and Thompson, Mark and Waagmeester, Andra and Weigel, Tobias and Wilkinson, Mark D. and Willighagen, Egon L. and Wittenburg, Peter and Roos, Marco and Mons, Barend and Schultes, Erik},
  doi          = {10.1162/dint_r_00024},
  journal      = {Data Intelligence},
  number       = {1-2},
  pages        = {10-29},
  shortjournal = {Data Intell.},
  title        = {FAIR principles: Interpretations and implementation considerations},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The FAIR principles: First generation implementation choices
and challenges. <em>DINT</em>, <em>2</em>(1-2), 1–9. (<a
href="https://doi.org/10.1162/dint_e_00023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {“FAIR enough”?… A question asked on a daily basis in the rapidly evolving field of open science and the underpinning data stewardship profession. After the publication of the FAIR principles in 2016, they have sparked theoretical debates, but some communities have already begun to implement FAIR-guided data and services. No-one really argues against the idea that data, as well as the accompanying workflows and services should be findable, accessible under well-defined conditions, interoperable without data munging, and thus optimally reusable. Being FAIR is not a goal in itself; FAIR Data and Services are needed to enable data intensive research and innovation and (thus) have to be “AI-ready①“ (= future proof for machines to optimally assist us). However, the fact that science and innovation becomes increasingly “machine-assisted” and hence the central role of machines, is still overlooked in some cases when people claim to implement FAIR.The FAIR guiding principles are exactly that; a guide to create reusable research objects. FAIR is not a new standard; is not a top down requirement; is not an all-or-nothing binary state (FAIR or not FAIR). The FAIR principles were conceived and designed as a resource for optimal choices to be made during many aspects of data and tool generation as well as (re)use and long term stewardship. They serve the purpose of guiding implementation considerations on our journey to machine-assisted research and innovation. Therefore this special issue of the Data Intelligence journal is dedicated to practical first generation implementation choices that are being made by communities of practice, relevant for the FAIR status of data and accompanying tooling. This issue also features “opinion articles” that address challenges encountered or anticipated along the implementation trajectory of FAIR for which there are no ready-tore-use solutions. These early examples and visionary discussions may inspire the further development of interoperable approaches by various early mover communities, who are convinced that both data and services (including tooling) should be FAIR to enable the envisioned Internet of FAIR Data and Services (IFDS) [1]. This is all “early stage”, because the FAIR principles were published in their current form only in March 2016 [2]. The FAIR principles did not mark a major new insight, but were rather a consolidation and a comprehensive rephrasing of a series of earlier foundational and pioneering approaches (some decades in the making) to move toward a machine-friendly research infrastructure. Several papers in this issue make this point in historical context [3,4,5].Why then is it that the FAIR acronym so rapidly sparked the discussions at the domain sciences level, got wide recognition at the policy level [6], among funders [7], repositories [8] and not only in Europe and the USA, but also in Africa [9], Latin America [10], and China [11,12]? There may be two important differences with earlier efforts. First, after the inception of the FAIR principles in January 2014 at the Lorentz workshop in Leiden, The Netherlands②, the principles where initially posted at the FORCE11 website for community comments③ and subsequently published in Scientific Data in March 2016 [2]. The article apparently “hit a chord” and was massively read, tweeted, discussed in blogs and cited [see box below].In addition to a sticky acronym, we strongly believe that the inception of the FAIR principles at the Lorentz workshop in Leiden (January 2014) marked a natural tipping point, also caused by the very visible discussions in the scope of the European Open Science Cloud preparations [1], which again lead to an “attraction phase” toward a common approach as described for many other major infrastructures [13].In a recent student-led survey, referenced in this issue [14], it was shown that 80\% of the papers citing the original FAIR paper, actually deal with practical implementations. This indicates that, next to the “political hype” caused by the acronym, a growing number of organizations and communities have actually attempted to forge technical implementation choices that adhere to the FAIR guiding principles. Some of them are described in this issue, but there are many more that can be found in the literature④. The implementations are apparently emerging in the entire spectrum of science and innovation domains and include life sciences (notably biomedicine and health, biodiversity and agriculture), nuclear energy, climate change, ocean research, humanities, economics, space science and mineralogy and many more. Furthermore, data science related implementations are also numerous, such as ontology mapping, machine learning algorithms, ontology-based access protocols, automation technology, annotation and curation, and many aspects practiced in the emerging profession of data stewardship in data competence centers in institutions all over the world [15]. Unfortunately, 80\% of the citations so far are from Europe and USA [14]. It is very encouraging though, that this issue reports on strong FAIR related activities, not only in Europe [5] and USA [16], but also in Africa [9] and Latin America [10]. Moreover, international organizations such as Research Data Alliance (RDA) [5], The Committee on Data for Science and Technology (CODATA) [17,18], European Strategy Forum on Research Infrastructures (ESFRI) [4] and scientific unions such as AGU [15] and IUPAC [18] are leading their domain communities toward more mature FAIR choices and infrastructures. Ever since the publication of the FAIR principles, they have sparked converging initiatives such as GO FAIR⑤ and strong collaborations between GO FAIR and other international data related initiatives including the Commission on Data of the International Science Council (ISC&#39;s CODATA⑥), it&#39;s World Data System⑦, and the Research Data Alliance (RDA)⑧. Based on all the above it is likely that well over 1,000 communities of practice already work on some implementation aspects guided by the FAIR principles (i.e., 80\% of &amp;gt; 1,600 written articles citing the FAIR principles paper [2]).So, what does “being FAIR enough” actually mean? First of all, this will vary widely for different communities and domains and will be ultimately decided by the communities of practice that adopt policies supporting machine-actionable data, that aim to “de-silo” and that strive to overcome disciplinary boundaries.Still, in this very early implementation phase there has also been quite some confusion and anxiety about what the FAIR principles actually cover. As a result several “additional acronym letters” have been proposed, even in some early draft articles for this issue. So far, all of these proposed changes could be resolved without changing the powerful acronym, because they could either be classified as a specific “implementation choice” [19] or because they were “beyond FAIR” [20]⑨ since they addressed issues that, “by design”, the FAIR principles do not cover, such as ethics, privacy, reproducibility, data or software quality per se. Many of these very important aspects are implicitly related to findability of software and data, their accessibility, interoperability and therefore the ability to reuse these research objects, but they should not be conflated with the FAIR principles themselves. These were designed to strictly cover the inherent machine-FAIRness of data and services. In that sense, even the fabrication of fake data, making them FAIR and publishing them in a Core Trust Seal Repository⑩ would not violate the principles, especially when the metadata indicate that the data are fabricated, for example a machine learning (ML) training-set. Conversely, putting high quality data in a mediocre repository can not be prevented by the principles as such, although obviously, when the only repository in which data or code was published is offline or not findable for other reasons, the FAIR principles are not properly followed. Abuse of the FAIR acronym is related to specific, and stakeholder defined, implementations, and some of them tangentially addressed by the FAIR principles and others not.In this issue [19], the original conception of the FAIR principles and what they are intended to cover is explained in detail. In an attempt to narrow down to the essence of what the original composers of the FAIR guiding principles had in mind, we would like to introduce an even higher level of abstraction than the principles themselves: the trigger for so much international attention for better data stewardship and Open Science is likely correlated to the data explosion we have created through ever increasing automation and instrumentation advances. It follows that we need “machines”, both as creators of data and as analytical assistants, all the time: we better make them as efficient and collaborative as possible. So at their very core, the FAIR guiding principles should lead us to ensure that “Machines know what it means“. Obviously, this does not (yet) take people out of the loop. In fact the envisioned Internet of FAIR Data and Services [1] should be an environment where our implementation choices support both machines and humans, in a tight and iterative collaboration (i.e., “Social Machines” [21] are the end users).Open Science is in fact a new way of doing and communicating science with an emphasis on reusability of data and the accompanying analytics, not only by other researchers, but ostensibly also by machines. Hence the one-liner that captures the essence of the FAIR principles is “Machines know what it means”. So, do we trivialize the role of humans in science and innovation? On the contrary; publishing our major research output (data, software tools, derived information and major scientific conclusions and claims) in FAIR format, will enable computers to “also” output the relevant information in precise, human-digestible formats, meanwhile mitigating ambiguity introduced by natural language, and effectively even crossing jargon, ontological false agreements and false disagreements [22], and ultimately even natural language barriers. It should also be emphasized that “data” should always be published with supplementary narrative for humans to judge and evaluate the data and information we provide in machine readable and actionable formats [23].Human prosaic narrative, graphical figures and tables and most supplementary data, in the formats we have used for scholarly communication for centuries, are “a nightmare for machines” and therefore intrinsically, in their native form, do not comply with FAIR principles, which obviously does not make them useless for human reuse. The good news is that precise scientific claims in legacy text as well as the supporting data can be transformed into FAIR formats with increasing relative ease. Human readable text, tables and figures for human intellectual consumption can also increasingly be produced by machines, for instance from relational databases to RDF and vice versa [24]. Supporting both machines and humans in their collaborative work is therefore the major contribution the FAIR guiding principles are supposed to make to 21st century research an innovation throughout the world. An important notion is also that research objects that are not “digital” or otherwise are not machine interpretable, such as geological and biological specimens, analogue pictures, PDFs and the like, can nonetheless always be adorned with FAIR metadata creating a “digital twin” [3,5]. In this context, beyond the original coining of the term by Michael Grieves in 2002 [25], we see a “digital twin” of a non-digital research object as a set of machine-readable metadata and instructions that allow machines to detect and resolve to the location of the object via its unique identifier [26] make the best possible interpretation of what the object is, what operations on it are technically possible and what is allowed to be done with the digital objects in the twin. The actual research object can be anything from a molecule to a packaged data and workflow object [27] to one of the 3 billion biological specimens in natural history museums [3], to citizens in the FAIR driven research and care environments such as the Personal Health Train [28]. FAIR digital objects, sometimes pointing to other digital objects and sometimes to objects in the physical world, thus form the basic substrate for machine-assisted science and innovation.In the first series of 15 articles in this special issue we have bundled a relevant set of “first generation” implementations and emerging practices in the context of FAIR. These are followed by 12 articles that focus more on gaps in existing technology and practice encountered or envisioned and offer opinion and propose directional solutions for the relevant communities to develop FAIR guided approaches. The Implementation Articles cover the overall protocols and operations to enable efficient handling of FAIR Digital Objects in the Internet and Web environments. The very first requirement being that each FAIR Digital Object has its own Unique, Persistent, Resolvable Identifier [26]. Machines subsequently need instructions and workflows, and these can and should be FAIR themselves to effectively participate in the Internet of FAIR Data and Services [27]. Next to that, data, even when they can not be Open Access without restrictions and as “closed off” as necessary, can nevertheless be FAIR [29]. For all research objects, restricted in use or not, there is a need for machines to independently access the data and “understand” what kind of (machine and human) operations are possible and allowed [30]. The actual reuse of the data is subsequently always subject to a user license, however liberal [31]. This is for instance critical for industrial use of data, as data and other research objects that have not been properly licensed is viewed as having uncertain legal liability, and thus cannot be easily reused by industry [32]. A very important aspect of the wide acceptance of FAIR data as a first class research output is that data are properly (indeed, automatically) cited upon reuse. Technologies to make effective and scalable data citation possible are in their early stages, but they will soon be well established [33]. A number of pioneering domain specific implementation efforts and choices to help make data and metadata FAIR are also emerging [34]. In addition, tools that enable planning of FAIR compliant metadata files and data management and stewardship plans are being developed and tested [35], and increasingly these interact with tools that expose FAIR standards in dedicated FAIR repositories to stimulate reuse [36]. As stated earlier, FAIR data alone remain a lame substrate, unless there are FAIR data consuming workflows, that in the Internet of FAIR Data and Services should be developed according to FAIR principles themselves, which poses a whole additional set of choices and challenges [37]. The “implementation section” is completed by a set of articles that describe how the various choices impact their own and potentially other disciplines, such as sensitive personal health data [28], data describing physical objects rather than digital objects, such as in biodiversity collections, biobanks and geosciences [3], and a massive cross-cutting domain such as chemistry [18]. In all these areas there are different, but also overlapping legal aspects associated with the reuse of data and workflows that should be addressed when publishing data and code for reuse [38]. Once all these decisions have been made, a final, and very important decision for FAIR-oriented researchers and data stewards is actually “Where to publish and archive my data with maximum chance of proper reuse”? This means that also data repositories should consider the aspects of FAIR metadata and the data collections themselves and how they can support long term reuse and preservation [35]. Finally it is very important to develop tooling that, as objectively as possible, can measure the maturity of FAIRness of digital resources [19,20 &amp;amp; footnotes 6–9] clearly demonstrating that FAIR is not a “binary” status, but an aspiration to move from scholarly communication assets that are “re-useless” for machines toward increasingly machine-actionable elements of an emerging Internet of FAIR Data and Services [33].Finally, we realized early on that FAIR should not, and will not be, exclusively an academic exercise. As happened in the Internet as we know it, sooner rather than later, private institutions and industry will (and should) join and much of what we will see happening on the route to the envisioned Internet of FAIR Data and Services will be done in public-private partnerships and in some cases scaled by large industries. It is important that at such an early stage, many industrial partners are already highly interested and contributing their views on what their needs are [32]. A balanced development of a professional (indeed, commercial) backbone on which both academic and industrial applications can run, will be as important for the Internet of FAIR Data and Services as it is for the current Internet. Moreover, given the commitments to Open Research and the “long-tail” of technically-rich disciplines participating in the Internet of FAIR Data and Services, the principles of net neutrality and open standards will necessarily feature prominently and irrevocably regardless of the emerging business models.It will be obvious after reading this special issue that FAIR compliant data stewardship will require many different skills that are not traditionally covered by the research curricula of contemporary students and researchers. Therefore, extensive training capacity and training materials are needed, and in need of development. Some academic tools under development have been described in [39], and also commercial training options and in-company FAIR competence centers are being developed [32]. Public research funders [7] as well as data driven private endeavors will increasingly call for proper (and funded) data stewardship plans, not only for research outputs, but also in the data-intensive processes for product approval, legislation and certification [32]. International agreements will be needed on good practices that can form the basis for better, FAIR and Open Science as well as for well documented innovation and production processes. The envisioned Internet of FAIR Data and Services will form a backbone for this future societal innovation and may be of very high impact on human wellbeing and the responsible stewardship of our planet.Thus, this special issue is entirely based on the concept of reusable FAIR digital objects that effectively form “one computer with one data set” as suggested by George Strawn in this issue, and which is distributed over the planet but functionally interconnected and interoperable by FAIR principles, for fair and equal use. This being said, we are fully aware of the limited and lumpy scope of the articles we were able to collect for this issue. Looking forward, the publisher and the co-editors therefore encourage from the community-at-large, additional collections of practical Implementation Choices and recognized Challenges as contributions to what we envision will be a recurring special issue.We are very grateful for so many authors contributing their early FAIR related experiences, choices, perceived challenges, views and practices to this special issue. We hope this is the first in a series of publications in which community-emerging and increasingly endorsed community practices in the FAIR realm will be published at regular intervals to serve conversion and the rapid realization of the Internet of FAIR Data and Services.},
  archive      = {J_DINT},
  author       = {Mons, Barend and Schultes, Erik and Liu, Fenghong and Jacobsen, Annika},
  doi          = {10.1162/dint_e_00023},
  journal      = {Data Intelligence},
  number       = {1-2},
  pages        = {1-9},
  shortjournal = {Data Intell.},
  title        = {The FAIR principles: First generation implementation choices and challenges},
  volume       = {2},
  year         = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
