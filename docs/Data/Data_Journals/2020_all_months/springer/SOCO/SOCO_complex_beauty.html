<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>SOCO_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="soco---1200">SOCO - 1200</h2>
<ul>
<li><details>
<summary>
(2020). Solving technician routing and scheduling problem using
improved particle swarm optimization. <em>SOCO</em>, <em>24</em>(24),
19007–19015. (<a
href="https://doi.org/10.1007/s00500-020-05333-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an improved particle swarm optimization (IPSO) algorithm is proposed to solve the technician routing and scheduling problem (TRSP). The TRSP consists of the assignment of technicians into teams, the assignment of teams to tasks, the construction of routes, and the selection of the day on which a service is provided by considering the proficiency level of workers and the proficiency requirement of the task. The paper considers the planning horizon as a multi-period covering 5 days, which further increases the complexity of the problem. Then a task can be fulfilled in any one of 5 days. The IPSO algorithm includes a particle swarm optimization (PSO) algorithm and one neighborhood operator. One neighborhood operator is used to avoid the local solution trap since the global best solution found by PSO is falling into a local solution trap. Further, the proposed algorithm’s performance is experimentally compared with the branch-and-cut algorithm for the solution of the TRSP, on the benchmark instances generated from the literature. The computational results show that IPSO provides better solutions considering the branch-and-cut algorithm within reasonable computing time.},
  archive      = {J_SOCO},
  author       = {Pekel, Engin},
  doi          = {10.1007/s00500-020-05333-5},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {19007-19015},
  shortjournal = {Soft Comput.},
  title        = {Solving technician routing and scheduling problem using improved particle swarm optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Neural optimal self-constrained computing in smart grid
considering fine-tuning island constraints with visual information.
<em>SOCO</em>, <em>24</em>(24), 18991–19006. (<a
href="https://doi.org/10.1007/s00500-020-05128-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the expansion of the power grid and the acceleration of power information construction, the information communication network covers all aspects and collects accurate information in time to provide continuous and reliable operation for users. The modern power system will gradually enter the era of interconnected power grids. It is more environmentally friendly and efficient than traditional power systems, management is more information and lean, and its operation is safer and more stable. As the infrastructure for carrying smart grid and future energy information interaction, the power communication network has higher and higher requirements for reliability. The coupling between the communication network and the power grid is more and more closely related. The real-time acquisition and the reliable transmission of control information such as the power system require the support of the power communication network. This paper uses machine learning algorithms to learn effective features or patterns from these data and apply them to new data. In this paper, we present a neural optimal self-constrained computing model based on fine-tuning island constraints with visual information. The experimental results show that the proposed algorithm has higher processing efficiency and accuracy.},
  archive      = {J_SOCO},
  author       = {Yuan, Zhi and Wang, Weiqing and He, Shan},
  doi          = {10.1007/s00500-020-05128-8},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18991-19006},
  shortjournal = {Soft Comput.},
  title        = {Neural optimal self-constrained computing in smart grid considering fine-tuning island constraints with visual information},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). HBDCWS: Heuristic-based budget and deadline constrained
workflow scheduling approach for heterogeneous clouds. <em>SOCO</em>,
<em>24</em>(24), 18971–18990. (<a
href="https://doi.org/10.1007/s00500-020-05127-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The predilection of scientific applications toward a high-performance computing system is attained through the emergence of the cloud. Large-scale scientific applications can be modeled as workflows and are scheduled on the cloud. However, such scheduling becomes even more onerous due to the dynamic and heterogeneous nature of cloud and therefore considered as a problem of NP-Complete. The scheduling of workflows is always constrained to QoS parameters. Most of the applications are bound to time and cost, which is observed to be the most crucial parameter. Therefore, in this paper, a heuristic-based budget and deadline constrained workflow scheduling algorithm (HBDCWS) has been proposed to utilize those applications that have the budget and deadline constraints. The novelty of the proposed work is to provide a simple budget and deadline distribution strategy where budget and deadline of workflow are converted to level budget and level deadline. Additionally, the level budget is again transferred to each task. This strategy not only satisfies the given constraints but also proves to be efficient for minimizing the makespan and reducing the cost of execution. Experimental results on several workflows demonstrate that the proposed HBDCWS algorithm finds a feasible solution that accomplishes the given constraints with a higher success rate in most cases.},
  archive      = {J_SOCO},
  author       = {Rizvi, Naela and Ramesh, Dharavath},
  doi          = {10.1007/s00500-020-05127-9},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18971-18990},
  shortjournal = {Soft Comput.},
  title        = {HBDCWS: Heuristic-based budget and deadline constrained workflow scheduling approach for heterogeneous clouds},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Using fuzzy logics to determine optimal oversampling factor
for voxelizing 3D surfaces in radiation therapy. <em>SOCO</em>,
<em>24</em>(24), 18959–18970. (<a
href="https://doi.org/10.1007/s00500-020-05126-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Voxelizing three-dimensional surfaces into binary image volumes is a frequently performed operation in medical applications. In radiation therapy (RT), dose-volume histograms (DVHs) calculated within such surfaces are used to assess the quality of an RT treatment plan in both clinical and research settings. To calculate a DVH, the 3D surfaces need to be voxelized into binary volumes. The voxelization parameters may considerably influence the output DVH. An effective way to improve the quality of the voxelized volume (i.e., increasing similarity between that and the original structure) is to apply oversampling to increase the resolution of the output binary volume. However, increasing the oversampling factor raises computational and storage demand. This paper introduces a fuzzy inference system that determines an optimal oversampling factor based on relative structure size and complexity, finding the balance between voxelization accuracy and computation time. The proposed algorithm was used to automatically calculate oversampling factor in four RT studies: two phantoms and two real patients. The results show that the method is able to find the optimal oversampling factor in most cases, and the calculated DVHs show good match to those calculated using manual overall oversampling of two. The algorithm can potentially be adopted by RT treatment planning systems based on the open-source implementation to maintain high DVH quality, enabling the planning system to find the optimal treatment plan faster and more reliably.},
  archive      = {J_SOCO},
  author       = {Pinter, C. and Olding, T. and Schreiner, L. J. and Fichtinger, G.},
  doi          = {10.1007/s00500-020-05126-w},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18959-18970},
  shortjournal = {Soft Comput.},
  title        = {Using fuzzy logics to determine optimal oversampling factor for voxelizing 3D surfaces in radiation therapy},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Three-value cutting tensors of intuitionistic fuzzy
tensors. <em>SOCO</em>, <em>24</em>(24), 18953–18958. (<a
href="https://doi.org/10.1007/s00500-020-05125-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we first introduce the definition of three-value cutting tensors of intuitionistic fuzzy tensors. Secondly, we discuss some fundamental properties by the definition of the three-value cutting tensors and relationships between elements and discuss the application of three-value cutting tensors in evaluating engineering projects. Finally, we investigate decomposition of intuitionistic fuzzy tensors by three-value cutting tensors under max–min compositional operations. Our numerical examples show the feasibility of the presented decomposition methods.},
  archive      = {J_SOCO},
  author       = {Chen, Ling},
  doi          = {10.1007/s00500-020-05125-x},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18953-18958},
  shortjournal = {Soft Comput.},
  title        = {Three-value cutting tensors of intuitionistic fuzzy tensors},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fixing state change inconsistency with self regulating
particle swarm optimization. <em>SOCO</em>, <em>24</em>(24),
18937–18952. (<a
href="https://doi.org/10.1007/s00500-020-05124-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software has made a profound influence in all walks of life. Developing quality software is a major challenge, and the consistency and completeness of the design has a prime role in the development of quality software. Many a times, the process of consistency checking in industries is manual. Artificial intelligence techniques can replace many of these manual efforts to make the development of software easier and cost-effective. Software developers use state diagrams to represent the dynamic behavior in the design stage. We propose a novel application of self regulating particle swarm optimization (SRPSO) algorithm to ensure consistency of state diagrams during the design phase of software development. Inconsistency management is modeled as an optimization problem. In this work, we detect two types of state change inconsistency, incompatible behavior inconsistency and disconnected model inconsistency. A fitness function is defined to detect inconsistency. We make use of the SRPSO algorithm to resolve inconsistency. Detecting inconsistencies in the early stages of software development enables phase containment of errors and prevents errors from being propagated to the code. The proposed approach generates consistent and complete state diagrams leading to accurate code generation, meeting time deadlines, reducing cost of production and easy system maintenance.},
  archive      = {J_SOCO},
  author       = {George, Renu and Samuel, Philip},
  doi          = {10.1007/s00500-020-05124-y},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18937-18952},
  shortjournal = {Soft Comput.},
  title        = {Fixing state change inconsistency with self regulating particle swarm optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Enhancing cloud security using crypto-deep neural network
for privacy preservation in trusted environment. <em>SOCO</em>,
<em>24</em>(24), 18927–18936. (<a
href="https://doi.org/10.1007/s00500-020-05122-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The users in communication interact over cloud for data exchange. The participants are in various levels, and their expectation varies on the nature of interactions. Though building a common platform for interactions over cloud environment is difficult, there is scope for developing security solutions that can ensure confidentiality of data exchange. In the proposed model distributed secure outsourcing scheme is enhanced using crypto-deep neural network. The proposed model has cloud server, web server, data center and cloud agent. The model mainly targets in handling impersonation attack using crypto-deep neural network cloud security (CDNNCS). The proposed framework is suitable for enhancing the level of trust among cloud users in comparison to secure linear algebraic equation scheme. The performance has been presented in terms of parameters namely Delay, Jitter, Throughput and Goodput. From the results it can be observed that with CDNNCS packet loss has been reduced by 10\% and the response time has been increased by 5\% in comparison to existing approach.},
  archive      = {J_SOCO},
  author       = {Abirami, P. and Bhanu, S. Vijay},
  doi          = {10.1007/s00500-020-05122-0},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18927-18936},
  shortjournal = {Soft Comput.},
  title        = {Enhancing cloud security using crypto-deep neural network for privacy preservation in trusted environment},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Artificial intelligent controller-based power quality
improvement for microgrid integration of photovoltaic system using new
cascade multilevel inverter. <em>SOCO</em>, <em>24</em>(24),
18909–18926. (<a
href="https://doi.org/10.1007/s00500-020-05120-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, grid-connected photovoltaic (PV) power system is quite popular in many countries. For grid-connected PV power system, to achieve maximum power and good power quality of the system are considered as big challenges. In order to achieve this, artificial intelligent (AI) controller-based maximum power point tracking (MPPT) algorithm has been investigated for PV system as well as a new cascade multilevel inverter (MLI) is proposed for grid integration of PV system. The proposed cascade MLI has been designed with a smaller number of power electronic switches and it can be operated at asynchronous voltage sources, which is most adaptable for PV system. This proposed inverter can reduce the total harmonic distortion (THD) at output side by means of increasing the output voltage level with this power quality of the system has been improved. The microgrid integration of proposed inverter has been controlled by using AI-based voltage source controller and this proposed system is designed and simulated in MATLAB environment at various weather conditions and loading conditions. Finally, prototype model has been developed in laboratory and evaluating its performance. The simulation results and prototype results were verified with IEEE 1547 standard that proves the proposed system effectiveness.},
  archive      = {J_SOCO},
  author       = {Mahendravarman, I. and Elankurisil, S. A. and Venkateshkumar, M. and Ragavendiran, A. and Chin, N.},
  doi          = {10.1007/s00500-020-05120-2},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18909-18926},
  shortjournal = {Soft Comput.},
  title        = {Artificial intelligent controller-based power quality improvement for microgrid integration of photovoltaic system using new cascade multilevel inverter},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improving secured ID-based authentication for cloud
computing through novel hybrid fuzzy-based homomorphic proxy
re-encryption. <em>SOCO</em>, <em>24</em>(24), 18893–18908. (<a
href="https://doi.org/10.1007/s00500-020-05119-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing environment (CCE) can empower an association to re-appropriate computing resources to increase monetary benefits. For both developers and the cloud users (CUs), CCE is transparent. Accordingly, it presents new difficulties when contrasted with precedent types of distributed computing. The precision of assessment results in CCE security risk assessment to take care of the issue of the multifaceted nature of the system and the classified fuzzy cloud method (CFCM) applied to CCE chance ID stage that captures the CCE risk factors through a complete investigation of CCE security area. Current CCE frameworks present a specific restriction on ensuring the client’s INFO privacy. We offer a homomorphic proxy re-encryption (HPRE) in this paper that enables various CU to share INFO that they redistributed HPRE encrypted utilizing their PubKs with the plausibility by a close procedure such as INFO remotely. The test of giving secrecy, uprightness, and access control (AC) of INFO facilitated on cloud stages is not provided for by conventional AC models. CFCM models were created through the duration of numerous decades to satisfy the association’s necessities, which accepted full authority over the physical structure of the assets. The hypothesis of the INFO proprietor, an INFO controller, and a supervisor is available in the equivalent trusted area. Besides, CCESR features like the essential unit, fuzzy set (FS) hypothesis, and EW strategy utilized to precisely measure the likelihood of CCE security risks (SR) and the subsequent damages of CCESR estimation. Eventually, the computation and authentication model specified, and the lack of CCE SECU threat evaluation examined.},
  archive      = {J_SOCO},
  author       = {Veerabathiran, Vijaya Kumar and Mani, Devi and Kuppusamy, Sangeetha and Subramaniam, Balu and Velayutham, Priya and Sengan, Sudhakar and Krishnamoorthy, Sujatha},
  doi          = {10.1007/s00500-020-05119-9},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18893-18908},
  shortjournal = {Soft Comput.},
  title        = {Improving secured ID-based authentication for cloud computing through novel hybrid fuzzy-based homomorphic proxy re-encryption},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An ECC-based access control scheme with lightweight
decryption and conditional authentication for data sharing in vehicular
networks. <em>SOCO</em>, <em>24</em>(24), 18881–18891. (<a
href="https://doi.org/10.1007/s00500-020-05117-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, more and more data are stored on cloud for sharing in vehicular networks, but the increasing number of cloud data security incidents makes how to guarantee confidentiality of sharing data one of the main concerns. Attribute-based encryption is considered as a suitable method to solve this issue. However, the requirements of lightweight and privacy make it difficult to apply the existing attribute-based encryption schemes directly in vehicular networks. In this paper, we put forward an access control scheme with lightweight decryption and conditional authentication for secure data sharing in vehicular networks. In this scheme, we extend elliptic-curve cryptography-based key-policy attribute-based encryption scheme with token-based decryption for lightweight access control. Moreover, we integrate Elliptic Curve Qu-Vanstone implicit certificate with ELGamal encryption algorithm to achieve both mutual authentication and conditional privacy protection. The performance analysis shows that the proposed scheme requires less time for both encryption and decryption on the user side. The security analysis shows that the proposed scheme can provide conditional anonymity.},
  archive      = {J_SOCO},
  author       = {Qin, Xuanmei and Huang, Yongfeng and Li, Xing},
  doi          = {10.1007/s00500-020-05117-x},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18881-18891},
  shortjournal = {Soft Comput.},
  title        = {An ECC-based access control scheme with lightweight decryption and conditional authentication for data sharing in vehicular networks},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-valued picture fuzzy soft sets and their applications
in group decision-making problems. <em>SOCO</em>, <em>24</em>(24),
18857–18879. (<a
href="https://doi.org/10.1007/s00500-020-05116-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft set theory initiated by Molodtsov in 1999 has been emerging as a generic mathematical tool for dealing with uncertainty. A noticeable progress is found concerning the practical use of soft set in decision-making problems. The purpose of this manuscript is to explore the novel of multi-valued picture fuzzy set (MPFS) and multi-valued picture fuzzy soft set (MPFSS) which are the generalizations of the notions of picture fuzzy soft set (PFSS) and multi-fuzzy soft set (MFSS). This notion can be used to express fuzzy information in more general and effective way. In particular, some basic operations such as union, intersection, complement and product of the proposed MPFSS are developed, and their properties are investigated. Furthermore, some aggregation operators corresponding to the proposed MPFSSs are called multi-picture fuzzy soft weighted averaging, multi-picture fuzzy soft ordered weighted averaging and multi-picture soft hybrid weighted averaging operators for a collections of MPFSSs are also developed. Moreover, based on these operators, we presented a new method to deal with the multi‐attribute group decision-making problems under the multi-valued picture fuzzy soft environment. Finally, we used some practical examples to illustrate the validity and superiority of the proposed method by comparing with other existing methods. The graphical interpretation of the explored approaches is also utilized with future directions.},
  archive      = {J_SOCO},
  author       = {Jan, Naeem and Mahmood, Tahir and Zedam, Lemnaouar and Ali, Zeeshan},
  doi          = {10.1007/s00500-020-05116-y},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18857-18879},
  shortjournal = {Soft Comput.},
  title        = {Multi-valued picture fuzzy soft sets and their applications in group decision-making problems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Applications of contractive-like mapping principles to fuzzy
fractional integral equations with the kernel <span
class="math display"><em>ψ</em></span> -functions. <em>SOCO</em>,
<em>24</em>(24), 18841–18855. (<a
href="https://doi.org/10.1007/s00500-020-05115-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we present a new class of generalized fractional integral equations with respect to the kernel $$\psi $$ -function under the fuzzy concept. The results of this problem can be used to recover a wide class of fuzzy fractional integral equations by the choice of the kernel $$\psi $$ -function. Without the Lipschitzian right-hand side, we investigate the existence and uniqueness of the fuzzy solutions by employing the fixed point theorem of weakly contractive mappings in the partially ordered space of fuzzy numbers. The proposed approach is based on the concept of a fuzzy metric space endowed with a partial order and the altering distance functions. In addition, the continuous dependence of solutions on the order and the initial condition of the given problem is also shown. Some concrete examples are presented in order to consolidate the obtained result.},
  archive      = {J_SOCO},
  author       = {Vu, Ho and Van Hoa, Ngo},
  doi          = {10.1007/s00500-020-05115-z},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18841-18855},
  shortjournal = {Soft Comput.},
  title        = {Applications of contractive-like mapping principles to fuzzy fractional integral equations with the kernel $$\psi $$ -functions},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Curve approximation by adaptive neighborhood simulated
annealing and piecewise bézier curves. <em>SOCO</em>, <em>24</em>(24),
18821–18839. (<a
href="https://doi.org/10.1007/s00500-020-05114-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The curve approximation problem is widely researched in CAD/CAM and geometric modelling. The problem consists in determining an approximating curve from a given sequence of points. The usual approach is the minimization of the discrepancy between the approximating curve and the given sequence of points. However, the minimization of just the discrepancy leads to the overfitting problem, in which the solution is not unique. A new approach is proposed to overcome this problem, in which the length of the approximating curve is used as a regularization increasing the algorithm stability. Another new proposal is the discrepancy determination, in which a method that has the best ratio between accuracy and processing time is proposed. A new simulated annealing (SA) approach is used to minimize the problem, in which the next candidate is determined by a probability distribution controlled by the crystallization factor. The crystallization factor is low for higher temperatures ensuring the exploration of the domain. The crystallization factor is high for lower temperatures, corresponding the refinement phase of the SA. The approximating curve is represented as a piecewise cubic Bézier curve, which is a sequence of several connected cubic Bézier curves. The piecewise Bézier curve supports a new proposed data structure that improves the proposed algorithm. A comparison is also made between the used single-objective SA and the AMOSA multi-objective SA. The results showed that the proposed single-objective SA finds a solution which is not dominated by the Pareto front determined by AMOSA. The results also showed that the regularization stabilized the algorithm, in which the increase in parameters does not lead to the overfitting problem. The proposed algorithm can process even complex curves with self-intersections and higher curvature.},
  archive      = {J_SOCO},
  author       = {Ueda, E. K. and Sato, A. K. and Martins, T. C. and Takimoto, R. Y. and Rosso, R. S. U. and Tsuzuki, M. S. G.},
  doi          = {10.1007/s00500-020-05114-0},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18821-18839},
  shortjournal = {Soft Comput.},
  title        = {Curve approximation by adaptive neighborhood simulated annealing and piecewise bézier curves},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Segmentation of spinal cord from computed tomography images
based on level set method with gaussian kernel. <em>SOCO</em>,
<em>24</em>(24), 18811–18820. (<a
href="https://doi.org/10.1007/s00500-020-05113-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the human body, organs segmentation is the most imperative issues in therapeutic applications. The challenges are connected with medicinal image segmentation and low complexity between required organ and incorporating tissues. There exist a wide range of methodologies for how a segmentation problem can be comprehended. These methods want to have a spot specific region of individual bones. The particular part remains a test for spinal cord segmentation. As a result of the beforehand expressed downsides of the current spinal cord segmentation procedures, this paper proposes a modified spatial fuzzy C clustering with level set segmentation method to incorporate Neumann Boundary Condition, a third function, called by the level set evolution. Neumann Boundary Condition is utilized to specify the normal derivative of the function present on any surface. The proposed method gives better results of segmentation of the spinal cord organs. The execution of the proposed method proves its superiority in term of accuracy as compared with the other methods.},
  archive      = {J_SOCO},
  author       = {Malathy, V. and Anand, M. and Dayanand Lal, N. and Adhoni, Zameer Ahmed},
  doi          = {10.1007/s00500-020-05113-1},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18811-18820},
  shortjournal = {Soft Comput.},
  title        = {Segmentation of spinal cord from computed tomography images based on level set method with gaussian kernel},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Possibility mean, variance and standard deviation of
single-valued neutrosophic numbers and its applications to
multi-attribute decision-making problems. <em>SOCO</em>,
<em>24</em>(24), 18795–18809. (<a
href="https://doi.org/10.1007/s00500-020-05112-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-valued neutrosophic numbers (SVN-numbers) are a special kind of neutrosophic set on the real number set. The concept of a SVN-number is important for quantifying an ill-known quantity and ranking of SVN-number is a very difficult situation in decision-making problems. The main aim of this paper is to present a new ranking methodology of SVN-numbers for solving multi-attribute decision-making problems. Therefore, we firstly define the possibility mean, variance and standard deviation of single-valued neutrosophic numbers. Using the ratio of possibility mean and standard deviation, we have developed the proposed ranking approach and applied to MADM problems. Finally, a numerical example is examined to show the applicability and embodiment of the proposed method.},
  archive      = {J_SOCO},
  author       = {Garai, Totan and Dalapati, Shyamal and Garg, Harish and Roy, Tapan Kumar},
  doi          = {10.1007/s00500-020-05112-2},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18795-18809},
  shortjournal = {Soft Comput.},
  title        = {Possibility mean, variance and standard deviation of single-valued neutrosophic numbers and its applications to multi-attribute decision-making problems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Predicting course achievement of university students based
on their procrastination behaviour on moodle. <em>SOCO</em>,
<em>24</em>(24), 18777–18793. (<a
href="https://doi.org/10.1007/s00500-020-05110-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A significant amount of educational data mining (EDM) research consider students’ past performance or non-academic factors to build predictive models, paying less attention to students’ activity data. While procrastination has been found as a crucial indicator which negatively affects performance of students, no research has investigated this underlying factor in predicting achievement of students in online courses. In this study, we aim to predict students’ course achievement in Moodle through their procrastination behaviour using their homework submission data. We first build feature vectors of students’ procrastination tendencies by considering their active, inactive, and spare time for homework, along with homework grades. Accordingly, we then use clustering and classification methods to optimally sort and put students into various categories of course achievement. We use a Moodle course from the University of Tartu in Estonia which includes 242 students to assess the efficacy of our proposed approach. Our findings show that our approach successfully predicts course achievement for students through their procrastination behaviour with precision and accuracy of 87\% and 84\% with L-SVM outperforming other classification methods. Furthermore, we found that students who procrastinate more are less successful and are potentially going to do poorly in a course, leading to lower achievement in courses. Finally, our results show that it is viable to use a less complex approach that is easy to implement, interpret, and use by practitioners to predict students’ course achievement with a high accuracy, and possibly take remedial actions in the semester.},
  archive      = {J_SOCO},
  author       = {Yang, Yeongwook and Hooshyar, Danial and Pedaste, Margus and Wang, Minhong and Huang, Yueh-Min and Lim, Heuiseok},
  doi          = {10.1007/s00500-020-05110-4},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18777-18793},
  shortjournal = {Soft Comput.},
  title        = {Predicting course achievement of university students based on their procrastination behaviour on moodle},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Rigorous reduction of partial shading condition in grid
connected solar PV system using discrete time-based PSO controller.
<em>SOCO</em>, <em>24</em>(24), 18765–18775. (<a
href="https://doi.org/10.1007/s00500-020-05109-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solar industry has seen tremendous development over the past decade and in particular, the PV (Photovoltaic) system which has an imperative advancement almost in all fields of science. Envisaging various faults in the PV system will significantly enhance the efficiency, reliability, and life of the PV system. The main vulnerable element in the PV system which is subjected under different weather condition causes total damage to the system. Proper monitoring and maintenance are needed to increase the life of the system. Several investigations were made so far to predict the faults in the PV system such as the Visual method, the Thermal method, the Electrical detection method, the Machine learning techniques, the Arc fault detection technique and the Protection device-based techniques were used generally. But more effective fault diagnosis techniques are required for PV arrays. The proposes a novel method for reducing the partial shading condition in solar PV system connected to a grid which consists of a discrete time-based particle swarm optimization (PSO) controller that controls the irradiation or partial shading as well as any short circuits in PV cell. Hence, this proposed work enhances with producing efficient energy by achieving high predictive accuracy of about 99\%, high efficiency of about 98.9\% and low THD (0.9) under partial shading conditions as well as harmonics.},
  archive      = {J_SOCO},
  author       = {Ganeshprabu, B. and Geethanjali, M.},
  doi          = {10.1007/s00500-020-05109-x},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18765-18775},
  shortjournal = {Soft Comput.},
  title        = {Rigorous reduction of partial shading condition in grid connected solar PV system using discrete time-based PSO controller},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An FMEA-based TOPSIS approach under single valued
neutrosophic sets for maritime risk evaluation: The case of ship
navigation safety. <em>SOCO</em>, <em>24</em>(24), 18749–18764. (<a
href="https://doi.org/10.1007/s00500-020-05108-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As in terrestrial facilities, safety is one of the most important issue in ships. Vessels navigating in many parts of the world face many different, tough and dangerous navigational risks. In this context, twenty-three fundamental risks which are frequently encountered in ship navigation were considered in this study and examined by an FMEA-based TOPSIS approach under single valued neutrosophic sets. Because of the lack of data in the literature, the opinions of the experts (Masters) who have many years of experience in the sector were taken. As a result of the study, extreme weather conditions, injury of crew, loss of input of sensory equipment (depth, gyro, speed etc.), struck by ropes, exposure to high speed machineries under high pressures, loss of maneuverability are very important among these risks. Considering these risks, corrective-preventive action plans and managerial implications for ship navigation have been presented. Consequently, the results of this study have an important warning and solution recommendation regarding ship navigation risks.},
  archive      = {J_SOCO},
  author       = {Başhan, Veysi and Demirel, Hakan and Gul, Muhammet},
  doi          = {10.1007/s00500-020-05108-y},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18749-18764},
  shortjournal = {Soft Comput.},
  title        = {An FMEA-based TOPSIS approach under single valued neutrosophic sets for maritime risk evaluation: The case of ship navigation safety},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Exploring multiple spatio-temporal information for
point-of-interest recommendation. <em>SOCO</em>, <em>24</em>(24),
18733–18747. (<a
href="https://doi.org/10.1007/s00500-020-05107-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional collaborative filtering methods perform poorly in providing location recommendations due to the high sparsity of users’ check-in data, prompting the development of new location recommendation approaches that can integrate situational factors such as time and location. Using long short-term memory (LSTM) neural networks and kernel density estimation (KDE), this paper integrates the impact of point-of-interest (POI) location and category on users’ check-in behavior according to check-in sequence data. First, LSTM neural networks are used to model users’ periodic and repetitive daily activities for a sequence-based prediction of the probability of whether the user will visit a candidate POI. Second, the user’s geographical preference in the two-dimensional space is represented by KDE and used to make a location-based check-in probability prediction. Next, the user’s category preference is used to predict the check-in probability of a candidate POI. Finally, a user preference model is constructed from three perspectives of time, location, and category, and the comprehensive check-in probability is used for Top-N recommendation. The validation experiments on Foursquare dataset verifies that, in terms of recommendation precision and recall, the proposed recommendation method is superior to both the basic LSTM approach and the method that uses only location information. In addition, it is experimentally confirmed that the geographical preference, which is reflected by “clustering” of a user’s check-in locations, is stable, but the user’s category preference is prone to drift.},
  archive      = {J_SOCO},
  author       = {Ma, Yingxue and Gan, Mingxin},
  doi          = {10.1007/s00500-020-05107-z},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18733-18747},
  shortjournal = {Soft Comput.},
  title        = {Exploring multiple spatio-temporal information for point-of-interest recommendation},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A particle swarm optimization-based feature selection for
unsupervised transfer learning. <em>SOCO</em>, <em>24</em>(24),
18713–18731. (<a
href="https://doi.org/10.1007/s00500-020-05105-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer learning (TL) method has captured an attractive presence because it facilitates the learning ability in the target domain by acquiring knowledge from well-established source domains. To gain strong knowledge from the source domain, it is important to narrow down the distribution difference between the source and the target domains. For this purpose, it is necessary to consider the objectives such as preserving the discriminative information, preserving the original similarity of the source and the target domain data, maximizing the variance of the target domain, and preserving marginal and conditional distribution at the same time. Furthermore, some existing TL methods use only original feature data, so there is a threat of degenerated feature transformation. To overcome all these limitations, in this paper, a novel feature selection-based transfer learning approach using particle swarm optimization (PSO) for unsupervised transfer learning (FSUTL-PSO) is implemented. In FSUTL-PSO, we incorporate all such objectives into one fitness function and select common good features from the source and target domains based on the fitness function for eliminating the threat of degenerated features. Extensive experiments have been done on all possible tasks of Office+Caltech and PIE Face datasets and our proposed method FSUTL-PSO has shown significant improvement over the existing transfer or non-transfer learning methods.},
  archive      = {J_SOCO},
  author       = {Sanodiya, Rakesh Kumar and Tiwari, Mrinalini and Mathew, Jimson and Saha, Sriparna and Saha, Subhajyoti},
  doi          = {10.1007/s00500-020-05105-1},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18713-18731},
  shortjournal = {Soft Comput.},
  title        = {A particle swarm optimization-based feature selection for unsupervised transfer learning},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fusion of self-organizing map and granular self-organizing
map for microblog summarization. <em>SOCO</em>, <em>24</em>(24),
18699–18711. (<a
href="https://doi.org/10.1007/s00500-020-05104-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we have proposed a fusion of two architectures, self-organizing map and granular self-organizing map (SOM + GSOM), for solving the microblog summarization task where a set of relevant tweets are extracted from the available set of tweets. SOM is used to reduce the available set of tweets to a smaller subset, and GSOM is used for extracting relevant tweets. The fusion of SOM + SOM is also accomplished to illustrate the effectiveness of GSOM over SOM in the second architecture. Moreover, only SOM version is also utilized to illustrate the potentiality of fusion in our proposed approaches. As similarity/dissimilarity measures play major role in any summarization system; therefore, to measure the same between tweets, various measures like word mover distance, cosine distance and Euclidean distance are also explored. The results obtained are evaluated on four datasets related to disaster events using ROUGE measures. Experimental results demonstrate that our best-proposed approach (SOM + GSOM) has obtained $$17\%$$ and $$5.9\%$$ improvements in terms of ROUGE-2 and ROUGE-L scores, respectively, over the existing techniques. The results are also validated using statistical significance t-test.},
  archive      = {J_SOCO},
  author       = {Saini, Naveen and Saha, Sriparna and Mansoori, Sahil and Bhattacharyya, Pushpak},
  doi          = {10.1007/s00500-020-05104-2},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18699-18711},
  shortjournal = {Soft Comput.},
  title        = {Fusion of self-organizing map and granular self-organizing map for microblog summarization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An algorithmic approach to solve unbalanced triangular fuzzy
transportation problems. <em>SOCO</em>, <em>24</em>(24), 18689–18698.
(<a href="https://doi.org/10.1007/s00500-020-05103-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents problems in fuzzy transportation, which deals with fuzzy costs, fuzzy supplies, and demands of a fuzzy nature on any quantity transported. The paper deals with the minimization of the total fuzzy cost under the fuzzified decision-variables. The proposed method gives better optimum for fuzzy transportation problem (FTP) with unbalance and balance types. The method is intended to obtain a basic feasible solution (or “initial basic feasible solution”) (IBFS) of unbalanced fuzzy problems with triangular fuzzy number. A new and simple heuristic approach for obtaining optimum solution of triangular fuzzy unbalanced transportation problem is proposed that reduces the number of iterations in the optimization process. A given triangular fuzzy unbalanced TP is converted into a modified triangular unbalanced FTP by increasing the fuzzy-demand/fuzzy-supply of an origin and a destination, and the same is resolved by new method. Also an illustrative numerical example is discussed for proposed method solving a triangular FTP with m, n origins and destinations, respectively.},
  archive      = {J_SOCO},
  author       = {Muthuperumal, S. and Titus, P. and Venkatachalapathy, M.},
  doi          = {10.1007/s00500-020-05103-3},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18689-18698},
  shortjournal = {Soft Comput.},
  title        = {An algorithmic approach to solve unbalanced triangular fuzzy transportation problems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Three-way decisions with decision-theoretic rough sets
based on pythagorean fuzzy covering. <em>SOCO</em>, <em>24</em>(24),
18671–18688. (<a
href="https://doi.org/10.1007/s00500-020-05102-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-way decisions (3WDs) with decision-theoretic rough sets (DTRSs) are a new method for solving problems of risky decision. In DTRSs, it is crucial to the determination of the loss function. Pythagorean fuzzy (PF) sets are a more powerful mathematical tool than intuitionistic fuzzy sets for dealing with uncertainty and inaccuracy. Although the researchers have introduced Pythagorean fuzzy numbers (PFNs) into the loss function, study on the combination of 3WDs and PF covering is still blank. In view of this, we develop 3WDs with DTRS based on PF covering. Firstly, by using the concepts of PF $$\beta $$ -covering and PF $$\beta $$ -neighborhood, we construct a Pythagorean fuzzy $$\beta $$ -covering decision-theoretic rough set (PFCDTRS) model as per Bayesian decision procedure. Then, some of interesting properties of the expected loss related to the model are investigated. Secondly, based on the membership degree and non-membership degree of PFNs, four methods to address the expected loss expressed in the form of PFNs are established and the corresponding 3WDs are also derived. Finally, we develop a corresponding algorithm for deriving 3WDs with PFCDTRS, and then, an example is provided to validate the feasibility and reliability of 3WDs with PFCDTRS. Compared the proposed methods with the existing methods, we conclude that the proposed Methods 3 and 4 are superior to the existing methods.},
  archive      = {J_SOCO},
  author       = {Zhang, Haidong and Ma, Qian},
  doi          = {10.1007/s00500-020-05102-4},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18671-18688},
  shortjournal = {Soft Comput.},
  title        = {Three-way decisions with decision-theoretic rough sets based on pythagorean fuzzy covering},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Online estimation of state of health for the airborne li-ion
battery using adaptive DEKF-based fuzzy inference system. <em>SOCO</em>,
<em>24</em>(24), 18661–18670. (<a
href="https://doi.org/10.1007/s00500-020-05101-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quick and accurate estimation of the state of health (SOH) of Li-ion battery is a technical difficulty in battery management system research. For the low accuracy of Li-ion battery SOH estimation under complex stress conditions, an estimation method of SOH for Li-ion battery using the adaptive dual extended Kalman filter-based fuzzy inference system (ADEKF-FIS) is proposed. First, Li-ion battery SOH is online estimated by dual extended Kalman filter. Then the Sage–Husa adaptive algorithm and the fuzzy controller are used to correct the state noise covariance and the observed noise covariance, respectively. The algorithm is flat on the state variance and the noise variance. The recursive estimation of the square root ensures the symmetry and nonnegative nature of the state and noise variance. In the end, this paper performing the dynamic stress test condition experiment for confirmation. Experimental results show that, compared with the EKF algorithm, ADEKF-FIS algorithm can obtain state of charge estimation with higher accuracy, which further improves the prediction accuracy of SOH and makes this algorithm have higher accuracy and better convergence.},
  archive      = {J_SOCO},
  author       = {Yang, Ke and Chen, Zewang and He, Zhijia and Wang, Youren and Zhou, Zhaihe},
  doi          = {10.1007/s00500-020-05101-5},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18661-18670},
  shortjournal = {Soft Comput.},
  title        = {Online estimation of state of health for the airborne li-ion battery using adaptive DEKF-based fuzzy inference system},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Expected utility operators and coinsurance problem.
<em>SOCO</em>, <em>24</em>(24), 18647–18659. (<a
href="https://doi.org/10.1007/s00500-020-05100-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The expected utility operators introduced in a previous paper offer a framework for a general risk aversion theory, in which risk is modeled by a fuzzy number A. In this paper, we formulate a coinsurance problem in the possibilistic setting defined by an expected utility operator T. Some properties of the optimal saving T-coinsurance rate are proved, and an approximate calculation formula of this is established with respect to the Arrow–Pratt index of the utility function of the policyholder, as well as the expected value and the variance of a fuzzy number A. Various formulas of the optimal T-coinsurance rate are deduced for a few expected utility operators in case of a triangular fuzzy number and of some HARA- and CRRA-type utility functions.},
  archive      = {J_SOCO},
  author       = {Georgescu, Irina},
  doi          = {10.1007/s00500-020-05100-6},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18647-18659},
  shortjournal = {Soft Comput.},
  title        = {Expected utility operators and coinsurance problem},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). TSASC: Tree–seed algorithm with sine–cosine enhancement for
continuous optimization problems. <em>SOCO</em>, <em>24</em>(24),
18627–18646. (<a
href="https://doi.org/10.1007/s00500-020-05099-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tree–seed algorithm (TSA) establishes a novel approach to solve continuous optimization problems, which is applied in many fields because of its simplicity and strength in finding optimal solutions. However, due to somewhat imbalance of its ability between exploration and exploitation in different search phases, the exploratory capability of TSA is relatively weak in optimizing multimodal and high-dimensional objective functions. To make some improvements, we propose a hybrid heuristic tree–seed algorithm named TSASC by integrating two features from sine–cosine algorithm. The proposed algorithm is then tested in comparison with TSA and other relevant algorithms through 30 benchmark functions from IEEE CEC 2014 and 3 constrained real engineering optimization problems. The results prove its enhanced balance between exploration and exploitation in both finding better global optimal solutions and effectively avoiding falling into local optimum, which shows that it has promising advantages in solving continuous optimization problems in engineering practices.},
  archive      = {J_SOCO},
  author       = {Jiang, Jianhua and Han, Rui and Meng, Xianqiu and Li, Keqin},
  doi          = {10.1007/s00500-020-05099-w},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18627-18646},
  shortjournal = {Soft Comput.},
  title        = {TSASC: Tree–seed algorithm with sine–cosine enhancement for continuous optimization problems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A hybrid active contour model for ultrasound image
segmentation. <em>SOCO</em>, <em>24</em>(24), 18611–18625. (<a
href="https://doi.org/10.1007/s00500-020-05097-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abundant noise, low contrast, intensity heterogeneity, shadows, and blurry boundaries exist in most medical images, especially for 2D ultrasound (US) image. In this paper, we propose a semiautomatic hybrid active contour model for 2D US image segmentation. The proposed method mainly uses a local bias correction function and probability score. It is well known that most region-based active contour models are based on the assumption of intensity homogeneity. It is very difficult to define a region descriptor for US images with intensity heterogeneity. Here, a bias field can account for the intensity heterogeneity of the US image. Therefore, the proposed local bias correction function is considered to integrate with respect to the neighborhood center of the US image. Besides, to segment complex ultrasound images more accurately, a probability score is constructed from the edge-based operator. Based on the estimation of the bias field and an interleaved process of probability score, minimization of the proposed energy functional is achieved. The proposed method is validated on synthetic images and real US images, with satisfactory performance in the presence of noise, intensity heterogeneity, and blurry boundaries.},
  archive      = {J_SOCO},
  author       = {Fang, Lingling and Pan, Xiaohang and Yao, Yibo and Zhang, Lirong and Guo, Dongmei},
  doi          = {10.1007/s00500-020-05097-y},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18611-18625},
  shortjournal = {Soft Comput.},
  title        = {A hybrid active contour model for ultrasound image segmentation},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). ICM-BTD: Improved classification model for brain tumor
diagnosis using discrete wavelet transform-based feature extraction and
SVM classifier. <em>SOCO</em>, <em>24</em>(24), 18599–18609. (<a
href="https://doi.org/10.1007/s00500-020-05096-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In medical image processing, the detection, classification and segmentation of the tumor region from MRI scans accurately are very complicated, significant and time-consuming process. When there is a scenario occurs to handle with large amount of images for tumor diagnosis, there is need of an efficient and adaptive classification model to handle with the anomalous structures of human brains. The MRI brain images show the typical internal brain structure and hence help scholars and medical practitioners in accurate disease diagnosis. With that note, this paper develops a model called improved classification model for brain tumor diagnosis for appropriate classification of tumor images from input MRI images. Initially, filtering techniques are applied for preprocessing the acquired scan images and feature extraction is done with gray-level co-occurrence matrix and discrete wavelet transform equations, which produces more precise results. And, classification is done with the technique called support vector machine, in which the binary classifications are effectively done. The proposed model is evaluated under simulation, and the obtained results outperform the results of traditional brain tumor detection process based on precision, recall and processing time.},
  archive      = {J_SOCO},
  author       = {Gokulalakshmi, A. and Karthik, S. and Karthikeyan, N. and Kavitha, M. S.},
  doi          = {10.1007/s00500-020-05096-z},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18599-18609},
  shortjournal = {Soft Comput.},
  title        = {ICM-BTD: Improved classification model for brain tumor diagnosis using discrete wavelet transform-based feature extraction and SVM classifier},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Automatic segmentation and classification of liver tumor
from CT image using feature difference and SVM based classifier-soft
computing technique. <em>SOCO</em>, <em>24</em>(24), 18591–18598. (<a
href="https://doi.org/10.1007/s00500-020-05094-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The liver is essential for endurance and to carry out a large number of significant functions, including manufacture of indispensable proteins, and metabolism of fats and carbohydrates. The examination of CT might be employed for planning and managing the treatments for tumor in a proper way and for directing biopsies as well as other simply determined process. The Manual segmentation and Computed Axial Tomography (CT) image classification is a tedious task and time consuming process for large amount of data. Computer-Aided Diagnosis (CAD) systems take part in a fundamental role in the detection of liver disease in an early stage and therefore decrease death rate of liver cancer. In this paper an automatic CAD system is presented in three stage. In the first step, automatic liver segmentation and lesion’s detection is carried out. Then, the next step is to extract features. At last, liver lesions classification into malignant and benign is done by using the novel contrast based feature-difference method. The extracted features from the lesion area with its surrounding normal liver tissue are based on intensity and texture. The lesion descriptor is obtained by considering the difference between the features of both lesion area and normal tissue of liver. Finally to categorize the liver lesions into malignant or benign a new SVM based machine learning classifier is trained on the new descriptors. The investigational outcome show hopeful improvement. Besides, the projected approach is insensitive to ranges of textures and intensity between demographics, imaging devices, and patients and settings. The classifier discriminates the tumor by comparatively high precision and offers a subsequent view to the radiologist.},
  archive      = {J_SOCO},
  author       = {Devi, R. Manjula and Seenivasagam, V.},
  doi          = {10.1007/s00500-020-05094-1},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18591-18598},
  shortjournal = {Soft Comput.},
  title        = {Automatic segmentation and classification of liver tumor from CT image using feature difference and SVM based classifier-soft computing technique},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Particle swarm optimisation with opposition learning-based
strategy: An efficient optimisation algorithm for day-ahead scheduling
and reconfiguration in active distribution systems. <em>SOCO</em>,
<em>24</em>(24), 18573–18590. (<a
href="https://doi.org/10.1007/s00500-020-05093-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In operation of active electric distribution networks, optimal configuration and schedule of distributed generation and reactive power resources are determined. This represents a formidable multi-modal constrained optimisation problem with discrete decision variables. Metaheuristics are the most common approaches for solving this problem. However, due to its multi-modal nature, metaheuristics commonly converge prematurely into local optima and cannot find near-global solutions. In this research, a new particle swarm optimisation (PSO) variant is put forward for finding optimal configuration and schedule of distributed generation and reactive power resources in distribution systems including both dispatchable and renewable distributed energy resources. In the proposed PSO variant, opposition-based learning concept is incorporated into PSO which reduces premature convergence probability through enhancement of swarm leaders. The results of the proposed opposition-based PSO in IEEE 69 bus system indicate its outperformance over conventional PSO, time-varying acceleration coefficient PSO, fractal optimisation algorithm and evolutionary programming.},
  archive      = {J_SOCO},
  author       = {Rezaee Jordehi, Ahmad},
  doi          = {10.1007/s00500-020-05093-2},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18573-18590},
  shortjournal = {Soft Comput.},
  title        = {Particle swarm optimisation with opposition learning-based strategy: An efficient optimisation algorithm for day-ahead scheduling and reconfiguration in active distribution systems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sequential characterization of statistical epi-convergence.
<em>SOCO</em>, <em>24</em>(24), 18565–18571. (<a
href="https://doi.org/10.1007/s00500-020-05092-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epi-convergence is used as an efficient tool in optimization theory. It finds optimal solutions in such a way that it ensures the convergence of infimum values. In some cases, some functions may not conform to an expected pattern and reduce the efficiency of optimization. Moreover, obtaining epi-limit function may fail due to disruption of these functions. For that reason, it may be necessary to use an alternative method that diminishes the effect of such functions by excluding them from consideration. In this paper, we give a sequential characterization of statistical epi-convergence which enables us to eliminate corrupted functions deviate from the majority of the data. Therefore, statistical epi-limit inferior and superior are defined. Then, we show that sequential characterization of statistical epi-convergence is not biconditional as its ordinary definition. At the end, these definitions lead the way through the conditions for statistical convergence of infimum values which is an essential property to solve optimization problems.},
  archive      = {J_SOCO},
  author       = {Tortop, Şükrü and Sever, Yurdal and Talo, Özer},
  doi          = {10.1007/s00500-020-05092-3},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18565-18571},
  shortjournal = {Soft Comput.},
  title        = {Sequential characterization of statistical epi-convergence},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Extension of multi-moora method with some q-rung orthopair
fuzzy dombi prioritized weighted aggregation operators for
multi-attribute decision making. <em>SOCO</em>, <em>24</em>(24),
18545–18563. (<a
href="https://doi.org/10.1007/s00500-020-05091-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Dombi operators provide a flexible structure with its adjustable parameter because of Dombi generalized structure. On the other hand, priority aggregation operators play an important role in expressing the importance level of alternatives and attributes. In this study, novel Dombi prioritized aggregations are developed on q-rung orthopair fuzzy sets (q-ROFSs). The q-ROFSs include many fuzzy sets with dynamically changing q parameters. q-ROFSs include intuitionistic fuzzy sets, Pythagorean fuzzy sets and Fermatean fuzzy sets according to value of q parameter. In this study, Dombi prioritized aggregation of q-ROFSs is presented. The operators introduced are q-ROFSs Dombi prioritized weighted averaging operator (q-ROFSDPWA) and q-ROFSs Dombi prioritized weighted geometric operator (q-ROFSDPWG). We also investigate some of the properties of these operators. The proposed operators are used in MULTIMOORA method. The proposed methods with new aggregation operators are analyzed according to the q parameter of q-ROFSs and Dombi parameter on numerical example and also compared with other existing studies. It is seen that novel q-ROFSDPWA and q-ROFSDPWG aggregations give reasonable and stable results for multiple criteria decision making problem.},
  archive      = {J_SOCO},
  author       = {Aydemir, Salih Berkan and Yilmaz Gündüz, Sevcan},
  doi          = {10.1007/s00500-020-05091-4},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18545-18563},
  shortjournal = {Soft Comput.},
  title        = {Extension of multi-moora method with some q-rung orthopair fuzzy dombi prioritized weighted aggregation operators for multi-attribute decision making},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Prediction of form roughness coefficient in alluvial
channels using efficient hybrid approaches. <em>SOCO</em>,
<em>24</em>(24), 18531–18543. (<a
href="https://doi.org/10.1007/s00500-020-05090-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In general, total roughness coefficient in open channels includes both grain resistance and bedform resistance. Due to the nonlinearity of the roughness coefficient, an accurate prediction of the bedform roughness is difficult. In this study, the capability of artificial neural network and multilayer perceptron (MLP) with firefly algorithm (MLP-FFA) were assessed in predicting the form resistance in channels with dune bedform. In this regard, different input combinations based on flow, bedform, and sediment characteristics were developed in order to determine the best combination. Five different experimental data series were applied to train and test the models. It was found that in predicting the form resistance, the model which took the advantages of both flow and sediment characteristics yielded to better outcomes. It was observed that the bedform characteristics led to an improvement in models accuracy. The results of the sensitivity analysis showed that the Reynolds number and the relative discharge were more effective parameters in the modeling process. Also, investigating the dune geometry (i.e., relative dune height) showed that the densimetric Froude number was the most significant variable.},
  archive      = {J_SOCO},
  author       = {Roushangar, Kiyoumars and Saghebian, Seyed Mahdi and Kirca, V. S. Ozgur and Ghasempour, Roghayeh},
  doi          = {10.1007/s00500-020-05090-5},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18531-18543},
  shortjournal = {Soft Comput.},
  title        = {Prediction of form roughness coefficient in alluvial channels using efficient hybrid approaches},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cotangent similarity measure of single-valued neutrosophic
interval sets with confidence level for risk-grade evaluation of
prostate cancer. <em>SOCO</em>, <em>24</em>(24), 18521–18530. (<a
href="https://doi.org/10.1007/s00500-020-05089-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The indeterminacy/inconsistency information of physicians’ confident degrees regarding their judgments is not considered in existing risk-grade evaluation methods of prostate cancer (PC). To overcome the insufficiency, based on the single-valued neutrosophic interval sets (SvNISs) expressing the hybrid information of both the uncertain judgment given by an interval number and the confident degree regarding the uncertain judgment expressed by a single-valued neutrosophic number, this original study contributes a cotangent similarity measure of SvNISs with confidence level, and a novel risk-grade evaluation method of PC by using the confidence level-based cotangent similarity measure. Then, 16 PC actual clinical cases are used to demonstrate the applicability and effectiveness of the developed risk-grade evaluation method in SvNIS setting. Finally, the comparison analysis with other existing evaluation methods and the sensitivity analysis of confidence levels show that the proposed risk-grade evaluation method of PC is reasonable and effective.},
  archive      = {J_SOCO},
  author       = {Cui, Wen-Hua and Ye, Jun and Fu, Jing},
  doi          = {10.1007/s00500-020-05089-y},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18521-18530},
  shortjournal = {Soft Comput.},
  title        = {Cotangent similarity measure of single-valued neutrosophic interval sets with confidence level for risk-grade evaluation of prostate cancer},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A belief degree-based uncertain scheme for a bi-objective
two-stage green supply chain network design problem with direct
shipment. <em>SOCO</em>, <em>24</em>(24), 18499–18519. (<a
href="https://doi.org/10.1007/s00500-020-05085-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the lack of historical data for an uncertain event, the belief degree-based uncertainty becomes more applicable than other types of uncertainty like fuzzy theory, stochastic programming, etc. This study focuses on an uncertain bi-objective two-stage supply chain network design problem. The problem consists of plants, depots, and customers with cost and environmental impacts (CO2 emission) where direct shipment between plants and customers is allowed. As such network could be designed for the first time in a geographical region, such problem is modeled in a belief degree-based uncertain environment. This is almost the first study on belief degree-based uncertain supply chain network design problem with environmental impacts and direct shipment. Three approaches of expected value model, chance-constrained model, and their combination are applied to convert the proposed uncertain problem to its crisp form. The obtained crisp forms are solved by two multi-objective optimization approaches of goal programming (GP) and global criterion method (GCM). An extensive computational study with various test problems is performed to study the performance of the crisp models and the solution approaches. As result, the obtained crisp formulations are highly sensitive to the changes in the cost parameters’ values, and the GP performs better than the GCM from the solution quality point of view.},
  archive      = {J_SOCO},
  author       = {Mahmoodirad, Ali and Niroomand, Sadegh},
  doi          = {10.1007/s00500-020-05085-2},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18499-18519},
  shortjournal = {Soft Comput.},
  title        = {A belief degree-based uncertain scheme for a bi-objective two-stage green supply chain network design problem with direct shipment},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Volumetric analysis framework for accurate segmentation and
classification (VAF-ASC) of lung tumor from CT images. <em>SOCO</em>,
<em>24</em>(24), 18489–18497. (<a
href="https://doi.org/10.1007/s00500-020-05081-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lung tumor can be typically stated as the abnormal cell growth in lungs that may cause severe threat to patient health, since lung is a significant organ which comprises associated network of blood veins and lymphatic canals. The earlier detection and classification of lung tumor creates a greater impact on increasing the survival rate of patients. For analysis, the Computed Tomography (CT) lung images are broadly used, since it gives information about the various lung regions. The prediction of tumor contour, position, and volume plays an imperative role in accurate segmentation and classification of tumor cells. This will aid in successful tumor stage detection and treatment phases. With that concern, this paper develops a Volumetric Analysis Framework for Accurate Segmentation and Classification of lung tumors. The volumetric analysis framework comprises the estimation of length, thickness, and height of the detected tumor cell for achieving précised results. Though there are many models for tumor detection from 2D CT inputs, it is very important to develop a method for lung nodule separation from noisy background. For that, this paper connectivity and locality features of the lung image pixels. Moreover, morphological processing techniques are incorporated for removing the additional noises and airways. Tumor segmentation has been accomplished by the k-means clustering approach. Tumor Nodule Metastasis classification based-volumetric analysis is performed for accurate results. The Volumetric Analysis Framework provides better results with respect to factors such as accuracy rate of tumor diagnosis, reduced computation time, and appropriate tumor stage classification.},
  archive      = {J_SOCO},
  author       = {Kavitha, M. S. and Shanthini, J. and Karthikeyan, N.},
  doi          = {10.1007/s00500-020-05081-6},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18489-18497},
  shortjournal = {Soft Comput.},
  title        = {Volumetric analysis framework for accurate segmentation and classification (VAF-ASC) of lung tumor from CT images},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Towards developing hybrid educational data mining model
(HEDM) for efficient and accurate student performance evaluation.
<em>SOCO</em>, <em>24</em>(24), 18477–18487. (<a
href="https://doi.org/10.1007/s00500-020-05075-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many educational institutions use data mining for maintaining the student records, specifically academic performances, which are more significant. The academic performances of the students are to be analyzed for improving their results and also the overall results of the institutions. Moreover, the prediction of academic performance of students has been an important and developing research domain in educational data mining (EDM), in which data mining and machine learning techniques are used for deriving data from educational warehouse. With that, this paper develops a novel approach called hybrid educational data mining model (HEDM) for analyzing the student performance for effectively enhancing the educational quality for students. The proposed model evaluates the student performances based on distinctive factors that provide appropriate results. Furthermore, the model combines the efficiencies of Naive Baye’s classification technique and J48 Classifier for deriving the results and categorizing the student performance in precise manner. The model is evaluated with the benchmark education dataset that is available online in the WEKA environment. The results show that the proposed model outperforms the results of existing works in evaluating student performance in EDM.},
  archive      = {J_SOCO},
  author       = {Karthikeyan, V. Ganesh and Thangaraj, P. and Karthik, S.},
  doi          = {10.1007/s00500-020-05075-4},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18477-18487},
  shortjournal = {Soft Comput.},
  title        = {Towards developing hybrid educational data mining model (HEDM) for efficient and accurate student performance evaluation},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Differential evolution and ACO based global optimal feature
selection with fuzzy rough set for cancer data classification.
<em>SOCO</em>, <em>24</em>(24), 18463–18475. (<a
href="https://doi.org/10.1007/s00500-020-05070-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the biomedical research field, feature selection plays the predominant role in prediction of diseases. The main objective of this paper is to predict cancer from microarray gene expression data by proposing two feature selection algorithms, namely (1) differential evolution with fuzzy rough set feature selection and (2) ant colony optimization with fuzzy rough set feature selection algorithms, which solve the multi-objective optimization problems. The first algorithm represents the hybridization of differential evolution and fuzzy rough set and aims to select the global optimal features by applying the fuzzy rough evaluation function as the fitness function. The second algorithm, i.e., hybridization of ant colony optimization and fuzzy rough set, selects global optimal features by applying the fuzzy rough evaluation function as the fitness function. The performance of proposed two features selection algorithms is evaluated with various classification metrics, which are computed from decision tree classifier using tenfold cross-validation. Five datasets are applied to analyze the performance of the feature selection algorithms. The datasets used are diffuse large B cell lymphoma, breast cancer, Leukemia and small round blue-cell tumors which are cancer datasets. In addition, a non-medical dataset, namely Gisette, is also used to demonstrate the generalization capability of the proposed algorithms. The metrics used for comparison are, namely, accuracy, precision, recall, f-measure, specificity, processing time and receiver operating characteristics. The performance comparison evidenced improved performances for the proposed algorithms. Similar to the hybridization of differential evolution and ant colony optimization with fuzzy rough set, particle swarm optimization can be extended in the future.},
  archive      = {J_SOCO},
  author       = {Meenachi, L. and Ramakrishnan, S.},
  doi          = {10.1007/s00500-020-05070-9},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18463-18475},
  shortjournal = {Soft Comput.},
  title        = {Differential evolution and ACO based global optimal feature selection with fuzzy rough set for cancer data classification},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Genomic signal processing of microarrays for cancer gene
expression and identification using cluster-fuzzy adaptive networking.
<em>SOCO</em>, <em>24</em>(24), 18447–18462. (<a
href="https://doi.org/10.1007/s00500-020-05068-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Genomic signal processing (GSP) is a functioning exploration area of recent times and a settled technique of digital signal processing for gathering information from genomic sequences. The recognition and identification of biological signals and analysis of sequences are the fundamental objectives of using GSP. Microarray data are typically used in GSP; microarray study decides genes that cause a specific disease and helps in anticipating and diagnosing a disease, and characterization of diseases. Microarray information is incredible innovation where information handled to an enormous number with plenty of genes. Recent research works show that microarray handling will be helpful for the classification of cancer genes. Different machine learning and artificial intelligence techniques are likewise used to distinguish the tumours and cancer cells. In this examination, the genomic signal processing is carried out utilizing cluster-fuzzy adaptive networking techniques. The major purpose of this research work is to evaluate the microarray data sets for recognizing the cancer genes. The microarray data set is generated using leukaemia, colon, prostate, breast cancer and lymphoma. Initially, the noise in the microarray is filtered and smoothened by utilizing a Kalman filter followed by an optimal clustering technique such as grid density-based clustering that is applied for clustering the microarray data sets. The clustered data of microarray are classified by adaptive neuro fuzzy interference system (ANFIS) for gene sequencing process of cancer identification. The adaptive network systems are developed based on autonomous networking concepts to change the static system into a dynamic. The efficiency of clustering is evaluated in terms of cluster indexes namely partition entropy, partition coefficient, Xie and Beni. The presented ANFIS is assessed in terms of precision, accuracy, recall, sensitivity, F-score and specificity. The proposed initiated methodology is mathematically designed and executed in the MATLAB platform and run for various test runs. During the implementation, the performance of cluster and classification efficiency of proposed techniques are compared with the existing strategies like fuzzy c-means with ANN and density-based clustering with ANN, respectively. Ultimately, the performance outcomes demonstrated that the proposed method can provide effective and optimal classification and identification of microarray cancer genes through genomic signal processing than the conventional methods, respectively.},
  archive      = {J_SOCO},
  author       = {Mishra, Purnendu and Bhoi, Nilamani},
  doi          = {10.1007/s00500-020-05068-3},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18447-18462},
  shortjournal = {Soft Comput.},
  title        = {Genomic signal processing of microarrays for cancer gene expression and identification using cluster-fuzzy adaptive networking},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Novel OGBEE-based feature selection and feature-level fusion
with MLP neural network for social media multimodal sentiment analysis.
<em>SOCO</em>, <em>24</em>(24), 18431–18445. (<a
href="https://doi.org/10.1007/s00500-020-05049-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerous public networks, namely Instagram, YouTube, Facebook, Twitter, etc., share their own feelings and idea as videotapes, posts, and pictures. In future research, adapting to such data and mining valuable information from it will be an undeniably troublesome errand. This paper proposes a novel audio–video–textual-based multimodal sentiment analysis approach. The proposed approach investigates the sentiments that are collected from the web recordings that utilize audio, video, and textual modalities for further extraction. A feature-level fusion technique is employed in fusing the extracted features from different modalities. Therefore, the extracted features are optimally chosen by using a novel oppositional grass bee optimization (OGBEE) algorithm to obtain the best optimal feature set. Here, 12 benchmark functions are developed to validate the numerical efficiency and the effectiveness of a novel OGBEE algorithm for various aspects. Moreover, our proposed approach utilizes multilayer perceptron-based neural network (MLP-NN) for sentiment classification. The experimental analysis reveals that the proposed approach provides better classification accuracy of about 95.2\% with less computational time.},
  archive      = {J_SOCO},
  author       = {Bairavel, S. and Krishnamurthy, M.},
  doi          = {10.1007/s00500-020-05049-6},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18431-18445},
  shortjournal = {Soft Comput.},
  title        = {Novel OGBEE-based feature selection and feature-level fusion with MLP neural network for social media multimodal sentiment analysis},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep learning-based soft computing model for image
classification application. <em>SOCO</em>, <em>24</em>(24), 18411–18430.
(<a href="https://doi.org/10.1007/s00500-020-05048-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growth of swarm intelligence approaches and machine learning models in the field of medical image processing is extravagant, and the applicability of these approaches for various types of cancer classification has as well grown in the recent years. Considering the growth of these machine learning models, in this work attempt is taken to develop an optimized deep learning neural network classifier for classifying the nodule tissues in the lung cancer images which is an important application in biomedical area. The optimized model developed is the hybrid version of adaptive multi-swarm particle swarm optimizer with the new improved firefly algorithm resulting in better exploration and exploitation mechanism to determine near-optimal solutions. Multi-swarm particle swarm optimizer (MSPSO) possesses strong exploration capability due to its regrouping schedule nature, and the improved firefly algorithm (ImFFA) possesses better exploitation mechanism due to its inherit attractiveness and intensity feature. At this juncture, the new adaptive MSPSO–ImFFA is applied to the deep learning neural classifier to overcome the local and global minima occurrences and premature convergence by tuning its weight values. As a result, in this work the new adaptive MSPSO–ImFFA-based deep learning neural network classifier is employed to classify the lung cancer tissues of the considered lung computed tomography images. Results obtained prove the effectiveness of the deep learning classifier for the considered lung image sample datasets in comparison with the other methods compared from the previous literature works.},
  archive      = {J_SOCO},
  author       = {Revathi, M. and Jeya, I. Jasmine Selvakumari and Deepa, S. N.},
  doi          = {10.1007/s00500-020-05048-7},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18411-18430},
  shortjournal = {Soft Comput.},
  title        = {Deep learning-based soft computing model for image classification application},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). RETRACTED ARTICLE: A novel distributed training on fog node
in IoT backbone networks for security. <em>SOCO</em>, <em>24</em>(24),
18399–18410. (<a
href="https://doi.org/10.1007/s00500-020-05047-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Security is a significant issue with ubiquitous connectivity, more so with the widespread adoption of Internet of Things (IoT). The novelty of attacks with each passing day poses a conundrum to the organizations and sectors deploying the IoT. The fact remains that conventional cybersecurity frameworks face the trouble of distinguishing unknown attacks in most scenarios. Recent studies explore the endless capabilities of machine learning (ML) in reinstating the security of the IoT infrastructure. ML includes the capability of self-study and training for discovering the path for security breach and attack detection. The training methodology and progression in ML is superior to centralized detection systems. A novel methodology of distributed training on fog node in the IoT architecture with exchange of parameters (DT-FN) enhancement of intelligence through machine learning is proposed in this paper. The analyses have demonstrated that appropriated assault recognition framework has outsmarted the incorporated discovery frameworks utilizing ML model. Intrusion detection system of IoT has been incorporated on DL for more effectiveness and identification of higher level security threats. Target prejudgement-based interruption identification framework for IoT has also been discussed. The key metrics that are considered are detection rate, detection accuracy, false alarm rate, F1 measurement, precision and recall.},
  archive      = {J_SOCO},
  author       = {Sugi, S. Shinly Swarna and Ratna, S. Raja},
  doi          = {10.1007/s00500-020-05047-8},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18399-18410},
  shortjournal = {Soft Comput.},
  title        = {RETRACTED ARTICLE: A novel distributed training on fog node in IoT backbone networks for security},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). MoSSE: A novel hybrid multi-objective meta-heuristic
algorithm for engineering design problems. <em>SOCO</em>,
<em>24</em>(24), 18379–18398. (<a
href="https://doi.org/10.1007/s00500-020-05046-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel hybrid optimization algorithm called MoSSE by combining the features of Multi-objective Spotted Hyena Optimizer (MOSHO), Salp Swarm Algorithm (SSA), and Emperor Penguin Optimizer (EPO). MoSSE uses MOSHO’s searching capabilities to effectively discover the search space, SSA’s leading and selection process to achieve the fittest global solution with quicker convergence technique, and EPO’s effective mover technique for better adjustment of the next solution. The algorithm is tested on ten IEEE CEC-9 standard test functions and compared with seven well-known multi-objective optimization algorithms according to their performance. The experimental results show that MoSSE provides highly competitive outcomes in terms of convergence speed, searchability, and accuracy. Statistical testing is also performed on IEEE CEC-9 test functions. Four performance metrics (i.e., Hypervolume, $$\Delta _p$$ , Spread, and Epsilon) are used to validate the searching capability of the proposed algorithm. MoSSE is further applied to welded beam, multi-disk clutch brake, pressure vessel, 25-bar truss design problems to test its effectiveness. The findings show the utility of the proposed algorithm to resolve the real-life complex multi-objective optimization problems.},
  archive      = {J_SOCO},
  author       = {Dhiman, Gaurav and Garg, Meenakshi},
  doi          = {10.1007/s00500-020-05046-9},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18379-18398},
  shortjournal = {Soft Comput.},
  title        = {MoSSE: A novel hybrid multi-objective meta-heuristic algorithm for engineering design problems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). RETRACTED ARTICLE: Big healthcare data for trivial client
having novel smart attire (NSA). <em>SOCO</em>, <em>24</em>(24),
18367–18378. (<a
href="https://doi.org/10.1007/s00500-020-05044-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Big Data and Big Data technologies are changing the world. Healthcare is no exemption. Hospitals need to face and solve Big Data problems including collecting, processing, storing, analysing and retrieving the real-time and accumulated historical healthcare data. Big Data technologies will benefit medicine by precise diagnosis, correct treatment decisions and individualized medicine prescriptions, effective prevention planning for avoiding preventable deaths, feasible clinical trial testing outcomes or conclusions drawn on a specific medical drug for a disease, faster discovery of the root-causes and cures of many diseases such as the variety of cancers and age-related diseases; and timely prediction of disease epidemics. Big Data in healthcare emerges from the large electronic health datasets. These datasets are very difficult to manage with conventional hardware and software. In this research proposal, the emotions of the patients are monitored continuously by using Smart Attire, which collects the data and transmits for further processing and actions. The ordering system, named as Trivial client, is proposed and expanded to improve the execution of the records, that are built to hits ratio, by empowering the bigger list quality space that in class ordering arrangements. This facilitates efficient and high-throughput image processing with parallel programs typically executed on a cluster. It provides a solution for how to store a large collection of images on the Hadoop Distributed File System and make them available for efficient distributed processing.},
  archive      = {J_SOCO},
  author       = {Vasuki, N. and Rajiv Kannan, A.},
  doi          = {10.1007/s00500-020-05044-x},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18367-18378},
  shortjournal = {Soft Comput.},
  title        = {RETRACTED ARTICLE: Big healthcare data for trivial client having novel smart attire (NSA)},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). APSO-MVS: An adaptive particle swarm optimization
incorporating multiple velocity strategies for optimal leader selection
in hybrid MANETs. <em>SOCO</em>, <em>24</em>(24), 18349–18365. (<a
href="https://doi.org/10.1007/s00500-020-05034-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a hierarchical topological-based auto-configuration scheme for MANETs providing global internet connectivity among leader and member nodes to reduce the control overhead. The proposed scheme has performed the duplication address detection (DAD) operation through selecting a pre-configured node called coordinator node by a new joining cluster node. Hence, the overhead is reduced by the elimination of DAD messages broadcasting in the whole network. Also, the clustering problem in MANETs is solved by introducing a new adaptive particle swarm optimization with multiple velocity strategy (APSO-MVS) algorithm for a new leader selection with the frequent departure and failure of a leader node. However, to enhance the robustness and global searching ability of classical PSO, the three new velocity updating strategies are used in a newly developed APSO-MVS algorithm. This proposed APSO-MVS algorithm has considered multiple node metrics (node distance from the cluster group centre, node speed and node density) for the selection of an optimal leader node. Simulation results have proved the efficacy of proposed protocol in overhead reduction compared to other existing auto-configuration protocols and in terms of 15 benchmark test functions.},
  archive      = {J_SOCO},
  author       = {Priya, J. Sathya and Femina, M. A. and Samuel, R. A.},
  doi          = {10.1007/s00500-020-05034-z},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18349-18365},
  shortjournal = {Soft Comput.},
  title        = {APSO-MVS: An adaptive particle swarm optimization incorporating multiple velocity strategies for optimal leader selection in hybrid MANETs},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new hybrid optimization method combining moth–flame
optimization and teaching–learning-based optimization algorithms for
visual tracking. <em>SOCO</em>, <em>24</em>(24), 18321–18347. (<a
href="https://doi.org/10.1007/s00500-020-05032-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new hybrid algorithm based on moth–flame optimization (MFO) and teaching–learning-based optimization (TLBO) algorithm named as MFO–TLBO is proposed to overwhelm their shortcomings and inherit their advantages using the low-level coevolutionary mixed hybrid. In the best interests of this, we progress the competence of exploitation in TLBO with the ability of exploration in the MFO algorithm to demonstrate the metiers of both methods. The sole inspiration behind integrating modifications in MFO is to benefit the procedure to avoid immature convergence and to steer the search in the direction of the potential search region in a quicker way. The proposed algorithm was tested on the set of best known unimodal and multimodal benchmark functions in various dimensions. The obtained results from basic and nonparametric statistical tests confirmed that this hybrid method dominates in terms of convergence and success rate. Furthermore, MFO–TLBO is applied to visual tracking as a real-life application. All experimental outcomes, illustrations and comparative investigation found that the MFO–TLBO algorithm can vigorously track a random target object in many stimulating circumstances than the other trackers successfully.},
  archive      = {J_SOCO},
  author       = {Reddy, K. Narsimha and Bojja, Polaiah},
  doi          = {10.1007/s00500-020-05032-1},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18321-18347},
  shortjournal = {Soft Comput.},
  title        = {A new hybrid optimization method combining moth–flame optimization and teaching–learning-based optimization algorithms for visual tracking},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal object detection and tracking in occluded video
using DNN and gravitational search algorithm. <em>SOCO</em>,
<em>24</em>(24), 18301–18320. (<a
href="https://doi.org/10.1007/s00500-020-05407-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Moving object tracking is an effective optimization procedure based on the impermanent relevant information associated with the original frames. Suggesting a method with efficient accuracy in convoluted atmospheres is a difficulty for scientists in the area of research study. In this research, powerful object detection and movement tracking videos are proposed. Here, we are considering the input video sequence PETS and Hall monitor videos. Initially, the background and foreground separations are done by modified kernel fuzzy c-means algorithm. The object detection and tracking are done by gravitational search algorithm-based deep belief neural network. The implementation will be in MATLAB. The effectiveness of the recommended strategy is assessed with means of precision, recall, F-measure, FPR, FNR, PWC, FAR, similarity, specificity, and accuracy. From the experimental results, the proposed work outperforms the state of artwork. Here, the proposed method attains maximum precision and recall value for both PETS and Hall monitor video when compared to the existing algorithm.},
  archive      = {J_SOCO},
  author       = {Mahalingam, T. and Subramoniam, M.},
  doi          = {10.1007/s00500-020-05407-4},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18301-18320},
  shortjournal = {Soft Comput.},
  title        = {Optimal object detection and tracking in occluded video using DNN and gravitational search algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Group operations and isomorphic relation with the 2-tuple
linguistic variables. <em>SOCO</em>, <em>24</em>(24), 18287–18300. (<a
href="https://doi.org/10.1007/s00500-020-05367-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to put forth the theory of 2-tuple linguistic groups concerning the binary operation in the conventional sense. For this, a formal methodology has been introduced to prove that a predefined nonempty linguistic term set, LT, and the interval, $$[\frac{-1}{2},\frac{1}{2}]$$ , forms a group. Further, we have proved that a set of all 2-tuple linguistic information, $$\overline{LT} \equiv LT \times [\frac{-1}{2},\frac{1}{2}]$$ , and numerical interval, $$[-n,n]$$ , where n is presumed to be a positive integer, also forms a group. Later on, we develop a one-to-one correspondence and homomorphic group relation between the set of all 2-tuple linguistic information and numerical interval, $$[-n,n]$$ . Henceforth, a similarity relation between the two groups is obtained. Finally, a practical application is defined by proposing the notion of a 2-tuple linguistic bipolar graph to illustrate the usefulness and practicality of the group isomorphic relation.},
  archive      = {J_SOCO},
  author       = {Malhotra, Tanya and Gupta, Anjana},
  doi          = {10.1007/s00500-020-05367-9},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18287-18300},
  shortjournal = {Soft Comput.},
  title        = {Group operations and isomorphic relation with the 2-tuple linguistic variables},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Zero-divisor graphs and total coloring conjecture.
<em>SOCO</em>, <em>24</em>(24), 18273–18285. (<a
href="https://doi.org/10.1007/s00500-020-05344-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we prove that the zero-divisor graphs of a special class of pseudocomplemented posets satisfy the total coloring conjecture. Also, we determine the edge chromatic number of the zero-divisor graphs of this special class of pseudocomplemented posets. These results are applied to zero-divisor graphs of finite reduced commutative rings.},
  archive      = {J_SOCO},
  author       = {Khandekar, Nilesh and Joshi, Vinayak},
  doi          = {10.1007/s00500-020-05344-2},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18273-18285},
  shortjournal = {Soft Comput.},
  title        = {Zero-divisor graphs and total coloring conjecture},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). On bipolar fuzzy soft topology with decision-making.
<em>SOCO</em>, <em>24</em>(24), 18259–18272. (<a
href="https://doi.org/10.1007/s00500-020-05342-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we bring out the idea of bipolar fuzzy soft topology (BFS-topology) based on bipolar fuzzy soft set (BFS-set). BFS-topology is the generalization of the crisp topology. We discuss certain properties of BFS-topology including, BFS-closure, BFS-interior, BFS-exterior and BFS-frontier by utilizing BFS-points. We study the concept of BFS-subspace, BFS-neighbourhoods and BFS-base for BFS-topology with the help of detailed examples. Furthermore, we use BFS-topology in decision-making by applying an algorithm to deal with unpredictability.},
  archive      = {J_SOCO},
  author       = {Riaz, Muhammad and Tehrim, Syeda Tayyba},
  doi          = {10.1007/s00500-020-05342-4},
  journal      = {Soft Computing},
  number       = {24},
  pages        = {18259-18272},
  shortjournal = {Soft Comput.},
  title        = {On bipolar fuzzy soft topology with decision-making},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel multi-attribute decision-making framework based on
z-RIM: An illustrative example of cloud service selection.
<em>SOCO</em>, <em>24</em>(23), 18233–18247. (<a
href="https://doi.org/10.1007/s00500-020-05087-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the multi-attribute decision-making (MADM) problems, decision makers refer to the extreme attribute values in general when evaluating the alternatives. However, in the real world, the ideal solution may lie in somewhere between the extreme values. The recently proposed reference ideal method (RIM) is able to solve the problem rightly. This study aims at developing a novel MADM framework combining best–worst method (BWM), maximizing deviation method (MDM), and RIM under Z-number environment. In this framework, Z-number is used to depict the inherent uncertainty and reliability of information in the decision makers’ judgments. And BWM and MDM are combined to determine the comprehensive attribute weights, in which BWM is utilized to obtain the subjective weights, while MDM is utilized to obtain the objective weights. In addition, Z-RIM is proposed by extending the traditional RIM under Z-number environment, which is employed for ranking the alternatives. An illustrative example of cloud service selection problem is implemented to illustrate the proposed framework. By comparison analysis, we demonstrate that Z-RIM can not only avoid rank reversal problem, but also generate reasonable results during the MADM processes.},
  archive      = {J_SOCO},
  author       = {Dong, Peiwu and Zhang, Tianyu and Ju, Yanbing and Wang, Aihua},
  doi          = {10.1007/s00500-020-05087-0},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {18233-18247},
  shortjournal = {Soft Comput.},
  title        = {A novel multi-attribute decision-making framework based on Z-RIM: An illustrative example of cloud service selection},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Global-best optimization of ANN trained by PSO using the
non-extensive cross-entropy with gaussian gain. <em>SOCO</em>,
<em>24</em>(23), 18219–18231. (<a
href="https://doi.org/10.1007/s00500-020-05080-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An efficient optimization of network weights has been the primary goal of the artificial neural network (ANN) research community since decades. The aim of every optimization problem is to minimize the network cost which is some form of error function between the desired and the actual network outputs, during the training phase. The conventional gradient-based optimization algorithms like backpropagation are likely to get trapped in local minima and are sensitive to choices of initial weights. The evolutionary algorithms have proved their usefulness in introducing randomness into the optimization procedure, since they work on a global search strategy and induce a globally minimum solution for the network weights. In this paper, we particularly focus on ANN trained by Particle Swarm Optimization (ANN-PSO), in which the local-best and global-best particle positions represent possible solutions to the set of network weights. The global-best position of the swarm, which corresponds to the minimum cost function over time, is determined in our work by minimizing a new non-extensive cross-entropy error cost function. The non-extensive cross-entropy is derived from the non-extensive entropy with Gaussian gain that has proven to give minimum values for regular textures containing periodic information represented by uneven probability distributions. The new cross-entropy is defined, and its utility for optimizing the network weights to a globally minimum solution is analyzed in this paper. Extensive experimentation on two different versions: the baseline ANN-PSO and one of its most recent variants IOPSO-BPA, on benchmark datasets from the UCI repository, with comparisons to the state of the art, validates the efficacy of our method.},
  archive      = {J_SOCO},
  author       = {Susan, Seba and Ranjan, Rohit and Taluja, Udyant and Rai, Shivang and Agarwal, Pranav},
  doi          = {10.1007/s00500-020-05080-7},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {18219-18231},
  shortjournal = {Soft Comput.},
  title        = {Global-best optimization of ANN trained by PSO using the non-extensive cross-entropy with gaussian gain},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Least absolute deviations estimation for uncertain
autoregressive model. <em>SOCO</em>, <em>24</em>(23), 18211–18217. (<a
href="https://doi.org/10.1007/s00500-020-05079-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To predict future values based on imprecisely observed values, uncertain time series has been proposed, and the least-squares method has been presented to estimate the unknown parameters of uncertain autoregressive models. This paper considers the least absolute deviations estimation of uncertain autoregressive model, and a minimization problem is derived to calculate the unknown parameters in the uncertain autoregressive model. Finally, some numerical examples are given to illustrate the robustness of the least absolute deviations estimation compared with the least-squares estimation.},
  archive      = {J_SOCO},
  author       = {Yang, Xiangfeng and Park, Gyei-Kark and Hu, Yancai},
  doi          = {10.1007/s00500-020-05079-0},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {18211-18217},
  shortjournal = {Soft Comput.},
  title        = {Least absolute deviations estimation for uncertain autoregressive model},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Performance analysis of ultra-dense heterogeneous network
switching technology based on region awareness bayesian decision.
<em>SOCO</em>, <em>24</em>(23), 18203–18210. (<a
href="https://doi.org/10.1007/s00500-020-05077-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The network switching is one of the most important techniques, which keeps continuous communication between two users. A variety of approaches and strategies (such as fuzzy logic control, neural network, smart algorithm etc.) have been proposed to confront this problem. These approaches and strategies play an important role in reducing delays, decreasing drop call rates, and improving QoS during switching. However, the existing techniques and strategies often apply to some special scenarios, such as between WLAN and WiFi (or WiMAX, or 3G, or UTMS and LTE). Facing the ultra-dense heterogeneous network in the 5G communication system, this brings great difficulties to the switching, especially how to properly select a service network. Whether the existing methods and strategies are feasible remains to be studied. For solving the switching in a complication networks environment, a novel switching way is proposed in this paper. We adopt the technology of regional awareness and combine with Bayes’ decision strategy to explore the switching of ultra-dense heterogeneous network. This way effectively solves the difficult problem of selecting a service network in the convention. Finally, we analyze the err probability of the proposed way. The experimental results show that our scheme can properly select the switched network in the 5G system, and the probability of the handover error is the lowest, which ensures the rationality and effectiveness of the network handover. Therefore, the proposed way in this paper is feasible.},
  archive      = {J_SOCO},
  author       = {Xie, Chaochen and Zhao, Jianzhou and Guo, Rujing and Li, Li and Lu, Chao},
  doi          = {10.1007/s00500-020-05077-2},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {18203-18210},
  shortjournal = {Soft Comput.},
  title        = {Performance analysis of ultra-dense heterogeneous network switching technology based on region awareness bayesian decision},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Analysis of slump and surge phenomenon in chinese stock
market based on sequence alignment method. <em>SOCO</em>,
<em>24</em>(23), 18185–18202. (<a
href="https://doi.org/10.1007/s00500-020-05076-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The method of sequence alignment in bioinformatics is introduced into financial time series analysis, which can capture the large-scale features of the variables, suppress the noise and reveal the implicit mode of the system from different angles without strict assumptions. Based on existing methods of sequence alignment, we propose a new scoring matrix construction method for financial sequence alignment, a purpose-oriented matrix. This method can be used to extract the feature segments of the sequence. An empirical study of the stocks of Shanghai Stock Exchange and Shenzhen Stock Exchange is implemented with this new method. The results reflect the relationship between the two stock markets under the conditions of boom or bust and confirm the feasibility and effectiveness of introducing the method into the financial analysis.},
  archive      = {J_SOCO},
  author       = {Long, Wen and Song, Linqiu and Tian, Yingjie and Yang, Wenning},
  doi          = {10.1007/s00500-020-05076-3},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {18185-18202},
  shortjournal = {Soft Comput.},
  title        = {Analysis of slump and surge phenomenon in chinese stock market based on sequence alignment method},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multimodal image-to-image translation between domains with
high internal variability. <em>SOCO</em>, <em>24</em>(23), 18173–18184.
(<a href="https://doi.org/10.1007/s00500-020-05073-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal image-to-image translation based on generative adversarial networks (GANs) shows suboptimal performance in the visual domains with high internal variability, e.g., translation from multiple breeds of cats to multiple breeds of dogs. To alleviate this problem, we recast the training procedure as modeling distinct distributions which are observed sequentially, for example, when different classes are encountered over time. As a result, the discriminator may forget about the previous target distributions, known as catastrophic forgetting, leading to non-/slow convergence. Through experimental observation, we found that the discriminator does not always forget the previously learned distributions during training. Therefore, we propose a novel generator regulating GAN (GR-GAN). The proposed method encourages the discriminator to teach the generator more effectively when it remembers more of the previously learned distributions, while discouraging the discriminator to guide the generator when catastrophic forgetting happens on the discriminator. Both qualitative and quantitative results show that the proposed method is significantly superior to the state-of-the-art methods in handling the image data that are with high variability.},
  archive      = {J_SOCO},
  author       = {Wang, Jian and Lv, Jiancheng and Yang, Xue and Tang, Chenwei and Peng, Xi},
  doi          = {10.1007/s00500-020-05073-6},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {18173-18184},
  shortjournal = {Soft Comput.},
  title        = {Multimodal image-to-image translation between domains with high internal variability},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Simultaneous localization and mapping of medical burn areas
based on binocular vision and capsule networks. <em>SOCO</em>,
<em>24</em>(23), 18155–18171. (<a
href="https://doi.org/10.1007/s00500-020-05067-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate evaluation of burn degree is a key step in the treatment of burn patients. The body surface area of burn area is the main basis to evaluate the degree of burn. To estimate the burn area timely and accurately is the basis of providing correct infusion volume for patients and determining further treatment measures. Therefore, it is necessary to study a fast and effective method to calculate the area of human body burn. For large-area burn patients, accurate fluid replenishment in shock period plays an important role in the maintenance of vital signs and wound healing, and the estimation of burn body surface area is the basis for calculating fluid replenishment in shock period. As an important branch of computer vision, binocular stereo vision has penetrated into many fields of production and life, which is a hot topic in computer application. Binocular stereo vision technology is based on the theory of parallax, which uses binocular camera to collect the left and right views of the measured objects. The paper proposes the binocular vision uses stereo matching algorithm to calculate the position deviation between two images, so as to obtain the 3D geometric information of the object. Based on this, this paper uses binocular vision technology and capsule network model to build a medical burn area evaluation model. The experimental results show that the method proposed in this paper can effectively locate the burn area and image processing.},
  archive      = {J_SOCO},
  author       = {Wu, Xianjun and Chen, Heming and Wu, Xiaoli and Wu, Shunjun and Huang, Jinbo},
  doi          = {10.1007/s00500-020-05067-4},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {18155-18171},
  shortjournal = {Soft Comput.},
  title        = {Simultaneous localization and mapping of medical burn areas based on binocular vision and capsule networks},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Credit linked two-stage multi-objective transportation
problem in rough and bi-rough environments. <em>SOCO</em>,
<em>24</em>(23), 18129–18154. (<a
href="https://doi.org/10.1007/s00500-020-05066-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With a rapid growth of research in multi-objective transportation problem, rough and bi-rough sets are two new mathematical ideas for formulating real-world-based problems involving uncertain data. In this study, we have investigated a two-stage multi-objective transportation problem by considering credit period policy under rough and bi-rough environments. In this regard, three conflicting objective functions have been optimized simultaneously under the same restrictions. In first objective function, we have presented the minimization of transportation cost of a production house. In second objective function, total transportation cost of retailers has been minimized. But, in last one, we have maximized total profit of distributors. Besides, due to existence of different types of uncertainties in our real-life problems, in the proposed model, independent parameters (including, actual transportation cost, requirement of the retailers, and cost per unit distance) have been considered as rough in nature and dependent parameters such as demanded transportation cost and demand of the distributors have been considered as bi-rough in nature. Moreover, to convert the uncertain model into an equivalent deterministic form, a rough and bi-rough programming approach has been derived along with the expected value approach. Finally, by using these ideas, the mathematical model of our considered transportation problem has been illustrated. After that, the proposed model has been solved by applying NSGA-II algorithm (elitist non-dominated sorting genetic algorithm) with some simulated numerical data. Some sensitivity analysis associated with our proposed model has also been discussed to show the effectiveness of the model.},
  archive      = {J_SOCO},
  author       = {Bera, Raj Kumar and Mondal, Shyamal Kumar},
  doi          = {10.1007/s00500-020-05066-5},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {18129-18154},
  shortjournal = {Soft Comput.},
  title        = {Credit linked two-stage multi-objective transportation problem in rough and bi-rough environments},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Design of optimal low-pass filter by a new levy swallow
swarm algorithm. <em>SOCO</em>, <em>24</em>(23), 18113–18128. (<a
href="https://doi.org/10.1007/s00500-020-05065-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The swallow swarm optimization (SS) is a challenging method of optimization, which has a quicker convergence speed, not getting caught in the local extreme points. However, the SS suffers from a few shortcomings—(1) the movement speed of particles is not controlled suitably during the search due to the requirement of an inertia weight and (2) the less flexibility of variables does not permit to maintain a balance between the local and the global searches. To solve these problems, a new Levy swallow swarm optimization (SSLY) algorithm with the exploitation capability is proposed. This article also provides an optimal design methodology for the low-pass filter using the suggested SSLY technique. A new objective function is introduced to achieve the maximally flat frequency response, which is another important contribution to the field. The firefly algorithm (FA), the sine cosine algorithm (SCA) and the standard global optimizers—real coded genetic algorithm (GA), conventional particle swarm optimization (PSO), cuckoo search (CS) and SS, are considered for a comparison. The proposed SSLY outperforms the FA, SCA, GA, PSO, CS and SS algorithms. Results authenticate suitability of the proposed algorithm for solving the filter design problems in the FIR domain.},
  archive      = {J_SOCO},
  author       = {Sarangi, Shubhendu Kumar and Panda, Rutuparna and Abraham, Ajith},
  doi          = {10.1007/s00500-020-05065-6},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {18113-18128},
  shortjournal = {Soft Comput.},
  title        = {Design of optimal low-pass filter by a new levy swallow swarm algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). CALA-FOMF: A continuous action-set learning automata-based
approach to finding optimized membership functions for fuzzy association
rules in web usage data. <em>SOCO</em>, <em>24</em>(23), 18089–18112.
(<a href="https://doi.org/10.1007/s00500-020-05064-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Web usage data usually contain quantitative values, and this implies that fuzzy logic can be used to represent such values. The time spent by users on each web page is a part of web usage data, which can be used to analyze users’ browsing behavior. In existing research on fuzzy web mining, the time duration of web pages is shown as trapezoidal membership functions (TMFs), and the number and parameters of TMFs are already predefined. TMFs of each web page are different from those of other web pages. Therefore, instead of using predefined TMFs, in this study, we proposed a new algorithm called CALA-FOMF to find both the number of TMFs and their optimized parameters to mine fuzzy association rules in web usage data using a team of continuous action-set learning automata (CALA). CALA-FOMF contained two steps. In the first step, using a team of CALA, we introduced a new framework. The proposed framework obtained the number of TMFs as inputs and found their optimized parameters. The proposed framework was able to reduce the search space and eliminate inappropriate membership functions during the learning process. In the second step, we proposed a new algorithm using the proposed framework to find an appropriate number of TMFs and their optimized parameters. The performance of the CALA-FOMF approach was compared with that of the fuzzy web mining algorithm, which used uniform TMFs. Experiments on datasets with different sizes confirmed that the proposed CALA-FOMF increased the efficiency of mining fuzzy association rules by extracting optimized TMFs.},
  archive      = {J_SOCO},
  author       = {Anari, Zohreh and Hatamlou, Abdolreza and Masdari, Mohammad},
  doi          = {10.1007/s00500-020-05064-7},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {18089-18112},
  shortjournal = {Soft Comput.},
  title        = {CALA-FOMF: A continuous action-set learning automata-based approach to finding optimized membership functions for fuzzy association rules in web usage data},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evolutionary operators for the hamiltonian completion
problem. <em>SOCO</em>, <em>24</em>(23), 18073–18088. (<a
href="https://doi.org/10.1007/s00500-020-05063-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with evolutionary algorithms for solving the Hamiltonian completion problem. More precisely, the paper is concerned with a collection of crossover and mutation operators, which mostly originate from the traveling salesman problem, but have further on been modified or customized for Hamiltonian completion. The considered crossovers and mutations are tested on a set of randomly generated problem instances. The obtained experimental results clearly show that the behavior and relative ranking of the operators within the Hamiltonian completion environment are different than within the traveling salesman environment. Moreover, it is shown that our modified or custom-designed operator variants accomplish much better results for Hamiltonian completion than the standard variants.},
  archive      = {J_SOCO},
  author       = {Puljić, Krunoslav and Manger, Robert},
  doi          = {10.1007/s00500-020-05063-8},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {18073-18088},
  shortjournal = {Soft Comput.},
  title        = {Evolutionary operators for the hamiltonian completion problem},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The use of local information sharing on soccer game
optimization. <em>SOCO</em>, <em>24</em>(23), 18057–18072. (<a
href="https://doi.org/10.1007/s00500-020-05060-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research that focuses on the performance improvement of metaheuristics is important to gain understanding on the characteristic of specific algorithm. Better understanding of metaheuristics method will bring benefit when it comes to implement the methods to solve real problems. This paper studies the effect of local information sharing on the performance of soccer game optimization with suitable control parameter settings. A novel method, called soccer game optimization with local information sharing (SGOLS), has been proposed in this paper. The method implements local information derived from several nearby players to conduct move forward. Therefore, the move forward will consider the position of the ball dribbler, the previous best player position as well as the position of players nearby. The proposed method is evaluated based on 20 unconstraint continuous problems, consisting of unimodal function and multimodal functions, and compared to SGO, PSO and DE. The experiment result reveals that the local information sharing could enhance intensification search in SGOLS. The proposed methods perform better in high-dimensionality problems than SGO, PSO and DE. However, the use of local information consumes more computational times than the SGO and PSO, but it is still faster than DE.},
  archive      = {J_SOCO},
  author       = {Purnomo, Hindriyanto Dwi and Kristianto, Budhi and Somya, Ramos},
  doi          = {10.1007/s00500-020-05060-x},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {18057-18072},
  shortjournal = {Soft Comput.},
  title        = {The use of local information sharing on soccer game optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hybrid model to improve the river streamflow forecasting
utilizing multi-layer perceptron-based intelligent water drop
optimization algorithm. <em>SOCO</em>, <em>24</em>(23), 18039–18056. (<a
href="https://doi.org/10.1007/s00500-020-05058-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) models have been effectively applied to predict/forecast certain variable in several engineering applications, in particular, where this variable is highly stochastic in nature and complex to identify utilizing classical mathematical model, such as river streamflow. However, the existing AI models, such as multi-layer perceptron neural network (MLP-NN), are basically incomprehensible and facing problem when applied for time series prediction or forecasting. One of the main drawbacks of the MLP-NN model is the ability of the used default optimization algorithm [gradient decent algorithm (GDA)] to search for the optimal weight and bias values associated with each neuron within the MLP-NN architecture. In fact, GDA is a first-order iteration algorithm that usually trapped in local minima, especially when the time series is highly stochastic as in the river streamflow historical records. As a result, the overall performance of the MLP-NN model experienced inaccurate prediction or forecasting for the desired output. Moreover, due to the possibility of overfitting with MLP model which may lead to poor performance of prediction of the unseen input pattern, there is need to introduce new augmented algorithm capable of identifying the complexity of streamflow data and improve the prediction accuracy. Therefore, in this study, a replacement for the GDA with advanced optimization algorithm, namely intelligent water drop (IWD), is proposed to enhance the searching procedure for the global optima. The new proposed forecasting model is, namely MLP-IWD. Two different historical rivers streamflow data have been collected from Nong Son and Thanh My stations on the Vu Gia Thu Bon river basin for period between (1978 and 2016) in order to examine the performance of the proposed MLP-IWD model. In addition, in order to evaluate the performance of the proposed MLP-IWD model under different conditions, four different scenarios for the model input–output architecture have been investigated. Results showed that the proposed MLP-IWD model outperformed the classical MLP-NN model and significantly improve the forecasting accuracy for the river streamflow. Finally, the proposed model could be generalized and applied in different rivers worldwide.},
  archive      = {J_SOCO},
  author       = {Pham, Quoc Bao and Afan, Haitham Abdulmohsin and Mohammadi, Babak and Ahmed, Ali Najah and Linh, Nguyen Thi Thuy and Vo, Ngoc Duong and Moazenzadeh, Roozbeh and Yu, Pao-Shan and El-Shafie, Ahmed},
  doi          = {10.1007/s00500-020-05058-5},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {18039-18056},
  shortjournal = {Soft Comput.},
  title        = {Hybrid model to improve the river streamflow forecasting utilizing multi-layer perceptron-based intelligent water drop optimization algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Genetic programming for high-dimensional imbalanced
classification with a new fitness function and program reuse mechanism.
<em>SOCO</em>, <em>24</em>(23), 18021–18038. (<a
href="https://doi.org/10.1007/s00500-020-05056-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Genetic programming (GP) has been successfully applied to classification. However, GP may evolve biased classifiers when encountering the problem of class imbalance. These biased classifiers are often not reliable to be applied to some real-world applications. High dimensionality makes it more difficult for classifiers to effectively separate the majority class and the minority class. The use of GP to handle the joint effect of high dimensionality and class imbalance has not been heavily investigated. In this paper, we propose a GP approach to high-dimensional imbalanced classification, with the goals of increasing the classification performance as well as saving training time. To achieve this goal, a new fitness function is developed to solve the problem of class imbalance, and moreover, a strategy is proposed to reuse previous good GP individuals for improving efficiency. The proposed method is examined on ten high-dimensional imbalanced datasets. Experimental results show that, for high-dimensional imbalanced classification, the proposed method generally outperforms other GP methods and traditional classification algorithms using sampling methods to solve the problem of class imbalance.},
  archive      = {J_SOCO},
  author       = {Pei, Wenbin and Xue, Bing and Shang, Lin and Zhang, Mengjie},
  doi          = {10.1007/s00500-020-05056-7},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {18021-18038},
  shortjournal = {Soft Comput.},
  title        = {Genetic programming for high-dimensional imbalanced classification with a new fitness function and program reuse mechanism},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Designing hybrid classifiers based on general type-2 fuzzy
logic and support vector machines. <em>SOCO</em>, <em>24</em>(23),
18009–18019. (<a
href="https://doi.org/10.1007/s00500-020-05052-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper describes two alternatives for hybridizing general type-2 fuzzy logic with the Support Vector Machine (SVM), which is one of the best classification methods in the literature. The main idea of using type-2 fuzzy logic is providing SVM with the ability for uncertainty handling in real-world situations, which suffer from dynamic changes and multiple sources of uncertainty. Two approaches for general type-2 fuzzy hybrid classifiers are proposed, tested and compared based on benchmark data sets. In order to find the best hybrid combination of these methods a comparison has been realized with different experiments using diagnosis benchmark datasets by measuring the classifier accuracy. The first approach consists on using fuzzy rules as additional features to the SVM in order to increase the separability of the data. On the other hand, the second approach consists on defining the Sugeno coefficients for a general type-2 fuzzy classifier as elements of the optimal hyperplane obtained by the SVM method. The motivation for proposing these hybrid approaches is finding the best classifier combining the abilities of the original methods, which are robustness and uncertainty handling. The conclusion based on the experimental results is that the hybrid combination of both methods produces a classifier that is better than the original individual approaches.},
  archive      = {J_SOCO},
  author       = {Ontiveros, Emanuel and Melin, Patricia and Castillo, Oscar},
  doi          = {10.1007/s00500-020-05052-x},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {18009-18019},
  shortjournal = {Soft Comput.},
  title        = {Designing hybrid classifiers based on general type-2 fuzzy logic and support vector machines},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Solving differential equations with artificial bee colony
programming. <em>SOCO</em>, <em>24</em>(23), 17991–18007. (<a
href="https://doi.org/10.1007/s00500-020-05051-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relying on artificial bee colony programming (ABCP), we present in this paper, for the first time, a novel methodology for solving differential equations. The three-phase evolving process of ABCP is managed to apply on the issue of recovering the exact solution of differential equations through a well-posed problem. In fact, the original ABCP model which has been initially developed for symbolic regression cannot be used directly as differential problems might have multiple outputs. Moreover, the definition of fitness function is a critical problem-dependent issue for model design. In this sense, a problem-specific ABCP algorithm is worked out in the present contribution. With the proposed algorithm, solution with multiple outputs can evolve under a multiple-tree framework toward the exact solution. For fitness function evaluation, different forms are derived for ordinary and partial differential equations by performing experiments with multiple runs. Results on several differential equations are reported and compared to other advanced methods to assess the feasibility and the potential of the proposed method. A computational performance evaluation is provided for the considered examples and completed with an additional study on the impact of key control parameters.},
  archive      = {J_SOCO},
  author       = {Boudouaoui, Yassine and Habbi, Hacene and Ozturk, Celal and Karaboga, Dervis},
  doi          = {10.1007/s00500-020-05051-y},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {17991-18007},
  shortjournal = {Soft Comput.},
  title        = {Solving differential equations with artificial bee colony programming},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Nested AdaBoost procedure for classification and multi-class
nonlinear discriminant analysis. <em>SOCO</em>, <em>24</em>(23),
17969–17990. (<a
href="https://doi.org/10.1007/s00500-020-05045-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {AdaBoost methods find an accurate classifier by combining moderate learners that can be computed using traditional techniques based, for instance, on separating hyperplanes. Recently, we proposed a strategy to compute each moderate learner using a linear ensemble of weak classifiers that are built through the kernel support vector machine (KSVM) hypersurface geometry. In this way, we apply AdaBoost procedure in a nested loop: Each iteration of the inner loop boosts weak classifiers to a moderate one while the outer loop combines the moderate classifiers to build the global decision rule. In this paper, we explore this methodology in two ways: (a) For classification in principal component analysis (PCA) spaces; (b) For multi-class nonlinear discriminant PCA, named MNDPCA. Up to the best of our knowledge, the former is a new AdaBoost-based classification technique. Besides, in this paper we study the influence of kernel types for MNDPCA in order to set a near optimum configuration for feature selection and ranking in PCA subspaces. We compare the proposed methodologies with counterpart ones using facial expressions of the Radboud Faces database and Karolinska Directed Emotional Faces (KDEF) image database. Our experimental results have shown that MNDPCA outperforms counterpart techniques for selecting PCA features in the Radboud database while it performs close to the best technique for KDEF images. Moreover, the proposed classifier achieves outstanding recognition rates if compared with the literature techniques.},
  archive      = {J_SOCO},
  author       = {Filisbino, Tiene A. and Giraldi, Gilson A. and Thomaz, Carlos E.},
  doi          = {10.1007/s00500-020-05045-w},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {17969-17990},
  shortjournal = {Soft Comput.},
  title        = {Nested AdaBoost procedure for classification and multi-class nonlinear discriminant analysis},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The multiple steiner TSP with order constraints: Complexity
and optimization algorithms. <em>SOCO</em>, <em>24</em>(23),
17957–17968. (<a
href="https://doi.org/10.1007/s00500-020-05043-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a variant of the Travelling Salesman Problem (TSP), the Multiple Steiner TSP with Order constraints (MSTSPO). Consider a weighted undirected graph and a set of salesmen, and each salesman is associated with a set of compulsory vertices to visit, called terminals. The MSTSPO consists in finding a minimum-cost subgraph containing for each salesman a tour going in a specified order through its terminals. Along with its importance from a theoretical point of view, the problem is also challenging in practice since it has applications in telecommunication networks. We show that the problem is NP-hard even for a single salesman and propose integer programming formulations. We then devise both Branch-and-Cut and Branch-and-Price algorithms to solve the problem. The extensive computational results are presented, showing the efficiency of our algorithms.},
  archive      = {J_SOCO},
  author       = {Gabrel, Virginie and Mahjoub, A. Ridha and Taktak, Raouia and Uchoa, Eduardo},
  doi          = {10.1007/s00500-020-05043-y},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {17957-17968},
  shortjournal = {Soft Comput.},
  title        = {The multiple steiner TSP with order constraints: Complexity and optimization algorithms},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Creating a road map for industry 4.0 by using an integrated
fuzzy multicriteria decision-making methodology. <em>SOCO</em>,
<em>24</em>(23), 17931–17956. (<a
href="https://doi.org/10.1007/s00500-020-05041-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industry 4.0 can be defined as a creative manufacturing concept which is the integration of up-to-date technologies such as wireless systems, cyberphysical systems, Internet of things, cloud computing, big data concept to increase flexibility, and speed in production systems. The concept also aims to transform the manufacturing industry into the next generation. Selection among appropriate strategies for transition to industry 4.0 is crucial and should be considered in a multidimensional perspective since the decision process involves many strategies with respect to multicriteria based on the judgments of multiexperts. In this paper, this critical decision has been considered as a multicriteria decision-making (MCDM) problem under the uncertainty and vagueness environments. To increase the applicability of the uncertain data for the proposed methodology, intuitionistic fuzzy sets have been adopted. In other words, an integrated fuzzy MCDM methodology consists of interval-valued intuitionistic fuzzy analytic hierarchy process and interval-valued intuitionistic fuzzy technique for order performance by similarity to ideal solution has been suggested to prioritize of transition strategies for industry 4.0. According to proposed approach, “Training and continuing professional development” is determined as the most important strategy during the transition process, while “Technology” and “Equipment and Tools” are specified as the most crucial main and sub-criterion, respectively. For the validation process, we also applied two distance-based methods on the same decision matrices as a comparative analysis. Both analyses’ results yield that the proposed methodology is applicable and effective for the decision-making process. Besides, the results of the one-at-a-time sensitivity analyses based on the changes of main criteria weights confirm the sensitivity and flexibility of the proposed methodology. Finally, a road map for transition to industry 4.0 has been determined with respect to priorities of strategies based on the constructed context.},
  archive      = {J_SOCO},
  author       = {Kaya, İhsan and Erdoğan, Melike and Karaşan, Ali and Özkan, Betül},
  doi          = {10.1007/s00500-020-05041-0},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {17931-17956},
  shortjournal = {Soft Comput.},
  title        = {Creating a road map for industry 4.0 by using an integrated fuzzy multicriteria decision-making methodology},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A greyness reduction framework for prediction of grey
heterogeneous data. <em>SOCO</em>, <em>24</em>(23), 17913–17929. (<a
href="https://doi.org/10.1007/s00500-020-05040-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing operational rules of interval grey numbers do not make full use of possible background information when determining the interval boundaries, and this may result in inconsistent results if applying different logical operations. This paper finds that multiplication and division rules of interval grey numbers do not meet the calculation rule of inverse operators. Direct solution and inverse solution of the same interval grey number object may differ not only in numerical ranges but also in greyness degrees. To improve the accuracy of grey number calculation, new operational rules for multiplication and division of interval grey numbers are proposed. Then the traditional prediction modelling method of grey heterogeneous data is refined and expanded by integrating a greyness reduction preprocessing, which is based on the proposed calculation rules. Application of the expanded heterogeneous interval grey number prediction model to a stock replenishment scheduling problem in emergency rescue scenarios is included to illustrate the new operational rules of grey numbers and their application in prediction algorithm, and the proposed approach is compared with other existing methods to demonstrate its effectiveness.},
  archive      = {J_SOCO},
  author       = {Li, Chong and Yang, Yingjie and Liu, Sifeng},
  doi          = {10.1007/s00500-020-05040-1},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {17913-17929},
  shortjournal = {Soft Comput.},
  title        = {A greyness reduction framework for prediction of grey heterogeneous data},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Applications of accelerated computational methods for
quasi-nonexpansive operators to optimization problems. <em>SOCO</em>,
<em>24</em>(23), 17887–17911. (<a
href="https://doi.org/10.1007/s00500-020-05038-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the convergence rates of two accelerated computational methods without assuming nonexpansivity of the underlying operators with convex and affine domains in infinite-dimensional Hilbert spaces. One method is a noninertial method, and its convergence rate is estimated as $$ R_{T,{x_n}}(n)=o\left( \frac{1}{\sqrt{n}}\right) $$ in worst case. The other is an inertial method, and its convergence rate is estimated as $$ R_{T,{y_n}}(n)=o\left( \frac{1}{\sqrt{n}}\right) $$ under practical conditions. Then, we apply our results to give new results on convergence rates for solving generalized split common fixed-point problems for the class of demimetric operators. We also apply our results to variational inclusion problems and convex optimization problems. Our results significantly improve and/or develop previously discussed fixed-point problems and splitting problems and related algorithms. To demonstrate the applicability of our methods, we provide numerical examples for comparisons and numerical experiments on regression problems for publicly available high-dimensional real datasets taken from different application domains.},
  archive      = {J_SOCO},
  author       = {Sahu, D. R.},
  doi          = {10.1007/s00500-020-05038-9},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {17887-17911},
  shortjournal = {Soft Comput.},
  title        = {Applications of accelerated computational methods for quasi-nonexpansive operators to optimization problems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Solutions of linear uncertain fractional-order delay
differential equations. <em>SOCO</em>, <em>24</em>(23), 17875–17885. (<a
href="https://doi.org/10.1007/s00500-020-05037-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncertain fractional-order delay differential equation is a class of fractional-order functional differential equations driven by Liu process. This paper devotes to studying linear uncertain fractional-order delay differential equation. The explicit representation and iterative formula of the solution to linear uncertain fractional-order delay differential equations are obtained. Meanwhile, the inverse uncertainty distribution of the solution to linear uncertain fractional-order delay differential equation by the $$\alpha $$ -path is presented.},
  archive      = {J_SOCO},
  author       = {Wang, Jian and Zhu, Yuanguo},
  doi          = {10.1007/s00500-020-05037-w},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {17875-17885},
  shortjournal = {Soft Comput.},
  title        = {Solutions of linear uncertain fractional-order delay differential equations},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Real power loss reduction by duponchelia fovealis
optimization and enriched squirrel search optimization algorithms.
<em>SOCO</em>, <em>24</em>(23), 17863–17873. (<a
href="https://doi.org/10.1007/s00500-020-05036-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, Duponchelia fovealis optimization (DFO) algorithm and enriched squirrel search optimization (ESSO) algorithm are designed to solve optimal reactive power problem. DFO algorithm is based on the natural progression of the Duponchelia fovealis. In the exploration space, Duponchelia fovealis population will act as search agent and the light source is considered as optimal places of Duponchelia fovealis which attained so far. Around the light source, each Duponchelia fovealis will explore and its position has been updated. Gaussian mutation, chaotic local search and Kernel extreme learning machine which are based on extreme learning machine are applied successively in order to perk up the performance of the algorithm. Then, in this work enriched squirrel search optimization (ESSO) algorithm is projected to solve the problem. Proposed algorithm is based on the actions of squirrel foraging behavior. Naturally, squirrels are very less active and consume the stored nuts in the winter time to get ample of energy. Hickory tree (hickory nuts are found), oak tree (acorn nuts are found) and normal tree are the three types of food sources for squirrel. Naturally, the behavior (foraging) will be varied with reference to the seasonal variations. Proposed Duponchelia fovealis optimization (DFO) algorithm and enriched squirrel search optimization (ESSO) algorithm have been tested in standard IEEE 30, bus test system. The results show that the projected DFO and ESSO algorithms reduced the power loss comprehensively. Mainly, projected Duponchelia fovealis optimization (DFO) algorithm and enriched squirrel search optimization (ESSO) algorithm solved the multi-objective formulation of the problem and with reference to power loss, voltage deviation minimization and voltage stability enhancement results have been analyzed.},
  archive      = {J_SOCO},
  author       = {Lenin, Kanagasabai},
  doi          = {10.1007/s00500-020-05036-x},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {17863-17873},
  shortjournal = {Soft Comput.},
  title        = {Real power loss reduction by duponchelia fovealis optimization and enriched squirrel search optimization algorithms},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evolutionary optimization of image processing for cell
detection in microscopy images. <em>SOCO</em>, <em>24</em>(23),
17847–17862. (<a
href="https://doi.org/10.1007/s00500-020-05033-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a new evolution-based algorithm that optimizes cell detection image processing workflows in a self-adaptive fashion. We use evolution strategies to optimize the parameters for all steps of the image processing pipeline and improve cell detection results. The algorithm reliably produces good cell detection results without the need for extensive domain knowledge. Our algorithm also needs no labeled data to produce good cell detection results compared to the state-of-the-art neural network approaches. Furthermore, the algorithm can easily be adapted to different applications by modifying the processing steps in the pipeline and has high scalability since it supports multithreading and computation on graphical processing units (GPUs).},
  archive      = {J_SOCO},
  author       = {Haghofer, Andreas and Dorl, Sebastian and Oszwald, Andre and Breuss, Johannes and Jacak, Jaroslaw and Winkler, Stephan M.},
  doi          = {10.1007/s00500-020-05033-0},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {17847-17862},
  shortjournal = {Soft Comput.},
  title        = {Evolutionary optimization of image processing for cell detection in microscopy images},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-label charge predictions leveraging label
co-occurrence in imbalanced data scenario. <em>SOCO</em>,
<em>24</em>(23), 17821–17846. (<a
href="https://doi.org/10.1007/s00500-020-05029-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Charge prediction is to predict associated charges based on fact descriptions and plays a significant role in legal aid systems. It is a fundamental and challenging task to automatically predict charges in the multi-label classification paradigm, which is fit to real applications. Existing works either focus on balanced data scenario and multiple charges or few-shot charges with a single label. Moreover, previous models utilize special initialization with label patterns to improve the performance of the multi-label classification task, which is only applicable when there is less training data, resulting in poor robustness. To this end, a multi-task convolutional neural network combined with bidirectional long short-time memory leveraging label co-occurrence framework, called CBLLC, is introduced to predict multiple charges with article information on imbalanced data occasion. We develop a new learning mechanism to train the framework of charge and article patterns when there is a lot of training data, increasing its robustness. In CBLLC, the data preprocessing process serves to aid the training in a more generalized manner and reduce overfitting. A salient word annotation is introduced to deal with few-shot charges. A better classification result is obtained with processed data and improves the generality of the model. Experimental results of Chinese AI and Law Challenge test set show the superiority of our proposed method compared with the state-of-the-art methods. In particular, a macro-F1 score of 92.9\% for charges and 86.6\% for articles is achieved with co-occurrence of charges and patterns of articles.},
  archive      = {J_SOCO},
  author       = {Dong, Hongsong and Yang, Fengbao and Wang, Xiaoxia},
  doi          = {10.1007/s00500-020-05029-w},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {17821-17846},
  shortjournal = {Soft Comput.},
  title        = {Multi-label charge predictions leveraging label co-occurrence in imbalanced data scenario},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A two-stage density clustering algorithm. <em>SOCO</em>,
<em>24</em>(23), 17797–17819. (<a
href="https://doi.org/10.1007/s00500-020-05028-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering by fast search and find of density peaks (CFDP) is a popular density-based algorithm. However, it is criticized because it is inefficient and applicable only to some types of data, and requires the manual setting of the key parameter. In this paper, we propose the two-stage density clustering algorithm, which takes advantage of granular computing to address the aforementioned issues. The new algorithm is highly efficient, adaptive to various types of data, and requires minimal parameter setting. The first stage uses the two-round-means algorithm to obtain $$\sqrt{n}$$ small blocks, where n is the number of instances. This stage decreases the data size directly from n to $$\sqrt{n}$$ . The second stage constructs the master tree and obtains the final blocks. This stage borrows the structure of CFDP, while the cutoff distance parameter is not required. The time complexity of the algorithm is $$O(mn^\frac{3}{2})$$ , which is lower than $$O (mn^2)$$ for CFDP. We report the results of some experiments performed on 21 datasets from various domains to compare a new clustering algorithm with some state-of-the-art clustering algorithms. The results demonstrated that the new algorithm is adaptive to different types of datasets. It is two or more orders of magnitude faster than CFDP.},
  archive      = {J_SOCO},
  author       = {Wang, Min and Zhang, Ying-Yi and Min, Fan and Deng, Li-Ping and Gao, Lei},
  doi          = {10.1007/s00500-020-05028-x},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {17797-17819},
  shortjournal = {Soft Comput.},
  title        = {A two-stage density clustering algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Artificial neural networks training acceleration through
network science strategies. <em>SOCO</em>, <em>24</em>(23), 17787–17795.
(<a href="https://doi.org/10.1007/s00500-020-05302-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of deep learning has led to a dramatic increase in the number of applications of artificial intelligence. However, the training of deeper neural networks for stable and accurate models translates into artificial neural networks (ANNs) that become unmanageable as the number of features increases. This work extends our earlier study where we explored the acceleration effects obtained by enforcing, in turn, scale freeness, small worldness, and sparsity during the ANN training process. The efficiency of that approach was confirmed by recent studies (conducted independently) where a million-node ANN was trained on non-specialized laptops. Encouraged by those results, our study is now focused on some tunable parameters, to pursue a further acceleration effect. We show that, although optimal parameter tuning is unfeasible, due to the high non-linearity of ANN problems, we can actually come up with a set of useful guidelines that lead to speed-ups in practical cases. We find that significant reductions in execution time can generally be achieved by setting the revised fraction parameter ( $$\zeta $$ ) to relatively low values.},
  archive      = {J_SOCO},
  author       = {Cavallaro, Lucia and Bagdasar, Ovidiu and De Meo, Pasquale and Fiumara, Giacomo and Liotta, Antonio},
  doi          = {10.1007/s00500-020-05302-y},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {17787-17795},
  shortjournal = {Soft Comput.},
  title        = {Artificial neural networks training acceleration through network science strategies},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modelling human active search in optimizing black-box
functions. <em>SOCO</em>, <em>24</em>(23), 17771–17785. (<a
href="https://doi.org/10.1007/s00500-020-05398-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modelling human function learning has been the subject of intense research in cognitive sciences. The topic is relevant in black-box optimization where information about the objective and/or constraints is not available and must be learned through function evaluations. In this paper, we focus on the relation between the behaviour of humans searching for the maximum and the probabilistic model used in Bayesian optimization. As surrogate models of the unknown function, both Gaussian processes and random forest have been considered: the Bayesian learning paradigm is central in the development of active learning approaches balancing exploration/exploitation in uncertain conditions towards effective generalization in large decision spaces. In this paper, we analyse experimentally how Bayesian optimization compares to humans searching for the maximum of an unknown 2D function. A set of controlled experiments with 60 subjects, using both surrogate models, confirm that Bayesian optimization provides a general model to represent individual patterns of active learning in humans.},
  archive      = {J_SOCO},
  author       = {Candelieri, Antonio and Perego, Riccardo and Giordani, Ilaria and Ponti, Andrea and Archetti, Francesco},
  doi          = {10.1007/s00500-020-05398-2},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {17771-17785},
  shortjournal = {Soft Comput.},
  title        = {Modelling human active search in optimizing black-box functions},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Comparison of active-set and gradient projection-based
algorithms for box-constrained quadratic programming. <em>SOCO</em>,
<em>24</em>(23), 17761–17770. (<a
href="https://doi.org/10.1007/s00500-020-05304-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents on four chosen benchmarks an experimental evidence of efficiency of active-set-based algorithms and a gradient projection scheme exploiting Barzilai–Borwein-based steplength rule for box-constrained quadratic programming problems, which have theoretically proven rate of convergence. The crucial phase of active-set-based algorithms is the identification of the appropriate active set combining three types of steps—a classical minimization step, a step expanding the active set and a step reducing it. Presented algorithms employ various strategies using the components of the gradient for an update of this active set to be fast, reliable and avoiding undesirable oscillations of active set size.},
  archive      = {J_SOCO},
  author       = {Crisci, Serena and Kružík, Jakub and Pecha, Marek and Horák, David},
  doi          = {10.1007/s00500-020-05304-w},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {17761-17770},
  shortjournal = {Soft Comput.},
  title        = {Comparison of active-set and gradient projection-based algorithms for box-constrained quadratic programming},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Spherical separation with infinitely far center.
<em>SOCO</em>, <em>24</em>(23), 17751–17759. (<a
href="https://doi.org/10.1007/s00500-020-05352-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We tackle the problem of separating two finite sets of samples by means of a spherical surface, focusing on the case where the center of the sphere is fixed. Such approach reduces to the minimization of a convex and nonsmooth function of just one variable (the radius), revealing very effective in terms of computational time. In particular, we analyze the case where the center of the sphere is selected far from both the two sets, embedding the grossone idea and obtaining a kind of linear separation. Some numerical results are presented on classical binary data sets drawn from the literature.},
  archive      = {J_SOCO},
  author       = {Astorino, Annabella and Fuduli, Antonio},
  doi          = {10.1007/s00500-020-05352-2},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {17751-17759},
  shortjournal = {Soft Comput.},
  title        = {Spherical separation with infinitely far center},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the topological convergence of multi-rule sequences of
sets and fractal patterns. <em>SOCO</em>, <em>24</em>(23), 17737–17749.
(<a href="https://doi.org/10.1007/s00500-020-05358-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many cases occurring in the real world and studied in science and engineering, non-homogeneous fractal forms often emerge with striking characteristics of cyclicity or periodicity. The authors, for example, have repeatedly traced these characteristics in hydrological basins, hydraulic networks, water demand, and various datasets. But, unfortunately, today we do not yet have well-developed and at the same time simple-to-use mathematical models that allow, above all scientists and engineers, to interpret these phenomena. An interesting idea was firstly proposed by Sergeyev in 2007 under the name of “blinking fractals.” In this paper we investigate from a pure geometric point of view the fractal properties, with their computational aspects, of two main examples generated by a system of multiple rules and which are enlightening for the theme. Strengthened by them, we then propose an address for an easy formalization of the concept of blinking fractal and we discuss some possible applications and future work.},
  archive      = {J_SOCO},
  author       = {Caldarola, Fabio and Maiolo, Mario},
  doi          = {10.1007/s00500-020-05358-w},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {17737-17749},
  shortjournal = {Soft Comput.},
  title        = {On the topological convergence of multi-rule sequences of sets and fractal patterns},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Safe global optimization of expensive noisy black-box
functions in the <span class="math display"><em>δ</em></span> -lipschitz
framework. <em>SOCO</em>, <em>24</em>(23), 17715–17735. (<a
href="https://doi.org/10.1007/s00500-020-05030-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the problem of safe global maximization (it should not be confused with robust optimization) of expensive noisy black-box functions satisfying the Lipschitz condition is considered. The notion “safe” means that the objective function f(x) during optimization should not violate a “safety” threshold, for instance, a certain a priori given value h in a maximization problem. Thus, any new function evaluation (possibly corrupted by noise) must be performed at “safe points” only, namely, at points y for which it is known that the objective function $$f(y) &gt; h$$ . The main difficulty here consists in the fact that the used optimization algorithm should ensure that the safety constraint will be satisfied at a point y before evaluation of f(y) will be executed. Thus, it is required both to determine the safe region $$\varOmega $$ within the search domain D and to find the global maximum within $$\varOmega $$ . An additional difficulty consists in the fact that these problems should be solved in the presence of the noise. This paper starts with a theoretical study of the problem, and it is shown that even though the objective function f(x) satisfies the Lipschitz condition, traditional Lipschitz minorants and majorants cannot be used due to the presence of the noise. Then, a $$\delta $$ -Lipschitz framework and two algorithms using it are proposed to solve the safe global maximization problem. The first method determines the safe area within the search domain, and the second one executes the global maximization over the found safe region. For both methods, a number of theoretical results related to their functioning and convergence is established. Finally, numerical experiments confirming the reliability of the proposed procedures are performed.},
  archive      = {J_SOCO},
  author       = {Sergeyev, Yaroslav D. and Candelieri, Antonio and Kvasov, Dmitri E. and Perego, Riccardo},
  doi          = {10.1007/s00500-020-05030-3},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {17715-17735},
  shortjournal = {Soft Comput.},
  title        = {Safe global optimization of expensive noisy black-box functions in the $$\delta $$ -lipschitz framework},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Solution of asymmetric discrete competitive facility
location problems using ranking of candidate locations. <em>SOCO</em>,
<em>24</em>(23), 17705–17713. (<a
href="https://doi.org/10.1007/s00500-020-05106-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address a discrete competitive facility location problem with an asymmetric objective function and a binary customer choice rule. Both an integer linear programming formulation and a heuristic optimization algorithm based on ranking of candidate locations are designed to solve the problem. The proposed population-based heuristic algorithm is specially adapted for the discrete facility location problems by using their features such as geographical distances and the maximal possible utility of candidate locations, which can be evaluated in advance. The performance of the proposed algorithm was experimentally investigated by solving different instances of the model with real data of municipalities in Spain.},
  archive      = {J_SOCO},
  author       = {Lančinskas, Algirdas and Žilinskas, Julius and Fernández, Pascual and Pelegrín, Blas},
  doi          = {10.1007/s00500-020-05106-0},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {17705-17713},
  shortjournal = {Soft Comput.},
  title        = {Solution of asymmetric discrete competitive facility location problems using ranking of candidate locations},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). ARBF: Adaptive radial basis function interpolation algorithm
for irregularly scattered point sets. <em>SOCO</em>, <em>24</em>(23),
17693–17704. (<a
href="https://doi.org/10.1007/s00500-020-05211-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radial basis functions (RBFs) are isotropic, simple in form, dimensionally independent and mesh-free and are suitable for interpolation and fitting of scattered data. In a scattered point set, the calculation accuracy of multiquadric (MQ) RBF interpolation is strongly related to the selection of the shape factor. There is still no uniform method for determining the shape factor. Many scholars focus on determining the single optimal shape factor and seldom consider the change in the shape factor with the spatial point density in scattered point sets. In this paper, an adaptive radial basis function (ARBF) interpolation algorithm is proposed. The shape factors of MQ functions are determined adaptively by the local point densities of the points to be interpolated. To evaluate the computational performance of the ARBF interpolation algorithm, twelve groups of benchmark tests are conducted in this paper. We found that (1) the numerical error of ARBF interpolation is approximately 10\% less than that of commonly used RBF interpolation with the shape factor recommended by Hardy. (2) The computational efficiency of ARBF interpolation is 1–2.5\% lower than that of commonly used RBF interpolation with the shape factor recommended by Hardy.},
  archive      = {J_SOCO},
  author       = {Gao, Kaifeng and Mei, Gang and Cuomo, Salvatore and Piccialli, Francesco and Xu, Nengxiong},
  doi          = {10.1007/s00500-020-05211-0},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {17693-17704},
  shortjournal = {Soft Comput.},
  title        = {ARBF: Adaptive radial basis function interpolation algorithm for irregularly scattered point sets},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). FOPA-MC: Fuzzy multi-criteria group decision making for peer
assessment. <em>SOCO</em>, <em>24</em>(23), 17679–17692. (<a
href="https://doi.org/10.1007/s00500-020-05155-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Massive Open Online Courses are gaining popularity with millions of students enrolled, thousands of courses available and hundreds of learning institutions involved. Due to the high number of students and the relatively small number of tutors, student assessment, especially for complex tasks, is a typical issue of such courses. Thus, peer assessment is becoming increasingly popular to solve such a problem and several approaches have been proposed so far to improve the reliability of its outcomes. Among the most promising, there is fuzzy ordinal peer assessment (FOPA) that adopts models coming from fuzzy set theory and group decision Making. In this paper we propose an extension of FOPA supporting multi-criteria assessment based on rubrics. Students are asked to rank a small number of peer submissions against specified criteria, then provided rankings are transformed in fuzzy preference relations, expanded to obtain missing values and aggregated to estimate final grades. Results obtained are promising if compared to other peer assessment techniques both in the reconstruction of the correct ranking and on the estimation of students’ grades.},
  archive      = {J_SOCO},
  author       = {Capuano, Nicola and Caballé, Santi and Percannella, Gennaro and Ritrovato, Pierluigi},
  doi          = {10.1007/s00500-020-05155-5},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {17679-17692},
  shortjournal = {Soft Comput.},
  title        = {FOPA-MC: Fuzzy multi-criteria group decision making for peer assessment},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The use of grossone in elastic net regularization and sparse
support vector machines. <em>SOCO</em>, <em>24</em>(23), 17669–17677.
(<a href="https://doi.org/10.1007/s00500-020-05185-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {New algorithms for the numerical solution of optimization problems involving the $$l_{0}$$ pseudo-norm are proposed. They are designed to use a recently proposed computational methodology that is able to deal numerically with finite, infinite and infinitesimal numbers. This new methodology introduces an infinite unit of measure expressed by the numeral $$\textcircled {1}$$ (grossone) and indicating the number of elements of the set $${\text {I}}\!{\text {N}}$$ , of natural numbers. We show how the numerical system built upon $$\textcircled {1}$$ and the proposed approximation of the $$l_0$$ pseudo-norm in terms of $$\textcircled {1}$$ can be successfully used in the solution of elastic net regularization problems and sparse support vector machines classification problems.},
  archive      = {J_SOCO},
  author       = {De Leone, Renato and Egidi, Nadaniela and Fatone, Lorella},
  doi          = {10.1007/s00500-020-05185-z},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {17669-17677},
  shortjournal = {Soft Comput.},
  title        = {The use of grossone in elastic net regularization and sparse support vector machines},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Patient scheduling with deteriorating treatment duration and
maintenance activity. <em>SOCO</em>, <em>24</em>(23), 17649–17668. (<a
href="https://doi.org/10.1007/s00500-020-05156-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a practical scheduling problem for radiotherapy patients, who are to be scheduled on different devices at different times. The treatment duration is increasing with time because of the continuously decaying effect of the radiation source, which also results in the decline of the serving ability. Therefore, the maintenance activity (replacing radiation source) is necessary to maintain the serving ability of medical institutions. The problem is to determine the schedule of all treatments and also when to have a maintenance activity, so as to minimize the maximum completion time of all the treatments on all devices. The lower bound of the problem is given in this paper. We prove that the optimal solution of the subproblem, i.e., scheduling patients on a single device, is independent of the sequence of the patients and is only related to the division of patients who are assigned before and after the maintenance, and thus, the subproblem can be converted to a two-partition problem. An improved dynamic programming algorithm is proposed to obtain an optimal scheme for this subproblem and its performance is better than other approaches. For multiple-device problem, an effective hybrid algorithm Gaussian crow search algorithm (GCSA) combined with crow search algorithm (CSA) and Gaussian distribution is proposed to assign all patients to different treatment devices. Finally, computational experiments demonstrate the effectiveness and stability of the proposed GCSA which is compared with CSA, simulated annealing (SA) and particle swarm optimization (PSO). The comparison results show that GCSA outperforms other algorithms in a feasible time.},
  archive      = {J_SOCO},
  author       = {Shao, Kaining and Fan, Wenjuan and Yang, Zishu and Yang, Shanlin and Pardalos, Panos M.},
  doi          = {10.1007/s00500-020-05156-4},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {17649-17668},
  shortjournal = {Soft Comput.},
  title        = {Patient scheduling with deteriorating treatment duration and maintenance activity},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Piecewise linear bounding functions in univariate global
optimization. <em>SOCO</em>, <em>24</em>(23), 17631–17647. (<a
href="https://doi.org/10.1007/s00500-020-05254-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper addresses the problem of constructing lower and upper estimators for univariate functions. This problem is of crucial importance in global optimization, where such bounds are used to reduce the search area. We propose to use piecewise linear estimators for bounding univariate functions and show how such estimators can be derived from the function’s algebraic expression. The basic properties of such estimators are formulated and proved. We implemented the algorithms for the automated construction of lower and upper piecewise linear estimators and experimentally compared the proposed approach with the first-order interval bounds, Pijavskij method, and slope arithmetic. Numerical examples demonstrate that the piecewise linear estimators are more accurate with respect to the mentioned approaches. We also show that global optimization algorithms can significantly benefit from using piecewise linear estimators. Another advantage of the proposed approach is that the objective function does not have to be differentiable. This feature can favorably distinguish this method from other methods where the first and second derivatives are used.},
  archive      = {J_SOCO},
  author       = {Posypkin, Mikhail and Usov, Alexander and Khamisov, Oleg},
  doi          = {10.1007/s00500-020-05254-3},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {17631-17647},
  shortjournal = {Soft Comput.},
  title        = {Piecewise linear bounding functions in univariate global optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A constructive sequence algebra for the calculus of
indications. <em>SOCO</em>, <em>24</em>(23), 17621–17629. (<a
href="https://doi.org/10.1007/s00500-020-05121-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate some aspects of Spencer–Brown’s Calculus of Indications. Drawing from earlier work by Kauffman and Varela, we present a new categorical framework that allows to characterize the construction of infinite arithmetic expressions as sequences taking values in grossone.},
  archive      = {J_SOCO},
  author       = {Gangle, Rocco and Caterina, Gianluca and Tohmé, Fernando},
  doi          = {10.1007/s00500-020-05121-1},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {17621-17629},
  shortjournal = {Soft Comput.},
  title        = {A constructive sequence algebra for the calculus of indications},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Soft clustering by convex electoral model. <em>SOCO</em>,
<em>24</em>(23), 17609–17620. (<a
href="https://doi.org/10.1007/s00500-020-05148-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we suggest a new technique for soft clustering of multidimensional data. It is based on a new convex voting model, where each voter chooses a party with certain probability depending on the divergence between his/her preferences and the position of the party. The parties can react on the results of polls by changing their positions. We prove that under some natural assumptions this system has a unique fixed point, providing a unique solution for soft clustering. The solution of our model can be found either by imitation of the sequential elections, or by direct minimization of a convex potential function. In both cases, the methods converge linearly to the solution. We provide our methods with worst-case complexity bounds. To the best of our knowledge, these are the first polynomial-time complexity results in this field.},
  archive      = {J_SOCO},
  author       = {Nesterov, Yurii},
  doi          = {10.1007/s00500-020-05148-4},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {17609-17620},
  shortjournal = {Soft Comput.},
  title        = {Soft clustering by convex electoral model},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A hybrid of the simplicial partition-based bayesian global
search with the local descent. <em>SOCO</em>, <em>24</em>(23),
17601–17608. (<a
href="https://doi.org/10.1007/s00500-020-05095-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a global optimization algorithm hybridizing a version of Bayesian global search with local minimization. The implementation of Bayesian algorithm is based on the simplician partition of the feasible region. Our implementation is free from the typical computational complexity of the standard implementations of Bayesian algorithms. The local minimization counterpart improves the efficiency of search in the indicated potential basins of global minimum. The performance of the proposed algorithm is illustrated by the results of a numerical experiment.},
  archive      = {J_SOCO},
  author       = {Žilinskas, Antanas and Litvinas, Linas},
  doi          = {10.1007/s00500-020-05095-0},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {17601-17608},
  shortjournal = {Soft Comput.},
  title        = {A hybrid of the simplicial partition-based bayesian global search with the local descent},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the use of the infinity computer architecture to set up a
dynamic precision floating-point arithmetic. <em>SOCO</em>,
<em>24</em>(23), 17589–17600. (<a
href="https://doi.org/10.1007/s00500-020-05220-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We devise a variable precision floating-point arithmetic by exploiting the framework provided by the Infinity Computer. This is a computational platform implementing the Infinity Arithmetic system, a positional numeral system which can handle both infinite and infinitesimal quantities expressed using the positive and negative finite or infinite powers of the radix $${\textcircled {1}}$$ . The computational features offered by the Infinity Computer allow us to dynamically change the accuracy of representation and floating-point operations during the flow of a computation. When suitably implemented, this possibility turns out to be particularly advantageous when solving ill-conditioned problems. In fact, compared with a standard multi-precision arithmetic, here the accuracy is improved only when needed, thus not affecting that much the overall computational effort. An illustrative example about the solution of a nonlinear equation is also presented.},
  archive      = {J_SOCO},
  author       = {Amodio, Pierluigi and Brugnano, Luigi and Iavernaro, Felice and Mazzia, Francesca},
  doi          = {10.1007/s00500-020-05220-z},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {17589-17600},
  shortjournal = {Soft Comput.},
  title        = {On the use of the infinity computer architecture to set up a dynamic precision floating-point arithmetic},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Ritz-like values in steplength selections for stochastic
gradient methods. <em>SOCO</em>, <em>24</em>(23), 17573–17588. (<a
href="https://doi.org/10.1007/s00500-020-05219-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The steplength selection is a crucial issue for the effectiveness of the stochastic gradient methods for large-scale optimization problems arising in machine learning. In a recent paper, Bollapragada et al. (SIAM J Optim 28(4):3312–3343, 2018) propose to include an adaptive subsampling strategy into a stochastic gradient scheme, with the aim to assure the descent feature in expectation of the stochastic gradient directions. In this approach, theoretical convergence properties are preserved under the assumption that the positive steplength satisfies at any iteration a suitable bound depending on the inverse of the Lipschitz constant of the objective function gradient. In this paper, we propose to tailor for the stochastic gradient scheme the steplength selection adopted in the full-gradient method knows as limited memory steepest descent method. This strategy, based on the Ritz-like values of a suitable matrix, enables to give a local estimate of the inverse of the local Lipschitz parameter, without introducing line search techniques, while the possible increase in the size of the subsample used to compute the stochastic gradient enables to control the variance of this direction. An extensive numerical experimentation highlights that the new rule makes the tuning of the parameters less expensive than the trial procedure for the efficient selection of a constant step in standard and mini-batch stochastic gradient methods.},
  archive      = {J_SOCO},
  author       = {Franchini, Giorgia and Ruggiero, Valeria and Zanni, Luca},
  doi          = {10.1007/s00500-020-05219-6},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {17573-17588},
  shortjournal = {Soft Comput.},
  title        = {Ritz-like values in steplength selections for stochastic gradient methods},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). CPEA: A parallel method to perform pathway enrichment
analysis using multiple pathways databases. <em>SOCO</em>,
<em>24</em>(23), 17561–17572. (<a
href="https://doi.org/10.1007/s00500-020-05243-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Genes/proteins are essential to activate or inhibit biological pathways both inside or outside the cells in each living organism. The key to understand the functional roles of genes/proteins is the deduction of the relationship between pathways and genes/proteins. To understand the role of genes/proteins in a biological context, we can use pathway enrichment analysis (PEA), an essential method in omics research, to identify the biological role of genes/proteins. A large number of PEA methods and tools are available; nevertheless, only a few can perform PEA exploiting information coming from multiple databases in the same analysis. Many of these databases were initially developed to use their pathway representation format, resulting in a heterogeneous collection of resources that are extremely difficult to combine and use. Soft computing enables approximate solutions for problems challenging to solve precisely, such as merging and integrating structured and unstructured data, or data from different databases. The integration and merging of biological pathways from diverse data sources are challenging due to the different pathway data representations used. The use of parallel preprocessing methods to deal with approximation and imprecision can contribute to integrate heterogeneous pathway data. We implemented an automatic methodology to perform PEA using pathways coming from different databases and a method to compute topological scores to rank enriched pathways. This methodology is available in a software framework called cross-pathway enrichment analysis. The obtained results show good performance in terms of execution times and reduced memory consumption, allowing to improve PEA by using pathways coming from different databases.},
  archive      = {J_SOCO},
  author       = {Agapito, Giuseppe and Cannataro, Mario},
  doi          = {10.1007/s00500-020-05243-6},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {17561-17572},
  shortjournal = {Soft Comput.},
  title        = {CPEA: A parallel method to perform pathway enrichment analysis using multiple pathways databases},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A GP-based ensemble classification framework for
time-changing streams of intrusion detection data. <em>SOCO</em>,
<em>24</em>(23), 17541–17560. (<a
href="https://doi.org/10.1007/s00500-020-05200-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intrusion detection tools have largely benefitted from the usage of supervised classification methods developed in the field of data mining. However, the data produced by modern system/network logs pose many problems, such as the streaming and non-stationary nature of such data, their volume and velocity, and the presence of imbalanced classes. Classifier ensembles look a valid solution for this scenario, owing to their flexibility and scalability. In particular, data-driven schemes for combining the predictions of multiple classifiers have been shown superior to traditional fixed aggregation criteria (e.g., predictions’ averaging and weighted voting). In intrusion detection settings, however, such schemes must be devised in an efficient way, since (part of) the ensemble may need to be re-trained frequently. A novel ensemble-based framework is proposed here for the online intrusion detection, where the ensemble is updated through an incremental stream-oriented learning scheme, correspondingly to the detection of concept drifts. Differently from mainstream ensemble-based approaches in the field, our proposal relies on deriving, though an efficient genetic programming (GP) method, an expressive kind of combiner function defined in terms of (non-trainable) aggregation functions. This approach is supported by a system architecture, which integrates different kinds of functionalities, ranging from the drift detection, to the induction and replacement of base classifiers, up to the distributed computation of GP-based combiners. Experiments on both artificial and real-life datasets confirmed the validity of the approach.},
  archive      = {J_SOCO},
  author       = {Folino, Gianluigi and Pisani, Francesco Sergio and Pontieri, Luigi},
  doi          = {10.1007/s00500-020-05200-3},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {17541-17560},
  shortjournal = {Soft Comput.},
  title        = {A GP-based ensemble classification framework for time-changing streams of intrusion detection data},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Representation of grossone-based arithmetic in simulink for
scientific computing. <em>SOCO</em>, <em>24</em>(23), 17525–17539. (<a
href="https://doi.org/10.1007/s00500-020-05221-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerical computing is a key part of the traditional computer architecture. Almost all traditional computers implement the IEEE 754-1985 binary floating point standard to represent and work with numbers. The architectural limitations of traditional computers make impossible to work with infinite and infinitesimal quantities numerically. This paper is dedicated to the Infinity Computer, a new kind of a supercomputer that allows one to perform numerical computations with finite, infinite, and infinitesimal numbers. The already available software simulator of the Infinity Computer is used in different research domains for solving important real-world problems, where precision represents a key aspect. However, the software simulator is not suitable for solving problems in control theory and dynamics, where visual programming tools like Simulink are used frequently. In this context, the paper presents an innovative solution that allows one to use the Infinity Computer arithmetic within the Simulink environment. It is shown that the proposed solution is user-friendly, general purpose, and domain independent.},
  archive      = {J_SOCO},
  author       = {Falcone, Alberto and Garro, Alfredo and Mukhametzhanov, Marat S. and Sergeyev, Yaroslav D.},
  doi          = {10.1007/s00500-020-05221-y},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {17525-17539},
  shortjournal = {Soft Comput.},
  title        = {Representation of grossone-based arithmetic in simulink for scientific computing},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Discrete uniform and binomial distributions with infinite
support. <em>SOCO</em>, <em>24</em>(23), 17517–17524. (<a
href="https://doi.org/10.1007/s00500-020-05190-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study properties of two probability distributions defined on the infinite set $${0,1,2, \ldots }$$ and generalizing the ordinary discrete uniform and binomial distributions. Both extensions use the grossone-model of infinity. The first of the two distributions we study is uniform and assigns masses $$1/\textcircled {1}$$ to all points in the set $$ {0,1,\ldots ,\textcircled {1}-1}$$ , where $$\textcircled {1}$$ denotes the grossone. For this distribution, we study the problem of decomposing a random variable $$\xi $$ with this distribution as a sum $$\xi {\mathop {=}\limits ^\mathrm{d}} \xi _1 + \cdots + \xi _m$$ , where $$\xi _1 , \ldots , \xi _m$$ are independent non-degenerate random variables. Then, we develop an approximation for the probability mass function of the binomial distribution Bin $$(\textcircled {1},p)$$ with $$p=c/\textcircled {1}^{\alpha }$$ with $$1/2&lt;\alpha \le 1$$ . The accuracy of this approximation is assessed using a numerical study.},
  archive      = {J_SOCO},
  author       = {Pepelyshev, Andrey and Zhigljavsky, Anatoly},
  doi          = {10.1007/s00500-020-05190-2},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {17517-17524},
  shortjournal = {Soft Comput.},
  title        = {Discrete uniform and binomial distributions with infinite support},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Infinite games on finite graphs using grossone.
<em>SOCO</em>, <em>24</em>(23), 17509–17515. (<a
href="https://doi.org/10.1007/s00500-020-05167-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In his seminal work, Robert McNaughton [see McNaughton (Ann Pure Appl Log 65:149–184, 1993) and Khoussainov and Nerode (Automata theory and its applications. Birkhauser, Basel, 2001)] developed a model of infinite games played on finite graphs. This paper presents a new model of infinite games played on finite graphs using the grossone paradigm. The new grossone paradigm provides certain advantages such as allowing for draws, which are common in board games, and a more accurate and decisive method for determining the winner.},
  archive      = {J_SOCO},
  author       = {D’Alotto, Louis},
  doi          = {10.1007/s00500-020-05167-1},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {17509-17515},
  shortjournal = {Soft Comput.},
  title        = {Infinite games on finite graphs using grossone},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). New algebraic and geometric constructs arising from
fibonacci numbers. <em>SOCO</em>, <em>24</em>(23), 17497–17508. (<a
href="https://doi.org/10.1007/s00500-020-05256-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fibonacci numbers are the basis of a new geometric construction that leads to the definition of a family $${C_n:n\in \mathbb {N}}$$ of octagons that come very close to the regular octagon. Such octagons, in some previous articles, have been given the name of Carboncettus octagons for historical reasons. Going further, in this paper we want to introduce and investigate some algebraic constructs that arise from the family $${C_n:n\in \mathbb {N}}$$ and therefore from Fibonacci numbers: From each Carboncettus octagon $$C_n$$ , it is possible to obtain an infinite (right) word $$W_n$$ on the binary alphabet $${0,1}$$ , which we will call the nth Carboncettus word. The main theorem shows that all the Carboncettus words thus defined are Sturmian words except in the case $$n=5$$ . The fifth Carboncettus word $$W_5$$ is in fact the only word of the family to be purely periodic: It has period 17 and periodic factor 000 100 100 010 010 01. Finally, we also define a further word $$W_{\infty }$$ named the Carboncettus limit word and, as second main result, we prove that the limit of the sequence of Carboncettus words is $$W_{\infty }$$ itself.},
  archive      = {J_SOCO},
  author       = {Caldarola, Fabio and d’Atri, Gianfranco and Maiolo, Mario and Pirillo, Giuseppe},
  doi          = {10.1007/s00500-020-05256-1},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {17497-17508},
  shortjournal = {Soft Comput.},
  title        = {New algebraic and geometric constructs arising from fibonacci numbers},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). To the special issue dedicated to the 3rd international
conference “numerical computations: Theory and algorithms—NUMTA 2019”
june 15–21, 2019, isola capo rizzuto, italy. <em>SOCO</em>,
<em>24</em>(23), 17495–17496. (<a
href="https://doi.org/10.1007/s00500-020-05395-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SOCO},
  author       = {De Leone, Renato and Sergeyev, Yaroslav D. and Toraldo, Gerardo},
  doi          = {10.1007/s00500-020-05395-5},
  journal      = {Soft Computing},
  number       = {23},
  pages        = {17495-17496},
  shortjournal = {Soft Comput.},
  title        = {To the special issue dedicated to the 3rd international conference “Numerical computations: Theory and Algorithms—NUMTA 2019” june 15–21, 2019, isola capo rizzuto, italy},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). ECG signal processing and KNN classifier-based abnormality
detection by VH-doctor for remote cardiac healthcare monitoring.
<em>SOCO</em>, <em>24</em>(22), 17457–17466. (<a
href="https://doi.org/10.1007/s00500-020-05191-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the invent of medical expert systems, the demand for efficient innovative techniques in signal processing to detect abnormalities is ever increasing for identifying heart-related problems. The major objective of this research is to offer medical services to people in remote villages at low cost. People in villages and remote areas do not have a facility to get treated by a medical expert. This research provides them an opportunity to get medical advice through the virtual environment called the VH-doctor machine. It is a virtual environment heart doctor and reduces the human effort in testing and treating of heart diseases at the initial stages. The patients are treated and diagnosed only with the help of machines but not human effort. Biomedical sensors, ARM processor and FPGA are used to detect, test, analyze and display normal or abnormal cases. In this research, ECG signal processing, feature extraction and KNN classifier are performed and achieve the highest accuracy of 99\% better than other machine learning algorithms.},
  archive      = {J_SOCO},
  author       = {Venkataramanaiah, B. and Kamala, J.},
  doi          = {10.1007/s00500-020-05191-1},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {17457-17466},
  shortjournal = {Soft Comput.},
  title        = {ECG signal processing and KNN classifier-based abnormality detection by VH-doctor for remote cardiac healthcare monitoring},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Correction to: Stability analysis for a class of
fractional-order nonlinear systems with time-varying delays.
<em>SOCO</em>, <em>24</em>(22), 17455. (<a
href="https://doi.org/10.1007/s00500-020-05309-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While typesetting the article all vertical lines were removed for all equations.},
  archive      = {J_SOCO},
  author       = {Rahmanipour, Pourya and Ghadiri, Hamid},
  doi          = {10.1007/s00500-020-05309-5},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {17455},
  shortjournal = {Soft Comput.},
  title        = {Correction to: Stability analysis for a class of fractional-order nonlinear systems with time-varying delays},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Stability analysis for a class of fractional-order
nonlinear systems with time-varying delays. <em>SOCO</em>,
<em>24</em>(22), 17445–17453. (<a
href="https://doi.org/10.1007/s00500-020-05118-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the stability analysis problem of fractional-order nonlinear systems with time-varying delay. After formulating the problem and selecting the nonlinear model as the system under study, stability analysis and expression of the sufficient conditions for fractional-order nonlinear systems with time-varying delay are obtained using two different methods. In these methods, sufficient conditions for stability of fractional-order nonlinear systems are found in the form of satisfying some inequalities based on norms of nonlinear functions in the system and in terms of linear matrix inequality according fractional-order and nonlinear functions. In each case, despite the presence of time-varying delay, the system stability is ensured by meeting the stability sufficient conditions in terms of an inequality of functions and system parameters. Finally, numerical examples are given to determine the effectiveness of the proposed theorem.},
  archive      = {J_SOCO},
  author       = {Rahmanipour, Pourya and Ghadiri, Hamid},
  doi          = {10.1007/s00500-020-05118-w},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {17445-17453},
  shortjournal = {Soft Comput.},
  title        = {Stability analysis for a class of fractional-order nonlinear systems with time-varying delays},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). RETRACTED ARTICLE: Soft computing-based fuzzy time series
model for dynamic vehicle routing problem. <em>SOCO</em>,
<em>24</em>(22), 17431–17444. (<a
href="https://doi.org/10.1007/s00500-020-05111-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Utmost models for vehicle steering detailed in the writing accept consistent travel times. Plainly, disregarding the way that the movement time between two areas does not depend just on the separation voyaged, yet on numerous different variables including time, sways the use of the models to genuine issues. In the present research, a multi-target dynamic vehicle-directing issue with fuzzy time series is displayed. In this issue, majority of the work where information is known ahead of time, some setoff ongoing solicitations arrive arbitrarily after some time and the dispatcher does not have any deterministic or probabilistic data on the area and size of them until they arrive. The manuscript utilizes an immediate understanding of the multi-target dynamic vehicle-directing issue with fuzzy time series as a multi-target issue where the required armada measure, generally all out voyaging separation, and hold-up time forced on vehicles are limited, and the general clients&#39; inclinations for administration are boosted. The presentation of the proposed methodology is assessed in various strides on different test issues summed up from a lot of static occasions in the writing. In the initial step, the exhibition of the proposed methodologies is checked in static conditions and after that, different presumptions and improvements are included progressively, and changes are analyzed. Computational tests on informational collections represent the productivity and adequacy of the proposed methodology.},
  archive      = {J_SOCO},
  author       = {Ganesh, C. S. Sundar and Sivakumar, R. and Rajkumar, N.},
  doi          = {10.1007/s00500-020-05111-3},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {17431-17444},
  shortjournal = {Soft Comput.},
  title        = {RETRACTED ARTICLE: Soft computing-based fuzzy time series model for dynamic vehicle routing problem},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An intelligent multiple vehicle detection and tracking using
modified vibe algorithm and deep learning algorithm. <em>SOCO</em>,
<em>24</em>(22), 17417–17429. (<a
href="https://doi.org/10.1007/s00500-020-05042-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple vehicle detection is a promising and challenging role in intelligent transportation systems and computer vision applications. Most existing methods detect vehicles with bounding box representation and fail to offer the location of vehicles. However, the location information is vigorous for several real-time applications such as the motion estimation and trajectory of vehicles moving on the road. In this paper, we propose an advanced deep learning method called enhanced you only look once v3 and improved visual background extractor algorithms are used to detect the multi-type and multiple vehicles in an input video. More precisely, tracking is to find the trace of the upcoming vehicles using a combined Kalman filtering algorithm and particle filter techniques. To improve the tracking results, further, we propose the technique, namely multiple vehicle tracking algorithms, and tested with different weather conditions such as sunny, rainy, night and fog in input videos of 30 frames per second. The major research issues were found in the recent kinds of literature in ITS sector which is closely related to the real-time traffic environmental problems such as occlusions, camera oscillations, background changes, sensors, cluttering, camouflage, varying illumination changes in a day- and sunny and at nighttime vision. The experimental results are tested with the ten different input videos and two benchmark datasets KITTI and DETRAC. The most eight high- level features have been considered for automatic feature extraction and annotation. The attributes are length, width, height, number of mirrors and wheels and windscreen shielding glass to detect the target region of interest (vehicles) on road. In addition, further experiments are carried out in multiple-input videos of high definition quality using a monocular camera, and the average accuracy is 98.6\%, and the time complexity of the algorithm is O(n) and also tracking results attained 96.6\%. The dataset and input videos are discussed in comparative results with the F-test measure done for multiple vehicles.},
  archive      = {J_SOCO},
  author       = {Sudha, D. and Priyadarshini, J.},
  doi          = {10.1007/s00500-020-05042-z},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {17417-17429},
  shortjournal = {Soft Comput.},
  title        = {An intelligent multiple vehicle detection and tracking using modified vibe algorithm and deep learning algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Optimization of geometry quality model for wire and arc
additive manufacture based on adaptive multi-objective grey wolf
algorithm. <em>SOCO</em>, <em>24</em>(22), 17401–17416. (<a
href="https://doi.org/10.1007/s00500-020-05027-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to obtain good geometry quality in the wire and arc additive manufacture, it is important to select the appropriate process parameters. Firstly, based on the 4-factor and 5-level experiments, the multi-objective mathematical model of process parameters and geometry quality is established by response surface methodology. Secondly, an adaptive grey wolf algorithm for solving multi-objective problems is proposed. The algorithm introduces external Archive, adaptive hunting mechanism, and fusion polynomial mutation mechanism to improve the search ability of the grey wolf algorithm. Experiments show that the Pareto set obtained by the adaptive multi-objective grey wolf algorithm is more diverse and convergent than the other five well-known algorithms. Meanwhile, in order to obtain the desired geometry quality, the TOPSIS algorithm is used to analyze the Pareto set obtained to get the optimal process parameters.},
  archive      = {J_SOCO},
  author       = {Zhao, Yun-tao and Li, Wei-gang and Liu, Ao},
  doi          = {10.1007/s00500-020-05027-y},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {17401-17416},
  shortjournal = {Soft Comput.},
  title        = {Optimization of geometry quality model for wire and arc additive manufacture based on adaptive multi-objective grey wolf algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multiple attribute group decision making based on
2-dimension linguistic intuitionistic fuzzy aggregation operators.
<em>SOCO</em>, <em>24</em>(22), 17377–17400. (<a
href="https://doi.org/10.1007/s00500-020-05026-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The 2-dimension linguistic variables (2-DLVs) add a subjective evaluation on the reliability of the evaluation results provided by decision makers, so 2-DLVs are very useful tools for describing uncertain or fuzzy information. This work extends the idea of 2-DLVs by introducing 2-dimension linguistic intuitionistic fuzzy variables (2-DLIFVs) in which 1 class and 2 class information describe in the form of linguistic intuitionistic fuzzy numbers. The paper defines some operational laws, score, and accuracy functions for 2-DLIFVs. Further, we develop some arithmetic and geometric aggregation operators for aggregating 2-DLIF information and prove a number of valuable properties associated with them. Using the proposed aggregation operators, an approach for multiple attribute group decision making with 2-DLIF information is formulated. Finally, an illustrated example is given to verify and prove the validity of the developed method. The computed results are also compared with the existing results.},
  archive      = {J_SOCO},
  author       = {Verma, Rajkumar and Merigó, José M.},
  doi          = {10.1007/s00500-020-05026-z},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {17377-17400},
  shortjournal = {Soft Comput.},
  title        = {Multiple attribute group decision making based on 2-dimension linguistic intuitionistic fuzzy aggregation operators},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Identifying cancer-associated modules from microRNA
co-expression networks: A multiobjective evolutionary approach.
<em>SOCO</em>, <em>24</em>(22), 17365–17376. (<a
href="https://doi.org/10.1007/s00500-020-05025-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {MicroRNAs (miRNAs) are a class of very small noncoding RNA molecules. Although they are not directly involved in protein translation process, they indirectly regulate production of proteins by targeting different protein-coding genes or messenger RNAs (mRNAs). Several miRNAs are known to have crucial role in progression of different diseases in the human body such as cancer, diabetes, viral infection and cardiovascular diseases. Therefore, it is very important to understand the regulatory relationship among the genes and miRNAs in order to find the potential drug targets for these life-threatening diseases. In this article, a multiobjective miRNA module detection algorithm has been proposed to identify a group of miRNAs associated with several cancer types. This module detection algorithm optimizes two objective functions simultaneously. The first objective function is based on the change in miRNA co-expression pattern across the different phenotypic conditions, and the second objective function is based on the functional similarity within the miRNA pairs. Here, non-dominated sorting genetic algorithm-II (NSGA-II) has been utilized to optimize both the objective functions simultaneously so that differentially co-expressed miRNA modules having greater functional similarity can be detected. The superiority of the proposed technique is demonstrated by comparing its performance in identifying microRNA markers with that of the other existing module detection algorithms. Furthermore, the biological significance of the mRNA targets of the identified miRNA markers has been investigated.},
  archive      = {J_SOCO},
  author       = {Biswas, Paramita and Mukhopadhyay, Anirban},
  doi          = {10.1007/s00500-020-05025-0},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {17365-17376},
  shortjournal = {Soft Comput.},
  title        = {Identifying cancer-associated modules from microRNA co-expression networks: A multiobjective evolutionary approach},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modelling drugs interaction in treatment-experienced
patients on antiretroviral therapy. <em>SOCO</em>, <em>24</em>(22),
17349–17364. (<a
href="https://doi.org/10.1007/s00500-020-05024-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding pharmacology and drug resistance patterns plus appropriate use of laboratory testing is vital for managing treatment-experienced patients with new agents. While we acknowledge that patients with extensive drug resistance now have multiple options for suppressive therapy, and expert care is essential to avoid the rapid emergence of resistance to these new agents, clinicians are unaware of the inherent (hidden) patterns created by combined drug regimens that could trigger adverse drug reactions. This paper proposes a novel hybrid system framework that combines soft computing techniques, for drugs interaction modelling and precise patient response optimisation. A Fuzzy Logic system was developed to address the uncertainty in treatment change episodes (TCEs). A weighted least-squares cost function was then employed to auto-tune hyperparameters for training the neural network. After acceptable tuning, the final hyperparameters served the neural network—to efficiently learn the ensuing patterns for precice drug interaction classification. The proposed framework was experimented with clinical data of TCEs from two disparate sources: a publicly available HIV database (the Stanford HIV database: https://hivdb.stanford.edu ), and clinical data collected from 13 health centers managing HIV cases in Akwa Ibom State of Nigeria (the Akwa-Ibom HIV database). In both databases, a correlation of prognostic markers suggests strong association between first line CD4 and follow-up CD4 counts; while a moderately weak association was observed for first line and follow-up viral loads. Correlation of physiological feature gave very strong association between first line and follow-up body mass index in Akwa-Ibom database. Analysis of the patients progress explains the decreased potency of CD4 count and body mass index as HIV predictors. The root mean square error (RMSE) and classification accuracy were used as performance metrics for measuring the precision of our hybrid framework. Results obtained showed improved RMSE and classification accuracy for both databases, when compared with existing works.},
  archive      = {J_SOCO},
  author       = {Ekpenyong, Moses E. and Etebong, Philip I. and Jackson, Tendewealth C. and Udofa, Edidiong M.},
  doi          = {10.1007/s00500-020-05024-1},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {17349-17364},
  shortjournal = {Soft Comput.},
  title        = {Modelling drugs interaction in treatment-experienced patients on antiretroviral therapy},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A design of information granule-based under-sampling method
in imbalanced data classification. <em>SOCO</em>, <em>24</em>(22),
17333–17347. (<a
href="https://doi.org/10.1007/s00500-020-05023-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In numerous real-world problems, we are faced with difficulties in learning from imbalanced data. The classification performance of a “standard” classifier (learning algorithm) is evidently hindered by the imbalanced distribution of data. The over-sampling and under-sampling methods have been researched extensively with the aim to increase the predication accuracy over the minority class. However, traditional under-sampling methods tend to ignore important characteristics pertinent to the majority class. In this paper, a novel under-sampling method based on information granules is proposed. The method exploits the concepts and algorithms of granular computing. First, information granules are built around the selected patterns coming from the majority class to capture the essence of the data belonging to this class. In the sequel, the resultant information granules are evaluated in terms of their quality and those with the highest specificity values are selected. Next, the selected numeric data are augmented by some weights implied by the size of information granules. Finally, a support vector machine and a K-nearest-neighbor classifier, both being regarded here as representative classifiers, are built based on the weighted data. Experimental studies are carried out using synthetic data as well as a suite of imbalanced data sets coming from the public machine learning repositories. The experimental results quantify the performance of support vector machine and K-nearest-neighbor with under-sampling method based on information granules. The results demonstrate the superiority of the performance obtained for these classifiers endowed with conventional under-sampling method. In general, the improvement of performance expressed in terms of G-means is over 10\% when applying information granule under-sampling compared with random under-sampling.},
  archive      = {J_SOCO},
  author       = {Liu, Tianyu and Zhu, Xiubin and Pedrycz, Witold and Li, Zhiwu},
  doi          = {10.1007/s00500-020-05023-2},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {17333-17347},
  shortjournal = {Soft Comput.},
  title        = {A design of information granule-based under-sampling method in imbalanced data classification},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The effect of cutting tool material on chatter vibrations
and statistical optimization in turning operations. <em>SOCO</em>,
<em>24</em>(22), 17319–17331. (<a
href="https://doi.org/10.1007/s00500-020-05022-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine tool vibrations consist of a self-stimulating mechanism during chip removal by machining operations. The system, which is a structural mode of the tool/workpiece, is initially stimulated by force. In turning operations, a wavy surface is formed on the workpiece because of both the previous revolution and structural vibrations. The maximum chip thickness may exponentially increase due to the phase shift between two consecutive waves, while the system oscillates at a chatter frequency very close to its structural mode. Variable growth in chip thickness increases vibrations, cutting forces and tool wear and causes a wavy surface. The purpose of the study is to compare different cutting tool inserts in terms of stable cutting depths. First, an experimental study was carried out and the stable cutting depths without chatter vibrations were determined in turning operations using various materials (AISI-1010, AISI-1050, Al-7075). Alumina inserts (Al2O3) were used in the study. Stable cutting depths were compared with the literature study that was performed using titanium carbide (TiC) inserts. A paired t test was used for the comparison. After the experimental study, a statistical/optimization study was performed to optimize stable cutting depths. It was observed that the chatter frequency was generally higher than the natural frequency of the cutting tool. Also, it was observed that the decrease in the number of revolutions, tool overhang lengths and yield strength of workpiece results in higher stable cutting depths. When the number of revolution is 125 rpm, the overhang length is 70 mm, and the yield strength is 124 MPa, the stable cutting depths maximize. In addition, stable cutting depths were higher when using Al2O3 cutting tool inserts and chatter vibrations were prevented. There was a significant difference between the two inserts (p &lt; 0.05). It was found that the Al2O3 cutting tool inserts had better performances than TiC cutting inserts for the hard materials.},
  archive      = {J_SOCO},
  author       = {Gök, Fatih and Orak, Sezan and Sofuoğlu, Mehmet Alper},
  doi          = {10.1007/s00500-020-05022-3},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {17319-17331},
  shortjournal = {Soft Comput.},
  title        = {The effect of cutting tool material on chatter vibrations and statistical optimization in turning operations},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptive neural fuzzy inference system-based scheduler for
cyber–physical system. <em>SOCO</em>, <em>24</em>(22), 17309–17318. (<a
href="https://doi.org/10.1007/s00500-020-05020-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Task scheduling is one of the challenging research problems in distributed computing, especially in a complex scenario like a cyber–physical system. The cyber–physical system consists of a physical system and cyber system which are operated on the different domain of response time. The performance of the scheduling algorithm under the cyber–physical system depends on both cyber and physical factors. But both the factors are unpredictable one in reality which makes the scheduling a challenging one. This paper proposes a fuzzy logic controller based on an efficient scheduler which tackles the above problem. The proposed dynamic scheduler involves three scheduling algorithms which will be selected by the fuzzy controller based on the dynamic behavior of a cyber–physical system. A neural network is incorporated into the fuzzy controller to provide the learning capability, and an adaptive neural fuzzy inference system (ANFIS) is designed. The simulation results demonstrate the superiority of the proposed mechanism in comparison with the existing one.},
  archive      = {J_SOCO},
  author       = {Padmajothi, V. and Iqbal, J. L. Mazher},
  doi          = {10.1007/s00500-020-05020-5},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {17309-17318},
  shortjournal = {Soft Comput.},
  title        = {Adaptive neural fuzzy inference system-based scheduler for cyber–physical system},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Uncertain four-dimensional multi-objective multi-item
transportation models via GP technique. <em>SOCO</em>, <em>24</em>(22),
17291–17307. (<a
href="https://doi.org/10.1007/s00500-020-05019-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new type of four-dimensional multi-objective multi-item transportation problem is established using uncertain theory. We formulate and derive the expected value goal programming model and chance-constrained goal programming model based on the uncertain theory, where unit transportation cost, availabilities, capacities of conveyances, demands, unit transportation time, unit loading and unloading time are represented as uncertain matrices. Based on some properties of uncertain theory, the expected value goal programming model and chance-constrained goal programming model are transformed into the corresponding deterministic equivalents form via the soft computing technique, i.e., generalized reduced gradient technique named by LINGO-14.0. After that, a real-life numerical example is given to illustrate the performance of the models. Finally, the sensitivity analysis of the proposed model is presented through chance-constrained goal programming method with respect to different confidence levels.},
  archive      = {J_SOCO},
  author       = {Sahoo, Palash and Jana, Dipak Kumar and Pramanik, Sutapa and Panigrahi, Goutam},
  doi          = {10.1007/s00500-020-05019-y},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {17291-17307},
  shortjournal = {Soft Comput.},
  title        = {Uncertain four-dimensional multi-objective multi-item transportation models via GP technique},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the recognition of devanagari ancient handwritten
characters using SIFT and gabor features. <em>SOCO</em>,
<em>24</em>(22), 17279–17289. (<a
href="https://doi.org/10.1007/s00500-020-05018-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recognition of Devanagari ancient handwritten character is an important task for resourceful contents&#39; exploitation of the priceless information contained in them. There are numerous Devanagari ancient handwritten documents from fifteenth to the nineteenth century. This paper presents an optical character recognition system for the recognition of Devanagari ancient manuscripts. In this paper, improved recognition results for Devanagari ancient characters have been presented using the scale-invariant feature transform (SIFT) and Gabor filter feature extraction techniques. Support vector machine (SVM) classifier is used for the classification task in this work. For experimental results, a database consisting of 5484 samples of Devanagari characters was collected from various ancient manuscripts placed in libraries and museums. SIFT- and Gabor filter-based features are used to extract the properties of the handwritten Devanagari ancient characters for recognition. Principle component analysis is used to reduce the length of the feature vector for reducing training time of the model and to improve recognition accuracy. Recognition accuracy of 91.39\% has been achieved using the proposed system based on tenfold cross-validation technique and poly-SVM classifier.},
  archive      = {J_SOCO},
  author       = {Narang, Sonika Rani and Jindal, M. K. and Ahuja, Shruti and Kumar, Munish},
  doi          = {10.1007/s00500-020-05018-z},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {17279-17289},
  shortjournal = {Soft Comput.},
  title        = {On the recognition of devanagari ancient handwritten characters using SIFT and gabor features},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A deep learning approach for effective intrusion detection
in wireless networks using CNN. <em>SOCO</em>, <em>24</em>(22),
17265–17278. (<a
href="https://doi.org/10.1007/s00500-020-05017-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Security is playing a major role in this Internet world due to the rapid growth of Internet users. The various intrusion detection systems were developed by many researchers in the past to identify and detect the intruders using data mining techniques. However, the existing systems are not able to achieve sufficient detection accuracy when using the data mining. For this purpose, we propose a new intrusion detection system to provide security in data communication by identifying and detecting the intruders effectively in wireless networks. Here, we propose a new feature selection algorithm called conditional random field and linear correlation coefficient-based feature selection algorithm to select the most contributed features and classify them using the existing convolutional neural network. The experiments have been conducted for evaluating the proposed intrusion detection system that achieves 98.88\% as overall detection accuracy. The tenfold cross-validation has been done for evaluating the performance of the proposed model.},
  archive      = {J_SOCO},
  author       = {Riyaz, B. and Ganapathy, Sannasi},
  doi          = {10.1007/s00500-020-05017-0},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {17265-17278},
  shortjournal = {Soft Comput.},
  title        = {A deep learning approach for effective intrusion detection in wireless networks using CNN},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal design for SCAP/battery power management applied in
electric vehicle (EV) applications: A KHO–RDF technique. <em>SOCO</em>,
<em>24</em>(22), 17247–17263. (<a
href="https://doi.org/10.1007/s00500-020-05016-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This dissertation proposes power management of optimal control scheme for hybrid energy storage system (HESS) like super capacitor and (SCAP) battery in electric vehicles. The proposed technique is a parallel performance of both the random decision forest (RDF) and krill herd optimization (KHO), and thus, it is called as KHO–RDF method. The main objective is to minimize the difference between the actual and reference power in the battery and SCAP. Here, the HESS framework comprises of two sections: (1) figuring the SCAP reference voltage dependent on load dynamics. (2) Maximizing the power flow through HESS. The reference voltage of SCAP by evaluating real-time load dynamics is computed at first, i.e., the vehicle dynamic, motor characteristics, regenerative braking systems and driving conditions. Furthermore, at the same time the magnitude variety of battery power was minimized and the power loss will occur. The input parameters of SCAP are load current, battery current and state of charge. In proposed technique, possible control signals dataset of HESS is fused to produce KHO. By utilizing the practiced dataset of KHO, the RDF is trained and predicts the optimal parameters of HESS. Moreover, the proposed technique advances the SCAP voltage, battery current magnitude, battery current varieties and battery power. With the proposed approach, the parameter of HESS is optimized and it provides certain solutions. The proposed technique is executed in Matrix Laboratory (MATLAB)/Simulink working platform. By using the comparison analysis with the existing procedures, the performance of the HESS is surveyed.},
  archive      = {J_SOCO},
  author       = {Ponnupandian, Aruna and Veeramani, Vasan Prabhu},
  doi          = {10.1007/s00500-020-05016-1},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {17247-17263},
  shortjournal = {Soft Comput.},
  title        = {Optimal design for SCAP/battery power management applied in electric vehicle (EV) applications: A KHO–RDF technique},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep learning-based sequential pattern mining for
progressive database. <em>SOCO</em>, <em>24</em>(22), 17233–17246. (<a
href="https://doi.org/10.1007/s00500-020-05015-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential pattern mining (SPM) is one of the main application areas in the field of online business, e-commerce, bioinformatics, etc. The traditional approaches in SPM are unable to accurately mine the huge volume of data. Therefore, the proposed work employs a sequential mining model based on deep learning to minimize complexity in handling huge data. Application areas such as online retailing, finance, and e-commerce face a dynamic change in data, which results in non-stationary data. Therefore, our proposed work uses discrete wavelet analysis to convert non-stationary data into time series. In the proposed SPM, a reformed hybrid combination of convolutional neural network (CNN) with long short-term memory (LSTM) is designed to find out customer behavior and purchasing patterns in terms of time. CNN is used to find the concerned itemsets (frequent) at the end of the pattern and LSTM for finding the time interval among each pair of successive itemsets. The proposed work mines the sequential pattern from a progressive database that removes the obsolete data. Finally, the accuracy of the proposed work is compared with some traditional algorithms to demonstrate its robustness.},
  archive      = {J_SOCO},
  author       = {Jamshed, Aatif and Mallick, Bhawna and Kumar, Pramod},
  doi          = {10.1007/s00500-020-05015-2},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {17233-17246},
  shortjournal = {Soft Comput.},
  title        = {Deep learning-based sequential pattern mining for progressive database},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bifurcation analysis for energy transport system and its
optimal control using parameter self-tuning law. <em>SOCO</em>,
<em>24</em>(22), 17221–17231. (<a
href="https://doi.org/10.1007/s00500-020-05014-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A dynamical system for optimal path of energy and resources between two cities in China is considered in this paper. We have discussed dynamics of variables and parameters involved in mentioned system. Bifurcation analysis around non-hyperbolic equilibria is also explained for codimension 1 and 2 bifurcations. Furthermore, double-zero eigenvalue condition is calculated for the proposed model. We have adopted methodology of the generalized vectors for existence of Bogdanov–Takens bifurcation critical point and used analytical computations instead of center manifold theorem for Bogdanov–Takens bifurcation around zero equilibria. Further, with the aid of bifurcation diagram, phase portraits and time history, we discussed occurrence of period doubling, Hopf bifurcation and chaotic region of our proposed model. Based on Lyapunov function and robust control, optimal controllers are designed using Hamilton-Jacobi theorem for the stability of disturbance and aperiodic solution in optimal transportation system (3) due to energy imports from city A to city B.},
  archive      = {J_SOCO},
  author       = {Marwan, Muhammad and Ahmad, Salman},
  doi          = {10.1007/s00500-020-05014-3},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {17221-17231},
  shortjournal = {Soft Comput.},
  title        = {Bifurcation analysis for energy transport system and its optimal control using parameter self-tuning law},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). RecDNN: Deep neural network for image reconstruction from
limited view projection data. <em>SOCO</em>, <em>24</em>(22),
17205–17220. (<a
href="https://doi.org/10.1007/s00500-020-05013-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improving the quality of reconstruction, even in a limited projection view, has become one of the prime objectives in computed tomography. Projection data over 180 $$^{\circ }$$ are always not practicable in many practical applications including medical imaging. Iterative approaches, such as algebraic reconstruction techniques (ART), are useful in the limited view scenarios; however, these approaches resulted in the streaking artifacts. Deep learning has paved a path to achieve high efficiency and accuracy for reconstruction with limited view projection data. Convolutional neural networks such as U-Net, residual neural networks and adversarial neural networks are being widely used for image reconstruction. U-Net and residual neural network for limited projection views have been found compute intensive and also produces a noisy image. The convergence of the adversarial neural network in case of the inverse problem is very slow; hence, the training is compute intensive. A deep neural network for image reconstruction (RecDNN) is proposed in this manuscript for a limited view case. The proposed architecture is designed to give reconstruction with minimal artifacts. The objective is to give a good quality of textural and contrast information about the reconstructed object. The image reconstruction has been addressed as inverse problem as well as optimization problem. The stochastic gradient method is applied to achieve image reconstruction. The proposed approach has been compared to the traditional transform-based approaches as well as the current deep learning methods for image reconstruction. Experimental results show that the proposed architecture is performing better than the existing approaches, as well as the state-of-the-art architectures available for image reconstruction. Experimental results also show that for the same number of projection views, the proposed architecture reconstructs the object with higher quality as compared to existing architectures for image reconstruction.},
  archive      = {J_SOCO},
  author       = {Kalare, Kailash Wamanrao and Bajpai, Manish Kumar},
  doi          = {10.1007/s00500-020-05013-4},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {17205-17220},
  shortjournal = {Soft Comput.},
  title        = {RecDNN: Deep neural network for image reconstruction from limited view projection data},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Neoteric ranked set sampling for robust <span
class="math display"><em>X̄</em></span> and r control charts.
<em>SOCO</em>, <em>24</em>(22), 17195–17204. (<a
href="https://doi.org/10.1007/s00500-020-05012-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neoteric ranked set sampling (NRSS) is defined as an efficient sampling design compared to counterparts in the literature. NRSS differs from ranked set sampling (RSS) by selecting ordered sample units, and this design provides more accurate results for estimation of population parameters compared to RSS. This sampling design is firstly used by Koyuncu and Karagöz (Qual Technol Quant Manag 15(5):602–621, 2018) to construct control charts under bivariate asymmetric distributions. Robust control charts are another important topic for monitoring of process when the contamination exists. The novelty of this paper is that we have used NRSS design firstly in statistical process control to monitor robust control charts. Moving this direction, we have proposed to use NRSS design in modified robust methods to construct $$\bar{X}$$ and R charts under contaminated skewed distributions. The performances of the $$\bar{X}$$ and R control charts for monitoring the process by using NRSS are evaluated according to Type I risk probabilities. Based on the simulation study, the NRSS design in modified robust methods gives the most efficient results compared to existing methods.},
  archive      = {J_SOCO},
  author       = {Koyuncu, Nursel and Karagoz, Derya},
  doi          = {10.1007/s00500-020-05012-5},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {17195-17204},
  shortjournal = {Soft Comput.},
  title        = {Neoteric ranked set sampling for robust $$\bar{X}$$ and r control charts},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the weighted gini–simpson index: Estimating feasible
weights using the optimal point and discussing a link with possibility
theory. <em>SOCO</em>, <em>24</em>(22), 17187–17194. (<a
href="https://doi.org/10.1007/s00500-020-05011-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Following a brief historic note on the foundations and some applications of the Gini–Simpson index and its weighted versions, it focuses on the inversion problem relative to the maximum point of the weighted index, which has the nature of a probability distribution given a set of positive weights. Then, after revisiting the general background of the topic under study is formulated the process of estimating feasible weights that would generate the maximizer’s solution. The methodology herein explained uses a fixed-pole method, what provides a unique solution restricted to the support of the maximizer under a normalization constraint. The procedure is exemplified numerically, and an appellative link with possibility theory is discussed. The novel probability–possibility transformation here outlined, anchored in the optimal point of the weighted Gini–Simpson index and an associated consistency sufficient condition, seems to be plausible and even useful in given contexts, either as a basis for decision-making procedures or for testing real weights operating as driving forces of the composition. Also, the method provides a distinction between virtual and epistemic possibilities, relative to a defined quantitative threshold.},
  archive      = {J_SOCO},
  author       = {Casquilho, José Pinto},
  doi          = {10.1007/s00500-020-05011-6},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {17187-17194},
  shortjournal = {Soft Comput.},
  title        = {On the weighted Gini–Simpson index: Estimating feasible weights using the optimal point and discussing a link with possibility theory},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A random-fuzzy portfolio selection DEA model using
value-at-risk and conditional value-at-risk. <em>SOCO</em>,
<em>24</em>(22), 17167–17186. (<a
href="https://doi.org/10.1007/s00500-020-05010-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complexity involved in portfolio selection has resulted in the development of a large number of methods to support ambiguous financial decision making. We consider portfolio selection problems where returns from investment securities are random variables with fuzzy information and propose a data envelopment analysis model for portfolio selection with downside risk criteria associated with value-at-risk (V@R) and conditional value-at-risk (CV@R). Both V@R and CV@R criteria are used to define possibility, necessity, and credibility measures, which are formulated as stochastic nonlinear programming programs with random-fuzzy variables. Our constructed stochastic nonlinear programs for analyzing portfolio selection are transformed into deterministic nonlinear programs. Moreover, we show an enumeration algorithm can solve the model without any mathematical programs. Finally, we demonstrate the applicability of the proposed framework and the efficacy of the procedures with a numerical example.},
  archive      = {J_SOCO},
  author       = {Khanjani Shiraz, Rashed and Tavana, Madjid and Fukuyama, Hirofumi},
  doi          = {10.1007/s00500-020-05010-7},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {17167-17186},
  shortjournal = {Soft Comput.},
  title        = {A random-fuzzy portfolio selection DEA model using value-at-risk and conditional value-at-risk},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Water management using genetic algorithm-based machine
learning. <em>SOCO</em>, <em>24</em>(22), 17153–17165. (<a
href="https://doi.org/10.1007/s00500-020-05009-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Water scarcity is the major problem presently being faced globally; it is to be managed in an efficient manner. The water management procedure is one of the techniques to condense necessary water. The objective of water management system is that water supply agency to collect, distribute quality water without any delay and scarcity. An intelligent system is necessary for efficient production, collection and distribution. The proposed intelligent system consists of genetic operations with fitness value and neural network for training. The fitness function is used to make new intelligent members from existing population of water resources for water collection and distribution. The system is applicable for prediction about water consumption, distribution using decision-making algorithms to increase optimization performance by calculation of objective function of various population types. The regression performance of proposed intelligent system is calculated and compared with other algorithms.},
  archive      = {J_SOCO},
  author       = {Gino Sophia, S. G. and Ceronmani Sharmila, V. and Suchitra, S. and Sudalai Muthu, T. and Pavithra, B.},
  doi          = {10.1007/s00500-020-05009-0},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {17153-17165},
  shortjournal = {Soft Comput.},
  title        = {Water management using genetic algorithm-based machine learning},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stochastic recurrent wavelet neural network with EEMD method
on energy price prediction. <em>SOCO</em>, <em>24</em>(22), 17133–17151.
(<a href="https://doi.org/10.1007/s00500-020-05007-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Novel hybrid neural network prediction model (denoted by E-SRWNN) is formed by combining ensemble empirical mode decomposition (EEMD) and stochastic recurrent wavelet neural network (SRWNN), in order to improve the precision of energy indexes price forecasting. Energy index price series are non-stationary, nonlinear and random. EEMD method is utilized to decompose the closing prices of four energy indexes into subsequences with different frequencies, and the SRWNN model is composed by adding stochastic time effective function and recurrent layer to the wavelet neural network (WNN). Stochastic time effective function makes the model assign different weights to the historical data at different times, and the introduction of recurrent layer structure will enhance the data learning. In this paper, E-SRWNN model is compared with other WNN-based models and the deep learning network GRU. In the error evaluation, the general standards, such as linear regression analysis, mean absolute error and theil inequality coefficient, are utilized to compare the predicted effects of different models, and then multiscale complexity-invariant distance is applied for further analysis. Empirical research illustrates that the proposed E-SRWNN model displays strong forecasting ability and accurate forecasting results in energy price series forecasting.},
  archive      = {J_SOCO},
  author       = {Li, Jingmiao and Wang, Jun},
  doi          = {10.1007/s00500-020-05007-2},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {17133-17151},
  shortjournal = {Soft Comput.},
  title        = {Stochastic recurrent wavelet neural network with EEMD method on energy price prediction},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Uncertain nonlinear system identification using jaya-based
adaptive neural network. <em>SOCO</em>, <em>24</em>(22), 17123–17132.
(<a href="https://doi.org/10.1007/s00500-020-05006-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The piezoelectric actuator has been receiving tremendous interest in the past decade, due to its broad applications in areas of micro-robotics, neurosurgical robot, MEMS, exoskeleton, medical applications, and other applications. However, the hysteresis nonlinearity widely existing in smart materials yields undesirable responses, which make the hysteresis control problem even more challenging. Therefore, many studies based on artificial neural networks have been developed to cope with the hysteresis nonlinearity. However, the back-propagation algorithm which is popular in training a neural network model often performs local optima with stagnation and slow convergence speed. To overcome these drawbacks, this paper proposes a new training algorithm based on the Jaya algorithm to optimize the weights of the neural NARX model (called Jaya-NNARX). The performance and efficiency of the proposed method are tested on identifying two typical nonlinear benchmark test functions and are compared with those of a classical BP algorithm, particle swarm optimization algorithm, and differential evolution algorithm. Forwardly, the proposed Jaya-NNARX method is applied to identify the nonlinear hysteresis behavior of the piezoelectric actuator. The identification results demonstrate that the proposed algorithm can successfully identify the highly uncertain nonlinear system with perfect precision.},
  archive      = {J_SOCO},
  author       = {Son, Nguyen Ngoc and Chinh, Tran Minh and Anh, Ho Pham Huy},
  doi          = {10.1007/s00500-020-05006-3},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {17123-17132},
  shortjournal = {Soft Comput.},
  title        = {Uncertain nonlinear system identification using jaya-based adaptive neural network},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new machine learning-based healthcare monitoring model for
student’s condition diagnosis in internet of things environment.
<em>SOCO</em>, <em>24</em>(22), 17111–17121. (<a
href="https://doi.org/10.1007/s00500-020-05003-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advancement in sensor technologies has resulted in rapid evolution of Internet of Things (IoT) applications for developing behavioral and physiological monitoring systems such as IoT-based student healthcare monitoring system. Nowadays, a growing number of students living alone scattered over wide geographical areas, and tracking their health function status is necessary. In this paper, an IoT-based student healthcare monitoring model is proposed to continuously check student vital signs and detect biological and behavioral changes via smart healthcare technologies. In this model, vital data are collected via IoT devices and data analysis is carried out through the machine learning methods for detecting the probable risks of student’s physiological and behavioral changes. The experimental results reveal that the proposed model meets the efficiency and proper accuracy for detecting the students’ condition. After evaluating the proposed model, the support vector machine has achieved the highest accuracy of 99.1\% which is a promising result for our purpose. The results outperformed decision tree, random forest, and multilayer perceptron neural network algorithms as well.},
  archive      = {J_SOCO},
  author       = {Souri, Alireza and Ghafour, Marwan Yassin and Ahmed, Aram Mahmood and Safara, Fatemeh and Yamini, Ali and Hoseyninezhad, Mahdi},
  doi          = {10.1007/s00500-020-05003-6},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {17111-17121},
  shortjournal = {Soft Comput.},
  title        = {A new machine learning-based healthcare monitoring model for student’s condition diagnosis in internet of things environment},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evolutionary optimization of artificial neural network using
an interactive phase-based optimization algorithm for chaotic time
series prediction. <em>SOCO</em>, <em>24</em>(22), 17093–17109. (<a
href="https://doi.org/10.1007/s00500-020-05002-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prediction of chaotic time series is an important issue in nonlinear information procession. Due to the multi-modal, high-dimensional and non-differentiable or discontinuous characteristics of chaotic systems, global optimization techniques are required to avoid from falling into local optima for the prediction of chaotic time series. Phase-based optimization is recently proposed as a global search algorithm inspired by natural phenomena. In this paper, an improved phase-based optimization algorithm integrating stochastic interaction strategy and global optimal interaction strategy, termed interactive phase-based optimization (IPBO), is proposed to train feed-forward neural networks (FNNs) for chaotic time series prediction. The combination of stochastic interaction strategy and global optimal interaction strategy can balance the capability of exploration and exploitation in the global optimization process. To demonstrate the searching capability, sixteen widely used benchmark functions are firstly used to investigate its optimization performance. Then, the prediction effectiveness of FNNs trained by IPBO has been illustrated using classical chaotic time series of Lorenz, Box–Jenkins and Mackey–Glass. The training and testing performances of IPBO and other state-of-the-art optimization algorithms have been compared for predicting these time series. Conducted numerical experiments indicate that IPBO is not only competitive in functions optimization and has also a better learning ability in training FNNs among other state-of-the-art optimization algorithms.},
  archive      = {J_SOCO},
  author       = {Cao, Zijian},
  doi          = {10.1007/s00500-020-05002-7},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {17093-17109},
  shortjournal = {Soft Comput.},
  title        = {Evolutionary optimization of artificial neural network using an interactive phase-based optimization algorithm for chaotic time series prediction},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Enhanced pedestrian detection using optimized deep
convolution neural network for smart building surveillance.
<em>SOCO</em>, <em>24</em>(22), 17081–17092. (<a
href="https://doi.org/10.1007/s00500-020-04999-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pedestrian detection and tracking is a critical task in the area of smart building surveillance. Due to advancements in sensors, the architects concentrate in construction of smart buildings. Pedestrian detection in smart building is greatly challenged by the image noises by various external environmental parameters. Traditional filter-based techniques for image classification like histogram of oriented gradients filters and machine learning algorithms suffer to perform well for huge volume of pedestrian input images. The advancements in deep learning algorithms perform exponentially good in handling the huge volume of image data. The current study proposes a pedestrian detection model based on deep convolution neural network (CNN) for classification of pedestrians from the input images. Proposed optimized version of VGG-16 architecture is evaluated for pedestrian detection on the INRIA benchmarking dataset consisting of 227 × 227 pixel images. The proposed model achieves an accuracy of 98.5\%. It was found that proposed model performs better than the other pretrained CNN architectures and other machine learning models. Pedestrians are reasonably detected and the performance of the proposed algorithm is validated.},
  archive      = {J_SOCO},
  author       = {Kim, Bubryur and Yuvaraj, N. and Sri Preethaa, K. R. and Santhosh, R. and Sabari, A.},
  doi          = {10.1007/s00500-020-04999-1},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {17081-17092},
  shortjournal = {Soft Comput.},
  title        = {Enhanced pedestrian detection using optimized deep convolution neural network for smart building surveillance},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An efficient parameter estimation method for nonlinear
high-order systems via surrogate modeling and cuckoo search.
<em>SOCO</em>, <em>24</em>(22), 17065–17079. (<a
href="https://doi.org/10.1007/s00500-020-04997-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work developed an efficient parameter estimation method for nonlinear high-order systems using surrogate modeling and cuckoo search. Specifically, to address the heavy computational burden required for evaluating the candidate parameters, we utilized a low-dimensional surrogate model to approximate the original system. The surrogate model was constructed by employing the proper orthogonal decomposition and the discrete empirical interpolation method. Then, to obtain the parameters of the original system, we applied the cuckoo search algorithm to solve the optimization problem that was built on the surrogate model. The accuracy and efficiency of the proposed method were verified on two numerical experiments, dealing with the identification of parameters for the FitzHugh–Nagumo system and the predator–prey system. The results showed that our approach yields accurate results while significantly reducing the computational cost.},
  archive      = {J_SOCO},
  author       = {Lai, Xuefang and Wang, Xiaolong and Nie, Yufeng and He, Xingshi},
  doi          = {10.1007/s00500-020-04997-3},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {17065-17079},
  shortjournal = {Soft Comput.},
  title        = {An efficient parameter estimation method for nonlinear high-order systems via surrogate modeling and cuckoo search},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new effective robust nonlinear controller based on PSO for
interleaved DC–DC boost converters for fuel cell voltage regulation.
<em>SOCO</em>, <em>24</em>(22), 17051–17064. (<a
href="https://doi.org/10.1007/s00500-020-04996-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Output voltage regulation of DC–DC converters has recently gained an increasing attention to face the many system nonidealities. The fast switching behavior is nonlinear time varying, the presence of model and measurement uncertainties, and large variations, are all inherited challenges. The aim of the present work is to design a robust nonlinear controller that ensures satisfactory and robust output voltage regulation for a proton-exchange membrane fuel cell (PEMFC) based on a DC–DC Interleaved Boost Converter (IBC). A state-space model of the DC–DC IBC is first derived using the state-space averaging technique, and a mathematical model is constructed for the PEFMC. In this regard, a robust nonlinear controller and a proportional integral controller are proposed. The controllers are tuned though particle swarm optimization algorithm to estimate their good parameters assuring the desired performance is met. The integral of absolute error criterion is used to improve the dynamic performance of the overall controlled system. Furthermore, the closed-loop stability is analyzed using the Lyapunov stability theorem, and the effectiveness of the closed-loop system is validated under various operating conditions of the PEMFC and load perturbations. Compared to other methods, the obtained results demonstrate a superior performance of the proposed control strategy in terms of its robustness to variations and uncertainties, smooth tracking of a varying set-point and faster transients.},
  archive      = {J_SOCO},
  author       = {Abdelmalek, Samir and Dali, Ali and Bettayeb, Maamar and Bakdi, Azzeddine},
  doi          = {10.1007/s00500-020-04996-4},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {17051-17064},
  shortjournal = {Soft Comput.},
  title        = {A new effective robust nonlinear controller based on PSO for interleaved DC–DC boost converters for fuel cell voltage regulation},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fuzzy modeling of refractory cement viscosity to improve
thermocouples manufacturing process. <em>SOCO</em>, <em>24</em>(22),
17035–17050. (<a
href="https://doi.org/10.1007/s00500-020-04995-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Refractory cement is one of the elementary materials for the thermocouples manufacture. It is important pointing out that viscosity greatly affects its quality and functionality. In this sense, there is a viscosity range in which refractory cement must be applied; this range is known as “pot life.” For this reason, the cement setting process (viscosity behavior) should be modeled in order to predict its life (useful time). Like this, some operational factors must be considered, among them: temperature and humidity as well as the fact that pot life behavior is nonlinear and must be performed by a growth model. At the modeling process, it is necessary considering the uncertainty which is not considered in the properties of the bodies studied in the rheological models for real materials. This work proposes an inverse prediction method for measuring the prediction error time. Furthermore, it is suggested performing the estimated times by a triangular fuzzy number with the purpose of considering all uncertainty information and providing a reliable prediction. Therefore, the fuzzy theory to the Weibull analysis was adapted in order to estimate some faculties: the fuzzy reliability, the fuzzy useful time with a desired reliability and the fuzzy mean pot life. Results show accuracy and useful pot life predictions.},
  archive      = {J_SOCO},
  author       = {González-González, David Salvador and Praga-Alejo, Rolando Javier and Cantu-Sifuentes, Mario and Alvarez-Vera, Melvyn},
  doi          = {10.1007/s00500-020-04995-5},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {17035-17050},
  shortjournal = {Soft Comput.},
  title        = {Fuzzy modeling of refractory cement viscosity to improve thermocouples manufacturing process},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Shadowed sets with higher approximation regions.
<em>SOCO</em>, <em>24</em>(22), 17009–17033. (<a
href="https://doi.org/10.1007/s00500-020-04992-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper mainly discusses three points involving shadowed set approximation of a given fuzzy set. Firstly, a principle of uncertainty balance, which guarantees that preservation of uncertainty in the induced shadowed set is studied. Secondly, an alternative formulation for determining the optimum partition thresholds of shadowed sets is suggested. This formulation helps us study principle of uncertainty balance in shadowed sets with higher approximation regions. Thirdly, five-region shadowed set, which effectively deals with the issue of uncertainty balance, is introduced. We provide a closed-form formula for determining its optimum partition thresholds and generalize it to $$n (\ge 5)$$ -region shadowed sets. Finally, some examples from synthetic and real dataset are provided to demonstrate the feasibility of the suggested methods.},
  archive      = {J_SOCO},
  author       = {Ibrahim, M. A. and William-West, T. O. and Kana, A. F. D. and Singh, D.},
  doi          = {10.1007/s00500-020-04992-8},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {17009-17033},
  shortjournal = {Soft Comput.},
  title        = {Shadowed sets with higher approximation regions},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Uncertain vector autoregressive model with imprecise
observations. <em>SOCO</em>, <em>24</em>(22), 17001–17007. (<a
href="https://doi.org/10.1007/s00500-020-04991-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prior uncertain autoregressive (UAR) model research has focused principally on a univariate time series. However, different variables tend to influence each other in reality. In order to fill this gap, this paper explores the interrelationships among different variables and proposes an exposition of uncertain vector autoregressive (UVAR) model. Furthermore, we choose the least squares principle to estimate the unknown parameters in the UVAR model and analyze the residual of disturbance term. Then, we present the point estimation and confidence interval of the variables in the next period. Finally, the empirical results show that essential improvements in forecasting can be obtained by adding relative variables.},
  archive      = {J_SOCO},
  author       = {Tang, Han},
  doi          = {10.1007/s00500-020-04991-9},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {17001-17007},
  shortjournal = {Soft Comput.},
  title        = {Uncertain vector autoregressive model with imprecise observations},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Semantic analysis-based relevant data retrieval model using
feature selection, summarization and CNN. <em>SOCO</em>,
<em>24</em>(22), 16983–17000. (<a
href="https://doi.org/10.1007/s00500-020-04990-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic analysis is playing a major role and task in text mining process caused by the presence of huge number of relevant and irrelevant data in Internet and other resources. Here, the semantic-based text summarization must be incorporated for the successful relevant data extraction by using data classification. The accurate classification process is done by using deep learning techniques recently. However, no existing model is achieved reasonable relevancy accuracy. For overcoming the drawbacks, we propose an effective semantic analysis-based relevant data retrieval model for retrieving the relevant data from local repository or web applications in Internet. This new model consists of (i) semantic similarity-based feature selection and (ii) enrichment technique, (iii) data summarization technique and iv) text relationship-based deep neural network classifier. Here, we propose a new semantic analysis-based feature selection algorithm to select the similarity indexed relevant data from local repositories or web applications. In addition, a new semantic-based data summarization technique is also introduced for summarizing the text that is available in the online resources. Finally, a new semantic similarity-based deep neural network-based classifier is also introduced for categorizing the data according to the semantic relation. The proposed model is proved the effectiveness of the data retrieval process by conducting various experiments based on the relevant data extraction from Internet resources, and it also tested with the recognized datasets.},
  archive      = {J_SOCO},
  author       = {Rosewelt, Antony and Renjit, Arokia},
  doi          = {10.1007/s00500-020-04990-w},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {16983-17000},
  shortjournal = {Soft Comput.},
  title        = {Semantic analysis-based relevant data retrieval model using feature selection, summarization and CNN},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Image classification algorithm based on stacked sparse
coding deep learning model-optimized kernel function nonnegative sparse
representation. <em>SOCO</em>, <em>24</em>(22), 16967–16981. (<a
href="https://doi.org/10.1007/s00500-020-04989-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image classification has received extensive attention as an important technical means of acquiring image information. It has been widely used in various engineering fields. Although the existing traditional image classification methods have been widely applied in practical problems, there are some problems in the application process, such as unsatisfactory effects, low classification accuracy and weak adaptive ability. This is because this type of method relies on the designer’s prior knowledge and cognitive understanding of the classification task. At the same time, this method separates image feature extraction and classification into two steps for classification operation. However, the deep learning model has a powerful learning ability, which integrates the feature extraction and classification process into a whole to complete the image classification test, which can effectively improve the image classification accuracy. At the same time, the image classification method based on deep learning also has the following problems in the application process: First, it is impossible to effectively approximate the complex functions in the deep learning model. Second, the deep learning model comes with a low classifier with low accuracy. To this end, this paper introduces the idea of sparse representation into the architecture of deep learning network, comprehensively utilizes the sparse representation of good multidimensional data linear decomposition ability and the deep structural advantages of multi-layer nonlinear mapping to complete the complex function approximation in deep learning model. It constructs a deep learning model with adaptive approximation ability, which solves the function approximation problem of deep learning models. At the same time, in order to further improve the classification effect of the deep learning classifier, a sparse representation classification method based on the optimized kernel function is proposed to replace the classifier in the deep learning model, thereby improving the image classification effect. Based on the above explanation, this paper proposes an image classification algorithm based on the stacked sparse coding depth learning model-optimized kernel function nonnegative sparse representation. The experimental results show that the proposed method not only has a higher average accuracy than other mainstream methods, but also can be well adapted to various image databases. This is because the proposed method can extract more image feature information than the traditional image classification method and can better adaptively match the image information. Compared with other deep learning methods, it can better solve the problems of complex function approximation and poor classifier effect, thus further improving image classification accuracy.},
  archive      = {J_SOCO},
  author       = {An, Fengping},
  doi          = {10.1007/s00500-020-04989-3},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {16967-16981},
  shortjournal = {Soft Comput.},
  title        = {Image classification algorithm based on stacked sparse coding deep learning model-optimized kernel function nonnegative sparse representation},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Determination of customer satisfaction using improved
k-means algorithm. <em>SOCO</em>, <em>24</em>(22), 16947–16965. (<a
href="https://doi.org/10.1007/s00500-020-04988-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective management of customer’s knowledge leads to efficient Customer Relationship Management (CRM). To accurately predict customer’s behaviour, clustering, especially K-means, is one of the most important data mining techniques used in customer relationship management marketing, with which it is possible to identify customers’ behavioural patterns and, subsequently, to align marketing strategies with customer preferences so as to maintain the customers. However, it has been observed in various studies on K-means clustering that customers with different behavioural indicators in clustering may seem to be the same, implying that customer behavioural indicators do not play any significant role in customer clustering. Therefore, if the level of customer participation depends on behavioural parameters such as their satisfaction, it can have a negative effect on the K-means clusters and has no acceptable result. In this paper, customer behavioural features—malicious feature—is considered in customer clustering, as well as a method for finding the optimal number of clusters and the initial values of cluster centres to obtain more accurate results. Finally, according to the organizations’ need to extract knowledge from customers’ views through ranking customers based on factors affecting customer value, a method is proposed for modelling their behaviour and extracting knowledge for customer relationship management. The results of the evaluation of the customers of Hamkaran System’s Company show that the improved K-means method proposed in this paper outperforms K-means in terms of speed and accuracy.},
  archive      = {J_SOCO},
  author       = {Zare, Hamed and Emadi, Sima},
  doi          = {10.1007/s00500-020-04988-4},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {16947-16965},
  shortjournal = {Soft Comput.},
  title        = {Determination of customer satisfaction using improved K-means algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Voltage unbalance evaluation in the intelligent recognition
of induction motor rotor faults. <em>SOCO</em>, <em>24</em>(22),
16935–16946. (<a
href="https://doi.org/10.1007/s00500-020-04986-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Induction motors are widely used in several industrial applications due to their factors of favouritism already consolidated, such as robustness, low cost and high reliability. Early detection and proper fault diagnosis reduce the maintenance cost and also increase process effectiveness. Therefore, this paper presents a method for fast classification of rotor faults in line-connected induction motors operating at steady state, under unbalanced voltages and load conditions. Hence, the amplitude of the stator’s current signal in the time domain is presented as input to intelligent computational models for the classification of rotor’s faults. After a proper discretization of the current signal, the points extraction technique is applied allowing a reduction in the classifier’s complexity. Results from 900 experimental tests are provided and compared to validate this study. The results indicate that this approach can be employed to proper classify rotor broken bars in induction motors operating under unbalanced voltage and different load conditions.},
  archive      = {J_SOCO},
  author       = {Palácios, Rodrigo H. C. and da Silva, Ivan N. and Godoy, Wagner F. and Fabri, José A. and de Souza, Lucas B.},
  doi          = {10.1007/s00500-020-04986-6},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {16935-16946},
  shortjournal = {Soft Comput.},
  title        = {Voltage unbalance evaluation in the intelligent recognition of induction motor rotor faults},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A complete online-SVM pipeline for case-based reasoning
system: A study on pipe defect detection system. <em>SOCO</em>,
<em>24</em>(22), 16917–16933. (<a
href="https://doi.org/10.1007/s00500-020-04985-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent developments in case-based reasoning system (CBR) have led to an interest in favoring machine learning (ML) approaches as a replacement for traditional weighted distance methods. However, valuable information obtained through a training process was relinquished as transferring to other phases. This paper proposed a complete pipeline integration of CBR using kernel method designated with support vector machine (SVM) as the main engine. Since the system requires learning SVM model to be invoked in every phase, the online learning mechanism is nominated to effectively update the model when a new case adjoins. The proposed full SVM-CBR integration has been successfully built into a pipe defect detection. The achieved result indicates a substantial improvement by transferring learning information accurately.},
  archive      = {J_SOCO},
  author       = {Le, D. Van-Khoa and Chen, Zhiyuan and Wong, Yee Wan and Isa, Dino},
  doi          = {10.1007/s00500-020-04985-7},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {16917-16933},
  shortjournal = {Soft Comput.},
  title        = {A complete online-SVM pipeline for case-based reasoning system: A study on pipe defect detection system},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modeling and simulation to optimize direct power control of
DFIG in variable-speed pumped-storage power plant using
teaching–learning-based optimization technique. <em>SOCO</em>,
<em>24</em>(22), 16895–16915. (<a
href="https://doi.org/10.1007/s00500-020-04984-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The issues related to the optimal control of large-scale storage systems in electric power systems such as pumped storage (PS) plant have turned into vital challenges in the way of integrating renewable energy sources into power systems to provide reliable and economical electric energy. In this regard, this paper uses the direct power control strategy to model and simulate a variable-speed PS plant, which includes a doubly fed induction generator (DFIG). The active and the reactive power of the stator would be able to be controlled, separately. This approach has a better dynamic performance compared to other methods, while it would be quite simple to implement. But there are some shortfalls with this method, such as high ripple relating to the active power as well as reactive power together with the current harmonics. In this respect, the space vector modulation (SVM) is applied to eliminate these shortfalls. In the proposed control technique, including SVM, the dynamic performance of the studied DFIG unit is controlled using the proportional–integral (PI) controller. It should be noted that the teaching–learning-based optimization (TLBO) method is employed to tune the PI controller for controlling the DFIG system in the PS plant. Finally, in order to validate the performance of the suggested framework, a comparison is made between the results obtained by the TLBO and the ones reported by other optimization methods. The obtained results using the TLBO algorithm indicate better performance of the PI controller to reduce the ripples of the active and reactive power of the stator as well as the harmonic power.},
  archive      = {J_SOCO},
  author       = {Hosseini, Seyed Mohammad Hassan and Rezvani, Alireza},
  doi          = {10.1007/s00500-020-04984-8},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {16895-16915},
  shortjournal = {Soft Comput.},
  title        = {Modeling and simulation to optimize direct power control of DFIG in variable-speed pumped-storage power plant using teaching–learning-based optimization technique},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel technique to self-adapt parameters in
parallel/distributed genetic programming. <em>SOCO</em>,
<em>24</em>(22), 16885–16894. (<a
href="https://doi.org/10.1007/s00500-020-04982-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces the Supervisor Evolutionary Algorithm, a novel technique that allows for self-adapt almost all the internal parameters in parallel distributed client-server genetic programming. This novel adapting mechanism, is itself of an evolutionary nature, so we have a double evolutionary tool. The upper level, as is usual in evolutionary computing, has its own customized selection, crossover, and mutation mechanisms. The lower stage used here is the Brain Project a parallel-distributed software tool for formal modelling of numerical data using a hybrid neural-genetic programming technique. As demonstrated by the experiment reported in this paper, our approach works well adapting continuously its internal parameters.},
  archive      = {J_SOCO},
  author       = {Russo, Marco},
  doi          = {10.1007/s00500-020-04982-w},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {16885-16894},
  shortjournal = {Soft Comput.},
  title        = {A novel technique to self-adapt parameters in parallel/distributed genetic programming},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A two-stage similarity clustering-based large group
decision-making method with incomplete probabilistic linguistic
evaluation information. <em>SOCO</em>, <em>24</em>(22), 16869–16883. (<a
href="https://doi.org/10.1007/s00500-020-04981-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, probabilistic linguistic term set (PLT) is widely used in large group decision making (LGDM) for its integrity. However, the complexity of probabilistic linguistic LGDM and the large span of experts’ profession cause two problems. On the one hand, it is difficult for all experts to give complete evaluation information in the form of PLTs. For this, we propose an expertise-based probabilistic linguistic evaluation information complement method. First, we identify authoritative experts under each attribute through professional hesitation and professional consistency. Then, we establish an optimization function to obtain the optimal missing value through the expectation score of authoritative experts and the linguistic term using habit of pending experts. On the other hand, the similarity between two experts cannot be fully represented by the sum of the distance of expert evaluation value. For this, we propose a two-stage similarity measurement method and introduce the distance weighting process, which not only measures the similarity between two expert evaluation values, but also measures the difference in degree of distance between two experts under different attributes. Finally, we apply this LGDM method to hot dry rock exploration site selection in southeast coast of China.},
  archive      = {J_SOCO},
  author       = {Xu, Xuanhua and Hou, Yuzhou and He, Jishan and Zhang, Zitao},
  doi          = {10.1007/s00500-020-04981-x},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {16869-16883},
  shortjournal = {Soft Comput.},
  title        = {A two-stage similarity clustering-based large group decision-making method with incomplete probabilistic linguistic evaluation information},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Neutrosophic linear programming using possibilistic mean.
<em>SOCO</em>, <em>24</em>(22), 16847–16867. (<a
href="https://doi.org/10.1007/s00500-020-04980-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper discusses the concept of fuzzy set theory, interval-valued fuzzy set, intuitionistic fuzzy set, interval-valued intuitionistic fuzzy set, neutrosophic set and its operational laws. The paper presents the $$ \alpha ,\beta ,\gamma $$ -cut of single-valued triangular neutrosophic numbers and introduces the arithmetic operations of triangular neutrosophic numbers using $$ \alpha ,\beta ,\gamma $$ -cut. Then, possibilistic mean of truth membership function, indeterminacy membership function and falsity membership function is defined. The proposed approach converts each triangular neutrosophic number in linear programming problem to weighted value using possibilistic mean to determine the crisp linear programming problem. The proposed approach also considers the risk attitude of expert while deciding the parameters of linear programming model.},
  archive      = {J_SOCO},
  author       = {Khatter, Kiran},
  doi          = {10.1007/s00500-020-04980-y},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {16847-16867},
  shortjournal = {Soft Comput.},
  title        = {Neutrosophic linear programming using possibilistic mean},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multimodal human eye blink recognition method using feature
level fusion for exigency detection. <em>SOCO</em>, <em>24</em>(22),
16829–16845. (<a
href="https://doi.org/10.1007/s00500-020-04979-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a precise multimodal eye blink recognition method using feature level fusion (MmERMFLF) is proposed. A new feature: eye-eyebrow facet ratio (EEBFR) (formed by fusing eye facet ratio (EFR: ratio of diagonal length and width of eye) and eyebrow to nose facet ratio (EBNFR: distance between eyebrow landmarks and nose landmark)) for approximating the eye state is computed. Initially, an improved intellectual framework (Sagacious Information Recuperation Technique) that senses the emergency state using information retrieved from eye blinks, pulse rate as well as behavioral patterns(emotions) exhibited by an individual is presented. Further a novel multimodal method (MmERMFLF) for detection and counting of eye blinks is implemented. For training, one state-of-the-art database—ZJU is used. To additionally improve the performance, feature-level fusion schemes [simple concatenate and fusion codes (gaborization)] are enforced and equated. Receiver operating characteristics, error rate, sensitivity, specificity, and precision are used to demonstrate the performance of the proposed method qualitatively and quantitatively. Accuracy with proposed MmERMFLF is increased to 99.02\% (using EEBGFR method with bagged ensemble classifier) in comparison to unimodal eye blink recognition system (97.60\%). 99.80\% genuine blinks are classified by MmERMFLF (when gaborization fusion is used) using simple tree classifier.},
  archive      = {J_SOCO},
  author       = {Lamba, Puneet Singh and Virmani, Deepali and Castillo, Oscar},
  doi          = {10.1007/s00500-020-04979-5},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {16829-16845},
  shortjournal = {Soft Comput.},
  title        = {Multimodal human eye blink recognition method using feature level fusion for exigency detection},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Forecasting hybrid neural network with variational learning
rate and q-DSCID synchronization evaluation for energy market.
<em>SOCO</em>, <em>24</em>(22), 16811–16828. (<a
href="https://doi.org/10.1007/s00500-020-04977-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Because of the nonlinearity, uncertainty, and dynamics of crude oil price, its price forecasting has continuously been a burdensome international research issue. To better implement the prediction of the energy market by machine learning algorithms, premeditating the influence factors of historical data in different periods on prediction consequence, random inheritance formula error correction algorithm is proposed in this work. The empirical wavelet transform and reconstruction are applied to extract data features simultaneously. A novel hybrid neural network model is constructed, which integrates empirical wavelet transform, Elman recurrent neural network, and random inheritance formula. Variational learning rate is proposed and used to ameliorate the selection of parameters for the network training procedure. In this paper, the proposed model is applied in crude oil futures price forecasting. Further, a variety of evaluation indicators are introduced to contrast and evaluate the predictions. An original representative synchronization evaluation arithmetic q-order dyadic scales complexity invariant distance is put forward and utilized. Demonstration results suggest that the proposed model has superior preciseness among comparison models.},
  archive      = {J_SOCO},
  author       = {Wang, Bin and Wang, Jun},
  doi          = {10.1007/s00500-020-04977-7},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {16811-16828},
  shortjournal = {Soft Comput.},
  title        = {Forecasting hybrid neural network with variational learning rate and q-DSCID synchronization evaluation for energy market},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Tukey’s biweight estimation for uncertain regression model
with imprecise observations. <em>SOCO</em>, <em>24</em>(22),
16803–16809. (<a
href="https://doi.org/10.1007/s00500-020-04973-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of regression analysis is to study how a response variable has a relation to a vector of explanatory variables. Traditionally, statisticians assume that the observation data are precise, and we can get some exact values. However, in many cases, the imprecise observation data are available. We assume that these data are uncertain variables in the sense of uncertainty theory. In this paper, the Tukey biweight or bisquare family of loss functions is applied to estimate unknown parameters satisfying the uncertain regression model. First, the Tukey biweight estimations of three types of regression models are given, namely linear, asymptotic and Michaelis–Menten. Then an empirical study is presented to verify the feasibility of this approach. Finally, the effectiveness of this method in weakening the outliers influence is shown by the comparative analysis.},
  archive      = {J_SOCO},
  author       = {Chen, Dan},
  doi          = {10.1007/s00500-020-04973-x},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {16803-16809},
  shortjournal = {Soft Comput.},
  title        = {Tukey’s biweight estimation for uncertain regression model with imprecise observations},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Truss-sizing optimization attempts with CSA: A detailed
evaluation. <em>SOCO</em>, <em>24</em>(22), 16775–16801. (<a
href="https://doi.org/10.1007/s00500-020-04972-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thanks to the advent of powerful computers, searching for optimal solutions to engineering design problems becomes easier every day. Numerous researchers are still developing modern optimization algorithms, and the competition for “the most efficient optimization algorithm” continues apace. This study evaluates the performances of the Crow Search Algorithm (CSA) and a slightly modified variant (CSAM) in one of the most popular and controversial competitions in the structural optimization field for the first time. Unlike most of the works on structural optimization, this paper does not tell a success story. After days of computation to collect the sensitivity and convergence data, it is shown that both CSA and CSAM mostly fail compared to today’s competitive algorithms. The findings of the study are discussed through tables and plots in detail to share the unfavorable experience on the truss optimization attempts, to review the difficulties of using parameter-controlled algorithms in structural optimization through CSA, and to save time for the researchers in the field.},
  archive      = {J_SOCO},
  author       = {Ozbasaran, Hakan and Eryilmaz Yildirim, Meltem},
  doi          = {10.1007/s00500-020-04972-y},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {16775-16801},
  shortjournal = {Soft Comput.},
  title        = {Truss-sizing optimization attempts with CSA: A detailed evaluation},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Applications of probabilistic hesitant fuzzy rough set in
decision support system. <em>SOCO</em>, <em>24</em>(22), 16759–16774.
(<a href="https://doi.org/10.1007/s00500-020-04971-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of this manuscript is to present the notion of probabilistic hesitant fuzzy rough (PHFR) set and their basic operations. As a generalization of the sets, PHFR set is a more profitable way to express the uncertainties in the data. For it, firstly, we define the basic operational laws like, the union, intersection and the composition of probabilistic hesitant fuzzy approximation spaces with some basic properties are discussed in details. Secondly, presented the novel decision-making technique based on the PHFR sets over two nonempty fixed sets to deal with uncertainty in decision-making problems. Finally, two numerical examples are provided with some comparative study to validate the proposed approach.},
  archive      = {J_SOCO},
  author       = {Khan, Muhammad Ali and Ashraf, Shahzaib and Abdullah, Saleem and Ghani, Fazal},
  doi          = {10.1007/s00500-020-04971-z},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {16759-16774},
  shortjournal = {Soft Comput.},
  title        = {Applications of probabilistic hesitant fuzzy rough set in decision support system},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Solving variable-order fractional differential algebraic
equations via generalized fuzzy hyperbolic model with application in
electric circuit modeling. <em>SOCO</em>, <em>24</em>(22), 16745–16758.
(<a href="https://doi.org/10.1007/s00500-020-04969-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new approach based on a generalized fuzzy hyperbolic model is used for the numerical solution of variable-order fractional differential algebraic equations. The fractional derivative is described in the Atangana–Baleanu sense that is a new derivative with fractional order based on the generalized Mittag–Leffler function. First, by using fuzzy solutions with adjustable parameters, the variable-order fractional differential algebraic equations are reduced to a problem consisting of solving a system of algebraic equations. For adjusting the parameters of fuzzy solutions, an unconstrained optimization problem is then considered. A learning algorithm is also presented for solving the unconstrained optimization problem. Finally, some numerical examples are given to verify the efficiency and accuracy of the proposed approach.},
  archive      = {J_SOCO},
  author       = {Mortezaee, Marzieh and Ghovatmand, Mehdi and Nazemi, Alireza},
  doi          = {10.1007/s00500-020-04969-7},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {16745-16758},
  shortjournal = {Soft Comput.},
  title        = {Solving variable-order fractional differential algebraic equations via generalized fuzzy hyperbolic model with application in electric circuit modeling},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bipolar n-soft set theory with applications. <em>SOCO</em>,
<em>24</em>(22), 16727–16743. (<a
href="https://doi.org/10.1007/s00500-020-04968-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the notion of bipolar N-soft set, which is the bipolar extension of N-soft set, and its fundamental properties are introduced. This new idea is illustrated with real-life examples. Moreover, some useful operations and products on the bipolar N-soft sets are derived. We thoroughly discuss the idempotent, commutative, associative, and distributive laws for these emerging operations and products. Also, we set forth two outstanding algorithms to handle the decision-making problems under bipolar N-soft set environments. We give potential applications and comparison analysis to demonstrate the efficiency and advantages of algorithms.},
  archive      = {J_SOCO},
  author       = {Kamacı, Hüseyin and Petchimuthu, Subramanian},
  doi          = {10.1007/s00500-020-04968-8},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {16727-16743},
  shortjournal = {Soft Comput.},
  title        = {Bipolar N-soft set theory with applications},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An effective compensation of power quality issues using
MPPT-based cuckoo search optimization approach. <em>SOCO</em>,
<em>24</em>(22), 16719–16725. (<a
href="https://doi.org/10.1007/s00500-020-04966-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Power quality becomes the most significant concerns for many reasons as the dependence of electricity is increasing in this modern society. In fact that less quality of power will generate some considerable losses in terms of economy in few moments. The potential power quality issues were flicker, voltage dips, supply and harmonic interruptions. The quality of power might be enhanced with the use of some filtering approaches and some compensators. This work presents a unique framework of optimal utilization of the unified power flow controller (UPFC). The UPFC’s inverter series is then controlled so as to perform the following functions: load reactive power sharing with the shunt inverter and compensation of voltage sag/swell. A cuckoo search optimization-based maximum power point tracking algorithm is employed for providing best fitness function for varying duty cycles. The approach of active power filter is widely employed in the harmonic compensation of voltage swell/sag. The proposed system also provides low rate of total harmonic distortion. MATLAB/Simulink-based simulation results are discussed to support the developed concept.},
  archive      = {J_SOCO},
  author       = {Radhika, A. and Soundradevi, G. and Mohan Kumar, R.},
  doi          = {10.1007/s00500-020-04966-w},
  journal      = {Soft Computing},
  number       = {22},
  pages        = {16719-16725},
  shortjournal = {Soft Comput.},
  title        = {An effective compensation of power quality issues using MPPT-based cuckoo search optimization approach},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Genetic algorithm-based tabu search for optimal energy-aware
allocation of data center resources. <em>SOCO</em>, <em>24</em>(21),
16705–16718. (<a
href="https://doi.org/10.1007/s00500-020-05240-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing delivers practical solutions for long-term image archiving systems. Cloud data centers consume enormous amounts of electrical energy that increases their operational costs. This shows the importance of investing on energy consumption techniques. Dynamic placement of virtual machines to appropriate physical nodes using metaheuristic algorithms is among the methods of reducing energy consumption. In metaheuristic algorithms, there should be a balance between both exploration and exploitation aspects so that they can find better solutions in a search space. Exploration means looking for a solution in a wider area, while exploitation is producing new solutions from existence ones. Artificial bee colony optimization, which is a biological metaheuristic algorithm, is a sign-oriented approach. It has a strong exploration ability, but a relatively weaker exploitation power. On the other hand, tabu search is a popular algorithm that shows better exploitation in comparison with ABC. In this study, cloud computing environments are detailed with an allocation protocol for efficient energy and resource management. The technique of energy-aware allocation splits data centers (DCs) resources among client applications end routes to enhance energy efficacy of DCs and also achieves anticipated quality of service (QoS) for everyone. Heuristic protocols are exercised for optimizing the distribution of resources to upgrade the efficiency of DC. In the current paper, energy-aware resources allotment technique is employed and optimized in clouds via a new approach called Tabu Job Master (JM). Tabu JM claims the benefits of some variables and also rapid convergence speeds. Results are duly achieved for energy consumption—the count of virtual machines (VMs) migration and also makespan. The results shown by Tabu JM are benchmarked by using genetic algorithm (GA), artificial bee colony (ABC), ABC with crossover and technique of mutation, the basic tabu search techniques, and Tabu Job Master.},
  archive      = {J_SOCO},
  author       = {Chandran, Ramesh and Rakesh Kumar, S. and Gayathri, N.},
  doi          = {10.1007/s00500-020-05240-9},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16705-16718},
  shortjournal = {Soft Comput.},
  title        = {Genetic algorithm-based tabu search for optimal energy-aware allocation of data center resources},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). High utility itemset mining: A boolean operators-based
modified grey wolf optimization algorithm. <em>SOCO</em>,
<em>24</em>(21), 16691–16704. (<a
href="https://doi.org/10.1007/s00500-020-05123-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In data mining, mining high utility itemset (HUI) is one among the recent thrust area that receives several approaches for solving it in an effective manner. In the past decade, addressing optimization problems using evolutionary algorithms are an unavoidable strategy due to its convergence towards optimal solution within the stipulated time. The results of evolutionary algorithms on various optimization problems are far effective when compared to the exhaustive approaches with respect to computational time. The problem with HUI is discovering a set of items from a transactional database that possess high level of utility when compared with other distinctive sets. This problem becomes harder while addressing the count of items in the database while its higher and computational time to solve this problem using exhaustive search becomes exponential as proposition of items in transaction database increases. In this paper, an optimization model based on the biological behaviour of grey wolf is proposed; the model namely grey wolf optimization algorithm is used to solve HUI using five different Boolean operations. The proposed model is evaluated using standard performance metrics over synthetic datasets and real-world datasets. The proposed model results are then compared with recent HUIM models to show the significance.},
  archive      = {J_SOCO},
  author       = {Pazhaniraja, N. and Sountharrajan, S. and Sathis Kumar, B.},
  doi          = {10.1007/s00500-020-05123-z},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16691-16704},
  shortjournal = {Soft Comput.},
  title        = {High utility itemset mining: A boolean operators-based modified grey wolf optimization algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Enhancing performance of cell formation problem using hybrid
efficient swarm optimization. <em>SOCO</em>, <em>24</em>(21),
16679–16690. (<a
href="https://doi.org/10.1007/s00500-020-05059-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cellular manufacturing design is apprehensive about the conception and activity of cells to take the benefits of adaptability, effective flow, and high creation rate. The way toward forming manufacturing cells with the greatest efficiency is the most critical strides in cellular manufacturing. In this paper, a new monarch butterfly optimization (MBO) and firefly (FF)-based meta-heuristic is proposed to solve a multi-objective cell formation problem (CFP). This hybridized MBO–FF acquires optimal arrangements in a worthy measure of time, particularly for big size problems also focused to enhance the working of CFP. This algorithm is competent to investigate the search space viably and recognize the global optimal within a short measure of time. Here, percentage of exceptional elements, machine utilization, grouping efficacy and cell efficiency are measured for the performance enhancement. Computational outcome of the presented MBO–FF herein demonstrates superior or equivalent to the benchmark instance collected from the literature.},
  archive      = {J_SOCO},
  author       = {Nagaraj, G. and Arunachalam, Manimaran and Vinayagar, K. and Paramasamy, S.},
  doi          = {10.1007/s00500-020-05059-4},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16679-16690},
  shortjournal = {Soft Comput.},
  title        = {Enhancing performance of cell formation problem using hybrid efficient swarm optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A systematic literature review on empirical studies towards
prediction of software maintainability. <em>SOCO</em>, <em>24</em>(21),
16655–16677. (<a
href="https://doi.org/10.1007/s00500-020-05005-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software maintainability prediction in the earlier stages of software development involves the construction of models for the accurate estimation of maintenance effort. This guides the software practitioners to manage the resources optimally. This study aims at systematically reviewing the prediction models from January 1990 to October 2019 for predicting software maintainability. We analyze the effectiveness of these models according to various aspects. To meet the goal of the research, we have identified 36 research papers. On investigating these papers, we found that various machine learning (ML), statistical (ST), and hybridized (HB) techniques have been applied to develop prediction models to predict software maintainability. The significant finding of this review is that the overall performance of ML-based models is better than that of ST models. The use of HB techniques for prediction of software maintainability is limited. The results of this review revealed that software maintainability prediction (SMP) models developed using ML techniques outperformed models developed using ST techniques. Also, the prediction performance of few models developed using HB techniques is encouraging, yet no conclusive results about the performance of HB techniques could be reported because different HB techniques are applied in a few studies.},
  archive      = {J_SOCO},
  author       = {Malhotra, Ruchika and Lata, Kusum},
  doi          = {10.1007/s00500-020-05005-4},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16655-16677},
  shortjournal = {Soft Comput.},
  title        = {A systematic literature review on empirical studies towards prediction of software maintainability},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Video trajectory analysis using unsupervised clustering and
multi-criteria ranking. <em>SOCO</em>, <em>24</em>(21), 16643–16654. (<a
href="https://doi.org/10.1007/s00500-020-04967-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surveillance camera usage has increased significantly for visual surveillance. Manual analysis of large video data recorded by cameras may not be feasible on a larger scale. In various applications, deep learning-guided supervised systems are used to track and identify unusual patterns. However, such systems depend on learning which may not be possible. Unsupervised methods relay on suitable features and demand cluster analysis by experts. In this paper, we propose an unsupervised trajectory clustering method referred to as t-Cluster. Our proposed method prepares indexes of object trajectories by fusing high-level interpretable features such as origin, destination, path, and deviation. Next, the clusters are fused using multi-criteria decision making and trajectories are ranked accordingly. The method is able to place abnormal patterns on the top of the list. We have evaluated our algorithm and compared it against competent baseline trajectory clustering methods applied to videos taken from publicly available benchmark datasets. We have obtained higher clustering accuracies on public datasets with significantly lesser computation overhead.},
  archive      = {J_SOCO},
  author       = {Sekh, Arif Ahmed and Dogra, Debi Prosad and Kar, Samarjit and Roy, Partha Pratim},
  doi          = {10.1007/s00500-020-04967-9},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16643-16654},
  shortjournal = {Soft Comput.},
  title        = {Video trajectory analysis using unsupervised clustering and multi-criteria ranking},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An improved jaya algorithm with a modified swap operator for
solving team formation problem. <em>SOCO</em>, <em>24</em>(21),
16627–16641. (<a
href="https://doi.org/10.1007/s00500-020-04965-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forming a team of experts that can match the requirements of a collaborative task is an important aspect, especially in project development. In this paper, we propose an improved Jaya optimization algorithm for minimizing the communication cost among team experts to solve team formation problem. The proposed algorithm is called an improved Jaya algorithm with a modified swap operator (IJMSO). We invoke a single-point crossover in the Jaya algorithm to accelerate the search, and we apply a new swap operator within Jaya algorithm to verify the consistency of the capabilities and the required skills to carry out the task. We investigate the IJMSO algorithm by implementing it on two real-life datasets (i.e., digital bibliographic library project and StackExchange) to evaluate the accuracy and efficiency of proposed algorithm against other meta-heuristic algorithms such as genetic algorithm, particle swarm optimization, African buffalo optimization algorithm and standard Jaya algorithm. Experimental results suggest that the proposed algorithm achieves significant improvement in finding effective teams with minimum communication costs among team members for achieving the goal.},
  archive      = {J_SOCO},
  author       = {El-Ashmawi, Walaa H. and Ali, Ahmed F. and Slowik, Adam},
  doi          = {10.1007/s00500-020-04965-x},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16627-16641},
  shortjournal = {Soft Comput.},
  title        = {An improved jaya algorithm with a modified swap operator for solving team formation problem},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Design of NEWMA np control chart for monitoring neutrosophic
nonconforming items. <em>SOCO</em>, <em>24</em>(21), 16617–16626. (<a
href="https://doi.org/10.1007/s00500-020-04964-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We will introduce a neutrosophic exponentially weighted moving average (NEWMA) statistic for the attribute data. We will use the proposed NEWMA to design an attribute control chart. We will introduce the neutrosophic Monte Carlo simulation to find the neutrosophic average run length (NARL). The comparative study shows the efficiency of the proposed NEWMA attribute. Two examples of having neutrosophic parameters will be given to explain the proposed control chart. We hope that the proposed chart will perform better under uncertainty.},
  archive      = {J_SOCO},
  author       = {Aslam, Muhammad and Bantan, Rashad A. R. and Khan, Nasrullah},
  doi          = {10.1007/s00500-020-04964-y},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16617-16626},
  shortjournal = {Soft Comput.},
  title        = {Design of NEWMA np control chart for monitoring neutrosophic nonconforming items},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). DeepBot: A time-based botnet detection with deep learning.
<em>SOCO</em>, <em>24</em>(21), 16605–16616. (<a
href="https://doi.org/10.1007/s00500-020-04963-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the decades, as the technology of Internet thrives rapidly, more and more kinds of cyber-attacks are blasting out around the world. Among them, botnet is one of the most noxious attacks which has always been challenging to overcome. The difficulties of botnet detection stem from the various forms of attack since the viruses keep evolving to avoid themselves from being found. Rule-based botnet detection has its shortcoming of detecting dynamically changing features. On the other hand, the more the Internet functionalities are developed, the severer the impacts botnets may cause. In recent years, many network devices have suffered from botnet attacks as the Internet of things technology prospers, which caused great damage in many industries. Consequently, botnet detection has always been a critical issue in computer security field. In this paper, we introduce a method to detect potential botnets by inspecting the behaviors of network traffics from network packets. In the beginning, we sample the given packets by a period of time and extract the behavioral features from a series of packets. By analyzing these features with proposed deep learning models, we can detect the threat of botnets and classify them into different categories.},
  archive      = {J_SOCO},
  author       = {Shi, Wan-Chen and Sun, Hung-Min},
  doi          = {10.1007/s00500-020-04963-z},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16605-16616},
  shortjournal = {Soft Comput.},
  title        = {DeepBot: A time-based botnet detection with deep learning},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Interaction design research based on large data rule mining
and blockchain communication technology. <em>SOCO</em>, <em>24</em>(21),
16593–16604. (<a
href="https://doi.org/10.1007/s00500-020-04962-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the amount of information in the internet of things increases, data storage management tends to be distributed, which leads to problems such as difficult data cooperation and interaction between sites, low communication efficiency, and poor reliability. Blockchain is one of the new information technologies supporting the development of management information system. It provides a solution for the storage, verification, transmission, and exchange of distributed data. To optimize the communication performance from two aspects of communication topology and communication mechanism, a multi-link and concurrent communication tree model was constructed. To improve blockchain communication technology, an interactive design method based on big data rule mining and blockchain communication technology was proposed, which mainly solved the optimization of transmission performance of blockchain data. On the basis of ensuring the stability and reliability of data transmission, the efficiency of data transmission in blockchain was further optimized, and the integrated factor communication tree algorithm (IFT) was proposed. To solve the influence of transmission delay between nodes on communication performance, a multi-link multifactor weighted communication tree algorithm (MMWT) considering weight was proposed. Moreover, to improve the efficiency of data communication, ensure the reliability of transmission, and improve the fairness of service in the blockchain, different strategies for optimizing the performance of data communication in the blockchain were proposed under the constraints of factors such as node communication ability, node trust, weight, and service request priority. Finally, the simulation results showed that MMWT algorithm had good communication performance in concurrent communication time, communication tree reliability, communication tree depth, and other aspects.},
  archive      = {J_SOCO},
  author       = {Zhang, Jiboning},
  doi          = {10.1007/s00500-020-04962-0},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16593-16604},
  shortjournal = {Soft Comput.},
  title        = {Interaction design research based on large data rule mining and blockchain communication technology},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). HFACS-based FAHP implementation to identify critical factors
influencing human error occurrence in nuclear plant control room.
<em>SOCO</em>, <em>24</em>(21), 16577–16591. (<a
href="https://doi.org/10.1007/s00500-020-04961-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human factor is an inevitable element of safety-critical control room operations in nuclear power plants. Identifying human factors influencing operator error occurrence in such critical application is important to mitigate human errors. Conventional methods employed for human factor identification are often static, unable to deal with data and model uncertainty, and to consider independencies among failure modes. This study employs the integration of the soft computing technique, viz. fuzzy analytic hierarchy process (FAHP), into the human factors analysis and classifying system (HFACS) framework to identify the critical human factors that contribute to human errors in the nuclear control room application. Integration of FAHP improves the HFACS framework by providing an analytical foundation and group decision-making ability in order to ensure quantitative assessment of nuclear accidents. The proposed model has two phases. The first phase is study of 18 human performance-related events that occurred in Indian nuclear power plants, utilizing HFACS to analyze and determine the human and organizational factors (HOFs) responsible for such events. Existing HFACS can only be used to detect a wide range of human factors. The proposed model further explores the underlying causes of such a wide range of factors. The hierarchy of HOFs identified as adverse mental states and organizational process factors that contributed most failures causing accident in the first phase provides inputs for the critical human factor identification to the second phase, which is a quantitative analysis using FAHP. In the second phase, more than 40 adverse mental state and organizational process factors are identified from literature survey and ten subfactors are screened and selected by human reliability assessment and control room operation experts. The study was conducted by administering a questionnaire that is comprised of the screened factors. Data have been collected from 88 senior reactor operators in an operating nuclear power plant. The critical factors contributing to human errors identified from FAHP are attention, perception and memory under cognitive factor and decision making, training and communications under organizational factor. The study results reveal that the implementation of HFACS-based FAHP methodology enabled in determining intrinsic human factors that contribute to nuclear power plant control room operator performance.},
  archive      = {J_SOCO},
  author       = {Karthick, M. and Robert, T. Paul and Kumar, C. Senthil},
  doi          = {10.1007/s00500-020-04961-1},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16577-16591},
  shortjournal = {Soft Comput.},
  title        = {HFACS-based FAHP implementation to identify critical factors influencing human error occurrence in nuclear plant control room},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Perturbation-based classifier. <em>SOCO</em>,
<em>24</em>(21), 16565–16576. (<a
href="https://doi.org/10.1007/s00500-020-04960-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Bayes classifier depends on the conditional densities and the prior probabilities. Among many density functions, the Gaussian density has received more attention mainly motivated by its analytical tractability. The parameters of the Bayes classifier for the Gaussian distribution data are generally unknown, and approximations are calculated for the mean vector $${\hat{{\varvec{\mu }}}}$$ and the covariance matrix $${\hat{\varSigma }}$$ . When a pattern is inserted in the training set of the class $$\omega _i$$ , the values of the parameters $$\hat{{\varvec{\mu }}}_{{\varvec{i}}}$$ and $${\hat{\varSigma }}_{i}$$ change by an amount given by $$\varDelta \hat{{\varvec{\mu }}}_{{\varvec{i}}}$$ and $$\varDelta {\hat{\varSigma }}_i$$ , respectively. The insertion of one pattern can cause a perturbation, so we claim that this perturbation can be used for supervised classification purposes. Based on this assumption, we propose a supervised classifier called Perturbation-based Classifier PerC that assigns the class of the query pattern as the one that presents the smallest perturbation among all the classes after the insertion of this query pattern in the classes. The rationale is that the addition of a pattern that belongs to one specific class should not alter much the distribution of that class. PerC only uses the perturbations ( $$\varDelta \hat{{\varvec{\mu }}}_{{\varvec{i}}}$$ and $$\varDelta {\hat{\varSigma }}_i$$ ) to evaluate the class of a query pattern; so, it is a parameter-free classifier. The proposed method was assessed on 21 datasets from the UCI Machine Learning Repository, and its results were compared with classifiers from the literature. Results have shown that PerC obtains very competitive recognition rates.},
  archive      = {J_SOCO},
  author       = {Araújo, Edson L. and Cavalcanti, George D. C. and Ren, Tsang Ing},
  doi          = {10.1007/s00500-020-04960-2},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16565-16576},
  shortjournal = {Soft Comput.},
  title        = {Perturbation-based classifier},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Analysis of social networks and wi-fi networks by using the
concept of picture fuzzy graphs. <em>SOCO</em>, <em>24</em>(21),
16551–16563. (<a
href="https://doi.org/10.1007/s00500-020-04959-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Atanassov’s intuitionistic fuzzy set described the uncertainty of real-life events with the help of a membership and a non-membership degree. However, human opinion cannot be restricted to yes or no, but there is some abstinence and refusal degree as well. In such cases, picture fuzzy set is a suitable solution which described the abstinence and refusal grade of human opinion along with membership and non-membership grades. The aim of this paper is to analyse a social network and a wife network using the concept of picture fuzzy graph (PFG). For this purpose, the concept of PFG is proposed and some basic terms are demonstrated including complement, degree and bridges. The main advantage of the proposed PFG is that it describes the uncertainty in any real-life event with the help of four membership degrees where the traditional FG and IFG fail to be applied. The viability of PFG is shown by utilizing the concept in demonstrating two real-life problems including a social network and a Wi-Fi-network. A comparison of PFG with existing notions is established showing its superiority over the existing frameworks.},
  archive      = {J_SOCO},
  author       = {Koczy, Laszlo T. and Jan, Naeem and Mahmood, Tahir and Ullah, Kifayat},
  doi          = {10.1007/s00500-020-04959-9},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16551-16563},
  shortjournal = {Soft Comput.},
  title        = {Analysis of social networks and wi-fi networks by using the concept of picture fuzzy graphs},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An extensive review of computational intelligence-based
optimization algorithms: Trends and applications. <em>SOCO</em>,
<em>24</em>(21), 16519–16549. (<a
href="https://doi.org/10.1007/s00500-020-04958-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Area of computational intelligence is gaining researcher’s attention in ongoing trend of technology and evolution due to their high capability to deliver near-optimal solutions. A new hierarchy of algorithms has been proposed in the paper, and they have been organized on the basis of their inspiration sources. The broad two domains of the algorithms are modeling of human mind and nature-inspired intelligence. Nature-inspired computational algorithms being heuristic algorithms are robust and have optimization capability to solve obscure and substantiated problems. The heuristic techniques aim on finding the best possible solution to the query in a satisfiable amount of time. The computational intelligence methods inspired from nature have further been categorized into artificial immune systems, evolutionary algorithms, swarm intelligence, artificial neural networks and geoscience-based algorithms. Geoscience-based domain is the least explored domain in which the algorithms can be developed based on geographic phenomenon taking place on the earth’s surface. An extensive tabular comparison is done among algorithms of all the domains on the basis of various attributes. Also, variants of the algorithms and their implementation in a specific application have been examined. The efficiency and performance of selected algorithms have been compared on clustering and traveling salesman problem for better understanding.},
  archive      = {J_SOCO},
  author       = {Goel, Lavika},
  doi          = {10.1007/s00500-020-04958-w},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16519-16549},
  shortjournal = {Soft Comput.},
  title        = {An extensive review of computational intelligence-based optimization algorithms: Trends and applications},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Time series data analysis of stock price movement using
machine learning techniques. <em>SOCO</em>, <em>24</em>(21),
16509–16517. (<a
href="https://doi.org/10.1007/s00500-020-04957-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stock market also called as equity market is the aggregation of the sellers and buyers. It is concerned with the domain where the shares of various public listed companies are traded. For predicting the growth of economy, stock market acts as an index. Due to the nonlinear nature, the prediction of the stock market becomes a difficult task. But the application of various machine learning techniques has been becoming a powerful source for the prediction. These techniques employ historical data of the stocks for the training of machine learning algorithms and help in predicting their future behavior. The three machine learning algorithms used in this paper are support vector machine, perceptron, and logistic regression, for predicting the next day trend of the stocks. For the experiment, dataset from about fifty stocks of Indian National Stock Exchange’s NIFTY 50 index was taken, by collecting stock data from January 1, 2013, to December 31, 2018, and lastly by the calculation of some technical indicators. It is reported that the average accuracy for the prediction of the trend of fifty stocks obtained by support vector machine is 87.35\%, perceptron is 75.88\%, and logistic regression is 86.98\%. Since the stock data are time series data, another dataset is prepared by reorganizing previous dataset into the supervised learning format which improves the accuracy of the prediction process which reported the results with support vector machine of 89.93\%, perceptron of 76.68\%, and logistic regression of 89.93\%, respectively.},
  archive      = {J_SOCO},
  author       = {Parray, Irfan Ramzan and Khurana, Surinder Singh and Kumar, Munish and Altalbe, Ali A.},
  doi          = {10.1007/s00500-020-04957-x},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16509-16517},
  shortjournal = {Soft Comput.},
  title        = {Time series data analysis of stock price movement using machine learning techniques},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An efficient soft computing approach for securing
information over GAMEOVER zeus botnets with modified CPA algorithm.
<em>SOCO</em>, <em>24</em>(21), 16499–16507. (<a
href="https://doi.org/10.1007/s00500-020-04956-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent times, security threats are predominant in almost all digital applications over the internet. One such threatening effect comes from GAMEOVER Zeus Botnet. These Botnets enter inside online networks and affect the Peer client list, through Internet Rely Chat (IRC). IRC includes applications like Tactical chat and On Chat. Zeus botnets gather the secret information of these users, such as bank data and military secrets. Moreover, the architecture is P2P and hence the location of GAMEOVER Zeus Botnet varies from the one to another botnets models. The threat of Zeus botnets loom large as they operate through the processes of identification of users, through which, they establish control over the hosts via P2P server. An intelligent method of identification of Zeus botnets in a distributed computing system using cryptographic schemes to defend against such attacks is the prime issue of research in this paper. An advanced Botnet capturing algorithm, named as modified cryptographic prefix IP anonymize (CPA) algorithm is proposed in this research paper to effectively counter the threats of Zeus bots. Essential features of the proposed CPA algorithm include prefixed IP mapped anonymizing in Internet Rely Chat, inbuilt adaptive security algorithm, which helps in network cleansing. If left unchecked, these Zeus botnets may result in consequent shutdown of the system. Hence, identification of the location of these botnets with the help of IP-prefix mapped method through modified CPA algorithm have been systematically presented in this paper.},
  archive      = {J_SOCO},
  author       = {Aanjankumar, S. and Poonkuntran, S.},
  doi          = {10.1007/s00500-020-04956-y},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16499-16507},
  shortjournal = {Soft Comput.},
  title        = {An efficient soft computing approach for securing information over GAMEOVER zeus botnets with modified CPA algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Intelligent fuzzy rule-based approach with outlier detection
for secured routing in WSN. <em>SOCO</em>, <em>24</em>(21), 16483–16497.
(<a href="https://doi.org/10.1007/s00500-020-04955-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In wireless sensor networks (WSNs), energy optimization and the provision of security are the major design challenges. Since the wireless sensor devices are energy constrained, the issue of high energy consumption by the malicious nodes must be addressed well in order to enhance the network performance by making increased network lifetime, reduced energy consumption and delay. In the past, many researchers worked in the provision of new techniques for providing improved security to WSN in order to enhance the reliability in the routing process. However, most of the existing routing techniques are not able to achieve the required security through the use of intelligent techniques for safeguarding the sensor nodes from malicious attacks. In order to address these problems, a new fuzzy temporal clustering-based secured communication model with trust analysis and outlier detection has been developed in this research work. For this purpose, a new fuzzy temporal rule-based cluster-based routing algorithm with trust modelling and outlier detection for monitoring the nodes participating in the communication has been proposed. In addition, a fuzzy temporal rule- and distance-based outlier detection algorithm is also proposed in this paper for distinguishing the malicious nodes from other nodes within each cluster of the network and has been used in the secured routing algorithm. The proposed secure routing algorithm uses the temporal reasoning tasks of explanation-based learning and prediction as well as spatial constraints for making efficient routing decisions through the application of trust and key management techniques for performing effective authentication of nodes and thereby isolating the malicious nodes from communication through outlier detection. By applying these two proposed algorithms for communication in the proposed work, it is proved through experiments that the proposed secure routing algorithm and the outlier detection algorithm are able to perform secured and reliable routing through genuine cluster head nodes more effectively. Moreover, these two algorithms provide improved quality of service with respect to the reliability of communication, packet delivery ratio, reduction in end-to-end delay and reduced energy consumption.},
  archive      = {J_SOCO},
  author       = {Thangaramya, K. and Kulothungan, K. and Indira Gandhi, S. and Selvi, M. and Santhosh Kumar, S. V. N. and Arputharaj, Kannan},
  doi          = {10.1007/s00500-020-04955-z},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16483-16497},
  shortjournal = {Soft Comput.},
  title        = {Intelligent fuzzy rule-based approach with outlier detection for secured routing in WSN},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Temporal convolutional neural (TCN) network for an effective
weather forecasting using time-series data from the local weather
station. <em>SOCO</em>, <em>24</em>(21), 16453–16482. (<a
href="https://doi.org/10.1007/s00500-020-04954-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-predictive or inaccurate weather forecasting can severely impact the community of users such as farmers. Numerical weather prediction models run in major weather forecasting centers with several supercomputers to solve simultaneous complex nonlinear mathematical equations. Such models provide the medium-range weather forecasts, i.e., every 6 h up to 18 h with grid length of 10–20 km. However, farmers often depend on more detailed short-to medium-range forecasts with higher-resolution regional forecasting models. Therefore, this research aims to address this by developing and evaluating a lightweight and novel weather forecasting system, which consists of one or more local weather stations and state-of-the-art machine learning techniques for weather forecasting using time-series data from these weather stations. To this end, the system explores the state-of-the-art temporal convolutional network (TCN) and long short-term memory (LSTM) networks. Our experimental results show that the proposed model using TCN produces better forecasting compared to the LSTM and other classic machine learning approaches. The proposed model can be used as an efficient localized weather forecasting tool for the community of users, and it could be run on a stand-alone personal computer.},
  archive      = {J_SOCO},
  author       = {Hewage, Pradeep and Behera, Ardhendu and Trovati, Marcello and Pereira, Ella and Ghahremani, Morteza and Palmieri, Francesco and Liu, Yonghuai},
  doi          = {10.1007/s00500-020-04954-0},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16453-16482},
  shortjournal = {Soft Comput.},
  title        = {Temporal convolutional neural (TCN) network for an effective weather forecasting using time-series data from the local weather station},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel selection mechanism for evolutionary algorithms with
metameric variable-length representations. <em>SOCO</em>,
<em>24</em>(21), 16439–16452. (<a
href="https://doi.org/10.1007/s00500-020-04953-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metameric problems are variable-length optimization problems whose representations take on an at least partially segmented structure. This is referred to as a metameric representation. Frequently, each of these segments defines one of a number of analogous components in the solution. Examples include the nodes in a coverage network or turbines in a wind farm. Locating optimal solutions requires, in part, determining the optimal number of components. Evolutionary algorithms can be applied but require modifications to the traditional fixed-length operators. This study proposes a new selection operator for metameric problems: length niching selection. First, the population is partitioned into several niches based on solution length. A window function determines at which lengths a niche is formed. Local selection is then applied within each niche independently, resulting in a new parent population formed by a diverse set of solution lengths. A coverage and a wind farm problem are used to demonstrate the effectiveness of the new operator.},
  archive      = {J_SOCO},
  author       = {Ryerkerk, Matt and Averill, Ron and Deb, Kalyanmoy and Goodman, Erik},
  doi          = {10.1007/s00500-020-04953-1},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16439-16452},
  shortjournal = {Soft Comput.},
  title        = {A novel selection mechanism for evolutionary algorithms with metameric variable-length representations},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel prediction method of complex univariate time series
based on k-means clustering. <em>SOCO</em>, <em>24</em>(21),
16425–16437. (<a
href="https://doi.org/10.1007/s00500-020-04952-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-series prediction has been widely studied and applied in various fields. For the time series with high acquisition frequency and high noise, it is very difficult to establish a prediction model directly. Therefore, it is necessary to study how to obtain the change trend information of time series accurately, and then build a prediction model for its change trend. To obtain the change trend information of the original time series effectively and establish an accurate prediction model, this paper proposes a novel prediction method of complex univariate time series based on K-means clustering. This method first obtains the change trend information of the original time series based on the K-means clustering idea, and then, a gated recurrent unit based on the input attention mechanism is used to establish a prediction model for the obtained time-series change trend information. Extensive experiments on the electromagnetic radiation dataset we collected, the AEP_hourly dataset, and the Wind Turbine Scada dataset published online, demonstrate that our proposed K-means clustering method can effectively reduce noise interference and accurately obtain the time-series change trend information. Comparative experiments of different prediction models demonstrate that our prediction model has the best prediction accuracy, and our proposed complex univariate time-series prediction algorithm has great practical value.},
  archive      = {J_SOCO},
  author       = {Liu, Yunxin and Ding, Shifei and Jia, Weikuan},
  doi          = {10.1007/s00500-020-04952-2},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16425-16437},
  shortjournal = {Soft Comput.},
  title        = {A novel prediction method of complex univariate time series based on k-means clustering},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Markov frameworks and stock market decision making.
<em>SOCO</em>, <em>24</em>(21), 16413–16424. (<a
href="https://doi.org/10.1007/s00500-020-04950-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present applications of Markov rough approximation framework (MRAF). The concept of MRAF is defined based on rough sets and Markov chains. MRAF is used to obtain the probability distribution function of various reference points in a rough approximation framework. We consider a set to be approximated together with its dynamacity and the effect of dynamacity on rough approximations is stated with the help of Markov chains. An extension to Pawlak’s decision algorithm is presented, and it is used for predictions in a stock market environment. In addition, suitability of the algorithm is illustrated in a multi-criteria medical diagnosis problem. Finally, the definition of fuzzy tolerance relation is extended to higher dimensions using reference points and basic results are established.},
  archive      = {J_SOCO},
  author       = {Koppula, Kavitha and Kedukodi, Babushri Srinivas and Kuncham, Syam Prasad},
  doi          = {10.1007/s00500-020-04950-4},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16413-16424},
  shortjournal = {Soft Comput.},
  title        = {Markov frameworks and stock market decision making},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Two calibrated meta-heuristics to solve an integrated
scheduling problem of production and air transportation with the
interval due date. <em>SOCO</em>, <em>24</em>(21), 16383–16411. (<a
href="https://doi.org/10.1007/s00500-020-04948-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contrary to previous methods in production management, today’s approaches mainly focus on the whole supply chain parties’ considerations. Considering production planning and distribution, as the two main functions in supply chain (SC) management, in an integrated manner in order to enhance the SC advantages is one of today’s main dilemma. Here, we have firstly proposed and investigated the integrated production and air transportation scheduling problem with time windows for the due date to minimize the total SC costs. Since the problem was NP-hard, two new coordinated and integrated solution procedures have been presented based on meta-heuristics. Four algorithms (i.e., simulated annealing (SA), genetic algorithm, particle swarm optimization/district PSO (PSO/DPSO), and hybrid variable neighborhood search–simulated annealing (H-VNS–SA)) have been developed in both procedures. For the first time in literature, we probe different encoding schemes in the proposed algorithms. In addition, by using Taguchi experimental design, the parameters of the algorithms have been tuned. Besides, to study the behavior of the algorithms, different problem sizes have been generated and the results of two procedures have been compared together and discussed. Finally, a comparison of the proposed algorithms with some state-of-art optimized algorithms has been presented to prove statistically better performance of the proposed algorithms in most cases.},
  archive      = {J_SOCO},
  author       = {Mousavi, M. and Hajiaghaei–Keshteli, M. and Tavakkoli–Moghaddam, R.},
  doi          = {10.1007/s00500-020-04948-y},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16383-16411},
  shortjournal = {Soft Comput.},
  title        = {Two calibrated meta-heuristics to solve an integrated scheduling problem of production and air transportation with the interval due date},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimized channel allocation in emerging mobile cellular
networks. <em>SOCO</em>, <em>24</em>(21), 16361–16382. (<a
href="https://doi.org/10.1007/s00500-020-04947-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of optimizing service quality in wireless networks is a continuous research that requires the design of efficient channel allocation schemes. The problem is how limited channel resources can be maximally utilized, to guarantee seamless communication while maintaining excellent service quality. Whereas, fixed channel allocation (FCA) schemes treat new and handoff calls equally without preference to normally prioritized handoff calls; dynamic channel allocation (DCA) schemes accommodate users mobility in randomly changing network conditions. However, classical Erlang-B models are deficient and do not consider users mobility and dynamically changing traffic of the mobile network environment. A modified Erlang-B dynamic channel allocation (MEB-DCA) scheme is therefore introduced in this paper, for improved network performance. The MEB-DCA algorithm introduces a conditional threshold for handoff request assignment to ensure that communication systems do not unnecessarily prioritize handoff calls at the detriment of new calls. Deriving knowledge from imprecise network data is difficult when developing functional relationships between parameters, requiring advanced modeling techniques with cognitive experience. Soft computing techniques have been shown to handle this challenge given its ability to represent precisely, both data and expert knowledge. An adaptive neuro-fuzzy inference system-based dynamic channel allocation (ANFIS-DCA) framework was proposed to automate the learning of communication parameters for optimized channel allocation decisions. Network parameters considered were received signal strength indication impacted by user mobility, number of guard and general channels, carried traffic, and handoff blocking threshold. The performance of the proposed ANFIS-DCA model was found to outsmart the static FCA and back propagation neural network-based DCA (NN-DCA) schemes using mean square error and root mean square error as performance measures. Our approach can be effectively deployed to improve channel allocation, resource utilization, network capacity, and satisfy users experience.},
  archive      = {J_SOCO},
  author       = {Asuquo, Daniel and Ekpenyong, Moses and Udoh, Samuel and Robinson, Samuel and Attai, Kingsley},
  doi          = {10.1007/s00500-020-04947-z},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16361-16382},
  shortjournal = {Soft Comput.},
  title        = {Optimized channel allocation in emerging mobile cellular networks},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Automatic method for classification of groundnut diseases
using deep convolutional neural network. <em>SOCO</em>, <em>24</em>(21),
16347–16360. (<a
href="https://doi.org/10.1007/s00500-020-04946-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Groundnut is one of the most important and popular oilseed foods in the agricultural field, and its botanical name is Arachis hypogaea L. Approximately, the pod of mature groundnut contains 1–5 seeds with 57\% of oil and 25\% of protein content. The oil obtained from the groundnut is widely used for cooking and losing body weight, and its fats are widely used for making soaps. The groundnut cultivation is affected by different kinds of diseases such as fungi, viruses, and bacteria. Hence, these diseases affect the leaf, root and stem of the groundnut plant and it leads to heavy loss in yield. Moreover, the enlarger number of diseases affects the leaf and root-like Alternaria, Pestalotiopsis, Bud necrosis, tikka, Phyllosticta, Rust, Pepper spot, Choanephora, early and late leaf spot. To overcome these issues, we introduce an efficient method of deep convolutional neural network (DCNN) because it automatically detects the important features without any human supervision. The DCNN procedure can deeply detect plant disease by using a deep learning process. Moreover, the DCNN training and testing process demonstrate an accurate groundnut disease determination and classification result. The number of groundnut leaf disease images is chosen from the plant village dataset, and it is used for the training and testing process. The stochastic gradient decent momentum method is used for dataset training, and it has shown the better performance of proposed DCNN. From the comparison analysis, the 6th combined layer of proposed DCNN delivers a 95.28\% accuracy value. Ultimately, the groundnut disease classification with its overall performance of proposed DCNN provides 99.88\% accuracy.},
  archive      = {J_SOCO},
  author       = {Vaishnnave, M. P. and Suganya Devi, K. and Ganeshkumar, P.},
  doi          = {10.1007/s00500-020-04946-0},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16347-16360},
  shortjournal = {Soft Comput.},
  title        = {Automatic method for classification of groundnut diseases using deep convolutional neural network},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). RETRACTED ARTICLE: MapReduce-based big data framework using
modified artificial neural network classifier for diabetic chronic
disease prediction. <em>SOCO</em>, <em>24</em>(21), 16335–16345. (<a
href="https://doi.org/10.1007/s00500-020-04943-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, healthcare data consist of an enormous amount of information, which is challenging to maintain by manual methods. Due to the development of big data in the communities of biomedical and health care, accurate study of the medical data helps the recognition of the disease in early stage, patient care and community services. It mainly focuses on predicting and exploring the conditions due to some significant effects on health which are on the increase in multiple cities. The existing system in the medical field cannot extract complete information from the chronic disease database. It is complicated for the healthcare practitioner to analyze and diagnose constant disease since it plays a challenging task. This paper presents a modified artificial neural network (ANN) classifier technique with a MapReduce framework for the prediction of disease. For preprocessing, min–max normalization is carried out to enhance the accuracy of system. This MapReduce is applied for providing a feasible framework in predictive programming algorithms for the map and reduce functions. This is a simple programming interface, which helps in efficiently solving predictive problems. The primary intention of the proposed system is to analyze accurate, fast and optimal results on chronic disease datasets. It increases the throughput and redundancy in cases of retrieving the vast data. Thus, integrating a modified ANN classifier with a reduced framework is useful in providing better outcomes. The experimental results over chronic diabetic dataset prove that the proposed artificial neural network with MapReduce structure is capable of predicting the precision, sensitivity and specificity level modified on comparing with other existing deep neural network approaches.},
  archive      = {J_SOCO},
  author       = {Ramani, R. and Vimala Devi, K. and Ruba Soundar, K.},
  doi          = {10.1007/s00500-020-04943-3},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16335-16345},
  shortjournal = {Soft Comput.},
  title        = {RETRACTED ARTICLE: MapReduce-based big data framework using modified artificial neural network classifier for diabetic chronic disease prediction},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A pattern recognition model to distinguish cancerous DNA
sequences via signal processing methods. <em>SOCO</em>, <em>24</em>(21),
16315–16334. (<a
href="https://doi.org/10.1007/s00500-020-04942-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cancer is one of the life-threatening diseases caused by changes in the structure of genetic components of the cell. DNA sequences are one of the most important factors in the formation and spread of this disease. The signal processing approach is one of the scientific fields that has been developed in the last two decades in the analysis of DNA sequences. In this research, a hybrid model of discrete Fourier transform and anti-notch digital filter has been used for this purpose. The aim of using these techniques is to model an approach that can distinguish cancerous samples from non-cancerous ones. In other words, a pattern recognition model is designed to discriminate cancerous cell samples based on the features of protein coding regions of DNA sequences. Some computational and statistical techniques have been used in feature extraction and feature selection stages. Despite the proposed model simplicity, it doesn’t face conventional challenges such as high computational complexity or memory dissipation. Case studies have been tested with the least possible feature, depending on the nature of the features. Experimental results and features relationship led to the proposal of the SVM classifier to discriminate two categories. The output features and classification show good discrimination results among the cancerous and non-cancerous samples. One of the main advantages of the proposed model is the independence of its performance over the data length. Evaluation and validation results indicate the high accuracy and precision of the proposed method which emphasizes the biological genetic mutation nature of cancer.},
  archive      = {J_SOCO},
  author       = {Khodaei, Amin and Feizi-Derakhshi, Mohammad-Reza and Mozaffari-Tazehkand, Behzad},
  doi          = {10.1007/s00500-020-04942-4},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16315-16334},
  shortjournal = {Soft Comput.},
  title        = {A pattern recognition model to distinguish cancerous DNA sequences via signal processing methods},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Granular matrix method of attribute reduction in formal
contexts. <em>SOCO</em>, <em>24</em>(21), 16303–16314. (<a
href="https://doi.org/10.1007/s00500-020-04941-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Granular reduction has been of great interests for formal context analysis. From the perspective of granular computing, granular matrices are proposed to represent the extensions and intensions of formal concepts. Within this framework, irreducible elements are studied. Furthermore, similarity degree, information granular and information entropy are developed to specify the significance of attribute. In this case, heuristic approaches for granular reduct are proposed. Finally, several data sets are experimented to demonstrate the feasibility and efficiency of our method. Our methods present a new framework for granular reduction in formal concept analysis.},
  archive      = {J_SOCO},
  author       = {Lin, Yidong and Li, Jinjin and Wang, Hongkun},
  doi          = {10.1007/s00500-020-04941-5},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16303-16314},
  shortjournal = {Soft Comput.},
  title        = {Granular matrix method of attribute reduction in formal contexts},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-objective evolutionary algorithm for solving
energy-aware fuzzy job shop problems. <em>SOCO</em>, <em>24</em>(21),
16291–16302. (<a
href="https://doi.org/10.1007/s00500-020-04940-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A growing concern about the environmental impact of manufacturing processes and in particular the associated energy consumption has recently driven some researchers within the scheduling community to consider energy costs in addition to more traditional performance-related measures, such as satisfaction of due-date commitments. Recent research is also devoted to narrowing the gap between real-world applications and academic problems by handling uncertainty in some input data. In this paper, we address the job shop scheduling problem, a well-known hard problem with many applications, using fuzzy sets to model uncertainty in processing times and with the target of finding solutions that perform well with respect to both due-date fulfilment and energy efficiency. The resulting multi-objective problem is solved using an evolutionary algorithm based on the NSGA-II procedure, where the decoding operator incorporates a new heuristic procedure in order to improve the solutions’ energy consumption. This heuristic is based on a theoretical analysis of the changes in energy consumption when a solution is subject to slight changes, referred to as local right shifts. The experimental results support the theoretical study and show the potential of the proposal.},
  archive      = {J_SOCO},
  author       = {González-Rodríguez, Inés and Puente, Jorge and Palacios, Juan José and Vela, Camino R.},
  doi          = {10.1007/s00500-020-04940-6},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16291-16302},
  shortjournal = {Soft Comput.},
  title        = {Multi-objective evolutionary algorithm for solving energy-aware fuzzy job shop problems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hesitant fuzzy soft topology and its applications to
multi-attribute group decision-making. <em>SOCO</em>, <em>24</em>(21),
16269–16289. (<a
href="https://doi.org/10.1007/s00500-020-04938-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of this research study is to extend the multi-attribute group decision-making (MAGDM) methods to hesitant fuzzy soft set (HFS-set), hesitant fuzzy soft topology (HFS-topology) and HFS-Hausdorff spaces in group decision-making environment, as HFS-set is more superior tool to capture vagueness, hesitancy and incompleteness in individual evaluations. In order to obtain optimal decisions in MAGDM, we present two algorithms based on hesitant fuzzy soft set and hesitant fuzzy soft topology. Lastly, we present MAGDM method by using HFS-Hausdorff space to deal with hesitancy and uncertainty. The developed methods have the ability to solve MADGM problems in which the assessment information on available alternatives, provided by the experts, is presented by hesitant fuzzy soft sets. Furthermore, the efficiency of proposed algorithms is shown by applying them to the real-world problems. We use reduct, optimum reduct, aggregate HFS-sets and weight vector according of given alternatives, priority of the attributes and customer demand for best MAGDM in the selection of car.},
  archive      = {J_SOCO},
  author       = {Riaz, Muhammad and Davvaz, Bijan and Fakhar, Atiqa and Firdous, Atiqa},
  doi          = {10.1007/s00500-020-04938-0},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16269-16289},
  shortjournal = {Soft Comput.},
  title        = {Hesitant fuzzy soft topology and its applications to multi-attribute group decision-making},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel chaotic flower pollination-based intrusion detection
framework. <em>SOCO</em>, <em>24</em>(21), 16249–16267. (<a
href="https://doi.org/10.1007/s00500-020-04937-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rise of network on handheld devices, security of the network has become critical issue. Intrusion detection system is used to predict intrusive packets on network; two-step procedure has been used to predict the intrusion, i.e., feature selection and then classification. Firstly, unwanted and expandable features in data lead to network classification problem which affect the decision capability of the classifiers, so we need optimize feature selection technique. Feature selection technique used in this paper is based on the correlation information known as correlation-based feature selection (CFS). In this paper, CFS’s search algorithm is implemented using Chaotic Flower Pollination Algorithm (CFPA) that logically selects the most favorable features for classification referred as CFPA-CFS. Further, hybridization of CFPA and support vector machine classifier is implemented and named as CFPSVM. Finally, novel IDS framework uses CFPA-CFS and CFPSVM in sequence to predict the intrusion. Further, performance of proposed framework is evaluated using two intrusion detection evaluation datasets, namely KDDCup99 and NSL-KDD. The results demonstrate that proposed CFPA-CFS contributes more critical features for CFPSVM to achieve better accuracy compared with the state-of-the-art methods.},
  archive      = {J_SOCO},
  author       = {Singh, Amrit Pal and Kaur, Arvinder and Pal, Saibal Kumar},
  doi          = {10.1007/s00500-020-04937-1},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16249-16267},
  shortjournal = {Soft Comput.},
  title        = {A novel chaotic flower pollination-based intrusion detection framework},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Lightning attachment procedure optimization algorithm for
nonlinear non-convex short-term hydrothermal generation scheduling.
<em>SOCO</em>, <em>24</em>(21), 16225–16248. (<a
href="https://doi.org/10.1007/s00500-020-04936-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short-term hydrothermal scheduling (STHS) is considered an important problem in the field of power system economics. The solution of this problem gives the hourly output of power generation schedule of the available hydro and thermal power units, which leads to minimization of the total fuel cost of thermal units for a given period of a time. The optimal generation of STHS is considered as a complicated and nonlinear optimization problem with a set of equality and inequality constraints such as the valve point loading effect of thermal units, the power transmission loss and the load balance. This paper proposes lightning attachment procedure Optimization (LAPO) algorithm for solving the nonlinear non-convex STHS optimization problem in order to minimize the operating fuel cost of thermal units with satisfying the operating constraints of the system. The performance of LAPO algorithm is validated using three different test systems considering the valve point loading effects of thermal units and the power transmission losses. The obtained results prove the effectiveness and superiority of LAPO algorithm for solving the STHS problem compared with other well-known optimization techniques.},
  archive      = {J_SOCO},
  author       = {Mohamed, Maha and Youssef, Abdel-Raheem and Kamel, Salah and Ebeed, Mohamed},
  doi          = {10.1007/s00500-020-04936-2},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16225-16248},
  shortjournal = {Soft Comput.},
  title        = {Lightning attachment procedure optimization algorithm for nonlinear non-convex short-term hydrothermal generation scheduling},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Physical significance of chemical processes and lorentz’s
forces aspects on sisko fluid flow in curved configuration.
<em>SOCO</em>, <em>24</em>(21), 16213–16223. (<a
href="https://doi.org/10.1007/s00500-020-04935-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current determination is committed to characterize the features of curved surface for Sisko fluid in the presence of Lorentz’s forces. Heat–mass relocation exploration is conducted in the presence of homogeneous–heterogeneous processes and non-uniform heat sink/source. Similarity variables are designated to transmute nonlinear PDEs into ODEs. These intricate ordinary differential expressions assessing the flow situation are handled efficaciously by manipulating bvp4c scheme. Graphical demonstration is deliberated to scrutinize the variation in pressure, velocity, temperature and concentration profiles with respect to flow regulating parameters. Numerical data are displayed through tables in order to surmise variation in surface drag force and heat transport rate. It is noted that radius of curvature and temperature-dependent heat sink/source significantly affect heat–mass transport mechanisms for curved surface. Furthermore, graphical analysis reveals that velocity profile of Sisko magneto-fluid enhances for augmented values of curvature parameter. Additionally, it is evaluated that increasing values of heat source parameter and Lorentz’s forces, pressure profile exhibited the diminishing behavior.},
  archive      = {J_SOCO},
  author       = {Ali, M. and Irfan, M. and Khan, W. A. and Sultan, F. and Shahzad, M. and Khan, M.},
  doi          = {10.1007/s00500-020-04935-3},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16213-16223},
  shortjournal = {Soft Comput.},
  title        = {Physical significance of chemical processes and lorentz’s forces aspects on sisko fluid flow in curved configuration},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Classification of noiseless corneal image using capsule
networks. <em>SOCO</em>, <em>24</em>(21), 16201–16211. (<a
href="https://doi.org/10.1007/s00500-020-04933-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classifying a particular image from a data set is a complex work for any image analyst. Generally, the output of medical image scan gives numerous images for analysis. In that, the image analyst has to manually predict a better noiseless image for computer-assisted image process program. Manual verification of all the output images from the scan device consumes a lot of time in predicting the abnormality of a patient. The proposed capsule network for noiseless image algorithm assists the image analyst by classifying the noiseless image from the data set for further computer-assisted image enhancement or segmentation program. The proposed algorithm performance is evaluated and compared with the existing algorithms in terms of accuracy, sensitivity, specificity, positive predictive value, and negative predictive value.},
  archive      = {J_SOCO},
  author       = {Koresh, H. James Deva and Chacko, Shanty},
  doi          = {10.1007/s00500-020-04933-5},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16201-16211},
  shortjournal = {Soft Comput.},
  title        = {Classification of noiseless corneal image using capsule networks},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Online scheduling of dependent tasks of cloud’s workflows to
enhance resource utilization and reduce the makespan using multiple
reinforcement learning-based agents. <em>SOCO</em>, <em>24</em>(21),
16177–16199. (<a
href="https://doi.org/10.1007/s00500-020-04931-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to different heterogeneous cloud resources and diverse and complex applications of the users, an optimal task scheduling, which can satisfy users and cloud service providers with energy-saving and cost-effective use of resources, is a major issue in cloud computing. On the one hand, network users are demanding the quality assurance of their requested services, minimizing their costs, and their own data security, and on the other hand, the service providers consider less power consumption, more efficient use of resources, and optimal utilization. In dependent tasks dealing with massive data, resource scheduling is considered as an important challenge. Due to the time limitation of online scheduling process of dependent tasks, many existing methods of the literature are not able to guarantee the best resource utilization. In this paper, a reinforcement learning approach is exploited in a multi-agent system for task scheduling and resource provisioning, in order to reduce the makespan, minimize the required power, optimize the cost of using the resources, and maximize the utilization of the resources (considering their expiration time), simultaneously. The proposed algorithm has two phases. In the first phase, the tasks are scheduled using reinforcement learning techniques, and in the second one, considering the information obtained from the scheduling phase, resources are allocated in a multi-agent environment. The results of experiments show that this method improves the efficiency of the use of resources and reduces their costs. Moreover, the expiration time of the tasks is observed and the total execution time and energy consumption will be significantly reduced.},
  archive      = {J_SOCO},
  author       = {Asghari, Ali and Sohrabi, Mohammad Karim and Yaghmaee, Farzin},
  doi          = {10.1007/s00500-020-04931-7},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16177-16199},
  shortjournal = {Soft Comput.},
  title        = {Online scheduling of dependent tasks of cloud’s workflows to enhance resource utilization and reduce the makespan using multiple reinforcement learning-based agents},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). New similarity and entropy measures of single-valued
neutrosophic sets with applications in multi-attribute decision making.
<em>SOCO</em>, <em>24</em>(21), 16165–16176. (<a
href="https://doi.org/10.1007/s00500-020-04930-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information measures play a fundamental role in single-valued neutrosophic set (SVNS) theory. The main purpose of this paper is to study the similarity and entropy measures of SVNS with applications in multi-attribute decision making. We proposed the axiomatic definitions of similarity and entropy for single-valued neutrosophic values (SVNVs) with respect to a new kind of inclusion relation between SVNVs. On the basis of Hamming distance, cosine function and cotangent function, three similarity measures and three entropies for SVNVs are constructed. Then, we extended the definitions and construction methods of similarity and entropy for SVNVs to SVNSs by using some aggregation operators. Finally, by using the new similarity and entropy measures we presented a SVNSs based multi-attribute decision making method. It demonstrated that the new information measures presented in this study are applicable and efficient.},
  archive      = {J_SOCO},
  author       = {Qin, Keyun and Wang, Lu},
  doi          = {10.1007/s00500-020-04930-8},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16165-16176},
  shortjournal = {Soft Comput.},
  title        = {New similarity and entropy measures of single-valued neutrosophic sets with applications in multi-attribute decision making},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Individual credit ranking by an integrated interval type-2
trapezoidal fuzzy electre methodology. <em>SOCO</em>, <em>24</em>(21),
16149–16163. (<a
href="https://doi.org/10.1007/s00500-020-04929-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, first, it is aimed to determine the most important criteria which affect the credit evaluation process. A type-2 trapezoidal fuzzy analytic hierarchy process method is proposed to analyze the criteria influencing the credit evaluation. Then, a ranking of experts is obtained using a type-2 trapezoidal fuzzy Electre (elimination and choice translating reality English) method. Lastly, the applicants’ ranking is determined as a real case. This method is aimed to be used by public and private banks to improve their credit ranking and evaluation strategies. Finally, the applicability and feasibility of the proposed approach are demonstrated by providing the results and sensitivity analysis.},
  archive      = {J_SOCO},
  author       = {Ayyildiz, Ertugrul and Taskin Gumus, Alev and Erkan, Merve},
  doi          = {10.1007/s00500-020-04929-1},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16149-16163},
  shortjournal = {Soft Comput.},
  title        = {Individual credit ranking by an integrated interval type-2 trapezoidal fuzzy electre methodology},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A hybrid fuzzy multi-attribute decision making model to
select road pavement type. <em>SOCO</em>, <em>24</em>(21), 16135–16148.
(<a href="https://doi.org/10.1007/s00500-020-04928-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pavement is an important part of a road structure. Selection of road pavement type is one of the important challenges of decision making by highway administrators. The life-cycle cost analysis is one of the common tools to select the pavement type which considers economic criteria such as costs of construction, maintenance and rehabilitation, and user costs; however, noneconomic criteria are neglected. The inadequate selection of road pavement type tends to increase the pavement life-cycle cost and impacts both environmental and social parameters. In this study, a three-step hybrid model is proposed to solve this problem. Initially, the causal relationships of main criteria affecting the pavement type selection are determined using decision making trial and evaluation laboratory. Then, the weight and importance of criteria and sub-criteria are determined using fuzzy analytic network process. Finally, the ranking of pavement alternatives is carried out using a fuzzy technique for order preference by similarity to ideal solution. A real case study consisting of five different types of pavements including hot mix asphalt, stone mastic asphalt, jointed plain concrete pavement, roller compacted concrete pavement with hot mix asphalt overlay and continuous reinforced concrete pavement is used to show the validity of the proposed model.},
  archive      = {J_SOCO},
  author       = {Pasha, Ali and Mansourian, Ahmad and Ravanshadnia, Mehdi},
  doi          = {10.1007/s00500-020-04928-2},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16135-16148},
  shortjournal = {Soft Comput.},
  title        = {A hybrid fuzzy multi-attribute decision making model to select road pavement type},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Cubic bipolar fuzzy set with application to multi-criteria
group decision making using geometric aggregation operators.
<em>SOCO</em>, <em>24</em>(21), 16111–16133. (<a
href="https://doi.org/10.1007/s00500-020-04927-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bipolar irrational emotions are implicated in a broad variety of individual actions. For example, two specific elements of decision making are the benefits and adverse effects. The harmony and respectful coexistence between these two elements is viewed as a cornerstone to a healthy social setting. For bipolar fuzzy characteristics of the universe of choices that rely on a small range of degrees, a bipolar fuzzy decision making method utilizing different techniques is accessible. The idea of a simplistic bipolar fuzzy set is ineffective in supplying consistency to the details about the frequency of the rating due to minimal knowledge. In this respect, we present cubic bipolar fuzzy sets (CBFSs) as a generalization of bipolar fuzzy sets. The plan of this research is to establish an innovative multi-criteria group decision making (MCGDM) based on cubic bipolar fuzzy set (CBFS) by unifying aggregation operators under geometric mean operations. The geometric mean operators are regarded to be a helpful technique, particularly in circumstances where an expert is unable to fuse huge complex unwanted information properly at the outset of the design of the scheme. We present some basic operations for CBFSs under dual order, i.e., $$\mathrm {P}$$ -Order and $$\mathrm {R}$$ -Order. We introduce some algebraic operations on CBFSs and some of their fundamental properties for both orders. We propose $$\mathrm {P}$$ -cubic bipolar fuzzy weighted geometric ( $$\mathrm {P}$$ -CBFWG) operator and $$\mathrm {R}$$ -cubic bipolar fuzzy weighted geometric ( $$\mathrm {R}$$ -CBFWG) operator to aggregate cubic bipolar fuzzy data. We also discuss the useability and efficiency of these operators in MCGDM problem. In human decisions, the second important part is ranking of alternatives obtained after evaluation. In this regard, we present an improved score and accuracy function to compare the cubic bipolar fuzzy elements (CBFEs). We also discuss a set theoretic comparison of proposed set with other theories as well as method base comparison of the proposed method with some existing techniques of bipolar fuzzy domain.},
  archive      = {J_SOCO},
  author       = {Riaz, Muhammad and Tehrim, Syeda Tayyba},
  doi          = {10.1007/s00500-020-04927-3},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16111-16133},
  shortjournal = {Soft Comput.},
  title        = {Cubic bipolar fuzzy set with application to multi-criteria group decision making using geometric aggregation operators},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fuzzy structural element method for solving fuzzy dual
medium seepage model in reservoir. <em>SOCO</em>, <em>24</em>(21),
16097–16110. (<a
href="https://doi.org/10.1007/s00500-020-04926-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study primarily introduces fuzzy set theory in the reservoirs modeling to enhance the accuracy of the model. The conventional seepage models of dual medium in reservoirs have several limitations. To be specific, it considers the complexity of the model during the modeling process and idealizes certain reservoir parameters to be constant. By adopting fuzzy set theory to study reservoir seepage theory, on the one hand, the seepage model is capable of fully considering the complex and variability of the reservoir; on the other hand, it can avoid parameter errors attributed to laboratory measurements. A numerical example is given in this study to illustrate the accuracy and superiority of the fuzzy seepage model. Studies suggest that fuzzy set theory is capable of effectively addressing the limitations in conventional seepage models.},
  archive      = {J_SOCO},
  author       = {Zhang, Duo and Shu, Lan and Li, Shunchu},
  doi          = {10.1007/s00500-020-04926-4},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16097-16110},
  shortjournal = {Soft Comput.},
  title        = {Fuzzy structural element method for solving fuzzy dual medium seepage model in reservoir},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). XACBench: A XACML policy benchmark. <em>SOCO</em>,
<em>24</em>(21), 16081–16096. (<a
href="https://doi.org/10.1007/s00500-020-04925-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {XACML standard defines a declarative language to determine access control policies which are critical for deploying security solutions. It is important to evaluate the performance of policies defined by XACML, for applications such as policy enforcement efficiency, policy refinement, anomaly detection, conflict resolution, and policy similarity assessment. Due to security and confidentiality reasons, at hands policy sets for such evaluations are very rare. Moreover, these policy sets are created gradually, thus access to large and effective policy sets in a short time is challenging and daunting task. In this paper, we present XACBench, a suite of tools for both generating synthetic XACML policies and benchmarking the policy evaluation algorithms. To this end, XACBench first extracts, models and generalizes some statistical properties of an input policy which is called policy profile. Such profile helps generating policies in a way that accurately simulates the statistic properties of the input policy. XACBench then generates synthetic policies of any desired length based on the profile. It also provides a simple mechanism for controlling the correlation between the generated policies and the input policy with respect to the extracted policy profile. Experimental results demonstrate that our approach is efficient and scalable to various policy lengths as well as input policies.},
  archive      = {J_SOCO},
  author       = {Ahmadi, Shayan and Nassiri, Mohammad and Rezvani, Mohsen},
  doi          = {10.1007/s00500-020-04925-5},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16081-16096},
  shortjournal = {Soft Comput.},
  title        = {XACBench: A XACML policy benchmark},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A forefront to machine translation technology: Deployment on
the cloud as a service to enhance QoS parameters. <em>SOCO</em>,
<em>24</em>(21), 16057–16079. (<a
href="https://doi.org/10.1007/s00500-020-04923-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine translation system (MTS) constitutes of functionally heterogeneous modules for processing source language to a given target language. Deploying such an application on a stand-alone system requires much time, knowledge and complications. It even becomes more challenging for a common user to utilize such a complex application. This paper presents a MTS that has been developed using a combination of linguistic rich, rule-based and prominent neural-based approach. The proposed MTS is deployed on the cloud to offer translation as a cloud service and improve the quality of service (QoS) from a stand-alone system. It is developed on TensorFlow and deployed under the cluster of virtual machines in the Amazon web server (EC2). The significance of this paper is to demonstrate management of recurrent changes in term of corpus, domain, algorithm and rules. Further, the paper also compares the MTS as deployed on stand-alone machine and on cloud for different QoS parameters like response time, server load, CPU utilization and throughput. The experimental results assert that in the translation task, with the availability of elastic computing resources in the cloud environment, the job completion time irrespective of its size can be assured to be within a fixed time limit with high accuracy.},
  archive      = {J_SOCO},
  author       = {Singh, Muskaan and Kumar, Ravinder and Chana, Inderveer},
  doi          = {10.1007/s00500-020-04923-7},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16057-16079},
  shortjournal = {Soft Comput.},
  title        = {A forefront to machine translation technology: Deployment on the cloud as a service to enhance QoS parameters},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). LegalCap: A model for complex case discrimination based on
capsule neural network. <em>SOCO</em>, <em>24</em>(21), 16043–16055. (<a
href="https://doi.org/10.1007/s00500-020-04922-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, artificial intelligence, especially deep learning techniques, has provided an excellent theoretical and technical basis for the development of intelligent court. Given that case description usually contains multiple charges, charge prediction can be regarded as a task of multi-label text classification. We utilize the gated recurrent unit (GRU), a variant of recurrent neural network (RNN), to extract the chronological features of sequence. Due to the lack of retaining the positional relationship of entities when using RNN to extract features from text, a fraction of information will be lost in the context of multi-label classification. To address the drawbacks aforementioned, capsule neural network is utilized to extract the positional relation. Considering the basic and positional feature of instance, a composite model LegalCap, which combines capsule neural network with GRU, is proposed to model the complicated cases. Extensive experiments prove that the proposed model outperforms the selected baselines in the task of charge prediction. To overcome the unsatisfactory performance of directly conducting deep learning in charge prediction on the minority cases, we relieve the impact of training case imbalance by means of re-sampling. Experimental results demonstrate that after modifying the data distribution, the LegalCap model has a significant improvement on models’ bias on labels, i.e., better predictions on minority cases.},
  archive      = {J_SOCO},
  author       = {Peng, Dunlu and Wu, Qiankun},
  doi          = {10.1007/s00500-020-04922-8},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16043-16055},
  shortjournal = {Soft Comput.},
  title        = {LegalCap: A model for complex case discrimination based on capsule neural network},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new bi-objective integrated dynamic cell formation and
AGVs’ dwell point location problem on the inter-cell unidirectional
single loop. <em>SOCO</em>, <em>24</em>(21), 16021–16042. (<a
href="https://doi.org/10.1007/s00500-020-04921-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to increase the flexibility, space utilization, product quality and safety, transferring the semi-manufactured parts between machines is performed by automated guided vehicles (AGVs). AGVs should be properly managed to maintain their efficiency as a material handling equipment in production systems. This AGVs’ management will be more important where the circumstances will be dynamic (i.e., where the volume and variety of demands are different one period to another). To determine one or several homes for idle AGVs (AGVs’ dwell point), the assignment of AGVs to manufacturing cell and to prevent the AGVs collisions are three basic aspects in their management. This paper proposes a new nonlinear mixed-integer bi-objective mathematical model of dynamic cell formation and dwell point location problem (DCFDPLP) for AGVs on unidirectional single loop in which AGVs assignment, location of dwell points for AGVs and transportation time of AGVs are considered besides cell reconfiguration, part families and machine groups formation in a dynamic environment. The first objective is to minimize the related costs, and the second one is to minimize the maximum response time for all AGVs. The nonlinear model is transformed to linear one. Due to the NP-hardness of DCFDPLP, a non-dominated sorting genetic algorithm (NSGA-II) is developed to solve the problem. Finally, randomly generated test problems are generated to demonstrate the performance of NSGA-II as a solution procedure.},
  archive      = {J_SOCO},
  author       = {Dehnavi-Arani, Saeed and Sadegheih, Ahmad and Zare Mehrjerdi, Yahia and Honarvar, Mahboobeh},
  doi          = {10.1007/s00500-020-04921-9},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16021-16042},
  shortjournal = {Soft Comput.},
  title        = {A new bi-objective integrated dynamic cell formation and AGVs’ dwell point location problem on the inter-cell unidirectional single loop},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Automatic detection and classification of EEG artifacts
using fuzzy kernel SVM and wavelet ICA (WICA). <em>SOCO</em>,
<em>24</em>(21), 16011–16019. (<a
href="https://doi.org/10.1007/s00500-020-04920-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalography (EEG) is almost contaminated with many artifacts while recording the brain signal activity. Clinical diagnostic and brain computer interface applications frequently require the automated removal of artifacts. In digital signal processing and visual assessment, EEG artifact removal is considered to be the key analysis technique. Nowadays, a standard method of dimensionality reduction technique like independent component analysis (ICA) and wavelet transform combination can be explored for removing the EEG signal artifacts. Manual artifact removal is time-consuming; in order to avoid this, a novel method of wavelet ICA (WICA) using fuzzy kernel support vector machine (FKSVM) is proposed for removing and classifying the EEG artifacts automatically. Proposed method presents an efficient and robust system to adopt the robotic classification and artifact computation from EEG signal without explicitly providing the cutoff value. Furthermore, the target artifacts are removed successfully in combination with WICA and FKSVM. Additionally, proposes the various descriptive statistical features such as mean, standard deviation, variance, kurtosis and range provides the model creation technique in which the training and testing the data of FKSVM is used to classify the EEG signal artifacts. The future work to implement various machine learning algorithm to improve performance of the system.},
  archive      = {J_SOCO},
  author       = {Yasoda, K. and Ponmagal, R. S. and Bhuvaneshwari, K. S. and Venkatachalam, K.},
  doi          = {10.1007/s00500-020-04920-w},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16011-16019},
  shortjournal = {Soft Comput.},
  title        = {Automatic detection and classification of EEG artifacts using fuzzy kernel SVM and wavelet ICA (WICA)},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Misdirection steganography. <em>SOCO</em>, <em>24</em>(21),
16005–16010. (<a
href="https://doi.org/10.1007/s00500-020-05345-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information is one of the most important resources in this world. Therefore, we must protect it from third parties. A typical method for protecting information contents is cryptography. We use cryptography to prevent secret information from leaking to third parties. However, we will use steganography to conceal the existence of information because cryptography cannot achieve this function. Many steganographic techniques have been also proposed as well as cryptography. In this paper, we propose a different type of steganography called misdirection steganography. Our steganography transfers two kinds of secret data, true secret data and decoy secret data, as data embedding into cover data, and the process embedding the true secret data depends on how to embed the decoy secret data, i.e., the information about embedding the decoy secret data is also required to extract the true secret data. Our aim is to transfer true secret data in secret by letting third parties pay attention to decoy secret data. In other words, misdirection in the proposed steganography techniques is caused by the fact that the decoy secret data protect the true secret data against third parties.},
  archive      = {J_SOCO},
  author       = {Mihara, Takashi},
  doi          = {10.1007/s00500-020-05345-1},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {16005-16010},
  shortjournal = {Soft Comput.},
  title        = {Misdirection steganography},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). BMDA: Applying biogeography-based optimization algorithm and
mexican hat wavelet to improve dragonfly algorithm. <em>SOCO</em>,
<em>24</em>(21), 15979–16004. (<a
href="https://doi.org/10.1007/s00500-020-05340-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the methods for solving optimization problems is applying metaheuristic algorithms that find near to optimal solutions. Dragonfly algorithm is one of the metaheuristic algorithms which search problem space by the inspiration of hunting and emigration behavior of dragonflies in nature. However, it suffers from the premature convergence of the population to an undesirable point in the detection ability (global search). In this research, an improved dragonfly algorithm called BMDA (applying Biogeography-based algorithm, Mexican hat wavelet, and Dragonfly algorithm) is presented to resolve the premature convergence in high workloads by creating a mutation phase based on the combination of the biogeography-based optimization (BBO) migration process and the Mexican hat wavelet transform in dragonfly algorithm (DA). The algorithm was evaluated for the mean error in comparison with standard dragonfly algorithm (DA), Memory-based Hybrid Dragonfly Algorithm (MHDA), chaotic dragonfly algorithm version 9 (CDA9), Adaptive_DA algorithm, bat algorithm (BAT), particle swarm optimization algorithm (PSO), raven roosting optimization (RRO) and whale optimization algorithm (WOA) using the CEC2017 benchmark functions. The implementation results of the proposed BMDA algorithm applying different benchmark functions outweighed the DA-based algorithm, MHDA algorithm, CDA9 algorithm, Adaptive_DA algorithm, BAT algorithm, PSO algorithm, RRO, and WOA algorithms in terms of mean error.},
  archive      = {J_SOCO},
  author       = {Shirani, Mohammad Reza and Safi-Esfahani, Faramarz},
  doi          = {10.1007/s00500-020-05340-6},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {15979-16004},
  shortjournal = {Soft Comput.},
  title        = {BMDA: Applying biogeography-based optimization algorithm and mexican hat wavelet to improve dragonfly algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Towards a general class of parametric probability weighting
functions. <em>SOCO</em>, <em>24</em>(21), 15967–15977. (<a
href="https://doi.org/10.1007/s00500-020-05335-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we present a novel methodology that can be used to generate parametric probability weighting functions, which play an important role in behavioral economics, by making use of the Dombi modifier operator of continuous-valued logic. Namely, we will show that the modifier operator satisfies the requirements for a probability weighting function. Next, we will demonstrate that the application of the modifier operator can be treated as a general approach to create parametric probability weighting functions including the most important ones such as the Prelec and the Ostaszewski, Green and Myerson (Lattimore, Baker and Witte) probability weighting function families. Also, we will show that the asymptotic probability weighting function induced by the inverse of the so-called epsilon function is none other than the Prelec probability weighting function. Furthermore, we will prove that, by using the modifier operator, other probability weighting functions can be generated from the dual generator functions and from transformed generator functions. Finally, we will show how the modifier operator can be used to generate strictly convex (or concave) probability weighting functions and introduce a method for fitting a generated probability weighting function to empirical data.},
  archive      = {J_SOCO},
  author       = {Dombi, József and Jónás, Tamás},
  doi          = {10.1007/s00500-020-05335-3},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {15967-15977},
  shortjournal = {Soft Comput.},
  title        = {Towards a general class of parametric probability weighting functions},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A dynamic approach for updating the lower approximation in
adjustable multi-granulation rough sets. <em>SOCO</em>, <em>24</em>(21),
15951–15966. (<a
href="https://doi.org/10.1007/s00500-020-05323-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Granular computing ( $$ GrC $$ ) is one of the key issues in the field of information sciences. Research on the theory and algorithms of granular computing has very important practical significance in huge amounts of information. In multi-granulation rough set theory, two subsets are calculated to approximate the target concept, which are extremely time-consuming for large-scale data. In this paper, to address the issue above, we propose efficient algorithms for updating the lower approximation when a single object is added into or deleted from the target concept in an incomplete information system. Firstly, adjustable multi-granulation rough sets ( $$ AMGRSs $$ ) are introduced in an incomplete information system, and the related properties and theorems are explored. Secondly, it is proved that local- $$ AMGRSs $$ and $$ AMGRSs $$ are equivalent in an incomplete information system. Finally, dynamic algorithms for updating the lower approximation are proposed, and the efficiency of these algorithms is verified by an experiment.},
  archive      = {J_SOCO},
  author       = {Liang, Meishe and Mi, Jusheng and Feng, Tao and Xie, Bin},
  doi          = {10.1007/s00500-020-05323-7},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {15951-15966},
  shortjournal = {Soft Comput.},
  title        = {A dynamic approach for updating the lower approximation in adjustable multi-granulation rough sets},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal trade-off between sample size, precision of
supervision, and selection probabilities for the unbalanced fixed
effects panel data model. <em>SOCO</em>, <em>24</em>(21), 15937–15949.
(<a href="https://doi.org/10.1007/s00500-020-05317-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is focused on the unbalanced fixed effects panel data model. This is a linear regression model able to represent unobserved heterogeneity in the data, by allowing each two distinct observational units to have possibly different numbers of associated observations. We specifically address the case in which the model includes the additional possibility of controlling the conditional variance of the output given the input and the selection probabilities of the different units per unit time. This is achieved by varying the cost associated with the supervision of each training example. Assuming an upper bound on the expected total supervision cost and fixing the expected number of observed units for each instant, we analyze and optimize the trade-off between sample size, precision of supervision (the reciprocal of the conditional variance of the output) and selection probabilities. This is obtained by formulating and solving a suitable optimization problem. The formulation of such a problem is based on a large-sample upper bound on the generalization error associated with the estimates of the parameters of the unbalanced fixed effects panel data model, conditioned on the training input dataset. We prove that, under appropriate assumptions, in some cases “many but bad” examples provide a smaller large-sample upper bound on the conditional generalization error than “few but good” ones, whereas in other cases the opposite occurs. We conclude discussing possible applications of the presented results, and extensions of the proposed optimization framework to other panel data models.},
  archive      = {J_SOCO},
  author       = {Gnecco, Giorgio and Nutarelli, Federico and Selvi, Daniela},
  doi          = {10.1007/s00500-020-05317-5},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {15937-15949},
  shortjournal = {Soft Comput.},
  title        = {Optimal trade-off between sample size, precision of supervision, and selection probabilities for the unbalanced fixed effects panel data model},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). LMIs conditions to robust pinning synchronization of
uncertain fractional-order neural networks with discontinuous
activations. <em>SOCO</em>, <em>24</em>(21), 15927–15935. (<a
href="https://doi.org/10.1007/s00500-020-05315-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with the robust pinning synchronization issue of uncertain fractional-order neural networks with discontinuous activations (FNNDAs) by means of the linear matrix inequalities (LMIs). In this paper, a class of FNNDAs model is presented. Moreover, an appropriate pinning controller is designed to ensure the error dynamical system gets robust Mittag–Leffler stability via Lyapunov function approach, non-smooth analysis theory and inequality analysis technique. In addition, the robust pinning synchronization conditions of FNNDAs drive system and FNNDAs response system are obtained in terms of the LMIs. Finally, a typical numerical simulation is provided to show the effectiveness of the obtained results.},
  archive      = {J_SOCO},
  author       = {Zhang, Xinxin and Ma, Yunpeng},
  doi          = {10.1007/s00500-020-05315-7},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {15927-15935},
  shortjournal = {Soft Comput.},
  title        = {LMIs conditions to robust pinning synchronization of uncertain fractional-order neural networks with discontinuous activations},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Decision making based on linguistic interval-valued
intuitionistic neutrosophic dombi fuzzy hybrid weighted geometric
operator. <em>SOCO</em>, <em>24</em>(21), 15907–15925. (<a
href="https://doi.org/10.1007/s00500-020-05282-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we proposed the notion of a linguistic interval-valued intuitionistic neutrosophic fuzzy number. We define some score and accuracy functions of LIVINFNs are defined with a brief study of related properties. Moreover, we propose the geometric forms of LIVINDFWG, LIVINDFOWG, and LIVINDFHWG operator, which is called the geometric operators. Then, we present its characteristics and some special cases. Moreover, we put forward two new MADM approaches founded on the developed LIVINDFWG and LIVINDFOWG operators. Finally, a representative example is provided to verify the effectiveness and superiority of the proposed method by comparing it with other several existing representative MAGDM methods.},
  archive      = {J_SOCO},
  author       = {Fahmi, Aliya and Amin, Fazli and Niaz, Sidra},
  doi          = {10.1007/s00500-020-05282-z},
  journal      = {Soft Computing},
  number       = {21},
  pages        = {15907-15925},
  shortjournal = {Soft Comput.},
  title        = {Decision making based on linguistic interval-valued intuitionistic neutrosophic dombi fuzzy hybrid weighted geometric operator},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A reformative teaching–learning-based optimization algorithm
for solving numerical and engineering design optimization problems.
<em>SOCO</em>, <em>24</em>(20), 15889–15906. (<a
href="https://doi.org/10.1007/s00500-020-04918-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Teaching–learning-based optimization (TLBO) algorithm, which simulates the process of teaching–learning in the classroom, has been studied by many researchers, and a number of experiments have shown that it has great performance in solving optimization problems. However, it has an inherent origin bias in teacher phase and may fall into local optima for solving complex high-dimensional optimization problems. Therefore, an improved teaching method is proposed to eliminate the bias of converging toward the origin and enhance the ability of exploration during the convergence process. And a self-learning phase is presented to maintain the ability of exploration after convergence. Besides, a mutation phase is introduced to provide a good mixing ability among the population, preventing premature convergence. As a result, a reformative TLBO (RTLBO) algorithm with three modifications, an improved teaching method, a self-learning phase and a mutation phase, is proposed to significantly improve the performance of the TLBO algorithm. Ten unconstrained benchmark functions and three constrained engineering design problems are employed to evaluate the performance of the RTLBO algorithm. The results of the experiments show that the RTLBO algorithm is of excellent performance and better than, or at least comparable to, other available optimization algorithms in literature.},
  archive      = {J_SOCO},
  author       = {Li, Zhuang and Zhang, Xiaotong and Qin, Jingyan and He, Jie},
  doi          = {10.1007/s00500-020-04918-4},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15889-15906},
  shortjournal = {Soft Comput.},
  title        = {A reformative teaching–learning-based optimization algorithm for solving numerical and engineering design optimization problems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A bi-objective function optimization approach for multiple
sequence alignment using genetic algorithm. <em>SOCO</em>,
<em>24</em>(20), 15871–15888. (<a
href="https://doi.org/10.1007/s00500-020-04917-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple sequence alignment (MSA) is characterized as a very high computational complex problem. Therefore, MSA problem cannot be solved by exhaustive methods. Nowadays, MSA is being solved by optimizing more than one objective simultaneously. In this paper, we propose a new genetic algorithm based alignment technique, named bi-objective sequence alignment using genetic algorithm (BSAGA). The novelty of this approach is its selection process. One part of the population is selected based on the Sum of Pair, and rest is selected based on Total Conserve Columns. We applied integer-based chromosomal coding to represent only the gap positions in an alignment. Such representation improves the search technique to reach an optimum even for longer sequences. We tested and compared the alignment score of BSAGA with other relevant alignment techniques on BAliBASE and SABmark. The BSAGA shows better performance than others do, which was further proved by the Wilcoxon sign test.},
  archive      = {J_SOCO},
  author       = {Chowdhury, Biswanath and Garai, Gautam},
  doi          = {10.1007/s00500-020-04917-5},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15871-15888},
  shortjournal = {Soft Comput.},
  title        = {A bi-objective function optimization approach for multiple sequence alignment using genetic algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Industrial time series forecasting based on improved
gaussian process regression. <em>SOCO</em>, <em>24</em>(20),
15853–15869. (<a
href="https://doi.org/10.1007/s00500-020-04916-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial processes often include shifting operating phases and dynamics, and system uncertainty. Industrial time series data may obey different distributions because of the time-varying characteristic. Therefore, a single global model cannot describe the local characteristics of multiple distributions. In this work, a hybrid GMM-IGPR model is proposed to solve this kind of time series prediction problem by using an improved Gaussian process regression (GPR) based on Gaussian mixture model (GMM) and a variant of the basic particles swarm optimization (PSO). In a first treatment to the time series, different distributions of the original dataset are characterized by adopting the GMM as a cluster method. Then, multiple localized GPR models are built to characterize the different properties between inputs and output within various clusters. In order to optimize the proposed algorithms, this paper utilizes the DEPSO which introduces differential evolution (DE) operator into the basic PSO algorithm to estimate hyperparameters of the GPR model, instead of using the traditional conjugate gradient (CG) method. Lastly, the Bayesian inference strategy is used to estimate the posterior probabilities of the test data with respect to different clusters. The various localized GPR models are integrated through these posterior probabilities as the weightings so that a global predictive model is developed for the final prediction. The effectiveness of the proposed algorithm is verified by means of a numerical example and a real industrial winding process. Statistical tests of experimental results compared with other popular prediction models demonstrate the good performance of the proposed model.},
  archive      = {J_SOCO},
  author       = {Liu, Tianhong and Wei, Haikun and Liu, Sixing and Zhang, Kanjian},
  doi          = {10.1007/s00500-020-04916-6},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15853-15869},
  shortjournal = {Soft Comput.},
  title        = {Industrial time series forecasting based on improved gaussian process regression},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A modified method of generating z-number based on OWA
weights and maximum entropy. <em>SOCO</em>, <em>24</em>(20),
15841–15852. (<a
href="https://doi.org/10.1007/s00500-020-04914-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How to generate Z-number is an important and open issue in the uncertain information processing of Z-number. In Kang et al. (Int J Intell Syst 33(8):1745–1755, 2018), a method of generating Z-number using OWA weight and maximum entropy is investigated. However, the meaning of the method in Kang et al. (2018) is not clear enough according to the definition of Z-number. Inspired by the methodology in Kang et al. (2018), we modify the method of determining Z-number based on OWA weights and maximum entropy, which is more clear about the meaning of Z-number. In addition, the model of generating Z-number under the environment of group decision making is well investigated based the modified model. Some numerical examples are used to illustrate the effectiveness of the proposed methodology.},
  archive      = {J_SOCO},
  author       = {Tian, Ye and Kang, Bingyi},
  doi          = {10.1007/s00500-020-04914-8},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15841-15852},
  shortjournal = {Soft Comput.},
  title        = {A modified method of generating Z-number based on OWA weights and maximum entropy},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Frequency domain CNN and dissipated energy approach for
damage detection in building structures. <em>SOCO</em>, <em>24</em>(20),
15821–15840. (<a
href="https://doi.org/10.1007/s00500-020-04912-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent developments tools and techniques for structural health monitoring allow the design of early warning systems for the damage diagnosis and structural assessment. Most methods to damage detection involve vibration data analysis by using identification systems that generally require a mathematical model and much information about the system, such as parameters and states that are mostly unknown. In this paper, a novel frequency domain convolutional neural network (FDCNN) proposed aims to design an identification system for damage detection based on Bouc–Wen hysteretic model. FDCNN, unlike other works, only requires acceleration measurements for damage diagnosis that are very sensitive to environmental noise. In contrast to neural network (NN) and time domain convolutional neural network, FDCNN reduces the computational time required for the learning stage and adds robustness against noise in data. The FDCNN includes random filters in the frequency domain to avoid measurement noise using a spectral pooling operation, which is useful when the system bandwidth is unknown. Incorrect filtering can produce unwanted results, as a shifted and attenuation signal relative to the original. Moreover, FDCNN allows overcoming the parameterization problem in nonlinear systems, which is often difficult to achieve. In order to validate the proposed methodology, a comparison between two different architectures of convolutional neural networks is made, showing that proposed CNN in frequency domain brings better performance in the identification system for damage diagnosis in building structures. Experimental results from reducing scale two-storey building confirm the effectiveness of the proposed.},
  archive      = {J_SOCO},
  author       = {Lopez-Pacheco, Mario and Morales-Valdez, Jesús and Yu, Wen},
  doi          = {10.1007/s00500-020-04912-w},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15821-15840},
  shortjournal = {Soft Comput.},
  title        = {Frequency domain CNN and dissipated energy approach for damage detection in building structures},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new ensemble feature selection approach based on genetic
algorithm. <em>SOCO</em>, <em>24</em>(20), 15811–15820. (<a
href="https://doi.org/10.1007/s00500-020-04911-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the ensemble feature selection method, if the weight adjustment is performed on each feature subset used, the ensemble effect can be significantly different; therefore, how to find the optimized weight vector is a key and challenging problem. Aiming at this optimization problem, this paper proposes an ensemble feature selection approach based on genetic algorithm (EFS-BGA). After each base feature selector generates a feature subset, the EFS-BGA method obtains the optimized weight of each feature subset through genetic algorithm, which is different from traditional genetic algorithm directly processing single features. We divide the EFS-BGA algorithm into two types. The first is a complete ensemble feature selection method; based on the first, we further propose the selective EFS-BGA model. After that, through mathematical analysis, we theoretically explain why weight adjustment is an optimization problem and how to optimize. Finally, through the comparative experiments on multiple data sets, the advantages of the EFS-BGA algorithm in this paper over the previous ensemble feature selection algorithms are explained in practice.},
  archive      = {J_SOCO},
  author       = {Wang, Hongzhi and He, Chengquan and Li, Zhuping},
  doi          = {10.1007/s00500-020-04911-x},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15811-15820},
  shortjournal = {Soft Comput.},
  title        = {A new ensemble feature selection approach based on genetic algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Implicit mood computing via LSTM and semantic mapping.
<em>SOCO</em>, <em>24</em>(20), 15795–15809. (<a
href="https://doi.org/10.1007/s00500-020-04909-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes an implicit mood computing system. The implicit mood computing task is a part of affective computing. Previous works in affective computing mostly focus on twitters, blogs, movie interviews, and news corpus. These works detect sentiment polarity (positive/negative), emotion types (joy, sadness, anger, etc.), or mood types (boring, tired, happy, etc.) of the text. Different from previous studies, our work focuses on the literature texts and detects the implicit mood of them. The implicit mood is sometimes discussed as the tone or the atmosphere of the text. The implicit mood is an important affective feature in the literature such as poetry, prose, and drama. Our work regards the implicit mood as a semantic phenomenon. We capture the feature of implicit mood via a semantic mapping approach and the long short-term memory neural network. The proposed system is capable of identifying 12 kinds of implicit moods with a promising result.},
  archive      = {J_SOCO},
  author       = {Su, Chang and Li, Junchao and Peng, Ying and Chen, Yijiang},
  doi          = {10.1007/s00500-020-04909-5},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15795-15809},
  shortjournal = {Soft Comput.},
  title        = {Implicit mood computing via LSTM and semantic mapping},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An intelligent heuristic-clustering algorithm to determine
the most probable reservoir model from pressure–time series in
underground reservoirs. <em>SOCO</em>, <em>24</em>(20), 15773–15794. (<a
href="https://doi.org/10.1007/s00500-020-04908-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precise characterization of underground reservoirs requires accurate calculations of the reservoir’s petrophysical data and accurate selection of the mathematical model governing the reservoir’s dynamic. In this study, we develop a novel heuristic-clustering algorithm, namely GA–DBSCAN–KMEANS, that can be applied over pressure transient data to assess the true reservoir model out of a pool of candidates. In this algorithm, each specific reservoir model is considered a subpopulation in the GA (genetic algorithm). Then, the simultaneous optimization of all the reservoir models is sought using the proposed hybrid algorithm. During the optimization process, the population size of different models will be either decreased, increased, or unchanged based on the average quality match obtained for each model. A combined DBSCAN (density-based spatial clustering of applications with noise)–KMEANS clustering scheme is used to increase the population size for the best reservoir model in each iteration of the GA. The accuracy of the proposed algorithm was verified using several synthetic data and a real field case obtained from the open literature. The tested data were collected from different types of reservoir models, including homogeneous reservoirs, matrix-fracture dual-porosity reservoirs, and fault-limited reservoirs. For uncertainty analyses and to test the performance of the algorithm under large numbers of initializations, Monte Carlo simulations were conducted. Results of the Monte Carlo simulations unveiled high values of P10, P50, and P90 for the probability of the true reservoir model and low values of these statistics for the false reservoir models. This shows that the outcome of the proposed algorithm is not affected by the initial randomization of the solution subspaces; hence, the developed algorithm is a reliable tool in determining the most probable reservoir model from transient well testing data.},
  archive      = {J_SOCO},
  author       = {Adibifard, Meisam and Sheidaie, Ali and Sharifi, Mohammad},
  doi          = {10.1007/s00500-020-04908-6},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15773-15794},
  shortjournal = {Soft Comput.},
  title        = {An intelligent heuristic-clustering algorithm to determine the most probable reservoir model from pressure–time series in underground reservoirs},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An ANN-based harmonic mitigation and power injection
technique for solar-fed distributed generation system. <em>SOCO</em>,
<em>24</em>(20), 15763–15772. (<a
href="https://doi.org/10.1007/s00500-020-04907-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, a fifteen-level cascaded H-bridge multilevel inverter with active power filtering capability is suggested to increase the power quality in a single-phase distributed generation (DG) system. Integrating renewable power sources in the distribution line becomes easier with advancements in power electronic converters. At the same time, increase in usage of nonlinear loads leads to electronic pollutions like harmonics and power factor issues. Since most of the DG systems have interfacing inverters, it can be utilized for power quality improvement. This proposed work presents a control scheme to gain maximum utilization of these grid interfacing inverters with artificial neural network (ANN). An instantaneous p-q theory in a-ß-0 reference frame-based control algorithm is derived to control the inverter in the single-phase distribution system. In the ANN-based approach, the control algorithm is solved and the ANN is trained based on the switching angles obtained. The trained system is integrated with DG system to operate as a multitasking circuit by adding active power filter (APF) operation. It is proposed to utilize the interfacing inverter as: (1) interfacing inverter to add power produced from renewable sources and (2) APF to mitigate the harmonics. Both functions are accomplished simultaneously. The proposed work is verified with extensive MATLAB/Simulink, and the obtained results demonstrate that the proposed approach delivers a notable improvement in power quality concerning reduction in total harmonic distortion and injection of real power generated through RES into the distribution line. A 3-kWp photovoltaic panel with multifunctioning inverter designed utilizing ANN is executed in an experimental setup to prove the efficiency of the proposed approach.},
  archive      = {J_SOCO},
  author       = {Rajkumar, R. and Ragupathy, U. S.},
  doi          = {10.1007/s00500-020-04907-7},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15763-15772},
  shortjournal = {Soft Comput.},
  title        = {An ANN-based harmonic mitigation and power injection technique for solar-fed distributed generation system},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Predictive analysis of electronic waste for reverse
logistics operations: A comparison of improved univariate grey models.
<em>SOCO</em>, <em>24</em>(20), 15747–15762. (<a
href="https://doi.org/10.1007/s00500-020-04904-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Growing rates of innovation and consumer demand resulted in rapid accumulation of waste of electrical and electronic equipment or electronic waste (e-waste). In order to build and sustain green cities, efficient management of e-waste rises as a viable response to this accumulation. Accurate e-waste predictions that municipalities can utilize to build appropriate reverse logistics infrastructures gain significance as collecting, recycling and disposing the e-waste become more complex and unpredictable. In line with its significance, the related literature presents several methodologies focusing on e-waste generation forecasting. Among these methodologies, grey modeling approach has aroused interest due to its ability to present meaningful results with small-sized or limited data. In order to improve the overall success rate of the approach, several grey modeling-based forecasting techniques have been proposed throughout the past years. The performance of these models, however, profoundly leans on the parameters used with no established consensus regarding the suitable criteria for better accuracy. To address this issue and to provide a guideline for academicians and practitioners, this paper presents a comparative analysis of most utilized grey modeling methods in the literature improved by particle swarm optimization. A case study employing e-waste data from Washington State is provided to demonstrate the comparative analysis proposed in the study.},
  archive      = {J_SOCO},
  author       = {Duman, Gazi Murat and Kongar, Elif and Gupta, Surendra M.},
  doi          = {10.1007/s00500-020-04904-w},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15747-15762},
  shortjournal = {Soft Comput.},
  title        = {Predictive analysis of electronic waste for reverse logistics operations: A comparison of improved univariate grey models},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A hybrid MCDM-based FMEA model for identification of
critical failure modes in manufacturing. <em>SOCO</em>, <em>24</em>(20),
15733–15745. (<a
href="https://doi.org/10.1007/s00500-020-04903-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The effective identification of critical failure modes of individual equipment components or processes and the development of plans for improvement are crucial for the manufacturing industry. Recently, the failure modes and effects analysis (FMEA) approach based on multiple criteria decision making (MCDM) has been utilized effectively for the assessment of primary failure modes and risks. However, the ranking results of failure modes produced by different MCDM methods might be different. This study proposes an integrated risk assessment model where several techniques are combined to produce an FMEA model for the generation of comprehensive failure mode ranking. First, the anticipated costs and environmental protection indicators are included in the FMEA model to enhance the comprehensiveness of assessment. Then, an influential network relationship map of risk factors is obtained by using the decision-making trial and evaluation laboratory (DEMATEL) technique to assist in identifying the critical factors. Finally, the ranking of the failure modes is identified using the four integrated MCDM methods, based on the technique for order preference by similarity to ideal solution (TOPSIS) concept. In addition, data from a machine tool manufacturing company survey are applied to demonstrate the effectiveness and robustness of the proposed model.},
  archive      = {J_SOCO},
  author       = {Lo, Huai-Wei and Shiue, William and Liou, James J. H. and Tzeng, Gwo-Hshiung},
  doi          = {10.1007/s00500-020-04903-x},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15733-15745},
  shortjournal = {Soft Comput.},
  title        = {A hybrid MCDM-based FMEA model for identification of critical failure modes in manufacturing},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust hybrid data-level sampling approach to handle
imbalanced data during classification. <em>SOCO</em>, <em>24</em>(20),
15715–15732. (<a
href="https://doi.org/10.1007/s00500-020-04901-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification process is significant in finding different patterns from data. The performance of classifiers is highly affected with many data impurities like imbalance data, noise, class overlapping and different distributions of data within classes. The data in the real-world applications are often corrupted with multiple data impurities. To handle this issue, this paper proposed a hybrid data-level method to handle multiple data impurities like class imbalance, noise and different data distributions within classes. The proposed approach works in phases; in the first phase, it identifies and removes noise from the data, and then, it detects minority and majority cluster by using kernel-based fuzzy clustering approach. Radial basis kernel is used for clustering. In the next phase, minority and majority clusters are processed to balance the data. It uses radial basis kernel fuzzy membership and $$\alpha $$ -cut to reduce the data size of majority cluster- and firefly-based SMOTE method to intelligently produce synthetic data within minority cluster. After removing all the data impurities, a traditional classifier (Decision Tree) is used to classify the balanced data. Performance of proposed method is tested with 3 synthetic data-sets and 44 UCI real-world data-sets of different imbalance ratios (imbalance ratio varies from 1.82 to 129.44). Area under the ROC curve is used to assess and compare the performance of proposed method with 20 other data-level methods. Experimental results confirmed that proposed method outperformed every other method especially in the case of highly imbalanced data-set.},
  archive      = {J_SOCO},
  author       = {Kaur, Prabhjot and Gosain, Anjana},
  doi          = {10.1007/s00500-020-04901-z},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15715-15732},
  shortjournal = {Soft Comput.},
  title        = {Robust hybrid data-level sampling approach to handle imbalanced data during classification},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Pragmatic approach for prioritization of flood and
sedimentation hazard potential of watersheds. <em>SOCO</em>,
<em>24</em>(20), 15701–15714. (<a
href="https://doi.org/10.1007/s00500-020-04899-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flood is one of the natural disasters that generates a lot of damages every year in different points of the world. Also, soil erosion is among the processes that threats the soil and water resources of the country. The performance of a small watershed is not same as the hydrologic response of a large watershed. Determining the amount of participation and prioritizing the sub-basins in terms of flood generation in the outlet of the basin can be a large help in correct locating the flood control and soil and water conservation projects and leads to decreasing the negative impacts of the flood control operations at unnecessary regions or at the regions with lower priority and also it prevents personal tastes. Therefore, determining the flood generator regions and prioritizing the sub-basins in terms of flooding and sedimentation potential is essential for better management of the watersheds. For this purpose, the aim of this research is to determine the amount of participation of the eastern sub-basins of the Gorganrud River Basin of Golestan province, Iran in flooding and sedimentation and their prioritization in terms of flooding and sedimentation potential using the multi-criteria decision-making methods. In this present study, we used area estimation indices, gravel coefficient, drainage density, basin average slope, basin average height, curve number, cover percentage, sediment yield, sediment delivery ratio, runoff height and concentration time. Indicators are considered to be important indicators affecting water permeability, runoff production and, consequently, the potential for flooding and sedimentation. Following the formation of decision matrix with 13 options (sub-basins) and 11 criteria (evaluation index), Technique For order Preference by Similarity to ideal Solution (TOPSIS), Simple Additive Weighting (SAW), Elimination Et Choice Translation Reality (ELECTRE) and Vise Kriterijumska Optimizacija Kompromisno Resenje (VIKOR) techniques were used to prioritize sub-basins. Borda and Copland methods were used to combine the rank of proposed techniques. Also, in order to validate the models, we estimated the percentage change and the intensity of the changes. The results showed that the highest runoff height index (0.179) and the average height index of the basin had the lowest weight (0.031), according to experts. Considering the results of the combined ranking of the proposed techniques, sub-basins 12, 1 and 2 are in first to third priority, respectively, and have a more critical situation than the rest of the sub-basins. Field studies clearly show the results of the research, because sub-basins 12 and 1 exhibit the highest erosion, poor soil and gradient. Also, zones with flood and sedimentation potential in the area showed that 49/31\% of the area in high and very high risk. This study proves that multi-criteria decision-making methods and RS and GIS techniques are very suitable, precise, economically and temporally advantageous, and helpful tools to evaluate and prioritize the sub-basins in the soil erosion and soil and water conservation topics. Therefore, considering the multiple objective functions and the costly watershed management operations, it can be said that multi-criteria decision-making methods can be used for better management of watersheds in terms of biological and structural flood control operations. So, prioritization can be done based on a mathematical logic. The proposed method in this research is very suitable for watersheds without sufficient data. Hence, such researches which are low cost as well as quick can be used and watersheds can be prioritized for management and conservative acts.},
  archive      = {J_SOCO},
  author       = {Ghaleno, Mohammad Reza Dahmardeh and Meshram, Sarita Gajbhiye and Alvandi, Ehsan},
  doi          = {10.1007/s00500-020-04899-4},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15701-15714},
  shortjournal = {Soft Comput.},
  title        = {Pragmatic approach for prioritization of flood and sedimentation hazard potential of watersheds},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A strategy of PI + repetitive control for LCL-type
photovoltaic inverters. <em>SOCO</em>, <em>24</em>(20), 15693–15699. (<a
href="https://doi.org/10.1007/s00500-020-04898-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the traditional grid-connected current control method of single Proportional Integral (PI) and Repetitive Control (RC) strategies, the photovoltaic inverter output current will have a distortion problem, which can not only maintain the stability of the whole photovoltaic system, but also the current quality of the photovoltaic inverter grid-connected system is reduced in the case of high-order LCL photovoltaic inverter control system operation. So, a strategy of PI + repetitive control in two-phase stationary frame is proposed. The introduction of the weighting coefficient m of the PI controller branch can enhance the adjustment ability of the PI link and accelerate the responding speed to meet the dynamic characteristics of the entire operating system, while the other weighting coefficient n on the repetitive controller branch can increase the correction capability and eliminate the steady-state error to meet system steady-state requirements. The scheme not only simplifies the coordinate transformation and decoupling calculation process, but also improves the harmonics suppression ability of the photovoltaic inverter and reduces the total harmonic distortion rate of the grid-connected current. At the same time, with the load operation mode change, the system can also retain better stability and keep a fast dynamic response capability, and the grid current can be able to return to a stable state in one cycle. Finally, the effectiveness of theoretical analysis and the strategy is verified by simulation.},
  archive      = {J_SOCO},
  author       = {Li, Shengqing and Chen, Wen and Fang, Baling and Zhang, Donghui},
  doi          = {10.1007/s00500-020-04898-5},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15693-15699},
  shortjournal = {Soft Comput.},
  title        = {A strategy of PI + repetitive control for LCL-type photovoltaic inverters},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modeling and mechanism analysis of inertia and damping
issues for wind turbines PMSG grid-connected system. <em>SOCO</em>,
<em>24</em>(20), 15681–15691. (<a
href="https://doi.org/10.1007/s00500-020-04897-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the problem of global climate change and energy crisis, wind power has become the focus of energy sustainable development in all countries. The wind turbines (WTs) power system is connected to the grid via the power electronic converter, causing the system inertia level to drop. In this paper, the direct-drive WT system is considered as the research object, and the whole-system frequency response model is established. The inertia and damping characteristics of the WT converter systems with virtual inertia control are analyzed. With the support of fan rotor kinetic energy and the energy saved in a capacitor, the simple control can also make the system exhibit different degrees of inertia and damping features. The results show that the equivalent inertia and the WT inertia time constant, capacitance parameters and virtual control parameters kd are related; the equivalent damping parameter is related to the steady-state operating point parameters and the virtual control parameter kp; the equivalent synchronization parameter is related to the steady-state operating point parameters and the virtual inertia control parameter ki. Finally, the correctness of the inertial and damping characteristics of the WT grid-connected system is verified by simulation, which provides a theoretical reference for studying the inertial damping of power electronic dominant systems.},
  archive      = {J_SOCO},
  author       = {Li, Shengqing and Donghui, Zhang and Lan, Zheng and Chen, Wen},
  doi          = {10.1007/s00500-020-04897-6},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15681-15691},
  shortjournal = {Soft Comput.},
  title        = {Modeling and mechanism analysis of inertia and damping issues for wind turbines PMSG grid-connected system},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient routing in UASN during the thermohaline
environment condition to improve the propagation delay and throughput.
<em>SOCO</em>, <em>24</em>(20), 15671–15680. (<a
href="https://doi.org/10.1007/s00500-020-04895-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In underwater acoustic sensor network (UASN), the challenging issues are bandwidth, higher propagation delay and heavy packet loss during data transmission. The issues can be solved through efficient routing algorithms. The existing UASN routing algorithms have larger latency in the network link and high rate of packet loss because of the salinity and temperature in the water at different depths. The salinity and temperature changes according to the depth and called as thermohaline circulation. In this paper, convex directional flooding optimisation (CDFO) algorithm improves the latency, throughput and lifetime of the nodes in the network under thermohaline condition and longshore drift from longshore current, which consist of transportation of sediments. The CDFO combines the convex optimisation and directional flooding-based routing algorithm, convex optimisation helps in identification of the hidden nodes in the network and strong communication links are established through polynomial time and semantic analysis and directional flooding algorithm reduces the packet loss and increases the network throughput. The routing protocol has implemented in ns2-AquaSim simulator and test bed for measurement of the performance metrics of the UASN.},
  archive      = {J_SOCO},
  author       = {Hemavathy, N. and Indumathi, P. and Shanker, N. R.},
  doi          = {10.1007/s00500-020-04895-8},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15671-15680},
  shortjournal = {Soft Comput.},
  title        = {Efficient routing in UASN during the thermohaline environment condition to improve the propagation delay and throughput},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Applying the fuzzy CESTAC method to find the optimal shape
parameter in solving fuzzy differential equations via RBF-meshless
methods. <em>SOCO</em>, <em>24</em>(20), 15655–15670. (<a
href="https://doi.org/10.1007/s00500-020-04890-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, by using the CESTAC method and the CADNA library a procedure is proposed to solve a fuzzy initial value problem based on RBF-meshless methods under generalized H-differentiability. So a reliable approach is presented to determine optimal shape parameter and number of points for RBF-meshless methods. The results reveal that the proposed method is very effective and simple. Also, the numerical accuracy of the method is shown in the tables and figures, and algorithms are given based on the stochastic arithmetic. The examples illustrate the efficiency and importance of using the stochastic arithmetic in place of the floating-point arithmetic.},
  archive      = {J_SOCO},
  author       = {Barzegar Kelishami, Hasan and Fariborzi Araghi, Mohammad Ali and Amirfakhrian, Majid},
  doi          = {10.1007/s00500-020-04890-z},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15655-15670},
  shortjournal = {Soft Comput.},
  title        = {Applying the fuzzy CESTAC method to find the optimal shape parameter in solving fuzzy differential equations via RBF-meshless methods},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). JMD method for transforming an unbalanced fully
intuitionistic fuzzy transportation problem into a balanced fully
intuitionistic fuzzy transportation problem. <em>SOCO</em>,
<em>24</em>(20), 15639–15654. (<a
href="https://doi.org/10.1007/s00500-020-04889-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mahmoodirad et al. (Soft Comput, 2018. https://doi.org/10.1007/s00500-018-3115-z ) proposed an approach for solving fully intuitionistic fuzzy transportation problems (FIFTPs) (transportation problems in which each parameter is represented as a triangular intuitionistic fuzzy number). In this approach, firstly, an unbalanced fully intuitionistic fuzzy transportation problem (FIFTP) is transformed into a balanced FIFTP, and then the intuitionistic fuzzy (IF) optimal solution of the transformed balanced FIFTP is obtained. In this paper, it is shown that Mahmoodirad et al.’s approach fails to transform an unbalanced FIFTP and hence, Mahmoodirad et al.’s approach fails to find the IF optimal solution of unbalanced FIFTPs. It is obvious that to overcome this limitation of Mahmoodirad et al.’s approach, there is need to propose a method to transform an unbalanced FIFTP into a balanced FIFTP. Therefore, in this paper, a new method (named as JMD method) is proposed to transform an unbalanced FIFTP into a balanced FIFTP.},
  archive      = {J_SOCO},
  author       = {Mishra, Akansha and Kumar, Amit},
  doi          = {10.1007/s00500-020-04889-6},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15639-15654},
  shortjournal = {Soft Comput.},
  title        = {JMD method for transforming an unbalanced fully intuitionistic fuzzy transportation problem into a balanced fully intuitionistic fuzzy transportation problem},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Application and research for electricity price forecasting
system based on multi-objective optimization and sub-models selection
strategy. <em>SOCO</em>, <em>24</em>(20), 15611–15637. (<a
href="https://doi.org/10.1007/s00500-020-04888-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In general, electricity prices reflect the cost to build, finance, maintain, and operate power plants and the electricity grid. Therefore, the cost-optimized scheduling of industrial loads with accurate price forecasts is very important. As such, recent studies have attempted to combine models to forecast electricity prices more accurately. Earlier combined models have tended to ignore the selection of sub-models and data analyses, leading to poor forecasting performance. In order to select the best forecasting models in a combined model, we propose a hybrid electricity price forecasting system that includes a data analysis module, a sub-model selection strategy module, optimized forecasting processing, and a model evaluation module. As such, the hybrid system fully exploits the advantages of a single model, thus improving the forecasting performance of the combined model. The experimental results show that the proposed system selects optimal sub-models effectively and successfully identifies future trend changes in the electricity price. Thus, the system can be an effective tool in the planning and implementation of smart grids.},
  archive      = {J_SOCO},
  author       = {Fu, Tonglin and Zhang, Shenghui and Wang, Chen},
  doi          = {10.1007/s00500-020-04888-7},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15611-15637},
  shortjournal = {Soft Comput.},
  title        = {Application and research for electricity price forecasting system based on multi-objective optimization and sub-models selection strategy},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improving self-training with density peaks of data and cut
edge weight statistic. <em>SOCO</em>, <em>24</em>(20), 15595–15610. (<a
href="https://doi.org/10.1007/s00500-020-04887-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised classification has become an active topic recently, and a number of algorithms, such as self-training, have been proposed to improve the performance of supervised classification using unlabeled data. Considering the influence of spatial distribution of data set and mislabeled samples on the classification performance of self-training method, an improved self-training algorithm based on density peaks and cut edge weight statistic is proposed in this paper. Firstly, the representative unlabeled samples are selected for labels prediction by space structure, which is discovered by clustering method based on density peaks. Secondly, cut edge weight is used as statistics to make hypothesis testing for identifying whether samples are labeled correctly. Thirdly, the labeled data set is gradually enlarged with correctly labeled samples. The above steps are iterated until all unlabeled samples are labeled. The framework of improved self-training method not only makes full use of space structure information, but also solves the problem that some samples may be classified incorrectly. Thus, the classification accuracy of algorithm is improved in a great measure. Extensive experiments on benchmark data sets clearly illustrate the effectiveness of proposed algorithm.},
  archive      = {J_SOCO},
  author       = {Wei, Danni and Yang, Youlong and Qiu, Haiquan},
  doi          = {10.1007/s00500-020-04887-8},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15595-15610},
  shortjournal = {Soft Comput.},
  title        = {Improving self-training with density peaks of data and cut edge weight statistic},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A consensus-based approach for multi-criteria decision
making with probabilistic hesitant fuzzy information. <em>SOCO</em>,
<em>24</em>(20), 15577–15594. (<a
href="https://doi.org/10.1007/s00500-020-04886-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a generalized fuzzy number, probabilistic hesitant fuzzy element (PHFE) improves the flexibility for decision makers in expressing hesitant information, and it has been receiving increased attention. This study develops a multi-criteria decision-making (MCDM) approach that considers consensus reaching among decision makers with probabilistic hesitant fuzzy information. To obtain this aim, first, a new approach to derive normalized PHFE (NPHFE) is proposed to overcome the shortcomings in previous studies. Subsequently, a new Euclidean distance and some operations related to PHFEs are developed based on the new proposed NPHFEs. At the same time, the effectiveness and rationality of the new proposed approaches are discussed. Second, a consensus index of group with PHFEs is presented, which based on the proposed Euclidean distance of decision-makers’ evaluation information on all the criteria. Third, if the consensus level of the group does not reach the expect threshold value, an iteration algorithm is designed to improve its consensus level. Moreover, the proof of the convergence of the proposed algorithm is provided to verify its effectiveness, and a MCDM approach based on group consensus is proposed. Finally, the most comprehensive candidate selection problems are provided to demonstrate the effectiveness of the proposed MCDM approach. And a comparative study with other methods is conducted with the same illustrative example.},
  archive      = {J_SOCO},
  author       = {Li, Jian and Niu, Li-li and Chen, Qiongxia and Wu, Guang},
  doi          = {10.1007/s00500-020-04886-9},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15577-15594},
  shortjournal = {Soft Comput.},
  title        = {A consensus-based approach for multi-criteria decision making with probabilistic hesitant fuzzy information},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel QIM-DCT based fusion approach for classification of
remote sensing images via PSO and SVM models. <em>SOCO</em>,
<em>24</em>(20), 15561–15576. (<a
href="https://doi.org/10.1007/s00500-020-04884-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fusion of panchromatic and multispectral images has become a research interest for the classification of remote sensing images. The spectral and spatial resolutions of different images give better information with the aid of image classification. However, fusing pixels for various satellite images is difficult due to the nature of original image consists of complex information. Similarly, most of the existing fusion algorithms implement a unified processing over the whole part of the image, thereby leaving certain important needs out of consideration. The main aim of our proposed approach is to fuse the images by gathering all important information from multiple images with minimum errors. In this paper, we propose a novel quantization index modulation with discrete contourlet transform-based fusion approach for classification of remote sensing images (LISS IV sensor). In order to improve the image fusion performance, we eliminate certain noises (salt, pepper, and Gaussian) using Bayesian filter with Adaptive Type-2 Fuzzy System. After image fusion, we make image classification by two steps of processes including deep multi-feature extraction and feature selection. Multiple features such as spectral, shape, global and local features are extracted using Affine Transformation (0°, 90°, 180°, and 270°), and then the best set of features are chosen by mutual information and maximal information coefficients. Finally, the image is classified into seven classes using PSO and SVM namely Urban, Vegetation, Wetland, Tank, Water Area, Bare Land, and Roadways. MATLAB R2017b has been used for evaluation of the LISS IV images. Experimental results revealed that our proposed approach is very effective in terms of their classification accuracy.},
  archive      = {J_SOCO},
  author       = {Uma Maheswari, K. and Rajesh, S.},
  doi          = {10.1007/s00500-020-04884-x},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15561-15576},
  shortjournal = {Soft Comput.},
  title        = {A novel QIM-DCT based fusion approach for classification of remote sensing images via PSO and SVM models},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A metaheuristic optimization model for spectral allocation
in cognitive networks based on ant colony algorithm (m-ACO).
<em>SOCO</em>, <em>24</em>(20), 15551–15560. (<a
href="https://doi.org/10.1007/s00500-020-04882-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cognitive radio networks have been gaining widespread attraction among researchers especially with the increasing demand for radio frequency spectrum whose availability is quite scarce. Cognitive radio networks provide an ideal solution to allocate spectrum to users on an intelligent basis through a series of spectrum sensing and decision making. A metaheuristic soft computing framework is proposed and implemented in this research work by using powerful optimization concepts of evolutionary algorithm, namely ant colony algorithm, coupled with graph-cut modeling of given wireless network to provide the expected precision of detection. Channel characteristics have been taken as the feature vectors which are modeled as n-tuple graph to decide upon the maximization of channel allocation probability based on availability in an opportunistic basis. Exhaustive experimentations have been conducted and optimal performance justified against other benchmark algorithms.},
  archive      = {J_SOCO},
  author       = {Padmanaban, B. and Sathiyamoorthy, S.},
  doi          = {10.1007/s00500-020-04882-z},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15551-15560},
  shortjournal = {Soft Comput.},
  title        = {A metaheuristic optimization model for spectral allocation in cognitive networks based on ant colony algorithm (M-ACO)},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new hybridization of DBSCAN and fuzzy earthworm
optimization algorithm for data cube clustering. <em>SOCO</em>,
<em>24</em>(20), 15529–15549. (<a
href="https://doi.org/10.1007/s00500-020-04881-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data aggregation from different databases into a data warehouse creates multidimensional data such as data cubes. With regard to the 3D structure of data, data cube clustering has significant challenges to perform on data cube. In this paper, new preprocessing techniques and a novel hybridization of DBSCAN and fuzzy earthworm optimization algorithm (EWOA) are proposed to solve the challenges. Proposed preprocessing consists of an assigned address to each cube cell and dimension move to create a related 2D data from the data cube and new similarity metric. The DBSCAN algorithm, as a density-based clustering algorithm, is adopted based on both Euclidean and newly proposed similarity metric, which are called DBSCAN1 and DBSCAN2 for the related 2D data. A new hybridization of the EWOA and DBSCAN is proposed to improve the DBSCAN, and it is called EWOA–DBSCAN. Also, to dynamically tune parameters of EWOA, a fuzzy logic controller is designed with two fuzzy group rules of Mamdani (EWOA–DBSCAN-Mamdani) and Sugeno (EWOA–DBSCAN-Sugeno), separately. These ideas are proposed to present efficient and flexible unsupervised analysis for a data cube by utilizing a meta-heuristic algorithm to optimize DBSCAN’s parameters and increasing the efficiency of the idea by applying dynamic tuning parameters of the algorithm. To evaluate the efficiency, the proposed algorithms are compared with DBSCAN1 and GA-DBSCAN1, GA-DBSCAN1-Mamdani and GA-DBSCAN1-Sugeno. The experimental results, consisting of 20 runs, indicate that the proposed ideas achieved their targets.},
  archive      = {J_SOCO},
  author       = {Hosseini Rad, Mina and Abdolrazzagh-Nezhad, Majid},
  doi          = {10.1007/s00500-020-04881-0},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15529-15549},
  shortjournal = {Soft Comput.},
  title        = {A new hybridization of DBSCAN and fuzzy earthworm optimization algorithm for data cube clustering},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Ranking-based triplet loss function with intra-class mean
and variance for fine-grained classification tasks. <em>SOCO</em>,
<em>24</em>(20), 15519–15528. (<a
href="https://doi.org/10.1007/s00500-020-04880-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposed a deep ranking model for triplet selection to efficiently learn similarity metric from top ranked images. A modified distance criterion described in the current work leverages the intra-category variance in metric learning of a triplet network by learning a local sample structure. A multicolumn fusion architecture is used to capture different levels of variance, which when incorporated in the loss function strengthens it and optimizes the objective of the triplet networks. This enables a fine-grained classification strategy. State-of-the-art techniques use a group-sensitive triplet sampling to deal with this issue. However, these have the disadvantage of increased group sampling computations. Experiments are conducted over a variety of benchmark datasets including Model40, PatternNet, and In-Shop Clothing. The main purpose of these experiments are to verify whether the triplet learning technique can be applied over different kinds of data. Results demonstrate that the current work provides superior results in most cases. These results can further be improved with specific parameter tunings and ensembling techniques wherever applicable.},
  archive      = {J_SOCO},
  author       = {Bhattacharya, J. and Sharma, R. K.},
  doi          = {10.1007/s00500-020-04880-1},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15519-15528},
  shortjournal = {Soft Comput.},
  title        = {Ranking-based triplet loss function with intra-class mean and variance for fine-grained classification tasks},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Kernel intuitionistic fuzzy c-means and state transition
algorithm for clustering problem. <em>SOCO</em>, <em>24</em>(20),
15507–15518. (<a
href="https://doi.org/10.1007/s00500-020-04879-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering problems widely exist in machine learning, pattern recognition, image analysis and information sciences, etc. Although many clustering algorithms have been proposed, it is unpractical to find a clustering algorithm suitable for all types of datasets. Fuzzy c-means (FCM) is one of the most frequently-used fuzzy clustering algorithm for the reason that it is efficient, straightforward, and easy to implement. However, the traditional FCM taking Euclidean distance as similarity measurement can not distinguish the intersection between two clusters. Therefore, kernel function has been taken as similarity measurement to solve this issue. As a comprehensive partition criterion, intuitionistic fuzzy set which consider both membership degree and non-membership degree has been used to replace traditional fuzzy set to describe the natural attributes of objective phenomena more delicately. Thus, Kernel intuitionistic fuzzy c-means (KIFCM) has been proposed in this paper to settle clustering problem. Considering FCM is easily getting trapped in local optima due to its high sensitivity to initial centroid. State Transition Algorithm (STA) has been adopted in this study to obtain the initial centroid to enhance its stability. The proposed STA-KIFCM compared with some other clustering algorithms are implemented using five benchmark datasets. Experimental results not only show that the proposed method is efficient and can reveal encouraging results, but also indicate that the proposed method can achieve high accuracy.},
  archive      = {J_SOCO},
  author       = {Zhou, Xiaojun and Zhang, Rundong and Wang, Xiangyue and Huang, Tingwen and Yang, Chunhua},
  doi          = {10.1007/s00500-020-04879-8},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15507-15518},
  shortjournal = {Soft Comput.},
  title        = {Kernel intuitionistic fuzzy c-means and state transition algorithm for clustering problem},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A fuzzy variational model for segmentation of images having
intensity inhomogeneity and slight texture. <em>SOCO</em>,
<em>24</em>(20), 15491–15506. (<a
href="https://doi.org/10.1007/s00500-020-04878-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Segmentation of real images having unwanted outliers, inhomogeneity or complex background is always very challenging for active contour models. In this paper, we propose a novel model for segmentation of such type of images. The proposed model is based on fuzzy energy functional, which uses coefficient of variation as a region statistics. The proposed model is convex due to introduction of fuzzy membership functions in the energy functional and hence converges to the absolute minima and avoids local minima. Convexity of the proposed model is proved, and hence, the model is independent of initial placement of the contour. Experimental results of the proposed model are compared with other state-of-the-art existing models both qualitatively and quantitatively. For quantitative comparison, we have used Jaccard similarity index and computational complexity. The proposed model is tested on various data sets containing noisy images, images having intensity inhomogeneity and slight texture. In all experimental results, performance of the proposed model can be seen in the experimental section.},
  archive      = {J_SOCO},
  author       = {Ahmad, Ali and Badshah, Noor and Ali, Haider},
  doi          = {10.1007/s00500-020-04878-9},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15491-15506},
  shortjournal = {Soft Comput.},
  title        = {A fuzzy variational model for segmentation of images having intensity inhomogeneity and slight texture},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A hybrid grasshopper and new cat swarm optimization
algorithm for feature selection and optimization of multi-layer
perceptron. <em>SOCO</em>, <em>24</em>(20), 15463–15489. (<a
href="https://doi.org/10.1007/s00500-020-04877-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classification accuracy of a multi-layer perceptron (MLP) depends on the selection of relevant features from the data set, its architecture, connection weights and the transfer functions. Generating an optimal value of all these parameters together is a complex task. Metaheuristic algorithms are popular choice among researchers to solve complex optimization problems. This paper presents a hybrid metaheuristic algorithm simple matching-grasshopper new cat swarm optimization algorithm (SM-GNCSOA) that optimizes all the four components simultaneously. SM-GNCSOA uses grasshopper optimization algorithm, a new variant of binary grasshopper optimization algorithm called simple matching-binary grasshopper optimization algorithm and a new variant of cat swarm optimization algorithm called new cat swarm optimization algorithm to generate an optimal MLP. Features play a vital role in determining the classification accuracy of a classifier. Here, we propose a new feature penalty function and use it in SM-GNCSOA to prevent underfitting or overfitting due to the selected number of features. To evaluate the performance of SM-GNCSOA, different variants of SM-GNCSOA are proposed and their classification accuracies are compared with SM-GNCSOA on ten classification data sets. The results show that SM-GNCSOA gives better results on most of the data sets due to its capability to balance exploration and exploitation and to avoid local minima.},
  archive      = {J_SOCO},
  author       = {Bansal, Priti and Kumar, Sachin and Pasrija, Sagar and Singh, Sachin},
  doi          = {10.1007/s00500-020-04877-w},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15463-15489},
  shortjournal = {Soft Comput.},
  title        = {A hybrid grasshopper and new cat swarm optimization algorithm for feature selection and optimization of multi-layer perceptron},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mobile phone selection based on a novel quality function
deployment approach. <em>SOCO</em>, <em>24</em>(20), 15447–15461. (<a
href="https://doi.org/10.1007/s00500-020-04876-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy quality function deployment (QFD) approach has been extensively implemented to transform customer requirements (CRs) into products or services because fuzzy numbers provide to obtain more accurately the judgments of experts in vagueness environment. This study proposes to use interval type-2 fuzzy (IT2F) numbers in the improving of fuzzy QFD method. The developed IT2F number-based QFD approach utilizes IT2F sets to define the correlations among CRs; the relations between CRs and design requirements (DRs); the correlations among DRs; the weights of DRs. There is no paper about integrating QFD approach and IT2F set in the literature. IT2F numbers include more accurately the judgments of the experts to express the vagueness of the applications. In addition, TOPSIS (technique for order performance by similarity to ideal solution) approach based on interval type-2 trapezoidal fuzzy (IT2TrF) is utilized to select the best mobile phone. Finally, mobile phone selection implementation is handled to indicate the efficiency of the proposed method.},
  archive      = {J_SOCO},
  author       = {Efe, Burak and Yerlikaya, Mehmet Akif and Efe, Ömer Faruk},
  doi          = {10.1007/s00500-020-04876-x},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15447-15461},
  shortjournal = {Soft Comput.},
  title        = {Mobile phone selection based on a novel quality function deployment approach},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient column-oriented processing for mutual subspace
skyline queries. <em>SOCO</em>, <em>24</em>(20), 15427–15445. (<a
href="https://doi.org/10.1007/s00500-020-04875-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A mutual skyline query will enable some new applications, such as marketing analysis, task allocation, and personalized matching. Algorithms for efficient processing of this query have been recently proposed in the literature. Those approaches use the R-tree indexes and apply a series of pruning criteria toward efficient processing. However, they are characterized by several limitations: (1) they cannot process different interests on attributes for skyline and reverse skyline, (2) they require a multidimensional index, which suffers from performance degradation, especially in high-dimensional space, and (3) they do not support vertically decomposed data that is a natural and intuitive choice for the parallel queries. To this end, we address aforementioned these problems and propose three efficient algorithms, i.e., index-based mutual subspace skyline, optimized index-based MSS, and parallel mutual subspace skyline, using the column-oriented processing that is more suitable for subspace and parallel skyline. Extensive experimental results show that our proposed algorithms are effective and efficient.},
  archive      = {J_SOCO},
  author       = {Jiang, Tao and Zhang, Bin and Lin, Dan and Gao, Yunjun and LI, Qing},
  doi          = {10.1007/s00500-020-04875-y},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15427-15445},
  shortjournal = {Soft Comput.},
  title        = {Efficient column-oriented processing for mutual subspace skyline queries},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). An immune-based response particle swarm optimizer for
knapsack problems in dynamic environments. <em>SOCO</em>,
<em>24</em>(20), 15409–15425. (<a
href="https://doi.org/10.1007/s00500-020-04874-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel binary particle swarm optimization algorithm (called IRBPSO) to address high-dimensional knapsack problems in dynamic environments (DKPs). The IRBPSO integrates an immune-based response strategy into the basic binary particle swarm optimization algorithm for improving the quantity of evolutional particles in high-dimensional decision space. In order to enhance the convergence speed of the IRBPSO in the current environment, the particles with high fitness values are cloned and mutated. In addition, an external archive is designed to store the elite from the current generation. To maintain the diversity of elites in the external archive, the elite of current generation will replace the worst one in the external archive if and only if it differs from any of the existing particles in the external archive based on the Hamming distance measurement when the archive is due to update. In this way, the external archive can store diversiform elites for previous environments as much as possible, and so as to the stored elites are utilized to transfer historical information to new environment for assisting to solve the new optimization problem. Moreover, the environmental reaction scheme is also investigated in order to improve the ability of adapting to different kinds of dynamic environments. Experimental results on a series of DKPs with different randomly generated data sets indicate that the IRBPSO can faster track the changing environments and manifest superior statistical performance, when compared with peer optimization algorithms.},
  archive      = {J_SOCO},
  author       = {Wu, Huihong and Qian, Shuqu and Liu, Yanmin and Wang, Dong and Guo, Benhua},
  doi          = {10.1007/s00500-020-04874-z},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15409-15425},
  shortjournal = {Soft Comput.},
  title        = {An immune-based response particle swarm optimizer for knapsack problems in dynamic environments},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The probe for the weighted dual probabilistic linguistic
correlation coefficient to invest an artificial intelligence project.
<em>SOCO</em>, <em>24</em>(20), 15389–15408. (<a
href="https://doi.org/10.1007/s00500-020-04873-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of the burgeoning decision-making instruments, the integrity of dual probabilistic linguistic term sets (DPLTSs) is to express the decision information in terms of cognitive certainty and uncertainty. The superiority of correlation coefficient is to demonstrate the interrelationship of the variables. This paper aims to give full play to the advantages of the above two. Firstly, it defines the dual probabilistic linguistic correlation coefficient. Then, it is based on the proposed entropy for DPLTSs calculates the comprehensive weight vector. Moreover, combined with the proposed correlation coefficient, it further defines the weighted correlation coefficient as a measure for the application about artificial intelligence. Besides, it uses the dual probabilistic linguistic closeness coefficient as the reference to compare the pros and cons. Finally, a specific numeric simulation is utilized to demonstrate the feasibility of the two different measures.},
  archive      = {J_SOCO},
  author       = {Xie, Wanying and Xu, Zeshui and Ren, Zhiliang and Herrera-Viedma, Enrique},
  doi          = {10.1007/s00500-020-04873-0},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15389-15408},
  shortjournal = {Soft Comput.},
  title        = {The probe for the weighted dual probabilistic linguistic correlation coefficient to invest an artificial intelligence project},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Frugal innovation in supply chain cooperation considering
e-retailer’s platform value. <em>SOCO</em>, <em>24</em>(20),
15373–15387. (<a
href="https://doi.org/10.1007/s00500-020-04872-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {E-retailers have recently paid close attention to frugal innovation in their supply chains. However, there are few studies on frugal innovation considering the e-retailer’s platform value raised by the increase in the platform user scale. Motivated by industrial practice, we consider a supply chain consisting of an e-retailer and a manufacturer in the context of frugal innovation, where the platform value of the retailer is characterized by Metcalfe’s law. We use game models to investigate the frugal product price and optimal degree of frugality decisions for the centralized, decentralized, retailer-led revenue-sharing contract and bargaining revenue-sharing contract scenarios. Our results indicate that the bargaining revenue-sharing contract can improve the frugal degree of the development-intensive frugal product (DIFP), while the frugal degree of the marginal cost-intensive frugal product (MIFP) cannot be improved by cooperation in the supply chain. We then compare the supply chain profit, the platform value of the retailer and the profit of the manufacturer in different scenarios. The results show that the centralized scenario is the optimal scenario where the platform retailer implements vertical integration strategy. Otherwise, establishing strategic partnership through the bargaining revenue-sharing contract is suboptimal for both the platform retailer and the manufacturer.},
  archive      = {J_SOCO},
  author       = {Li, Zhiguo and Zhang, Han and Gao, Rong},
  doi          = {10.1007/s00500-020-04872-1},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15373-15387},
  shortjournal = {Soft Comput.},
  title        = {Frugal innovation in supply chain cooperation considering e-retailer’s platform value},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimization of feedback bits using firefly algorithm for
interference reduction in LTE femtocell networks. <em>SOCO</em>,
<em>24</em>(20), 15361–15371. (<a
href="https://doi.org/10.1007/s00500-020-04871-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Femtocells are the feasible solutions to extend the network coverage of indoor users and to enhance the network capacity in long-term evolution advanced (LTE-A)-based 5G networks. However, the femtocell base station shares the same frequency spectrum of microcell base station in unplanned manner. Hence, interference mitigation is a crucial problem in densely deployed femtocell environment and it is more severe with the deployment of femtocells in LTE-A network. In this paper, a modified dirty paper coding is proposed for interference mitigation along with the optimization of feedback bits using natural inspired meta-heuristic firefly algorithm. The proposed meta-heuristic algorithm reduces the interference by periodically unicasting the channel state information. Since the bandwidth of feedback system is limited, it is optimized in such a way that it does not affect the performance of the system. As compared to the conventional zero-forcing pre-coding, the proposed modified dirty paper coding along with firefly algorithm scheme offers improved sum rate of 70\% and 64\% with increase in the number of feedback bits and number of users, respectively.},
  archive      = {J_SOCO},
  author       = {Hariharan, S. and Chikte, Kartiki and Shankar, T. and Rajesh, A. and Fouziya Sulthana, S.},
  doi          = {10.1007/s00500-020-04871-2},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15361-15371},
  shortjournal = {Soft Comput.},
  title        = {Optimization of feedback bits using firefly algorithm for interference reduction in LTE femtocell networks},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Artificial bee colony optimization-inspired synergetic study
of fractional-order economic production quantity model. <em>SOCO</em>,
<em>24</em>(20), 15341–15359. (<a
href="https://doi.org/10.1007/s00500-020-04867-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inventory control is one of the most widely recognized issues in the reality. This investigation manages the utilization of fractional derivatives and integration on an inventory control problem. The memory of a dynamical model is a highly concerned issue which is commonly neglected by the models described in terms of integer-order differential equation. The memory capturing the power of fractional derivative (in Caputo’s sense) is utilized here to describe an economic production quantity model with deterioration when the demand depends on price and stock and production is stock dependent. Also, this study covers the integer-order model with the same assumptions as a memoryless model and a particular case of the fractional model. Due to the complex nature of the model, numerical optimization with the help of a modified artificial bee colony algorithm is done instead of the analytical approach of optimization. Finally, we have performed a sensitivity analysis in order to make a fruitful conclusion.},
  archive      = {J_SOCO},
  author       = {Rahaman, Mostafijur and Mondal, Sankar Prasad and Shaikh, Ali Akbar and Pramanik, Prasenjit and Roy, Samarjit and Maiti, Manas Kumar and Mondal, Rituparna and De, Debashis},
  doi          = {10.1007/s00500-020-04867-y},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15341-15359},
  shortjournal = {Soft Comput.},
  title        = {Artificial bee colony optimization-inspired synergetic study of fractional-order economic production quantity model},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-label learning for crop leaf diseases recognition and
severity estimation based on convolutional neural networks.
<em>SOCO</em>, <em>24</em>(20), 15327–15340. (<a
href="https://doi.org/10.1007/s00500-020-04866-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crop diseases have always been a dilemma as it can cause significant diminution in both quality and quantity of agricultural yields. Thus, automatic recognition and severity estimation of crop diseases on leaves plays a crucial role in agricultural sector. In this paper, we propose a series of automatic image-based crop leaf diseases recognition and severity estimation networks, i.e., BR-CNNs, which can simultaneously recognize crop species, classify crop diseases and estimate crop diseases severity based on deep learning. BR-CNNs based on binary relevance (BR) multi-label learning algorithm and deep convolutional neural network (CNN) approaches succeed in identifying 7 crop species, 10 crop diseases types (including Healthy) and 3 crop diseases severity kinds (normal, general and serious). Compared with LP-CNNs and MLP-CNNs, the overall performance of BR-CNNs is superior. The BR-CNN based on ResNet50 achieves the best test accuracy of 86.70\%, which demonstrates the feasibility and effectiveness of our network. The BR-CNN based on the light-weight NasNet also achieves excellent test accuracy of 85.28\%, which can provide more possibilities for the development of mobile systems and devices.},
  archive      = {J_SOCO},
  author       = {Ji, Miaomiao and Zhang, Keke and Wu, Qiufeng and Deng, Zhao},
  doi          = {10.1007/s00500-020-04866-z},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15327-15340},
  shortjournal = {Soft Comput.},
  title        = {Multi-label learning for crop leaf diseases recognition and severity estimation based on convolutional neural networks},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Non-convex low-rank representation combined with rank-one
matrix sum for subspace clustering. <em>SOCO</em>, <em>24</em>(20),
15317–15326. (<a
href="https://doi.org/10.1007/s00500-020-04865-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exploring the multiple subspace structures of data such as low-rank representation is effective in subspace clustering. Non-convex low-rank representation (NLRR) via matrix factorization is one of the state-of-the-art techniques for subspace clustering. However, NLRR cannot scale to problems with large n (number of samples) as it requires either the inversion of an $$n\times n$$ matrix or solving an $$n\times n$$ linear system. To address this issue, we propose a novel approach, NLRR++, which reformulates NLRR as a sum of rank-one components, and apply a column-wise block coordinate descent to update each component iteratively. NLRR++ reduces the time complexity per iteration from $${\mathcal {O}}(n^3)$$ to $${\mathcal {O}}(mnd)$$ and the memory complexity from $${\mathcal {O}}(n^2)$$ to $${\mathcal {O}} (mn)$$ , where m is the dimensionality and d is the target rank (usually $$d\ll m\ll n$$ ). Our experimental results on simulations and real datasets have shown the efficiency and effectiveness of NLRR++. We demonstrate that NLRR++ is not only much faster than NLRR, but also scalable to large datasets such as the ImageNet dataset with 120K samples.},
  archive      = {J_SOCO},
  author       = {Liu, Xiaofang and Wang, Jun and Cheng, Dansong and Shi, Daming and Zhang, Yongqiang},
  doi          = {10.1007/s00500-020-04865-0},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15317-15326},
  shortjournal = {Soft Comput.},
  title        = {Non-convex low-rank representation combined with rank-one matrix sum for subspace clustering},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). RETRACTED ARTICLE: Load prediction using (DoG–ALMS) for
resource allocation based on IFP soft computing approach in cloud
computing. <em>SOCO</em>, <em>24</em>(20), 15307–15315. (<a
href="https://doi.org/10.1007/s00500-020-04864-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s world, most of the applications run with the service of cloud computing, which proceeds the process using the internet. In the case of cloud computing, based on customer needs, they may increase or decrease resource utilization. Virtualization is the process of multiplexing the resources from physical machines to virtual machines. However, it is challenging to prevent overloading for each physical machine of an automatic resources management system which affects virtualization to allocate the resources dynamically. To overcome these concerns, a new algorithm is proposed in this work, which can predict the future load precisely in the physical machine and decide which may be overloaded next. Then, the necessary action is taken to prevent overload in the system. In this work, the prediction of loads for allocating future resources is presented, and the dynamic scheduling and resource allocation for the predicted tasks are performed using IFPA. The difference of Gaussian-based adaptive least mean square filter is employed for predicting the loads function points which are used to estimate the complexity and cost rate. Also, a soft computing technique (improved flower pollination algorithm) is employed for the effective resource allocation strategy. The performance of the approach is intended and compared with other conventional works. The results proved that the work has better accuracy in load prediction and provide a way to allocate the resource precisely. At the same time, the traffic at the physical machines is significantly controlled.},
  archive      = {J_SOCO},
  author       = {Reshmi, R. and Saravanan, D. Shanthi},
  doi          = {10.1007/s00500-020-04864-1},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15307-15315},
  shortjournal = {Soft Comput.},
  title        = {RETRACTED ARTICLE: Load prediction using (DoG–ALMS) for resource allocation based on IFP soft computing approach in cloud computing},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Enhancing artificial bee colony algorithm using refraction
principle. <em>SOCO</em>, <em>24</em>(20), 15291–15306. (<a
href="https://doi.org/10.1007/s00500-020-04863-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The artificial bee colony algorithm (ABC), as one of the excellent intelligent optimization technologies, has presented very good optimization performance for many complex problems due to its simplicity and easiness of implementation. However, ABC has a very good performance at exploration relatively, but for some complex problems it still results in slower convergent speed and lower convergent accuracy in the later stage of algorithms. Meanwhile, ABC has relatively poor performance at exploitation. To overcome these drawbacks further, the enhancing ABC algorithm using refraction principle is proposed (EABC-RP) in this paper. In EABC-RP, on the one hand, in order to enhance its exploration further, the unified opposition-based learning (UOBL) based on refraction principle is employed to generate refraction solutions (new food sources) for employed bees, which helps to increase population diversity and guide search direction close to the global optimal solution. On the other hand, for exploitation, when ABC has fallen into the local optimal solution, the UOBL based on refraction principle is employed for mutation to increase the probability of jumping out of the local optimal solution for scout bees. A lot of experiments are conducted on 23 benchmark functions to verify the effectiveness of EABC-RP. The experimental results show that EABC-RP achieves higher solution accuracy and faster convergent speed in most cases and outperforms other ABC variants. In addition, EABC-RP is used to optimize finite impulse response (FIR) low-pass digital filter which obtains the better filtering performance, which validates the effectiveness of the EABC-RP algorithm further.},
  archive      = {J_SOCO},
  author       = {Shao, Peng and Yang, Le and Tan, Liang and Li, Guangquan and Peng, Hu},
  doi          = {10.1007/s00500-020-04863-2},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15291-15306},
  shortjournal = {Soft Comput.},
  title        = {Enhancing artificial bee colony algorithm using refraction principle},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel hybrid model based on recurrent neural networks for
stock market timing. <em>SOCO</em>, <em>24</em>(20), 15273–15290. (<a
href="https://doi.org/10.1007/s00500-020-04862-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stock market timing is regarded as a challenging task of financial prediction. An accurate prediction of stock trend can yield great profits for investors. At present, recurrent neural networks (RNNs) have a good performance in stock market forecasting. However, there has been a relative lack of research in the stock market timing using RNNs. In this paper, a novel model named hybrid RNN model is proposed for stock market timing by incorporating multi-layer long short-term memory, multi-layer gated recurrent unit and one-layer ReLU layer. Moreover, based on five popular benchmark datasets from UCI Machine Learning Repository and six daily securities from Shanghai Stock Exchange, comparisons with 12 state-of-the-art models are conducted to verify the superiority of the proposed hybrid RNN model in terms of nine technical indicators. The findings from the experiment demonstrate that: (1) as opposed to 12 models, the average accuracy, MSE and AUC of hybrid RNN model (0.7406, 0.2592, 0.7368) are significantly better than other comparison models, and (2) the proposed hybrid RNN classification procedure can be considered as a feasible and effective tool for stock market timing.},
  archive      = {J_SOCO},
  author       = {Qiu, Yue and Yang, Hao-Yu and Lu, Shan and Chen, Wei},
  doi          = {10.1007/s00500-020-04862-3},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15273-15290},
  shortjournal = {Soft Comput.},
  title        = {A novel hybrid model based on recurrent neural networks for stock market timing},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An improved particle swarm optimization with clone selection
principle for dynamic economic emission dispatch. <em>SOCO</em>,
<em>24</em>(20), 15249–15271. (<a
href="https://doi.org/10.1007/s00500-020-04861-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an improved particle swarm optimization algorithm (PSOCS) that integrates with a clone selection (CS) principle of artificial immune system is proposed to solve dynamic economic emission dispatch (DEED) problem. Classical particle swarm optimization method is easy to fall into stagnation when no particle discovers a position that is better than its previous best position. To overcome the disadvantage, the CS mechanism is used to evolve the personal best swarm (i.e., $$P^{\mathrm{best}}$$ ) at every generation. The fittest particles in $$P^{\mathrm{best}}$$ will be cloned independently and proportionally to their fitness. In order to force PSOCS jump out of stagnation, a hybrid mutation scheme (called R/1orCB/1) is developed to mutate the clones generated. A constrain-handling approach is utilized to repair infeasible solutions for enhancing the ability of adapting to the DEED problem with various strong constraints. In numerical experiments, the proposed PSOCS is applied to solve three test cases (5-unit, 10-unit, and 15-unit systems) with nonsmooth fuel cost and emission functions. Simulation results indicate that the PSOCS can find the high-quality solutions for the DEED problem, when compared with the most recent methods reported in the literature.},
  archive      = {J_SOCO},
  author       = {Qian, Shuqu and Wu, Huihong and Xu, Guofeng},
  doi          = {10.1007/s00500-020-04861-4},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15249-15271},
  shortjournal = {Soft Comput.},
  title        = {An improved particle swarm optimization with clone selection principle for dynamic economic emission dispatch},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An efficient method for human hand gesture detection and
recognition using deep learning convolutional neural networks.
<em>SOCO</em>, <em>24</em>(20), 15239–15248. (<a
href="https://doi.org/10.1007/s00500-020-04860-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The physical movement of the human hand produces gestures, and hand gesture recognition leads to the advancement in automated vehicle movement system. In this paper, the human hand gestures are detected and recognized using convolutional neural networks (CNN) classification approach. This process flow consists of hand region of interest segmentation using mask image, fingers segmentation, normalization of segmented finger image and finger recognition using CNN classifier. The hand region of the image is segmented from the whole image using mask images. The adaptive histogram equalization method is used as enhancement method for improving the contrast of each pixel in an image. In this paper, connected component analysis algorithm is used in order to segment the finger tips from hand image. The segmented finger regions from hand image are given to the CNN classification algorithm which classifies the image into various classes. The proposed hand gesture detection and recognition methodology using CNN classification approach with enhancement technique stated in this paper achieves high performance with state-of-the-art methods.},
  archive      = {J_SOCO},
  author       = {Neethu, P. S. and Suguna, R. and Sathish, Divya},
  doi          = {10.1007/s00500-020-04860-5},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15239-15248},
  shortjournal = {Soft Comput.},
  title        = {An efficient method for human hand gesture detection and recognition using deep learning convolutional neural networks},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Conventional neural network for blind image blur correction
using latent semantics. <em>SOCO</em>, <em>24</em>(20), 15223–15237. (<a
href="https://doi.org/10.1007/s00500-020-04859-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, deep learning for enhancing the sharpness of blurred image is investigated. Initial pre-processing is blur image kernel estimation which is critical for blind image de-blurring. In prior investigation, handcrafted blur features are optimized for certain uniform blur, which is unrealistic for blind de-convolution. To deal with this crisis, initially this work attempts to carry out kernel matrix estimation using latent semantic analysis (KME-LSA) in dermatology image. In order to enhance the image sparseness, this work modelled an image descriptor based on Gaussian mixture model in auto-encoder (GMM-AE) as a primary layer in convolutional neural networks. The functionality of the proposed GMM-AE triggers the selection of efficient features for subsequent layers in CNN. The features extracted from the integrated trained GMM-AE in CNN can fine-tune the quality of blurred image. Datasets used are melanoma-based dermascope images. Pre-processing procedures are carried out by LSA-based kernel matrix estimation. The attained sharp image outcome is given to the proposed model for effective feature extraction and to attain improved blind image. The anticipated KME-LSA and GMM-AE in CNN estimates blur parameters with high accuracy. Experiment illustrates the efficacy of proposed method and the competitive outcomes are compared with state-of-the-art datasets. Simulation was carried out in MATLAB environment; performance metrics like MSE—227.6, PSNR—33.6762, SSIM—0.9755 and VIF—0.08162 are evaluated. The results show better trade-off than the prevailing techniques.},
  archive      = {J_SOCO},
  author       = {Gowthami, S. and Harikumar, R.},
  doi          = {10.1007/s00500-020-04859-y},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15223-15237},
  shortjournal = {Soft Comput.},
  title        = {Conventional neural network for blind image blur correction using latent semantics},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Blockchain expansion to secure assets with fog node on
special duty. <em>SOCO</em>, <em>24</em>(20), 15209–15221. (<a
href="https://doi.org/10.1007/s00500-020-04857-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain expansion is the high priority necessity to improve security. Hacking and other attacks are headway from system innovation and security measures for the cloud architecture. That is why the countermeasure deployed for such attacks should act in an opportune way and ought to be situated as close as possible to attacking device. As an example, DDoS attacks were not that complex as they are getting now with the new technology known as IoT. Imagine the consequences if 25 billion of IoT devices generate a huge amount of data for DDoS attacks. That is why we propose a new framework that can expand blockchain in a manner where more companies can share their resources to enhance security. So, we proposed a new and complete framework with cloud, fog, to secure configuration files with blockchain technology. Our framework considers the configuration files from SDN or NFV as an asset to secure with blockchain. By saving configuration files into blockchain, we can detect illegal changes occurred to configuration files after hacking attack. This study also focuses on expanding blockchain between the multiple service providers with ease to prevent waste of resources. This paper mainly provides opportunities for different could or companies to secure their assets by employing the power of blockchain and smart contracts.},
  archive      = {J_SOCO},
  author       = {Gul, M. Junaid and Rehman, Abdul and Paul, Anand and Rho, Seungmin and Riaz, Rabia and Kim, Jeonghong},
  doi          = {10.1007/s00500-020-04857-0},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15209-15221},
  shortjournal = {Soft Comput.},
  title        = {Blockchain expansion to secure assets with fog node on special duty},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fusion of deep-learned and hand-crafted features for
cancelable recognition systems. <em>SOCO</em>, <em>24</em>(20),
15189–15208. (<a
href="https://doi.org/10.1007/s00500-020-04856-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent years have witnessed a dramatic shift in the way of biometric identification, authentication, and security processes. Among the essential challenges that face these processes are the online verification and authentication. These challenges lie in the complexity of such processes, the necessity of the personal real-time identifiable information, and the methodology to capture temporal information. In this paper, we present an integrated biometric recognition method to jointly recognize face, iris, palm print, fingerprint and ear biometrics. The proposed method is based on the integration of the extracted deep-learned features together with the hand-crafted ones by using a fusion network. Also, we propose a novel convolutional neural network (CNN)-based model for deep feature extraction. In addition, several techniques are exploited to extract the hand-crafted features such as histogram of oriented gradients (HOG), oriented rotated brief (ORB), local binary patterns (LBPs), scale-invariant feature transform (SIFT), and speeded-up robust features (SURF). Furthermore, for dimensional consistency between the combined features, the dimensions of the hand-crafted features are reduced using independent component analysis (ICA) or principal component analysis (PCA). The core of this paper is the template protection via a cancelable biometric scheme without significantly affecting the recognition performance. Specifically, we have used the bio-convolving approach to enhance the user’s privacy and ensure the robustness against spoof attacks. Additionally, various CNN hyper-parameters with their impact on the proposed model performance are studied. Our experiments on various datasets revealed that the proposed method achieves 96.69\%, 95.59\%, 97.34\%, 96.11\% and 99.22\% recognition accuracies for face, iris, fingerprint, palm print and ear recognition, respectively.},
  archive      = {J_SOCO},
  author       = {Abdellatef, Essam and Omran, Eman M. and Soliman, Randa F. and Ismail, Nabil A. and Abd Elrahman, Salah Eldin S. E. and Ismail, Khalid N. and Rihan, Mohamed and Abd El-Samie, Fathi E. and Eisa, Ayman A.},
  doi          = {10.1007/s00500-020-04856-1},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15189-15208},
  shortjournal = {Soft Comput.},
  title        = {Fusion of deep-learned and hand-crafted features for cancelable recognition systems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An improved multi-sensor d–s rule for conflict reassignment
of failure rate of set. <em>SOCO</em>, <em>24</em>(20), 15179–15188. (<a
href="https://doi.org/10.1007/s00500-020-05298-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to realize high-precision sensor sensing system for unmanned vehicle, a method based on D–S (Dempster–Shafer) evidence theory was presented. D–S evidence theory is a method of evidence processing. However, because of the limitation of multiplication rule, it cannot deal with the evidence of high conflict caused by the failure of a sensor in the system. In the existing D–S theory framework, the prior probability is used to measure the sensor’s failure rate. The correlation matrix is obtained by the mass distribution of evidence, and the interval classification is carried out accordingly. Bayes formula is used to adjust the prior probability of the sensor by synthesizing the risk distribution function of different intervals, and the calculation rule of correction report using convolution rule is proposed. Compared to existing methods, it can reduce the conflict degree and information entropy of the system, so that a reasonable decision can be made.},
  archive      = {J_SOCO},
  author       = {Qiao, Jiale and Zhang, Jindong and Wang, Yuze},
  doi          = {10.1007/s00500-020-05298-5},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15179-15188},
  shortjournal = {Soft Comput.},
  title        = {An improved multi-sensor D–S rule for conflict reassignment of failure rate of set},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On decision evaluation functions in three-way decision
spaces derived from overlap and grouping functions. <em>SOCO</em>,
<em>24</em>(20), 15159–15178. (<a
href="https://doi.org/10.1007/s00500-020-05283-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Overlap and grouping functions, as two kinds of particular binary aggregation functions, have been continuously discussed in the literature for their vast preponderance in some real applications. Meanwhile, after Hu introduced the notion of three-way decision spaces, the decision evaluation functions in three-way decision spaces constructed from the so-called semi-decision evaluation functions have been investigated consistently. This paper continues to consider this research topic and mainly focuses the decision evaluation functions in three-way decision spaces obtained from overlap and grouping functions. Firstly, based on overlap and grouping functions, we give several methods of constructing semi-decision evaluation functions in semi-three-way decision spaces. Secondly, we show some novel semi-decision evaluation functions which are related to fuzzy sets, interval-valued fuzzy sets, fuzzy relations and hesitant fuzzy sets, respectively. Finally, using overlap and grouping functions, we get some ways to construct decision evaluation functions in three-way decision spaces from semi-decision evaluation functions in semi-three-way decision spaces.},
  archive      = {J_SOCO},
  author       = {Jia, Zihang and Qiao, Junsheng},
  doi          = {10.1007/s00500-020-05283-y},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15159-15178},
  shortjournal = {Soft Comput.},
  title        = {On decision evaluation functions in three-way decision spaces derived from overlap and grouping functions},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Attribute reduction of SE-ISI concept lattices for
incomplete contexts. <em>SOCO</em>, <em>24</em>(20), 15143–15158. (<a
href="https://doi.org/10.1007/s00500-020-05271-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-way concept analysis in incomplete contexts lays the theory dealing with the data in incomplete contexts, especially three kinds of partially known formal concepts including SE-ISI formal concept, ISE-SI formal concept and ISE-ISI formal concept. Generally speaking, not every attribute is essential in an incomplete context since the purpose of research is different. Thus, we propose four kinds of attribute reduction of SE-ISI concept lattices based on different criteria. Then, we discuss the relationships among the four kinds of attribute reduction, including the relationships among the consistent sets and relationships among the reducts. Finally, based on discernibility matrices and discernibility functions, the approaches to obtaining these attribute reduction are presented.},
  archive      = {J_SOCO},
  author       = {Wang, Zhen and Wei, Ling and Qi, Jianjun and Qian, Ting},
  doi          = {10.1007/s00500-020-05271-2},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15143-15158},
  shortjournal = {Soft Comput.},
  title        = {Attribute reduction of SE-ISI concept lattices for incomplete contexts},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multiple clustering and selecting algorithms with combining
strategy for selective clustering ensemble. <em>SOCO</em>,
<em>24</em>(20), 15129–15141. (<a
href="https://doi.org/10.1007/s00500-020-05264-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering ensemble can overcome the instability of clustering and improve clustering performance. With the rapid development of clustering ensemble, we find that not all clustering solutions are effective in their final result. In this paper, we focus on selection strategy in selective clustering ensemble. We propose a multiple clustering and selecting approach (MCAS), which is based on different original clustering solutions. Furthermore, we present two combining strategies, direct combining and clustering combining, to combine the solutions selected by MCAS. These combining strategies combine results of MCAS and get a more refined subset of solutions, compared with traditional selective clustering ensemble algorithms and single clustering and selecting algorithms. Experimental results on UCI machine learning datasets show that the algorithm that uses multiple clustering and selecting algorithms with combining strategy performs well on most datasets and outperforms most selective clustering ensemble algorithms.},
  archive      = {J_SOCO},
  author       = {Ma, Tinghuai and Yu, Te and Wu, Xiuge and Cao, Jie and Al-Abdulkarim, Alia and Al-Dhelaan, Abdullah and Al-Dhelaan, Mohammed},
  doi          = {10.1007/s00500-020-05264-1},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15129-15141},
  shortjournal = {Soft Comput.},
  title        = {Multiple clustering and selecting algorithms with combining strategy for selective clustering ensemble},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Approximation of two-variable functions using high-order
takagi–sugeno fuzzy systems, sparse regressions, and metaheuristic
optimization. <em>SOCO</em>, <em>24</em>(20), 15113–15127. (<a
href="https://doi.org/10.1007/s00500-020-05238-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new hybrid method for training high-order Takagi–Sugeno fuzzy systems using sparse regressions and metaheuristic optimization. The fuzzy system is considered with Gaussian fuzzy sets in the antecedents and high-order polynomials in the consequents of fuzzy rules. The fuzzy sets can be chosen manually or determined by a metaheuristic optimization method (particle swarm optimization, genetic algorithm or simulated annealing), while the polynomials are obtained using ordinary least squares, ridge regression or sparse regressions (forward selection, least angle regression, least absolute shrinkage and selection operator, and elastic net regression). A quality criterion is proposed that expresses a compromise between the prediction ability of the fuzzy model and its sparsity. The conducted experiments showed that: (a) the use of sparse regressions and/or metaheuristic optimization can reduce the validation error compared with the reference method, and (b) the use of sparse regressions may simplify the fuzzy model by zeroing some of the coefficients.},
  archive      = {J_SOCO},
  author       = {Wiktorowicz, Krzysztof and Krzeszowski, Tomasz},
  doi          = {10.1007/s00500-020-05238-3},
  journal      = {Soft Computing},
  number       = {20},
  pages        = {15113-15127},
  shortjournal = {Soft Comput.},
  title        = {Approximation of two-variable functions using high-order Takagi–Sugeno fuzzy systems, sparse regressions, and metaheuristic optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new approach for ergonomic risk assessment integrating
KEMIRA, best–worst and MCDM methods. <em>SOCO</em>, <em>24</em>(19),
15093–15110. (<a
href="https://doi.org/10.1007/s00500-020-05143-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, a new three-phase ergonomic risk assessment approach was proposed for manual lifting tasks to determine which worker has the highest ergonomic risk level considering two criteria sets as lifting-related criteria and human-related criteria. In the first phase, Modified Kemeny Median Indicator Ranks Accordance (KEMIRA-M) and a novel two-dimensional best–worst method (BWM) integration were proposed for weighting ergonomic risk criteria in two sets. In this way, weighting procedure of KEMIRA-M was advanced by the proposed two-dimensional BWM in a consistent manner and subjectivity in determining the best and the worst criteria in traditional BMW was prevented by using KEMIRA-M. Thus, the weaknesses of both methods have been developed. In the second phase, the rankings of workers were determined via utilizing multi-objective optimization on the basis of simple ratio analysis, multi-objective optimization by ratio analysis (MOORA) ratio, MOORA reference point and complex proportional assessment to see how worker rankings differ despite using the same advanced weighting approach based on KEMIRA-M and two-dimensional BWM integration. Finally, to aggregate these different ranking results, technique of precise order preference was applied. In this way, different viewpoints of each ranking approach can be reflected on a single worker’s priority. The applicability of the proposed ergonomic risk assessment approach was demonstrated with a real application in tube manufacturing.},
  archive      = {J_SOCO},
  author       = {Delice, Elif Kılıç and Can, Gülin Feryal},
  doi          = {10.1007/s00500-020-05143-9},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {15093-15110},
  shortjournal = {Soft Comput.},
  title        = {A new approach for ergonomic risk assessment integrating KEMIRA, best–worst and MCDM methods},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Performance improvement of cloud security with parallel
anarchies society optimization algorithm for virtual machine selection
in cloud computing. <em>SOCO</em>, <em>24</em>(19), 15081–15092. (<a
href="https://doi.org/10.1007/s00500-020-04892-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing (CC) is a future promising computing technology and has proven tremendous exceptional attainable in managing the hardware and software program sources placed at third-party provider vendors. However, security and virtual machines (VMs) selection to a process a request characterize a large venture. The major problem in the usage of the technology is the security concerns which increase the demand for a robust security mechanism to protect the data on the cloud. Hence in order to resolve this issue, an approach was designed for the purpose of enhancing the cloud security as well as the time of execution known as weighted mean-based convolutional neural network with advanced encryption standard (WMCNN-AES). By employing the method of pseudorandom number generators (PRNGs), random keys are generated and the finest keys are produced by using the WMCNN method. In the WMCNN approach, randomly generated keys are taken as input and the approximation concerning the secret key of the input is produced by the hidden layers. For the purpose of encrypting the data, the finest secret keys are generated by the output layer. By employing the advanced encryption standard (AES) algorithm, encryption is executed. Storage of the files concerning the encrypted data is done in the cloud storage system. Optimal selection of VMs performs a significant enhancement of the performance through reducing the execution time of requests (tasks) coming from stakeholders and maximizing utilization of cloud resources. For the purpose of optimizing the virtual machines’ or VMs’ selection, parallel anarchies society optimization (PASO) is employed in the cloud environment to increase the performance and resource utilization. When comparing the experimental results of the proposed system with the existing system, it is observed that the proposed system accomplished an enhanced performance with respect to resource utilization, cost, throughput, service latency as well as execution time.},
  archive      = {J_SOCO},
  author       = {Lanitha, B. and Karthik, S.},
  doi          = {10.1007/s00500-020-04892-x},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {15081-15092},
  shortjournal = {Soft Comput.},
  title        = {Performance improvement of cloud security with parallel anarchies society optimization algorithm for virtual machine selection in cloud computing},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Effective long short-term memory with fruit fly optimization
algorithm for time series forecasting. <em>SOCO</em>, <em>24</em>(19),
15059–15079. (<a
href="https://doi.org/10.1007/s00500-020-04855-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A number of recent studies have adopted long short-term memory (LSTM) in extensive applications, such as handwriting recognition and time series prediction, with considerable success. However, the parameters of LSTM have greatly influenced its accuracy and performance. In this study, LSTM with fruit fly optimization algorithm (FOA), called FOA-LSTM, is designed to solve time series problems. As a novel intelligent algorithm, FOA is applied to decide on the optimal hyper-parameter of LSTM. Experiments under the NN3 time series, three comparative experiments and the monthly energy consumption of the USA are conducted to verify the effectiveness of the FOA-LSTM model. The results indicate that the symmetric mean absolute percentage error (SMAPE) is reduced by up to 11.44\% in the last 11 monthly series in the NN3 dataset. Four comparative experiments and the real-life series verify further that the FOA-LSTM model obtains a better result compared with other forecasting models.},
  archive      = {J_SOCO},
  author       = {Peng, Lu and Zhu, Qing and Lv, Sheng-Xiang and Wang, Lin},
  doi          = {10.1007/s00500-020-04855-2},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {15059-15079},
  shortjournal = {Soft Comput.},
  title        = {Effective long short-term memory with fruit fly optimization algorithm for time series forecasting},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Quasi-closed-form solution and numerical method for currency
option with uncertain volatility model. <em>SOCO</em>, <em>24</em>(19),
15041–15057. (<a
href="https://doi.org/10.1007/s00500-020-04854-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There exist some non-stochastic factors in the financial market, so the dynamics of the exchange rate highly depends on human uncertainty. This paper investigates the pricing problems of foreign currency options under the uncertain environment. First, we propose an currency model under the assumption that exchange rate, volatility, domestic interest rate and foreign interest rate are all driven by uncertain differential equations; especially, the exchange rate exhibits mean reversion. Since the analytical solutions of nested uncertain differential equations cannot always be obtained, we design a new numerical method, Runge–Kutta-99 hybrid method, for solving nested uncertain differential equations. The accuracy of the designed numerical method is investigated by comparison with the analytical solution. Subsequently, the quasi-closed-form solutions are derived for the prices of both European and American foreign currency options. Finally, in order to illustrate the rationality and the practicability of the proposed currency model, we design several numerical algorithms to calculate the option prices and analyze the price behaviors of foreign currency options across strike price and maturity.},
  archive      = {J_SOCO},
  author       = {Li, Zhe and Liu, Yong-Jun and Zhang, Wei-Guo},
  doi          = {10.1007/s00500-020-04854-3},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {15041-15057},
  shortjournal = {Soft Comput.},
  title        = {Quasi-closed-form solution and numerical method for currency option with uncertain volatility model},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Enhanced superposition determination for weighted
superposition attraction algorithm. <em>SOCO</em>, <em>24</em>(19),
15015–15040. (<a
href="https://doi.org/10.1007/s00500-020-04853-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper argues the efficiency enhancement study of a recent meta-heuristic algorithm, WSA, by modifying one of its operators, superposition (target point) determination procedure. The original operator is based on the weighted vector summation and has some potential disadvantages with regard to domain of the decision variables such that determining a superposition out of the search space. Such potential disadvantages may cause WSA to behave as a random search and result in an unsatisfactory performance for some problems. In order to eliminate such potential disadvantages, we propose a new superposition determination procedure for the WSA algorithm. Thus, the mWSA algorithm will be able to behave more consistent during its search and its robustness will improve significantly in comparison to its original version. The mWSA algorithm is compared against the WSA algorithm and some other algorithms taken from the existing literature on both the constrained and unconstrained optimization problems. The experimental results clearly indicate that the mWSA algorithm is an improvement for the original WSA algorithm, and also prove that the mWSA algorithm is more robust and consistent search procedure in solving complex optimization problems.},
  archive      = {J_SOCO},
  author       = {Baykasoğlu, Adil and Akpinar, Şener},
  doi          = {10.1007/s00500-020-04853-4},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {15015-15040},
  shortjournal = {Soft Comput.},
  title        = {Enhanced superposition determination for weighted superposition attraction algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Covariances with OWA operators and bonferroni means.
<em>SOCO</em>, <em>24</em>(19), 14999–15014. (<a
href="https://doi.org/10.1007/s00500-020-04852-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The covariance is a statistical technique that is widely used to measure the dispersion between two sets of elements. This work develops new covariance measures by using the ordered weighted average (OWA) operator and Bonferroni means. Thus, this work presents the Bonferroni covariance OWA operator. The main advantage of this approach is that the decision maker can underestimate or overestimate the covariance according to his or her attitudes. The article further generalizes this formulation by using generalized and quasi-arithmetic means to obtain a wide range of particular types of covariances, including the quadratic Bonferroni covariance and the cubic Bonferroni covariance. The paper also considers some other extensions by using induced aggregation operators in order to use complex reordering processes in the analysis. The work ends by studying the applicability of these new techniques to real-world problems and presents an illustrative example of a research and development (R&amp;D) investment problem.},
  archive      = {J_SOCO},
  author       = {Blanco-Mesa, Fabio and León-Castro, Ernesto and Merigó, José M.},
  doi          = {10.1007/s00500-020-04852-5},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14999-15014},
  shortjournal = {Soft Comput.},
  title        = {Covariances with OWA operators and bonferroni means},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Quantum-behaved particle swarm optimization with generalized
space transformation search. <em>SOCO</em>, <em>24</em>(19),
14981–14997. (<a
href="https://doi.org/10.1007/s00500-020-04850-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nature-inspired algorithms have been proved to be very powerful methods for complex numerical optimization problems. Quantum-behaved particle swarm optimization (QPSO) is a typical member of nature-inspired algorithms, and it is a simple and effective population-based technique used in numerical optimization. Despite its efficiency and wide use, QPSO suffers from premature convergence and poor balance between exploration and exploitation in solving complex optimization problems. To address these issues, a new evolutionary technique called generalized space transformation search is proposed, and then, we introduce an improved quantum-behaved particle swarm optimization algorithm combined with this new technique in this study. The proposed generalized space transformation search is based on opposition-based learning and generalized opposition-based learning, which can not only improve the exploitation of the current search space but also strengthen the exploration of the neighborhood of the current search space. The improved quantum-behaved particle swarm optimization algorithm employs generalized space transformation search for population initialization and generation jumping. A comprehensive set of 16 well-known unconstrained benchmark functions is employed for experimental verification. The contribution of the generalized space transformation search is empirically verified, and the influence of dimensionality is also investigated. Besides, the improved quantum-behaved particle swarm optimization algorithm is also compared with some typical extensions of QPSO and several competitive meta-heuristic algorithms. Such comparisons suggest that the improved quantum-behaved particle swarm optimization algorithm may lead to finding promising solutions compared to the other algorithms.},
  archive      = {J_SOCO},
  author       = {Zhang, Yiying and Jin, Zhigang},
  doi          = {10.1007/s00500-020-04850-7},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14981-14997},
  shortjournal = {Soft Comput.},
  title        = {Quantum-behaved particle swarm optimization with generalized space transformation search},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hybrid machine learning for predicting strength of
sustainable concrete. <em>SOCO</em>, <em>24</em>(19), 14965–14980. (<a
href="https://doi.org/10.1007/s00500-020-04848-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Foamed concrete material is a sustainable material which is widely used in the construction industry due to their sustainability. Accurate prediction of their compressive strength is vital for structural design. However, empirical methods are limited to consider simultaneously all influencing factors in predicting the compressive strength of foamed concrete materials. Thus, this study proposed a novel hybrid artificial intelligence (AI) model which couples the least squares support vector regression (LSSVR) with the grey wolf optimization (GWO) to consider effectively the influencing factors and improve the predictive accuracy in predicting the foamed concrete’s compressive strength. Performance of the proposed model was evaluated using a real-world dataset. Comparison results confirm that the proposed GWO–LSSVR model was superior than the support vector regression, artificial neural networks, random forest, and M5Rules with the improvement rate of 144.2–284.0\% in mean absolute percentage error (MAPE). Notably, the evaluation results show that the GWO–LSSVR model showed the good agreement between the actual and predicted values with the correlation coefficient of 0.991 and MAPE of 3.54\%. Thus, the proposed AI model was suggested as an effective tool for designing foamed concrete materials.},
  archive      = {J_SOCO},
  author       = {Pham, Anh-Duc and Ngo, Ngoc-Tri and Nguyen, Quang-Trung and Truong, Ngoc-Son},
  doi          = {10.1007/s00500-020-04848-1},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14965-14980},
  shortjournal = {Soft Comput.},
  title        = {Hybrid machine learning for predicting strength of sustainable concrete},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fast replica recovery and adaptive consistency preservation
for edge cloud system. <em>SOCO</em>, <em>24</em>(19), 14943–14964. (<a
href="https://doi.org/10.1007/s00500-020-04847-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge cloud extends the power of cloud computing to the edge of the devices that are closest to the demands of big connection, low latency and large bandwidth. However, there are still many challenges due to the dynamic, heterogeneous and real-time bandwidth of the node in the edge cloud environment. This paper studies dynamic replica creation, fast replica recovery and adaptive consistency preservation. Before solving the problem of data inconsistency caused by frequent updates of replicas, we consider the strategy of fast replica recovery. Firstly, the DRC-DS is based on the regional structure, considering the number of replicas and the creation location of the data process and copying the data information with high access frequency and long average response time. Moreover, the FRR-LB is based on the heat ranking of the replica, the source node and the target node are determined according to the double-cycle lookup structure. Besides, the ACP-IMP is proposed to solve the problem of replica consistency in the environment of high failure rate of network and node. The more certainty replica nodes are elected as the leaders of edge nodes, and the message transmission of reconfirmation is reduced.},
  archive      = {J_SOCO},
  author       = {Guo, Jingjing and Li, Chunlin and Luo, Youlong},
  doi          = {10.1007/s00500-020-04847-2},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14943-14964},
  shortjournal = {Soft Comput.},
  title        = {Fast replica recovery and adaptive consistency preservation for edge cloud system},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An efficient green computing fair resource allocation in
cloud computing using modified deep reinforcement learning algorithm.
<em>SOCO</em>, <em>24</em>(19), 14933–14942. (<a
href="https://doi.org/10.1007/s00500-020-04846-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing provides services and resources in the Internet, and many applications are self-service-supported, on-demand resource allocation-adapted. These dynamic networks allocated necessary resource to the users’ need and they require proper resource allocation scheme. Since various resources are consumed by users if resource allocation is not proper, this leads the system to load imbalance nature. Using Internet-connected devices for storage and computation not only communicates the cloud resources but also connects the devices to network through various protocols. These changes make the network into a complex, dense, heterogeneous system. In this paper, a green computing fair resource allocation through deep reinforcement learning model is proposed to provide efficient resource allocation scheme to the users in the network. Conventional Q-learning model fails in dimensionality problem when the state space increases exponentially. The proposed model is combined with fair resource allocation with deep reinforcement learning to provide better allocation schemes compared to the conventional model.},
  archive      = {J_SOCO},
  author       = {Karthiban, K. and Raj, Jennifer S.},
  doi          = {10.1007/s00500-020-04846-3},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14933-14942},
  shortjournal = {Soft Comput.},
  title        = {An efficient green computing fair resource allocation in cloud computing using modified deep reinforcement learning algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A kernel principal component analysis-based approach for
determining the spatial warning domain of dam safety. <em>SOCO</em>,
<em>24</em>(19), 14921–14931. (<a
href="https://doi.org/10.1007/s00500-020-04845-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is important to determine the warning value of structural behavior for evaluating the service safety, identifying the potential risk and preventing the failure of dam engineering. However, more attention was paid to determining the security warning value of a single observation point on deformation, seepage or stress. And the correlation between the adjacent points or among all points in one dam section is usually lack of consideration. In this paper, the monitoring data of multi-points are taken to determine the spatial warning domain of dam safety. The warning mode of abnormal structural behavior is changed from the single point into the linked multi-points. First, the kernel principal component analysis method is adopted to identify the inherent characteristics among observation points in a dam section. Second, considering the correlation among observation points, the implementation process is proposed to determine the spatial warning domain of dam safety. Finally, an actual concrete gravity dam is taken as an example. The proposed approach is used to determine the spatial warning domains of deformation and seepage. The results, which are obtained by the proposed approach, the traditional method and the qualitative analysis for monitoring data, are compared. It is indicated that the proposed multi-points correlation-based approach is feasible and superior to determine the spatial warning domain of dam safety.},
  archive      = {J_SOCO},
  author       = {Su, Huaizhi and Wen, Zhiping and Ren, Jie},
  doi          = {10.1007/s00500-020-04845-4},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14921-14931},
  shortjournal = {Soft Comput.},
  title        = {A kernel principal component analysis-based approach for determining the spatial warning domain of dam safety},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fuzzy logic-based decision-making system design for safe
forklift truck speed: Cast cobblestone production application.
<em>SOCO</em>, <em>24</em>(19), 14907–14920. (<a
href="https://doi.org/10.1007/s00500-020-04843-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a model in which “fuzzy logic multi-criteria decision-making method” is suggested to determine real-time forklift speed to reduce occupational accidents caused by operators. The model developed in the study uses the variables: the weight and height of the load carried by the forklift, the number of products on its pallet, the places with high risk of accident, and the wet-dry condition of the ground. In order to evaluate the performance of the suggested model, a data set comprises 128 different conditions in cast cobblestone production. Determined forklift speeds were compared with the forklift speeds determined by fuzzy logic using statistically analyses. Results showed that fuzzy logic model has a high accuracy and low error. Fuzzy logic modeling has proved to be a good way to decide the real-time speed of the forklifts being used in production without compromising occupational safety. Friedman test and Wilcoxon test have been used to estimate the significance of fuzzy logic method. The fuzzy logic results showed that our method achieved better results compared to beginner operator.},
  archive      = {J_SOCO},
  author       = {Dizdar, Ercüment Neşet and Koçar, Oğuz},
  doi          = {10.1007/s00500-020-04843-6},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14907-14920},
  shortjournal = {Soft Comput.},
  title        = {Fuzzy logic-based decision-making system design for safe forklift truck speed: Cast cobblestone production application},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improving image thresholding by the type II fuzzy entropy
and a hybrid optimization algorithm. <em>SOCO</em>, <em>24</em>(19),
14885–14905. (<a
href="https://doi.org/10.1007/s00500-020-04842-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The segmentation of digital images is an open problem that has increasingly attracted the attention of researchers during the last years. Thresholding approaches are often used due to their independence from the resolution of the images and their speed. However, simple thresholding approaches usually generate low-quality images. To achieve a better balance between speed and quality, many criteria are used to select the thresholds that segment the image. The type II fuzzy entropy (TII-FE) was introduced to perform image thresholding by modeling the classes of an image as membership functions to avoid uncertainty on the selection of the thresholds leading to improvement regarding the quality of the segmented image. To maximize the TII-FE, an efficient optimizer should be used to converge quickly to the optimal. In this paper, a hybrid method based on the Paddy Field Algorithm (PFA) and the Plant Propagation Algorithm (PPA) with the disruption operator (HPFPPA-D) is presented for the maximization of the TII-FE. The hybridization of these algorithms is used to enhance the performance of each algorithm by introducing operators from other approaches. In this case, the PFA shows good exploitation features that are complemented by the exploration behavior of PPA and refined with the disruption operator. The synergy between those methods has led to an accurate methodology for TII-FE thresholding. The proposed HPFPPA-D for TII-FE is evaluated using a set of benchmark images regarding convergence and image quality. The results are compared against other state-of-the-art evolutionary algorithms providing evidence of a superior and significant performance.},
  archive      = {J_SOCO},
  author       = {Abd Elaziz, Mohamed and Sarkar, Uddalok and Nag, Sayan and Hinojosa, Salvador and Oliva, Diego},
  doi          = {10.1007/s00500-020-04842-7},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14885-14905},
  shortjournal = {Soft Comput.},
  title        = {Improving image thresholding by the type II fuzzy entropy and a hybrid optimization algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Proposed s-algo+ data mining algorithm for web platforms
course content and usage evaluation. <em>SOCO</em>, <em>24</em>(19),
14861–14883. (<a
href="https://doi.org/10.1007/s00500-020-04841-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper suggests a novel data mining algorithm for the evaluation of e-learning courses from a Learning Management System. This new algorithm, which is called S-Algo+ (Superposition Algorithm), takes as input the course rankings and the suggestion results from any kind of ranking/hierarchical algorithms and evaluates the validity of a course ranking position. The ranking algorithms estimate the quantity and quality of the course content according to users’ actions and interest. S-Algo+ generates an improved final ranking suggestion output, combining the best results of the source ranking algorithms using statistical and mathematic techniques. In this way, the researchers and course instructors can use more accurate results. The efficiency and applicability of the S-Algo+ algorithm was evaluated successfully with a cross-comparison quantitative and qualitative process in a case study at a Greek university. Our new proposed S-Algo+ algorithm may lead to both theoretical and practical advantages. It may also apply not only for course evaluation but for any kind of web application such as e-commerce.},
  archive      = {J_SOCO},
  author       = {Kazanidis, Ioannis and Valsamidis, Stavros and Gounopoulos, Elias and Kontogiannis, Sotirios},
  doi          = {10.1007/s00500-020-04841-8},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14861-14883},
  shortjournal = {Soft Comput.},
  title        = {Proposed S-algo+ data mining algorithm for web platforms course content and usage evaluation},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Energy-efficient strategy for virtual machine consolidation
in cloud environment. <em>SOCO</em>, <em>24</em>(19), 14845–14859. (<a
href="https://doi.org/10.1007/s00500-020-04839-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An important issue of energy efficiency in cloud environment is to perform more jobs while consuming less amount of power. Virtual machine consolidation remains the most deployed strategy to manage both performance and energy consumption. Most of existing energy efficiency techniques save energy against the cost on performance degradation. Consolidation techniques leverage thresholds to detect overloaded and underloaded hosts that could be vacated to achieve optimal balance between host utilization and energy consumption. In this research, we propose an energy-efficient strategy (EES) to consolidate virtual machines in cloud environment with an aim of reducing the energy consumption while completing more tasks with the highest throughput. Our proposal makes use of the performance-to-power ratio to set upper thresholds for overload detection. In addition, EES considers the overall data center workload utilization to set lower thresholds, which can reduce the number of virtual machine migrations. The simulation results show that EES leads to energy-efficient workload consolidation with the minimal number of migrations and less energy consumption. The results conclude that EES saves energy consumption without compromising user’s workload requirement.},
  archive      = {J_SOCO},
  author       = {Saadi, Youssef and El Kafhali, Said},
  doi          = {10.1007/s00500-020-04839-2},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14845-14859},
  shortjournal = {Soft Comput.},
  title        = {Energy-efficient strategy for virtual machine consolidation in cloud environment},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel quasi-reflected harris hawks optimization algorithm
for global optimization problems. <em>SOCO</em>, <em>24</em>(19),
14825–14843. (<a
href="https://doi.org/10.1007/s00500-020-04834-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Harris hawks optimization (HHO) is a recently developed meta-heuristic optimization algorithm based on hunting behavior of Harris hawks. Similar to other meta-heuristic algorithms, HHO tends to be trapped in low diversity, local optima and unbalanced exploitation ability. In order to improve the performance of HHO, a novel quasi-reflected Harris hawks algorithm (QRHHO) is proposed, which combines HHO algorithm and quasi-reflection-based learning mechanism (QRBL) together. The improvement includes two parts: the QRBL mechanism is introduced firstly to increase the population diversity in the initial stage, and then, QRBL is added in each population position update to improve the convergence rate. The proposed method will also be helpful to control the balance between exploration and exploitation. The performance of QRHHO has been tested on twenty-three benchmark functions of various types and dimensions. Through comparison with the basic HHO, HHO combined with opposition-based learning mechanism and HHO combined with quasi-opposition-based learning mechanism, the results demonstrate that QRHHO can effectively improve the convergence speed and solution accuracy of the basic HHO and two variants of HHO. At the same time, QRHHO is also better than other swarm-based intelligent algorithms.},
  archive      = {J_SOCO},
  author       = {Fan, Qian and Chen, Zhenjian and Xia, Zhanghua},
  doi          = {10.1007/s00500-020-04834-7},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14825-14843},
  shortjournal = {Soft Comput.},
  title        = {A novel quasi-reflected harris hawks optimization algorithm for global optimization problems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimization insisted watermarking model: Hybrid firefly and
jaya algorithm for video copyright protection. <em>SOCO</em>,
<em>24</em>(19), 14809–14823. (<a
href="https://doi.org/10.1007/s00500-020-04833-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this digital era, illegitimate redistribution and protection of digital multimedia have to turn out to be the critical issue. Therefore, digital watermarking has been introduced for avoiding illegitimate works and also to ensure security and authentication as well. “Digital video watermarking is a method to hide some kind of data like audio, image, text into digital video sequences which is nothing but orders of successive still images.” This paper intends to formulate a novel video watermarking framework that includes three stages, such as (i) optimal video frame prediction, (ii) watermark embedding process and (iii) watermark extraction process. Very first, the optimal frames are determined using a new hybrid algorithm termed trial-based update on Jaya plus firefly (TU-JF) algorithm, in such a way that the peak signal-to-noise ratio (PSNR) should be maximal. The frames are assigned with a label of one or zero, where label one denotes the frame with better PSNR (can select for embedding process) and label zero denotes the frame with reduced PSNR (cannot be used for embedding). Consequently, a data library is formed from the obtained results, where each frame of videos is determined with their gray-level co-occurrence matrix (GLCM) features and labels (can embed or not). As in the proposed model, the optimal frame prediction is carried out using deep belief network (DBN) framework; the obtained data are then trained in the model. The optimal frames could be predicted in an efficient manner while testing. The significant contribution of this work concerns the optimization of hidden neurons in the DBN framework, which helps to enhance prediction accuracy. At last, the “watermark embedding process” and “watermark extraction process” are done by which the image could be embedded within the optimal frames.},
  archive      = {J_SOCO},
  author       = {Alotaibi, Saud S.},
  doi          = {10.1007/s00500-020-04833-8},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14809-14823},
  shortjournal = {Soft Comput.},
  title        = {Optimization insisted watermarking model: Hybrid firefly and jaya algorithm for video copyright protection},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Enhanced salp swarm algorithm based on random walk and its
application to training feedforward neural networks. <em>SOCO</em>,
<em>24</em>(19), 14791–14807. (<a
href="https://doi.org/10.1007/s00500-020-04832-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Salp Swarm Algorithm (SSA) is a new type of metaheuristic and has shown superiority over other well-known algorithms such as Particle Swarm Optimization and Grey Wolf Optimizer in solving challenging optimization problems. Despite its superior performance, SSA still has problems such as insufficient convergence speed. Moreover, its local optima avoidance ability is not as good as those evolutionary algorithms using crossover operators. In this paper, we propose a modified Salp Swarm Algorithm (m-SSA) which improves the exploitation and exploration of SSA by integrating random walk strategy and especially enhances exploration by adding a new controlling parameter. In addition, a simulated annealing-type acceptance criterion is adopted to accept the fittest follower position as the new best leader position. The performance of the proposed algorithm is benchmarked on a set of classical functions and CEC2014 test suite. The proposed algorithm (m-SSA) outperforms SSA significantly on most test functions. When compared with other state-of-the-art metaheuristics, it also presents very competitive results. Besides, we apply the proposed algorithm on training feedforward neural networks (FNNs) and the results prove the effectiveness and efficiency of m-SSA.},
  archive      = {J_SOCO},
  author       = {Yin, Yongqiang and Tu, Qiang and Chen, Xuechen},
  doi          = {10.1007/s00500-020-04832-9},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14791-14807},
  shortjournal = {Soft Comput.},
  title        = {Enhanced salp swarm algorithm based on random walk and its application to training feedforward neural networks},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Barriers to implementation of blockchain into supply chain
management using an integrated multi-criteria decision-making method: A
numerical example. <em>SOCO</em>, <em>24</em>(19), 14771–14789. (<a
href="https://doi.org/10.1007/s00500-020-04831-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information and product visibilities have been crucial in today’s supply chain processes, as economic, environmental and social sustainability concepts, which have been frequently focused on in recent years, prioritize the transparency of business processes. Blockchain technology, with continuously expanding application areas, has been revealed to be applicable in supply chain processes. On the other hand, integration of blockchain technology into supply chain processes will not be as smooth as estimated, since some challenges and constraints have already been identified. Therefore, companies aiming to integrate blockchain into supply chain processes should qualify and investigate each of these challenges. In the literature, to the best of the authors’ knowledge, there is no study addressing the issues arising during the integration process. Moreover, most studies related to blockchain technology have merely examined the positive aspects. This study, on the contrary, discusses the technologic, financial, organizational and environmental challenges that are confronted on a sectoral basis during the integration process. The fuzzy AHP and fuzzy TOPSIS methods, which are used in uncertainties and are capable of simultaneous multi-criteria evaluation, were employed. Furthermore, it is intended to produce a study that is of benefit to industrial actors by analyzing the findings related to the challenges merging during technological transformation. The outputs of this study are as follows: (i) High investment costs, data security and utility are important; (ii) integration is harder for the health and logistic sectors; (iii) the supply chains, which are less complicated, will be able to coordinate faster than the blockchain technology does. Consequently, the obtained results are evaluated, and strategic outputs are shared for the decision-makers aiming to integrate blockchain technology into the supply chain processes.},
  archive      = {J_SOCO},
  author       = {Öztürk, Cihat and Yildizbaşi, Abdullah},
  doi          = {10.1007/s00500-020-04831-w},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14771-14789},
  shortjournal = {Soft Comput.},
  title        = {Barriers to implementation of blockchain into supply chain management using an integrated multi-criteria decision-making method: A numerical example},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the analysis of hyper-parameter space for a genetic
programming system with iterated f-race. <em>SOCO</em>, <em>24</em>(19),
14757–14770. (<a
href="https://doi.org/10.1007/s00500-020-04829-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary algorithms (EAs) have been with us for several decades and are highly popular given that they have proved competitive in the face of challenging problems’ features such as deceptiveness, multiple local optima, among other characteristics. However, it is necessary to define multiple hyper-parameter values to have a working EA, which is a drawback for many practitioners. In the case of genetic programming (GP), an EA for the evolution of models and programs, hyper-parameter optimization has been extensively studied only recently. This work builds on recent findings and explores the hyper-parameter space of a specific GP system called neat-GP that controls model size. This is conducted using two large sets of symbolic regression benchmark problems to evaluate system performance, while hyper-parameter optimization is carried out using three variants of the iterated F-Race algorithm, for the first time applied to GP. From all the automatic parametrizations produced by optimization process, several findings are drawn. Automatic parametrizations do not outperform the manual configuration in many cases, and overall, the differences are not substantial in terms of testing error. Moreover, finding parametrizations that produce highly accurate models that are also compact is not trivially done, at least if the hyper-parameter optimization process (F-Race) is only guided by predictive error. This work is intended to foster more research and scrutiny of hyper-parameters in EAs, in general, and GP, in particular.},
  archive      = {J_SOCO},
  author       = {Trujillo, Leonardo and Álvarez González, Ernesto and Galván, Edgar and Tapia, Juan J. and Ponsich, Antonin},
  doi          = {10.1007/s00500-020-04829-4},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14757-14770},
  shortjournal = {Soft Comput.},
  title        = {On the analysis of hyper-parameter space for a genetic programming system with iterated F-race},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fuzzy optimal control for nonlinear systems with
time-varying delay via sampled-data controller. <em>SOCO</em>,
<em>24</em>(19), 14743–14755. (<a
href="https://doi.org/10.1007/s00500-020-04827-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work is devoted to a fuzzy sampled-data optimal control problem for nonlinear systems with time-varying delay in Takagi–Sugeno fuzzy form. Based on the Lyapunov–Krasovskii functional theory, some novel stability criteria are established. A fuzzy sampled-data controller is developed to ensure that the fuzzy closed-loop sampled-data control system is asymptotically stable and the guaranteed cost performance is also minimized. It is shown that the obtained results are less conservative in the stability analysis. Two examples of the computer-simulated truck-trailer system and the continuous stirred tank reactor system are provided to show the effectiveness and the merits of the proposed design.},
  archive      = {J_SOCO},
  author       = {Qu, Zifang and Zhang, Zhengdi and Du, Zhenbin and Zhao, Tiebiao},
  doi          = {10.1007/s00500-020-04827-6},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14743-14755},
  shortjournal = {Soft Comput.},
  title        = {Fuzzy optimal control for nonlinear systems with time-varying delay via sampled-data controller},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A genetic approach for the maximum network lifetime problem
with additional operating time slot constraints. <em>SOCO</em>,
<em>24</em>(19), 14735–14741. (<a
href="https://doi.org/10.1007/s00500-020-04821-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The maximum network lifetime problem is a well-known and challenging optimization problem which has been addressed successfully with several approaches in the last years. It essentially consists in finding an optimal schedule for sensors activities in a wireless sensor network (WSN) aiming at maximizing the total amount of time during which the WSN is able to perform its monitoring task. In this paper, we consider a new scenario in which, in order to monitor some locations in a geographical area, the sensors need to be active for a fixed amount of time, defined as operating time slot. For this new scenario, we derive an upper bound on the maximum lifetime and propose a genetic algorithm for finding a near-optimal node activity schedule. The performance evaluation results obtained on numerous benchmark instances show the effectiveness of the proposed approach.},
  archive      = {J_SOCO},
  author       = {D’Ambrosio, Ciriaco and Iossa, Antonio and Laureana, Federica and Palmieri, Francesco},
  doi          = {10.1007/s00500-020-04821-y},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14735-14741},
  shortjournal = {Soft Comput.},
  title        = {A genetic approach for the maximum network lifetime problem with additional operating time slot constraints},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Archimedean geometric heronian mean aggregation operators
based on dual hesitant fuzzy set and their application to multiple
attribute decision making. <em>SOCO</em>, <em>24</em>(19), 14721–14733.
(<a href="https://doi.org/10.1007/s00500-020-04819-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy set, intuitionistic fuzzy set, hesitant fuzzy set can be regarded as a special case of dual hesitant fuzzy set. Therefore, dual hesitant fuzzy set is a more comprehensive set. Further, Archimedean t-norm and t-conorm provides generalized operational rules for dual hesitant fuzzy set. And geometric Heronian mean have advantages when considering the interrelationship of aggregation arguments. Thus, it is necessary to extend the geometric Heronian mean operator to the dual hesitant fuzzy environment based on Archimedean t-norm and t-conorm. Comprehensive above, in this paper, the dual hesitant fuzzy geometric Heronian mean operator and dual hesitant fuzzy geometric weighted Heronian mean operator based on Archimedean t-norm and t-conorm are developed. Their properties and special case are investigated. Moreover, a multiple attribute decision making method is proposed. The effectiveness of our method and the influence of parameters on multiple attribute decision making are studied by an example. The superiority of our method is illustrated by comparing with other existing methods.},
  archive      = {J_SOCO},
  author       = {Mo, Jiongmei and Huang, Han-Liang},
  doi          = {10.1007/s00500-020-04819-6},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14721-14733},
  shortjournal = {Soft Comput.},
  title        = {Archimedean geometric heronian mean aggregation operators based on dual hesitant fuzzy set and their application to multiple attribute decision making},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An intelligent computer-aided approach for target protein
prediction in infectious diseases. <em>SOCO</em>, <em>24</em>(19),
14707–14720. (<a
href="https://doi.org/10.1007/s00500-020-04815-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Essential proteins are the most important constituents for all kinds of organism. The research on predicting essential target proteins contributes significantly to drug development, disease diagnosis, and treatment. Numerous computational- and experimental-based approaches have been used in the recent past for essential protein prediction. However, it is highly challenging to bring remarkable improvement in the accuracy of the essential target proteins. In this method, we introduce an intelligent computational technique known as graph colouring-deep neural network which automatically extracts the target proteins by combining a graph-theoretic approach called graph colouring and neural network. In this approach, the protein–protein interaction network (PPI) of homosapiens are extracted from string DB (data base) and then applied to the graph colouring algorithm. Initially, each protein in the network is assigned a colour by checking the connectivity with the neighbourhood proteins. Secondly, the proteins with primary and secondary colours are extracted from the PPI. Finally, a deep neural network-based approach is used to automatically extract the essential target proteins depending on the physicochemical features of the proteins. To assess the performance of the proposed model, the experiment has been carried out in four different diseases such as cancer, diabetes, asthma and human papilloma virus viral infection. The proposed approach shows a remarkable performance than the traditional approaches in views of various metrics such as accuracy, precision, recall, and F-measure.},
  archive      = {J_SOCO},
  author       = {Narmadha, D. and Pravin, A.},
  doi          = {10.1007/s00500-020-04815-w},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14707-14720},
  shortjournal = {Soft Comput.},
  title        = {An intelligent computer-aided approach for target protein prediction in infectious diseases},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Geometric distortion and mixed pixel elimination via TDYWT
image enhancement for precise spatial measurement to avoid land survey
error modeling. <em>SOCO</em>, <em>24</em>(19), 14687–14705. (<a
href="https://doi.org/10.1007/s00500-020-04814-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In remote sensing, land cover classification of vegetation and water area from satellite image play a vital role for rural and urban planning and development. Existing algorithms of land cover classification require more sample image datasets for training. For existing algorithms, land cover classification of vegetation and water area is a challenging task because of mixed pixel and geometric distortion over boundary and curvature region. Mixed pixel affects the precise classification and measurement of land cover. Geometric distortion arises due to frame of isotropic and angular selectivity during image acquisition and affects the contour of land cover. In this paper, the proposed transverse dyadic wavelet transform (TDyWT) enhances and classifies vegetation and water area in land cover from LANDSAT image without training datasets. The proposed TDyWT uses Haar wavelet for decomposition and Burt 5 × 7 wavelet for reconstruction. The TDyWT enhances the contour, curvature, and boundary of vegetation and water area in LANDSAT image due to reversible and lifting properties of wavelet. TDyWT removes geometric distortion and spatial scale error of mixed pixel. In traditional land surveying spatial scale error reduction eliminates through total station and error modeling techniques. From the results, the proposed TDyWT algorithm classifies the area of subclass of vegetation and water with the 95\% of accuracy with respect to ground truth survey methods.},
  archive      = {J_SOCO},
  author       = {Prabu, M. and Shanker, N. R. and Celine Kavida, A. and Ganesh, E.},
  doi          = {10.1007/s00500-020-04814-x},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14687-14705},
  shortjournal = {Soft Comput.},
  title        = {Geometric distortion and mixed pixel elimination via TDYWT image enhancement for precise spatial measurement to avoid land survey error modeling},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Primary frequency regulation of a microgrid by deloaded
tidal turbines. <em>SOCO</em>, <em>24</em>(19), 14667–14685. (<a
href="https://doi.org/10.1007/s00500-020-04813-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, mindset of people is observed much more inclined towards the usage of renewable energy systems because of the environmentally friendly nature and the monetary advantages of fuel saving. However, since non-conventional sources are unpredictable in nature, consequently high penetration of these sources causes reliability and power quality issues. It inspires researchers to redefine or develop the frequency regulation strategies. This paper introduces a fractional-order control methodology to adapt the primary frequency regulation from deloaded tidal power generators on the basis of existing power constraints. It is ameliorated by inertia and damping control, primary frequency control, and supplementary frequency control of the system. The control processes are implemented through fractional controllers. The parameters of fractional controllers are tuned by imperialist competitive algorithm. To assess the effectiveness of the proposed controller, simulated outcomes are evaluated with conventional controller. Besides this, the ICA-based controller results are also compared with other algorithms such as particle swarm optimization and genetic algorithm. An improvement in performance index from 16.11 to 22.80\% is reported with proposed control strategy.},
  archive      = {J_SOCO},
  author       = {Zaheeruddin and Singh, Kavita},
  doi          = {10.1007/s00500-020-04813-y},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14667-14685},
  shortjournal = {Soft Comput.},
  title        = {Primary frequency regulation of a microgrid by deloaded tidal turbines},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Red deer algorithm (RDA): A new nature-inspired
meta-heuristic. <em>SOCO</em>, <em>24</em>(19), 14637–14665. (<a
href="https://doi.org/10.1007/s00500-020-04812-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nature has been considered as an inspiration of several recent meta-heuristic algorithms. This paper firstly studies and mimics the behavior of Scottish red deer in order to develop a new nature-inspired algorithm. The main inspiration of this meta-heuristic algorithm is to originate from an unusual mating behavior of Scottish red deer in a breading season. Similar to other population-based meta-heuristics, the red deer algorithm (RDA) starts with an initial population called red deers (RDs). They are divided into two types: hinds and male RDs. Besides, a harem is a group of female RDs. The general steps of this evolutionary algorithm are considered by the competition of male RDs to get the harem with more hinds via roaring and fighting behaviors. By solving 12 benchmark functions and important engineering as well as multi-objective optimization problems, the superiority of the proposed RDA shows in comparison with other well-known and recent meta-heuristics.},
  archive      = {J_SOCO},
  author       = {Fathollahi-Fard, Amir Mohammad and Hajiaghaei-Keshteli, Mostafa and Tavakkoli-Moghaddam, Reza},
  doi          = {10.1007/s00500-020-04812-z},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14637-14665},
  shortjournal = {Soft Comput.},
  title        = {Red deer algorithm (RDA): A new nature-inspired meta-heuristic},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stability analysis of dynamic nonlinear interval type-2 TSK
fuzzy control systems based on describing function. <em>SOCO</em>,
<em>24</em>(19), 14623–14636. (<a
href="https://doi.org/10.1007/s00500-020-04811-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the limit cycles prediction problem to discuss the stability analysis of dynamic nonlinear interval type-2 Takagi–Sugeno–Kang fuzzy control systems (NIT2 TSK FCSs) with adjustable parameters. First, in order to alleviate computational burden, a simple architecture of NIT2 TSK FCS using two embedded nonlinear type-1 TSK fuzzy control systems (NT1 TSK FCSs) is proposed. Then, describing function (DF) of NIT2 TSK FCS is obtained based on the DFs of embedded NT1 TSK FCSs. Subsequently, integrating the stability equation and parameter plane approaches provides a solution to identify the limit cycle and the asymptotically stable regions. Moreover, particle swarm optimization technique is applied to minimize the limit cycle region. Furthermore, for robust design, a gain-phase margin tester is utilized to specify the minimum gain margin ( $$\hbox {GM}_{\mathrm{min}}$$ ) and phase margin ( $$\hbox {PM}_{\mathrm{min}}$$ ) when limit cycles can arise. Finally, two simulation examples are considered to validate the advantages of the presented method.},
  archive      = {J_SOCO},
  author       = {Namadchian, Zahra and Zare, Assef},
  doi          = {10.1007/s00500-020-04811-0},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14623-14636},
  shortjournal = {Soft Comput.},
  title        = {Stability analysis of dynamic nonlinear interval type-2 TSK fuzzy control systems based on describing function},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient solving of strategic bidding issues under no
karush–kuhn–tucker optimality constraints. <em>SOCO</em>,
<em>24</em>(19), 14611–14622. (<a
href="https://doi.org/10.1007/s00500-020-04809-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A typical bidding procedure is to maximize the profit of the strategic producers, in a manner that the offer curve yields solutions to the ISO marketing clearing problem. The literature portrays the procedure in the form of a searching problem with dual levels, wherein the minimization of the market clearing function along with profit maximization is yielded using the offer curve. But, the elevated levels of complexity in computing and solving the bi-level searching problem have forced the researchers to transform it as a one-level maximization problem through employing Karush–Kuhn–Tucker (KKT) optimality conditions. Yet, serious problems emerge with the profit maximization algorithms incorporating KKT optimality conditions (for instance, the classical optimization algorithms). The complexity grows in size, if the transmission constraints get vital in the deregulated environment. Our research contribution devises the profit maximization problem to be a minimization function, lacking consideration on KKT optimality conditions for the ISO market clearing functions, the operating limits and the transmission constraints. A modified form of group search optimizer (GSO), one of the currently popular optimization algorithms, provides solutions to the developed model. The conventional GSO, an optimization algorithm that operates using population, has its motivation from the animals’ searching activities. The modified GSO changes the maximum pursuit angle of the animal searching activity relative to the number of iterations. The testing of the proposed method employs both the IEEE 30 bus system as well as the IEEE 14 bus system. Performance comparison among the proposed method, the strategic bidding approaches that rely on the particle swarm optimization, the genetic algorithm and the GSO reveal excessive profit maximization and superiority for the proposed method.},
  archive      = {J_SOCO},
  author       = {Yadav, Naresh Kumar},
  doi          = {10.1007/s00500-020-04809-8},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14611-14622},
  shortjournal = {Soft Comput.},
  title        = {Efficient solving of strategic bidding issues under no Karush–Kuhn–Tucker optimality constraints},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). BiPhase adaptive learning-based neural network model for
cloud datacenter workload forecasting. <em>SOCO</em>, <em>24</em>(19),
14593–14610. (<a
href="https://doi.org/10.1007/s00500-020-04808-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing promises elasticity, flexibility and cost-effectiveness to satisfy service level agreement conditions. The cloud service providers should plan and provision the computing resources rapidly to ensure the availability of infrastructure to match the demands with closed proximity. The workload prediction has become critical as it can be helpful in managing the infrastructure effectively. In this paper, we present a workload forecasting framework based on neural network model with supervised learning technique. An improved and adaptive differential evolution algorithm is developed to improve the learning efficiency of predictive model. The algorithm is capable of optimizing the best suitable mutation operator and crossover operator. The prediction accuracy and convergence rate of the learning are observed to be improved due to its adaptive behavior in pattern learning from sampled data. The predictive model’s performance is evaluated on four real-world data traces including Google cluster trace and NASA Kennedy Space Center logs. The results are compared with state-of-the-art methods, and improvements up to 91\%, 97\% and 97.2\% are observed over self-adaptive differential evolution, backpropagation and average-based workload prediction techniques, respectively.},
  archive      = {J_SOCO},
  author       = {Kumar, Jitendra and Saxena, Deepika and Singh, Ashutosh Kumar and Mohan, Anand},
  doi          = {10.1007/s00500-020-04808-9},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14593-14610},
  shortjournal = {Soft Comput.},
  title        = {BiPhase adaptive learning-based neural network model for cloud datacenter workload forecasting},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). SETJoin: A novel top-k similarity join algorithm.
<em>SOCO</em>, <em>24</em>(19), 14577–14592. (<a
href="https://doi.org/10.1007/s00500-020-04807-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an important operation in data cleaning, near duplicate Web pages detection and data mining, similarity joins have received much attention recently. Existing similarity joins fall into two broad categories—the similarity-threshold-based similarity join and top-k similarity join (TopkJoin). Compared with the traditional one, TopkJoin is more suitable for cases where the similarity threshold is unknown before hand. In this paper, we focus on the performance optimization problem of TopkJoin. Particularly, we observed that the state-of-the-art TopkJoin algorithm has three serious performance issues, i.e., the inappropriate application of hash table, inefficient use of suffix filtering and unnecessary evaluation of excessive unqualified candidates. To resolve these problems, we proposed a novel algorithm, SETJoin, by combining the existing event-driven framework with three simple yet efficient optimization techniques, viz., (1) reducing the cost in hashing by rearranging the orders of the candidate filtering and hash table lookup operations; (2) maximizing the pruning capability of suffix filtering by judiciously choosing the (near) optimal recursion depth; and (3) terminating join operations earlier by setting a much tighter stop condition for iteration. The experimental results show that SETJoin achieves up to 1.26x–3.49x speedup over the state-of-the-art algorithm on several real datasets.},
  archive      = {J_SOCO},
  author       = {Wang, Hongya and Yang, Lihong and Xiao, Yingyuan},
  doi          = {10.1007/s00500-020-04807-w},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14577-14592},
  shortjournal = {Soft Comput.},
  title        = {SETJoin: A novel top-k similarity join algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modeling of UCS value of stabilized pond ashes using
adaptive neuro-fuzzy inference system and artificial neural network.
<em>SOCO</em>, <em>24</em>(19), 14561–14575. (<a
href="https://doi.org/10.1007/s00500-020-04806-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the capability of adaptive neuro-fuzzy inference system (ANFIS) and artificial neural network (ANN) modeling approach to predict the unconfined compressive strength (UCS) of stabilized pond ashes with lime alone and in combination with lime sludge. Out of 170 data set, a total of 119 data were randomly selected for training, whereas remaining 51 were used for testing the model. Four membership’s functions (MFs) such as Gaussian, generalized bell-shaped, triangular, and trapezoidal were used with ANFIS model. Statistical parameters were used to compare the performance of four MF-based ANFIS and ANN models. A comparison of results suggests that Triangular MF-based ANFIS model exhibit better predictive performance with higher CC = 0.980 and lower MSE = 3028.515 and RMSE = 55.032 than other MF-based ANFIS and ANN model. The results of single-factor analysis of variance indicate that there is an insignificant difference between measured and predicted values of UCS using different models. Further, results of sensitivity analysis depict that the curing period, lime sludge, and lime are the most important parameters which affect the performance of Triangular MF-based ANFIS in predicting the UCS of stabilized pond ashes. Thus, the Triangular MF-based ANFIS model could be a useful tool in predicting the UCS value of stabilized pond ashes because of its adequacy in handling uncertainties in the test results with accuracy.},
  archive      = {J_SOCO},
  author       = {Suthar, Manju},
  doi          = {10.1007/s00500-020-04806-x},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14561-14575},
  shortjournal = {Soft Comput.},
  title        = {Modeling of UCS value of stabilized pond ashes using adaptive neuro-fuzzy inference system and artificial neural network},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Huffman quantization approach for optimized EEG signal
compression with transformation technique. <em>SOCO</em>,
<em>24</em>(19), 14545–14559. (<a
href="https://doi.org/10.1007/s00500-020-04804-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The significance of the electroencephalography (EEG) signal is used to read the brain activity in the form of electrical patterns. EEG signals help to diagnose anomalies in the brain at the time of head injuries, epilepsy, seizures, brain tumor, dizziness and sleep deprivation. So such types of crucial signals should be transported in a secure method to avoid any data loss or to prevent noise interruptions which can lead to the misdetection of diseases. As the EEG signals are in higher-dimensional size, it should be compressed for effective transportation. In this research, a lossless compression method named as Huffman-based discrete cosine transform is implemented to transmit the EEG data efficiently. The discrete cosine transform and inverse discrete cosine transform are proposed here to increase the privacy of the data and reduce the complexity of the data. This paper mainly focuses on to get a high accuracy ratio in reconstructing the original data after compression and transportation without any losses in minimum computational time. The preprocessing and sampling are made at the initial stages to remove the noises and transmit the original data. The Huffman quantization method based on discrete cosine transform achieves high-performance metrics in terms of peak signal-to-noise ratio, quality score and compression ratio when compared with existing methods in various transformations of data.},
  archive      = {J_SOCO},
  author       = {Rajasekar, P. and Pushpalatha, M.},
  doi          = {10.1007/s00500-020-04804-z},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14545-14559},
  shortjournal = {Soft Comput.},
  title        = {Huffman quantization approach for optimized EEG signal compression with transformation technique},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improvising the performance of image-based recommendation
system using convolution neural networks and deep learning.
<em>SOCO</em>, <em>24</em>(19), 14531–14544. (<a
href="https://doi.org/10.1007/s00500-020-04803-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation systems now hold special significance, for in a world full of choices, order is the need of the hour. Without proper sorting, the gift of choice means nothing. The online retail world is fast-paced and ever-growing. With the exponential waning of attention span, it has become crucial to convert a casual visitor into a buyer within a limited window. Different ways can be used to do this: analysing buying patterns, surveys, user–user relationships, user-item relationships, and so on. This can be done with simple data analysis or with complex algorithms—the data must be harnessed one way or another. Deep learning is a branch of machine learning that has now become synonymous with computer vision, as these deep architectures closely emulate the biological process of vision. In this paper, the primary focus is the incorporation of a recommendation system with the visual features of products. This is done with the help of a deep architecture and a series of “convolution” operations that cause the overlapping of edges and blobs in images. We find that when the dimensionality problem has been dealt with, the features extracted serve as good quality representations of the images. Our empirical study compares the different linear and nonlinear reduction techniques on convolutional neural network features for building a recommendation model entirely based on the images.},
  archive      = {J_SOCO},
  author       = {Sulthana, A. Razia and Gupta, Maulika and Subramanian, Shruthi and Mirza, Sakina},
  doi          = {10.1007/s00500-020-04803-0},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14531-14544},
  shortjournal = {Soft Comput.},
  title        = {Improvising the performance of image-based recommendation system using convolution neural networks and deep learning},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A review of data replication based on meta-heuristics
approach in cloud computing and data grid. <em>SOCO</em>,
<em>24</em>(19), 14503–14530. (<a
href="https://doi.org/10.1007/s00500-020-04802-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous distributed computing environments are emerging for developing data-intensive (big data) applications that require to access huge data files. Therefore, effective data management like efficient access and data availability has become critical requirement in these systems. Data replication is an essential technique applied to achieve these goals through storing multiple replicas in a wisely manner. There are replication algorithms that address some metrics such as reliability, availability, bandwidth consumption, storage usage, response time. In this paper, we present different issues involved in data replication and discuss the key points of the recent algorithms with a tabular representation of all those features. The focus of the review is the existing algorithms of data replication that are based on the meta-heuristic techniques. This review will enable the readers to see that previous studies contributed response time to the data replication, but the contribution of the energy consumption and security improvement has not been considerable well. Moreover, the impact of meta-heuristic algorithms on data replication performance is investigated in a simulation study. Finally, open issues and future challenges have been presented in this research work.},
  archive      = {J_SOCO},
  author       = {Mansouri, Najme and Javidi, Mohammad Masoud},
  doi          = {10.1007/s00500-020-04802-1},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14503-14530},
  shortjournal = {Soft Comput.},
  title        = {A review of data replication based on meta-heuristics approach in cloud computing and data grid},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improving the prediction rate of unusual behaviors of animal
in a poultry using deep learning technique. <em>SOCO</em>,
<em>24</em>(19), 14491–14502. (<a
href="https://doi.org/10.1007/s00500-020-04801-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Poultry farms across the world house animals such as cows, sheep’s, pigs and hen These farms are the places from where the market gets meat, eggs, wool and other animal products which are used in our daily lives. But sometimes the business of the farms is severely hit primarily due to poultry animals catching diseases or these animals succumbing to injuries caused due to fighting each other. The identification of such animals showing unusual characteristics or behavior is necessary. We through our paper use deep learning concepts to help the poultry owner to identify these unusual characteristics in a sheep. Some of the characteristics that our paper identifies are skinny, redness, non-aggression, aggression, beefy and foraging. Our paper makes use of a video, shot from a camera and the implementation of a sequential model as well as make use of the SSD algorithm to identify and characterize the sheep’s depicted in the video. The sequential model is trained using the training dataset which contains static images of sheep’s and the attribute/characteristics depicted by those sheep’s that are stored in a CSV file. The testing dataset contains the images that are extracted from the input video as frames. The testing dataset is passed through the sequential model to get the characteristics/attributes depicted by the sheep in each frame and store those characteristics/attributes in a CSV file. The SSD algorithm is trained on identifying the various animals and not only does it display the name of the animal detected, it displays the confidence percentage of the animal as well, in our paper it is used for identifying sheep. The above stated algorithm also creates a border around the identified sheep such that it can be used for tracking purposes during the entirety of the video. The SSD algorithm also takes in the attributes depicted by these frames and displays them along the border which identifies the sheep. The accuracy is compared with YOLO algorithms and shows 3 to 6\% improvement on prediction rate.},
  archive      = {J_SOCO},
  author       = {Thenmozhi, M. and Saravanan, M. and Kumar, K. Pradeep Mohan and Suseela, S. and Deepan, S.},
  doi          = {10.1007/s00500-020-04801-2},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14491-14502},
  shortjournal = {Soft Comput.},
  title        = {Improving the prediction rate of unusual behaviors of animal in a poultry using deep learning technique},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-warehouse partial backlogging inventory system with
inflation for non-instantaneous deteriorating multi-item under imprecise
environment. <em>SOCO</em>, <em>24</em>(19), 14471–14490. (<a
href="https://doi.org/10.1007/s00500-020-04800-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we explored a multi-item inventory model for non-instantaneous deteriorating items under inflation in fuzzy rough environment with multiple warehouse facilities, where one is an owned warehouse and others are rented warehouses with limited storage capacity. Due to a number of uncertainties in the environment, the various expenditures and coefficients are considered as a fuzzy rough type. The objective and constraints in fuzzy rough are made deterministic using Tr–Pos chance constrained technique. The demand of items is considered as stock dependent, and deterioration of items is assumed to be constant over time. The model allows shortages in owned warehouse subject to partial backlogging. The purpose of this study is to find the retailer’s optimal replenishment policies to maximize the total profit. To illustrate the proposed model and also test the validity of the same, a numerical example is solved using the Mathematica-8.0 software. Sensitivity analysis is also performed to study the impact of important parameters on system decision variables, and its implications are discussed.},
  archive      = {J_SOCO},
  author       = {Chakraborty, Dipankar and Jana, Dipak Kumar and Roy, Tapan Kumar},
  doi          = {10.1007/s00500-020-04800-3},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14471-14490},
  shortjournal = {Soft Comput.},
  title        = {Multi-warehouse partial backlogging inventory system with inflation for non-instantaneous deteriorating multi-item under imprecise environment},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Choquet integration by simpson’s rule with application in
hellinger distance. <em>SOCO</em>, <em>24</em>(19), 14463–14470. (<a
href="https://doi.org/10.1007/s00500-020-04798-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In non-additive measure theory, there are a few studies on the numerical Choquet integral in continuous case on real line. Recently, based on the statistics software R, Torra and Narukawa (Inf Fusion 31:137–145, 2016) considered the problem of computing a numerical Choquet integral and some algorithms for Hellinger distance between two monotone measures. In this paper, the composite Simpson rule for numerical Choquet integration is proposed. Then some algorithms in Mathematica software are given. As well as, CPU time of the Examples in terms of seconds is reported which shows, in computational view, the presented method has a high speed.},
  archive      = {J_SOCO},
  author       = {Agahi, Hamzeh and Behroozifar, Mahmoud},
  doi          = {10.1007/s00500-020-04798-8},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14463-14470},
  shortjournal = {Soft Comput.},
  title        = {Choquet integration by simpson’s rule with application in hellinger distance},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-sensor data fusion for accurate surface modeling.
<em>SOCO</em>, <em>24</em>(19), 14449–14462. (<a
href="https://doi.org/10.1007/s00500-020-04797-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-sensor data fusion is advantageous while fusing data from heterogeneous range sensors, for scanning a scene containing both fine and coarse details. This paper presents a new multi-sensor range data fusion method with the aim to increase the descriptive contents of the entire generated surface model. First, a new training framework of the scanned range dataset to solve the relaxed Gaussian mixture model-based method by applying the convex relaxation technique is presented. The classification of the range data is based on a trained statistical model. In the data fusion experiments, a laser range sensor and Kinect (V1) are used. Based on the segmentation criterion, the range data fusion is performed by integration of the finer regions range data obtained from a laser range sensor with the coarser regions of the Kinect range data. The fused range information overcomes the weaknesses of the respective range sensors, i.e., the laser scanner is accurate but takes time while the Kinect is fast but not very accurate. The surface model of the fused range dataset generates a highly accurate, realistic surface model of the scene. The experimental results demonstrate robustness of the proposed approach.},
  archive      = {J_SOCO},
  author       = {Singh, Mahesh K. and Dutta, Ashish and Venkatesh, K. S.},
  doi          = {10.1007/s00500-020-04797-9},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14449-14462},
  shortjournal = {Soft Comput.},
  title        = {Multi-sensor data fusion for accurate surface modeling},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Time-dependent intuitionistic fuzzy system reliability
analysis. <em>SOCO</em>, <em>24</em>(19), 14441–14448. (<a
href="https://doi.org/10.1007/s00500-020-04796-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of the present paper is to provide a method for constructing time-dependent reliability systems based on intuitionistic fuzzy random variables. A lifetime variable cannot be precisely recorded due to machine errors, experimentation pitfalls, personal judgments, estimation errors or other unexpected sources of error. In order to satisfy the purpose of this paper, an intuitionistic fuzzy random variable with exact parameters was introduced and adopted to evaluate the reliability functions of a k-out-of-n system, with some reliability evaluation criteria discussed and interpreted. Numerical evaluations were further presented to illustrate the calculation of the system reliability criteria in the form of intuitionistic fuzzy numbers. Finally, a number of potential engineering applications of the proposed method were presented.},
  archive      = {J_SOCO},
  author       = {Akbari, Mohammad Ghasem and Hesamian, Gholamreza},
  doi          = {10.1007/s00500-020-04796-w},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14441-14448},
  shortjournal = {Soft Comput.},
  title        = {Time-dependent intuitionistic fuzzy system reliability analysis},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Copy-move forgery detection using SURF feature extraction
and SVM supervised learning technique. <em>SOCO</em>, <em>24</em>(19),
14429–14440. (<a
href="https://doi.org/10.1007/s00500-020-04795-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of computer vision is to identify objects of interest from images. Copy-move forgery is the process of copying one or more parts of an image and moved into another part of an equivalent image. The detection of copy-move images has many limitations in recognition of objects. In this paper, the proposed work uses Speeded Up Robust Feature (SURF) feature extraction, and the specific object is recognized with the help of the support vector machine. When copy-move forgery was performed, some modifications were done to the image. For instance, turning, scaling, darkening, compression, and noise addition are applied to make effective impersonation forgeries. Here, feature matching process uses the image rotate function, which consists of bicubic and crop operations, and calculates the difference using the blend, scale and joint operation. The results show that forged images are extracted from a given set of test images. The test results exhibit that the proposed technique can get noteworthy and impressive results.},
  archive      = {J_SOCO},
  author       = {Dhivya, S. and Sangeetha, J. and Sudhakar, B.},
  doi          = {10.1007/s00500-020-04795-x},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14429-14440},
  shortjournal = {Soft Comput.},
  title        = {Copy-move forgery detection using SURF feature extraction and SVM supervised learning technique},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). State-of-the-art fuzzy active contour models for image
segmentation. <em>SOCO</em>, <em>24</em>(19), 14411–14427. (<a
href="https://doi.org/10.1007/s00500-020-04794-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image segmentation is the initial step for every image analysis task. A large variety of segmentation algorithm has been proposed in the literature during several decades with some mixed success. Among them, the fuzzy energy-based active contour models get attention to the researchers during last decade which results in development of various methods. A good segmentation algorithm should perform well in a large number of images containing noise, blur, low contrast, region in-homogeneity, etc. However, the performances of the most of the existing fuzzy energy-based active contour models have been evaluated typically on the limited number of images. In this article, our aim is to review the existing fuzzy active contour models from the theoretical point of view and also evaluate them experimentally on a large set of images under the various conditions. The analysis under a large variety of images provides objective insight into the strengths and weaknesses of various fuzzy active contour models. Finally, we discuss several issues and future research direction on this particular topic.},
  archive      = {J_SOCO},
  author       = {Mondal, Ajoy and Ghosh, Kuntal},
  doi          = {10.1007/s00500-020-04794-y},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14411-14427},
  shortjournal = {Soft Comput.},
  title        = {State-of-the-art fuzzy active contour models for image segmentation},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Isomorphism on generalized fuzzy graphs and image
visualizations. <em>SOCO</em>, <em>24</em>(19), 14401–14409. (<a
href="https://doi.org/10.1007/s00500-020-05260-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The graph theory is being used for representation in networks and chemical atomic structures very frequently. However, these days, uncertainties are imposed on such networks. Isomorphism in generalized fuzzy graphs has been introduced here to capture the similarity of uncertainties in different networks. Homomorphism, weak isomorphism, co-weak isomorphism and nearly isomorphism are defined with examples. Also, an application of image visualization is described.},
  archive      = {J_SOCO},
  author       = {Samanta, Sovan and Sarkar, Biswajit},
  doi          = {10.1007/s00500-020-05260-5},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14401-14409},
  shortjournal = {Soft Comput.},
  title        = {Isomorphism on generalized fuzzy graphs and image visualizations},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Orthomodular lattices as l-algebras. <em>SOCO</em>,
<em>24</em>(19), 14391–14400. (<a
href="https://doi.org/10.1007/s00500-020-05242-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We first prove that the axioms system of orthomodular L-algebra (O-L-algebras for short) as given in [Rump: Forum Mathematicum, 30(4), 2018: 973–995] are not independent by giving an independent axiom one. Then, two conditions for KL-algebras to be Boolean are provided. Furthermore, some theorems of Holland are reproved using the self-similar closure of OM-L-algebras. In particular, the monoid operation of the self-similar closure is shown to be commutative.},
  archive      = {J_SOCO},
  author       = {Wu, Yali and Yang, Yichuan},
  doi          = {10.1007/s00500-020-05242-7},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14391-14400},
  shortjournal = {Soft Comput.},
  title        = {Orthomodular lattices as L-algebras},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mendelian evolutionary theory optimization algorithm.
<em>SOCO</em>, <em>24</em>(19), 14345–14390. (<a
href="https://doi.org/10.1007/s00500-020-05239-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presented a new multi-species binary coded algorithm, Mendelian evolutionary theory optimization (METO), inspired by the plant genetics. This framework mainly consists of three concepts: first, the “denaturation” of DNA’s of two different species to produce the hybrid “offspring DNA”. Second, the Mendelian evolutionary theory of genetic inheritance, which explains how the dominant and recessive traits appear in two successive generations. Third, the Epimutation, through which organism resist for natural mutation. The above concepts are reconfigured in order to design the binary meta-heuristic evolutionary search technique. Based on this framework, four evolutionary operators—(1) Flipper, (2) Pollination, (3) Breeding, and (4) Epimutation—are created in the binary domain. In this paper, METO is compared with well-known evolutionary and swarm optimizers: (1) binary hybrid GA, (2) bio-geography-based optimization, (3) invasive weed optimization, (4) shuffled frog leap algorithm, (5) teaching–learning-based optimization, (6) cuckoo search, (7) bat algorithm, (8) gravitational search algorithm, (9) covariance matrix adaptation evolution strategy, (10) differential evolution, (11) firefly algorithm and (12) social learning PSO. This comparison is evaluated on 30 and 100 variables benchmark test functions, including noisy, rotated, and hybrid composite functions. Kruskal–Wallis statistical rank-based nonparametric H-test is utilized to determine the statistically significant differences between the output distributions of the optimizer, which are the result of the 100 independent runs. The statistical analysis shows that METO is a significantly better algorithm for complex and multi-modal problems with many local extremes.},
  archive      = {J_SOCO},
  author       = {Gupta, Neeraj and Khosravy, Mahdi and Patel, Nilesh and Dey, Nilanjan and Mahela, Om Prakash},
  doi          = {10.1007/s00500-020-05239-2},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14345-14390},
  shortjournal = {Soft Comput.},
  title        = {Mendelian evolutionary theory optimization algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). EBL-algebras. <em>SOCO</em>, <em>24</em>(19), 14333–14343.
(<a href="https://doi.org/10.1007/s00500-020-05235-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we define the notion of EBL-algebras, which are generalizations of BL-algebras and EMV-algebras. The notions of ideals, congruences and filters in EBL-algebras are introduced, and their mutual relationships are investigated. There is a one-to-one correspondence between the set of all ideals in an EBL-algebra and the set of all congruences on an EBL-algebra. Moreover, we give a representation theorem on EBL-algebras. Every proper EBL-algebras under some condition can be embedded into an EBL-algebras with a top element as an ideal.},
  archive      = {J_SOCO},
  author       = {Liu, Hongxing},
  doi          = {10.1007/s00500-020-05235-6},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14333-14343},
  shortjournal = {Soft Comput.},
  title        = {EBL-algebras},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Basic algebras and l-algebras. <em>SOCO</em>,
<em>24</em>(19), 14327–14332. (<a
href="https://doi.org/10.1007/s00500-020-05231-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the relation between L-algebras and basic algebras. In particular, we construct a lattice-ordered effect algebra which improves an example of Chajda et al. (Algebra Univ 60(1), 63–90, 2009).},
  archive      = {J_SOCO},
  author       = {Wang, Jing and Wu, Yali and Yang, Yichuan},
  doi          = {10.1007/s00500-020-05231-w},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14327-14332},
  shortjournal = {Soft Comput.},
  title        = {Basic algebras and L-algebras},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-strategy synergy-based backtracking search
optimization algorithm. <em>SOCO</em>, <em>24</em>(19), 14305–14326. (<a
href="https://doi.org/10.1007/s00500-020-05225-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to solve the problems of backtracking search optimization algorithm with slow convergence speed and easy to fall into local optimum, an improved backtracking search optimization algorithm based on multi-strategy synergy is proposed. Foremost, a combination mutation strategy based on chaotic map and gamma distribution is introduced. The poor individuals are mutated to generate better quality individuals under a certain probability. Next, the global optimal individual information is introduced into the cross equation to guide the population update. Last but not least, a small habitat displacement method based on simulated annealing is designed. The poor individual is found by the niche radius, and the rich individuals are reconstructed by the global optimal individual information and the Gaussian distribution random function, and the convergence speed of the algorithm is improved. The simulated annealing algorithm is integrated on the niche technology to ensure the diversity of the new population and improve the convergence speed of the algorithm. In this paper, some standard test functions are selected, and numerical simulations are carried out in low-dimensional and high-dimensional states, compared with seven well-performing algorithms. The improved algorithm was analyzed by complexity, T test and ANOVA test. Simulation experiments on 20 standard test functions show that the improved algorithm has a faster convergence speed and higher convergence accuracy. Even in a high-dimensional multi-peak function, the convergence accuracy of the improved algorithm after the same number of iterations is 15 times higher than the original algorithm above the magnitude.},
  archive      = {J_SOCO},
  author       = {Wei, Fengtao and Shi, Yunpeng and Li, Junyu and Zhang, Yangyang},
  doi          = {10.1007/s00500-020-05225-8},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14305-14326},
  shortjournal = {Soft Comput.},
  title        = {Multi-strategy synergy-based backtracking search optimization algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Positive influence maximization in signed social networks
under independent cascade model. <em>SOCO</em>, <em>24</em>(19),
14287–14303. (<a
href="https://doi.org/10.1007/s00500-020-05195-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For existing methods for positive influence maximization in signed networks, two factors prevent them from getting high-quality results. First, very few researchers consider the critical effect of negative edges on influence propagation. Second, most of those methods use Monte Carlo simulation to estimate the influence propagating of each candidate seed set. Such time-consuming simulation process hinders the application of those methods in solving real-world problems. Motivated by these limitations, this study investigates the problem of positive influence maximization in competitive signed networks. First, an opposite influence propagating model is defined by a set of propagation rules, where negative links play a more critical role than the positive ones. Second, an influence propagation function is defined to estimate the positive influence propagating of a seed set. Using such influence propagation function, the process of simulation can be avoided, and the computation time can be reduced greatly. An algorithm is presented to select the seed nodes which can obtain the largest positive influence spreading in the signed network. The algorithm employs the greedy strategy to sequentially select the seed nodes according to their spreading increments, which are estimated by the influence propagation function. Experimental results on real-world social networks show that our algorithm consistently outperforms the state-of-the-art in terms of solution quality and is several orders of magnitude faster than other methods.},
  archive      = {J_SOCO},
  author       = {Sheng, Jun and Chen, Ling and Chen, Yixin and Li, Bin and Liu, Wei},
  doi          = {10.1007/s00500-020-05195-x},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14287-14303},
  shortjournal = {Soft Comput.},
  title        = {Positive influence maximization in signed social networks under independent cascade model},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The logic induced by effect algebras. <em>SOCO</em>,
<em>24</em>(19), 14275–14286. (<a
href="https://doi.org/10.1007/s00500-020-05188-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effect algebras form an algebraic formalization of the logic of quantum mechanics. For lattice effect algebras $${\mathbf {E}}$$ , we investigate a natural implication and prove that the implication reduct of $${\mathbf {E}}$$ is term equivalent to $${\mathbf {E}}$$ . Then, we present a simple axiom system in Gentzen style in order to axiomatize the logic induced by lattice effect algebras. For effect algebras which need not be lattice-ordered, we introduce a certain kind of implication which is everywhere defined but whose result need not be a single element. Then, we study effect implication algebras and prove the correspondence between these algebras and effect algebras satisfying the ascending chain condition. We present an axiom system in Gentzen style also for not necessarily lattice-ordered effect algebras and prove that it is an algebraic semantics for the logic induced by finite effect algebras.},
  archive      = {J_SOCO},
  author       = {Chajda, Ivan and Halaš, Radomír and Länger, Helmut},
  doi          = {10.1007/s00500-020-05188-w},
  journal      = {Soft Computing},
  number       = {19},
  pages        = {14275-14286},
  shortjournal = {Soft Comput.},
  title        = {The logic induced by effect algebras},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Flash flood potential prioritization of sub-basins in an
ungauged basin in turkey using traditional multi-criteria
decision-making methods. <em>SOCO</em>, <em>24</em>(18), 14251–14263.
(<a href="https://doi.org/10.1007/s00500-020-04792-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Morphometric analysis of watersheds based on morphometric parameters is the most widely accepted method for watershed prioritization. However, traditional methods adopted for prioritization of sub-basins lack a standard classification of the morphometric parameters and ranges of their values. So, in this study several multi-criteria decision-making (MCDM) methods and a number of traditional methods are used for watershed prioritization regarding the flash flood potential of the sub-basins. Akçay, a small ungauged basin in Turkey, was chosen as the study area, and 12 morphometric parameters were determined for the basin. The geomorphological instantaneous unit hydrograph concept coupled with Monte Carlo analysis was used to estimate the flood yield of the basin due to the lack of flow data. Kendall tau and Spearman correlation coefficient tests and receiver operating characteristics analysis were performed to validate the results of the traditional methods and the MCDM approaches for prioritization of the sub-basins. Results showed that the AHP method could well predict the sub-basins with higher flood potential, while the methodology adopted in the study to determine the criteria weights obtained from ANP method in MCDM improved the prediction capability of those approaches, especially VIKOR. The initial values of criteria weights were determined to be effective on the predictions and sensitivity analysis. When the results of traditional methods and MCDM approaches were compared, the MCDM approaches were found to give improved results. This study showed that MCDM approaches can be used to provide an efficient management of basins regarding conservation of water resources and soil.},
  archive      = {J_SOCO},
  author       = {Akay, Hüseyin and Baduna Koçyiğit, Müsteyde},
  doi          = {10.1007/s00500-020-04792-0},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {14251-14263},
  shortjournal = {Soft Comput.},
  title        = {Flash flood potential prioritization of sub-basins in an ungauged basin in turkey using traditional multi-criteria decision-making methods},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Computer vision algorithms for dominant contact lens feature
extraction using fuzzy-logic-based classifications. <em>SOCO</em>,
<em>24</em>(18), 14235–14249. (<a
href="https://doi.org/10.1007/s00500-020-04791-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Iris image recognition is an emerging approach for human identification but offers low reliability. An algorithm for dominant contact lens feature extraction based on an improved neighboring binary pattern (NBP) approach is proposed herein. Features are compared with neighboring features in various directions, assigning a value of 1 to dominant features and 0 otherwise. The features in two-dimensional binary tables are then trained using an adaptive neuro fuzzy inference system (ANFIS) and classified using various classifiers. The performance of various feature descriptors based on the classification algorithms is measured and compared using parameters such as the accuracy, training time, positive acceptance rate (PAR), and negative acceptance rate (NAR), and the PAR and NAR are compared based upon a confusion matrix of classifiers. The proposed dominant feature extraction method achieves an accuracy rate of 95.7\%.},
  archive      = {J_SOCO},
  author       = {Gino Sophia, S. G. and Ceronmani Sharmila, V.},
  doi          = {10.1007/s00500-020-04791-1},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {14235-14249},
  shortjournal = {Soft Comput.},
  title        = {Computer vision algorithms for dominant contact lens feature extraction using fuzzy-logic-based classifications},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A binary differential evolution algorithm for airline
revenue management: A case study. <em>SOCO</em>, <em>24</em>(18),
14221–14234. (<a
href="https://doi.org/10.1007/s00500-020-04790-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the current highly competitive airline market, many companies have failed due to their low revenue rates. For this reason, many of them have to develop strategies to increase their revenue. In this study, we develop revenue management (RM) strategy for the Iranian airline industry. More specifically, we present a mathematical model that considers some conditions not studied in previous research in order to provide a more realistic RM modeling of airlines that fits well for the special characteristics of Iranian Airways. A binary differential evolution algorithm is employed to solve the model due to the stochastic nature of data and the NP-hardness of the considered problem. To generate maximum revenue among the six types of airplanes that fly the four capital cities of Iran, the airline under investigation is advised to operate only 21 flights to those cities and cancel the rest of the flights.},
  archive      = {J_SOCO},
  author       = {Karbassi Yazdi, Amir and Kaviani, Mohamad Amin and Hanne, Thomas and Ramos, Andres},
  doi          = {10.1007/s00500-020-04790-2},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {14221-14234},
  shortjournal = {Soft Comput.},
  title        = {A binary differential evolution algorithm for airline revenue management: A case study},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Performance analysis intelligent-based advanced PSO
algorithm and testing of real-time matrix converter electrical system.
<em>SOCO</em>, <em>24</em>(18), 14209–14220. (<a
href="https://doi.org/10.1007/s00500-020-04789-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advanced improvements in power electronic switches make the development of power electronic converters. This drastic development results the matrix converter (MC) evaluation. MC is a bidirectional power flow device with single-stage conversion process with variable voltage and variable frequency. The major drawback of MC is harmonic content present due to switching of power electronic devices. To reduce the harmonics present in the MC, lots of research works were carried out, but it is limited to some extent; beyond the limit, the harmonics can be reduced in MC by introducing soft computational algorithm-based controller. The PSO-based controller was implemented in the literature with resistive and inductive loads. In this paper, PSO-, modified PSO-, modified hybrid PSO-based controllers were implemented with induction motor as load. This soft computing-based controller for MC effectively reduces the harmonic content by choosing the optimal switching pulses for each sampling. The simulation results were carried out on the MATLAB/Simulink interface. Both Simulink and hardware results of the MC strongly recommend the soft computing-based controller for MC to improve the behavior.},
  archive      = {J_SOCO},
  author       = {Amarendra, Ch. and Reddy, K. Harinadha},
  doi          = {10.1007/s00500-020-04789-9},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {14209-14220},
  shortjournal = {Soft Comput.},
  title        = {Performance analysis intelligent-based advanced PSO algorithm and testing of real-time matrix converter electrical system},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new expert system in prediction of lung cancer disease
based on fuzzy soft sets. <em>SOCO</em>, <em>24</em>(18), 14179–14207.
(<a href="https://doi.org/10.1007/s00500-020-04787-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Every year, millions of people worldwide (including a major portion in China) are suffering from lung cancer disease (Chinese report of Smoking and Health 2017). The aim of this paper is to develop a new fuzzy soft expert system which can be used to predict lung cancer disease. A prediction process using this fuzzy soft expert system is composed of four main steps: (1) Transform real-valued inputs into fuzzy numbers. (2) Transform fuzzy numbers of data into fuzzy soft sets. (3) Reduce, using normal parameter reduction method, the obtained family of fuzzy soft sets into a new family of fuzzy soft sets. (4) Use the proposed algorithm to get the output data. An experiment is conducted on forty five patients (thirty males, fifteen females, all are cigarette smokers) who endure treatment in the Respiratory Department of Nanjing Chest Hospital, China. The number of training data taken was 55 records, and the remaining 45 records were used for the testing process in our system by using weight loss, shortness of breath, chest pain, persistence a cough, blood in sputum, and age of patients. The quantized accuracies of the proposed system were found to be $$100\%$$ . In this work, we developed a fuzzy soft expert system based on fuzzy soft sets; we used a fuzzy membership functions and an algorithm to predict those patients who may suffer lung cancer. In this way, it is possible to conclude that the use of fuzzy soft expert system can produce valuable results for lung cancer detection. It is found that the fuzzy soft expert system developed is useful to the expert doctor to decide if a patient has lung cancer or not. Finally, we introduce comparison diagnosed between our proposed system and the fuzzy inference system.},
  archive      = {J_SOCO},
  author       = {Khalil, Ahmed Mostafa and Li, Sheng-Gang and Lin, Yong and Li, Hong-Xia and Ma, Sheng-Guan},
  doi          = {10.1007/s00500-020-04787-x},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {14179-14207},
  shortjournal = {Soft Comput.},
  title        = {A new expert system in prediction of lung cancer disease based on fuzzy soft sets},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Soft computing model using cluster-PCA in port model for
throughput forecasting. <em>SOCO</em>, <em>24</em>(18), 14167–14177. (<a
href="https://doi.org/10.1007/s00500-020-04786-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the sequence of port throughput analysis, many nonlinear and fluctuation signals are included in order to find the accuracy of port. Besides the socioeconomic factors, the virtually decision making and execution are considered as some kind of forecast. The seasonality and volatility are the critical issues in predicting the efficiency. The forecasting is a useful tool to cross these issues. The forecasting uses many qualitative and casual models and performs time series analysis to find the information about events, pattern changes, relationship between the system elements. It assumes two different kinds of phenomena share the same model of behavior. One is to promote new issues and another is to predict the outcome of the analysis. The judgmental forecasting technique is based on present situation and past situation in order to predict the issues in port. To deal with these issues, this paper addresses a method of hyperchaotic model for optimizing the throughput based on PCA. We review the latest models to provide the theoretical basis and propose novel ideas; the proposed methodology is simulated compared with the other state-of-the-art approaches. The experimental analysis proves the robustness of the model. In the future, more scenarios will be tested.},
  archive      = {J_SOCO},
  author       = {Jiang, Liupeng and Jiang, He and Wang, Harry Haoxiang},
  doi          = {10.1007/s00500-020-04786-y},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {14167-14177},
  shortjournal = {Soft Comput.},
  title        = {Soft computing model using cluster-PCA in port model for throughput forecasting},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multiple-kernel combination fuzzy clustering for community
detection. <em>SOCO</em>, <em>24</em>(18), 14157–14165. (<a
href="https://doi.org/10.1007/s00500-020-04785-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection on social network is a challenging task, and the multiple-kernel learning method is gaining popularity. In this paper, we propose a new multiple-kernel combination algorithm for community partitioning. We study several base kernel matrices from the adjacency matrix of a network. By adjusting the weights of different base kernel matrices, a new kernel matrix is constructed using linear combination of those matrices. To partition networks whose number of communities are known in advance, we derive a new kernel matrix which forms a basis for community partitioning. We further propose a novel robust multiple-kernel combination-based fuzzy clustering algorithm. Extensive experiments are conducted on many real-world networks that contain ground truth on community structures. The experimental results indicate that the proposed algorithm is more efficient than other existing community detection methods and related kernel clustering algorithms. This study demonstrates the feasibility and efficiency of the multiple-kernel learning method for community detection.},
  archive      = {J_SOCO},
  author       = {Lu, Hu and Song, Yuqing and Wei, Hui},
  doi          = {10.1007/s00500-020-04785-z},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {14157-14165},
  shortjournal = {Soft Comput.},
  title        = {Multiple-kernel combination fuzzy clustering for community detection},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). One more look on visualization of operation of a
root-finding algorithm. <em>SOCO</em>, <em>24</em>(18), 14135–14155. (<a
href="https://doi.org/10.1007/s00500-020-04784-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many algorithms that iteratively find solution of an equation require tuning. Due to the complex dependence of many algorithm’s elements, it is difficult to know their impact on the work of the algorithm. The article presents a simple root-finding algorithm with self-adaptation that requires tuning, similarly to evolutionary algorithms. Moreover, the use of various iteration processes instead of the standard Picard iteration is presented. In the algorithm’s analysis, visualizations of the dynamics were used. The conducted experiments and the discussion regarding their results allow to understand the influence of tuning on the proposed algorithm. The understanding of the tuning mechanisms can be helpful in using other evolutionary algorithms. Moreover, the presented visualizations show intriguing patterns of potential artistic applications.},
  archive      = {J_SOCO},
  author       = {Gościniak, Ireneusz and Gdawiec, Krzysztof},
  doi          = {10.1007/s00500-020-04784-0},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {14135-14155},
  shortjournal = {Soft Comput.},
  title        = {One more look on visualization of operation of a root-finding algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Interval-valued intuitionistic fuzzy TODIM method based on
schweizer–sklar power aggregation operators and their applications to
group decision making. <em>SOCO</em>, <em>24</em>(18), 14091–14133. (<a
href="https://doi.org/10.1007/s00500-020-04783-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present work proposes a novel integrated group decision making framework for decision making in IVIF setting employing Schweizer–Sklar t-conorm and t-norm (SSTT) aggregation operators, power average (PA) operators and TODIM (an acronym in Portuguese of interactive and multiple attribute decision making) methods. The SSTT aggregation operators make the aggregation process more flexible and the PA operators relive the decision making process from unreasonable data arising out due to biased evaluations. The TODIM method, on the other hand, ranks the alternatives by giving due consideration to the psychological behaviour of the expert towards risk. The extension of PA and SSTT operators to IVIF give rise to the weighted averaging and weighted geometric operators and are referred to as IVIFSSPAWA and IVIFSSPAWG operators. These operators, on integration with the TODIM method, give rise to two group decision making frameworks and are referred to as IVIFSSPWA fuzzy TODIM and IVIFSSPWG fuzzy TODIM approaches. The applicability of the proposed methods has been demonstrated through five illustrative examples from different domains: material selection, personnel selection, supplier selection, facility evaluation and technology evaluation. A comprehensive evaluation of the proposed methods with the considered illustrative examples aided to reveal the strength and weaknesses of the proposed approaches. The comprehensive analysis shows that the proposed IVIFSSPWA fuzzy TODIM and IVIFSSPWG fuzzy TODIM methods are superior to the benchmarks considered in the present work and also other MCDM methods without SSTT and PA aggregation operators and those ignoring the criticality of risk attitude of the experts. The proposed methodology, therefore, enhances the way of dealing with fuzzy information and in a way provides an improvisation of current studies.},
  archive      = {J_SOCO},
  author       = {Zindani, Divya and Maity, Saikat Ranjan and Bhowmik, Sumit},
  doi          = {10.1007/s00500-020-04783-1},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {14091-14133},
  shortjournal = {Soft Comput.},
  title        = {Interval-valued intuitionistic fuzzy TODIM method based on Schweizer–Sklar power aggregation operators and their applications to group decision making},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Inverse–adaptive multilayer t–s fuzzy controller for
uncertain nonlinear system optimized by differential evolution
algorithm. <em>SOCO</em>, <em>24</em>(18), 14073–14089. (<a
href="https://doi.org/10.1007/s00500-020-04782-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper initiatively proposes a novel inverse–adaptive multilayer T–S fuzzy controller (IFC + AF) optimized with differential evolution (DE) soft computing algorithm available for a class of robust control methods applied in uncertain nonlinear SISO and MISO systems. First, a novel multilayer T–S fuzzy model is created by combined multiple simple T–S fuzzy models with a sum function in the output. Then, the parameters of multilayer T–S fuzzy model are optimally identified using DE algorithm to create offline the inverse nonlinear system regarding uncertain system parameters. Second, an adaptive fuzzy-based sliding-mode surface is innovatively designed to guarantee that the closed-loop system is asymptotically stable using Lyapunov stability principle. Moreover, necessary benchmark tests are investigated in MATLAB/Simulink platform, including the spring–mass–damper SMD system and the fluid level of a double tank with uncertain parameters, in order to illustrate the effectiveness and the feasibility of the proposed IFC + AF control scheme. The IFC + AF control algorithm is adequately investigated with various control coefficients and is strictly compared with the advanced adaptive fuzzy control and the inverse fuzzy control (IFC) approaches. Simulation and experiment results are satisfactorily investigated and demonstrate the feasibility and performance of the proposed IFC + AF control method.},
  archive      = {J_SOCO},
  author       = {Van Kien, Cao and Anh, Ho Pham Huy and Son, Nguyen Ngoc},
  doi          = {10.1007/s00500-020-04782-2},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {14073-14089},
  shortjournal = {Soft Comput.},
  title        = {Inverse–adaptive multilayer T–S fuzzy controller for uncertain nonlinear system optimized by differential evolution algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An improved brainstorm optimization using chaotic
opposite-based learning with disruption operator for global optimization
and feature selection. <em>SOCO</em>, <em>24</em>(18), 14051–14072. (<a
href="https://doi.org/10.1007/s00500-020-04781-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimization has increased its use in different domains for accurately solving challenging problems. Complex optimization problems require the use of methods that possess the capabilities to properly explore the search spaces. The traditional algorithms commonly tend to fail in suboptimal values during the optimization process; this fact affects the quality of the solutions. This situation occurs for different reasons, but the lack of diversity due to the use of exploitation operators is the most common. Brainstorm optimization is an alternative method based on the social strategy to generate new innovative ideas in work groups. In brainstorm optimization, each solution representing an idea and brainstorm process is performed using clustering algorithms. However, brainstorm optimization is not able to thoroughly explore the search space, and its diversity is reduced. It does not possess any mechanism to escape from suboptimal solutions. Besides, the computational effort is also increased in the iterative process. This paper presents a modified version of brainstorm optimization that improves its performance. In the proposed algorithm, chaotic maps and opposition-based learning are applied to initialize the solutions for a given problem. Moreover, in the optimization process, the positions of the initial population are updated using the disruptor operator. After updating the population, opposition-based learning is used again to analyze the opposite solutions. The combination of chaotic maps, opposition-based learning and disruption operator improve the exploration ability of brainstorm optimization by increasing the diversity of the population. The proposed method has been evaluated using a set of benchmark functions, and it has been also used for feature selection in data mining. The results show the high efficacy of the proposed method to determine the optimal solutions of the tested functions.},
  archive      = {J_SOCO},
  author       = {Oliva, Diego and Elaziz, Mohamed Abd},
  doi          = {10.1007/s00500-020-04781-3},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {14051-14072},
  shortjournal = {Soft Comput.},
  title        = {An improved brainstorm optimization using chaotic opposite-based learning with disruption operator for global optimization and feature selection},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Attribute reduction for multi-label classification based on
labels of positive region. <em>SOCO</em>, <em>24</em>(18), 14039–14049.
(<a href="https://doi.org/10.1007/s00500-020-04780-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, on the basis of the rough set theory, four attribute reduction algorithms are proposed for multi-label data. In order to improve the computational efficiency, the proposed algorithms utilize the lower approximations of the label information set instead of the decision class to evaluate the importance of attributes. The relationship between the proposed methods and two classical attribute reductions is analyzed and shows that the proposed methods are more applicable to multi-label classification. Experimental results reveal that the proposed algorithms can remove redundant attributes without reducing classification accuracy for most data.},
  archive      = {J_SOCO},
  author       = {Fan, Xiaodong and Chen, Qi and Qiao, Zhijun and Wang, Changzhong and Ten, Mingyan},
  doi          = {10.1007/s00500-020-04780-4},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {14039-14049},
  shortjournal = {Soft Comput.},
  title        = {Attribute reduction for multi-label classification based on labels of positive region},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Information reconciliation through an agent-controlled graph
model. <em>SOCO</em>, <em>24</em>(18), 14019–14037. (<a
href="https://doi.org/10.1007/s00500-020-04779-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancement of Internet technology and the rise of big data, securing information from malicious attacks has become more important; yet, more challenging. Even though prevention techniques exist, they are not enough to fully secure the data from malicious activities. This dictated the need for a detection and recovery model to assess the damage and bring the database back to its consistent state in case of an attack. This recovery should be done as quickly and efficiently as possible in order to avoid damage propagation and inaccurate access to data. Multiple models have been proposed, and different techniques and data structures were used to recover the database to its reliable state. In this work, we present a superior damage assessment and recovery algorithm that is centered on agents. Our hybrid lightweight approach is based on clustering database transactions based on a given set of criteria using graphs to keep track of transactional dependencies. This way, our model allows for: (1) parallel information processing—which makes recovery more effectual, (2) separation of concerns—which makes it easier to maintain a given data structure, (3) attack/problem isolation where a malicious transaction will be isolated from the remaining unharmed parts of database (the undamaged parts of the database can remain ‘live’ and there is no need to take them offline, and (4) easier scaling as bottlenecks are diminished. The presented approach is compared to other existing ones and exhibited superior performance.},
  archive      = {J_SOCO},
  author       = {Haraty, Ramzi A. and Saba, Rita},
  doi          = {10.1007/s00500-020-04779-x},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {14019-14037},
  shortjournal = {Soft Comput.},
  title        = {Information reconciliation through an agent-controlled graph model},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Generalized hesitant fuzzy rough sets (GHFRS) and their
application in risk analysis. <em>SOCO</em>, <em>24</em>(18),
14005–14017. (<a
href="https://doi.org/10.1007/s00500-020-04776-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a generalization of fuzzy rough sets, the concept of generalized hesitant fuzzy rough sets (GHFRS) is presented in this paper. It is an endeavor to define rough approximations of a collection of hesitant fuzzy sets over a given universe. To this end, elements of the universe are initially clustered using a set-valued map, and then, hesitant fuzzy sets are aggregated by using lower and upper approximation operators. These operators produce hesitant fuzzy sets which aggregate hesitant fuzzy elements. Structural and topological properties associated with GHFRS have been examined. The model is further employed to design a three-way decision analysis technique which preserves many properties of classical techniques but needs less effort and computation. Unlike the existing approaches, the alternatives can be clustered and selected jointly by using a set-valued mapping. This feature makes its application area broader. Moreover, this method is applied to an example, where risk analysis issue is discussed for the selection of energy projects.},
  archive      = {J_SOCO},
  author       = {Shaheen, Tanzeela and Ali, Muhammad Irfan and Shabir, Muhammad},
  doi          = {10.1007/s00500-020-04776-0},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {14005-14017},
  shortjournal = {Soft Comput.},
  title        = {Generalized hesitant fuzzy rough sets (GHFRS) and their application in risk analysis},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Applications of fuzzy <span
class="math display"><em>ρ</em></span> -ideals in <span
class="math display"><em>ρ</em></span> -algebras. <em>SOCO</em>,
<em>24</em>(18), 13997–14004. (<a
href="https://doi.org/10.1007/s00500-020-04773-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Some new notions of fuzzy algebras like fuzzy $$\rho $$ -subalgebra, fuzzy $$\rho $$ -ideal, and fuzzy $${\overline{\rho }}$$ -ideal are introduced in this work. Moreover, the relationships between our new notions and other types of fuzzy algebras like fuzzy d-subalgebra, fuzzy d-ideal, fuzzy BCK-subalgebra, and fuzzy BCK-ideal are investigated. Also, some basic characterizations of fuzzy $$\rho $$ -ideal with their applications on images, Cartesian product, upper level, characteristic function, and strongest fuzzy relation are studied and discussed in this paper. Furthermore, several examples are presented to expound our notions in this work.},
  archive      = {J_SOCO},
  author       = {Khalil, Shuker Mahmood and Hameed, Fatima},
  doi          = {10.1007/s00500-020-04773-3},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {13997-14004},
  shortjournal = {Soft Comput.},
  title        = {Applications of fuzzy $$\rho $$ -ideals in $$\rho $$ -algebras},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Autonomous mobile robot path planning in unknown dynamic
environments using neural dynamics. <em>SOCO</em>, <em>24</em>(18),
13979–13995. (<a
href="https://doi.org/10.1007/s00500-020-04771-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel variant of bio-inspired planning algorithms is presented for robot collision-free path planning in dynamic environments without prior information. The first contribution of this paper is that, with mild technical analysis, the traditional neural dynamic model almost always returns a sub-optimal choice in some challenging scenarios, such as the boundary map and the narrow pathway map. Second, the proposed planning algorithm, namely the padding mean neural dynamic model, is a topologically organized network with connections among neighbouring neurons and is good for spreading nerve impulses such as a waves without coupling effects. The signal transduction method within a network is based on a dynamic neural activity field, which propagates high neural activity from the target state to the whole field, excluding obstacle regions. Third, simulation studies are conducted to compare the performance of the proposed planning algorithm and other popular planning algorithms in terms of effectiveness and efficiency. As a result, the proposed method can drive a robot to find more reasonable paths in both static maps and unknown dynamic scenarios with moving obstacles and a moving target. Finally, the novel excitatory input design of the proposed algorithm is discussed and analysed to explore the neural stimulus propagation mechanism within the network.},
  archive      = {J_SOCO},
  author       = {Chen, Yanjie and Liang, Jiacheng and Wang, Yaonan and Pan, Qi and Tan, Jianhao and Mao, Jianxu},
  doi          = {10.1007/s00500-020-04771-5},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {13979-13995},
  shortjournal = {Soft Comput.},
  title        = {Autonomous mobile robot path planning in unknown dynamic environments using neural dynamics},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Goal programming technique for solving fully interval-valued
intuitionistic fuzzy multiple objective transportation problems.
<em>SOCO</em>, <em>24</em>(18), 13955–13977. (<a
href="https://doi.org/10.1007/s00500-020-04770-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In transportation problems, the cost depends on various irresistible factors like climatic conditions, fuel expenses, etc. Consequently, the transportation problems with crisp parameters fail to handle such situations. However, the construction of the problems under an imprecise environment can significantly tackle these circumstances. The intuitionistic fuzzy number associated with a point is framed by two parameters, namely membership and non-membership degrees. The membership degree determines its acceptance level, while the non-membership measures its non-belongingness (rejection level). However, a person, because of some hesitation, instead of giving a fixed real number to the acceptance and rejection levels, may assign them intervals. This new construction not only generalizes the concept of intuitionistic fuzzy theory but also gives wider scope with more flexibility. In the present article, a balanced transportation problem having all the parameters and variables as interval-valued intuitionistic fuzzy numbers is formulated. Then, a solution methodology based on goal programming approach is proposed. This algorithm not only cares to maximize the acceptance level of the objective functions but simultaneously minimizes the deviational variables attached with each goal. To tackle the interval-valued intuitionistic fuzzy constraints corresponding to each objective function, three membership and non-membership functions, linear, exponential and hyperbolic, are used. Further, a numerical example is solved to demonstrate the computational steps of the algorithm, and a comparison is drawn amidst linear, exponential and hyperbolic membership functions.},
  archive      = {J_SOCO},
  author       = {Malik, Manisha and Gupta, S. K.},
  doi          = {10.1007/s00500-020-04770-6},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {13955-13977},
  shortjournal = {Soft Comput.},
  title        = {Goal programming technique for solving fully interval-valued intuitionistic fuzzy multiple objective transportation problems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An evaluation of monte carlo-based hyper-heuristic for
interaction testing of industrial embedded software applications.
<em>SOCO</em>, <em>24</em>(18), 13929–13954. (<a
href="https://doi.org/10.1007/s00500-020-04769-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyper-heuristic is a new methodology for the adaptive hybridization of meta-heuristic algorithms to derive a general algorithm for solving optimization problems. This work focuses on the selection type of hyper-heuristic, called the exponential Monte Carlo with counter (EMCQ). Current implementations rely on the memory-less selection that can be counterproductive as the selected search operator may not (historically) be the best performing operator for the current search instance. Addressing this issue, we propose to integrate the memory into EMCQ for combinatorial t-wise test suite generation using reinforcement learning based on the Q-learning mechanism, called Q-EMCQ. The limited application of combinatorial test generation on industrial programs can impact the use of such techniques as Q-EMCQ. Thus, there is a need to evaluate this kind of approach against relevant industrial software, with a purpose to show the degree of interaction required to cover the code as well as finding faults. We applied Q-EMCQ on 37 real-world industrial programs written in Function Block Diagram (FBD) language, which is used for developing a train control management system at Bombardier Transportation Sweden AB. The results show that Q-EMCQ is an efficient technique for test case generation. Addition- ally, unlike the t-wise test suite generation, which deals with the minimization problem, we have also subjected Q-EMCQ to a maximization problem involving the general module clustering to demonstrate the effectiveness of our approach. The results show the Q-EMCQ is also capable of outperforming the original EMCQ as well as several recent meta/hyper-heuristic including modified choice function, Tabu high-level hyper-heuristic, teaching learning-based optimization, sine cosine algorithm, and symbiotic optimization search in clustering quality within comparable execution time.},
  archive      = {J_SOCO},
  author       = {Ahmed, Bestoun S. and Enoiu, Eduard and Afzal, Wasif and Zamli, Kamal Z.},
  doi          = {10.1007/s00500-020-04769-z},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {13929-13954},
  shortjournal = {Soft Comput.},
  title        = {An evaluation of monte carlo-based hyper-heuristic for interaction testing of industrial embedded software applications},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Predicting users’ review helpfulness: The role of
significant review and reviewer characteristics. <em>SOCO</em>,
<em>24</em>(18), 13913–13928. (<a
href="https://doi.org/10.1007/s00500-020-04767-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are thousands of reviews constantly being posted for popular products on e-commerce websites. The number of reviews is rapidly increasing which creates information overload problem. To solve this problem, many websites introduced a feedback mechanism to vote for a review (helpful or not). The attracted votes reflect the review helpfulness. This study addresses the review helpfulness prediction problem and investigated the impact of review, reviewer and product features. Multiple helpfulness prediction models are built using multivariate adaptive regression, classification and regression tree, random forest, neural network and deep neural network approaches using two real-life Amazon product review datasets. Deep neural network-based review helpfulness prediction model has outperformed. The results demonstrate that review-type characteristics are most effective indicators as compared to reviewer and product type. In addition, hybrid combination (review, reviewer and product) of proposed features demonstrates the best performance. The influence of product type (search and experience) on review helpfulness is also examined, and reviews of search goods show strong relationship to review helpfulness. Our findings suggest that polarity of review title, sentiment and polarity of review text and cosine similarity between review text and product title effectively contribute to the helpfulness of users’ reviews. Reviewer production time and reviewer active since features are also strong predictors of review helpfulness. Our findings will enable consumers to write useful reviews that will help retailers to manage their websites intelligently by assisting online users in making purchase decisions.},
  archive      = {J_SOCO},
  author       = {Malik, Muhammad Shahid Iqbal},
  doi          = {10.1007/s00500-020-04767-1},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {13913-13928},
  shortjournal = {Soft Comput.},
  title        = {Predicting users’ review helpfulness: The role of significant review and reviewer characteristics},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Energy demand forecasting using a novel remnant GM(1,1)
model. <em>SOCO</em>, <em>24</em>(18), 13903–13912. (<a
href="https://doi.org/10.1007/s00500-020-04765-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grey prediction models play a significant role in forecasting energy demand, particularly the GM(1,1) model. To increase the prediction accuracy of the original GM(1,1) model, the corresponding residual GM(1,1) model is often recommended. However, the original and residual models that form the basis of the remnant grey prediction model are usually set up independently. In this work, we use a neural network to determine the degree to which a predicted value obtained from the original GM(1,1) model can be modified. A distinctive feature of our proposed prediction model is that the residual model is leveraged by providing a new adjustment mechanism for predicted values to maximize the prediction accuracy. The independent creation of a residual model is no longer required for the proposed model. The prediction accuracy of the proposed prediction models is verified using real energy demand cases. Experimental results showed that the proposed remnant GM(1,1) models perform well in comparison with other remnant GM(1,1) variants.},
  archive      = {J_SOCO},
  author       = {Hu, Yi-Chung},
  doi          = {10.1007/s00500-020-04765-3},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {13903-13912},
  shortjournal = {Soft Comput.},
  title        = {Energy demand forecasting using a novel remnant GM(1,1) model},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). IADF security: Insider attack detection using fuzzy logic in
wireless multimedia sensor networks. <em>SOCO</em>, <em>24</em>(18),
13893–13902. (<a
href="https://doi.org/10.1007/s00500-020-04764-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless multimedia sensor networks (WMSNs) consist of spatially distributed, autonomous sensor nodes that monitor physical or environmental conditions. WMSN networks, in general, are prone to insider attacks like node replication attacks, where a malicious node replicates itself as an insider node, which may lead to a situation where a non-authentic node becomes a rightful part of the network. Insider attacks are not detectable with classic cryptographical techniques. Many WMSN applications require a dedicated on-demand algorithm to detect the insider attacker in the system without any prior knowledge of the system. This paper proposes a new security scheme, called the insider attack detection using fuzzy logic (IADF). This security scheme uses the fuzzification of six parameters present in a wireless multimedia sensor node categorized as network and physical parameters. Physical parameters used are received signal strength, transceiver range and residual energy. Network parameters used include packet delivery ratio, forwarding delay and transmission rate. The fuzzy approach makes the IADF algorithm flexible and scalable. Simulation results show that the IADF algorithm can predict malicious nodes with a higher prediction rate and higher detection accuracy.},
  archive      = {J_SOCO},
  author       = {Janarthanan, Ashwinth and Kumar, Dhananjay and Antony, R. Remo and Parvathe, C. B. Divya},
  doi          = {10.1007/s00500-020-04764-4},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {13893-13902},
  shortjournal = {Soft Comput.},
  title        = {IADF security: Insider attack detection using fuzzy logic in wireless multimedia sensor networks},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The impact of virtual reality technology on tourists’
experience: A textual data analysis. <em>SOCO</em>, <em>24</em>(18),
13879–13892. (<a
href="https://doi.org/10.1007/s00500-020-04883-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is focused on the study of the quality of experience lived by tourists when visiting a cultural heritage destination by using a tourist product based on a virtual tour. The research is justified by the increased demand by tourists to have a memorable experience in a destination as well as the growing offer on virtual reality and augmented reality technologies applied to the tourism sector. The database consists of online comments extracted from those who visited two well-known tourism destinations in Spain, Seville and Barcelona, where the immersive virtual reality technology named Past View is currently used. A total of 119 online comments on the tourists’ experience after the use of the Past View smart glasses and posted in the e-WOM community Trip Advisor were valid for the analysis. Using a correspondence analysis of textual data, the results shed light about how virtual reality technologies influence on tourists’ quality of experience. The findings drawn from the empirical analysis provide destination marketing organizations suitable and useful information to promote the destination and therefore encouraging entrepreneurs to innovate in tourism sector to attend the desire of tourists to have a memorable tourist experience.},
  archive      = {J_SOCO},
  author       = {González-Rodríguez, M. Rosario and Díaz-Fernández, M. Carmen and Pino-Mejías, Miguel Ángel},
  doi          = {10.1007/s00500-020-04883-y},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {13879-13892},
  shortjournal = {Soft Comput.},
  title        = {The impact of virtual reality technology on tourists’ experience: A textual data analysis},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Liquidity transmission and the subprime mortgage crisis: A
multivariate GARCH approach. <em>SOCO</em>, <em>24</em>(18),
13871–13878. (<a
href="https://doi.org/10.1007/s00500-020-04772-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper examines the liquidity transmission across the interbank money market by investigating four liquidity measurements. We detect an empirical evidence of the increase in conditional correlation across different liquidity channels during the subprime mortgage crisis. Two structural breaks are observed, and the break dates correspond to the critical events that happened at the beginning of the subprime mortgage crisis. Furthermore, two out of three significant pairwise liquidity transmissions involved the TED liquidity spread.},
  archive      = {J_SOCO},
  author       = {Xiao, Ling and Dhesi, Gurjeet and Ceptureanu, Eduard Gabriel and Lin, Kevin and Herteliu, Claudiu and Syed, Babar and Ceptureanu, Sebastian Ion},
  doi          = {10.1007/s00500-020-04772-4},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {13871-13878},
  shortjournal = {Soft Comput.},
  title        = {Liquidity transmission and the subprime mortgage crisis: A multivariate GARCH approach},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sustainable consumption behaviours in P2P accommodation
platforms: An exploratory study. <em>SOCO</em>, <em>24</em>(18),
13863–13870. (<a
href="https://doi.org/10.1007/s00500-020-04681-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper examines how sustainable consumption behaviours are assembled in peer-to-peer (P2P) platforms, based on four factors—services portfolio complexity, network membership, reputation and innovative practices—and its impact on P2P platform performance. Using data from one P2P accommodation platform in Romania and based on 2556 observations, we tested the research hypothesis using ordinary least squares regression. Specifically, services portfolio complexity positively influences sustainable consumption behaviours, while network membership has a negative influence. Services portfolio complexity has a positive influence on sustainable consumption behaviours when innovative practices are high. Finally, sustainable consumption behaviours positively influence P2P platform performance.},
  archive      = {J_SOCO},
  author       = {Ceptureanu, Eduard Gabriel and Ceptureanu, Sebastian Ion and Herteliu, Claudiu and Cerqueti, Roy},
  doi          = {10.1007/s00500-020-04681-6},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {13863-13870},
  shortjournal = {Soft Comput.},
  title        = {Sustainable consumption behaviours in P2P accommodation platforms: An exploratory study},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). New social media for health promotion management: A
statistical analysis. <em>SOCO</em>, <em>24</em>(18), 13853–13862. (<a
href="https://doi.org/10.1007/s00500-019-04664-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The literature from several areas of study reports social media Web sites plays an important role for society in the third millennium. Using the Internet as a tool for health is increasingly common: In particular, Facebook has played increasing role in health promotion management. The objective of the paper was to demonstrate, by a sample survey, how and how much Facebook promotes health by encouraging healthy lifestyles. The online questionnaire has been loaded on Facebook pages and groups that promote healthy lifestyle and well-being. Statistical data analysis, used in an integrated and complementary approach, has been multiple correspondence analysis, cluster analysis and cross-tabulations. The final sample consisted of 3.640 Facebook users. Social media Web sites are widely used by younger generation, but also by adult and senior population to find health information. Starting from the research results, it can be argued that Facebook users would like to have more “certified information” on health through social media Web sites. Starting from this information, governments could promote healthy lifestyles through Facebook, paying attention to certify the contents.},
  archive      = {J_SOCO},
  author       = {Belfiore, Patrizia and Sarnacchiaro, Pasquale and Sorrentini, Alessandra and Ricchiuti, Roberta},
  doi          = {10.1007/s00500-019-04664-2},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {13853-13862},
  shortjournal = {Soft Comput.},
  title        = {New social media for health promotion management: A statistical analysis},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Streaming generalized cross entropy. <em>SOCO</em>,
<em>24</em>(18), 13837–13851. (<a
href="https://doi.org/10.1007/s00500-019-04632-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new method to combine adaptive processes with a class of entropy estimators for the case of streams of data. Starting from a first estimation obtained from a batch of initial data, model parameters are estimated at each step by combining the prior knowledge with the new observation (or a block of observations). This allows to extend the maximum entropy technique to a dynamical setting, also distinguishing between entropic contributions of the signal and the error. Furthermore, it provides a suitable approximation of standard GME problems when the exacted solutions are hard to evaluate. We test this method by performing numerical simulations at various sample sizes and batch dimensions. Moreover, we extend this analysis exploring intermediate cases between streaming GCE and standard GCE, i.e., considering blocks of observations of different sizes to update the estimates, and incorporating collinearity effects as well. The role of time in the balance between entropic contributions of signal and errors is further explored considering a variation of the Streaming GCE algorithm, namely Weighted Streaming GCE. Finally, we discuss the results: In particular, we highlight the main characteristics of this method, the range of application, and future perspectives.},
  archive      = {J_SOCO},
  author       = {Angelelli, Mario and Ciavolino, Enrico and Pasca, Paola},
  doi          = {10.1007/s00500-019-04632-w},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {13837-13851},
  shortjournal = {Soft Comput.},
  title        = {Streaming generalized cross entropy},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Using markov-switching models with markov chain monte carlo
inference methods in agricultural commodities trading. <em>SOCO</em>,
<em>24</em>(18), 13823–13836. (<a
href="https://doi.org/10.1007/s00500-019-04629-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, the use of Markov-switching GARCH (MS-GARCH) models is tested in an active trading algorithm for corn and soybean future markets. By assuming that a given investor lives in a two-regime world (with low- and high-volatility time periods), a trading algorithm was simulated (from January 2000 to March 2019), which helped the investor to forecast the probability of being in the high-volatility regime at t + 1. Once this probability was known, the investor could decide to invest either in commodities, during low-volatility periods or in the 3-month US Treasury bills, during high-volatility periods. Our results suggest that the Gaussian MS-GARCH model is the most appropriate to generate alpha or extra returns (from a passive investment strategy) in the corn market and the t-Student MS-GARCH is the best one for soybean trading.},
  archive      = {J_SOCO},
  author       = {De la Torre-Torres, Oscar V. and Aguilasocho-Montoya, Dora and Álvarez-García, José and Simonetti, Biagio},
  doi          = {10.1007/s00500-019-04629-5},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {13823-13836},
  shortjournal = {Soft Comput.},
  title        = {Using markov-switching models with markov chain monte carlo inference methods in agricultural commodities trading},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Predicting one type of technological motion? A nonlinear map
to study the “sailing-ship” effect. <em>SOCO</em>, <em>24</em>(18),
13813–13822. (<a
href="https://doi.org/10.1007/s00500-019-04622-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we use a proven model to study a dynamic duopolistic competition between an old technology and a new technology which through an improved technical performance—e.g. data transmission capacity—fight in order to conquer market share. The process whereby an old technology fights a new one off through own improvements has been named ‘sailing-ship effect’. In the simulations proposed, intentional improvements of both the old technology and the new technology are affected by the values of three key parameters: scientific-technological, purely technological and purely economic. The interaction between these components gives rise to different outcomes in terms of prevalence of one technology over the other.},
  archive      = {J_SOCO},
  author       = {Filatrella, Giovanni and De Liso, Nicola},
  doi          = {10.1007/s00500-019-04622-y},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {13813-13822},
  shortjournal = {Soft Comput.},
  title        = {Predicting one type of technological motion? a nonlinear map to study the ‘sailing-ship’ effect},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Non-parametric news impact curve: A variational approach.
<em>SOCO</em>, <em>24</em>(18), 13797–13812. (<a
href="https://doi.org/10.1007/s00500-019-04607-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose an innovative algorithm for modelling the news impact curve. The news impact curve provides a nonlinear relation between past returns and current volatility and thus enables to forecast volatility. Our news impact curve is the solution of a dynamic optimization problem based on variational calculus. Consequently, it is a non-parametric and smooth curve. The technique we propose is directly inspired from noise removal techniques in signal theory. To our knowledge, this is the first time that such a method is used for volatility modelling. Applications on simulated heteroskedastic processes as well as on financial data show a better accuracy in estimation and forecast for this approach than for standard parametric (symmetric or asymmetric ARCH) or non-parametric (Kernel-ARCH) econometric techniques.},
  archive      = {J_SOCO},
  author       = {Garcin, Matthieu and Goulet, Clément},
  doi          = {10.1007/s00500-019-04607-x},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {13797-13812},
  shortjournal = {Soft Comput.},
  title        = {Non-parametric news impact curve: A variational approach},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fundamental bubbles in equity markets. <em>SOCO</em>,
<em>24</em>(18), 13769–13796. (<a
href="https://doi.org/10.1007/s00500-019-04514-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using an affine model to compute the price of equities based on a dataset of macroeconomic factors, we propose a measure of equity bubbles. We use a dynamic affine term structure framework to price equity and bonds jointly, and investigate how prices are related to a set of macrofactors extracted from a large dataset of economic time series. We analyze the discrepancies between market and model implied equity prices and use them as a measure for bubbles. A bubble is diagnosed over a given period whenever the discrepancies are not stationary and impact the underlying economy consistently with the literature’s findings, increasing over the shorter term economic activity before leading to a net loss in it. We perform the analysis over 3 major US and 3 major European equity indices over the 1990–2017 period and find bubbles only for two of the US equity indices, the S&amp;P500 and the Dow Jones.},
  archive      = {J_SOCO},
  author       = {Ielpo, Florian and Kniahin, Mikita},
  doi          = {10.1007/s00500-019-04514-1},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {13769-13796},
  shortjournal = {Soft Comput.},
  title        = {Fundamental bubbles in equity markets},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Consensus dynamics, network interaction, and shapley indices
in the choquet framework. <em>SOCO</em>, <em>24</em>(18), 13757–13768.
(<a href="https://doi.org/10.1007/s00500-019-04512-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a set $$N = { 1,\ldots ,n }$$ of interacting agents whose individual opinions are denoted by $$ x_{i}$$ , $$i \in N $$ in some domain $${\mathbb {D}}\subseteq {\mathbb {R}}$$ . The interaction among the agents is expressed by a symmetric interaction matrix with null diagonal and off-diagonal coefficients in the open unit interval. The interacting network structure is thus that of a complete graph with edge values in (0, 1). In the Choquet framework, the interacting network structure is the basis for the construction of a consensus capacity $$\mu $$ , where the capacity value $$\mu (S)$$ of a coalition of agents $$S \subseteq N$$ is defined to be proportional to the sum of the edge interaction values contained in the subgraph associated with S. The capacity $$\mu $$ is obtained in terms of its 2-additive Möbius transform $$m_{\mu }$$ , and the corresponding Shapley power and interaction indices are identified. We then discuss two types of consensus dynamics, both of which refer significantly to the notion of context opinion. The second type converges simply the plain mean, whereas the first type produces the Shapley mean as the asymptotic consensual opinion. In this way, it provides a dynamical realization of Shapley aggregation.},
  archive      = {J_SOCO},
  author       = {Bortot, Silvia and Marques Pereira, Ricardo Alberto and Stamatopoulou, Anastasia},
  doi          = {10.1007/s00500-019-04512-3},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {13757-13768},
  shortjournal = {Soft Comput.},
  title        = {Consensus dynamics, network interaction, and shapley indices in the choquet framework},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A fuzzy functional k-means approach for monitoring italian
regions according to health evolution over time. <em>SOCO</em>,
<em>24</em>(18), 13741–13755. (<a
href="https://doi.org/10.1007/s00500-019-04505-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent decades, functional data analysis has attracted the attention of many researchers in mathematics and statistics. For this reason, both the theory and applications have proliferated in the literature. Much of classical statistics has been rewritten in functional terms to handle data that are or can be represented by functions through appropriate smoothing operations. Within the framework of supervised and unsupervised classification, numerous techniques have been proposed to identify homogeneous groups of functional data based on different possible metrics and semi-metrics depending on the specific context. A limitation of these techniques is that they always lead to crisp-type groupings. Recently, in fuzzy set theory, many classification methods have been proposed to obtain non-crisp groupings so that the researcher is not forced to assign a statistical unit to a single group in a unique way. Following this approach, it is possible to carry out a classification that contemplates the possibility that a statistical unit belongs to different groups at the same time with different degrees of membership. The objective of this article is to propose a fuzzy functional unsupervised classification algorithm that takes into account both the functional and the fuzzy approach in order to identify similar patterns of functional data. After presenting the method, a possible application is proposed using the health composite indicator concerning the Italian regions in the period 2010–2015. The final aim of this work is to provide professionals with a tool capable of monitoring the risks of health imbalances at the national level, identifying similar behaviours at the local level but embracing the uncertainty that the fuzzy functional classification preserves in results.},
  archive      = {J_SOCO},
  author       = {Maturo, Fabrizio and Ferguson, John and Di Battista, Tonio and Ventre, Viviana},
  doi          = {10.1007/s00500-019-04505-2},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {13741-13755},
  shortjournal = {Soft Comput.},
  title        = {A fuzzy functional k-means approach for monitoring italian regions according to health evolution over time},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The inventory routing problem under uncertainty with
perishable products: An application in the agri-food supply chain.
<em>SOCO</em>, <em>24</em>(18), 13725–13740. (<a
href="https://doi.org/10.1007/s00500-019-04497-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a dynamic and stochastic approach for an inventory routing problem in which products with a high perishability must be delivered from a supplier to a set of customers. This problem falls within the agri-food supply chain ( $${\mathcal {ASC}}$$ ) management field, which includes all the activities from production to distribution. The need for high-quality products that are subject to perishability is a critical issue to consider in the $${\mathcal {ASC}}$$ optimization. Moreover, the demand uncertainty makes the problem very challenging. In order to effectively manage all these features, a rolling horizon approach based on a multistage stochastic linear program is proposed. Computational experiments over medium-size instances designed on the basis of the real data provided by an agri-food company operating in Southern Italy show the effectiveness of the proposed approach.},
  archive      = {J_SOCO},
  author       = {Violi, Antonio and Laganá, Demetrio and Paradiso, Rosario},
  doi          = {10.1007/s00500-019-04497-z},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {13725-13740},
  shortjournal = {Soft Comput.},
  title        = {The inventory routing problem under uncertainty with perishable products: An application in the agri-food supply chain},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A group-AHP-based approach for selecting the best public
tender. <em>SOCO</em>, <em>24</em>(18), 13717–13724. (<a
href="https://doi.org/10.1007/s00500-019-04479-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the selection of the best tender in a public procurement process. This process involves different steps: the design of the tender process, the choice of tender selection methods, and scoring rules for evaluating tenders—the ex post control. Due to the interconnections between the rules on public contracts and those aimed to tackle corruption, the choice of tender selection methods and scoring rules for evaluating tenders assumes a crucial importance. The criterion usually used to select the best tender is the most economic advantageous tender (MEAT) based on the evaluation of technical requirements, on the one hand, and economic offer, on the other hand. First, this paper highlights some critical issues on the weighted sum method and some analytical formulas, commonly used to calculate the MEAT. Then, in order to apply a unique procedure and limit some risks of corruption and collusive agreements, it proposes to implement a unified group-AHP approach: In particular, a group-AHP model is applied for analyzing the qualitative component and another AHP model is used for the quantitative component.},
  archive      = {J_SOCO},
  author       = {Marcarelli, Gabriella and Squillante, Massimo},
  doi          = {10.1007/s00500-019-04479-1},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {13717-13724},
  shortjournal = {Soft Comput.},
  title        = {A group-AHP-based approach for selecting the best public tender},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Risk management of food health hazard by meat consumption
reduction: A coopetitive game approach. <em>SOCO</em>, <em>24</em>(18),
13705–13716. (<a
href="https://doi.org/10.1007/s00500-019-04474-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we face the serious problem of food health hazard, also in connection with global food production scarcity and feeding sustainability, in view of important environmental issues and the severe incumbent climate change. Specifically, our innovative risk management approach considers cooperation among producers of vegan and non-vegan food, a strong commitment more and more observed, recently, in technologically advanced western countries. The novelty of our work consists in proposing possible quantitative agreements among complementary food producers, usually non-interacting, in order to develop a sustainable healthy food production for human population—also characterized by low impact on the planet. Another new feature of our approach lies in using coopetition and game theory together; we show, quantitatively, how to conjugate human health defense, environmental defense, economic interests and less government spending, needs which usually appear in contrast with each other. Another point of our coopetitive approach is the suggestion of an easier way to entry the global market for vegan food producers. Meanwhile, our model suggests to big producers/sellers of non-vegan food a way to smoothly and rapidly transit toward more sustainable production. Technically, we propose an innovative exemplary complex agreement among global food sellers and small (but strongly sustainable and innovative) vegan food producers. Moreover, our model implies a general saving for the countries, by mitigating the health expenditures. The result of our mathematical study suggests a novel win–win solution for global economy, world environment and governments, while improving human population sustainability and climate change effects.},
  archive      = {J_SOCO},
  author       = {Carfí, David and Donato, Alessia},
  doi          = {10.1007/s00500-019-04474-6},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {13705-13716},
  shortjournal = {Soft Comput.},
  title        = {Risk management of food health hazard by meat consumption reduction: A coopetitive game approach},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel measure of edge and vertex centrality for assessing
robustness in complex networks. <em>SOCO</em>, <em>24</em>(18),
13687–13704. (<a
href="https://doi.org/10.1007/s00500-019-04470-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we propose a novel robustness measure for networks, which we refer to as Effective Resistance Centrality of a vertex (or an edge), defined as the relative drop of the Kirchhoff index due to deletion of this vertex (edge) from the network. Indeed, we provide a local robustness measure, able to catch which is the effect of either a specific vertex or a specific edge on the network robustness. The validness of this new measure is illustrated on some typical graphs and on a wide variety of well-known model networks. Furthermore, we analyse the topology of the US domestic flight connections. In particular, we investigate the role that airports play in maintaining the structure of the entire network.},
  archive      = {J_SOCO},
  author       = {Clemente, G. P. and Cornaro, A.},
  doi          = {10.1007/s00500-019-04470-w},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {13687-13704},
  shortjournal = {Soft Comput.},
  title        = {A novel measure of edge and vertex centrality for assessing robustness in complex networks},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Systemic shock propagation in a complex system.
<em>SOCO</em>, <em>24</em>(18), 13667–13685. (<a
href="https://doi.org/10.1007/s00500-019-04466-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the effects of delivering a shock to a complex system comprising components (‘agents’) that interact in a pairwise fashion, independent of other parts of the system and with no central control. There are three aspects to the contribution of this paper. First, shock propagation in a network is developed purely from fundamental principles of complex systems. Second, systemic risk is shown to arise naturally in such a complex system. If a shock is delivered either to one agent or to many agents simultaneously, that shock may be transmitted further, thereby resulting in systemic risk. Third, the monetary loss to the entire system as a result of systemic shock is quantified. Simulations are used to study two particular characteristics of the interactions. The first is the resistance or susceptibility of individual agents to a shock. The second is the time it takes for the shock to affect the entire system. The results show that if a shock is applied to all agents in a network, the systemic effect of that shock is transmitted very quickly. Applying a shock to very few agents results only in an idiosyncratic effect. If an agent can transmit the shock further, a systemic effect will result. The recovery period for agents affected by a systemic shock can be orders of magnitude greater than the time taken for the shock to take effect. The overall effect of the shock on the system is quantified by formulating a ‘contagion index’, which measures the ratio of the total capital lost due to the systemic effect to the total capital before the shock was delivered. The result (approximately 7\%) is consistent with other studies, but is more widely applicable because it is not based on one empirical data set.},
  archive      = {J_SOCO},
  author       = {Mitic, Peter},
  doi          = {10.1007/s00500-019-04466-6},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {13667-13685},
  shortjournal = {Soft Comput.},
  title        = {Systemic shock propagation in a complex system},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Life cycle of scientific publications in the field of high
social impact. <em>SOCO</em>, <em>24</em>(18), 13657–13666. (<a
href="https://doi.org/10.1007/s00500-019-04441-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a previous work, we have presented an innovative theoretical model to describe the evolution of the life cycle of a new technology. We have proposed a mathematical approach based on a rate equation, similar to that used to describe quantum level transitions. The model is able to describe the hype curve evolution in many relevant conditions, which can be associated with various external parameters. In this article, we apply this model to describe the evolution of the number of publications in some different research fields that are very current and extremely advanced in terms of social impact. The applications have been chosen in the fields of biomolecular chemistry, genetics and superconducting nanoelectronics.},
  archive      = {J_SOCO},
  author       = {Ruggiero, B. and Amato, U. and Franco, B. and De Petrocellis, L. and Vettoliere, A. and Granata, C. and Silvestrini, S. and Bonavolontà, C. and Valentino, M. and Brocchieri, J. and Silvestrini, P.},
  doi          = {10.1007/s00500-019-04441-1},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {13657-13666},
  shortjournal = {Soft Comput.},
  title        = {Life cycle of scientific publications in the field of high social impact},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Risk analysis via łukasiewicz logic. <em>SOCO</em>,
<em>24</em>(18), 13651–13655. (<a
href="https://doi.org/10.1007/s00500-019-04440-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we apply logical methods to risk analysis. We study generalized events, i.e. not yes-no events but continuous ones. We define on this class of events a risk function and a measure over it to analyse risk in this context. We use Riesz MV-algebras as algebraic structures and their associated logic in support of our research, thanks to their relations with other applications. Moreover, we investigate on decidability of consequence problem for our class of risk.},
  archive      = {J_SOCO},
  author       = {Vitale, Gaetano},
  doi          = {10.1007/s00500-019-04440-2},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {13651-13655},
  shortjournal = {Soft Comput.},
  title        = {Risk analysis via Łukasiewicz logic},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Utilisation of ANPSort for sorting alternative with
interdependent criteria illustrated through a researcher’s
classification problem in an academic context. <em>SOCO</em>,
<em>24</em>(18), 13639–13650. (<a
href="https://doi.org/10.1007/s00500-019-04405-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Six problem formulations exist in multi-criteria decision analysis (MCDA): choice, sorting, ranking, description, elimination and design problems. MCDA methods are generally developed for choice or ranking problems. Recently, several methods have been adapted for sorting problems. However, they all assume that the criteria are independent, which is often not the case practically in real life. Therefore, this paper proposes a new sorting technique ANPSort, which can handle problems and challenges with interdependent criteria. Moreover, another practical limitation of ANP is that a high number of alternatives imply a large number of comparisons. In comparison, our proposed ANPSort requires far-less comparisons than ANP, which facilitates decision-making within large-scale problems. It further allows a structured, transparent and consistent evaluation integrating qualitative and quantitative criteria. In this paper, we contextualise and problematise this challenge and contribute through the lens of a practical case study in a higher education academic set-up specifically concentrating on a topical area of ‘researcher classification’, to illustrate our concept and approach.},
  archive      = {J_SOCO},
  author       = {Ishizaka, Alessio and Pereira, Vijay},
  doi          = {10.1007/s00500-019-04405-5},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {13639-13650},
  shortjournal = {Soft Comput.},
  title        = {Utilisation of ANPSort for sorting alternative with interdependent criteria illustrated through a researcher’s classification problem in an academic context},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Using ELECTRE to analyse the behaviour of economic agents.
<em>SOCO</em>, <em>24</em>(18), 13629–13637. (<a
href="https://doi.org/10.1007/s00500-019-04397-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {According to behavioural finance, economic agents display cognitive bias, heuristics and emotional factors that generate preferences which systematically violate the rationality assumptions of the normative model of classical decision theory. Rather than maximizing the expected utility, representing the optimal choice, they attempt to accept a satisfactory solution. Morton and Fasolo (J Oper Res Soc 60:268–275, 2009) outlined some behavioural findings relevant to the practice of multicriteria approach. In this paper, we propose a multicriteria model for analysing some experiments proposed by Kahneman and Tversky (Econometrica 47:263–29 l, 1979). Our aim is to verify whether a multicriteria tool reduces or minimizes cognitive biases. We focus on ELECTRE due to its main features: it accepts the violation of some mathematical axioms. By a simulation study, we represent a set of prospects by means of decision matrices: the prospects are considered as alternatives, the events as criteria, the probabilities of events as the weights assigned to criteria. Then, we apply ELECTRE to verify whether the preference ranking among the alternatives confirms the results obtained by Kahneman–Tversky, that is, whether it is able to describe the emotional behaviours of economic agents.},
  archive      = {J_SOCO},
  author       = {Fattoruso, Gerarda and Marcarelli, Gabriella and Olivieri, Maria Grazia and Squillante, Massimo},
  doi          = {10.1007/s00500-019-04397-2},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {13629-13637},
  shortjournal = {Soft Comput.},
  title        = {Using ELECTRE to analyse the behaviour of economic agents},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Duration gap analysis revisited method in order to improve
risk management: The case of chinese commercial bank interest rate risks
after interest rate liberalization. <em>SOCO</em>, <em>24</em>(18),
13609–13627. (<a
href="https://doi.org/10.1007/s00500-019-04376-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern theories attach much attention to interest rate-related problems. We discuss the impacts of the interest rate liberalization, in China, for ten commercial banks of three markedly different ownership types. The methodology is based on revisited interest rate sensitivity analysis, duration analysis and value-at-risk analysis. The situation is examined within both vertical (composition of operating income and interest rate sensitivity gap for the ten banks in the same year) and horizontal (one bank over a 7-year period) aspects. Thereafter, we discuss the present management of interest rate risks by such banks. We conclude with several suggestions on how such commercial banks risk management can be refocused and on how their cases can be used for comforting other banking cases.},
  archive      = {J_SOCO},
  author       = {Ausloos, Marcel and Ma, Qianhui and Kaur, Parmjit and Syed, Babar and Dhesi, Gurjeet},
  doi          = {10.1007/s00500-019-04376-7},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {13609-13627},
  shortjournal = {Soft Comput.},
  title        = {Duration gap analysis revisited method in order to improve risk management: The case of chinese commercial bank interest rate risks after interest rate liberalization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sentiment analysis of expectation and perception of MILANO
EXPO2015 in twitter data: A generalized cross entropy approach.
<em>SOCO</em>, <em>24</em>(18), 13597–13607. (<a
href="https://doi.org/10.1007/s00500-019-04368-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, data concerning MILANO EXPO2015 is collected from the official twitter page of the event before and after its opening. In order to extract a semi-supervised ontology and to evaluate the global sentiment around the event, a variety of language processing techniques has been applied on the collected “tweets”: Latent Semantic Analysis, sentiment polarity tracking, along with gap analysis has allowed the semantic evaluation of users’ opinions. Moreover, the generalized cross entropy approach has been applied for the first time on web data, adding prior information on the effect of semantic classes on the global sentiment, improving accuracy and adding detail to the analysis.},
  archive      = {J_SOCO},
  author       = {Corallo, Angelo and Fortunato, Laura and Massafra, Andrea and Pasca, Paola and Angelelli, Mario and Hobbs, Mike and Al-Nasser, Amjad D. and Al-Omari, Amer I. and Ciavolino, Enrico},
  doi          = {10.1007/s00500-019-04368-7},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {13597-13607},
  shortjournal = {Soft Comput.},
  title        = {Sentiment analysis of expectation and perception of MILANO EXPO2015 in twitter data: A generalized cross entropy approach},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Seismic risk of critical facilities in the dominican
republic: Case study of school buildings. <em>SOCO</em>,
<em>24</em>(18), 13579–13595. (<a
href="https://doi.org/10.1007/s00500-019-04361-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The island of Hispaniola, shared by the Dominican Republic and Haiti, is located in a subduction zone between the North America plate and the Caribbean plate. In addition, there are 13 geological faults in the interior of the island, some of which have shown the potential to generate earthquakes of magnitude 7.5 and higher. Thus, the whole island is considered to be a high seismic risk region. In the past 100 years, several earthquakes have affected both parts of the island. In the case of the Dominican Republic, two earthquakes stand out: a magnitude 8.1 earthquake on August 4, 1946, north of the Samaná Province, which caused a tsunami, soil liquefaction, and the loss of about 100 lives, and a magnitude 6.5 earthquake on September 22, 2003, in the city of Puerto Plata, which caused significant damage for infrastructures. Among the observed effects, the partial and total collapse of several school buildings had a remarkable impact on local communities. In addition to the high seismic risk, a large part of the national infrastructure may exhibit high vulnerability to earthquakes because the seismic regulations had been the same for 32 years, namely from 1979 to 2011. During these three decades, thousands of structures were built nationwide, including essential facilities such as hospitals and schools. Considering that the current student population in public schools in the Dominican Republic is over 2 million, with the majority attending buildings that were designed with the 1979 seismic code and which proved to be highly vulnerable during the Puerto Plata earthquake, it is vital to take measures that reduce the risk and minimize potential earthquake damage to school buildings. In this context, the Technological Institute of Santo Domingo (INTEC) has undertaken recently a project with the main objective to assess the seismic vulnerability of 22 schools located in the San Cristóbal Province, in the south of the Dominican Republic. The latter schools were all built prior to the adoption of the current updated seismic code. This paper presents the results of the assessment of the Fernando Cabral Ortega School. Although only the results of a single RC building are presented, the response of such structure can be considered representative of a portfolio of existing schools in Dominican Republic.},
  archive      = {J_SOCO},
  author       = {Rojas-Mercedes, N. J. and Di Sarno, L. and Simonelli, A. L. and Penna, A.},
  doi          = {10.1007/s00500-019-04361-0},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {13579-13595},
  shortjournal = {Soft Comput.},
  title        = {Seismic risk of critical facilities in the dominican republic: Case study of school buildings},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Quantification of qualitative assessments using computing
with words: In framework of fuzzy set theory. <em>SOCO</em>,
<em>24</em>(18), 13565–13577. (<a
href="https://doi.org/10.1007/s00500-019-04354-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When qualitative data are collected, which is a widespread situation encountered in several disciplines ranging from social sciences to decision making to engineering as a result of dealing with ill-defined concepts or with complex tasks to assess, there is a certain need to crunch them and infer from them. Hence, quantification, namely computing with words (CW), emerges as a research area. Even though social science disciplines deal with these types of data numerically using various Likert scales, fuzzy set theory first proposed by Zadeh dealing words or sentences with mathematically oriented manner in order to create machines that mimic the reasoning of human being brings new perspectives. Since then, its applicability has expanded into various disciplines for different purposes to transform subjectivity into objectivity. In this manuscript, the effort of transformation from subjectivity into objectivity will be reviewed based on the available proposed methods in the literature. Two illustrative examples will be employed. While the first illustrative example, which consists of balanced and unbalanced linguistic term sets, is used for each reviewed method in the literature to show its computations step by step, the second of which, balanced linguistic term set, is an example used in the literature that is employed. Therefore, a comprehensive review of the proposed methods with illustrative examples is presented.},
  archive      = {J_SOCO},
  author       = {Basaran, Murat Alper and Simonetti, Biagio and Basaran, Alparslan Abdurrahman},
  doi          = {10.1007/s00500-019-04354-z},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {13565-13577},
  shortjournal = {Soft Comput.},
  title        = {Quantification of qualitative assessments using computing with words: In framework of fuzzy set theory},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust distance measure to detect outliers for categorical
data. <em>SOCO</em>, <em>24</em>(18), 13557–13564. (<a
href="https://doi.org/10.1007/s00500-019-04340-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distance-based techniques in detecting outliers appears to be an effective tool in both univariate and multivariate data. However, the effectiveness of the same is yet to be firmly established in categorical data as it poses challenges due to polarization of cell frequencies. The purpose of this paper is to evolve a new distance-based measure to detect outliers in two-dimensional contingency tables. The new distance measure based on pivotal element is evaluated through a comparison with other suitable distance measures from the literature for its performance. The consistency of the four distance measures is examined through a simulation study followed by the application to real datasets.},
  archive      = {J_SOCO},
  author       = {Sripriya, T. P. and Srinivasan, M. R. and Gallo, M.},
  doi          = {10.1007/s00500-019-04340-5},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {13557-13564},
  shortjournal = {Soft Comput.},
  title        = {Robust distance measure to detect outliers for categorical data},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Seasonality in crude oil returns. <em>SOCO</em>,
<em>24</em>(18), 13547–13556. (<a
href="https://doi.org/10.1007/s00500-019-04329-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the efficiency issue of the oil market in order to test the seasonal behavior of oil price returns, specifically day-of-the-week effect and month-of-the-year effect for the period December 1987 to January 2016. We use a dummy variable regression estimation technique to test seasonal anomalies for the Brent and WTI crude oil returns. Our empirical results find support for the negative Monday effect. The evidence of negative Monday returns is consistent with the relevant empirical literature. Moreover, the returns on Thursday are highest in a week followed by returns on Friday for both oil markets. This study also found evidence on month-of-the-year effect as the negative returns in November and December for Brent and WTI oil markets. Finally, this study is important for energy researchers, market participants, and policy-makers because anomalous oil markets’ behavior implies return predictability and the implementation of profitable investment strategies by market players and may also impact the macroeconomic variables and stock market returns.},
  archive      = {J_SOCO},
  author       = {Quayyoum, Sobia and Khan, Mushtaq Hussain and Shah, Syed Zulfiqar Ali and Simonetti, Biagio and Matarazzo, Michela},
  doi          = {10.1007/s00500-019-04329-0},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {13547-13556},
  shortjournal = {Soft Comput.},
  title        = {Seasonality in crude oil returns},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An ATLD–ALS method for the trilinear decomposition of large
third-order tensors. <em>SOCO</em>, <em>24</em>(18), 13535–13546. (<a
href="https://doi.org/10.1007/s00500-019-04320-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {CP decomposition of large third-order tensors can be computationally challenging. Parameters are typically estimated by means of the ALS procedure because it yields least-squares solutions and provides consistent outcomes. Nevertheless, ALS presents two major flaws which are particularly problematic for large-scale problems: slow convergence and sensitiveness to degeneracy conditions such as over-factoring, collinearity, bad initialization and local minima. More efficient algorithms have been proposed in the literature. They are, however, much less dependable than ALS in delivering stable results because the increased speed often comes at the expense of accuracy. In particular, the ATLD procedure is one of the fastest alternatives, but it is hardly employed because of the unreliable nature of its convergence. As a solution, multi-optimization is proposed. ATLD and ALS steps are concatenated in an integrated procedure with the purpose of increasing efficiency without a significant loss in precision. This methodology has been implemented and tested under realistic conditions on simulated data sets.},
  archive      = {J_SOCO},
  author       = {Simonacci, Violetta and Gallo, Michele},
  doi          = {10.1007/s00500-019-04320-9},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {13535-13546},
  shortjournal = {Soft Comput.},
  title        = {An ATLD–ALS method for the trilinear decomposition of large third-order tensors},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). IT2-based multidimensional evaluation approach to the
signaling: Investors’ priorities for the emerging industries.
<em>SOCO</em>, <em>24</em>(18), 13517–13534. (<a
href="https://doi.org/10.1007/s00500-019-04288-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grounded in the signaling theory, the study aims to develop a model for evaluation of emerging industries. The integrated method is proposed to evaluate the emerging industries with DANP (DEMATEL-based Analytic Network Process) and MOORA (Multi-Objective Optimization on the basis of Ratio Analysis) methodologies based on interval type 2 fuzzy sets, respectively. The application is illustrated by considering cleantech, new generation of information technology, biology/biotechnology and high-end equipment manufacturing industries, three dimensions and 12 criteria. The novelties of the study lie in a set of criteria and alternatives for the signaling in emerging industries supported by the literature and suggest a hybrid decision-making model based on the type 2 fuzzy sets. The signaling determinants for emerging industries could be evaluated by the proposed interval type 2 hybrid decision-making approach more accurately. The results demonstrate that the firms, operating in emerging industries at the early stage of their development, have to put emphasis on the third-party endorsements and human capital criteria, aiming to attract external investors. The suggested method lets the external investors narrow their options in selecting emerging industries and select the most attractive industries or spread investments among the most attractive industries.},
  archive      = {J_SOCO},
  author       = {Dinçer, Hasan and Hošková-Mayerová, Šárka and Korsakienė, Renata and Yüksel, Serhat},
  doi          = {10.1007/s00500-019-04288-6},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {13517-13534},
  shortjournal = {Soft Comput.},
  title        = {IT2-based multidimensional evaluation approach to the signaling: Investors’ priorities for the emerging industries},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Special issue on dynamics of socioeconomic systems: Systemic
risk—complex systems. <em>SOCO</em>, <em>24</em>(18), 13515. (<a
href="https://doi.org/10.1007/s00500-020-05214-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SOCO},
  author       = {Cavallo, Bice and de Peretti, Philippe and Simonetti, Biagio and Squillante, Massimo and Vitting-Andersen, Jorgen},
  doi          = {10.1007/s00500-020-05214-x},
  journal      = {Soft Computing},
  number       = {18},
  pages        = {13515},
  shortjournal = {Soft Comput.},
  title        = {Special issue on dynamics of socioeconomic systems: Systemic risk—complex systems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A weight optimized artificial neural network for automated
software test oracle. <em>SOCO</em>, <em>24</em>(17), 13501–13511. (<a
href="https://doi.org/10.1007/s00500-020-05197-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software testing has its main goal as designing new test case sets in a manner in which it is able to depict its maximum faults. As soon as these test cases have been designed, Oracle software provides a method in which the software has to behave for a particular test case given. Prioritization of such test cases with the execution of their components specifying inputs, their operation and their outcome will determine as to whether the application and their properties are working in the right manner. The prioritization methods are as follows: initial ordering, random ordering and finally reverse ordering that were based on fault detection abilities. For developing software applications, a test suite that was less commonly known as the suite for checking the validity of software was employed. The test suite contained a detailed set of instructions and goals for each test case collection based on the system and its configuration used during testing. Automating the generation of a test case and test oracle was researched in an extensive manner. From among the automated test oracle, the artificial neural network (ANN) was used extensively but with a high cost of computation. This work proposed a weight optimized ANN using stochastic diffusion search to find the optimal weights with a unique fitness function such that computational time is reduced and misclassification rate reduced.},
  archive      = {J_SOCO},
  author       = {Kamaraj, K. and Arvind, C. and Srihari, K.},
  doi          = {10.1007/s00500-020-05197-9},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {13501-13511},
  shortjournal = {Soft Comput.},
  title        = {A weight optimized artificial neural network for automated software test oracle},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel fractional-order neural network for model reduction
of large-scale systems with fractional-order nonlinear structure.
<em>SOCO</em>, <em>24</em>(17), 13489–13499. (<a
href="https://doi.org/10.1007/s00500-020-04763-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new method for reducing the order of nonlinear large-scale fractional-order systems is presented. The considered system has a nonlinear large-scale dynamic. The proposed method is developed by introducing a new fractional-based approach for neural network learning. According to the fractional-order modeling of the system, the structure of the neural network is selected as a recurrent neural network and new design and analysis are done on this network. In order to show the proposed method for model reduction has an acceptable error, a novel fractional-order stability analysis is used to derive the neural network weighting function. Moreover, it can be concluded that the proposed reducing method can preserve the main properties of the original system like a system’s stability. Simulation examples are provided to show the effectiveness of the proposed method. Finally, the proposed method is compared with the existing methods and advantages of the proposed method are shown.},
  archive      = {J_SOCO},
  author       = {Jahanbakhti, Hadi},
  doi          = {10.1007/s00500-020-04763-5},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {13489-13499},
  shortjournal = {Soft Comput.},
  title        = {A novel fractional-order neural network for model reduction of large-scale systems with fractional-order nonlinear structure},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Island artificial bee colony for global optimization.
<em>SOCO</em>, <em>24</em>(17), 13461–13487. (<a
href="https://doi.org/10.1007/s00500-020-04760-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an efficient version of artificial bee colony (ABC) algorithm based on the island model concepts. The new version is called the island artificial bee colony (iABC) algorithm. It uses the structured population concept by applying the island model to improve the diversification capabilities of ABC. In the island model, the population is divided into a set of sub-populations called islands, each of which is manipulated separately by an independent variant of the ABC. After a predefined number of iterations, the islands exchange their solutions by migration. This process can help ABC in controlling the diversity of the population during the search process and thus improve the performance. The proposed iABC is evaluated using global optimization functions established by the IEEE-CEC 2015 which include 15 test functions with various dimensions and complexities (i.e., 10, 30, and 50). In order to evaluate the performance of iABC, various parameter settings are utilized to test the effectiveness of their convergence properties. Furthermore, the performance of iABC is compared against 19 comparative methods that used the same IEEE-CEC 2015 test functions. The results show that iABC produced better results when compared with ABC in all IEEE-CEC 2015 test functions, while the results of iABC better than those of the other island-based algorithm on almost all test functions. Furthermore, iABC is able to obtain three new results for three test functions better than all the comparative methods. Using Friedman test and Holm’s procedure, iABC is ranked third, seventh, and ninth out of 19 comparative methods for the test functions with 10, 30, 50 dimensionality, respectively.},
  archive      = {J_SOCO},
  author       = {Awadallah, Mohammed A. and Al-Betar, Mohammed Azmi and Bolaji, Asaju La’aro and Doush, Iyad Abu and Hammouri, Abdelaziz I. and Mafarja, Majdi},
  doi          = {10.1007/s00500-020-04760-8},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {13461-13487},
  shortjournal = {Soft Comput.},
  title        = {Island artificial bee colony for global optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Research on the performance of multi-population genetic
algorithms with different complex network structures. <em>SOCO</em>,
<em>24</em>(17), 13441–13459. (<a
href="https://doi.org/10.1007/s00500-020-04759-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Genetic algorithm is a frequently used evolutionary algorithm that cannot avoid premature convergence. Multi-population is usually used to overcome this disadvantage, obtaining multi-population genetic algorithm (MGA). If sub-populations and communications among them are considered as nodes and edges, respectively, an MGA can be represented as a complex network. After reviewing previous researches, we find that the network structures used to design MGAs are limited and some parameters (SPS, sub-population size, and SPN, sub-population number) under a certain total individual number (TIN) are always ignored. Using seven network structures (BAnet, BDnet, CTnet, ERnet, HAnet, LCnet, and SWnet) to design MGAs that are used to solve some flexible job shop scheduling problems, how the network structures and parameters affect the performances of MGAs is addressed. The simulation results indicate that: (i) the MGA with ERnet rather than the famous BAnet often performs well although their performances are problem-dependent; (ii) the Hamming distance index proposed here can properly capture the phenomenon that the smaller the average path length, the higher the propagation rate; and (iii) under a certain TIN, their performances first increase and then decrease gradually as SPN increases, and their performances first increase rapidly and then remain almost unchanged as SPS increases.},
  archive      = {J_SOCO},
  author       = {Shi, Xiaoqiu and Long, Wei and Li, Yanyan and Deng, Dingshan and Wei, Yonglai},
  doi          = {10.1007/s00500-020-04759-1},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {13441-13459},
  shortjournal = {Soft Comput.},
  title        = {Research on the performance of multi-population genetic algorithms with different complex network structures},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The feedback artificial tree (FAT) algorithm. <em>SOCO</em>,
<em>24</em>(17), 13413–13440. (<a
href="https://doi.org/10.1007/s00500-020-04758-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by the transport of organic matters and the update theories of branches, the artificial tree (AT) algorithm was proposed recently. This work presents an improved version of AT algorithm that is called the feedback artificial tree (FAT) algorithm. In FAT, besides the transfer of organic matters, the feedback mechanism of moistures is introduced. Meanwhile, the self-propagating operator and dispersive propagation operator are also put forward. Some typical benchmark problems are applied to test the performance of FAT. The experimental results have clearly demonstrated the higher performance of FAT compared with AT over the tested set of problems. In addition, some well-known heuristic algorithms and their improved algorithms are also applied to validate the performance of FAT, and the computational results of FAT listed in this study are the best among these algorithms. In addition, sensitive analyses on the specific parameters of FAT algorithm are carried out, and the performance of FAT is validated.},
  archive      = {J_SOCO},
  author       = {Li, Q. Q. and He, Z. C. and Li, Eric},
  doi          = {10.1007/s00500-020-04758-2},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {13413-13440},
  shortjournal = {Soft Comput.},
  title        = {The feedback artificial tree (FAT) algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An integrated fuzzy-genetic failure mode and effect analysis
for aircraft wing reliability. <em>SOCO</em>, <em>24</em>(17),
13401–13412. (<a
href="https://doi.org/10.1007/s00500-020-04757-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of this paper is to propose a model for assessing the hazard system based on the failure structure of aircraft wing. The model considers reliability maintenance and repair factors. Failure Mode and Effect Analysis (FMEA) is one of the well-known methods of quality management being used for continuous improvement in product or process plans. One serious issue of FMEA is the definition of the risk priorities of failure modes. This paper proposes an analytical method based on failure modes and failure analysis in criticality and suggests a fuzzy evaluation method for evaluating the risk level of the wing of aircraft. The analytical technique includes qualitatively analyzing the operation, failure modes, failure cause, failure rate, and severity through FMEA and quantitatively assessing the safety by using the fuzzy evaluation method. Fuzzy logic and Genetic Algorithms are integrated using a risk-cost model based on FMEA and comparisons with Simulated Annealing algorithms.},
  archive      = {J_SOCO},
  author       = {Gholizadeh, Hadi and Javadian, Nikbakhsh and Fazlollahtabar, Hamed},
  doi          = {10.1007/s00500-020-04757-3},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {13401-13412},
  shortjournal = {Soft Comput.},
  title        = {An integrated fuzzy-genetic failure mode and effect analysis for aircraft wing reliability},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). New method for interval-valued hesitant fuzzy decision
making based on preference relations. <em>SOCO</em>, <em>24</em>(17),
13381–13399. (<a
href="https://doi.org/10.1007/s00500-020-04756-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interval-valued hesitant fuzzy preference relations (IVHFPRs) are powerful to express the judgments of decision makers (DMs) such as hesitancy and uncertainty. This paper continues to research decision making with IVHFPRs. To do this, it first defines a multiplicative consistency index for interval fuzzy preference relations (IFPRs). Then, it gives a new (acceptably) multiplicative consistency concept for IVHFPRs. After that, optimization models for judging the acceptably multiplicative consistency of IVHFPRs are built. When the multiplicative consistency is unacceptable, optimization models for improving the multiplicative consistency level and for minimizing the number of adjusted judgments are constructed, respectively. Based on the acceptably multiplicative consistency analysis, an algorithm for decision making with IVHFPRs is presented. Furthermore, formulae for determining the weights of the DMs and for measuring the consensus are offered. Based on the acceptably multiplicative consistency and consensus analysis, a new method for group decision making with IVHFPRs is proposed. Finally, an example about selecting the reservoir operation schemes is offered to show the efficiency of the new method and to compare with previous research.},
  archive      = {J_SOCO},
  author       = {Tang, Jie and Meng, Fanyong},
  doi          = {10.1007/s00500-020-04756-4},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {13381-13399},
  shortjournal = {Soft Comput.},
  title        = {New method for interval-valued hesitant fuzzy decision making based on preference relations},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep learning-based data imputation on time-variant data
using recurrent neural network. <em>SOCO</em>, <em>24</em>(17),
13369–13380. (<a
href="https://doi.org/10.1007/s00500-020-04755-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In general, numerous inbuilt diagnosis complications are due to improper or missing data. Thus, it becomes mandatory to perform proper imputation of the missed values to predict the diseases accurately. Imputation operations will be crucial when we encounter incompletely recorded patient data. The measurement of blood glucose level is considered to be the most important health-conscious effort that one does periodically since the false diagnosis of it leads to misinterpretation of patient health conditions that might cause fatal outcomes. But predicting those measures has become a tedious task in the course of diabetic treatment of these days. This paper focuses on the aim of the imputation of the missing patient-specific diabetic data, especially to overcome the existing methods’ demerits of yielding lesser accuracy and more time. This work attempts to predict the blood glucose levels by analyzing time-series data along with the patient activities. The patient activities are being thoroughly investigated here in this work; for instance, with the first 20-day diabetic data of a patient, the diabetic forecast for the next 10 days is made in the considered month. This prediction of patient diabetic conditions is done by proposing a novel approach for predicting the blood glucose levels with the aid of Maclaurin series-based expectation maximization, estimation of correlation relationship and dissimilarities, kernel-based Hilbert–Schmidt optimization, optimized features, and classification using the deep learning methodology of RNN—recurrent neural network. Finally, we make the performance analysis with the performance metrics like accuracy, Kappa, TN, TP, FN, FP, precision, recall, Jaccard coefficient, F1-measure, and error.},
  archive      = {J_SOCO},
  author       = {Sangeetha, M. and Senthil Kumaran, M.},
  doi          = {10.1007/s00500-020-04755-5},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {13369-13380},
  shortjournal = {Soft Comput.},
  title        = {Deep learning-based data imputation on time-variant data using recurrent neural network},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A distributed parallel training method of deep belief
networks. <em>SOCO</em>, <em>24</em>(17), 13357–13368. (<a
href="https://doi.org/10.1007/s00500-020-04754-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, it has become well known that efficient training of deep neural networks plays a vital role in various successful applications. To achieve this goal, it is impractical to use only one computer, especially when the scale of models is large and some efficient computing resources are available. In this paper, we present a distributed parallel computing framework for training deep belief networks (DBNs) by employing the great power of high-performance clusters (i.e., a system consists of many computers). Motivated by the greedy layer-wise learning algorithm of DBNs, the whole training process is divided layer by layer and distributed to different machines. At the same time, rough representations are exploited to parallelize the training process. By conducting experiments on several large-scale real datasets, the novel algorithms are shown to significantly accelerate the training speed of DBNs while achieving better or competitive prediction accuracy in comparison with the original algorithm.},
  archive      = {J_SOCO},
  author       = {Shi, Guang and Zhang, Jiangshe and Zhang, Chunxia and Hu, Junying},
  doi          = {10.1007/s00500-020-04754-6},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {13357-13368},
  shortjournal = {Soft Comput.},
  title        = {A distributed parallel training method of deep belief networks},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A metaheuristic segmentation framework for detection of
retinal disorders from fundus images using a hybrid ant colony
optimization. <em>SOCO</em>, <em>24</em>(17), 13347–13356. (<a
href="https://doi.org/10.1007/s00500-020-04753-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imaging modalities play a major role in early detection and diagnosis of various medical conditions related to the patient. Retinal image segmentation has been taken up for investigation in this research paper to efficiently detect the presence of eye disorder which could be indicators of major onset of conditions like hypertension, cataracts, diabetic retinopathy, age-related macular disorders, etc. A machine learning method for classification of given pixels in the search space into regions containing blood vessels and those that do not contain blood vessels is implemented using a three-stage neural classifier in this paper. Prior to classification, an optimization algorithm namely ant colony optimization derived from nature-inspired phenomena is used to provide an optimal feature vector set to set high standards for the neural network based classification approach. The novelty and merits of the paper lie in back tracing of the segmentation process in which optimization is done first on the preprocessed features followed by classification for segmented output on the optimized features. This results in elimination of redundant feature vectors which tend to occupy much memory as well increase the computational overhead on the process. The entire implemented system is automated by the machine learning process and tested on 30 samples, 15 each on DRIVE and STARE databases. Classification rates of nearly 98\% on an average scenario have been achieved for segmentation and 96.5\% for abnormality detection. The performances have been compared against Bayesian set models and standalone ANN models.},
  archive      = {J_SOCO},
  author       = {Devarajan, D. and Ramesh, S. M. and Gomathy, B.},
  doi          = {10.1007/s00500-020-04753-7},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {13347-13356},
  shortjournal = {Soft Comput.},
  title        = {A metaheuristic segmentation framework for detection of retinal disorders from fundus images using a hybrid ant colony optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Uncertain random portfolio selection based on risk curve.
<em>SOCO</em>, <em>24</em>(17), 13331–13345. (<a
href="https://doi.org/10.1007/s00500-020-04751-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper discusses the uncertain random portfolio selection problem when there are some existing risky securities which have enough historical data and some newly listed ones with insufficient data in the portfolio. So far, in the field of uncertain random portfolio selection, variance, skewness, and value-at-risk have been proposed as the risk criterion. This paper gives a new risk criterion for uncertain random portfolio selection and proposes a new type of mean-risk model based on this criterion to optimization. And in the end, a numerical example is presented for the sake of illustration.},
  archive      = {J_SOCO},
  author       = {Mehralizade, Rouhollah and Amini, Mohammad and Sadeghpour Gildeh, Bahram and Ahmadzade, Hamed},
  doi          = {10.1007/s00500-020-04751-9},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {13331-13345},
  shortjournal = {Soft Comput.},
  title        = {Uncertain random portfolio selection based on risk curve},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Switched-mode luo converter with power factor correction and
fast regulation under transient conditions. <em>SOCO</em>,
<em>24</em>(17), 13319–13329. (<a
href="https://doi.org/10.1007/s00500-020-04747-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {New advancements in light-emitting diode (LED) have attracted many to use LEDs in commercial and industrial applications. In the recent years, new family of DC-to-DC converters, namely super-lift Luo converters, has evolved in the power electronics terrain which have high gain than the conventional boost converter. In this paper, AC–DC converter with super-lift Luo converter as PFC topology for high-brightness light-emitting diode applications is proposed. When subjected to load and line variations, power quality parameters of PFC AC–DC converter will have a change. The indices continue to change till the output voltage gets stabilized. For fast regulation under transient conditions, particle swarm optimization tuned proportional–integral (PI) controller is used. MATLAB/Simulink environment is used to carry out extensive simulation on the work proposed. The laboratory model is constructed and tested to verify simulation results. Total harmonic distortion at the input side of an AC–DC converter is validated as per the standards of IEC 61000-3-2 of class c equipment’s.},
  archive      = {J_SOCO},
  author       = {Jambulingam Jawahar Babu and Thirumavalavan, Vinopraba},
  doi          = {10.1007/s00500-020-04747-5},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {13319-13329},
  shortjournal = {Soft Comput.},
  title        = {Switched-mode luo converter with power factor correction and fast regulation under transient conditions},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Developed multi-objective grey wolf optimizer with fuzzy
logic decision-making tool for direction overcurrent relays
coordination. <em>SOCO</em>, <em>24</em>(17), 13305–13317. (<a
href="https://doi.org/10.1007/s00500-020-04745-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new methodology for solving the coordination problem of DOCRs based on multi-objective grey wolf optimizer and fuzzy logic decision-making. In addition to the conventional objective function, a new objective function which aims to minimize the discrimination time between primary and backup relays is proposed. Moreover, the conventional objective function related to minimizing the total operating time of primary and backup relays is considered. The feasibility and performance of the proposed methodology for solving the coordination problem of DOCRs are investigated using two different systems (8-bus system and IEEE-30 bus system). The proposed methodology is compared with other reported methods. The results prove the viability and effectiveness of the proposed methodology to solve the DOCR coordination problem without any miscoordination between primary and backup relays.},
  archive      = {J_SOCO},
  author       = {Korashy, Ahmed and Kamel, Salah and Nasrat, Loai and Jurado, Francisco},
  doi          = {10.1007/s00500-020-04745-7},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {13305-13317},
  shortjournal = {Soft Comput.},
  title        = {Developed multi-objective grey wolf optimizer with fuzzy logic decision-making tool for direction overcurrent relays coordination},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Enhanced decision support system to predict and prevent
hypertension using computational intelligence techniques. <em>SOCO</em>,
<em>24</em>(17), 13293–13304. (<a
href="https://doi.org/10.1007/s00500-020-04743-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical decision support systems have been a core of intense research for years. The ongoing study shows that artificial intelligence has been accustomed to probe risk factors for hypertension. Factors, like health-damaging personal behaviors and changes in lifestyle and environment, are major contributors to chronic diseases. The goal of this research was to forecast the risk of developing hypertension by revealing hidden patterns in medical datasets. Quality of the data is the key to enhance the performance of learning model. But most healthcare data suffer from class imbalance problem, which induce the need for an intelligent model which can learn from such grimy data. This paper incorporates a novel approach by combing learning model and rule-based mining to offer decision support. Typically, the proposed work comprises two main implications. First suggests an intelligent learning model using boosting-based support vector machine to diagnose and expose multi-class categories in the imbalanced datasets. Finally, the enhanced predictive model is built upon the classification solution which will portray the innate data similarities. An intelligent fuzzy-based approach was employed to recognize frequent behavioral patterns. Based on these rules, valid decisions could be made to prevent hypertension. The suggested enhanced model is evaluated using a real-time hypertension dataset obtained through primary health centers. With the combination of ensemble strategies, the proposed intelligent learning model attains high classification accuracy for the imbalanced dataset above the traditional model. Thus, the efficient integration of personalized behavior with health data could provide a better understanding regarding patient health. In future this can serve as an eye toward personalized medicine.},
  archive      = {J_SOCO},
  author       = {Ambika, M. and Raghuraman, G. and SaiRamesh, L.},
  doi          = {10.1007/s00500-020-04743-9},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {13293-13304},
  shortjournal = {Soft Comput.},
  title        = {Enhanced decision support system to predict and prevent hypertension using computational intelligence techniques},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fuzzy approximations of a multiplicative inverse cubic
functional equation. <em>SOCO</em>, <em>24</em>(17), 13285–13292. (<a
href="https://doi.org/10.1007/s00500-020-04741-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this study is to introduce a new multiplicative inverse cubic functional equation, to accomplish its general solution, to employ Hyers’ method for solving its stability problems in Felbin’s type fuzzy normed linear spaces, to present an apt example for justifying its stability result is invalid for singular case and to elucidate its interpretation through an application in electromagnetism.},
  archive      = {J_SOCO},
  author       = {Senthil Kumar, B. V. and Dutta, Hemen and Sabarinathan, S.},
  doi          = {10.1007/s00500-020-04741-x},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {13285-13292},
  shortjournal = {Soft Comput.},
  title        = {Fuzzy approximations of a multiplicative inverse cubic functional equation},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimization of planning cost of radial distribution
networks at different loads with the optimal placement of distribution
STATCOM using differential evolution algorithm. <em>SOCO</em>,
<em>24</em>(17), 13269–13284. (<a
href="https://doi.org/10.1007/s00500-020-04739-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an optimization of planning of distribution systems with the allocation of DSTATCOM based on maximization of a net cost profit/savings analysis approach by using the differential evolution algorithm. In the proposed approach, the optimal placement of DSTATCOM, and reactive power compensation at a certain location, and the improvement of voltage profile are obtained by three objective functions: (1) minimization of the size of DSTATCOM, (2) minimization of network power loss, and (3) maximization of net cost profit/savings by minimizing the total planning cost of DSTATCOM installation scheme. Present worth factor is adopted to evaluate the net cost profit/savings of the DSTATCOM installation scheme for a certain planning horizon. The appropriate mathematical modeling of DSTATCOM is used to incorporate it suitably in the forward–backward sweep load flow algorithm of radial distribution networks to provide the reactive power compensation. The recommended method is validated on the IEEE 30-bus, 33-bus and 69-bus distribution networks.},
  archive      = {J_SOCO},
  author       = {Sanam, Joseph},
  doi          = {10.1007/s00500-020-04739-5},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {13269-13284},
  shortjournal = {Soft Comput.},
  title        = {Optimization of planning cost of radial distribution networks at different loads with the optimal placement of distribution STATCOM using differential evolution algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multivariate bounded support laplace mixture model.
<em>SOCO</em>, <em>24</em>(17), 13239–13268. (<a
href="https://doi.org/10.1007/s00500-020-04737-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, bounded Laplace mixture model (BLMM) is proposed. The parameters of proposed model are estimated by maximum likelihood approach via expectation maximization and Newton–Raphson algorithm. The model is proposed for data modeling to perform clustering using synthetic data for univariate and multivariate examples and real datasets of different medical experiments. BLMM is validated through correctness of estimated parameters for synthetic data and clustering accuracy of medical datasets. A new modeling scheme is also introduced for wavelet coefficients which is based on BLMM. It is applied to image clustering and content-based image retrieval (CBIR) for feature extraction in wavelet domain. For feature extraction in this application, each image is decomposed into a set of wavelet subspaces and BLMM with two components is adopted to model the statistical characteristics of the wavelet coefficients for each wavelet subspace. The model parameters adapted from BLMM represent the image features in wavelet domain for each subspace and selected to formulate the feature space which is further used in clustering and CBIR. In the framework for clustering and image retrieval, features extracted in wavelet domain are further modeled through BLMM to categorize images into different groups and trained model is adopted for CBIR. In order to perform image retrieval with trained model via BLMM, city block distance, posterior probability and Kullback–Leibler divergence are introduced. We also propose a novel solution to compute Kullback–Leibler divergence which is very effective for image retrieval due to its low computational complexity and high retrieval rate. The effectiveness and viability of BLMM in texture image clustering and CBIR are demonstrated through UIUC, KTH-TIPS, DTD, STex and Kylberg databases. Different experiments are performed in the chosen applications, and from the results, BLMM has demonstrated its effectiveness in modeling synthetic data, real datasets from medical experiments, feature extraction in wavelet domain, image clustering and CBIR.},
  archive      = {J_SOCO},
  author       = {Azam, Muhammad and Bouguila, Nizar},
  doi          = {10.1007/s00500-020-04737-7},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {13239-13268},
  shortjournal = {Soft Comput.},
  title        = {Multivariate bounded support laplace mixture model},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Clustering of the body shape of the adult male by using
principal component analysis and genetic algorithm–BP neural network.
<em>SOCO</em>, <em>24</em>(17), 13219–13237. (<a
href="https://doi.org/10.1007/s00500-020-04735-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to improve the efficiency and accuracy of human body shape prediction, principal component analysis method (PCA) is proposed to reduce the dimension of related variables and eliminate the multicollinearity among variables. Then, the transformed variables are input into genetic algorithm and BP neural network, and a new method of human body shape prediction is designed. To avoid the problems that slow convergence speed and easy falling into local minima of BP neural network, the genetic algorithm is used to optimize the weights and thresholds of BP neural network. Moreover, to prove the superiority of PCA–GA–BP model, the prediction results are compared with those of other algorithms. Body sizes of 18–25-year-old, 26–44-year-old and 45–59-year-old males were selected as experimental data to analyze these models. The prediction results of GA–BP, PCA–BP, BP, SVM and K-means were compared with PCA–GA–BP neural network. The results show that the prediction effect of PCA–GA–BP neural network is significantly better than that of GA–BP, PCA–BP, BP, SVM and K-means prediction models, which can accurately predict and cluster the human body shape. The model has better prediction and classification and simpler structure.},
  archive      = {J_SOCO},
  author       = {Cheng, Pengpeng and Chen, Daoling and Wang, Jianping},
  doi          = {10.1007/s00500-020-04735-9},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {13219-13237},
  shortjournal = {Soft Comput.},
  title        = {Clustering of the body shape of the adult male by using principal component analysis and genetic algorithm–BP neural network},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). LASSO multi-objective learning algorithm for feature
selection. <em>SOCO</em>, <em>24</em>(17), 13209–13217. (<a
href="https://doi.org/10.1007/s00500-020-04734-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work proposes a new algorithm for training neural networks to solve the problems of feature selection and function approximation. The algorithm applies different weight constraint functions for the hidden and the output layers of a multilayer perceptron neural network. The LASSO operator is applied to the hidden layer; therefore, the training provides automatic selection of relevant features and the standard norm regularization function is applied to the output layer. Therefore, we propose a multi-objective training algorithm that is able to select the important features while solving the approximation problem.},
  archive      = {J_SOCO},
  author       = {Coelho, Frederico and Costa, Marcelo and Verleysen, Michel and Braga, Antônio P.},
  doi          = {10.1007/s00500-020-04734-w},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {13209-13217},
  shortjournal = {Soft Comput.},
  title        = {LASSO multi-objective learning algorithm for feature selection},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A computational approach for printed document forensics
using SURF and ORB features. <em>SOCO</em>, <em>24</em>(17),
13197–13208. (<a
href="https://doi.org/10.1007/s00500-020-04733-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Document forgery is quite common nowadays due to the availability of cost-effective scanners and printers. Important documents like certificates, passport, identification cards, etc., are protected using watermarks or signatures. These are made secured with a protective printing mechanism with extrinsic fingerprints. Therefore, it is easy to authenticate such documents. Other documents required a passive approach for their authentication. These approaches look for document inconsistencies for chances of modification. Some of these attempt to detect and fix the source of the printed document. This paper proposes a classifier-based model to identify the source printer and classify the questioned document in one of the printer classes. A novel approach of utilizing Speeded Up Robust Features and Oriented Fast Rotated and BRIEF feature descriptors is proposed for printer attribution. Naive Bayes, k-NN, random forest and different combinations of these classifiers have been experimented for classification. The proposed model can efficiently classify the questioned documents to their respective printer class. An accuracy of 86.5\% has been achieved using a combination of Naive Bayes, k-NN, random forest classifiers with a simple majority voting scheme and adaptive boosting methodology.},
  archive      = {J_SOCO},
  author       = {Kumar, Munish and Gupta, Surbhi and Mohan, Neeraj},
  doi          = {10.1007/s00500-020-04733-x},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {13197-13208},
  shortjournal = {Soft Comput.},
  title        = {A computational approach for printed document forensics using SURF and ORB features},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Self-adaptive weight vector adjustment strategy for
decomposition-based multi-objective differential evolution algorithm.
<em>SOCO</em>, <em>24</em>(17), 13179–13195. (<a
href="https://doi.org/10.1007/s00500-020-04732-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-objective and many-objective optimization, weight vectors are particularly crucial to the performance of decomposition-based optimization algorithms. The uniform weight vectors are not suitable for complex Pareto fronts (PFs), so it is necessary to improve the distribution of weight vectors. Besides, the balance between convergence and diversity is a difficult issue as well in multi-objective optimization, and it becomes increasingly important with the augment of the number of objectives. To address these issues, a self-adaptive weight vector adjustment strategy for decomposition-based multi-objective differential evolution algorithm (AWDMODE) is proposed. In order to ensure that the guidance of weight vectors becomes accurate and effective, the adaptive adjustment strategy is introduced. This strategy distinguishes the shapes and adjusts weight vectors dynamically, which can ensure that the guidance of weight vectors becomes accurate and effective. In addition, a self-learning strategy is adopted to produce more non-dominated solutions and balance the convergence and diversity. The experimental results indicate that AWDMODE outperforms the compared algorithms on WFG suites test instances, and shows a great potential when handling the problems whose PFs are scaled with different ranges in each objective.},
  archive      = {J_SOCO},
  author       = {Fan, Rui and Wei, Lixin and Li, Xin and Zhang, Jinlu and Fan, Zheng},
  doi          = {10.1007/s00500-020-04732-y},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {13179-13195},
  shortjournal = {Soft Comput.},
  title        = {Self-adaptive weight vector adjustment strategy for decomposition-based multi-objective differential evolution algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Risk factors analysis and classification on heart disease.
<em>SOCO</em>, <em>24</em>(17), 13167–13178. (<a
href="https://doi.org/10.1007/s00500-020-04731-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, there has been a high prevalence rate of heart disease (HD) among 50-year-old people in China. It has become the first disease of old ages death. It is a very interesting and challenging work to have an effective early forecasting of the risk of HD according to the patients data. In this paper, we propose a novel method to analyze the factors with views of group features. Normalized mutual information based on entropies and information gain ratio are employed to select factors. Discriminant minimum class locality preserving canonical correlation analysis is presented to determine the effectiveness of the view of group factors. Moreover, a novel model is given to forecast the risks of New York Heart Association Functional Classification. To verify the effectiveness of the proposed method and model, we collected electronic health records of 1271 patients from 28 Chinese Level III-A hospitals in 2015. After the risk factors analysis, several results are concluded: (1) Patients with HD usually suffer from similar complications. For example, most patients with heart disease suffer from hypertension, diabetes and arrhythmia at the same time. (2) The risk forecasting has an accurate recognition rate. The risk value of the level of patients is impacted on the complications. (3) Hypertension, arrhythmia, chronic cardiac insufficiency and coronary disease are the highest concurrent diseases. There is a high reliability to have a decision of levels on the cardiac functional diseases according to the output of our proposed model.},
  archive      = {J_SOCO},
  author       = {Luo, Jianfeng and Yan, Haifeng and Yuan, Yubo},
  doi          = {10.1007/s00500-020-04731-z},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {13167-13178},
  shortjournal = {Soft Comput.},
  title        = {Risk factors analysis and classification on heart disease},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A self-adaptive virus optimization algorithm for continuous
optimization problems. <em>SOCO</em>, <em>24</em>(17), 13147–13166. (<a
href="https://doi.org/10.1007/s00500-020-04730-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the outstanding effectiveness and efficiency performance in different fields such as image processing and energy dispatching, the virus optimization algorithm (VOA), a newly developed metaheuristic for general optimization purposes, has been further improved. Similar to other metaheuristic methods, VOA performance to some degree relies on proper parameter settings, which may require large numbers of experiments to determine. Therefore, this study proposes a self-adaptive version of VOA (SaVOA) to decrease the number of controllable parameters in the algorithm and thus reduce the time needed to determine proper parameter values by any sort of experimental design process. Having an SaVOA ensures the ease access of the algorithm for different types of continuous domain problems, whereas previous different optimization problems may have needed different parameter settings. To perform the comparison, SaVOA is tested by optimizing the same set of benchmark functions used when proposing the original VOA. Computational results indicate some major advances were achieved by the SaVOA in addition to competitive results obtained. Most importantly, SaVOA proved its superiority on functions where the original VOA was not powerful enough to perform well, such as Rosenbrock, Schwefel, Drop Wave, Levy, and Easom’s functions. In terms of implementation, the number of controllable parameters in SaVOA was greatly reduced to only one—the stopping criterion. This promises a significant improvement in the utility of SaVOA for any type of continuous domain optimization problem.},
  archive      = {J_SOCO},
  author       = {Liang, Yun-Chia and Cuevas Juarez, Josue Rodolfo},
  doi          = {10.1007/s00500-020-04730-0},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {13147-13166},
  shortjournal = {Soft Comput.},
  title        = {A self-adaptive virus optimization algorithm for continuous optimization problems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Soft computing-based fuzzy integral sliding mode control: A
real-time investigation on a conical tank process. <em>SOCO</em>,
<em>24</em>(17), 13135–13146. (<a
href="https://doi.org/10.1007/s00500-020-04729-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, a fuzzy integral sliding mode controller (FISMC) for level control in a conical tank process is demonstrated in real time. In traditional sliding mode controller (SMC) algorithm, the robustness with respect to parameter variations and external disturbances can be achieved only after the reach of sliding phase. However, robustness is not guaranteed during the reaching phase. But integral sliding mode controller (ISMC) hunts to eliminate the reaching phase by imposing sliding mode throughout the system response. ISMC also mitigates chattering caused by discontinuity of controller. Hence, integral of error term is used in the sliding surface. A modified power rate reaching law is proposed to describe the dynamics of the switching function. The fuzzy logic system is integrated to approximate the sliding variable, and control law is formulated so as to alleviate the chattering effect of the control signal. In this paper, Takagi and Sugeno fuzzy logic is integrated with ISMC to achieve smoother sliding surface. Genetic algorithm (GA) is used to tune the membership functions of fuzzy logic and the parameters of the control law. GA-tuned FISMC integrates the features of fuzzy logic control, SMC and soft computing techniques. The effectiveness of algorithm is demonstrated in an experimental setup. The reported results confirm the superiority of GAFISMC compared with proportional integral controller and ISMC algorithm. The real-time implementation ensures the robustness of GAFISMC in terms of operating-level variations, parameter variations and disturbance rejection.},
  archive      = {J_SOCO},
  author       = {Nagammai, S. and Latha, S. and Varatharajan, M.},
  doi          = {10.1007/s00500-020-04729-7},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {13135-13146},
  shortjournal = {Soft Comput.},
  title        = {Soft computing-based fuzzy integral sliding mode control: A real-time investigation on a conical tank process},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fuzzy volumetric delineation of brain tumor and survival
prediction. <em>SOCO</em>, <em>24</em>(17), 13115–13134. (<a
href="https://doi.org/10.1007/s00500-020-04728-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel three-dimensional detailed delineation algorithm is introduced for Glioblastoma multiforme tumors in MRI. It efficiently delineates the whole tumor, enhancing core, edema and necrosis volumes using fuzzy connectivity and multi-thresholding, based on a single seed voxel. While the whole tumor volume delineation uses FLAIR and T2 MRI channels, the outlining of the enhancing core, necrosis and edema volumes employs the T1C channel. Discrete curve evolution is initially applied for multi-thresholding, to determine intervals around significant (visually critical) points, and a threshold is determined in each interval using bi-level Otsu’s method or Li and Lee’s entropy. This is followed by an interactive whole tumor volume delineation using FLAIR and T2 MRI sequences, requiring a single user-defined seed. An efficient and robust whole tumor extraction is executed using fuzzy connectedness and dynamic thresholding. Finally, the segmented whole tumor volume in T1C MRI channel is again subjected to multi-level segmentation, to delineate its sub-parts, encompassing enhancing core, necrosis and edema. This was followed by survival prediction of patients using the concept of habitats. Qualitative and quantitative evaluation, on FLAIR, T2 and T1C MR sequences of 29 GBM patients, establish its superiority over related methods, visually as well as in terms of Dice scores, Sensitivity and Hausdorff distance.},
  archive      = {J_SOCO},
  author       = {Bhadani, Saumya and Mitra, Sushmita and Banerjee, Subhashis},
  doi          = {10.1007/s00500-020-04728-8},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {13115-13134},
  shortjournal = {Soft Comput.},
  title        = {Fuzzy volumetric delineation of brain tumor and survival prediction},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal electrical load forecasting for hybrid renewable
resources through a hybrid memetic cuckoo search approach.
<em>SOCO</em>, <em>24</em>(17), 13099–13114. (<a
href="https://doi.org/10.1007/s00500-020-04727-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although renewable energy grows to be progressively trendier in the universal power grid, enhancing the precision or accuracy is a crucial task. Therefore, managing, operating and planning of modern power systems become difficult in case of renewable energy load forecasting. Due to the intermittent and disordered nature of renewable resources, load forecasting becomes a complicated task. The renewable energy system introduces various approaches to enhance load forecasting accuracy. This paper describes the technofeasibility and the optimal design of HRE resources such as photovoltaic, wind turbine, biogasifiers, and battery to satisfy all power demand optimally using a hybrid algorithm. The hybrid algorithm is the grouping of DRNN, memetic and cuckoo search algorithm to form a proposed HMCS-DRNN approach. This proposed approach is employed to provide better optimization performances, and apart from precision and stability in load forecasting, the HMCS-DRNN approach offers the predicted result with better efficiency and minimum error value rate. The efficiency of the proposed approach articulates by calculating the statistical measure regarding RMSE and MAPE, respectively. The simulation results describe that the performances of the HMCS algorithm provide better optimization results on various 30 unconstrained benchmark functions.},
  archive      = {J_SOCO},
  author       = {Sengar, Shweta and Liu, Xiaodong},
  doi          = {10.1007/s00500-020-04727-9},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {13099-13114},
  shortjournal = {Soft Comput.},
  title        = {Optimal electrical load forecasting for hybrid renewable resources through a hybrid memetic cuckoo search approach},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Estimating the distribution of enterprise values with
quantile neural networks. <em>SOCO</em>, <em>24</em>(17), 13085–13097.
(<a href="https://doi.org/10.1007/s00500-020-04726-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The probability density function of enterprise values may be more precise and useful in the cases of corporate investment, financing, or transactions. Although the quantile regression analysis can generate a set of models for a series of quantiles, it cannot generate the probability density function of the dependent variable. Therefore, this paper proposes a novel method of employing prediction results of the quantile neural networks to build probability density functions with which we can effectively assess enterprise values. Empirical evidence reveals that the estimated cumulative lognormal distribution curves of the price-to-book value ratio (PBR) and the data are well matched. In addition, the corporate market value is equal to the PBR multiplied by the corporate stockholders equity. Thus, the corporate market value is also a lognormal distribution. PBR distributions of building and construction industries are more tilted to the left, implying that enterprise values of building and construction industries are lower than those of other industries with the same stockholders equity and return on equity.},
  archive      = {J_SOCO},
  author       = {Yeh, I-Cheng and Liu, Yi-Cheng},
  doi          = {10.1007/s00500-020-04726-w},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {13085-13097},
  shortjournal = {Soft Comput.},
  title        = {Estimating the distribution of enterprise values with quantile neural networks},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new flower pollination algorithm for equalization in
synchronous DS/CDMA multiuser communication systems. <em>SOCO</em>,
<em>24</em>(17), 13069–13083. (<a
href="https://doi.org/10.1007/s00500-020-04725-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work proposes a modified version of an emerging nature-inspired technique, named flower pollination algorithm, for equalizing digital multiuser channels. This equalization involves two different tasks: (1) estimation of the channel impulse response, and (2) estimation of the users’ transmitted symbols. The new algorithm is developed and applied in a direct sequence/code-division multiple-access multiuser communications system. Important issues such as robustness, convergence speed and population diversity control have been in deep investigated. A method based on the entropy of the flowers’ fitness is proposed for in-service monitoring and adjusting population diversity. Numerical simulations analyze the performance, showing comparisons with well-known conventional multiuser detectors such as matched filter, minimum mean square error estimator or several Bayesian schemes, as well as with other nature-inspired strategies. Numerical analysis shows that the proposed algorithm enables transmission at higher symbol rates under stronger fading and interference conditions, constituting an attractive alternative to previous algorithms, both conventional and nature-inspired, whose performance is frequently sensible to near–far effects and multiple-access interference problems. These results have been validated by running hypothesis tests to confirm statistical significance.},
  archive      = {J_SOCO},
  author       = {San-José-Revuelta, Luis M. and Casaseca-de-la-Higuera, Pablo},
  doi          = {10.1007/s00500-020-04725-x},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {13069-13083},
  shortjournal = {Soft Comput.},
  title        = {A new flower pollination algorithm for equalization in synchronous DS/CDMA multiuser communication systems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimum design and analysis of HRES for rural
electrification: A case study of korkadu district. <em>SOCO</em>,
<em>24</em>(17), 13051–13068. (<a
href="https://doi.org/10.1007/s00500-020-04724-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper demonstrates the optimum design and analysis of hybrid renewable energy system (HRES) for village electrification in Korkadu, Puducherry, India. Renewable energy sources (RES) comprises of photovoltaic, wind turbine and bio-diesel generators. The main target of this work is to design an optimal HRES system that can generate and provide cost-effective electricity to satisfy the electricity need. In the pre-hybrid optimization model for the electric renewable (HOMER), the paper evaluates the load forecasting for the selected district. For reliable electrification, the desired HRES needs to meet the forecasted load demand. HOMER software is used to estimate the different feasible hybrid configurations. The configurations are hybrid conventional (bio-gasifiers) and renewable energy system, standalone renewable energy system with high renewable fractions and standalone conventional (bio-gasifiers) system. From the investigations, it indicates that the Korkadu zone is highly potential area for implementing standalone hybrid electrification system. Furthermore, the proposed work result demonstrates that the HRES-based power generation at off-grid location can be a cost-effective. Additionally, our proposed strategy can conquer the uncertainty found in RES and the over-sizing issues in installed capacity.},
  archive      = {J_SOCO},
  author       = {Krishnamoorthy, Murugaperumal and Raj, P. Ajay D. Vimal},
  doi          = {10.1007/s00500-020-04724-y},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {13051-13068},
  shortjournal = {Soft Comput.},
  title        = {Optimum design and analysis of HRES for rural electrification: A case study of korkadu district},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal processing of nearest-neighbor user queries in
crowdsourcing based on the whale optimization algorithm. <em>SOCO</em>,
<em>24</em>(17), 13037–13050. (<a
href="https://doi.org/10.1007/s00500-020-04722-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generally, human and machine-based query operations can be modified with the use of crowdsourcing. Location-based queries are classified into range and k-nearest neighbor (KNN) queries. Space and point of interest (POI) information can be obtained from both range and KNN queries. In this paper, we expose the trust stage computation of range and KNN query answers with the help of the whale optimization algorithm (WOA). The system chooses either parallel or serial processing, and the experiments are carried out using real-time crowdsourcing. The effectiveness of the proposed concept is evaluated through various consequences such as gang dimension, POI information, space information, and range and KNN query consequences. Each of these effects produces an optimal and reliable result. Finally, the computation time and communication overhead performance of serial and parallel processing are analyzed by examining consequences and production of optimal outcomes.},
  archive      = {J_SOCO},
  author       = {Bhaskar, N. and Kumar, P. Mohan},
  doi          = {10.1007/s00500-020-04722-0},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {13037-13050},
  shortjournal = {Soft Comput.},
  title        = {Optimal processing of nearest-neighbor user queries in crowdsourcing based on the whale optimization algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel nature-inspired meta-heuristic algorithm for
optimization: Bear smell search algorithm. <em>SOCO</em>,
<em>24</em>(17), 13003–13035. (<a
href="https://doi.org/10.1007/s00500-020-04721-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the recent years, the optimization problems show that they are a big challenge for engineering regarding the fast growth of new nature-inspired optimization algorithms. Therefore, this paper presents a novel nature-inspired meta-heuristic algorithm for optimization which is called as bear smell search algorithm (BSSA) that takes into account the powerful global and local search operators. The proposed algorithm imitates both dynamic behaviors of bear based on sense of smell mechanism and the way bear moves in the search of food in thousand miles farther. Among all animals, bears have inconceivable sense of smell due to their huge olfactory bulbs that manage the sense of different odors. Since the olfactory bulb is a neural model of the vertebrate forebrain, it can make a strong exploration and exploitation for optimization. According to the odors value, bear moves the next location. Therefore, this paper mathematically models these structures. To demonstrate and evaluate the BSSA ability, numerous types of benchmark functions and four engineering problems are employed to compare the obtained results of BSSA with other available optimization methods with several analyzed indices such as pair-wise test, Wilcoxon rank and statistical analysis. The numerical results revealed that proposed BSSA presents competitive and greater results compared to other optimization algorithms.},
  archive      = {J_SOCO},
  author       = {Ghasemi-Marzbali, Ali},
  doi          = {10.1007/s00500-020-04721-1},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {13003-13035},
  shortjournal = {Soft Comput.},
  title        = {A novel nature-inspired meta-heuristic algorithm for optimization: Bear smell search algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Bi-ideal approximation spaces and their applications.
<em>SOCO</em>, <em>24</em>(17), 12989–13001. (<a
href="https://doi.org/10.1007/s00500-020-04720-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The original model of rough sets was advanced by Pawlak, which was mainly involved with the approximation of things using an equivalence relation on the universal set of his approximation space. In this paper, two kinds of approximation operators via ideals which represent extensions of Pawlak’s approximation operator have been presented. In both kinds, the definitions of upper and lower approximations based on ideals have been given. Moreover, a new type of approximation spaces via two ideals which is called bi-ideal approximation spaces was introduced for the first time. This type of approximations was analyzed by two different methods, their properties are investigated, and the relationship between these methods is proposed. The importance of these methods was its dependent on ideals which were topological tools, and the two ideals represent two opinions instead of one opinion. At the end of the paper, an applied example had been introduced in the chemistry field by applying the current methods to illustrate the definitions in a friendly way.},
  archive      = {J_SOCO},
  author       = {Kandil, A. and El-Sheikh, S. A. and Hosny, M. and Raafat, M.},
  doi          = {10.1007/s00500-020-04720-2},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {12989-13001},
  shortjournal = {Soft Comput.},
  title        = {Bi-ideal approximation spaces and their applications},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Soft computing-based semi-automated test case selection
using gradient-based techniques. <em>SOCO</em>, <em>24</em>(17),
12981–12987. (<a
href="https://doi.org/10.1007/s00500-020-04719-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software testing has been one very time-consuming and expensive phases in the process of software development. It needs plenty of effort in the development of tools for the process to reduce both cost and time in the development of software. The test cases were the input parameters along with expected results and conditions of execution that are used for testing. The test case selection (TCS) is approaches that aim at the selection of subsets for the test cases in a particular domain based on the criterion of interest. The primary aim is the elimination of unwanted and redundant test data aside from maximizing fault detection. Optimization techniques are applied for TCS to efficient testing. A local method of search is very popular among algorithms for the performance of optimization which is known as the gradient descent. This makes use of structural information from the nonlinear model. Simulated annealing (SA), on the other hand, is one which is global heuristic that minimizes the cost function. This work has proposed a high level of gradient descent and simulated annealing for the selection of software test case. Experiments showed that the modified SA has a lower number of print tokens by 3.82\% for the 10,000 cost, by about 2.5\% for the 30,000 cost, by about 1.17\% for the 50,000 cost and finally by about 1.14\% for the 70,000 cost.},
  archive      = {J_SOCO},
  author       = {Nithya, T. M. and Chitra, S.},
  doi          = {10.1007/s00500-020-04719-9},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {12981-12987},
  shortjournal = {Soft Comput.},
  title        = {Soft computing-based semi-automated test case selection using gradient-based techniques},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A binary social spider algorithm for continuous optimization
task. <em>SOCO</em>, <em>24</em>(17), 12953–12979. (<a
href="https://doi.org/10.1007/s00500-020-04718-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The social spider algorithm (SSA) is a new heuristic algorithm created on spider behaviors. The original study of this algorithm was proposed to solve continuous problems. In this paper, the binary version of SSA (binary SSA) is introduced to solve binary problems. Currently, there is insufficient focus on the binary version of SSA in the literature. The main part of the binary version is at the transfer function. The transfer function is responsible for mapping continuous search space to discrete search space. In this study, four of the transfer functions divided into two families, S-shaped and V-shaped, are evaluated. Thus, four different variations of binary SSA are formed as binary SSA-Tanh, binary SSA-Sigm, binary SSA-MSigm and binary SSA-Arctan. Two different techniques (SimSSA and LogicSSA) are developed at the candidate solution production schema in binary SSA. SimSSA is used to measure similarities between two binary solutions. With SimSSA, binary SSA’s ability to discover new points in search space has been increased. Thus, binary SSA is able to find global optimum instead of local optimums. LogicSSA which is inspired by the logic gates and a popular method in recent years has been used to avoid local minima traps. By these two techniques, the exploration and exploitation capabilities of binary SSA in the binary search space are improved. Eighteen unimodal and multimodal standard benchmark optimization functions are employed to evaluate variations of binary SSA. To select the best variations of binary SSA, a comparative study is presented. The Wilcoxon signed-rank test has applied to the experimental results of variations of binary SSA. Compared to well-known evolutionary and recently developed methods in the literature, the variations of binary SSA performance is quite good. In particular, binary SSA-Tanh and binary SSA-Arctan variations of binary SSA showed superior performance.},
  archive      = {J_SOCO},
  author       = {Baş, Emine and Ülker, Erkan},
  doi          = {10.1007/s00500-020-04718-w},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {12953-12979},
  shortjournal = {Soft Comput.},
  title        = {A binary social spider algorithm for continuous optimization task},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptive parameter tuning stacked autoencoders for process
monitoring. <em>SOCO</em>, <em>24</em>(17), 12937–12951. (<a
href="https://doi.org/10.1007/s00500-020-04717-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In process monitoring based on stacked autoencoders (SAEs), the performance of monitoring models is directly decided by the validity of the structure and parameters, which are primarily determined by time-consuming manual adjustments. This paper presents a novel method that can adaptively select parameters rather than tuning them manually. The proposed method is called adaptive parameter tuning SAE (APT-SAE). Basic SAEs aim to compress the original input data and extract simple and abstract features. Thus, the redundant information of each hidden layer output should be as small as possible. The next layer of nodes can be remarkably reduced if the amount of redundant information is large. During the pre-training stage of APT-SAE, an adaptive parameter tuning strategy is used for rapidly determining the number of layers and nodes in the paper. The cross-covariance of each AE’s input data is used to determine the node number of succeeding AE. The pre-training stage ends when the correlation is weak, which is decided by the average value of cross-variance matrix. The proposed method is applied to a benchmark problem, and it outperforms several state-of-the-art methods.},
  archive      = {J_SOCO},
  author       = {Kong, Diehao and Yan, Xuefeng},
  doi          = {10.1007/s00500-020-04717-x},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {12937-12951},
  shortjournal = {Soft Comput.},
  title        = {Adaptive parameter tuning stacked autoencoders for process monitoring},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modified sine cosine algorithm-based fuzzy-aided PID
controller for automatic generation control of multiarea power systems.
<em>SOCO</em>, <em>24</em>(17), 12919–12936. (<a
href="https://doi.org/10.1007/s00500-020-04716-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The research paper presents implementation of a fuzzy rule and membership function-based fuzzy-aided PID controller for automatic generation control (AGC) in multiarea nonlinear power system. At the initial stage of this proposed work, a three-area nine-unit installed interconnected network is considered for developing different dynamic responses in response to AGC analysis. A modified approach named modified sine cosine algorithm (M-SCA) is proposed for tuning the gain parameters of the above-proposed fuzzy controller to produce close optimum gain values. The proposed modified algorithm is developed from its original sine cosine algorithm by improving and updating few equations which is capable of making the balance between exploration and exploitation levels of this algorithm and improving the updating quality of iteration. To impose supremacy of M-SCA technique, it is examined through convergence curves and its performance is compared with host sine cosine algorithm, genetic algorithm, and particle swarm optimization algorithm. For controller supremacy analysis, the performance of the proposed fuzzy-aided PID controller is compared with conventional I, PI, and PID controllers, and it has been revealed that proposed M-SCA-tuned fuzzy-aided PID controller exhibits better performances through different deviated responses for AGC analysis. To demonstrate most standard and supremacy of proposed approaches, finally these are tested through a five-area ten-unit system considering some physical nonlinear constraints like generation rate constraint, governor dead band, boiler dynamics and time delay. At the final observation level, the proposed fuzzy controller has gone through different sensitivity analyses with variation of different system parametric conditions and different load conditions.},
  archive      = {J_SOCO},
  author       = {Sahu, P. C. and Prusty, R. C. and Sahoo, B. K.},
  doi          = {10.1007/s00500-020-04716-y},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {12919-12936},
  shortjournal = {Soft Comput.},
  title        = {Modified sine cosine algorithm-based fuzzy-aided PID controller for automatic generation control of multiarea power systems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Knowledge-enhanced temporal word embedding for diachronic
semantic change estimation. <em>SOCO</em>, <em>24</em>(17), 12901–12918.
(<a href="https://doi.org/10.1007/s00500-020-04714-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Historical, social and linguistic factors cause semantic changes that can narrow, broaden or completely alter the meanings of words. Frequency, syntactic and semantic variations are to be studied to examine such changes. Syntactic changes cannot be observed in many cases, if words have no POS variation. Context and connotation contribute more to semantic alteration. In addition, words have similar or related meanings in certain contexts, and the context is considered with diverse features such as co-occurrence and word association. The semantic change is generally related to the variation in n-gram context with a maximum of 5 g. However, distant context terms also play a prominent role in semantic change. There is also a link between the type of change and the use of lexical relations. This paper builds a knowledge-enhanced temporal word embedding model that utilizes ‘word-centric dependency relations’ for capturing context words irrespective of their n-gram position and ‘syntactic patterns for lexical relations’ for determining the type of semantic change. The joint learning of contexts with both dependency and lexical relations from diachronic corpora is performed to obtain temporal word embedding vectors. The proposed model outperforms other n-gram-based approaches when evaluated with standard diachronic corpora.},
  archive      = {J_SOCO},
  author       = {Vijayarani, J. and Geetha, T. V.},
  doi          = {10.1007/s00500-020-04714-0},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {12901-12918},
  shortjournal = {Soft Comput.},
  title        = {Knowledge-enhanced temporal word embedding for diachronic semantic change estimation},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evolving semantic object segmentation methods automatically
by genetic programming from images and image processing operators.
<em>SOCO</em>, <em>24</em>(17), 12887–12900. (<a
href="https://doi.org/10.1007/s00500-020-04713-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Even though numerous segmentation methods exist, the requirement of prior knowledge or parameter tuning makes them restricted to limited image domains. Without predefining solution models, genetic programming (GP) is able to solve complex problems by evolving computer programs automatically. In this paper, three new GP-based methods are designed to evolve segmentation algorithms automatically from images and primitive image processing operators (e.g., filters and histogram equalization). Specifically, a strongly typed representation, the cooperative coevolution technique and a two-stage evolution are introduced in GP, respectively, to form three new methods that can evolve solutions to conduct image preprocessing, segmentation and postprocessing automatically. The new methods are termed as StronglyGP, CoevoGP and TwostageGP, and standard GP-based algorithm (StandardGP) is employed as a reference method. The proposed methods are tested on two complicated datasets (i.e., Weizmann and Pascal datasets), which contain high variations in both objects and backgrounds. The results show that StronglyGP and StandardGP can evolve effective segmentors for the given complex segmentation tasks, while CoevoGP and TwostageGP perform worse than StronglyGP and StandardGP, which may be caused by the overfitting problem in deriving postprocessing solutions. In addition, compared with StandardGP, StronglyGP achieves better segmentation performance with smaller solution sizes. Moreover, compared with four widely used segmentation methods, StronglyGP and StandardGP can produce satisfactory results consistently on both Weizmann and Pascal datasets.},
  archive      = {J_SOCO},
  author       = {Liang, Jiayu and Wen, Jixiang and Wang, Zhe and Wang, Jianming},
  doi          = {10.1007/s00500-020-04713-1},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {12887-12900},
  shortjournal = {Soft Comput.},
  title        = {Evolving semantic object segmentation methods automatically by genetic programming from images and image processing operators},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel ODV crossover operator-based genetic algorithms for
traveling salesman problem. <em>SOCO</em>, <em>24</em>(17), 12855–12885.
(<a href="https://doi.org/10.1007/s00500-020-04712-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The genetic algorithm is a popular meta-heuristic optimization technique whose performance depends on the quality of the initial population and the crossover operator used to manipulate the individuals to obtain the final optimal solution. It is evident that when similar principle is followed for population seeding and crossover operators, it can enhance the speed of convergence and the quality of final individuals. The recent and popular population seeding technique for combinatorial genetic algorithm is ordered distance vector-based population seeding which works best with respect to convergence rate and diversity. However, the technique could not achieve the zero error rate convergence for the large-sized test instances. Thus, in this paper, an ordered distance vector-based crossover operator is proposed that exclusively exploits the advantages of individuals’ generated using the same initialization methods to attain the complete convergence, particularly for most of the large-sized test instances considered. One of the famous combinatorial problems of traveling salesman problem obtained from standard library is chosen as the testbed. From the experimental results, the proposed genetic algorithm model outshines the other existing and popular working genetic algorithm models in the literature.},
  archive      = {J_SOCO},
  author       = {Victer Paul, P. and Ganeshkumar, C. and Dhavachelvan, P. and Baskaran, R.},
  doi          = {10.1007/s00500-020-04712-2},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {12855-12885},
  shortjournal = {Soft Comput.},
  title        = {A novel ODV crossover operator-based genetic algorithms for traveling salesman problem},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Energy-efficient multipath routing in networking aid of
clustering with OGFSO algorithm. <em>SOCO</em>, <em>24</em>(17),
12845–12854. (<a
href="https://doi.org/10.1007/s00500-020-04710-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Networking is made out of remote mobile nodes; these nodes progressively structure a network with no centralized controller. Due to this dynamic nature, the nodes act as routers to keep up routing and sending data bundles. Be that as it may, the mobile nodes do not have changeless power supply and need to depend on batteries; in this way, they consume more energy and lessen network lifetime. The proposed work considers the issue of energy consumption in MANET, and it is overwhelmed by the optimization of energy constraint. At first, the mobile nodes in MANET are grouped by the proposed K-medoid clustering algorithm, which can lessen the cost of the routing of data in huge and dense networks. From each cluster, the limited energy consumption-based multipath routing is accomplished by utilizing the opposition genetic-based fish swarm optimization algorithm. The exhibition of the proposed system will be evaluated as far as data transmission, service cost, network lifetime, etc., are concerned. Simulation results revealed that the energy efficiency and network lifetime of our recommended work are improved than those of existing work.},
  archive      = {J_SOCO},
  author       = {Rajashanthi, M. and Valarmathi, K.},
  doi          = {10.1007/s00500-020-04710-4},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {12845-12854},
  shortjournal = {Soft Comput.},
  title        = {Energy-efficient multipath routing in networking aid of clustering with OGFSO algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Embedded chaotic whale survival algorithm for filter–wrapper
feature selection. <em>SOCO</em>, <em>24</em>(17), 12821–12843. (<a
href="https://doi.org/10.1007/s00500-020-05183-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification accuracy provided by a machine learning model depends a lot on the feature set used in the learning process. Feature selection (FS) is an important and challenging preprocessing technique which helps to identify only the relevant features from a dataset, thereby reducing the feature dimension as well as improving the classification accuracy at the same time. The binary version of whale optimization algorithm (WOA) is a popular FS technique which is inspired from the foraging behavior of humpback whales. In this paper, an embedded version of WOA called embedded chaotic whale survival algorithm (ECWSA) has been proposed which uses its wrapper process to achieve high classification accuracy and a filter approach to further refine the selected subset with low computation cost. Chaos has been introduced in the ECWSA to guide selection of the type of movement followed by the whales while searching for prey. A fitness-dependent death mechanism has also been introduced in the system of whales which is inspired from the real-life scenario in which whales die if they are unable to catch their prey. The proposed method has been evaluated on 18 well-known UCI datasets and compared with its predecessors as well as some other popular FS methods. The source code of ECWSA can be found in https://github.com/Ritam-Guha/ECWSA .},
  archive      = {J_SOCO},
  author       = {Guha, Ritam and Ghosh, Manosij and Mutsuddi, Shyok and Sarkar, Ram and Mirjalili, Seyedali},
  doi          = {10.1007/s00500-020-05183-1},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {12821-12843},
  shortjournal = {Soft Comput.},
  title        = {Embedded chaotic whale survival algorithm for filter–wrapper feature selection},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptive differential evolution with a new joint parameter
adaptation method. <em>SOCO</em>, <em>24</em>(17), 12801–12819. (<a
href="https://doi.org/10.1007/s00500-020-05182-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential evolution (DE) is a population-based metaheuristic algorithm that has been proved powerful in solving a wide range of real-parameter optimization tasks. However, the selection of the mutation strategy and control parameters in DE is problem dependent, and inappropriate specification of them will lead to poor performance of the algorithm such as slow convergence and early stagnation in a local optimum. This paper proposes a new method termed as Joint Adaptation of Parameters in DE (JAPDE). The key idea lies in dynamically updating the selection probabilities for a complete set of pairs of parameter generating functions based on feedback information acquired during the search by DE. Further, for mutation strategy adaptation, the Rank-Based Adaptation (RAM) method is utilized to facilitate the learning of multiple probability distributions, each of which corresponds to an interval of fitness ranks of individuals in the population. The coupling of RAM with JAPDE results in the new RAM-JAPDE algorithm that enables simultaneous adaptation of the selection probabilities for pairs of control parameters and mutation strategies in DE. The merit of RAM-JAPDE has been evaluated on the benchmark test suit proposed in CEC2014 in comparison to many well-known DE algorithms. The results of experiments demonstrate that the proposed RAM-JAPDE algorithm outperforms or is competitive to the other related DE variants that perform mutation strategy and control parameter adaptation, respectively.},
  archive      = {J_SOCO},
  author       = {Leon, Miguel and Xiong, Ning},
  doi          = {10.1007/s00500-020-05182-2},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {12801-12819},
  shortjournal = {Soft Comput.},
  title        = {Adaptive differential evolution with a new joint parameter adaptation method},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A diversity introduction strategy based on change intensity
for evolutionary dynamic multiobjective optimization. <em>SOCO</em>,
<em>24</em>(17), 12789–12799. (<a
href="https://doi.org/10.1007/s00500-020-05175-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real-world problems can be modeled as dynamic multiobjective optimization ones with several competing objectives, which requires an optimization algorithm to track the movement of Pareto front over time. This paper proposes a novel dynamic diversity introduction strategy based on change intensity to improve the performance of dynamic multiobjective optimization based on evolutionary algorithm (DMOEA). In this proposed method, the information generated during evolution is recorded in preparation for evaluating the change intensity. Then, by comparing the evaluated intensity with the inherent intensity, the introduction ratio can be determined by that greater one. Two diversity introduction strategies are utilized to keep the balance between convergence and diversity when environmental change is detected. An improved inverse modeling is used for those drastic changes, while partial solutions random initialization is utilized for these mild ones. We compare the proposed algorithm with four existing DMOEAs on a variety of test instances. The experimental results show that the proposed algorithm exhibits better search performance.},
  archive      = {J_SOCO},
  author       = {Liu, Ruochen and Peng, Luyao and Liu, Jiangdi and Liu, Jing},
  doi          = {10.1007/s00500-020-05175-1},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {12789-12799},
  shortjournal = {Soft Comput.},
  title        = {A diversity introduction strategy based on change intensity for evolutionary dynamic multiobjective optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Some generalizations of p-semisimple BCI algebras and
groups. <em>SOCO</em>, <em>24</em>(17), 12781–12787. (<a
href="https://doi.org/10.1007/s00500-020-05168-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce and investigate the strong p-semisimple property for some generalizations of BCI algebras. For BCI algebras, the strong p-semisimple property is equivalent to the p-semisimple property. We describe the connections of strongly p-semisimple algebras and various generalizations of groups (such as, for example, involutive moons and goops). Moreover, we present some examples of proper strongly p-semisimple algebras.},
  archive      = {J_SOCO},
  author       = {Walendziak, Andrzej},
  doi          = {10.1007/s00500-020-05168-0},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {12781-12787},
  shortjournal = {Soft Comput.},
  title        = {Some generalizations of p-semisimple BCI algebras and groups},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptive synchronization of chaotic systems with
time-varying delay via aperiodically intermittent control.
<em>SOCO</em>, <em>24</em>(17), 12773–12780. (<a
href="https://doi.org/10.1007/s00500-020-05161-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The time-varying delay makes the state of a chaotic system more complex, which has a great influence on stability analysis and synchronization. To solve this problem, we utilize the method of adaptive intermittent control and the theory of Lyapunov stability to realize the synchronization of chaotic systems with time-varying delay. Firstly, we propose the control strategy to achieve the asymptotic exponential stability of the synchronous system under the aperiodically intermittent control. To make it easier to implement, we also propose a periodic intermittent control strategy. Finally, we choose the Lorenz and financial systems to do a numerical simulation. The experimental results verified the validity of our method.},
  archive      = {J_SOCO},
  author       = {Wang, Yuangan and Li, Dong},
  doi          = {10.1007/s00500-020-05161-7},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {12773-12780},
  shortjournal = {Soft Comput.},
  title        = {Adaptive synchronization of chaotic systems with time-varying delay via aperiodically intermittent control},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Characterizations and uncertainty measurement of a fuzzy
information system and related results. <em>SOCO</em>, <em>24</em>(17),
12753–12771. (<a
href="https://doi.org/10.1007/s00500-020-05138-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An information system (IS) is an important model in the field of artificial intelligence. A fuzzy information system (FIS) may be regarded as an IS under fuzzy environment. This paper obtains some results on a FIS. Operators on a FIS are first researched. Then, relationships between FISs are discussed from two aspects of dependence and separability, and dependence between FISs is characterized by the inclusion degree and two kinds of fuzzy distances between FISs are proposed. Next, algebraic characterizations of a FIS are obtained and invariant characterizations of a FIS under some homomorphisms are given. Finally, measuring uncertainty of a FIS is investigated, and experimental analyses illustrates that the proposed measures are suitable.},
  archive      = {J_SOCO},
  author       = {Yu, Guangji},
  doi          = {10.1007/s00500-020-05138-6},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {12753-12771},
  shortjournal = {Soft Comput.},
  title        = {Characterizations and uncertainty measurement of a fuzzy information system and related results},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Convexity on complete lattices. <em>SOCO</em>,
<em>24</em>(17), 12743–12751. (<a
href="https://doi.org/10.1007/s00500-020-05137-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By means of closure systems and closure operators on complete lattices, a generalized convex structure under which classical convex structures and L-convex structures are consistent with each other is established. The related convex spaces and hull spaces are investigated, and it is shown that they are isomorphic to each other from the viewpoint of category. In order to further characterize this convex structure, the notion of enclosed order spaces and their corresponding mappings are introduced. It is proved that the category of enclosed order spaces is also isomorphic to that of convex spaces we presented.},
  archive      = {J_SOCO},
  author       = {Liu, Hongping and Shi, Fu-Gui},
  doi          = {10.1007/s00500-020-05137-7},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {12743-12751},
  shortjournal = {Soft Comput.},
  title        = {Convexity on complete lattices},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On 2S-metric spaces. <em>SOCO</em>, <em>24</em>(17),
12731–12742. (<a
href="https://doi.org/10.1007/s00500-020-05134-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce 2-metric spaces in terms of soft points, called 2s-metric spaces, in the soft universe, which is a nonlinear generalization of soft metric spaces. Then we induce a soft topology from a given 2s-metric space and also study some of its topological structures such as open balls, open (closed) sets, completeness and etc. After that, we prove the Cantor’s Intersection Theorem for complete 2s-metric spaces and use it to show that such a space cannot be expressed as a countable union of no-where dense soft sets under some general situations. At the end, we obtain some fixed point results in complete 2s-metric spaces by using Cantor’s theorem.},
  archive      = {J_SOCO},
  author       = {Çetkin, Vildan and Güner, Elif and Aygün, Halis},
  doi          = {10.1007/s00500-020-05134-w},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {12731-12742},
  shortjournal = {Soft Comput.},
  title        = {On 2S-metric spaces},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Kinetic-molecular theory optimization algorithm using
opposition-based learning and varying accelerated motion. <em>SOCO</em>,
<em>24</em>(17), 12709–12730. (<a
href="https://doi.org/10.1007/s00500-020-05057-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an improved kinetic-molecular theory optimization algorithm (OKMTOA) by analyzing the characteristics of KMTOA cluster behavior and combining the opposition-based learning strategy with varying accelerated motion in physics. The algorithm first applies different opposition-based learning strategies to the population initialization and iterative process of the algorithm. The two-stage strategy is beneficial to improving the quality of the solution set and accelerating the convergence of the algorithm. Then, based on the concept of varying accelerated motion, the acceleration formula is improved to increase the ability to escape local optimum. The experimental results show that the algorithm has good performance in solution precision, convergence speed and can be well applied to the functions with different shift values.},
  archive      = {J_SOCO},
  author       = {Fan, Chaodong and Zheng, Ningjun and Zheng, Jinhua and Xiao, Leyi and Liu, Yingnan},
  doi          = {10.1007/s00500-020-05057-6},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {12709-12730},
  shortjournal = {Soft Comput.},
  title        = {Kinetic-molecular theory optimization algorithm using opposition-based learning and varying accelerated motion},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Representing uncertainty about fuzzy membership grade.
<em>SOCO</em>, <em>24</em>(17), 12691–12707. (<a
href="https://doi.org/10.1007/s00500-020-05050-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel uncertainty representation framework is introduced based on the inter-linkage between the inherent fuzziness and the agent’s confusion in its representation. The measure of fuzziness and this confusion is considered to be directly related to the lack of distinction between membership and non-membership grades. We term the proposed structure as confidence fuzzy set (CFS). It is further generalized as generalized CFS, quasi CFS and interval-valued CFS to take into consideration the DM’s individualistic bias in the representation of the underlying fuzziness. The operations on CFSs are investigated. The usefulness of CFS in multi-criteria decision making is discussed, and a real application in supplier selection is included.},
  archive      = {J_SOCO},
  author       = {Aggarwal, Manish},
  doi          = {10.1007/s00500-020-05050-z},
  journal      = {Soft Computing},
  number       = {17},
  pages        = {12691-12707},
  shortjournal = {Soft Comput.},
  title        = {Representing uncertainty about fuzzy membership grade},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). RWFOA: A random walk-based fruit fly optimization algorithm.
<em>SOCO</em>, <em>24</em>(16), 12681–12690. (<a
href="https://doi.org/10.1007/s00500-020-04830-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one kind of the classic swarm intelligence (SI) algorithms, fruit fly optimization algorithm has been widely used in many aspects, such as multiple objective optimization and service computing. However, due to the limitation that introduced by the initial population location, its global optimization ability is limited. Therefore, we propose a random walk-based fruit fly optimization algorithm, namely RWFOA, to enhance its global optimization ability. RWFOA employs the random walk mechanism to dynamically adjust the position of the fruit fly population, which can reduce the impact of the initial population location and thus enhance the global optimization ability. We conduct a comprehensive experimental evaluation of RWFOA by comparing it with three representative algorithms, i.e., the OFOA, CFOA and IFFO, over 29 widely used benchmark functions published in CEC 2015. Experimental results demonstrate that RWFOA can find better solutions in most of the selected benchmark functions.},
  archive      = {J_SOCO},
  author       = {Chen, Chong},
  doi          = {10.1007/s00500-020-04830-x},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {12681-12690},
  shortjournal = {Soft Comput.},
  title        = {RWFOA: A random walk-based fruit fly optimization algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Image segmentation of nasopharyngeal carcinoma using 3D CNN
with long-range skip connection and multi-scale feature pyramid.
<em>SOCO</em>, <em>24</em>(16), 12671–12680. (<a
href="https://doi.org/10.1007/s00500-020-04708-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nasopharyngeal carcinoma (NPC) is one of the most common cancers of the nasopharynx. A structural analysis of NPC can provide vital insights into methods of treatment. However, manually marking the boundaries of NPC in images is tedious, time-consuming, and prone to error. It has become necessary to use computer-based automatic segmentation algorithms to accurately locate NPC. However, this remains a challenging task owing to the high variation (in shape and size) in the structure of the nasopharynx across subjects. Moreover, the nasopharyngeal area is small, and this causes severe imbalance in the foreground and background categories. In this paper, we propose a 3D convolutional neural network with long-range skip connection and multi-scale feature pyramid (SFP) for the segmentation of images of NPC. Unlike the traditional skip connection in residual blocks, which only considers the feature transfer and feature fusion between the same convolutional layer, long-range skip connection with original features from the first convolution in our network is passed to each down-sampling stage using element-wise sum to effectively increase reuse of low-level features and to solve the problems of gradient disappearance and explosion. The multi-scale feature pyramid with a varying atrous rate adapts to images of different sizes to learn multi-scale features, and hierarchical contextual information regarding NPC. To accelerate the convergence of our network, we use deep supervision to generate three auxiliary segmentation maps and merge the weighted loss into the objective function. And we fuse these auxiliary segmentation maps to refine the final segmentation result. In our experiments, the proposed network was trained and tested on 3D magnetic resonance imaging (MRI) images of 120 clinical patients using 5-fold cross-validation. The average dice similarity coefficient (DSC) and average symmetric surface distance (ASSD), used as evaluation metric, were 0.737 and 1.214 mm, respectively. This shows that in terms of results, our method is superior to five state-of-the-art networks and equivalent to the judgment of an experienced physician.},
  archive      = {J_SOCO},
  author       = {Guo, Feng and Shi, Canghong and Li, Xiaojie and Wu, Xi and Zhou, Jiliu and Lv, Jiancheng},
  doi          = {10.1007/s00500-020-04708-y},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {12671-12680},
  shortjournal = {Soft Comput.},
  title        = {Image segmentation of nasopharyngeal carcinoma using 3D CNN with long-range skip connection and multi-scale feature pyramid},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient agricultural yield prediction using metaheuristic
optimized artificial neural network using hadoop framework.
<em>SOCO</em>, <em>24</em>(16), 12659–12669. (<a
href="https://doi.org/10.1007/s00500-020-04707-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The low-resolution imagery of satellite is used extensively for monitoring crops and forecasting of yield which has a major role to play in the operational systems. A combination of high levels of temporal frequency along with an extended coverage was connected with lower costs per each area unit making the images a choice that is convenient at the national level and the regional level scales. There are various quantitative and qualitative approaches for low-resolution satellite imagery to be used for the primary predictor of the final yield of crops. But, very little work is done on the yield prediction that is based on environmental and satellite data. To handle such satellite images may be very challenging owing to large data amounts. Big data analysis is efficient in handling a large amount of data generated for predicting agricultural yield. In this work, a neural network is used for prediction and to enhance its performance; a population-based incremental learning technique is proposed for optimizing the weights. The results of the experiment proved that the method proposed has better results compared to that of the other methods.},
  archive      = {J_SOCO},
  author       = {Saranya, C. P. and Nagarajan, N.},
  doi          = {10.1007/s00500-020-04707-z},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {12659-12669},
  shortjournal = {Soft Comput.},
  title        = {Efficient agricultural yield prediction using metaheuristic optimized artificial neural network using hadoop framework},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). RETRACTED ARTICLE: Complex image recognition algorithm
based on immune random forest model. <em>SOCO</em>, <em>24</em>(16),
12643–12657. (<a
href="https://doi.org/10.1007/s00500-020-04706-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous advancement of science and technology, the social network based on the Internet has gradually penetrated into people’s daily lives. The image data shared on social media using platforms such as mobile phones has exploded, and hundreds of millions of dollars are generated every day with picture information. In the past, the traditional ways of expressing textual information that people are familiar with have begun to be gradually replaced by image information that is not subject to regional culture such as language and script. In modern warfare, with the continuous development and equipment of highly sophisticated weapons and equipment, the amount of information that the entire combat system needs to process will also increase. In particular, the air defense system needs to quickly and accurately identify the aircraft targets that are coming. It mainly uses computer to extract the feature information of the acquired image and converts the content in the image into a feature expression that can be processed by the computer. After the appropriate classification algorithm, the image is the target object is classified by category. In this paper, we propose a complex image recognition algorithm based on immune random forest model. The experimental results show that the proposed algorithm has high recognition efficiency and higher robustness.},
  archive      = {J_SOCO},
  author       = {Zhang, Xiaoyu and Huang, Wei and Lin, Xiao and Jiang, Linhua and Wu, Yan and Wu, Chunxue},
  doi          = {10.1007/s00500-020-04706-0},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {12643-12657},
  shortjournal = {Soft Comput.},
  title        = {RETRACTED ARTICLE: Complex image recognition algorithm based on immune random forest model},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). FSS-SDD: Fuzzy-based semantic search for secure data
discovery from outsourced cloud data. <em>SOCO</em>, <em>24</em>(16),
12633–12642. (<a
href="https://doi.org/10.1007/s00500-020-04701-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In current decade, cloud computing has become more prevalent and utilized for managing more sensitive data that are stored over cloud storage. While outsourcing the sensitive and private data on to the cloud, security is the major factor to be concentrated in efficient data search using keywords. As is auspicious, security of selective keyword search can be achieved using the powerful cryptographic technique called encryption. That is, the data that are to be outsourced have to be encrypted before storing it on cloud. Symmetric encryption is used between the data owner and the customer, whereas asymmetric encryption is used between the data owner and the cloud server. In such cases, the data discovery and retrieval have become more stimulating process. However, there are many methodologies developed for searching the encrypted outsourced data from the cloud. In this paper, the efficient data discovery process is focused and enhanced with the developed model called fuzzy-based semantic search for secure data discovery (FSS-SDD). A multi-valued logic called fuzzy logic is used, which has truth values of variables ranging between 0 and 1. It is used where the truth values range between completely true and completely false. The fuzzy logic-based semantic search improves the searching experience of the end user, by finding and retrieving the exact matching files for corresponding search files given by the user. Moreover, the model discovers the closely relevant matches using the semantic similarities, in cases, when the exact matches are not avail. For reducing the false positive rates, grading mechanism is enforced. Using the proposed FSS-SDD model, the processing overhead on new updates is effectively reduced and security in data retrieval is guaranteed.},
  archive      = {J_SOCO},
  author       = {Ananthi, M. and Sabitha, R. and Karthik, S. and Shanthini, J.},
  doi          = {10.1007/s00500-020-04701-5},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {12633-12642},
  shortjournal = {Soft Comput.},
  title        = {FSS-SDD: Fuzzy-based semantic search for secure data discovery from outsourced cloud data},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multimodal biometric systems based on different fusion
levels of ECG and fingerprint using different classifiers.
<em>SOCO</em>, <em>24</em>(16), 12599–12632. (<a
href="https://doi.org/10.1007/s00500-020-04700-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal biometric system can be accomplished at different levels of fusion and achieve higher recognition performance than the unimodal system. This paper concerned to study the performance of different classification techniques and fusion rules in the context of unimodal and multimodal biometric systems based on the electrocardiogram (ECG) and fingerprint. The experiments are conducted on ECG and fingerprint databases to evaluate the performance of the proposed biometric systems. MIT-BIH database is utilized for ECG, FVC2004 database is utilized for the fingerprint, and further experiments are being performed to evaluate the proposed multimodal system with 47 subjects from virtual multimodal database. The performance of the proposed unimodal and multimodal biometric systems is measured using receiver operating characteristic (ROC) curve, AUC (area under the ROC curve), sensitivity, specificity, efficiency, standard error of the mean, and likelihood ratio. The findings indicate AUC up to 0.985 for sequential multimodal system, and up to 0.956 for parallel multimodal system, as compared to the unimodal systems that achieved AUC up to 0.951, and 0.866, for the ECG and fingerprint biometrics, respectively. The overall performance of the proposed multimodal systems is better than that of the unimodal systems based on different classifiers and different fusion levels and rules.},
  archive      = {J_SOCO},
  author       = {El_Rahman, Sahar A.},
  doi          = {10.1007/s00500-020-04700-6},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {12599-12632},
  shortjournal = {Soft Comput.},
  title        = {Multimodal biometric systems based on different fusion levels of ECG and fingerprint using different classifiers},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Bio-inspired predictive models for shear strength of
reinforced concrete beams having steel stirrups. <em>SOCO</em>,
<em>24</em>(16), 12587–12597. (<a
href="https://doi.org/10.1007/s00500-020-04698-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, three bio-inspired predictive models are proposed with the aim of estimating the shear capacity of reinforced concrete (RC) beams having steel stirrups. For this purpose, 194 experimental tests of this type of RC beams were gathered from the literature. Then, the structures of the artificial neural network models are trained and validated using seven parameters including concrete compressive strength, width of the member, effective depth of the member, the yielding strength of transverse reinforcement, area of the reinforcement as a proportion of the beam area, the yielding strength of longitudinal reinforcement and also the transverse reinforcement ratio to determine the observed shear capacity in the experimental tests. It was concluded that the proposed mathematical frameworks could determine the shear capacity with a satisfactory level of precision in comparison with the obtained results of ACI-318.},
  archive      = {J_SOCO},
  author       = {Naderpour, Hosein and Mirrashid, Masoomeh},
  doi          = {10.1007/s00500-020-04698-x},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {12587-12597},
  shortjournal = {Soft Comput.},
  title        = {Bio-inspired predictive models for shear strength of reinforced concrete beams having steel stirrups},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A rough-GA based optimal feature selection in attribute
profiles for classification of hyperspectral imagery. <em>SOCO</em>,
<em>24</em>(16), 12569–12585. (<a
href="https://doi.org/10.1007/s00500-020-04697-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Morphological attribute profiles are robust in capturing the spectral–spatial information of hyperspectral imagery. To incorporate maximum spatial information, generation of a profile using multiple attributes with large number of threshold values is a well-known approach. Although the profile contains very rich spatial information, at the same time its dimensionality increases. This raises two critical problems for hyperspectral image classification: (i) curse of dimensionality and (ii) computational complexity. To mitigate such problems, the only supervised feature selection technique that exists in the literature is computationally demanding. In this article, a fast supervised feature selection technique by exploiting rough set theory and genetic algorithms is proposed. Our technique computes the relevance and significance of each feature in the profile using rough set theory. Then, based on the relevance and significance values a novel fitness function of genetic algorithms is designed to select an optimal subset of features from the constructed profile. To show the effectiveness of the proposed technique, it is compared with the existing state-of-the-art technique by considering three real hyperspectral data sets.},
  archive      = {J_SOCO},
  author       = {Das, Arundhati and Patra, Swarnajyoti},
  doi          = {10.1007/s00500-020-04697-y},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {12569-12585},
  shortjournal = {Soft Comput.},
  title        = {A rough-GA based optimal feature selection in attribute profiles for classification of hyperspectral imagery},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An optimized collaborative intrusion detection system for
wireless sensor networks. <em>SOCO</em>, <em>24</em>(16), 12553–12567.
(<a href="https://doi.org/10.1007/s00500-020-04695-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In wireless sensor networks (WSNs), sensor nodes regularly monitor environment and transmit measured values for specific phenomena to a central point called base station (BS). Recently, many intrusion detection systems (IDSs) are proposed for WSNs as they are vulnerable to multiple types of attacks. Unfortunately, most of these systems cause computational overhead and consume the limited resources of sensor nodes. Since sensor nodes are limited in resources (memory, microprocessor, battery, etc.), designing a real-time IDS for WSNs should be considered. In this article, an optimized collaborative intrusion detection system (OCIDS) is proposed for WSNs. It uses an improved artificial bee colony optimization algorithm to optimize the hierarchical IDS applied to WSNs with respect to both the accuracy of intrusion detection and also the consumption of limited resources. Besides that, the proposed system optimizes the weighted support vector machine algorithm to improve the detection accuracy and reduce false alarm rate. Since in hierarchical WSNs each of sensor nodes, cluster heads, and BS has different views of the network, collaboration among them is considered in the proposed OCIDS system to provide more precise intrusion detection. To prove the efficiency and robustness of the proposed system, we analyzed and evaluated the impact of different attack scenarios on the system performance and compared its performance to other systems. Comparing its performance to others in the presence of both normal and intrusion traffic using NSL-KDD dataset proves that it exhibits the highest detection rate and lowest false alarm rate. The proposed system outperforms the other systems by achieving 97.9\% average detection rate with a small standard deviation 0.9\%, and the average false alarm rate reaches 1.8\% with a small standard deviation 1\% which shows an obvious advantage than other detection systems.},
  archive      = {J_SOCO},
  author       = {Elsaid, Shaimaa Ahmed and Albatati, Nouf Saleh},
  doi          = {10.1007/s00500-020-04695-0},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {12553-12567},
  shortjournal = {Soft Comput.},
  title        = {An optimized collaborative intrusion detection system for wireless sensor networks},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An enhanced soft computing-based formulation for secure data
aggregation and efficient data processing in large-scale wireless sensor
network. <em>SOCO</em>, <em>24</em>(16), 12541–12552. (<a
href="https://doi.org/10.1007/s00500-020-04694-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rapid growth in wireless technologies and communication, wireless sensor network (WSN) skills, data gathering and management models has paved the sensor technology a great impact on all factors of human life. In WSN, maximum consumption of constrained resources is considered to be the major challenge. Additionally, secure data aggregation has made the research domain more interesting. For consuming the limited sensor node resources optimally, data aggregation model plays a vital role. It reduces the redundant and unwanted data transmission and enhances the accuracy of data, thereby reducing the energy consumption rate and consumption overhead. Hence, for balancing the energy efficient data processing with secure data aggregation in large-scale WSN, optimized security model using enhanced fully homomorphic encryption (OSM-EFHE) has been developed in this work. First, the network is divided into clusters and cluster head which acts as an aggregator is selected based on the fuzzy if–then rule which helps in consumption of energy. Second, it provides data confidentiality and maintains subjective aggregation functions through fully homomorphic encryption (FHE). In this work, Van Dijk, Gentry, Halevi and Vaikunathan key generation plan with public key compression is used which condenses the public key dimension which is one of the major computations overhead for FHE. Finally, data integrity operation has also been induced with message authentication code. When comparing with the existing approaches, simulation results make a clear note of average delay of the network as 1.2 ms and a higher throughput of 4500 bps approximately. Thus, the overall transmission of data has been increased by means of employing OSM-EFHE model.},
  archive      = {J_SOCO},
  author       = {Shobana, M. and Sabitha, R. and Karthik, S.},
  doi          = {10.1007/s00500-020-04694-1},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {12541-12552},
  shortjournal = {Soft Comput.},
  title        = {An enhanced soft computing-based formulation for secure data aggregation and efficient data processing in large-scale wireless sensor network},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal spectral and energy efficiency trade-off for massive
MIMO technology: Analysis on modified lion and grey wolf optimization.
<em>SOCO</em>, <em>24</em>(16), 12523–12539. (<a
href="https://doi.org/10.1007/s00500-020-04690-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the technology makes progress towards the era of fifth generation (5G) communication networks, energy efficiency (EE) becomes an significant design criterion, because it guarantees sustainable evolution. In this regard, the massive multiple-input multiple-output (MIMO) technology, where the base stations are outfitted with enormous count of antennas so as to reach multiple orders of spectral and energy efficiency gains, will be a fundamental technology enabler for 5G. This paper plans to implement a massive MIMO model considering the spectral efficiency (SE) and EE. Here, the main goal is to generate the optimal solutions for beam-forming vectors and power allocation. The optimal solution is formed in such a way that both the SE and EE are maximum through resource efficiency metric model. The beam-forming vectors and power allocations are generated by two modified meta-heuristic algorithm to frame a valuable analysis. The first algorithm uses the modified grey wolf optimization (GWO) termed as improved random vector-based GWO (IRV-GWO), and the second algorithm uses the modified lion algorithm (LA) termed as improved random vector-based LA (IRV-LA). Both the algorithms have the ability to solve the complex optimization problems under different applications with respect to better convergence rate, which in turn performs well for pertaining better trade-off between the SE and EE in massive MIMO technology.},
  archive      = {J_SOCO},
  author       = {Nimmagadda, Satyanarayana Murthy},
  doi          = {10.1007/s00500-020-04690-5},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {12523-12539},
  shortjournal = {Soft Comput.},
  title        = {Optimal spectral and energy efficiency trade-off for massive MIMO technology: Analysis on modified lion and grey wolf optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fuzzy conformable fractional differential equations: Novel
extended approach and new numerical solutions. <em>SOCO</em>,
<em>24</em>(16), 12501–12522. (<a
href="https://doi.org/10.1007/s00500-020-04687-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this article is to propose a new definition of fuzzy fractional derivative, so-called fuzzy conformable. To this end, we discussed fuzzy conformable fractional integral softly. Meanwhile, uniqueness, existence, and other properties of solutions of certain fuzzy conformable fractional differential equations under strongly generalized differentiability are also utilized. Furthermore, all needed requirements for characterizing solutions by equivalent systems of crisp conformable fractional differential equations are debated. In this orientation, modern trend and new computational algorithm in terms of analytic and approximate conformable solutions are proposed. Finally, the reproducing kernel Hilbert space method in the conformable emotion is constructed side by side with numerical results, tabulated data, and graphical representations.},
  archive      = {J_SOCO},
  author       = {Arqub, Omar Abu and Al-Smadi, Mohammed},
  doi          = {10.1007/s00500-020-04687-0},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {12501-12522},
  shortjournal = {Soft Comput.},
  title        = {Fuzzy conformable fractional differential equations: Novel extended approach and new numerical solutions},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Development of operation multi-objective model of dam
reservoir under conditions of temperature variation and loading using
NSGA-II and DANN models: A case study of karaj/amir kabir dam.
<em>SOCO</em>, <em>24</em>(16), 12469–12499. (<a
href="https://doi.org/10.1007/s00500-020-04686-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For determining optimal operation policies, it is of vital importance to the structural stability of dams, besides meeting the downstream water demands during the operation period. Since water level variations in upstream dam cause changes in loadings of the dam body, ignoring factors, which are effective in the structural stability of dams, might result in cracks and instability of dams in the long term. Therefore, in the present study, a multi-objective model was developed by integrating the reservoir structure simulation model and optimization approach in order to meet water supply demands and maintain the dam structural stability. Linear static analysis of Amir Kabir dam was performed using ABAQUS 6.14.3 software to extract the structural parameters, indicating the dam structural stability. For this purpose, a dynamic artificial neural network was also used as an interfaced model to relate the results of the simulator model to those of the proposed approach. The best solution was extracted from the optimal trade-off curve, which was developed using non-dominated sorting genetic algorithm (NSGA-II) and multi-criteria decision-making methods. Results showed that the allocation to the downstream water demands was applied in the best possible way based on the stability of the dam. A comparison between the existing and optimal conditions indicated that the value of reliability and vulnerability coefficients was improved in optimal conditions in comparison with the existing conditions. According to the results, there was a 7\% rise in the fuzzy stability index in optimal conditions compared to the existing conditions that indicate better performance in the optimal model. Therefore, as to consider the downstream water demands, summer was the most deficient and spring was the least deficient with the water supply of 30\% and 72\%, respectively. During summer, the average optimal allocation and the average demand were 20.51 MCM and 67.50 MCM, respectively. However, this season showed the best performance in preserving the dam stability with having the lowest parameters of the dam structural stability compared to other seasons. Finally, the support vector regression method was used to develop an optimal operational policy based on optimal allocation values obtained from the proposed model structure. The optimal developed policy can be used to determine optimal allocation based on hydrological parameters of the dam and its water demands. Meanwhile, it can maintain dam stability without implementing the proposed structure.},
  archive      = {J_SOCO},
  author       = {Tabari, Mahmoud Mohammad Rezapour and Azadani, Mitra Nasr and Kamgar, Reza},
  doi          = {10.1007/s00500-020-04686-1},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {12469-12499},
  shortjournal = {Soft Comput.},
  title        = {Development of operation multi-objective model of dam reservoir under conditions of temperature variation and loading using NSGA-II and DANN models: A case study of Karaj/Amir kabir dam},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A decision support model based on the combined structure of
DEMATEL, QFD and fuzzy values. <em>SOCO</em>, <em>24</em>(16),
12449–12468. (<a
href="https://doi.org/10.1007/s00500-020-04685-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncertainty and risk are inevitable issues in decision making in supply chain systems. In knowledge-based communities, uncertain conditions are recognized, analyzed and eliminated using wide range of concepts and approaches. One intelligent tool to aid in decreasing impreciseness and in delivering an acceptable level of accuracy is fuzzy logic. This study reports a new version of the fuzzy multiple criteria decision-making family. The decision-making trial and evaluation laboratory (DEMATEL) is extended for the first time with interval fuzzy values and then integrated as an input for the quality function deployment (QFD) mechanism. Although the application of decision-making tools in the supply chain and its sustainable development is undeniable, the implementation of fuzzy decision support systems in sustainable supply chains still demands more research work. This study develops an IT2F DEMATEL-QFD model to evaluate and rank sustainable supply chain drivers in a group decision-making environment. The proposed fuzzy decision model is connected to a real research project for eliminating risks in the supply chain related to agricultural production systems. Sensitivity analysis confirms the stability of the model. It is concluded that the outcomes and advantages of the newly developed model will profit academic and non-academic partners.},
  archive      = {J_SOCO},
  author       = {Yazdani, Morteza and Wang, Z. X. and Chan, Felix T. S.},
  doi          = {10.1007/s00500-020-04685-2},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {12449-12468},
  shortjournal = {Soft Comput.},
  title        = {A decision support model based on the combined structure of DEMATEL, QFD and fuzzy values},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multidisciplinary design optimization of an aircraft by
using knowledge-based systems. <em>SOCO</em>, <em>24</em>(16),
12429–12448. (<a
href="https://doi.org/10.1007/s00500-020-04684-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new strategy for solving multidisciplinary design optimization problems is presented in this paper. The main idea of this approach is based on the use of designer experiences and attention to his/her preferences during design optimization which is implemented using a concept called the fuzzy preference function. Two important advantages of this approach are: (1) using the experiences of expert people during optimization and (2) transforming a constrained multiobjective design optimization problem into an unconstrained single-objective design optimization problem. The multidisciplinary design optimization of an unmanned aerial vehicle (UAV) is considered to show the performance of the proposed methodology. The optimization problem in this case study is a constrained two-objective problem (minimization of takeoff weight and drag of the cruise phase), and the genetic algorithm (GA) is utilized as the optimizer. Performance, weight, aerodynamics, center of gravity, trim and dynamic stability are the considered modules in the multidisciplinary analysis that are modeled using empirical and semiempirical equations. The optimization results show that the proposed strategy has been able to offer an optimal design where has higher performance relative to other methods from the point of view of objective functions, low computational cost and simplicity of implementation.},
  archive      = {J_SOCO},
  author       = {Setayandeh, Mohammad Reza and Babaei, Ali-Reza},
  doi          = {10.1007/s00500-020-04684-3},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {12429-12448},
  shortjournal = {Soft Comput.},
  title        = {Multidisciplinary design optimization of an aircraft by using knowledge-based systems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel parallel image encryption algorithm based on hybrid
chaotic maps with OpenCL implementation. <em>SOCO</em>, <em>24</em>(16),
12413–12427. (<a
href="https://doi.org/10.1007/s00500-020-04683-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since chaotic maps have the excellent properties of unpredictability, ergodicity and sensitivity to their parameters and initial values, they are quite suitable for generating chaotic sequences for securing communication systems and are also especially useful for securing images, and a lot of chaotic map-based image encryption algorithms have been proposed. But some existing image encryption algorithms were proved that their security, encryption efficiency or computational speeds are not quite satisfactory for practical applications. Some of them using only one type of chaotic system may suffer from low key space, and some others using two or more types of chaotic system may suffer from high computational overheads. In this paper, based on the classic 1D logistic map, a 2D one-coupling logistic dynamics system and OpenCL, a novel parallel image encryption algorithm HCMO is proposed. Our algorithm consists of a confusion phase and a diffusion phase using four sub-key matrices based on the hybrid logistic dynamics systems, the linear transformation and the enlarging operation. In the confusion phase, the image’s pixel positions are first scrambled by performing row-wise and column-wise permutation operations using two sub-key matrices; then, in its diffusion phase, both the bit XOR operation and the bit cyclic shifting are applied onto the scrambled intermediate image matrix using the other two sub-key matrices. In order to reduce the whole encrypting execution time, we speed up our HCMO on an OpenCL’s heterogeneous and parallel characteristics. Compared to the implementation of Vihari’s algorithm and some other chaotic map-based algorithms referred in this paper with the OpenCL-based implementation on the CPU and on the GPU, respectively, our algorithm’s simulation demonstrates remarkable improvement in the operational speedup, and the experimental result analyses have also shown that HCMO has a higher-level security than some other referred algorithms.},
  archive      = {J_SOCO},
  author       = {You, Lin and Yang, Ersong and Wang, Guangyi},
  doi          = {10.1007/s00500-020-04683-4},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {12413-12427},
  shortjournal = {Soft Comput.},
  title        = {A novel parallel image encryption algorithm based on hybrid chaotic maps with OpenCL implementation},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hourly day-ahead wind power forecasting with the
EEMD-CSO-LSTM-EFG deep learning technique. <em>SOCO</em>,
<em>24</em>(16), 12391–12411. (<a
href="https://doi.org/10.1007/s00500-020-04680-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wind power forecasting has gained significant attention due to advances in wind energy generation in power frameworks and the uncertain nature of wind. In this manner, to maintain an affordable, reliable, economical, and dependable power supply, accurately predicting wind power is important. In recent years, several investigations and studies have been conducted in this field. Unfortunately, these examinations disregarded the significance of data preprocessing and the impact of various missing values, thereby resulting in poor performance in forecasting. However, long short-term memory (LSTM) network, a kind of recurrent neural network (RNN), can predict and process the time-series data at moderately long intervals and time delays, thereby producing good forecasting results using time-series data. This article recommends a hybrid forecasting model for forecasting wind power to improve the performance of the prediction. An improved long short-term memory network-enhanced forget-gate network (LSTM-EFG) model, whose appropriate parameters are optimized using cuckoo search optimization algorithm (CSO), is used to forecast the subseries data that is extracted using ensemble empirical mode decomposition (EEMD). The experimental results show that the proposed forecasting model overcomes the limitations of traditional forecasting models and efficiently improves forecasting accuracy. Furthermore, it serves as an operational tool for wind power plants management.},
  archive      = {J_SOCO},
  author       = {Devi, A. Shobana and Maragatham, G. and Boopathi, K. and Rangaraj, A. G.},
  doi          = {10.1007/s00500-020-04680-7},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {12391-12411},
  shortjournal = {Soft Comput.},
  title        = {Hourly day-ahead wind power forecasting with the EEMD-CSO-LSTM-EFG deep learning technique},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A hybrid control approach for the cracking outlet
temperature system of ethylene cracking furnace. <em>SOCO</em>,
<em>24</em>(16), 12375–12390. (<a
href="https://doi.org/10.1007/s00500-020-04679-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main objective of this paper is to show the design and application on the cracking outlet temperature (COT) system using a hybrid control approach including non-minimal state-space model predictive control with an adjustable factor (AFNMSSMPC) and humanoid intelligent multimodality control (HIMMC) in two 100 k tone/year SC-1 ethylene cracking furnaces. Compared with the conventional control structure, the advanced control structure is designed based on the existing control problem. The advanced controller is developed at the platform of APC-ISYS software made by Zhejiang Supcon Company and implemented in an industrial upper computer which sets over and is connected with a CS3000 distributed control system (DCS) through OPCServer. In order to reduce the fluctuation of the COT, AFNMSSMPC is chosen as feedback controller, which guarantees system robustness together with tracking ability, and meanwhile HIMMC is as feed-forward controller based on the change in chamber temperature (measured disturbance), which can eliminate the effect on cracking outlet temperature (COT) in advance. The application results on COT of two ethylene cracking furnaces labeled M and N furnaces in practice using AFNMSSMPC-HIMMC compared to the traditional proportional–integral–differential (PID) control are presented. The standard deviation of COT reduces by 54.03\% and 60.87\% for M and N furnaces, respectively. The results show that the designed COT system has the capability of good tracking and strong disturbance rejection.},
  archive      = {J_SOCO},
  author       = {Shi, Huiyuan and Peng, Bo and Jiang, Xueying and Su, Chengli and Cao, Jiangtao and Li, Ping},
  doi          = {10.1007/s00500-020-04679-0},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {12375-12390},
  shortjournal = {Soft Comput.},
  title        = {A hybrid control approach for the cracking outlet temperature system of ethylene cracking furnace},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Wireless sensor network intrusion detection system based on
MK-ELM. <em>SOCO</em>, <em>24</em>(16), 12361–12374. (<a
href="https://doi.org/10.1007/s00500-020-04678-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advances in digital electronics, wireless communications, and electro-mechanical systems technology have revolutionized the society and economy across the globe by enabling the development of low-cost, low-power, and multi-functional sensor nodes, from which the sensor networks are realized by leveraging the features of sensing, data processing, and communication present in these nodes. Though the energy of the wireless sensor network (WSN) nodes is limited, the detection of existing intrusion detection systems in WSN is weakly accurate further. To reduce the energy consumption of nodes in WSNs during detection processing, we propose a hierarchical intrusion detection model that clusters the nodes in a WSN according to their functions. Even more, to improve the detection accuracy of abnormal behavior of the WSN intrusion detection system and reduce the false alarm rate, it is considered in this research the usage of the classification algorithm of kernel extreme learning machine, following to Mercer Property to synthesize multi-kernel functions. We realize the optimal linear combination by testing and applying the multi-kernel function and build a multi-kernel extreme learning machine to WSN intrusion detection systems. Simulation results show that the system not only guarantees a high detection accuracy but also dramatically reduces the detection time, being well suited for resource-constrained WSNs.},
  archive      = {J_SOCO},
  author       = {Zhang, Wenjie and Han, Dezhi and Li, Kuan-Ching and Massetto, Francisco Isidro},
  doi          = {10.1007/s00500-020-04678-1},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {12361-12374},
  shortjournal = {Soft Comput.},
  title        = {Wireless sensor network intrusion detection system based on MK-ELM},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Note on “fuzzy multi-granulation decision-theoretic rough
sets based on fuzzy preference relation.” <em>SOCO</em>,
<em>24</em>(16), 12357–12360. (<a
href="https://doi.org/10.1007/s00500-020-04677-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this note, we point out that the transfer function for computing the fuzzy preference degree in Mandal and Ranadive (Soft Comput, 2018. https://doi.org/10.1007/s00500-018-3411-7 ) for the construction of upward/downward fuzzy relations is not additive consistent. Appropriate counterexample is given. Further, their modified versions are presented.},
  archive      = {J_SOCO},
  author       = {Ali, Abbas and Rehman, Noor and Hila, Kostaq},
  doi          = {10.1007/s00500-020-04677-2},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {12357-12360},
  shortjournal = {Soft Comput.},
  title        = {Note on “Fuzzy multi-granulation decision-theoretic rough sets based on fuzzy preference relation”},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multiple criteria decision making based on weighted
archimedean power partitioned bonferroni aggregation operators of
generalised orthopair membership grades. <em>SOCO</em>, <em>24</em>(16),
12329–12355. (<a
href="https://doi.org/10.1007/s00500-020-04676-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a multiple criteria decision making (MCDM) method based on weighted Archimedean power partitioned Bonferroni aggregation operators of generalised orthopair membership grades (GOMGs) is proposed. Bonferroni mean operator, geometric Bonferroni mean operator, power average operator, partitioned average operator, and Archimedean T-norm and T-conorm operations are introduced into generalised orthopair fuzzy sets to develop the Bonferroni aggregation operators. Their formal definitions are provided, and generalised and specific expressions are constructed. On the basis of the specific operators, a method for solving the MCDM problems based on GOMGs is designed. The working process, characteristics, and feasibility of the method are, respectively, demonstrated via a numerical example, a qualitative comparison at the aspect of characteristics, and a quantitative comparison using the example as benchmark. The demonstration results show that the proposed method is feasible that has desirable generality and flexibility in the aggregation of criterion values and concurrently has the capabilities to deal with the heterogeneous interrelationships of criteria, reduce the negative influence of biased criterion values, and capture the risk attitudes of decision makers.},
  archive      = {J_SOCO},
  author       = {Qin, Yuchu and Qi, Qunfen and Scott, Paul J. and Jiang, Xiangqian},
  doi          = {10.1007/s00500-020-04676-3},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {12329-12355},
  shortjournal = {Soft Comput.},
  title        = {Multiple criteria decision making based on weighted archimedean power partitioned bonferroni aggregation operators of generalised orthopair membership grades},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new soft computing approach for green supplier selection
problem with interval type-2 trapezoidal fuzzy statistical group
decision and avoidance of information loss. <em>SOCO</em>,
<em>24</em>(16), 12313–12327. (<a
href="https://doi.org/10.1007/s00500-020-04675-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Green supplier selection problem (GSSP) is viewed as multiple attributes group decision-making (MAGDM) issue that includes the green growth and influential factors within subjective and objective natures. Because of the expanding uncertain conditions of social and economic environments, some assessment factors are not sufficiently described by numerical appraisals and classic fuzzy sets. Moreover, supply chain decision makers (DMs) may not provide complete rationality under numerous viable choice circumstances. In this research, a new MAGDM model is proposed by interval type-2 trapezoidal fuzzy numbers (IT2TrFNs) via some matrices of possibilistic mean and standard deviation statistical concepts. A new weighting method of experts within the group decision-making process is developed based on possibilistic statistical information. Also, a new ranking process based on relative-closeness coefficients is presented to rank all green supplier candidates under IT2TrF uncertainty. Finally, this research offers an illustrative example in supply chain networks to appraise green supplier candidates in terms of some factors by the proposed model along with the comparison to a recent decision method.},
  archive      = {J_SOCO},
  author       = {Mousavi, S. M. and Foroozesh, N. and Zavadskas, E. K. and Antucheviciene, J.},
  doi          = {10.1007/s00500-020-04675-4},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {12313-12327},
  shortjournal = {Soft Comput.},
  title        = {A new soft computing approach for green supplier selection problem with interval type-2 trapezoidal fuzzy statistical group decision and avoidance of information loss},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Intelligent video analysis for enhanced pedestrian detection
by hybrid metaheuristic approach. <em>SOCO</em>, <em>24</em>(16),
12303–12311. (<a
href="https://doi.org/10.1007/s00500-020-04674-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent video analytics for pedestrian detection plays a vital role for enhanced and effective surveillance system. Since smart city projects are gaining momentum in most of the countries nowadays, enhanced pedestrian detection plays a vital role in the field of security and surveillance. Various classification models were in existence for detecting the pedestrians which suffers from variety of challenges like illumination, pedestrian outfits, gestures, occlusion, lighting, etc., that affects the accuracy of detection. A strong feature vector describing the pedestrian is developed to enhance the accuracy of detection. In this paper, a novel hybrid metaheuristic pedestrian detection (HMPD) approach is proposed to enhance the accuracy of the classifier. HMPD extracts the working principles of support vector machine and genetic algorithm. The proposed model is trained using a set of human and non-human images. The accuracy of the proposed model is tested with benchmarking video data available at VISOR repository. The result clearly shows that HMPD approach produces the maximum accuracy than any traditional approaches. HMPD approach can further be applied in other domains for enhanced security and surveillance.},
  archive      = {J_SOCO},
  author       = {Sri Preethaa, K. R. and Sabari, A.},
  doi          = {10.1007/s00500-020-04674-5},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {12303-12311},
  shortjournal = {Soft Comput.},
  title        = {Intelligent video analysis for enhanced pedestrian detection by hybrid metaheuristic approach},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Performance-driven ensemble ICA chemical process monitoring
based on fault-relevant models. <em>SOCO</em>, <em>24</em>(16),
12289–12302. (<a
href="https://doi.org/10.1007/s00500-020-04673-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Independent component analysis has been widely used in non-Gaussian chemical process monitoring. However, using the normal operation data or adopting a certain independent component selection criteria alone to construct the monitoring model cannot achieve satisfactory monitoring performance. To address the problem effectively, a fault-relevant model selection combined with ensemble learning and the Bayesian inference method is developed in this study. First, numerous models are constructed on the basis of the randomly selected ICs. Second, the models with the highest fault detection rates for each fault are selected. Then, a screening algorithm based on the difference in detection results is adopted to reduce the redundancy of the selected models and thus improve the monitoring performance. Finally, Bayesian inference is adopted to combine the testing results of the retained models. Case studies containing numerical simulations and the Tennessee Eastman benchmark process illustrate the validity of the proposed approach.},
  archive      = {J_SOCO},
  author       = {Li, Zhichao and Yan, Xuefeng},
  doi          = {10.1007/s00500-020-04673-6},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {12289-12302},
  shortjournal = {Soft Comput.},
  title        = {Performance-driven ensemble ICA chemical process monitoring based on fault-relevant models},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient hybrid multi-level matching with diverse set of
features for image retrieval. <em>SOCO</em>, <em>24</em>(16),
12267–12288. (<a
href="https://doi.org/10.1007/s00500-020-04671-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Content-based image retrieval has become popular in the retrieval of images from large image database using reduced human intervention. Researchers are still in need to develop effective systems for dealing many of the wide-scope scientific and medical applications. Past research works have faced a problem on differentiating different images by means of using the single features alone. In this paper, a multi-level matching scheme is introduced for retrieval of image based on a hybrid feature similarity integrating local and global features. Both global- and local-level features included in multi-level scheme are used for image representation. From an image, the color information is extracted globally using a new color, edge directivity descriptor and color-based features. Further, the interest of points from each image is detected using local descriptors called local binary pattern and speeded-up robust features. Using two image databases, the improved retrieval accuracy obtained with the combination of global and local features is analyzed. Experimental outcomes have revealed the effectiveness of proposed system on achieving 91\% and 92\% precision rates over two datasets compared to other existing methods.},
  archive      = {J_SOCO},
  author       = {Geetha, V. and Anbumani, V. and Sasikala, S. and Murali, L.},
  doi          = {10.1007/s00500-020-04671-8},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {12267-12288},
  shortjournal = {Soft Comput.},
  title        = {Efficient hybrid multi-level matching with diverse set of features for image retrieval},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evaluation of retail ındustry performance ability through
ıntegrated ıntuitionistic fuzzy TOPSIS and data envelopment analysis
approach. <em>SOCO</em>, <em>24</em>(16), 12255–12266. (<a
href="https://doi.org/10.1007/s00500-020-04669-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research proposes a performance evaluation model for the retail industry (RI) through an integrated intuitionistic fuzzy Technique for Order of Preference by Similarity to Ideal Solution (IF-TOPSIS) and data envelopment analysis (DEA). In the literature, DEA is one of the most commonly applied methods for RI evaluation to measure the relative efficiency of peer decision-making units (DMUs). This research proposes a decision-making algorithm with a hierarchical structure to find performance efficiencies. The objective of this research is to develop the performance evaluation process for RI in Turkey by utilizing both qualitative and quantitative criteria. Firstly, IF-TOPSIS is applied to handle more complex problems in which the decision-maker has some uncertainty and hesitation in assigning qualitative preference values for the considered objects. Secondly, the alternatives based on both qualitative and quantitative data are formulated by DEAs to classify RI performance evaluation. The results imply that using IF-TOPSIS value as the only output into DEA classification is more accurate than just using the entire quantitative variables. The results show that the combination of the two methods is suitable for any number of DMUs.},
  archive      = {J_SOCO},
  author       = {Rouyendegh, Babak Daneshvar and Yildizbasi, Abdullah and Yilmaz, Ibrahim},
  doi          = {10.1007/s00500-020-04669-2},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {12255-12266},
  shortjournal = {Soft Comput.},
  title        = {Evaluation of retail ındustry performance ability through ıntegrated ıntuitionistic fuzzy TOPSIS and data envelopment analysis approach},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dynamic ensemble selection based on hesitant fuzzy multiple
criteria decision making. <em>SOCO</em>, <em>24</em>(16), 12241–12253.
(<a href="https://doi.org/10.1007/s00500-020-04668-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Among several extensions of fuzzy sets, hesitant fuzzy sets (HFSs) are interesting and practical. This paper proposes an application of HFSs in multiple classifier systems (MCSs). The MCSs have been proven as an effective and robust strategy for classification problems. These systems combine different classifiers and generally are composed of three steps: generation, selection (optional) and integration. This paper focuses on the selection step and proposes a novel dynamic ensemble selection method. In particular, the proposed method employs some selection criteria to determine the range of competency of the classifiers, and then, a HMCDM (hesitant fuzzy multiple criteria decision making) method is utilized to select the appropriate classifiers. Experimental results show that the proposed framework improves classification accuracy when compared against current state-of-the-art dynamic ensemble selection techniques. The Quade nonparametric statistical test confirms the capability of our proposed method.},
  archive      = {J_SOCO},
  author       = {Elmi, Javad and Eftekhari, Mahdi},
  doi          = {10.1007/s00500-020-04668-3},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {12241-12253},
  shortjournal = {Soft Comput.},
  title        = {Dynamic ensemble selection based on hesitant fuzzy multiple criteria decision making},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An artificial neural network model for the unary description
of pure substances and its application on the thermodynamic modelling of
pure iron. <em>SOCO</em>, <em>24</em>(16), 12227–12239. (<a
href="https://doi.org/10.1007/s00500-019-04663-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this work is to introduce a novel approach for the universal description of the thermodynamic functions of pure substances on the basis of artificial neural networks. The proposed approximation method is able to describe the thermodynamic functions ( $$C_{p}(T), S(T), H(T)-H(T_{\mathrm{ref}}), G(T)$$ ) of the different phases of unary material systems in a wide temperature range (between 0 and 6000 K). Phase transition temperatures and the respective enthalpies of transformation, which are computationally determined by the minimization of the Gibbs free energy, are also approximated. This is achieved by using artificial neural networks as models for the thermodynamic functions of the individual phases and by expressing the thermodynamic quantities in terms of the free network parameters. The resulting expressions are then optimized with machine learning algorithms on the basis of measurement data. A physical basis for the resulting approximation is given by the use of, among others, Planck–Einstein functions as activation function of the neurons of the network. This article provides a description of the method and as an example of a specific application the approximation of the thermodynamic functions of the different phases of pure iron. The article focuses on the problem of the representation of thermodynamic data and their practical application.},
  archive      = {J_SOCO},
  author       = {Länge, Maximilian},
  doi          = {10.1007/s00500-019-04663-3},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {12227-12239},
  shortjournal = {Soft Comput.},
  title        = {An artificial neural network model for the unary description of pure substances and its application on the thermodynamic modelling of pure iron},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Interpolative leishman-stained transformation invariant deep
pattern classification for white blood cells. <em>SOCO</em>,
<em>24</em>(16), 12215–12225. (<a
href="https://doi.org/10.1007/s00500-019-04662-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blood analysis is regarded as the one of the most predominant examinations in medicine field to obtain patient physiological state. A significant process in the classification of white blood cells (WBC) is blood sample analysis. An automatic system that is potential of identifying WBC aids the physicians in early disease diagnosis. In contrast to previous methods, thus resulting in trade-off among computational time (CT) and performance efficiency, an interpolative Leishman-stained multi-directional transformation invariant deep classification (LSM-TIDC) for WBC is presented. LSM-TIDC method discovers possibilities of interpolation and Leishman-stained function, because they require no explicit segmentation, and yet they eliminated false regions for several input images. Next, with the preprocessed images, optimal and relevant features are extracted by applying multi-directional feature extraction. To identify and classify blood cells, a system is developed via the implementation of transformation invariant model for extraction of nucleus and subsequently performs classification through convolutional and pooling characteristics. The proposed method is evaluated by extensive experiments on benchmark database like blood cell images from Kaggle. Experimental results confirm that LSM-TIDC method significantly captures optimal and relevant features and improves the classification accuracy without compromising CT and computational overhead.},
  archive      = {J_SOCO},
  author       = {Karthikeyan, M. P. and Venkatesan, R.},
  doi          = {10.1007/s00500-019-04662-4},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {12215-12225},
  shortjournal = {Soft Comput.},
  title        = {Interpolative leishman-stained transformation invariant deep pattern classification for white blood cells},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Secure auditing and deduplication for encrypted cloud data
supporting ownership modification. <em>SOCO</em>, <em>24</em>(16),
12197–12214. (<a
href="https://doi.org/10.1007/s00500-019-04661-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Storing only one unique copy of the same cloud data and guaranteeing its integrity are two main goals for cloud storage auditing and deduplication schemes. In such schemes, data owners can firmly believe the data integrity by periodically auditing and the cloud server can save lots of storage space by exploiting the duplication techniques. However, when a data owner deletes or modifies his outsourced data, he should lose the ownership for the original data and should not be able to successfully retrieve this data any more. For all we know, existing cloud storage auditing and deduplication literatures fail to support the modifications of ownership, which actually occur quite often in actual cloud storage scenarios. In this paper, we propose the first deduplicated data integrity auditing scheme supporting the ownership modification. It guarantees the integrity of the outsourced data and supports the dynamic access control over the outsourced data. We employ a re-encryption algorithm and the secure identity-based broadcast encryption technology, which prevent data from being disclosed to the revoked owners, even if they previously had prior ownership of these data. The security and efficiency of our proposed scheme have been validated by detailed analysis and experiments.},
  archive      = {J_SOCO},
  author       = {Bai, Jianli and Yu, Jia and Gao, Xiang},
  doi          = {10.1007/s00500-019-04661-5},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {12197-12214},
  shortjournal = {Soft Comput.},
  title        = {Secure auditing and deduplication for encrypted cloud data supporting ownership modification},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multidimensional agro-economic model with soft-IoT
framework. <em>SOCO</em>, <em>24</em>(16), 12187–12196. (<a
href="https://doi.org/10.1007/s00500-019-04657-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent times, there has been a great motivation toward research in the field of big data analysis and their incorporation into Internet of Things (IoT). The basic idea behind IoT is to ensure provision of services to clients all over the globe at any point of time from a pool of resources. With increasing volumes of data being handled, processed and stored in recent times, an efficient processing mechanism for these huge volumes of data is available in the form of big data handlers which ensure speedy provision of services without any delay overhead. Hence, big data and IoT put together prove to be the most effective tool and need of the hour for smooth handling and provision of services demanded by clients thus improving the overall quality of service. These two concepts have been effectively applied to developing an intelligent agricultural economic model which is quite heterogeneous in nature thus posing to be a great research challenge. Agro-economic models are quite essential and critical as agriculture forms the backbone of many developing nations across the globe. ANFIS model introduces the necessary intelligence for the big data analytic system to handle the heterogeneous nature of agro-economic input data and provide a suitable prediction. A sample data of five hundred details from five different subsets have been used in the experimental model and prediction of yield computed and compared against recent techniques.},
  archive      = {J_SOCO},
  author       = {Chen, Xiaowei and Wang, Harry Haoxiang and Tian, Bin},
  doi          = {10.1007/s00500-019-04657-1},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {12187-12196},
  shortjournal = {Soft Comput.},
  title        = {Multidimensional agro-economic model with soft-IoT framework},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Classification of bearing vibration speeds under 1D-LBP
based on eight local directional filters. <em>SOCO</em>,
<em>24</em>(16), 12175–12186. (<a
href="https://doi.org/10.1007/s00500-019-04656-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bearings are the most commonly used machine element in order to reduce rotational friction in machines and to compensate radial and axial loads. It is very important to determine the faults in the bearings in terms of the machine health. In order to accurately diagnose bearing-related faults with traditional machine learning methods, it is necessary to identify the features that characterize bearing fault most accurately. Therefore, a new feature extraction procedure has been proposed to determine the vibration signal velocities of different fault sizes and types in this study. The new approach has been employed to obtain features from the vibration signals for different scenarios. After different filtering based on 1D-LBP method, the F-1D-LBP method was used to construct feature vectors. The filters reduce the noise in the signals and provide different feature groups. In other words, it is aimed to generate filters in order to extract different patterns that can separate signals. For each filter applied, different patterns can be obtained for the same local point on signals. Thus, the signals can be represented by different feature vectors. Then, by using these feature groups with various machine learning methods, vibration velocities were separated from each other. As a result, it was observed that the obtained feature had promising results for classification of bearing vibrations.},
  archive      = {J_SOCO},
  author       = {Kaya, Yılmaz and Kuncan, Melih and Kaplan, Kaplan and Minaz, Mehmet Recep and Ertunç, H. Metin},
  doi          = {10.1007/s00500-019-04656-2},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {12175-12186},
  shortjournal = {Soft Comput.},
  title        = {Classification of bearing vibration speeds under 1D-LBP based on eight local directional filters},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Homographic pun location using multi-dimensional semantic
relationships. <em>SOCO</em>, <em>24</em>(16), 12163–12173. (<a
href="https://doi.org/10.1007/s00500-019-04654-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Homographic pun has been developed into a new research area as an important branch of humor research, being a common source of humor in jokes and other comedic works. Pun word is the key to better understand homographic pun. However, in order to construct automatic model for locating the pun from homographic pun, it remains difficult challenges because of the ambiguity and confusion. In this paper, we firstly introduce several multi-dimensional semantic relationships of homographic pun based on the relevant theory and then employ a novel effective un-supervised semantic similarity match approach MSRLP that depending on the multi-dimensional semantic relationships to locate the pun in a homographic pun. Performance evaluation demonstrates that our presented approach significantly achieves the state-of-the-art performance on the public SemEval2017 Task7 dataset, outperforming a number of strong baselines by at least 3.67\% in F1-score measure.},
  archive      = {J_SOCO},
  author       = {Diao, Yufeng and Lin, Hongfei and Yang, Liang and Fan, Xiaochao and Wu, Di and Xu, Kan},
  doi          = {10.1007/s00500-019-04654-4},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {12163-12173},
  shortjournal = {Soft Comput.},
  title        = {Homographic pun location using multi-dimensional semantic relationships},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). UAV tracking based on saliency detection. <em>SOCO</em>,
<em>24</em>(16), 12149–12162. (<a
href="https://doi.org/10.1007/s00500-019-04652-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel unmanned aerial vehicle tracking framework. First, hierarchical convolutional neural network features are used to track the object independently in a correlation filter tracking framework. Second, a stability criterion is proposed, which is based on the variance of tracking results of each layer. Next, tracking result is adaptively fused via the variance. Meanwhile, the criterion can be used to measure the quality of tracking results. A saliency detection method is utilized to generate candidate regions when tracking failure occurs. By virtue of this method, our tracking algorithm can robustly cope with appearance changes and prevent drifting issues. Experimental results show that our proposed tracking algorithm performs favorably against state-of-the-art methods on two benchmark datasets.},
  archive      = {J_SOCO},
  author       = {Wang, Yong and Luo, Xinbin and Luo, Lingkun and Zhang, Huanlong and Wei, Xian},
  doi          = {10.1007/s00500-019-04652-6},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {12149-12162},
  shortjournal = {Soft Comput.},
  title        = {UAV tracking based on saliency detection},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Some new basic operations of probabilistic linguistic term
sets and their application in multi-criteria decision making.
<em>SOCO</em>, <em>24</em>(16), 12131–12148. (<a
href="https://doi.org/10.1007/s00500-019-04651-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the operations and methods to tackle the probabilistic linguistic multi-criteria decision making (PL-MCDM) problems where criteria are interactive. To avoid the defects of the existing operations of the probabilistic linguistic term sets (PLTSs) and make the operations easier, we redefine a family of operations for PLTSs and investigate their properties in-depth. Then, based on the probabilistic linguistic group utility measure, the probabilistic linguistic individual regret measure and the probabilistic linguistic compromise measure proposed in this paper, the probabilistic linguistic E-VIKOR method is developed. To make up for the deficiency of the above method, the improved probabilistic linguistic VIKOR method which can not only consider the distances between the alternatives and the positive ideal solution but also consider the distances between the alternatives and the negative ideal solution is developed to solve the correlative PL-MCDM problems. And then a case about the video recommender system is conducted to demonstrate the applicability and effectiveness of the proposed methods. Finally, the improved probabilistic linguistic VIKOR method is compared with the probabilistic linguistic E-VIKOR method, the general VIKOR method and the extended TOPSIS method to show its merits.},
  archive      = {J_SOCO},
  author       = {Yue, Na and Xie, Jialiang and Chen, Shuili},
  doi          = {10.1007/s00500-019-04651-7},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {12131-12148},
  shortjournal = {Soft Comput.},
  title        = {Some new basic operations of probabilistic linguistic term sets and their application in multi-criteria decision making},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel framework for stock trading signals forecasting.
<em>SOCO</em>, <em>24</em>(16), 12111–12130. (<a
href="https://doi.org/10.1007/s00500-019-04650-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates stock trading points prediction that is an attractive yet challenging research topic in the financial investment area, as the stock market is an unstable and complex system. A small improvement in the predictive performance can make profit. To realize trading points detection, we propose a novel method which integrates piecewise linear representation (PLR) and feature weighted support vector machine (FW-WSVM) to forecast the stock trading points (PLR–FW-WSVM). Firstly, we generate numerous trading points (valley or peak) from the trading data by PLR and formulate the stock trading points prediction as a weighted four-class classification problem. Then, we estimate the importance of each input feature by computing the information gain and apply FW-WSVM to learn the prediction model between the trading points and the input features from the historical data. Afterward, the model is used to forecast the future turning points from the input features. Lastly, we conduct a series of experiments among PLR–FW-WSVM, PLR–WSVM and PLR–ANN over 30 stocks with different investment strategies. The results show that our proposed method generates the highest accuracy and profits in average, which indicates PLR–FW-WSVM is effective and can be applied to forecast the future trading points in the real-world application.},
  archive      = {J_SOCO},
  author       = {Chen, Yingjun and Hao, Yijie},
  doi          = {10.1007/s00500-019-04650-8},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {12111-12130},
  shortjournal = {Soft Comput.},
  title        = {A novel framework for stock trading signals forecasting},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Quintuple implication principle on interval-valued
intuitionistic fuzzy sets. <em>SOCO</em>, <em>24</em>(16), 12091–12109.
(<a href="https://doi.org/10.1007/s00500-019-04649-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper mainly aims to introduce Quintuple Implication Principle (QIP) on interval-valued intuitionistic fuzzy sets (IVIFSs). Firstly, some algebraic properties of a class of interval-valued intuitionistic triangular norms are discussed in detail. In particular, a unified expression of residual interval-valued intuitionistic fuzzy implications generated by left-continuous triangular norms is presented. Secondly, Triple Implication Principles (TIPs) of both interval-valued intuitionistic fuzzy modus ponens (IVIFMP) and fuzzy modus tollens (IVIFMT) based on residual interval-valued intuitionistic fuzzy implications are analyzed. It is shown that the TIP solution of IVIFMP is recoverable, and the TIP solution of IVIFMT is only weakly local recoverable. Moreover, it sees by an illustrated example that the TIP method sometimes makes the computed solutions for IVIFMP and IVIFMT meaningless or misleading. To avoid the above shortcoming and enhance the recovery property of TIP solution of IVIFMT, QIP and $$\alpha $$ -QIP for IVIFMP and IVIFMT are investigated and the corresponding expressions of solutions of them are also given, respectively. In addition, the QIP methods for IVIFMP and IVIFMT are recoverable and sound. Finally, QIP solutions of IVIFMP for multiple fuzzy rules are provided. An application example for medical diagnosis is given to illustrate the feasibility and effectiveness of the QIP of IVIFMP.},
  archive      = {J_SOCO},
  author       = {Jin, Jianhua and Ye, Mingfei and Pedrycz, Witold},
  doi          = {10.1007/s00500-019-04649-1},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {12091-12109},
  shortjournal = {Soft Comput.},
  title        = {Quintuple implication principle on interval-valued intuitionistic fuzzy sets},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Development and evaluation of the cascade correlation neural
network and the random forest models for river stage and river flow
prediction in australia. <em>SOCO</em>, <em>24</em>(16), 12079–12090.
(<a href="https://doi.org/10.1007/s00500-019-04648-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately predicting river flows over daily timescales is considered as an important task for sustainable management of freshwater ecosystems, agricultural applications, and water resources management. In this research paper, artificial intelligence (AI) techniques, namely the cascade correlation neural networks (CCNN) and the random forest (RF) models, were employed in daily river stage and river flow prediction for two river systems (i.e., Dulhunty River and Herbert River) in Australia. To develop the CCNN and RF models, a significant 3-day antecedent river stage and river flow time series were used. 80\% of the whole data were used for model training and the remaining 20\% for model testing. A total of ten different model structures with different input combinations were used to evaluate the optimal model in the training phase, and the results were analyzed using statistical metrics including the root mean square error (RMSE), Nash–Sutcliffe coefficient (NS), Willmott’s index of agreement (WI), and Legate and McCabe’s index (ELM) in the testing phase. The inter-comparison of CCNN and RF models for both river systems showed that the CCNN model was able to generate a more accurate prediction of the river stage and river flow compared to the RF model. Due to hydro-geographic differences leading to a different underlying historical data characteristics, the optimal CCNN’s performance for the Dulhunty River was found to be most accurate, in terms of ELM = 0.779, WI = 0.964, and ENS = 0.862 versus 0.775, 0.968, and 0.885 for the Herbert River. Following the performance accuracies, the authors ascertained that the CCNN model can be taken as a preferred data intelligent tool for river stage and river flow prediction.},
  archive      = {J_SOCO},
  author       = {Ghorbani, Mohammad Ali and Deo, Ravinesh C. and Kim, Sungwon and Hasanpour Kashani, Mahsa and Karimi, Vahid and Izadkhah, Maryam},
  doi          = {10.1007/s00500-019-04648-2},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {12079-12090},
  shortjournal = {Soft Comput.},
  title        = {Development and evaluation of the cascade correlation neural network and the random forest models for river stage and river flow prediction in australia},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel clustering method built on random weight artificial
neural networks and differential evolution. <em>SOCO</em>,
<em>24</em>(16), 12067–12078. (<a
href="https://doi.org/10.1007/s00500-019-04647-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is the process of partition of samples, which have not got any labels, into groups. The main aim of clustering was to achieve the lowest distance between samples in each cluster and to achieve the highest distance between the samples in a cluster with the samples in other clusters. In this paper, a novel clustering approach was proposed. This novel approach was built on the differential evolution, which is a meta-heuristic method that searches for the optimum solution, and the randomized artificial neural network, which is a kind of artificial neural network that has a single hidden layer. To evaluate and validate the proposed approach, 48 datasets were employed. Achieved results by the proposed approach were compared with the obtained results by k-means, hierarchical, k-centers clustering, and some other versions of the proposed approach, which are built on ANN and particle swarm optimization, and harmony search methods. It was found that the proposed approach is successful enough to be employed for clustering in terms of achieved inner and outer distance.},
  archive      = {J_SOCO},
  author       = {Ertuğrul, Ömer Faruk},
  doi          = {10.1007/s00500-019-04647-3},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {12067-12078},
  shortjournal = {Soft Comput.},
  title        = {A novel clustering method built on random weight artificial neural networks and differential evolution},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Color harmony algorithm: An art-inspired metaheuristic for
mathematical function optimization. <em>SOCO</em>, <em>24</em>(16),
12027–12066. (<a
href="https://doi.org/10.1007/s00500-019-04646-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last 3 decades, metaheuristic algorithms have received more popularity because of their superior performance to solve large and complex optimization problems. Most of these algorithms are inspired by biological phenomena, social behavior of animals, science and art. Among these four sources, the last one is utilized only by one algorithm. In this paper, we propose another novel art-inspired population-based metaheuristic, called color harmony algorithm (CHA), for solving the global optimization problems. The proposed method models its search behavior through combining harmonic colors based on their relative positions around the hue circle in the Munsell color system and harmonic templates. We utilize simultaneously four different fitness information to construct the hue groups, which improve search ability of the algorithm. CHA has two different phases including the concentration phase and the dispersion phase which are employed to explore and exploit the search space. The performance of the proposed method has been examined using several benchmark test functions commonly used in the literature. To show the effectiveness and robustness of the proposed method, the results are compared with those obtained using ten well-known metaheuristic algorithms. Also, the Wilcoxon Signed-Rank test is conducted to measure the pair-wise statistical performances of the algorithms. The results indicate that besides the simplicity of the proposed algorithm, CHA can outperform the other considered algorithms in terms of the convergence speed and the number of function evaluations.},
  archive      = {J_SOCO},
  author       = {Zaeimi, Mohammad and Ghoddosian, Ali},
  doi          = {10.1007/s00500-019-04646-4},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {12027-12066},
  shortjournal = {Soft Comput.},
  title        = {Color harmony algorithm: An art-inspired metaheuristic for mathematical function optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Soft computing approaches for character credential and word
prophecy analysis with stone encryptions. <em>SOCO</em>,
<em>24</em>(16), 12013–12026. (<a
href="https://doi.org/10.1007/s00500-019-04643-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The uniform corpus of untranslated script is a preliminary stage for computational epigraphy. Mechanizing this process through deep learning algorithms will be an essential support to the epigraphical research. Our proposed system based on soft computing techniques focuses on the progression of recognizing the eleventh-century ancient Tamil character and converting them into current-century word form. Initially, the system is implemented by performing preprocessing steps followed by image segmentation. The decomposed image undergoes a hybrid feature extraction technique along with Chi-square test to check whether entire pixel in image of Zernike is bounded inside the unit circle or not, whereas ANOVA method is used for testing the significant difference between HOG feature and zoning feature. These functions are subjected to image classification and proceeded with character recognition using convolutional neural networks. Finally, the identified character is progressed into word form with the help of boggle algorithm. The hybrid feature extraction along with convolutional neural networks is achieved with 92.78\% of recognition rate accurately. Our experiment shows a large perspective of deep learning algorithms in automatic epigraphy.},
  archive      = {J_SOCO},
  author       = {Vani, V. and Ananthalakshmi, S. R.},
  doi          = {10.1007/s00500-019-04643-7},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {12013-12026},
  shortjournal = {Soft Comput.},
  title        = {Soft computing approaches for character credential and word prophecy analysis with stone encryptions},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new randomness approach based on sine waves to improve
performance in metaheuristic algorithms. <em>SOCO</em>, <em>24</em>(16),
11989–12011. (<a
href="https://doi.org/10.1007/s00500-019-04641-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main goal of this paper is to outline a new approach to represent the randomness that we can find in different metaheuristics as a stochastic process which helps in the performance of the analyzed metaheuristic. This new way of viewing randomness is based on the behavior of sine waves that we can find in many situations in nature or in physics laws. In this paper, we evaluate this proposed randomness with three metaheuristics: the grey wolf optimizer, firefly algorithm and flower pollination algorithm, with the goal of studying the performance of the proposed randomness method in different types of metaheuristics. A set of standard benchmark functions were used to test the proposed randomness method, which are classified as unimodal and multimodal benchmark functions. In addition, the benchmark functions of the CEC 2015 Competition are used. Finally, we present tests with functions that were presented in the CEC 2017 competition for constrained real-parameter optimization. We also present a comparative study of the analyzed metaheuristics, and this comparison is between their original randomness method and the proposed randomness method for each algorithm. Finally, we present the performance and results of the methods with different number of dimensions to complete the study.},
  archive      = {J_SOCO},
  author       = {Rodríguez, Luis and Castillo, Oscar and García, Mario and Soria, José},
  doi          = {10.1007/s00500-019-04641-9},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {11989-12011},
  shortjournal = {Soft Comput.},
  title        = {A new randomness approach based on sine waves to improve performance in metaheuristic algorithms},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Enhanced crow search algorithm for AVR optimization.
<em>SOCO</em>, <em>24</em>(16), 11957–11987. (<a
href="https://doi.org/10.1007/s00500-019-04640-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an enhanced crow search algorithm (ECSA) for solving numerical and real-life engineering problems. Novelties of the proposed method are fourfold: (1) addition of an archive component in the standard crow search algorithm (CSA) to incorporate past experience of finding solution (2) formulation of non-hideout position so that crow will remain near its hideout position, (3) Rechenberg’s 1/5th rule is exploited to change the flight length (instead of fixed) to speed up optimization process and (4) awareness probability is regulated to set a trade-off between local and global exploration. The performance of proposed technique is investigated on 23 benchmark functions such as unimodal, multimodal and fixed-dimension multimodal benchmark functions. The results of ECSA are compared to other state-of-the-art metaheuristic algorithms, in which ECSA outperformed other algorithms in majority of the benchmark functions. Further, to validate the effectiveness of the proposed method, ECSA has been used for optimization of proportional–integral–derivative (PID) controller. Results of ECSA–PID have been compared with conventional CSA as well as with other state-of-the-art techniques like Ziegler–Nichols (Z–N), Kitamori, ACO, multi-objective ACO, multi-objective GA and fuzzy and space gravitational optimization algorithm. The proposed algorithm is implemented on the AVR system and tested under various conditions for robustness. Consistency in the results on benchmark systems as well as on their variants and AVR system and its variants prove the robustness of the proposed method. Also, the performance of the proposed algorithm is found to be better than the existing techniques.},
  archive      = {J_SOCO},
  author       = {Bhullar, Amrit Kaur and Kaur, Ranjit and Sondhi, Swati},
  doi          = {10.1007/s00500-019-04640-w},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {11957-11987},
  shortjournal = {Soft Comput.},
  title        = {Enhanced crow search algorithm for AVR optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Intuitionistic fuzzy optimistic and pessimistic multi-period
portfolio optimization models. <em>SOCO</em>, <em>24</em>(16),
11931–11956. (<a
href="https://doi.org/10.1007/s00500-019-04639-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are myriad works that deal with the fuzzy multi-period portfolio selection problem, but when we talk about multi-period portfolio selection in an intuitionistic fuzzy realm, to the best of our knowledge, there is no research work that deals with the same. So, to fill this research gap, we propose an intuitionistic fuzzy multi-period portfolio selection model with the objectives of maximization of the terminal wealth and minimization of the cumulative risk subject to several realistic constraints such as complete capital utilization, no short selling, fixed transaction costs for buying and selling, bounds on the desired returns of each period, cardinality constraint, and bounds on the minimal and the maximal proportion of the capital allocated to an asset. The membership and non-membership of the objectives are modeled using their extreme values. The proposed approach provides avenues for the inclusion and minimization of the hesitation degree into decision making, thereby resulting in a significantly better portfolio. Parameters $$\theta _W$$ and $$\theta _{Va}$$ are used to introduce the hesitation in the model, and, based on their values, the model is further categorized into optimistic and pessimistic intuitionistic fuzzy multi-period portfolio selection models for optimistic and pessimistic investors, respectively. The max–min approach is used to solve the proposed models. Furthermore, a numerical illustration is presented to exhibit the virtues of the proposed model.},
  archive      = {J_SOCO},
  author       = {Gupta, Pankaj and Mehlawat, Mukesh Kumar and Yadav, Sanjay and Kumar, Arun},
  doi          = {10.1007/s00500-019-04639-3},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {11931-11956},
  shortjournal = {Soft Comput.},
  title        = {Intuitionistic fuzzy optimistic and pessimistic multi-period portfolio optimization models},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The uncertainty measures for covering rough set models.
<em>SOCO</em>, <em>24</em>(16), 11909–11929. (<a
href="https://doi.org/10.1007/s00500-020-05098-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncertainty measures are important tools for analyzing various data. However, there are relatively few studies on the uncertainty measures for covering rough set models. In this paper, from the viewpoint of the lower and upper approximations, we propose new uncertainty measures, the lower rough entropy and the upper rough entropy, for covering rough set models. Then, we define the concepts of the joint entropy and the conditional entropy in the covering rough set models. Some important properties of these measures are obtained, and their relationships are investigated. Furthermore, we provide a certain characterization of reducible element of a covering by means of the proposed measures, and apply the proposed rough entropy to evaluate the significance of covering granules of a covering. Finally, we apply these rough entropies to measure a dual degree between covering lower and upper approximations. The theoretical analysis and examples show that the proposed uncertainty measures for covering rough set models are reasonable and useful.},
  archive      = {J_SOCO},
  author       = {Wang, Zhaohao and Zhang, Xiaoping and Deng, Jianping},
  doi          = {10.1007/s00500-020-05098-x},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {11909-11929},
  shortjournal = {Soft Comput.},
  title        = {The uncertainty measures for covering rough set models},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A comprehensive study of PAPR reduction techniques: Design
of DSLM-CT joint reduction technique for advanced waveform.
<em>SOCO</em>, <em>24</em>(16), 11893–11907. (<a
href="https://doi.org/10.1007/s00500-020-05086-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the challenges in rollout of 5G is utilizing the radio communication which is not accessible by today’s radio system. To achieve a high data rate, it is necessary to make 5G networks compatible with advanced waveform. In this correspondence, we discussed advanced waveform technique non-orthogonal multiple access (NOMA) and filter bank multicarrier (FBMC) for 5G network. The design of advanced form technique compatible with advanced wireless communication is very important to fulfill the vision the 5G. Peak average to power ratio (PAPR) is viewed as a significant issue in actualizing NOMA and FBMC framework. PAPR reduction design for FBMC has been presented in the writing survey, yet PAPR decrease methods in NOMA are not investigated up until this point. In that regard are different downsides of minimization techniques introduced in the review. In the present investigation, we have inspected and analyzed the presence of the reduction systems and proposed a hybrid strategy (DSLM-CT) based on discrete selective mapping (DSLM) and circular transformation technique. Further, several parameters are discussed and analyzed. At long last, it is reasoned that the exhibition of the proposed hybrid technique is better than the existed minimization methods. Additionally, it is also observed that the implementation of proposed technique reduces the power consumption of solid state power amplifier.},
  archive      = {J_SOCO},
  author       = {Kumar, Arun and Gupta, Manisha},
  doi          = {10.1007/s00500-020-05086-1},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {11893-11907},
  shortjournal = {Soft Comput.},
  title        = {A comprehensive study of PAPR reduction techniques: Design of DSLM-CT joint reduction technique for advanced waveform},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Granulation of ecological networks under fuzzy soft
environment. <em>SOCO</em>, <em>24</em>(16), 11867–11892. (<a
href="https://doi.org/10.1007/s00500-020-05083-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main idea of this work is the exploration of granular structures by applying the hybrid models of fuzzy soft sets and fuzzy soft graphs to discuss the indiscernibility partition of set of universe. The information granulation is examined by applying fuzzy soft theory, and the corresponding behavior of granules is reviewed. This article proposes a novel technique of formation of granular structures using fuzzy soft graphs and defines the fuzzy soft granules. Two degree-based models are introduced to explore the abstraction of these granular structure. Then, we use these two degree-based models to granulate the certain relationships between different species in an ecological system. Further, we develop and implement some algorithms of our proposed models to granulate the underconsideration networks. Finally, a comprehensive comparison of our proposed model with other existing techniques is presented to prove the applicability and effectiveness of fuzzy soft granulation.},
  archive      = {J_SOCO},
  author       = {Akram, Muhammad and Luqman, Anam},
  doi          = {10.1007/s00500-020-05083-4},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {11867-11892},
  shortjournal = {Soft Comput.},
  title        = {Granulation of ecological networks under fuzzy soft environment},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Global optimization method with dual lipschitz constant
estimates for problems with non-convex constraints. <em>SOCO</em>,
<em>24</em>(16), 11853–11865. (<a
href="https://doi.org/10.1007/s00500-020-05078-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the constrained global optimization problems, in which the functions are of the “black-box” type and satisfy the Lipschitz condition. The algorithms for solving the problems of this class require the use of adequate estimates of the a priori unknown Lipschitz constants for the problem functions. A novel approach presented in this paper is based on a simultaneous use of two estimates of the Lipschitz constant: an overestimated and an underestimated one. The upper estimate provides the global convergence, whereas the lower one reduces the number of trials necessary to find the global optimizer with the required accuracy. The considered algorithm for solving the constrained problems does not use the ideas of the penalty function method; each constraint of the problem is accounted for separately. The convergence conditions of the proposed algorithm are formulated in the corresponding theorem. The results of the numerical experiments on a series of multiextremal problems with non-convex constraints demonstrating the efficiency of the proposed scheme of dual Lipschitz constant estimates are presented.},
  archive      = {J_SOCO},
  author       = {Strongin, Roman and Barkalov, Konstantin and Bevzuk, Semen},
  doi          = {10.1007/s00500-020-05078-1},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {11853-11865},
  shortjournal = {Soft Comput.},
  title        = {Global optimization method with dual lipschitz constant estimates for problems with non-convex constraints},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On fundamental isomorphism theorems in soft subgroups.
<em>SOCO</em>, <em>24</em>(16), 11841–11851. (<a
href="https://doi.org/10.1007/s00500-020-05074-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Molodsov initiated a novel concept of soft set theory, which is a completely new approach for modeling vagueness and uncertainty, which there is no limited condition to description of objects and is free from the difficulties affecting existing methods. This makes the theory very convenient and easy to apply in practice. After the pioneering work of Molodsov, there has been a great effort to obtain soft set analogues of classical theories. Among other fields, a progressive developments are made in the field of algebraic structure. To extend the soft set in group theory, many researchers introduced the notions of soft subgroup and investigated its applications in group theory and decision making. In this paper, by using the soft sets and their duality, we introduce new concepts on the soft sets, which are called soft quotient subgroup and quotient dual soft subgroup. We then derive their algebraic properties and, in sequel, investigate the fundamental isomorphism theorems in soft subgroups analogous to the group theory.},
  archive      = {J_SOCO},
  author       = {Çağman, N. and Barzegar, R. and Hosseini, S. B.},
  doi          = {10.1007/s00500-020-05074-5},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {11841-11851},
  shortjournal = {Soft Comput.},
  title        = {On fundamental isomorphism theorems in soft subgroups},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mathematical modeling and chemical conduct considering
non-newtonian nanofluid by utilizing heat flux features. <em>SOCO</em>,
<em>24</em>(16), 11829–11839. (<a
href="https://doi.org/10.1007/s00500-020-05072-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the current era of nanotechnology, the design of biological devices requires efficient transmission of energy among the components. Computational studies are always prerequisite for general models. In view of this importance, this paper investigated the characterizations regarding the steady flow of 2D Oldroyd-B nanofluid in the presence of thermal radiation (nonlinear) over a radially stretched sheet. Buongiorno revised nanofluid relation of the nanomaterial is instigated in precise modeling. For the mechanism of mass transmission, we utilized features of constructive–destructive prescription. As a result of modeling, the raised PDEs are converted into ODEs by appropriate transformations. The numeric scheme BVP4C is utilized for the solutions. The physical variables of the assumed flow pattern are shown graphically with the significance of the involved parameter. Besides, the prescribed investigation explored the significant impact by involved physical parameters along with the declining conduct influenced by chemical reaction parameters on the considered model. Moreover, the numerical outcomes of surface drag force and the transfer rate of heat–mass are tabulated for numerous sets of physical parameters. The improvement of these results is guaranteed by comparing it with existing techniques.},
  archive      = {J_SOCO},
  author       = {Ali, W. and Mahmood, S. and Chammam, Wathek and Ul-Haq, Wasim and Khan, W. A. and Abbas, S. Z.},
  doi          = {10.1007/s00500-020-05072-7},
  journal      = {Soft Computing},
  number       = {16},
  pages        = {11829-11839},
  shortjournal = {Soft Comput.},
  title        = {Mathematical modeling and chemical conduct considering non-newtonian nanofluid by utilizing heat flux features},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Enhancement of network lifetime using fuzzy clustering and
multidirectional routing for wireless sensor networks. <em>SOCO</em>,
<em>24</em>(15), 11805–11818. (<a
href="https://doi.org/10.1007/s00500-020-04900-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless sensors are those devices which sense any physical quantity. Group of sensor node working together can be termed as a wireless sensor network (WSN). The lifetime of WSN is critical and is based greatly on energy consumption for data transmission. By using the available energy efficiently, the nodes can operate for a longer time thereby increasing the network lifetime. In this paper, fuzzy-based clustering is used for clustering, which selects an optimal cluster head (CH). Fuzzy clustering is made with the help of residual energy and distance as fuzzy descriptors. However, when the network is heterogeneous, fuzzy-based clustering is found in efficient in many cases. To improve efficiency, a multidirectional routing is proposed along with fuzzy clustering. Using multidirectional routing, possible multiple paths between node and BS will be found out and the path with least hop will be selected as a routing path. The simulation results have been compared with traditional low energy adaptive clustering hierarchy, and a significant improvement in the lifetime of a node has been observed.},
  archive      = {J_SOCO},
  author       = {Kiran, W. S. and Smys, S. and Bindhu, V.},
  doi          = {10.1007/s00500-020-04900-0},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11805-11818},
  shortjournal = {Soft Comput.},
  title        = {Enhancement of network lifetime using fuzzy clustering and multidirectional routing for wireless sensor networks},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Development of harmonic aggregation operator with
trapezoidal pythagorean fuzzy numbers. <em>SOCO</em>, <em>24</em>(15),
11791–11803. (<a
href="https://doi.org/10.1007/s00500-019-04638-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pythagorean fuzzy sets are one of the extensions of ordinary fuzzy sets and allow a larger domain to be utilized by decision makers with respect to other extensions. Pythagorean fuzzy sets have been often used as an effective tool for handling the vagueness of multi-criteria decision making problems. Aggregation operators are a useful tool in order to collect different information provided by different sources. The objective of this paper is to develop harmonic aggregation operators for trapezoidal Pythagorean fuzzy numbers. We developed trapezoidal Pythagorean fuzzy weighted harmonic mean operator, trapezoidal Pythagorean fuzzy ordered weighted harmonic mean operator, and trapezoidal Pythagorean fuzzy hybrid harmonic mean operator. We proved some theorems for the developed operators. Finally, we presented an illustrative example using the proposed aggregation operators in order to rank the alternatives.},
  archive      = {J_SOCO},
  author       = {Aydin, Serhat and Kahraman, Cengiz and Kabak, Mehmet},
  doi          = {10.1007/s00500-019-04638-4},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11791-11803},
  shortjournal = {Soft Comput.},
  title        = {Development of harmonic aggregation operator with trapezoidal pythagorean fuzzy numbers},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Reliability of ranking-based decision methods: A new
perspective from the alternatives’ supremacy. <em>SOCO</em>,
<em>24</em>(15), 11769–11790. (<a
href="https://doi.org/10.1007/s00500-019-04637-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the immediacy of communications, the interconnection of different data sources and the large volume of information available in digital environments, rankings have become one of the most used tools in the decision making (DM) process. When choosing an option, the decision maker not only considers the positions of the different alternatives into the ranking, but also usually checks the intensity values associated with them. Therefore, it is very important that methods used to build rankings adequately represent the preferences of users. These issues, known as order and intensity preservation conditions, have been studied for the well-known multi-criteria decision analysis (MCDA) called analytical hierarchical process (AHP) and extended to reconstruction methods of AHP matrices by defining a measure that considers only the order preservation condition. In this article, a measure, complementary to the latter, that allows establishing the difference between the predominance of the alternatives between two rankings is defined. To do this, the relations of predominance between the alternatives for each ranking are analyzed, and then the comparison between these relations is made by defining a bounded supremacy-based measure called supremacy difference index $$ sdi_{m} $$ . The $$ sdi_{m} $$ behavior is compared to conventional distance measures that are not bounded, and it is used to compare three reconstruction methods of AHP from the supremacy point of view and, finally, how the $$ sdi_{m} $$ usage can be extended for the evaluation of any ranking-based method is discussed.},
  archive      = {J_SOCO},
  author       = {Karanik, Marcelo and Gomez-Ruiz, Jose Antonio and Peláez, José Ignacio and Bernal, Rubén},
  doi          = {10.1007/s00500-019-04637-5},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11769-11790},
  shortjournal = {Soft Comput.},
  title        = {Reliability of ranking-based decision methods: A new perspective from the alternatives’ supremacy},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptive wavelet ELM-fuzzy inference system-based soft
computing model for power estimation in sustainable CMOS VLSI circuits.
<em>SOCO</em>, <em>24</em>(15), 11755–11768. (<a
href="https://doi.org/10.1007/s00500-019-04636-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rapid growth of very large-scale integration (VLSI) technologies has achieved integrating millions of transistors into a single chip. This integration into a single chip results in complex circuitry, and hence, it is required to have minimal cost and low complex power estimation approaches. Power estimation of VLSI circuits at an initial stage is most prominent because it increases the life and stability of the circuit. In this work, a modified version of extreme learning machine (ELM) neural network called as adaptive wavelet extreme learning machine neural network model (AWELM) is developed and integrated with a designed fuzzy inference system (FIS) for computing power in respect of standard International Symposium on Circuits and Systems 1989 (ISCAS 1989) benchmark circuits. The proposed method is devised to estimate the power accurately for the complementary metal oxide semiconductor VLSI circuits. The developed method does not require prior knowledge about the circuit architecture and its connections. The new AWELM-FIS technique developed in this paper estimates the power in the circuit based on the input and output information and various data of gates pertaining to VLSI circuit itself. The developed method is investigated for its validity and effectiveness by comparing it with the existing methods reported in earlier literature studies, and to train the new model, the results presented in the literature of ISCAS 1989 have been employed. Results prove the effectiveness of newly proposed AWELM-FIS approach over all other compared methods from the existing literatures.},
  archive      = {J_SOCO},
  author       = {Kuntavai, T. and Jeevanandham, A.},
  doi          = {10.1007/s00500-019-04636-6},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11755-11768},
  shortjournal = {Soft Comput.},
  title        = {Adaptive wavelet ELM-fuzzy inference system-based soft computing model for power estimation in sustainable CMOS VLSI circuits},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel systematic approach to diagnose brain tumor using
integrated type-II fuzzy logic and ANFIS (adaptive neuro-fuzzy inference
system) model. <em>SOCO</em>, <em>24</em>(15), 11731–11754. (<a
href="https://doi.org/10.1007/s00500-019-04635-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumor is an alarming threat among children and adults worldwide. Early detection and proper diagnosis of the tumor can enhance the chance of accurate survival among the individuals. Segmentation and classification of the detected tumor are based on its grade, i.e., criticality intensifies the survival rate and accurate treatment planning. However, manual segmentation of gliomas is time-consuming and results in an inaccurate diagnosis. Prompted by these facts, a multi-module automated framework has been developed to segment the brain multi-resonance images and classify it into two major classes, namely benign (low-grade) and malignant (high-grade). The present work is divided into four distinct modules: pre-processing, segmentation (clustering), feature extraction and classification. An efficient segmentation technique of the glioma images is proposed, which thereby provides a novel approach for the detection algorithm. Subsequently, prominent features characterizing mass effect, contrast, midline shift and irregularity of the edges of the tumor that are necessary for the physicians to detect tumor, are extracted. Using an ensemble of type-II fuzzy inference system and adaptive neuro-fuzzy inference system, a novel classifying technique has been developed to classify the detected tumor incorporating the extracted features. Finally, the research is tested and validated to show its consistency and accuracy using the images of patients of the BRATS dataset where the ground truth is made available. The detailed implementation of the proposed hybrid model is accomplished to establish its superiority in recognizing the grade of the tumor over other models mentioned in the literature survey.},
  archive      = {J_SOCO},
  author       = {Chatterjee, Subhashis and Das, Ananya},
  doi          = {10.1007/s00500-019-04635-7},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11731-11754},
  shortjournal = {Soft Comput.},
  title        = {A novel systematic approach to diagnose brain tumor using integrated type-II fuzzy logic and ANFIS (adaptive neuro-fuzzy inference system) model},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Proposed soft computing models for moment capacity
prediction of reinforced concrete columns. <em>SOCO</em>,
<em>24</em>(15), 11715–11729. (<a
href="https://doi.org/10.1007/s00500-019-04634-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational intelligence (CI) is a powerful approach to determine the response values of complex systems. Despite their benefits, the way to reach the solution in these approaches is difficult and cannot be expressed in a clear and simple formulation. In recent years, some methods have been proposed to provide simple and efficient mathematical forms in such approaches. In this paper, five of these methods are investigated to estimate the amount of moment capacity in rectangular concrete columns based on the extracted equations of CI. To train, validate and also test the proposed equations, a set of experimental laboratory tests of RC columns were collected from PEER database, and then mathematical frameworks for calculating the target were extracted. The obtained results of the proposed structures are also compared with each other, and it was concluded that all methods with high accuracy were able to estimate the moment capacity, but equation-based neuro-fuzzy system had better results than other presented models. The proposed equations are very powerful tools for determining the final capacity of RC columns as a key element in concrete structures.},
  archive      = {J_SOCO},
  author       = {Naderpour, Hosein and Mirrashid, Masoomeh},
  doi          = {10.1007/s00500-019-04634-8},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11715-11729},
  shortjournal = {Soft Comput.},
  title        = {Proposed soft computing models for moment capacity prediction of reinforced concrete columns},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multivector particle swarm optimization algorithm.
<em>SOCO</em>, <em>24</em>(15), 11695–11713. (<a
href="https://doi.org/10.1007/s00500-019-04631-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an improved meta-heuristic algorithm called multivector particle swarm optimization (MVPSO) for solving single-objective optimization problems. MVPSO improves particle swarm optimization (PSO) algorithm by creating more possible solutions for each particle during the optimization process. It proposes a mathematical model and new position vectors for each particle that enhance the particle movement toward the global best value. This improvement emphasizes the exploration and exploitation of the particles in the search space during the optimization process. To test the performance of MVPSO, the algorithm is then benchmarked on 23 well-known test functions including unimodal, multimodal and fixed multimodal functions at different dimensions. These benchmark functions test the exploration, exploitation, local optima avoidance and convergence features of MVPSO. MVPSO has been compared to the state-of-the-art swarm optimization algorithms as well as PSO algorithm. Experimental results indicate that in terms of robustness, stability and quality of the solution obtained, MVPSO is better than original PSO algorithm, especially as the dimension increases. Further, it shows that a MVPSO based on the multivector mathematical model is competitive with the state-of-the-art swarm optimization algorithms. Moreover, the results of the tested benchmark functions, statistical analysis and performance metrics prove that the proposed algorithm is able to explore more solutions and regions in the search space, avoiding local optima points.},
  archive      = {J_SOCO},
  author       = {Fakhouri, Hussam N. and Hudaib, Amjad and Sleit, Azzam},
  doi          = {10.1007/s00500-019-04631-x},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11695-11713},
  shortjournal = {Soft Comput.},
  title        = {Multivector particle swarm optimization algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dependency-aware software release planning through mining
user preferences. <em>SOCO</em>, <em>24</em>(15), 11673–11693. (<a
href="https://doi.org/10.1007/s00500-019-04630-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software vendors aim to find, for a release of the software, an optimal subset of features that gives the highest value while respecting the resource limitations. The value of a feature subset, however, is determined by the values of the individual features within that subset—which are specified by the preferences of users. But user preferences for some features may change in the presence or absence of others. As such, the values of certain software features may be influenced, either positively or negatively, by other features. Such influences are widely recognized and referred to in the literature as value-related dependencies among software features. Value-related dependencies impact the overall value of a software product and, therefore, need to be considered in software release planning. To achieve this, we have proposed identifying value-related dependencies by mining user preferences for software features. We integrate these dependencies into an integer programming model, that finds an optimal subset of the features for a release of a software product. We have demonstrated the practicality of our proposed approach by studying a real-world software project and simulations.},
  archive      = {J_SOCO},
  author       = {Mougouei, Davoud and Powers, David M. W.},
  doi          = {10.1007/s00500-019-04630-y},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11673-11693},
  shortjournal = {Soft Comput.},
  title        = {Dependency-aware software release planning through mining user preferences},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Feature selection based on hybridization of genetic
algorithm and competitive swarm optimizer. <em>SOCO</em>,
<em>24</em>(15), 11663–11672. (<a
href="https://doi.org/10.1007/s00500-019-04628-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is one of the hottest machine learning topics in recent years. The main purposes of it are to simplify the original model, improve the readability of the model, and prevent over-fitting by searching for a suitable subset of features. There are many methods for this problem, including evolutionary algorithms and particle swarm optimization. Among them, the competitive swarm optimizer is a new optimization algorithm proposed in recent years, which is based on particle swarm optimization algorithm, and has achieved good results in high-dimensional feature selection problems, but it also has the problems of high computation time cost and easily being premature. Aiming at these problems, this paper proposes to add the crossover operator and mutation operator in the genetic algorithm to the competitive swarm optimization, so as to improve the generation speed of new individuals in the algorithm and prevent premature population. After testing on UC Irvine Machine Learning Repository, the new algorithm not only improves the computational efficiency, but also avoids the problem that the competitive swarm optimization algorithm is easy to fall into the local optimum, which greatly improves the calculation effect.},
  archive      = {J_SOCO},
  author       = {Ding, Ye and Zhou, Kui and Bi, Weihong},
  doi          = {10.1007/s00500-019-04628-6},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11663-11672},
  shortjournal = {Soft Comput.},
  title        = {Feature selection based on hybridization of genetic algorithm and competitive swarm optimizer},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel entropy and divergence measures with multi-criteria
service quality assessment using interval-valued intuitionistic fuzzy
TODIM method. <em>SOCO</em>, <em>24</em>(15), 11641–11661. (<a
href="https://doi.org/10.1007/s00500-019-04627-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interval-valued intuitionistic fuzzy sets (IVIFSs) are proven to be the fastest growing research area and are more flexible way to handle the uncertainty. Information measures play vital role in the study of uncertain information; therefore, number of new interval-valued intuitionistic fuzzy divergence and entropy measures have been proposed in the literature and applied for different purposes. Recently, multi-criteria decision-making (MCDM) methods with IVIFSs have broadly studied by researchers and practitioners in various fields. In this paper, firstly surveys of IVIF-divergence and entropy measures are conducted and then demonstrated some counter-intuitive cases. Then, novel divergence and entropy measures are originated for IVIFSs to avoid the shortcomings of previous measures. Later on, systematic reviews of Portuguese for Interactive Multi-criteria Decision Making (TODIM) method are presented with recent fuzzy developments. Based on classical TODIM method, a new approach for MCDM is introduced under IVIF environment which considers the bounded rationality of decision makers. In the present method, the proposed entropy measure is utilized to compute the weight vector of the criteria, and the proposed divergence measure is applied in the calculation of dominance degrees. To illustrate the effectiveness of the present approach, a decision-making problem of vehicle insurance companies is presented where the evaluation values of the alternatives are given in terms of IVIF numbers. Comparison with some existing methods shows the applicability and consistency of the present method.},
  archive      = {J_SOCO},
  author       = {Mishra, Arunodaya Raj and Rani, Pratibha and Pardasani, Kamal Raj and Mardani, Abbas and Stević, Željko and Pamučar, Dragan},
  doi          = {10.1007/s00500-019-04627-7},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11641-11661},
  shortjournal = {Soft Comput.},
  title        = {A novel entropy and divergence measures with multi-criteria service quality assessment using interval-valued intuitionistic fuzzy TODIM method},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Solving an integrated cell formation and group layout
problem using a simulated annealing enhanced by linear programming.
<em>SOCO</em>, <em>24</em>(15), 11621–11639. (<a
href="https://doi.org/10.1007/s00500-019-04626-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new approach to integrating the cell formation, group layout of rectangle-shaped machines and routing selection problems. The problem is formulated as a mixed-integer program with the objective of minimizing the handling costs. Due to the computational complexity of the problem, a hybrid simulated annealing (SA) is employed to solve the problem. The sequence-pair representation, originally proposed for block placement, is utilized for solution encoding. Two placement algorithms are developed to evaluate the objective function value of an encoded solution in the SA. The first placement algorithm is based on solving a linear program embedded with a constraint reduction algorithm. The second one is a fast heuristic that can evaluate an encoded solution in much less computational time. Benchmarks selected from the literature are solved to verify the performance of the SA and to accomplish comparisons. The computational results demonstrated the high performance of both designed hybrid SA algorithms. The comparison against the literature also indicated that the flexibility incorporated into the model results in better layouts, even if the model is solved only by a solver such as CPLEX.},
  archive      = {J_SOCO},
  author       = {Forghani, Kamran and Fatemi Ghomi, S. M. T. and Kia, Reza},
  doi          = {10.1007/s00500-019-04626-8},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11621-11639},
  shortjournal = {Soft Comput.},
  title        = {Solving an integrated cell formation and group layout problem using a simulated annealing enhanced by linear programming},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new initialization and performance measure for the rough
k-means clustering. <em>SOCO</em>, <em>24</em>(15), 11605–11619. (<a
href="https://doi.org/10.1007/s00500-019-04625-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new initialization algorithm is proposed in this study to address the issue of random initialization in the rough k-means clustering algorithm refined by Peters. A new means to choose appropriate zeta values in Peters algorithm is proposed. Also, a new performance measure S/O [within-variance (S)/total-variance (O)] index has been introduced for the rough clustering algorithm. The performance criteria such as root-mean-square standard deviation, S/O index, and running time complexity are used to validate the performance of the proposed and random initialization with that of Peters. In addition, other popular initialization algorithms like k-means++, Peters Π, Bradley, and Ioannis are also herein compared. It is found that our proposed initialization algorithm has performed better than the existing initialization algorithms with Peters refined rough k-means clustering algorithm on different datasets with varying zeta values.},
  archive      = {J_SOCO},
  author       = {Murugesan, Vijaya Prabhagar and Murugesan, Punniyamoorthy},
  doi          = {10.1007/s00500-019-04625-9},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11605-11619},
  shortjournal = {Soft Comput.},
  title        = {A new initialization and performance measure for the rough k-means clustering},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Engaging soft computing in material and modeling uncertainty
quantification of dam engineering problems. <em>SOCO</em>,
<em>24</em>(15), 11583–11604. (<a
href="https://doi.org/10.1007/s00500-019-04623-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to complex nature of nearly all infrastructures (and more specifically concrete dams), the uncertainty quantification is an inseparable part of risk assessment. Uncertainties might be propagated in different aspects depending on their relative importance such as epistemic and aleatory, or spatial and temporal. The objective of this paper is to focus on the material and modeling uncertainties, and to couple them with soft computing techniques aiming to reduce the computational burden of the conventional Monte Carlo-based finite element simulations. Several scenarios are considered in which the concrete and foundation material properties, the water level, and the dam geometry are assumed as random variables. Five soft computing techniques (i.e., random forest, boosted regression trees, multi-adaptive regression splines, artificial neural networks, and support vector machines) are employed to predict various quantities of interest based on different training sizes. It is argued that the artificial neural network is the most accurate algorithm in majority of cases, with enough accuracy as to be useful in reliability analysis as a complement to numerical models. The results with 200 samples in the training set are enough for reaching useful accuracy in most cases. For the simple prediction tasks, the results were predicted with less than 1\% error. It is observed that increasing the number of input parameters increases the prediction error. The partial dependence plots provided most sensitive variables in dam design, which were consistent with the physics of the problem. Finally, several practical recommendations are provided for future applications.},
  archive      = {J_SOCO},
  author       = {Hariri-Ardebili, Mohammad Amin and Salazar, Fernando},
  doi          = {10.1007/s00500-019-04623-x},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11583-11604},
  shortjournal = {Soft Comput.},
  title        = {Engaging soft computing in material and modeling uncertainty quantification of dam engineering problems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Differential evolutionary algorithm with an evolutionary
state estimation method and a two-level selection mechanism.
<em>SOCO</em>, <em>24</em>(15), 11561–11581. (<a
href="https://doi.org/10.1007/s00500-019-04621-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The efficiency and effectiveness of differential evolution (DE) greatly depend on the mutation operator due to the principle that different mutation operators are beneficial to different evolutionary states. However, it is not easy to automatically and effectively identify the evolutionary state. In this paper, we propose an evolutionary state estimation method (ESE) based on the correlation coefficient between the population’s distributions in objective space (Δf) and solution space (Δx). To be specific, Δf consists of the distances between each individual and the current best individual based on their objective function values, while Δx includes the Euclidean distances between each individual and the current best individual based on their positions in the search space. Based on the correlation coefficient between Δx and Δf, the entire evolutionary process is classified into three kinds of state. At each generation, the evolutionary state is firstly determined according to the correlation coefficient, subsequently adaptively choosing a mutation operator from the corresponding candidate operator pool for each individual to generate its mutation vector. Moreover, a two-level selection mechanism (TLSM) is presented to get away from stagnation. The algorithm combines DE with ESE and TLSM (DEET for short) is proposed. Experimental results on twenty frequently used benchmark functions and the CEC2017 test problems show that DEET exhibits very competitive performance compared with other state-of-the-art DE variants.},
  archive      = {J_SOCO},
  author       = {Li, Yang and Li, Genghui},
  doi          = {10.1007/s00500-019-04621-z},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11561-11581},
  shortjournal = {Soft Comput.},
  title        = {Differential evolutionary algorithm with an evolutionary state estimation method and a two-level selection mechanism},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-objective cluster analysis using a gradient evolution
algorithm. <em>SOCO</em>, <em>24</em>(15), 11545–11559. (<a
href="https://doi.org/10.1007/s00500-019-04620-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data analysis becomes more important since rapid technology developments. In data analysis, data clustering is one of the very useful approaches. It can reveal important information hiding inside the dataset by organizing the instances based on their similarity. The objectives of data clustering are maximizing dissimilarity between clusters and minimizing dissimilarity within clusters. In order to construct a good clustering results, many clustering algorithms have been proposed, including the metaheuristic-based clustering algorithms. Recently, a new metaheuristic algorithm named gradient evolution has been proposed. This algorithm shows a good performance on solving the optimization problems. Therefore, this paper employs this GE algorithm for solving the clustering problem. In order to obtain a better clustering result, this paper considers multi-objective clustering instead of single-objective clustering. In this paper, the original GE algorithm is improved so then it is suitable for the multi-objective problem. The proposed modification includes the procedure for vector updating and jumping which involves Pareto rank assignment. In addition, it also employs K-means algorithm to provide the final clustering result. The proposed algorithm is verified using some benchmark datasets. It is also compared with some other multi-objective metaheuristic-based clustering algorithms. The experimental results show that the proposed algorithm can obtain better results than other metaheuristic-based algorithms.},
  archive      = {J_SOCO},
  author       = {Kuo, R. J. and Zulvia, Ferani E.},
  doi          = {10.1007/s00500-019-04620-0},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11545-11559},
  shortjournal = {Soft Comput.},
  title        = {Multi-objective cluster analysis using a gradient evolution algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fault tolerant control for nonlinear systems using sliding
mode and adaptive neural network estimator. <em>SOCO</em>,
<em>24</em>(15), 11535–11544. (<a
href="https://doi.org/10.1007/s00500-019-04618-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new fault tolerant control scheme for a class of nonlinear systems including robotic systems and aeronautical systems. In this method, a sliding mode control is applied to maintain system stability under the post-fault dynamics. A neural network is used as on-line estimator to reconstruct the change rate of the fault and compensate for the impact of the fault on the system performance. The control law and the neural network learning algorithms are derived using the Lyapunov method, so that the neural estimator is guaranteed to converge to the fault change rate, while the entire closed-loop system stability and tracking control is guaranteed. Compared with the existing methods, the proposed method achieved fault tolerant control for time-varying fault, rather than just constant fault. This greatly expands the industrial applications of the developed method to enhance system reliability. The main contribution and novelty of the developed method is that the system stability is guaranteed and the fault estimation is also guaranteed for convergence when the system subject to a time-varying fault. A simulation example is used to demonstrate the design procedure and the effectiveness of the method. The simulation results demonstrated that the post-fault is stable and the performance is maintained.},
  archive      = {J_SOCO},
  author       = {Qi, Haiying and Shi, Yiran and Li, Shoutao and Tian, Yantao and Yu, Ding-Li and Gomm, J. B.},
  doi          = {10.1007/s00500-019-04618-8},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11535-11544},
  shortjournal = {Soft Comput.},
  title        = {Fault tolerant control for nonlinear systems using sliding mode and adaptive neural network estimator},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Approaches to multiple attribute group decision making based
on triangular cubic linguistic uncertain fuzzy aggregation operators.
<em>SOCO</em>, <em>24</em>(15), 11511–11533. (<a
href="https://doi.org/10.1007/s00500-019-04614-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, triangular cubic linguistic uncertain fuzzy averaging (geometric) operator, triangular cubic linguistic uncertain fuzzy weighted averaging operator, triangular cubic linguistic uncertain fuzzy weighted geometric operator, triangular cubic linguistic uncertain fuzzy ordered weighted averaging operator, triangular cubic linguistic uncertain fuzzy ordered weighted geometric operator, triangular cubic linguistic uncertain fuzzy hybrid averaging operator, and triangular cubic linguistic uncertain fuzzy hybrid geometric operator for triangular cubic linguistic uncertain fuzzy numbers have been introduced. Furthermore, by using these aggregation operators an approach to multiple attribute group decision making with triangular cubic linguistic uncertain fuzzy information has been developed. Finally, a numerical example is constructed to validate the established approach.},
  archive      = {J_SOCO},
  author       = {Amin, Fazli and Fahmi, Aliya and Aslam, Muhammad},
  doi          = {10.1007/s00500-019-04614-y},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11511-11533},
  shortjournal = {Soft Comput.},
  title        = {Approaches to multiple attribute group decision making based on triangular cubic linguistic uncertain fuzzy aggregation operators},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Design of comprehensive evaluation index system for P2P
credit risk of “three rural” borrowers. <em>SOCO</em>, <em>24</em>(15),
11493–11509. (<a
href="https://doi.org/10.1007/s00500-019-04613-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the emerging peer-to-peer (P2P) lending industry, risks such as credit risk and default risk will bring huge losses to online lending platforms and investors. Therefore, it is necessary to design a reasonable evaluation index system of credit risk to scientifically evaluate the risk level of borrowers. This paper studies the design of comprehensive evaluation index system for P2P credit risk of “three rural” (i.e., agriculture, rural areas and farmers) borrowers. Concretely, we construct the feature set for P2P credit risk of “three rural” borrowers. Based on the traditional index system, we add the static indexes specific to the agriculture-related borrowers and the dynamic indexes reflect the Internet as the preliminary indexes of the feature set and select the borrowers data of the “Pterosaur loan” platform as the research sample. Then, 35 borrower credit features are extracted as a feature set of credit risk. Then, we present a two-stage feature selection method based on filter and wrapper to select the main features from 35 initial borrower credit features. In the stage of filter, three filter methods are used to calculate the importance of the unbalanced features. In the stage of wrapper, a Lasso-logistic method is proposed to filter the feature subset through heuristic search algorithm. In the end, 21 main independent features are selected according to the classification accuracy, which constitute the evaluation index system of credit risk of “three rural” borrowers.},
  archive      = {J_SOCO},
  author       = {Rao, Congjun and Lin, Hui and Liu, Ming},
  doi          = {10.1007/s00500-019-04613-z},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11493-11509},
  shortjournal = {Soft Comput.},
  title        = {Design of comprehensive evaluation index system for P2P credit risk of “three rural” borrowers},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Enhancing human iris recognition performance in
unconstrained environment using ensemble of convolutional and residual
deep neural network models. <em>SOCO</em>, <em>24</em>(15), 11477–11491.
(<a href="https://doi.org/10.1007/s00500-019-04610-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the prominent advancements in iris recognition, unconstrained image acquisition through heterogeneous sensors has been a major obstacle in applying it for large-scale applications. In recent years, deep convolutional networks have achieved remarkable performance in the field of computer vision and have been employed in iris applications. In this study, three distinct models based on the ensemble of convolutional and residual blocks are proposed to enrich heterogeneous (cross-sensor) iris recognition. In order to analyze their quantitative performances, extensive experiments are carried out on two publicly available iris databases, ND-iris-0405 dataset and ND-CrossSensor-Iris-2013 dataset. Further, the final model has been scrutinized based on the least error rate and then fused using score-level fusion with two preeminent feature extraction methods, i.e., scale-invariant feature transform and binarized statistical information features. The resultant model is examined for cross-sensor iris recognition and reported the top two error rates as 1.01\% and 1.12\%. It infers that the proposed approach constitutes vital discerning iris features and can recognize that the micro-patterns exist inside the iris region. Furthermore, a comparative study is carried out with the state of the art, where the proposed approach obtains significantly improved performance.},
  archive      = {J_SOCO},
  author       = {Choudhary, Meenakshi and Tiwari, Vivek and Venkanna, U.},
  doi          = {10.1007/s00500-019-04610-2},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11477-11491},
  shortjournal = {Soft Comput.},
  title        = {Enhancing human iris recognition performance in unconstrained environment using ensemble of convolutional and residual deep neural network models},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A comparative study of exact methods for the simple assembly
line balancing problem. <em>SOCO</em>, <em>24</em>(15), 11459–11475. (<a
href="https://doi.org/10.1007/s00500-019-04609-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exact methods have shown advanced and promising performance in solving the simple assembly line balancing problem, known as NP-hard. This research investigates the impact of various structural parameters on the performance of exact methods, including branching methods, search direction, method to achieve upper bounds, utilized lower bounds, utilized dominance rules and search strategy. In accordance with the structural parameter evaluation, utilized dominance rules and search strategy have shown the most important effect on the exact methods’ performance. This research also improves and re-implements three well-known exact methods [i.e., SALOME, bounded dynamic programming (BDP) heuristic and branch, bound and remember (BBR) algorithm] using effective parameters. Computational study demonstrates that the utilization of high-performance structural parameters enhances the performance of exact methods by a significant margin. The re-implemented BBR method with proper parameters shows clear superiority over all the published exact methods and might be regarded as the state-of-the-art exact methodology.},
  archive      = {J_SOCO},
  author       = {Li, Zixiang and Kucukkoc, Ibrahim and Tang, Qiuhua},
  doi          = {10.1007/s00500-019-04609-9},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11459-11475},
  shortjournal = {Soft Comput.},
  title        = {A comparative study of exact methods for the simple assembly line balancing problem},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). New SVM kernel soft computing models for wind speed
prediction in renewable energy applications. <em>SOCO</em>,
<em>24</em>(15), 11441–11458. (<a
href="https://doi.org/10.1007/s00500-019-04608-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a hybrid multi-step wind speed prediction model based on combination of singular spectrum analysis (SSA), variational mode decomposition (VMD) and support vector machine (SVM) and was applied for sustainable renewable energy application. In the proposed SSA–VMD–SVM model, the SSA was applied to eliminate the noise and to approximate the signal with trend information; VMD was applied to decompose and to extract the features of input time series wind speed data into a number of sub-layers; and the SVM model with various kernel functions was adopted to predict the wind speed from each of the sub-layers, and the parameters of SVM were fine-tuned by differential evolutionary algorithm. To investigate the effectiveness of the proposed model, various prediction models are considered for comparative study, and it is demonstrated that the proposed model outperforms with better prediction accuracy.},
  archive      = {J_SOCO},
  author       = {Natarajan, Yogambal Jayalakshmi and Subramaniam Nachimuthu, Deepa},
  doi          = {10.1007/s00500-019-04608-w},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11441-11458},
  shortjournal = {Soft Comput.},
  title        = {New SVM kernel soft computing models for wind speed prediction in renewable energy applications},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Feature selection by using privacy-preserving of
recommendation systems based on collaborative filtering and mutual trust
in social networks. <em>SOCO</em>, <em>24</em>(15), 11425–11440. (<a
href="https://doi.org/10.1007/s00500-019-04605-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the increasing growth of the Web and consequently the growth of e-commerce, the amount of data which users face are increasing day by day. Therefore, one of the key issues in today’s world is the extraction of knowledge from a large database. The recommendation systems are able to extract useful information from large databases. The information extracted by the recommendation systems may breach the privacy-preserving of individuals and increase the error rate. Concerns will grow along with the increasing privacy breaches, which are done by recommendation systems. In recent years, researchers have provided a variety of techniques for privacy-preserving and reduced error rates in recommendation systems. But most of these methods have not offered good solutions for privacy-preserving issues and reducing error rates. The aim of the proposed method is to provide a solution for users’ security concerns in common filtering systems with reduced error rates and more privacy preservation. In this article, we propose a privacy-preserving method for recommendation systems called PRS, which first uses an anonymous method to convert secondary data without user identification information. The existing trust data are measured in terms of resemblance and trust-weighted criterion and then converted from perturbation-based chaos to confidential data. Finally, these two algorithms have been used for clustering the data: fuzzy c-ordered means and particle swarm optimization. The results of experiments have been compared with state-of-the-art methods, which show the superiority of the proposed method in terms of classification error rates and privacy-preserving.},
  archive      = {J_SOCO},
  author       = {Kashani, Somayeh Moghaddam Zadeh and Hamidzadeh, Javad},
  doi          = {10.1007/s00500-019-04605-z},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11425-11440},
  shortjournal = {Soft Comput.},
  title        = {Feature selection by using privacy-preserving of recommendation systems based on collaborative filtering and mutual trust in social networks},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel topic model for documents by incorporating semantic
relations between words. <em>SOCO</em>, <em>24</em>(15), 11407–11423.
(<a href="https://doi.org/10.1007/s00500-019-04604-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Topic models have been widely used to infer latent topics in text documents. However, the unsupervised topic models often result in incoherent topics, which always confused users in applications. Incorporating prior domain knowledge into topic models is an effective strategy to extract coherent and meaningful topics. In this paper, we go one step further to explore how different forms of prior semantic relations of words can be encoded into models to improve the performance of topic modeling process. We develop a novel topic model—called Mixed Word Correlation Knowledge-based Latent Dirichlet Allocation—to infer latent topics from text corpus. Specifically, the proposed model mines two forms of lexical semantic knowledge based on recent progress in word embedding, which can represent semantic information of words in a continuous vector space. To incorporate generated prior knowledge, a Mixed Markov Random Field is constructed over the latent topic layer to regularize the topic assignment of each word during the topic sampling process. Experimental results on two public benchmark datasets illustrate the superior performance of the proposed approach over several state-of-the-art baseline models.},
  archive      = {J_SOCO},
  author       = {Chen, Jihong and Zhang, Kai and Zhou, Yuan and Chen, Zheng and Liu, Yufei and Tang, Zhuo and Yin, Li},
  doi          = {10.1007/s00500-019-04604-0},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11407-11423},
  shortjournal = {Soft Comput.},
  title        = {A novel topic model for documents by incorporating semantic relations between words},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An improvement growing neural gas method for online anomaly
detection of aerospace payloads. <em>SOCO</em>, <em>24</em>(15),
11393–11405. (<a
href="https://doi.org/10.1007/s00500-019-04603-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The unfluctuating running of on-orbit spacecraft equipment has a decisive impact on the smooth implementation of space exploration mission. However, due to the adverse work conditions and complex running states, it is really a challenge for the online monitoring of aerospace equipment. In this paper, an improved growing neural gas method based on incremental learning is proposed, which is dedicated to solving the problem of online anomaly detection. The learning rate of the proposed method is adaptively adjusted according to the process of model training, ensuring the weights update quickly at the beginning of model construction and converge steady at the end of model training. The optimized insertion mechanisms of neurons ensure that the necessary new neurons are inserted at the right time and location dynamically, while the innovative deletion mechanisms of neurons ensure that the worthless neurons be deleted timely and at the same time guarantee the representation ability of model. The comparison results with the conventional methods on public datasets show that the proposed method achieves the better performance obviously, both in the aspects of detection accuracy and computational efficiency, respectively. At last, as a case study, the proposed method is used for online anomaly detection of a real aerospace device, i.e., a gamma ray detector, and the final F1 score of anomaly detection is as high as 98.78\%. The results show that the proposed method can be applied to online detection of aerospace equipment health conditions effectively.},
  archive      = {J_SOCO},
  author       = {Song, Lei and Zheng, Taisheng and Wang, Jianxing and Guo, Lili},
  doi          = {10.1007/s00500-019-04603-1},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11393-11405},
  shortjournal = {Soft Comput.},
  title        = {An improvement growing neural gas method for online anomaly detection of aerospace payloads},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Data augmentation using MG-GAN for improved cancer
classification on gene expression data. <em>SOCO</em>, <em>24</em>(15),
11381–11391. (<a
href="https://doi.org/10.1007/s00500-019-04602-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Molecular biology studies on cancer, using gene expression datasets, have revealed that the datasets have a very small number of samples. Obtaining medical data is difficult and expensive due to privacy constraints. Accuracy of classifiers depends greatly on the quality and quantity of input data. The problem of small sample size or small data size has been addressed by augmentation. Owing to the sensitivity of synthetic data samples for the cancer data classification for gene expression data, this paper is motivated to investigate data augmentation using GAN. GAN is based on the principle of two blocks (generator and discriminator) working in a collaborative yet adversarial way. This paper proposes modified generator GAN (MG-GAN) where the generator is fed with original data and multivariate noise to generate data with Gaussian distribution. As the generated data lie within latent space, we reach saddle point faster. GAN has been widely used in data augmentation for image datasets. As per our understanding, this is the first attempt of using GAN for augmentation on gene expression dataset. The performance merit of proposed MG-GAN was compared with KNN and Basic GAN. As compared to KNN and GAN, MG-GAN improves classification accuracy by 18.8\% and 11.9\%, respectively. The loss value of the error function for MG-GAN is drastically reduced, from 0.6978 to 0.0082, ensuring sensitivity of the generated data. Improved classification accuracy and reduction in the loss value make our improved MG-GAN method better suited for critical applications with sensitive data.},
  archive      = {J_SOCO},
  author       = {Chaudhari, Poonam and Agrawal, Himanshu and Kotecha, Ketan},
  doi          = {10.1007/s00500-019-04602-2},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11381-11391},
  shortjournal = {Soft Comput.},
  title        = {Data augmentation using MG-GAN for improved cancer classification on gene expression data},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new QPSO based hybrid algorithm for constrained
optimization problems via tournamenting process. <em>SOCO</em>,
<em>24</em>(15), 11365–11379. (<a
href="https://doi.org/10.1007/s00500-019-04601-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of this paper is to propose a new hybrid algorithm based on advanced quantum behaved particle swarm optimization (QPSO) technique and binary tournamenting for solving constrained optimization problems. In binary tournamenting, six different situations/options are considered and accordingly six variants of hybrid algorithms are proposed. Then to test the efficiency and performance of these algorithms and also to select the best algorithm among these, six benchmark optimization problems are selected and solved. Then the computational results are compared graphically as well as numerically. Finally, the best found algorithm is applied to solve three engineering design problems and the computational results are compared with the existing algorithms available in the literature.},
  archive      = {J_SOCO},
  author       = {Kumar, Nirmal and Mahato, Sanat Kumar and Bhunia, Asoke Kumar},
  doi          = {10.1007/s00500-019-04601-3},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11365-11379},
  shortjournal = {Soft Comput.},
  title        = {A new QPSO based hybrid algorithm for constrained optimization problems via tournamenting process},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Combining technique for order preference by similarity to
ideal solution with relative preference relation for interval-valued
fuzzy multi-criteria decision-making. <em>SOCO</em>, <em>24</em>(15),
11347–11364. (<a
href="https://doi.org/10.1007/s00500-019-04599-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past, technique for order preference by similarity to ideal solution (TOPSIS) was one of multi-criteria decision-making (MCDM) methods and often extended into a fuzzy multi-criteria decision-making (FMCDM) one for encompassing uncertainty and vagueness messages. Obviously, TOPSIS extended under fuzzy environment is useful to solve FMCDM problems, but the extension only constructed on general fuzzy numbers (i.e., triangular or trapezoidal fuzzy ones), not interval-valued fuzzy ones. In real world, the recent decision-making process is getting complicated and thus more information now must be grasped than ever. For presenting varied and added data, general fuzzy numbers may not be adequate, whereas interval-valued fuzzy numbers are suitable. Based on above, TOPSIS should be extended under interval-valued fuzzy environment. In this paper, we associate TOPSIS with a relative preference relation under interval-valued fuzzy environment into interval-valued FMCDM for dealing with complicated decision-making problems to obtain more information. The proposed relative preference relation as similar as Wang’s relative preference relation is also improved from Lee’s fuzzy preference relation on general fuzzy numbers. An important difference is the proposed relative preference relation used on interval-valued fuzzy numbers, but Wang’s relative preference relation is utilized on triangular fuzzy numbers. Through the combination of TOPSIS and relative preference relation under interval-valued fuzzy environment, interval-valued FMCDM can be feasibly and rationally finished.},
  archive      = {J_SOCO},
  author       = {Wang, Yu-Jie},
  doi          = {10.1007/s00500-019-04599-8},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11347-11364},
  shortjournal = {Soft Comput.},
  title        = {Combining technique for order preference by similarity to ideal solution with relative preference relation for interval-valued fuzzy multi-criteria decision-making},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new algorithmic decision for categorical syllogisms via
carroll’s diagrams. <em>SOCO</em>, <em>24</em>(15), 11337–11346. (<a
href="https://doi.org/10.1007/s00500-019-04598-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a new effective algorithm for the categorical syllogisms by using a calculus system Syllogistic Logic with Carroll Diagrams, which determines a formal approach to logical reasoning with diagrams, for representations of the fundamental Aristotelian categorical syllogisms. We show that this logical reasoning is closed under the syllogistic criterion of inference. Therefore, the calculus system is implemented to let the formalism which comprises synchronically bilateral and trilateral diagrammatical appearance and naive algorithmic nature. And also, there is no need specific knowledge or exclusive ability to understand this decision procedure as well as to use it in an algorithmic system. Consequently, the empirical contributions of this paper are to design a polynomial-time algorithm at the first time in the literature to conduce to researchers getting into the act in different areas of science used categorical syllogisms such as artificial intelligence, engineering, computer science and etc.},
  archive      = {J_SOCO},
  author       = {Kircali Gursoy, Necla and Senturk, Ibrahim and Oner, Tahsin and Gursoy, Arif},
  doi          = {10.1007/s00500-019-04598-9},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11337-11346},
  shortjournal = {Soft Comput.},
  title        = {A new algorithmic decision for categorical syllogisms via carroll’s diagrams},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A hybrid technique for simultaneous network reconfiguration
and optimal placement of distributed generation resources.
<em>SOCO</em>, <em>24</em>(15), 11315–11336. (<a
href="https://doi.org/10.1007/s00500-019-04597-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new meta-heuristic method, comprehensive teaching learning harmony search optimization algorithm (CTLHSO), is developed in this paper for the simultaneous reconfiguration and optimal allocation of distributed generation resources in radial distribution systems. The proposed method is a hybridization of the teaching–learning-based optimization (TLBO) and the harmony search (HS) algorithms. Primarily, eleven mathematical benchmark functions are used to test the performance of the CTLHSO algorithm. The results are then compared with that of global best artificial bee colony (G-ABC), particle swarm artificial bee colony (PS-ABC), TLBO and improved TLBO (I-TLBO) with identical parameters and initial conditions. The results show that the CTLHSO performance is better than the G-ABC, PS-ABC, TLBO and I-TLBO. Subsequently, CTLHSO is implemented on the IEEE 33-bus and 69-bus radial distribution systems for network reconfiguration and optimal placement of distributed generation resources to minimize the power losses and improve the voltage profiles. Five case studies at three different load levels are carried out. The results obtained are found to be better than those obtained with HS algorithm, genetic algorithm, refined genetic algorithm and fireworks algorithm.},
  archive      = {J_SOCO},
  author       = {Quadri, Imran Ahmad and Bhowmick, S.},
  doi          = {10.1007/s00500-019-04597-w},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11315-11336},
  shortjournal = {Soft Comput.},
  title        = {A hybrid technique for simultaneous network reconfiguration and optimal placement of distributed generation resources},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An n-state switching PSO algorithm for scalable
optimization. <em>SOCO</em>, <em>24</em>(15), 11297–11314. (<a
href="https://doi.org/10.1007/s00500-020-05069-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Particle swarm optimization (PSO) is an optimization method that is most widely used to solve a number of problems in various fields such as engineering, economics and computer systems. However, due to its scalability and unsatisfying performance particularly for large-scale optimization problems; numerous PSO variants have been suggested so far, in the literature. This paper also proposes a new variant of the canonical PSO algorithm (‘N-state switching PSO—NS-SPSO’) that uses the evolutionary factor information to update particles velocities and, therefore, further enhance its performance. The evolutionary factor is derived by using the population distribution and the mean distance of each particle from the global best. The population distribution and the mean distance are determined through Euclidean distance. Moreover, algorithmic parameters such as inertia weight, and acceleration coefficients are assigned appropriate values at N stages (derived from exploration, exploitation, convergence and jumping out states) that improves the search efficiency and convergence speed. The proposed algorithm is applied to 12 widely used mathematical benchmark functions that demonstrate its best performance in terms of minimum evaluation error, fast convergence and low computational time. Besides these, seven high-dimensional functions and few other algorithms for large-scale optimization were considered to test the scalability of NS-SPSO algorithm. Our comparative results show that NS-SPSO performs well on low-dimensional problems and is promising for solving large-scale optimization problems. Furthermore, the proposed NS-PSO algorithm almost outperforms its closest rivals for various benchmarks.},
  archive      = {J_SOCO},
  author       = {Rahman, Izaz Ur and Zakarya, Muhammad and Raza, Mushtaq and Khan, Rahim},
  doi          = {10.1007/s00500-020-05069-2},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11297-11314},
  shortjournal = {Soft Comput.},
  title        = {An n-state switching PSO algorithm for scalable optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multilayer analysis of population diversity in grammatical
evolution for symbolic regression. <em>SOCO</em>, <em>24</em>(15),
11283–11295. (<a
href="https://doi.org/10.1007/s00500-020-05062-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we analyze the population diversity of grammatical evolution (GE) on multiple levels of genetic information: chromosome diversity, expression diversity, and output diversity. Thereby, we use a tree-similarity metric from tree-based GP literature to determine similarity of expression trees generated in GE. The similarity of outputs is determined via their correlation. We track the pairwise similarities for all individuals within a generation on all three levels and track the distribution of similarity values over generations. We demonstrate the analysis method using four symbolic regression problem instances and find that the visualization highlights some issues that can occur when using GE such as: large groups of individuals with highly similar outputs, a high fraction of trees with constant outputs, or short and highly similar trees in the early stages of the GE run. Especially in the early phases of GE, we see that a large subset of the population represents equivalent expressions. In early stages, rather short expressions are produced leaving large parts of the chromosome unexpressed. More complex expressions can be derived only after GE has successfully evolved well-working beginnings of chromosomes.},
  archive      = {J_SOCO},
  author       = {Kronberger, Gabriel and Colmenar, J. Manuel and Winkler, Stephan M. and Hidalgo, J. Ignacio},
  doi          = {10.1007/s00500-020-05062-9},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11283-11295},
  shortjournal = {Soft Comput.},
  title        = {Multilayer analysis of population diversity in grammatical evolution for symbolic regression},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Grammatically uniform population initialization for
grammar-guided genetic programming. <em>SOCO</em>, <em>24</em>(15),
11265–11282. (<a
href="https://doi.org/10.1007/s00500-020-05061-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The initial population distribution is an essential issue in evolutionary computation performance. Population initialization methods for grammar-guided genetic programming have some difficulties generating a representative sample of the search space, which negatively affects the overall evolutionary process. This paper presents a grammatically uniform population initialization method to address this issue by improving the initial population uniformity: the equiprobability of obtaining any individual of the search space defined by the context-free grammar. The proposed initialization method assigns and updates probabilities dynamically to the production rules of the grammar to pursue uniformity and includes a code bloat control mechanism. We have conducted empirical experiments to compare the proposed algorithm with a standard initialization approach very often used in grammar-guided genetic programming. The results report that the proposed initialization method approximates very well a uniform distribution of the individuals in the search space. Moreover, the overall evolutionary process that takes place after the population initialization performs better in terms of convergence speed and quality of the final solutions achieved when the proposed method generates the initial population than when the usual approach does. The results also show that these performance differences are more significant when the experiments involve large search spaces.},
  archive      = {J_SOCO},
  author       = {Ramos Criado, Pablo and Barrios Rolanía, D. and Manrique, Daniel and Serrano, Emilio},
  doi          = {10.1007/s00500-020-05061-w},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11265-11282},
  shortjournal = {Soft Comput.},
  title        = {Grammatically uniform population initialization for grammar-guided genetic programming},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The explicit solution of fuzzy singular differential
equations using fuzzy drazin inverse matrix. <em>SOCO</em>,
<em>24</em>(15), 11251–11264. (<a
href="https://doi.org/10.1007/s00500-020-05055-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to provide a fuzzy solution for fuzzy singular differential equations (FSDEs) in which the coefficient matrices and/or initial conditions are considered as fuzzy matrices and/or numbers. In addition, the fuzzy derivative is in the sense of the granular derivative. To achieve the aim, some new concepts such as the rank and index of fuzzy matrices, and granular inverse of a nonsingular fuzzy matrix are presented. Moreover, a fuzzy matrix called fuzzy Drazin inverse matrix is defined which has a pivotal role of a fuzzy inverse matrix of a singular fuzzy matrix. Furthermore, two approaches for finding the fuzzy Drazin inverse matrix are given. In order to present the solution of FSDEs, a definition of nth order granular derivative is presented. This paper closes with some examples showing the approach is capable of finding the solution of FSDEs.},
  archive      = {J_SOCO},
  author       = {Najariyan, Marzieh and Zhao, Yi},
  doi          = {10.1007/s00500-020-05055-8},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11251-11264},
  shortjournal = {Soft Comput.},
  title        = {The explicit solution of fuzzy singular differential equations using fuzzy drazin inverse matrix},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A study of similarity measures through the paradigm of
measurement theory: The fuzzy case. <em>SOCO</em>, <em>24</em>(15),
11223–11250. (<a
href="https://doi.org/10.1007/s00500-020-05054-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We extend to fuzzy similarity measures the study made for classical ones in a companion paper (Coletti and Bouchon-Meunier in Soft Comput 23:6827–6845, 2019). Using a classic method of measurement theory introduced by Tversky, we establish necessary and sufficient conditions for the existence of a particular class of fuzzy similarity measures, representing a binary relation among pairs of objects which expresses the idea of “no more similar than”. In this fuzzy context, the axioms are strictly dependent on the combination operators chosen to compute the union and the intersection.},
  archive      = {J_SOCO},
  author       = {Coletti, Giulianella and Bouchon-Meunier, Bernadette},
  doi          = {10.1007/s00500-020-05054-9},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11223-11250},
  shortjournal = {Soft Comput.},
  title        = {A study of similarity measures through the paradigm of measurement theory: The fuzzy case},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fuzzy and improved fuzzy-wavelet approach in modeling
municipal residential water consumption estimation using climatic
variables. <em>SOCO</em>, <em>24</em>(15), 11213–11222. (<a
href="https://doi.org/10.1007/s00500-020-05053-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work highlights the importance of fuzzy-wavelet denoise and fuzzy-wavelet compress in modeling the municipal residential water consumption estimation. To begin, fuzzy logic is used with different rules, membership criteria and fuzzy set. Based on accuracy of the developed model, optimum number of rules and best membership function were selected. To improve the accuracy of the single fuzzy model, wavelets technique (denoise and compress approach) was coupled with fuzzy logic and results were compared to single fuzzy technique. To map the input and output functions, the present research work includes Mamdani fuzzy inference approach based on various climatic input variables like rainfall, maximum temperature, minimum temperature and relative humidity. The models were trained based on climatic data to a certain period, and corresponding estimated models were tested for the same period. Result highlights that models with denoise and compress approach have better accuracy compared to single fuzzy model.},
  archive      = {J_SOCO},
  author       = {Surendra, H. J. and Deka, Paresh Chandra},
  doi          = {10.1007/s00500-020-05053-w},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11213-11222},
  shortjournal = {Soft Comput.},
  title        = {Fuzzy and improved fuzzy-wavelet approach in modeling municipal residential water consumption estimation using climatic variables},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). State theory on bounded hyper EQ-algebras. <em>SOCO</em>,
<em>24</em>(15), 11199–11211. (<a
href="https://doi.org/10.1007/s00500-020-05039-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a hyper structure $$(X,\star )$$ , $$x\star y$$ is a non-empty subset of X. For a state s, $$s(x\star y)$$ need not be well defined. In this paper, by defining $$s^*(x\star y)=sup{s(z)\mid z\in x\star y}$$ , we introduce notions of sup-Bosbach states, state-morphisms and sup-Riečan states on a bounded hyper EQ-algebra and discuss the related properties. The states on bounded hyper EQ-algebras are the generalization of states on EQ-algebras. Then we discuss the relations among sup-Bosbach states, state-morphisms and sup-Riečan states on bounded hyper EQ-algebras. By giving a counter example, we show that a sup-Bosbach state may not be a sup-Riečan state on a hyper EQ-algebra. We give conditions in which each sup-Bosbach state becomes a sup-Riečan state on bounded hyper EQ-algebras. Moreover, we introduce several kinds of congruences on bounded hyper EQ-algebras, by which we construct the quotient hyper EQ-algebras. By use of the state s on a bounded hyper EQ-algebra H, we set up a state $${\bar{s}}$$ on the quotient hyper EQ-algebra $$H/\theta $$ . We also give the condition, by which a bounded hyper EQ-algebra admits a sup-Bosbach state.},
  archive      = {J_SOCO},
  author       = {Xin, Xiao Long},
  doi          = {10.1007/s00500-020-05039-8},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11199-11211},
  shortjournal = {Soft Comput.},
  title        = {State theory on bounded hyper EQ-algebras},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Study on green’s relations in ordered semihypergroups.
<em>SOCO</em>, <em>24</em>(15), 11189–11197. (<a
href="https://doi.org/10.1007/s00500-020-05035-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the hyper versions of Green’s relations in ordered semihypergroups in detail. The Green’s relations $${{\mathcal {R}}}, {{\mathcal {L}}}, {{\mathcal {J}}}$$ and $$ {\mathcal H}$$ in ordered semihypergroups are first introduced, and the relations between them are given. Furthermore, we investigate the properties of Green’s relations in ordered semihypergroups. Particularly, we illustrate the Green’s relation $${{\mathcal {R}}}$$ (resp. $${{\mathcal {L}}}$$ ) in an ordered semihypergroup S is not necessarily a left (resp. right) congruence on S by counterexamples. Meanwhile, we also provide a sufficient condition that makes the above conclusion true. Finally, we introduce the concept of a-maximal hyperideals of an ordered semihypergroup, and discuss its related properties by terms of the Green’s relation $${{\mathcal {J}}}.$$},
  archive      = {J_SOCO},
  author       = {Tang, Jian and Davvaz, Bijan},
  doi          = {10.1007/s00500-020-05035-y},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11189-11197},
  shortjournal = {Soft Comput.},
  title        = {Study on green’s relations in ordered semihypergroups},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A parametric recurrent neural network scheme for solving a
class of fuzzy regression models with some real-world applications.
<em>SOCO</em>, <em>24</em>(15), 11159–11187. (<a
href="https://doi.org/10.1007/s00500-020-05008-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a hybrid scheme based on recurrent neural networks for approximate fuzzy coefficients (parameters) of fuzzy linear and polynomial regression models with fuzzy output and crisp inputs is presented. Here, a neural network is first constructed based on some concepts of convex optimization and stability theory. The suggested neural network model guarantees to find the approximate parameters of the fuzzy regression problem. The existence and convergence of the trajectories of the neural network are studied. The Lyapunov stability for the neural network is also shown. Some illustrative examples provide a further demonstration of the effectiveness of the method.},
  archive      = {J_SOCO},
  author       = {Karbasi, Delara and Nazemi, Alireza and Rabiei, Mohammadreza},
  doi          = {10.1007/s00500-020-05008-1},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11159-11187},
  shortjournal = {Soft Comput.},
  title        = {A parametric recurrent neural network scheme for solving a class of fuzzy regression models with some real-world applications},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Western culture correct guidance and penetration teaching
and its multi-dimensional training mode. <em>SOCO</em>, <em>24</em>(15),
11149–11158. (<a
href="https://doi.org/10.1007/s00500-020-05004-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chinese college English teaching inevitably involves western culture, but actually great differences exist between Chinese culture and western culture. Therefore, how to establish the scientific outlook on western culture has long been a thorny issue for Chinese college English teachers. Commencing with an illustration of the necessity and importance of correct guidance and penetration western culture in Chinese college English teaching, this paper deeply analyzes the problems and shortcomings of present Chinese college English teaching in correct guidance and penetration for western culture and puts forward effective strategies of western culture introduction and penetration in Chinese college English teaching. And the paper aims to provide a useful reference for further improving the actual result of Chinese college English teaching and effectively avoiding cultural conflict between East and West.},
  archive      = {J_SOCO},
  author       = {Li, Zhenjin and Hu, Li},
  doi          = {10.1007/s00500-020-05004-5},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11149-11158},
  shortjournal = {Soft Comput.},
  title        = {Western culture correct guidance and penetration teaching and its multi-dimensional training mode},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Research on relation extraction of named entity on social
media in smart cities. <em>SOCO</em>, <em>24</em>(15), 11135–11147. (<a
href="https://doi.org/10.1007/s00500-020-04742-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media make significant contribution to the evolution of smart cities. The key issue of smart cities is to develop a series of automatic methods to support smart applications. As one of the basic techniques of smart cities, the task of relation extraction of named entities on social media provides an indispensable means to construct and expand knowledge map and contributes to the utilization of information resources in smart cities. What’s more, it is conducive to improve the efficiency of network supervision. This paper proposes an automatic method to extract entity relations via deep learning techniques on a two-level neural network named Bi-CLSTM. The research conquers some challenges of relation extraction on social media. To extract entity relations on conversation scenarios, Bi-CLSTM represents texts with the strategy of “word embedding + position embedding + shortest dependency path” and extracts relations via a hybrid model of LSTM and PCNN. The nodes and networks of Bi-CLSTM are designed to adapt to the scenarios of conversation and over-sentence. To reduce the dependency on training data, distant supervised strategy is employed and a two-level attention mechanism is used to prevent noise signals. Experiments are carried out on Sina Microblog corpus, and the results show that Bi-CLSTM model makes outstanding performance.},
  archive      = {J_SOCO},
  author       = {Liu, Zuoguo and Chen, Xiaorong},
  doi          = {10.1007/s00500-020-04742-w},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11135-11147},
  shortjournal = {Soft Comput.},
  title        = {Research on relation extraction of named entity on social media in smart cities},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). K-OpenAnswer: A simulation environment to analyze the
dynamics of massive open online courses in smart cities. <em>SOCO</em>,
<em>24</em>(15), 11121–11134. (<a
href="https://doi.org/10.1007/s00500-020-04696-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The smartness of a city is given by the technologies it put to use, and more than that, by the people empowered by such technologies; it is worth thinking about how people can be trained to be empowered by smart technologies, and how cities can become “educational.” So, while sustainability and technology solutions for smart cities are strategic challenges, one of these is surely distance education and training. In this field, the Web offers many opportunities, such as the e-learning platforms where students can learn, according to their own needs and pace. The massive open online courses (MOOCs) are particular distance learning platforms, generally offering, so far, free courses on a huge amount of topics, and characterized by a (potentially) very high number of enrollments. In a MOOC, a teacher, or tutor, has a hard life when trying to follow and manage with the learning processes of thousands of students. In particular, assessment can be managed almost exclusively by letting the student answer questions in closed answers tests. This strategy has some didactic limits, while a valid alternative is to use peer assessment (PA) over more articulated assessment activities (e.g., open-ended questions). PA makes students grade their peers’ answers, and provides learners with significant advantages, such as refining their knowledge of the subject matter, and developing their meta-cognitive skills. In this work, we present a software platform called K-OpenAnswer, which helps teachers to simulate the dynamic of a MOOC where PA is used. The system uses a machine learning technique, based on a modified version of the K-NN algorithm, and provides teachers with a statistical environment by which they can monitor the evolving dynamic of a simulated MOOC, according to the techniques we use to implement PA. An experimental evaluation is presented that highlights the advantages of using the system as a valid tool for the study of real MOOCs.},
  archive      = {J_SOCO},
  author       = {Sciarrone, Filippo and Temperini, Marco},
  doi          = {10.1007/s00500-020-04696-z},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11121-11134},
  shortjournal = {Soft Comput.},
  title        = {K-OpenAnswer: A simulation environment to analyze the dynamics of massive open online courses in smart cities},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bot prediction on social networks of twitter in altmetrics
using deep graph convolutional networks. <em>SOCO</em>, <em>24</em>(15),
11109–11120. (<a
href="https://doi.org/10.1007/s00500-020-04689-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of smart cities, it is crucial to filter out falsified information spread on social media channels through paid campaigns or bot-user accounts that significantly influence communication networks across the social communities and may affect smart decision-making by the citizens. In this paper, we focus on two major aspects of the Twitter social network associated with altmetrics: (a) to analyze the properties of bots on Twitter networks and (b) to distinguish between bots and human accounts. Firstly, we employed state-of-the-art social network analysis techniques that exploit Twitter’s social network properties in novel altmetrics data. We found that 87\% of tweets are affected by bots that are involved in the network’s dominant communities. We also found that, to some extent, community size and the degree of distribution in Twitter’s altmetrics network follow a power-law distribution. Furthermore, we applied a deep learning model, graph convolutional networks, to distinguish between organic (human) and bot Twitter accounts. The deployed model achieved the promising results, providing up to 71\% classification accuracy over 200 epochs. Overall, the study concludes that bot presence in altmetrics-associated social media platforms can artificially inflate the number of social usage counts. As a result, special attention is required to eliminate such discrepancies when using altmetrics data for smart decision-making, such as research assessment either independently or complementary along with traditional bibliometric indices.},
  archive      = {J_SOCO},
  author       = {Aljohani, Naif Radi and Fayoumi, Ayman and Hassan, Saeed-Ul},
  doi          = {10.1007/s00500-020-04689-y},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11109-11120},
  shortjournal = {Soft Comput.},
  title        = {Bot prediction on social networks of twitter in altmetrics using deep graph convolutional networks},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Formal modelling of OWL ontologies-based requirements for
the development of safe and secure smart city systems. <em>SOCO</em>,
<em>24</em>(15), 11095–11108. (<a
href="https://doi.org/10.1007/s00500-020-04688-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Formal methods are mathematical techniques used for developing reliable and verified systems. Event-B formal method is proved to be very useful to construct models of systems that are corrected by construction. Developing safe, secure, and reliable smart systems is essential for effective smart city solutions. The integration of safety and security mechanisms is an important aspect to achieve trust in smart cities’ services and applications. In this paper, we present prototype for the development of smart systems using OWL ontologies and Event-B formal models. We focus on the proposed approach that uses OWL ontologies to generate Event-B formal models for secure and safe development of systems. In recent years, ontologies-driven approaches have been applied during different phases to requirements engineering (RE), such as elicitation, analysis, specification, and validation. Many empirical studies have demonstrated benefits of the application of ontologies to handle ambiguity, inconsistency and incompleteness of requirements. We derive benefit from OWL ontologies to produce textual requirements that are consistent, complete, and unambiguous for formal modelling and to manage traceability between requirements and models. The approach uses Protégé-OWL editor, OWL verbaliser, Rodin platform, and OntoGraf tool. Protégé-OWL editor enables to build and view ontologies in Web Ontology Language (OWL). OWL verbaliser is used to generate controlled English requirements called Attempto Controlled English (ACE) from OWL ontologies. ACE representation is used as input requirements and transformed into Event-B formal models. Rodin platform is used for specification, refinement and proof. OntoGraf is a tool in Protégé that is used to visualise ontologies, and we make use of OntoGraf in this paper to assist in deciding refinement strategy and managing traceability between requirements and models.},
  archive      = {J_SOCO},
  author       = {Alkhammash, Eman},
  doi          = {10.1007/s00500-020-04688-z},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11095-11108},
  shortjournal = {Soft Comput.},
  title        = {Formal modelling of OWL ontologies-based requirements for the development of safe and secure smart city systems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Unifying user similarity and social trust to generate
powerful recommendations for smart cities using collaborating
filtering-based recommender systems. <em>SOCO</em>, <em>24</em>(15),
11071–11094. (<a
href="https://doi.org/10.1007/s00500-019-04588-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems can improve the quality of life in smart cities by presenting personalized services to the community. Such systems maintain a database of user profiles for producing recommendations for a specific user. The collaborative filtering (CF) approach used in these systems has become a benchmark approach for generating recommendations for interested users because it can provide “out of the box” solutions. These CF-based approaches first construct a user–item rating matrix and then exploit similarity methods. These approaches suffer from scalability, sparsity, and cold user conditions, which consequently result in the poor recommendation accuracy of these systems. To enhance the accuracy of recommender systems, social trust can play a vital role because people tend to interact with a system or respond positively to recommendations that originate from their social trustworthy friends. The proposed unified approach of this article uses explicit trust, implicit trust, and user preference similarity to create a unified rating profile for the target user to produce more powerful and accurate recommendations. The proposed unified approach also enhances the recommendation performance of CF-based recommender systems when only a limited set of ratings is available. Experiments are performed on three publicly available datasets which are FilmTrust, CiaoDVD, and Epinions. Comparison of obtained results is made with traditional similarity measures as well as up-to-date trust-based approaches. The results show that the proposed unified approach is superior to existing approaches in terms of both predictive and classification-based accuracy measures.},
  archive      = {J_SOCO},
  author       = {Ayub, Mubbashir and Ghazanfar, Mustansar Ali and Mehmood, Zahid and Alyoubi, Khaled H. and Alfakeeh, Ahmed S.},
  doi          = {10.1007/s00500-019-04588-x},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11071-11094},
  shortjournal = {Soft Comput.},
  title        = {Unifying user similarity and social trust to generate powerful recommendations for smart cities using collaborating filtering-based recommender systems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Towards cyberbullying-free social media in smart cities: A
unified multi-modal approach. <em>SOCO</em>, <em>24</em>(15),
11059–11070. (<a
href="https://doi.org/10.1007/s00500-019-04550-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart cities are shifting the presence of people from physical world to cyber world (cyberspace). Along with the facilities for societies, the troubles of physical world, such as bullying, aggression and hate speech, are also taking their presence emphatically in cyberspace. This paper aims to dig the posts of social media to identify the bullying comments containing text as well as image. In this paper, we have proposed a unified representation of text and image together to eliminate the need for separate learning modules for image and text. A single-layer Convolutional Neural Network model is used with a unified representation. The major findings of this research are that the text represented as image is a better model to encode the information. We also found that single-layer Convolutional Neural Network is giving better results with two-dimensional representation. In the current scenario, we have used three layers of text and three layers of a colour image to represent the input that gives a recall of 74\% of the bullying class with one layer of Convolutional Neural Network.},
  archive      = {J_SOCO},
  author       = {Kumari, Kirti and Singh, Jyoti Prakash and Dwivedi, Yogesh Kumar and Rana, Nripendra Pratap},
  doi          = {10.1007/s00500-019-04550-x},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11059-11070},
  shortjournal = {Soft Comput.},
  title        = {Towards cyberbullying-free social media in smart cities: A unified multi-modal approach},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Quantification of cultural identity through artificial
intelligence: A case study on the waorani amazonian ethnicity.
<em>SOCO</em>, <em>24</em>(15), 11045–11057. (<a
href="https://doi.org/10.1007/s00500-019-04469-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The first step toward a Smart Village is that the community itself can benefit from the novel techniques that are applied. Some communities are far from being able to use the benefits that these technologies usually offer; however, they can benefit from the techniques that have led to the development of smart cities. This is the case of the indigenous people belonging to communities in the Amazon: They have seen their identity drastically eroded in recent decades as a result of the process of Western acculturation. In this context, the use of artificial intelligence techniques may contribute to the detection and quantification of cultural identity loss by identifying the most and least affected identity components of this process. This research work presents a quantitative method, which evaluates several variables of the cultural identity of an Ecuadorian Amazonian indigenous community: the Waorani. The proposed method automatically classifies the individuals and provides a subspace of it able to identify the weights of the subcomponents of this instrument in regard to its contribution to the Waorani identity. The systematic application of the instrument together with the artificial intelligence-based approach can provide decision makers with valuable information about which aspects of their identity are most sensitive to change and thus help design development policies that minimally interfere with their ethnic identity.},
  archive      = {J_SOCO},
  author       = {Espín-León, Aldrin and Jimeno-Morenilla, Antonio and Pertegal-Felices, María Luisa and Azorín-López, Jorge},
  doi          = {10.1007/s00500-019-04469-3},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11045-11057},
  shortjournal = {Soft Comput.},
  title        = {Quantification of cultural identity through artificial intelligence: A case study on the waorani amazonian ethnicity},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Predicting stock market trends using machine learning
algorithms via public sentiment and political situation analysis.
<em>SOCO</em>, <em>24</em>(15), 11019–11043. (<a
href="https://doi.org/10.1007/s00500-019-04347-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stock market trends can be affected by external factors such as public sentiment and political events. The goal of this research is to find whether or not public sentiment and political situation on a given day can affect stock market trends of individual companies or the overall market. For this purpose, the sentiment and situation features are used in a machine learning model to find the effect of public sentiment and political situation on the prediction accuracy of algorithms for 7 days in future. Besides, interdependencies among companies and stock markets are also studied. For the sake of experimentation, stock market historical data are downloaded from Yahoo! Finance and public sentiments are obtained from Twitter. Important political events data of Pakistan are crawled from Wikipedia. The raw text data are then pre-processed, and the sentiment and situation features are generated to create the final data sets. Ten machine learning algorithms are applied to the final data sets to predict the stock market future trend. The experimental results show that the sentiment feature improves the prediction accuracy of machine learning algorithms by 0–3\%, and political situation feature improves the prediction accuracy of algorithms by about 20\%. Furthermore, the sentiment attribute is most effective on day 7, while the political situation attribute is most effective on day 5. SMO algorithm is found to show the best performance, while ASC and Bagging show poor performance. The interdependency results indicate that stock markets in the same industry show a medium positive correlation with each other.},
  archive      = {J_SOCO},
  author       = {Khan, Wasiat and Malik, Usman and Ghazanfar, Mustansar Ali and Azam, Muhammad Awais and Alyoubi, Khaled H. and Alfakeeh, Ahmed S.},
  doi          = {10.1007/s00500-019-04347-y},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11019-11043},
  shortjournal = {Soft Comput.},
  title        = {Predicting stock market trends using machine learning algorithms via public sentiment and political situation analysis},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A soft computing approach to violence detection in social
media for smart cities. <em>SOCO</em>, <em>24</em>(15), 11007–11017. (<a
href="https://doi.org/10.1007/s00500-019-04310-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, social media has become an everyday tool for the distribution of videos in which signs of violence appear in different ways. Citizens of smart cities are demanding increasing efforts to authorities in order to maintain public safety, as well as to be efficient in an emergency response. The complexity of monitoring automatically the enormous amount of information generated through social networks results in the need for the development of systems that allow for the automatic detection of violent content in videos. This fact is becoming increasingly important in order to guarantee security for the citizens in any smart city. As a result, this work proposes the development of a system for detecting violence in videos by combining different descriptors that calculate the acceleration produced between two frames of a video. To do this, different techniques, such as the Radon transform or optical flow, are used. The trained system then performs the classification using support vector Machines. The results are promising, with accuracy rates between 85 and 97\%, depending on the complexity of the databases used, which demonstrates the validity of our proposal.},
  archive      = {J_SOCO},
  author       = {Pujol, Francisco A. and Mora, Higinio and Pertegal, Maria Luisa},
  doi          = {10.1007/s00500-019-04310-x},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {11007-11017},
  shortjournal = {Soft Comput.},
  title        = {A soft computing approach to violence detection in social media for smart cities},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Predicting the helpfulness score of online reviews using
convolutional neural network. <em>SOCO</em>, <em>24</em>(15),
10989–11005. (<a
href="https://doi.org/10.1007/s00500-019-03851-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The smart cities aim to provide an infrastructure to their citizens that reduces both their time and effort. An example of such an available infrastructure is electronic shopping. Electronic shopping has become the hotbeds of many customers as it is easier to judge the quality of the product based on the review information. The purpose of this study is to predict the best helpful online product review, out of the several thousand reviews available for the product using review representation learning. The prediction is done using a two-layered convolutional neural network model. The review texts are embedded into low-dimensional vectors using a pre-trained model. To learn the best features of the review text, three filters are used to learn tri-gram, four-gram, and five-gram features of the text. The proposed approach is found to be better than existing machine learning based models which used hand-crafted features. The very low value of mean squared error confirms the prediction accuracy of the proposed method. The proposed method can be easily applied to any kind of review as the features are calculated only from the review text and not from other domain knowledge. The proposed model helps in predicting the helpfulness score of new reviews as soon as it gets posted on the product review page.},
  archive      = {J_SOCO},
  author       = {Saumya, Sunil and Singh, Jyoti Prakash and Dwivedi, Yogesh K.},
  doi          = {10.1007/s00500-019-03851-5},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {10989-11005},
  shortjournal = {Soft Comput.},
  title        = {Predicting the helpfulness score of online reviews using convolutional neural network},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Social media mining for smart cities and smart villages
research. <em>SOCO</em>, <em>24</em>(15), 10983–10987. (<a
href="https://doi.org/10.1007/s00500-020-05084-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The imperative of well-being and improved quality of life in smart cities context can only be attained if the smart services, so central to the concept of smart cities, correspond with the needs, expectations and skills of cities’ inhabitants. Considering that social media generate and/or open real-time entry points to vast amounts of data pertinent to well-being and quality of life, such as citizens’ expectations, opinions, as well as to recent developments related to regulatory frameworks, debates, political decisions and policymaking, the big question is how to exploit the potential inherent in social media and use it to enhance the value added smart cities generate. Social mining is traditionally understood as the process of representing, analyzing, and extracting actionable patterns and trends from raw social media data. In the context of smart cities, this special issue focuses on how social media data, also potentially combined with other data, can be used to optimize the efficiency of city operations and services, and thereby contribute more efficiently to citizens’ well-being and quality of life.},
  archive      = {J_SOCO},
  author       = {Lytras, Miltiadis D. and Visvizi, Anna and Jussila, Jari},
  doi          = {10.1007/s00500-020-05084-3},
  journal      = {Soft Computing},
  number       = {15},
  pages        = {10983-10987},
  shortjournal = {Soft Comput.},
  title        = {Social media mining for smart cities and smart villages research},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An innovative synthesis of deep learning techniques
(DCapsNet &amp; DCOM) for generation electrical renewable energy from
wind energy. <em>SOCO</em>, <em>24</em>(14), 10943–10962. (<a
href="https://doi.org/10.1007/s00500-020-04905-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Renewable energy becomes one of the main resources that help the world to safety the environment from pollution and provide the people of new type of energy; therefore, this paper presents model called multi-objectives renewable energy-generation (MORE-G) for generating electrical energy from the wind. In general, this model consists of five basic phases: in a first phase collecting and preparing the data, so to make it in format suitable for the decision-making stage, this phase split into multi-steps (i.e., handle missing values and normalization dataset), and the second phase focuses on building constraints for each dataset and develops one of the optimization algorithms called cuckoo based on horizontal combination and multi-objective optimization used in third phase to generate the energy. Another model is developed as multi-layer neural network called (DCapsNet) based on linear combination and multi-objective functions used in the fourth phase to generate the energy. Final phase is related to evaluation of both models (DCOM and DCapsNet) to determine the best. The MORE-G is characterized by addressing one of the real problems, saving on material costs (i.e., reducing the need for manpower and reducing dependence on other countries in importing electric power) and upgrading the scope of the ministry of electricity.},
  archive      = {J_SOCO},
  author       = {Al-Janabi, Samaher and Alkaim, Ayad F. and Adel, Zuhal},
  doi          = {10.1007/s00500-020-04905-9},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10943-10962},
  shortjournal = {Soft Comput.},
  title        = {An innovative synthesis of deep learning techniques (DCapsNet &amp; DCOM) for generation electrical renewable energy from wind energy},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A hybrid group search optimization: Firefly algorithm-based
big data framework for ancient script recognition. <em>SOCO</em>,
<em>24</em>(14), 10933–10941. (<a
href="https://doi.org/10.1007/s00500-019-04596-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optical character recognition is becoming one of the widely researched areas in recent times. This research paper presents an optimization framework for ancient script recognition using the process of script or character segmentation. The proposed algorithm is based on evolutionary algorithm and capable of handing a continuous script of high-resolution data using concepts of big data. A hybrid combination of group search and firefly algorithm has been proposed in this research work and compared against recent works. Optimal classifications results are observed and recorded in this research paper.},
  archive      = {J_SOCO},
  author       = {Suganya, T. S. and Murugavalli, S.},
  doi          = {10.1007/s00500-019-04596-x},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10933-10941},
  shortjournal = {Soft Comput.},
  title        = {A hybrid group search optimization: Firefly algorithm-based big data framework for ancient script recognition},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Robust credibilistic intuitionistic fuzzy clustering for
image segmentation. <em>SOCO</em>, <em>24</em>(14), 10903–10932. (<a
href="https://doi.org/10.1007/s00500-019-04593-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To improve the anti-noise ability of credibilistic intuitionistic fuzzy c-means clustering method (CIFCM) for image segmentation, this paper proposes a robust credibilistic intuitionistic fuzzy c-means clustering method based on credibility of pixels and intuitionistic fuzzy entropy. Firstly, a new similarity measure is constructed by utilizing the grayscale and spatial relationship between the current pixel and its neighborhood pixels. Secondly, it is embedded into the objective function of credibilistic intuitionistic fuzzy c-means clustering, and a new robust clustering method with spatial constraints is presented to effectively solve the segmentation problem of image corrupted by high noise. In the end, the convergence of this proposed robust clustering method is strictly proved by iterated convergence theorem. Experimental results show that proposed algorithm has better noise-suppression ability and more satisfactory segmentation results than CIFCM algorithm.},
  archive      = {J_SOCO},
  author       = {Wu, Chengmao and Yang, Xiaoqiang},
  doi          = {10.1007/s00500-019-04593-0},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10903-10932},
  shortjournal = {Soft Comput.},
  title        = {Robust credibilistic intuitionistic fuzzy clustering for image segmentation},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hybrid evolutionary algorithm (NNACOR) for energy
minimization in a wireless mesh topology towards green computing.
<em>SOCO</em>, <em>24</em>(14), 10893–10902. (<a
href="https://doi.org/10.1007/s00500-019-04592-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless sensor networks are a very rapidly emerging class of network structures being utilized in almost all computing environments. Energy consumption is an essential criterion especially with the recent need in conservation of energy and carbon footprint. The proposed research paper investigated the prospects of green computing towards implementation of a hybrid algorithm (NNACOR) based on evolutionary computing model deriving its behaviour from naturally occurring phenomenon for reducing the energy consumed by each node in the mesh topology. The experiments have been conducted in NS2 and compared against the conventional AODC routing protocol, and the observed results indicate a superior performance of the proposed evolutionary model by providing up to a 48\% in energy saving as against a 44\% energy saving reported in the literature.},
  archive      = {J_SOCO},
  author       = {Prakash, B. and Jayashri, S. and Prabaharan, G.},
  doi          = {10.1007/s00500-019-04592-1},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10893-10902},
  shortjournal = {Soft Comput.},
  title        = {Hybrid evolutionary algorithm (NNACOR) for energy minimization in a wireless mesh topology towards green computing},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Statistical <span
class="math display">(<em>C</em>, 1)(<em>E</em>, <em>μ</em>)</span>-summability
and associated fuzzy approximation theorems with statistical fuzzy
rates. <em>SOCO</em>, <em>24</em>(14), 10883–10892. (<a
href="https://doi.org/10.1007/s00500-019-04591-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concept of statistical convergence has attracted the pervasive attention of the current researchers due basically to the fact that it is stronger than the ordinary convergence. Korovkin-type approximation theorem plays a vital role in the convergence of sequences of positive linear operators. Moreover, this type of approximation theorems has been extended through different statistical summability methods over general sequence spaces. The paper investigated statistical $$(C,1)(E,\mu )$$ product summability mean for sequences of fuzzy numbers and proved a fuzzy Korovkin-type approximation theorem. Furthermore, we have established another result for the fuzzy rate of convergence which is uniform in fuzzy Korovkin-type approximation theorem under our proposed summability mean.},
  archive      = {J_SOCO},
  author       = {Das, A. A. and Paikray, S. K. and Pradhan, T. and Dutta, Hemen},
  doi          = {10.1007/s00500-019-04591-2},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10883-10892},
  shortjournal = {Soft Comput.},
  title        = {Statistical $$(C,1)(E,\mu )$$-summability and associated fuzzy approximation theorems with statistical fuzzy rates},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An integrated optimization technique for optimal power flow
solution. <em>SOCO</em>, <em>24</em>(14), 10865–10882. (<a
href="https://doi.org/10.1007/s00500-019-04590-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of the research work is to propose an integrated optimization technique, established with the integration of the invasive weed optimization (IWO) and Powell’s pattern search (PPS) method. The IWO algorithm has been undertaken as a global search technique, which is inspired from the specific ecological behavior of weeds and has the ability to adapt to the changing environment. The local search PPS method is based upon a conjugate-based search and having excellent exploitation search capability, which helps to improve the solution obtained from IWO technique. The proposed technique is applied to solve optimal power flow (OPF) problem with the flexible AC transmission system devices. The OPF problem is a nonlinear, non-convex optimization problem and consists of continuous and discrete decision variables. The three objective functions comprise total fuel cost, pollutant emission and system transmission loss which are minimized sequentially. The proposed technique is tested on four standard IEEE test systems, and results are compared with the reported results in the literature and found promising. The results illustrate that the proposed technique performs better as compared to IWO technique in terms of the quality of solution and convergence characteristics. Further, t test is performed to validate the statistical performance of the proposed integrated optimization technique.},
  archive      = {J_SOCO},
  author       = {Kaur, Mandeep and Narang, Nitin},
  doi          = {10.1007/s00500-019-04590-3},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10865-10882},
  shortjournal = {Soft Comput.},
  title        = {An integrated optimization technique for optimal power flow solution},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-view heterogeneous fusion and embedding for
categorical attributes on mixed data. <em>SOCO</em>, <em>24</em>(14),
10843–10863. (<a
href="https://doi.org/10.1007/s00500-019-04586-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Categorical attributes are ubiquitous in real-world collected data. However, such attributes lack a well-defined distance metric and cannot be directly manipulated per algebraic operations, so many data mining algorithms are unable to work directly on them. Learning an appropriate metric or an effective numerical embedding is very vital yet challenging, for categorical attributes with multi-view heterogeneous data characteristics. This paper proposes a novel multi-view heterogeneous fusion model (MVHF), which first captures basic coupling information for each view and then fuses these heterogeneous information from different views by multi-kernel metric learning, to measure the intrinsic distances between this type of categorical attributes; based on these measured distances, further, we use the manifold learning method to learn a high-quality numerical embedding for each categorical value. Experiments on 33 mixed data sets demonstrate that MVHF-enabled classification significantly enhances the performance, compared with state-of-the-art distance metrics or embedding competitors.},
  archive      = {J_SOCO},
  author       = {Li, Qiude and Xiong, Qingyu and Ji, Shengfen and Gao, Min and Yu, Yang and Wu, Chao},
  doi          = {10.1007/s00500-019-04586-z},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10843-10863},
  shortjournal = {Soft Comput.},
  title        = {Multi-view heterogeneous fusion and embedding for categorical attributes on mixed data},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new overall quality indicator OQoC and the corresponding
context inconsistency elimination algorithm based on OQoC and
dempster–shafer theory. <em>SOCO</em>, <em>24</em>(14), 10829–10841. (<a
href="https://doi.org/10.1007/s00500-019-04585-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of Internet of things technology, context-aware systems (CASs) are being gradually improved and widely applied to many fields such as digital home, smart health and so on. However, context information from sensor-rich CASs usually has inconsistency, which leads to wrong decisions made by systems, and even lowers user experience. Therefore, a new overall quality of context (OQoC) indicator is defined, which is the effective fusion of the parameters of reliability, up-to-dateness and modified correctness. Its accurate measurement is of great importance in inconsistency elimination. Moreover, we put forward a new context inconsistency elimination algorithm based on OQoC and Dempster–Shafer theory. The performance of the proposed algorithm is verified in personal identity verification scenario. Experimental results from multiple dimensions fully show the superiority of the proposed algorithm in solving context inconsistency problem, and quality of context information using the proposed algorithm has been greatly improved.},
  archive      = {J_SOCO},
  author       = {Chen, Min and Xu, Hongji and Xiong, Hailiang and Pan, Lingling and Du, Baozhen and Li, Feifei},
  doi          = {10.1007/s00500-019-04585-0},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10829-10841},
  shortjournal = {Soft Comput.},
  title        = {A new overall quality indicator OQoC and the corresponding context inconsistency elimination algorithm based on OQoC and Dempster–Shafer theory},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The online soft computing models of key variables based on
the boundary forest method. <em>SOCO</em>, <em>24</em>(14), 10815–10828.
(<a href="https://doi.org/10.1007/s00500-019-04584-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Online Soft Computing Models (OSCMs) based on ensemble methods are novel and quite effective data-driven tools for predicting key variables. The current challenge encountered by them is how to enhance the reliability caused by both the uncertainty from noise and the unsuitable specifications of models, on the premise of high predicting accuracy and low computational cost. To meet the current challenge, the OSCM based on the Boundary Forest (OSCM-BF) is proposed in this paper. The BF combines a set of the Tree-Structure Ensemble (TSE) models. In terms of the different values of θ (i.e., the minimum size of leaf nodes), the BF enhances the reliability of a single TSE not only by overlapping the gap segments of output range (i.e., connecting the discontinuous boundaries of leaf nodes), but also by possessing stronger robustness via producing enough diversity. Moreover, a theoretical range of the value of θ constructed by BF is provided. Since the simplicity, the nice interpretability and the flexibility on large-scale data, the moving-window strategy was adopted to realize the update of the BF models. The experiments on the noisy data from the industrial process of Ladle Furnace reveal that the OSCM-BF can enhance the reliability of the OSCM-TSE on the premise of high predicting accuracy and low computational cost.},
  archive      = {J_SOCO},
  author       = {Deng, Chang-Hui and Wang, Xiao-Jun and Gu, Jun and Wang, Wei},
  doi          = {10.1007/s00500-019-04584-1},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10815-10828},
  shortjournal = {Soft Comput.},
  title        = {The online soft computing models of key variables based on the boundary forest method},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Reduction of an information system. <em>SOCO</em>,
<em>24</em>(14), 10801–10813. (<a
href="https://doi.org/10.1007/s00500-019-04582-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Notion of soft binary relation is studied here. Some properties of lower and upper approximations with the help of soft equivalence relations are given. Actually, approximations of a subset by a soft binary relation give rise to two soft sets. This new setting is very clear and provides approximations related to every parameter/attribute under consideration. For any subset X,  there is an associated fuzzy subset with respect to each parameter. These fuzzy sets are very helpful in decision-making problems. Parametric reduction helps to reduce the size of data. A technique has been presented for this purpose.},
  archive      = {J_SOCO},
  author       = {Shabir, Muhammad and Kanwal, Rani Sumaira and Ali, Muhammad Irfan},
  doi          = {10.1007/s00500-019-04582-3},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10801-10813},
  shortjournal = {Soft Comput.},
  title        = {Reduction of an information system},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hybrid on-chip soft computing model for performance
evaluation of 6T SRAM cell using 45-nm technology. <em>SOCO</em>,
<em>24</em>(14), 10785–10799. (<a
href="https://doi.org/10.1007/s00500-019-04581-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A hybrid on-chip approach based on the variants of soft computing techniques is proposed in this work to evaluate the performance metrics of a 6T static random access memory (SRAM) cell in 45-nm technology. The performance metric evaluated for the SRAM cell is the data retention voltage (DRV) with optimal memory requirements. Each of the SRAM memory cells intends the chip to possess low density but operates at high speed. This paper formulates a hybrid soft computing framework comprising a deep backpropagation neural network which trains the fuzzy inference system to determine the performance metrics of 6T SRAM cell. The weight and bias parameters of the deep learning neural framework are optimized through a cat swarm optimization algorithm so as to reduce the elapsed convergence time of the new hybrid soft computing model. Evaluation process is executed based on the driven outputs from deep learning model to the fuzzy inference system (FIS) module so as to achieve the best values of DRV. Data retention voltage plays a major role in reducing the substantial leakage current and static noise margin intends to retain the data without losing them. Deep backpropagation neural network gets trained with deep learning procedures and optimizes the rule parameters and membership parameters of the FIS design structure. The performance metric DRV under various constraints prove to be better and effective in comparison with the solutions from the existing literature works for the same configuration of 6T SRAM cell using 45-nm technology.},
  archive      = {J_SOCO},
  author       = {Selvarasu, S. and Saravanan, S.},
  doi          = {10.1007/s00500-019-04581-4},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10785-10799},
  shortjournal = {Soft Comput.},
  title        = {Hybrid on-chip soft computing model for performance evaluation of 6T SRAM cell using 45-nm technology},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Analysis on energy consumption in smart grid WSN using path
operator calculus centrality based HSA-PSO algorithm. <em>SOCO</em>,
<em>24</em>(14), 10771–10783. (<a
href="https://doi.org/10.1007/s00500-019-04580-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the consumption of energy is efficiently balanced using the high searching capability of harmony search algorithm (HSA). However, centrality in finding the route is considered as an utmost challenge in finding the important node in WSN. Hence, the path operator calculus centrality (SPOCC) is used to optimize the centrality problems in routing. The SPOCC finds the main routing path using HSA, and high centrality node is estimated by particle swarm optimization (PSO) algorithm, thereby ensuring optimal routing with reduced energy consumption. The utilization of PSO improves the lifetime of nodes using its dynamic capability. The performance of the proposed hybrid algorithm is evaluated using the various result metrics in smart grid outdoor transmission environment. The results show that the proposed hybrid algorithm obtains better improvement in terms of reduced delay and high residual energy than the existing algorithms.},
  archive      = {J_SOCO},
  author       = {Hemalatha, R. and Prakash, R. and Sivapragash, C.},
  doi          = {10.1007/s00500-019-04580-5},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10771-10783},
  shortjournal = {Soft Comput.},
  title        = {Analysis on energy consumption in smart grid WSN using path operator calculus centrality based HSA-PSO algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel methodology for performance evaluation of IT
projects in a fuzzy environment: A case study. <em>SOCO</em>,
<em>24</em>(14), 10755–10770. (<a
href="https://doi.org/10.1007/s00500-019-04579-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the information technology (IT) projects are canceled or failed due to different reasons, while some of them are performed poorly in terms of cost, time, scope, customer satisfaction, etc. Therefore, it is important to identify the most important criteria affecting the performance of IT projects, measure their performance, identify the issues, and continually improve the performance of both the projects and the organizations. Although IT organizations place value on the importance of the project performance to release on time, with low cost, and in accordance with the customer expectations, they lack ways of determining the most suitable performance criteria for continually measuring, improving, and controlling them. This study proposes a new methodology to evaluate the performance of IT projects in a fuzzy environment. For this aim, firstly, the most suitable criteria are identified based on the balanced scorecard method. In the second step, the relative priorities of the criteria are determined with the help of expert judgments and hesitant fuzzy weights with hesitant multiplicative geometric operator. Then, the priorities of the criteria are used to evaluate the performance of IT projects in a Turkish company by using real data.},
  archive      = {J_SOCO},
  author       = {Basar, Ayfer},
  doi          = {10.1007/s00500-019-04579-y},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10755-10770},
  shortjournal = {Soft Comput.},
  title        = {A novel methodology for performance evaluation of IT projects in a fuzzy environment: A case study},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimum outflow determination of the multi-reservoir system
using constrained improved artificial bee colony algorithm.
<em>SOCO</em>, <em>24</em>(14), 10739–10754. (<a
href="https://doi.org/10.1007/s00500-019-04577-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this research, a new meta-heuristic algorithm, named artificial bee colony (ABC) algorithm, is used to solve multi-reservoir operation optimization problem. For this purpose, two improved versions of ABC are proposed by modifying the structure of original standard form of ABC algorithm. Furthermore, in order to increase the performance of proposed algorithms for solving large-scale problems, the constrained versions of original and improved form of ABC algorithms have been proposed in which the problem constraints are explicitly satisfied. Two benchmark text examples, including four- and ten-reservoir operation optimization problems, are solved here using proposed algorithms, and the results are presented and compared. In order to solve these problems, here, two formulations are also proposed in which in the first formulation, the water releases from the reservoir and in the second one the water storage volumes of the reservoir are considered as the decision variables of the problem. Comparison of the results shows that by using the improved ABC algorithm, the better results are obtained with less computational effort in comparison with the original form of ABC algorithm in which the result improvement is notable when the proposed constrained version of the algorithms is used.},
  archive      = {J_SOCO},
  author       = {Moeini, Ramtin and Soghrati, Farnaz},
  doi          = {10.1007/s00500-019-04577-0},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10739-10754},
  shortjournal = {Soft Comput.},
  title        = {Optimum outflow determination of the multi-reservoir system using constrained improved artificial bee colony algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Behavioral DEA model and its application to the efficiency
evaluation of manufacturing transformation and upgrading in the yangtze
river delta. <em>SOCO</em>, <em>24</em>(14), 10721–10738. (<a
href="https://doi.org/10.1007/s00500-019-04576-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Yangtze River Delta (YRD) is a Chinese region with the highest level of economic development, which has an important impact on the level of China’s modernization. The development of manufacturing is the driving and critical force for the industrialization of the YRD. Transformation and upgrading are considered as an effective measure to improve the development of manufacturing industry. The purpose of this study is to develop a behavioral DEA (BDEA) model-based efficiency evaluation method by integrating the traditional DEA model with prospect theory. In this BDEA model framework, prospect theory is combined with the traditional DEA model to evaluate the development efficiency of manufacturing transformation and upgrading in the YRD, which takes behavioral preference of the decision-makers (DMs) in decision-making problems into account. In addition, the technique for order of preference by similarity to ideal solution method is applied to identify the reference points, in which maximum input minimum output is regarded as a negative reference point and the minimum input maximum output is regarded as a positive reference point. Then, the gain value and the loss value are obtained on the basis of the value function with reference points of prospect theory, and the overall utility function is further constructed to depict the behavioral preference of DMs. Finally, a case study is employed to illustrate the applicability of the proposed BDEA method by evaluating the relative efficiency of manufacturing transformation and upgrading in the YRD, and the comparative analysis with the result of efficiency values also shows the feasibility of the proposed BDEA model.},
  archive      = {J_SOCO},
  author       = {Chen, Xiaoqing and Liu, Xinwang and Wang, Weizhong and Gong, Zaiwu},
  doi          = {10.1007/s00500-019-04576-1},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10721-10738},
  shortjournal = {Soft Comput.},
  title        = {Behavioral DEA model and its application to the efficiency evaluation of manufacturing transformation and upgrading in the yangtze river delta},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimizing ligand conformations in flexible protein targets:
A multi-objective strategy. <em>SOCO</em>, <em>24</em>(14), 10705–10719.
(<a href="https://doi.org/10.1007/s00500-019-04575-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding the orientation of a ligand (small molecule) with the lowest binding energy to the macromolecule (receptor) is a complex optimization problem, commonly called ligand–protein docking. This problem has been usually approached by minimizing a single objective that corresponds to the final free energy of binding. In this work, we propose a new multi-objective strategy focused on minimizing: (1) the root mean square deviation (RMSD) between the co-crystallized and predicted ligand atomic coordinates, and (2) the ligand–receptor intermolecular energy. This multi-objective strategy provides the molecular biologists with a range of solutions computing different RMSD scores and intermolecular energies. A set of representative multi-objective algorithms, namely NSGA-II, SMPSO, GDE3 and MOEA/D, have been evaluated in the scope of an extensive set of docking problems, which are featured by including HIV-proteases with flexible ARG8 side chains and their inhibitors. As use cases for biological validation, we have included a set of instances based on new retroviral inhibitors to HIV-proteases. The proposed multi-objective approach shows that the predictions of ligand’s pose can be promising in cases in which studies in silico are necessary to test new candidate drugs (or analogue drugs) to a given therapeutic target.},
  archive      = {J_SOCO},
  author       = {López-Camacho, Esteban and García-Godoy, María Jesús and García-Nieto, José and Nebro, Antonio J. and Aldana-Montes, José F.},
  doi          = {10.1007/s00500-019-04575-2},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10705-10719},
  shortjournal = {Soft Comput.},
  title        = {Optimizing ligand conformations in flexible protein targets: A multi-objective strategy},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A passive detection algorithm for low-altitude small target
based on a wavelet neural network. <em>SOCO</em>, <em>24</em>(14),
10693–10703. (<a
href="https://doi.org/10.1007/s00500-019-04574-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A passive detection algorithm is presented for multiple low-altitude small targets, which employs a wavelet neural network (WNN). The slope, kurtosis, and skewness are employed as the features for low-altitude small target detection, and an algorithm is given to determine the number of targets. A WNN is used to establish a relationship between signal classes and the signal characteristics using training signals. Then, signals are classified as either target present or target not present using the WNN. Indoor data from a research laboratory and outdoor data from a bridge in the Jimo District, Qingdao, were used for training and evaluation. The performance results show that the error rate with the proposed WNN-based algorithm is better than those based on the slope, skewness, and kurtosis of signal. Furthermore, the proposed algorithm is better than those based on other neural networks such as BPNN, RBFNN, SOMNN, and SVM. At a distance of 3 km, the recognition rate is greater than 84\%, which is better than other techniques such as visual recognition, acoustic, and active radar.},
  archive      = {J_SOCO},
  author       = {Cao, Conghui and Hou, Qun and Gulliver, Thomas Aaron and Lan, Qiang},
  doi          = {10.1007/s00500-019-04574-3},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10693-10703},
  shortjournal = {Soft Comput.},
  title        = {A passive detection algorithm for low-altitude small target based on a wavelet neural network},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Enhancement of security using optimized DoS
(denial-of-service) detection algorithm for wireless sensor network.
<em>SOCO</em>, <em>24</em>(14), 10681–10691. (<a
href="https://doi.org/10.1007/s00500-019-04573-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless sensor networks involved every part of application in today’s life. This can detect the various type of information from environment and communicated to users in real time. Information is stored by using cloud technology and that can be accessed by the users. The information is prone to attacks as they are part of cooperative communication. Building algorithms at node level is not secured as they transfer data in open traffic. This has provided scope for this study to concentrate on algorithms that are available for denial-of-service attacks as they put down the network performance to a less minimum. The paper henceforth proposes optimized energy-based constraint DoS (denial-of-service) detection algorithm, i.e., OBES algorithm for handling denial-of-service attacks that learns the network traffic and manages the intruders. This has been compared with denial-of-service attack detection with energy constraint in WSN. The implementation has been done in NS2. The performance has been presented in terms of nodes, interval and lifetime. From results, it can be observed that the proposed OBES algorithm is efficient as it achieves more available energy, less delay, less packet loss and more lifetime for the network. From results, it can be observed that OBES algorithm performs well compared to denial-of-service attack detection with energy constraint algorithm.},
  archive      = {J_SOCO},
  author       = {Suryaprabha, E. and Saravana Kumar, N. M.},
  doi          = {10.1007/s00500-019-04573-4},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10681-10691},
  shortjournal = {Soft Comput.},
  title        = {Enhancement of security using optimized DoS (denial-of-service) detection algorithm for wireless sensor network},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Weight-and-universum-based semi-supervised multi-view
learning machine. <em>SOCO</em>, <em>24</em>(14), 10657–10679. (<a
href="https://doi.org/10.1007/s00500-019-04572-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised multi-view learning machine is developed to process the corresponding semi-supervised multi-view data sets which consist of labeled and unlabeled instances. But in real-world applications, for a multi-view data set, only few instances are labeled with the limitation of manpower and cost. As a result, few prior knowledge which is necessary for the designing of a learning machine is provided. Moreover, in practice, different views and features play diverse discriminant roles while traditional learning machines treat these roles equally and assign the same weight just for convenience. In order to solve these problems, we introduce Universum learning to obtain more prior knowledge and assign different weights for views and features to reflect their diverse discriminant roles. The proposed learning machine is named as weight-and-Universum-based semi-supervised multi-view learning machine (WUSM). In WUSM, we first obtain weights of views and features. Then, we construct Universum set to obtain more prior knowledge on the basis of these weights. Different from traditional construction ways, the used construction way makes full use of the information of all labeled and unlabeled instances rather than only a pair of positive and negative training instances. Finally, we design the machine with the usage of the Universum set along with original data set. Our contributions are given as follows. (1) With the usage of all (labeled, unlabeled) instances of the data set, the Universum set provides more useful prior knowledge. (2) WUSM considers the diversities of views and features. (3) WUSM advances the development of semi-supervised multi-view learning machines. Experiments on bipartite ranking, feature selection, dimensionality reduction, classification, clustering, etc. validate the advantages of WUSM and draw a conclusion that with the introduction of Universum learning, view weights, and feature weights, the performance of a semi-supervised multi-view learning machine is boosted.},
  archive      = {J_SOCO},
  author       = {Zhu, Changming and Miao, Duoqian and Zhou, Rigui and Wei, Lai},
  doi          = {10.1007/s00500-019-04572-5},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10657-10679},
  shortjournal = {Soft Comput.},
  title        = {Weight-and-universum-based semi-supervised multi-view learning machine},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Partial discharge pattern analysis using multi-class support
vector machine to estimate cavity size and position in solid insulation.
<em>SOCO</em>, <em>24</em>(14), 10645–10656. (<a
href="https://doi.org/10.1007/s00500-019-04570-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial discharge (PD) measurement is used for a diagnosis and performance assessment of the solid insulation material inside the high-voltage (HV) equipment. PD measurement indicates the presence of voids, cracks and imperfection present in solid insulation material. The major problem associated with this measured PD signal is heavily contaminated by noise which results in reduction in PD pattern recognition. The objective of this work is to measure and de-noise the PD signal due to cavity and recognize two different size of cavities present in three different locations, namely near HV electrode, center and lower electrode. In first part, the measured PD signal is de-noised using translation invariant wavelet transform. In second part, the three-dimensional (φ–q–n) PD patterns are extracted from the de-noised PD data. Then, it is subjected to canny edge detection technique, and the features like horizontal and vertical fractal dimension averages are evaluated using fractal image compression-based semi-variance technique. For classification, multi-class nonlinear support vector machine has been proposed to classify position and size of the cavity based on the PD fingerprints. The findings of this proposed work can be used to design a solid basis for an recognition of cavity size and position in an electrical apparatus.},
  archive      = {J_SOCO},
  author       = {Vigneshwaran, B. and Willjuice Iruthayarajan, M. and Maheswari, R. V.},
  doi          = {10.1007/s00500-019-04570-7},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10645-10656},
  shortjournal = {Soft Comput.},
  title        = {Partial discharge pattern analysis using multi-class support vector machine to estimate cavity size and position in solid insulation},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Online adaptive PID tracking control of an aero-pendulum
using PSO-scaled fuzzy gain adjustment mechanism. <em>SOCO</em>,
<em>24</em>(14), 10629–10643. (<a
href="https://doi.org/10.1007/s00500-019-04568-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article is centered on the development of a robust position control and disturbance compensation strategy for a mechatronic aero-pendulum using the soft computing paradigm. The pendulum arm is rotated about its pivot via the thrust generated by two coaxial contra-rotating motorized propellers installed at its free end. The tracking error in arm’s angular position is fed to a multi-loop feedback controller. The proportional–integral–derivative (PID) controller, in the outer loop, stabilizes the arm at the reference position. The reference current control signals generated by the PID position controller are fed to two PI controllers, in the inner loop, that are responsible for regulating the current consumption of each motorized propeller. Initially, the fixed PID controller gains are evaluated by selecting the optimal value of the system’s closed-loop pole using the particle swarm optimization (PSO) algorithm. However, to mitigate the inefficacies of fixed gain controller and further enhance the system’s robustness against bounded exogenous disturbances and damping against oscillations, the closed-loop pole is dynamically adjusted via fuzzy inference system, after every sampling interval. The fuzzy membership functions are calibrated offline via PSO algorithm. The superior time optimal control behavior rendered by the proposed controller is validated by comparing its performance with fixed gain controller via credible real-time experiments.},
  archive      = {J_SOCO},
  author       = {Saleem, Omer and Rizwan, Mohsin and Zeb, Agha Ali and Ali, Abdul Hannan and Saleem, Muhammad Ahmad},
  doi          = {10.1007/s00500-019-04568-1},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10629-10643},
  shortjournal = {Soft Comput.},
  title        = {Online adaptive PID tracking control of an aero-pendulum using PSO-scaled fuzzy gain adjustment mechanism},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new hybrid discriminative/generative model using the
full-covariance multivariate generalized gaussian mixture models.
<em>SOCO</em>, <em>24</em>(14), 10611–10628. (<a
href="https://doi.org/10.1007/s00500-019-04567-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discriminative models have been shown to be more advantageous for pattern recognition problem in machine learning. For this study, the main focus is developing a new hybrid model that combines the advantages of a discriminative technique namely the support vector machines (SVM) with the full efficiency offered through covariance multivariate generalized Gaussian mixture models (MGGMM). This new hybrid MGGMM applies the Fisher and Kullback–Leibler kernels derived from MGGMM to improve the kernel function of SVM. This approach is based on two different learning techniques explicitly: the Fisher scoring algorithm and the Bayes inference technique based on Markov Chain Monte Carlo and Metropolis–Hastings algorithm. These learning methods work with two model selection approaches (minimum message length and marginal likelihood) to determine the number of clusters. The effectiveness of the framework is demonstrated through extensive experiments including synthetic datasets, facial expression recognition and human activity recognition.},
  archive      = {J_SOCO},
  author       = {Najar, Fatma and Bourouis, Sami and Bouguila, Nizar and Belghith, Safya},
  doi          = {10.1007/s00500-019-04567-2},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10611-10628},
  shortjournal = {Soft Comput.},
  title        = {A new hybrid discriminative/generative model using the full-covariance multivariate generalized gaussian mixture models},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A decomposition-based evolutionary algorithm with adaptive
weight adjustment for many-objective problems. <em>SOCO</em>,
<em>24</em>(14), 10597–10609. (<a
href="https://doi.org/10.1007/s00500-019-04565-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For many-objective optimization problems (MaOPs), how to get a set of solutions with good convergence and diversity is a difficult and challenging work. In this paper, a new decomposition-based evolutionary algorithm with adaptive weight adjustment is designed to obtain this goal. The proposed algorithm adopts the uniform design method to set the weight vectors which are uniformly distributed over the design space, and an adaptive weight adjustment is used to solve some MaOPs with complex Pareto optimal front (PF) (i.e., PF with a sharp peak of low tail or discontinuous PF). A selection strategy is used to help solutions to converge to the Pareto optimal solutions. Comparing with some efficient state-of-the-art algorithms, e.g., NSGAII-CE, MOEA/D and HypE, on some benchmark functions, the proposed algorithm is able to find more accurate Pareto front with better diversity.},
  archive      = {J_SOCO},
  author       = {Dai, Cai and Lei, Xiujuan and He, Xiaoguang},
  doi          = {10.1007/s00500-019-04565-4},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10597-10609},
  shortjournal = {Soft Comput.},
  title        = {A decomposition-based evolutionary algorithm with adaptive weight adjustment for many-objective problems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). High-gain observer-based sensorless control of a flywheel
energy storage system for integration with a grid-connected
variable-speed wind generator. <em>SOCO</em>, <em>24</em>(14),
10585–10596. (<a
href="https://doi.org/10.1007/s00500-019-04564-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces an induction machine-based flywheel energy storage system (FESS) for direct integration with a variable-speed wind generator (VSWG). The aim is to connect the FESS at the DC bus level of a permanent magnet synchronous generator-based VSWG in order to stabilize the DC bus voltage as well as the power flowing into the grid. A rotor flux-oriented control strategy is proposed for the FESS converter based on the actual speed of the flywheel rotor. Since mechanical speed sensors are prone to failure and increase the maintenance cost of the system, a sensorless technique is proposed to estimate the rotor speed through a specially synthesized high-gain observer (HGO). The proposed observer achieves accurate tracking of the flywheel speed and flux and reduces the adverse effects of variations in the rated rotor resistance. Simulation results obtained using the MATLAB-Simulink environment are presented to illustrate the theoretical synthesis and analysis of the proposed FOC and sensorless HGO control strategies.},
  archive      = {J_SOCO},
  author       = {Mansour, M. and Hadj Saïd, S. and Bendoukha, S. and Berrayana, W. and Mansouri, M. N. and Mimouni, M. F.},
  doi          = {10.1007/s00500-019-04564-5},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10585-10596},
  shortjournal = {Soft Comput.},
  title        = {High-gain observer-based sensorless control of a flywheel energy storage system for integration with a grid-connected variable-speed wind generator},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-dimensional particle swarm optimization for robust
blind image watermarking using intertwining logistic map and hybrid
domain. <em>SOCO</em>, <em>24</em>(14), 10561–10584. (<a
href="https://doi.org/10.1007/s00500-019-04563-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust blind watermarking has become a vital means of copyright protection, and this paper presents a new optimal robust and blind watermarking method of grayscale images based on intertwining logistic map and a variant of particle swarm optimization (PSO) in a hybrid domain. In the proposed approach, firstly a host image is decomposed by discrete wavelet transform, and discrete cosine transform (DCT) is applied to insensitive LH and HL subbands according to human visual model. Then, optimum frequency spectra in the DCT domain are chosen to form a feature matrix for improving the robustness and transparency of watermark. Finally, a shuffled watermark image using the chaotic logistic map is inserted by modifying the largest singular values of a feature matrix pair in the singular value decomposition domain. An improved version of PSO is employed to perform multi-dimensional optimization for selection of the most qualified DCT coefficients and estimation of watermark embedding strength in terms of their significant influence on imperceptibility and robustness. The security of the proposed method is provided by intertwining logistic map. Experimental results on standard test images indicate that PSO searches efficiently optimal values of watermark embedding strength and the most suitable DCT subbands, and the proposed watermarking algorithm performs much better than the other compared schemes in imperceptibility and robustness objectives.},
  archive      = {J_SOCO},
  author       = {Kang, Xiaobing and Chen, Yajun and Zhao, Fan and Lin, Guangfeng},
  doi          = {10.1007/s00500-019-04563-6},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10561-10584},
  shortjournal = {Soft Comput.},
  title        = {Multi-dimensional particle swarm optimization for robust blind image watermarking using intertwining logistic map and hybrid domain},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel multi-resolution representation for time series
sensor data analysis. <em>SOCO</em>, <em>24</em>(14), 10535–10560. (<a
href="https://doi.org/10.1007/s00500-019-04562-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evolution of IoT has increased the popularity of all types of sensing devices in a variety of industrial fields and has resulted in enormous growth in the volume of sensor data. Considering the high volume and dimensionality of sensor data, the ability to perform in-depth data analysis and data mining tasks directly on the raw time series sensor data is limited. To solve this problem, we propose a novel dimensional reduction and multi-resolution representation approach for time series sensor data. This approach utilizes an appropriate number of important data points (IDPs) within a certain time series sensor data to produce a corresponding multi-resolution piecewise linear representation (MPLR), called MPLR-IDP. The results of the theoretical analyses and experiments show that MPLR-IDP can reduce the dimensionality while maintaining the important characteristics of time series data. MPLR-IDP can represent the data in a more flexible way to meet diverse needs of different users.},
  archive      = {J_SOCO},
  author       = {Hu, Yupeng and Ji, Cun and Zhang, Qingke and Chen, Lin and Zhan, Peng and Li, Xueqing},
  doi          = {10.1007/s00500-019-04562-7},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10535-10560},
  shortjournal = {Soft Comput.},
  title        = {A novel multi-resolution representation for time series sensor data analysis},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A two-stage three-machine assembly scheduling problem with a
truncation position-based learning effect. <em>SOCO</em>,
<em>24</em>(14), 10515–10533. (<a
href="https://doi.org/10.1007/s00500-019-04561-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The two-stage assembly scheduling problem has a lot of applications in industrial and service sectors. Furthermore, truncation-based learning effects have received growing attention in connection with scheduling problems. However, it is relatively unexplored in the two-stage assembly scheduling problem. Therefore, we addressed the two-stage assembly with truncation learning effects with two machines in the first stage and an assembly machine in the second stage. The objective function was to complete all jobs as soon as possible (or to minimize the makespan). Due to the NP-hardness of the considered problem, we proposed several dominance relations and a lower bound for the branch-and-bound method for finding the optimal solution. Moreover, we proposed six versions of hybrids greedy iterative algorithm, where three versions of the local searches algorithm with and without a probability scheme are embedded. They include extraction and backward-shifted reinsertion, pairwise interchange and extraction and forward-shifted reinsertion for searching good-quality solutions. The experimental results of all proposed algorithms are presented on small-size and big-size jobs.},
  archive      = {J_SOCO},
  author       = {Azzouz, Ameni and Pan, Po-An and Hsu, Peng-Hsiang and Lin, Win-Chin and Liu, Shangchia and Ben Said, Lamjed and Wu, Chin-Chia},
  doi          = {10.1007/s00500-019-04561-8},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10515-10533},
  shortjournal = {Soft Comput.},
  title        = {A two-stage three-machine assembly scheduling problem with a truncation position-based learning effect},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal utilization of interconnected RESs to microgrid: A
hybrid AWO-ANFIS technique. <em>SOCO</em>, <em>24</em>(14), 10493–10513.
(<a href="https://doi.org/10.1007/s00500-019-04558-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This dissertation proposes an elite converter for the optimal utilization of hybrid renewable energy sources in the microgrid-associated systems using hybrid technique. Microgrid (MG)-associated systems are photovoltaic, wind turbine and battery. The proposed elite converter is the high conversion ratio (HCR) DC–DC converter with a maximum power point tracking (MPPT) controller. The main advantage of the converter is to eliminate the problem of high switch voltage stress. The proposed hybrid technique is the joint execution of both the adaptive whale optimization algorithm (AWOA) and adaptive neuro-fuzzy interference system (ANFIS), and hence, it is named as AWO-ANFIS technique. Here, AWOA technique is utilized to establish the exact control signals based on the power variation between the source side (renewable energy sources and battery) and load side. ANFIS technique is utilized for error minimization by using the achieved dataset from AWOA technique. Here, the reference currents of the controller are managed in view of the MPPT for solar and wind energy. In the proposed technique, the objective function is defined by the system data subject to equality and inequality constraints. Finally, the proposed technique is executed in the MATLAB/Simulink working platform and the execution is compared with the existing techniques. To test the performance of the proposed method, different case studies are conducted such as variation of irradiance under constant wind speed, variation of PV power under constant irradiance and load variation under constant irradiance and wind speed. For all the cases, the response of current, voltage and power of all the sources is analyzed and compared with that of the existing techniques such as GA, PSO and WOA. The statistical analysis of the proposed technique is also analyzed. Likewise, the computation time using various trails such as 100, 250, 500 and 1000 is also analyzed. The comparison results affirm that the proposed technique has less computational time than the exiting techniques. Moreover, the proposed method is cost-effective power production of MG and effective utilization of renewable energy source without wasting the available energy.},
  archive      = {J_SOCO},
  author       = {Padhmanabhaiyappan, S. and Karthik, R. and Ayyar, K.},
  doi          = {10.1007/s00500-019-04558-3},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10493-10513},
  shortjournal = {Soft Comput.},
  title        = {Optimal utilization of interconnected RESs to microgrid: A hybrid AWO-ANFIS technique},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new artificial bee colony algorithm-based color space for
fire/flame detection. <em>SOCO</em>, <em>24</em>(14), 10481–10492. (<a
href="https://doi.org/10.1007/s00500-019-04557-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image processing-based fire/flame detection has become popular in recent years. In this paper, a novel fire/flame detection system based on a new conversion matrix and artificial bee colony algorithm was presented. Flame and non-flame image pixel values were combined to have a new feature matrix. A conversion matrix was generated randomly. The conversion matrix was multiplied by the feature matrix. The error of this multiplication result was calculated using the K-means clustering algorithm. The conversion matrix was updated until getting desired performance using artificial bee colony algorithm. At the end of the updating process, updated conversion matrix was multiplied with all images in the dataset to move all images to new color space. The final images were converted into binary images. Otsu method was used to get binary images. These binary images were compared with the corresponding ground truth images in the dataset. The aim of this comparison is to calculate the similarity ratio of the two images. This ratio shows the extent to which the original image features are preserved. A forest fire dataset was used which has 500 forest fire images. It is publicly available and called as Corsican Fire Database. Jaccard and Dice similarity measure parameters were used to evaluate the proposed system performance and compared with other similar study such as particle swarm optimization. Evaluated mean Jaccard index value was 0.76, and mean Dice index value was 0.85. This evaluation was made for 500 images. These results provide that this system can be used in fire/flame detection systems.},
  archive      = {J_SOCO},
  author       = {Toptaş, Buket and Hanbay, Davut},
  doi          = {10.1007/s00500-019-04557-4},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10481-10492},
  shortjournal = {Soft Comput.},
  title        = {A new artificial bee colony algorithm-based color space for fire/flame detection},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Framework to forecast environment changes by optimized
predictive modelling based on rough set and elman neural network.
<em>SOCO</em>, <em>24</em>(14), 10467–10480. (<a
href="https://doi.org/10.1007/s00500-019-04556-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The techniques pertaining to soft computing are the base for commencement, model and organization of intelligent systems in order to offer more perfect, economical and realistic solution which has minimal complexity levels. The concept of intelligent systems has for long supported objectives on sustainability, improvisation of efficiency and symbolized various kinds of activities like creation of jobs, earning profits, providing services and improvement in capacities in ICT. The applications based on this system are widespread in the technological market because of massive development in grid, cloud, mobile and big data applications and its corresponding connectivity advantages. ICT triggers data scientists to satisfy technical-based demands of intelligent systems around data analytics and big data applications. The major features of big data like that of reservation of designs on information and knowledge have offered the public undertaking an opportunity to enhance production levels, improved efficiency and its effectiveness. The main objective of this paper is to enhance the accuracy of predictive modelling using an optimized predictive modelling based on rough set (RS) and Elman neural network (ElNN). These advanced predictive models are designed on the basis of RS approach in initial stages and in later processes enhanced with the support of Elman-NN. RS has an excellent feature selection capability, and Elman-NN is the best at nonlinear system modelling. By integrating them, the proposed method can limit the input dimension and optimize the structure for ElNN modelling. This can reduce the mathematical computation complexity with the progress of predictive models. The experimental results indicate that through RS feature selection and the structure of Elman-NN, the predictive model can be simplified significantly with enhanced model performance. The predictive accuracy of data sets, namely air quality in Northern Taiwan, hazardous air pollutants, historical hourly weather data and US pollutants through optimization, is above 99\%, and this model proves that the results of optimized predictive error are far better than those obtained by other neural networks like PCA-RBF, PCA-NN, FFNN-BP with PCA, MLR, FFNN-BP, ELM, SOM, RBF and ART2.},
  archive      = {J_SOCO},
  author       = {Selvi, S. and Chandrasekaran, M.},
  doi          = {10.1007/s00500-019-04556-5},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10467-10480},
  shortjournal = {Soft Comput.},
  title        = {Framework to forecast environment changes by optimized predictive modelling based on rough set and elman neural network},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An AdaBoost-modified classifier using stochastic diffusion
search model for data optimization in internet of things. <em>SOCO</em>,
<em>24</em>(14), 10455–10465. (<a
href="https://doi.org/10.1007/s00500-019-04554-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) depicts the network that contains the objects or the “things” that have been embedded along with the network connectivity, the sensors, electronics or the software that enables the objects to collect and exchange data. Wireless sensor networks (WSNs) connect different sensors/things to the Internet by means of a gateway which interfaces the concept of the WSN to the Internet. They have a certain trait that collects all sensed data and duly forwards it to a gateway using a one-way protocol. Huge amount of either unstructured or semi-structured data collected by the WSN is transmitted to IoT for processing. To improve the efficacy of the storing and processing of data, it is required to classify the data. Genetic algorithm is used to find optimal solutions in IoT. Stochastic diffusion search is a heuristic algorithm which has a robust mathematical model and is distributed. This work proposed a Stochastic AdaBoost algorithm for efficient classification of data obtained from WSN and IoT network.},
  archive      = {J_SOCO},
  author       = {Suganya, E. and Rajan, C.},
  doi          = {10.1007/s00500-019-04554-7},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10455-10465},
  shortjournal = {Soft Comput.},
  title        = {An AdaBoost-modified classifier using stochastic diffusion search model for data optimization in internet of things},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Solving energy management of renewable integrated microgrid
systems using crow search algorithm. <em>SOCO</em>, <em>24</em>(14),
10433–10454. (<a
href="https://doi.org/10.1007/s00500-019-04553-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to percolate energy management of microgrid systems by minimizing the generation cost of the same. Energy management of microgrid refers to the optimal sizing and scheduling of the distributed energy resources to reduce the generation cost and pollutant emission. A recently developed crow search algorithm (CSA) is implemented to execute the optimization. The proposed CSA imitates the crows’ memory and tactics of hiding and chasing their food. Six renewable integrated microgrid test systems and a total of eighteen different cases are considered for this study. Various practical complexities such as valve point loading effect, combined economic–emission dispatch using price penalty factor method, modeling of the renewable energy sources and energy storage systems are taken into consideration for energy management of the microgrid systems. Results obtained are then compared to a number of different soft computing techniques such as genetic algorithm and particle swarm optimization and the likes to justify the effectiveness of the proposed algorithm. A statistical analysis, viz. Wilcoxon signed-rank test, is performed to prove the superiority of the proposed approach over the various other optimization techniques used in the paper.},
  archive      = {J_SOCO},
  author       = {Dey, Bishwajit and Bhattacharyya, Biplab and Srivastava, Apoorv and Shivam, Kumar},
  doi          = {10.1007/s00500-019-04553-8},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10433-10454},
  shortjournal = {Soft Comput.},
  title        = {Solving energy management of renewable integrated microgrid systems using crow search algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Lion optimization algorithm (LOA)-based reliable emergency
message broadcasting system in VANET. <em>SOCO</em>, <em>24</em>(14),
10415–10432. (<a
href="https://doi.org/10.1007/s00500-019-04545-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In vehicular ad hoc network (VANET), the standard topology changes caused by the fast mobility of nodes create many challenges to the efficient data delivery in vehicular environment. The density-, mobility- and location-based dissemination technique can fulfill the needs of emergency message broadcasting. Emergency message broadcasting in both highway and urban scenarios has so many problems such as high reliability, low latency and scalability that remains unsolved. The road structure, message redundancy, channel contention are the major issues in urban scenarios. Usually, broadcast protocols for VANET use beacon messages, which is disseminated among the vehicles, in order to get neighborhood information. When the vehicles are next to each other trying to broadcast at the same time, this may lead to frequent contention and broadcast storms. On the other hand, in sparse density scenarios, vehicles have to face with failures in the message delivery. In our research, an adaptive scheduled partitioning and broadcasting technique (ASPBT) will be introduced for a reliable and efficient emergency message broadcasting. This protocol dynamically adjusts the number of partitions and beacon periodicity to reduce the number of retransmissions. In our proposed technique, partition sizes are determined using network density, and the transmission schedule for each partition is estimated using lion optimization algorithm (LOA). It is an optimization biologically inspired by the characteristics of lions. Its corporate and solitary behaviors such as prey capturing, roaming, mating and defense are helped to identify the optimal partition to broadcast the emergency messages first. To lower emergency message transmission delay and reduce message redundancy, ASPBT includes a novel forwarding node selection scheme that utilizes optimal partition, mini-slot and black burst to quickly select remote neighboring nodes, and a single forwarding node is successfully chosen by the asynchronous contention among them. Then, bidirectional broadcast, multi-directional broadcast and directional broadcast are designed according to the positions of the emergency message senders. ASPBT will work well in different network densities and both highway and urban scenarios. Our solid analytical evaluation and simulation results indicate that our proposed technique outperforms the existing broadcasting schemes in VANET in terms of efficiency, delay and reliability.},
  archive      = {J_SOCO},
  author       = {Selvi, M. and Ramakrishnan, B.},
  doi          = {10.1007/s00500-019-04545-8},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10415-10432},
  shortjournal = {Soft Comput.},
  title        = {Lion optimization algorithm (LOA)-based reliable emergency message broadcasting system in VANET},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hierarchical detection of abnormal behaviors in video
surveillance through modeling normal behaviors based on AUC
maximization. <em>SOCO</em>, <em>24</em>(14), 10401–10413. (<a
href="https://doi.org/10.1007/s00500-019-04544-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detection of abnormal behaviors is a challenging issue as there are disagreements over how abnormal behaviors should be defined. In this paper, a new method is proposed to estimate a model of normal behaviors and consequently to detect abnormal behaviors. Estimating a model of normal behaviors constitutes a main part of the training phase in detecting abnormal behaviors and is one of the main issues in the field. To estimate such a model, the histogram of the oriented optical flow (HOF) is first extracted as a local-based feature, and then, the proposed features of speed, variance of the trajectory and deviation from the trajectory are extracted as object-based features. Spectral clustering is used to cluster behavioral features that are similar. To design a classifier for estimating the model of normal behaviors in each cluster, a new method is proposed based on maximization of the area under the receiver operating characteristic curve (AUC). This new method does not need manual labeling for estimation of the model, and then, it carries out the estimation process in a semi-supervised fashion. In this paper, a method for hierarchical detection of abnormal behaviors based on the priority of the behavioral features is also proposed in the testing phase of the study. To this purpose, the existence of an abnormal behavior is hierarchically detected through using the HOF feature and the three object-based features of speed, variance of the trajectory and deviation from the trajectory. The distinguishing characteristic of the proposed method is that, as soon as the abnormal behavior is detected along the hierarchical application of the features, the process stops. The experimental results show that the proposed method can effectively detect the abnormal behaviors in several databases and achieve comparable performance to the state-of-the-art methods for detection of abnormal behaviors.},
  archive      = {J_SOCO},
  author       = {Feizi, Asghar},
  doi          = {10.1007/s00500-019-04544-9},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10401-10413},
  shortjournal = {Soft Comput.},
  title        = {Hierarchical detection of abnormal behaviors in video surveillance through modeling normal behaviors based on AUC maximization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The solution of direct and inverse fractional
advection–dispersion problems by using orthogonal collocation and
differential evolution. <em>SOCO</em>, <em>24</em>(14), 10389–10399. (<a
href="https://doi.org/10.1007/s00500-019-04541-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advection–dispersion phenomenon can be observed in various fields of science. Mathematically, this process can be studied by considering empirical models, high-order differential equations, and fractional differential equations. In this paper, a fractional model considered to represent the transport of passive tracers carried out by fluid flow in a porous media is studied both in the direct and inverse contexts. The studied mathematical model considers a one-dimensional fractional advection–dispersion equation with fractional derivative boundary conditions. The solutions of both direct and inverse problems are obtained by using the orthogonal collocation method and the differential evolution optimization algorithm approaches, respectively. In this case, the source term along the spatial and time coordinates is taken as a design variable. The obtained results with the solution of the direct problem are compared with those determined by using an implicit finite difference scheme. The results indicate that the proposed approach characterizes a promising methodology to solve the direct and inverse fractional advection–dispersion problems.},
  archive      = {J_SOCO},
  author       = {Lobato, F. S. and Lima, W. J. and Borges, R. A. and Cavalini, A. Ap. and Steffen, V.},
  doi          = {10.1007/s00500-019-04541-y},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10389-10399},
  shortjournal = {Soft Comput.},
  title        = {The solution of direct and inverse fractional advection–dispersion problems by using orthogonal collocation and differential evolution},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-item fuzzy economic production quantity model with
multiple deliveries. <em>SOCO</em>, <em>24</em>(14), 10363–10387. (<a
href="https://doi.org/10.1007/s00500-019-04539-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inventory control is one of the most critical issues in corporate management. Many mathematical models have been developed to optimize control strategies for the companies’ inventory. Economic production quantity (EPQ) is one of the classic models for inventory control, which is widely used. To deal with the uncertainty in the real world, we need to develop new and useful models for modeling systems of inventory management. In such cases, fuzzy models play a unique role in the field of inventory management. The main contribution of this study is to apply some well-known metaheuristic to solve an extended EPQ model based on fuzzy numbers considering multiple deliveries. This study aims to develop an EPQ model by considering demand as triangular fuzzy numbers and multiple deliveries (delivering in multiple packages) and by considering limitations in warehouse space as well as the total number of orders. Given these conditions, EPQ costs are calculated, and new modeling is presented. The obtained fuzzy model has been simplified by using the $$ \alpha{\text{-cut}} $$ and changing the variables, and finally, the most well-known metaheuristic algorithms, GA, PSO, GWO, and ICA, are applied in different problem sizes, and obtained results are analyzed in terms of minimizing cost function and CPU time. The result of this paper shows that GWO has superior performance in terms of various parameters.},
  archive      = {J_SOCO},
  author       = {Moghdani, Reza and Sana, Shib Sankar and Shahbandarzadeh, Hamid},
  doi          = {10.1007/s00500-019-04539-6},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10363-10387},
  shortjournal = {Soft Comput.},
  title        = {Multi-item fuzzy economic production quantity model with multiple deliveries},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Detection and classification of power quality disturbances
or events by adaptive NFS classifier. <em>SOCO</em>, <em>24</em>(14),
10351–10362. (<a
href="https://doi.org/10.1007/s00500-019-04538-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In power distributed generation system, analysis of power quality is a major issue and hence it is essential to implement an efficient power quality system. To address and end this issue, the proposed work is mainly focused on the detection and classification of power quality disturbances or events by applying Hilbert–Huang transform (HHT) technique. HHT technique is a novel signal processing algorithm that comprises two processes. First is the empirical mode decomposition (EMD), which is an iterative process where N number of power quality signals are decomposed into intrinsic mode functions (IMFs). The second process, Hilbert transform, is applied to each IMF component. The advantage of using these two processes makes it an attractive power tool for quality event analysis. Once the IMF is obtained, it is easy to construct a time–frequency representation model. Then, the significant features are extracted from amplitude, phase and frequency instantly, which are the contour of IMFs of each power quality disturbance. For classification, adaptive neuro-fuzzy system (NFS) classifier is used. It is an intelligent system used for the combination of neural network and fuzzy logic. Power quality features are given as input to the NFS system. The experimental simulation is conducted in a MATLAB environment, and proposed HHT has higher efficiency compared to existing methods.},
  archive      = {J_SOCO},
  author       = {Kiruthiga, B. and Narmatha Banu, R. and Devaraj, D.},
  doi          = {10.1007/s00500-019-04538-7},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10351-10362},
  shortjournal = {Soft Comput.},
  title        = {Detection and classification of power quality disturbances or events by adaptive NFS classifier},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Novel neutrality aggregation operator-based multiattribute
group decision-making method for single-valued neutrosophic numbers.
<em>SOCO</em>, <em>24</em>(14), 10327–10349. (<a
href="https://doi.org/10.1007/s00500-019-04535-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper aims to give some new kinds of operational laws named as neutrality addition and scalar multiplication for the pairs of single-valued neutrosophic numbers. The main idea behind these operations is to include the neutral characters of the decision-maker towards the preferences of the objects when it shows the equal degrees to membership functions. Some salient features of them are investigated also. Further based on these laws, some new aggregation operators are developed to aggregate the different preferences of the decision-makers. Desirable relations and properties are investigated in detail. Finally, a multiattribute group decision-making approach based on the proposed operators is presented and investigated with numerous numerical examples. The superiors, as well as the advantages of the operators, are also discussed in it.},
  archive      = {J_SOCO},
  author       = {Garg, Harish},
  doi          = {10.1007/s00500-019-04535-w},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10327-10349},
  shortjournal = {Soft Comput.},
  title        = {Novel neutrality aggregation operator-based multiattribute group decision-making method for single-valued neutrosophic numbers},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). From a quantum theory to a classical one. <em>SOCO</em>,
<em>24</em>(14), 10315–10325. (<a
href="https://doi.org/10.1007/s00500-020-04934-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present and discuss a formal approach for describing the quantum to classical crossover based on the group-theoretic construction of generalized coherent states. The method was originally introduced by Yaffe (Rev Mod Phys 54:407, 1982) in 1982 for tackling large-N quantum field theories and has been recently used for studying open quantum systems whose environment, while becoming macroscopic, may or may not display a classical behaviour (Liuzzo-Scorpo et al. in EPL (Europhys Lett) 111(4):40008, 2015; Rossi et al. in Phys Rev A 96:032116, 2017; Foti et al. in Quantum 3:179, 2019; Coppo in Schwarzschild black holes as macroscopic quantum systems, Università degli studi di Firenze, Florence, 2019). Referring to these recent developments, in this paper we provide the essential elements of Yaffe’s approach in the framework of standard quantum mechanics, so as to clarify how the approach can be used without referring to quantum field theory. Moreover, we address the role played by a possible global symmetry in making the large-N limit of the original quantum theory to flow into a formally well-defined classical theory, and we specifically consider the quantum-to-classical crossover of angular momentum. We also give details of a paradigmatic example, namely that of N free one-dimensional spinless particles. Finally, we discuss upon the foundational requirement that any classical description should ultimately be derived from an underlying quantum theory, that, however, is not, and should never be confused with, the one obtained via some quantization procedure of the classical description itself.},
  archive      = {J_SOCO},
  author       = {Coppo, A. and Cuccoli, A. and Foti, C. and Verrucchi, P.},
  doi          = {10.1007/s00500-020-04934-4},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10315-10325},
  shortjournal = {Soft Comput.},
  title        = {From a quantum theory to a classical one},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fuzzy representation of finite-valued quantum gates.
<em>SOCO</em>, <em>24</em>(14), 10305–10313. (<a
href="https://doi.org/10.1007/s00500-020-04870-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The theory of logical gates in quantum computation has inspired the development of new forms of quantum logic based on the following semantic idea: the meaning of a formula is identified with a quantum information quantity, represented by a density operator. At the same time, the logical connectives are interpreted as operations defined in terms of quantum gates. In this framework, some possible relations between fuzzy representations based on continuous t-norms for quantum gates and the probabilistic behavior of quantum computational finite-valued connectives are investigated. In particular, a fuzzy-type representation for quantum many-valued extensions of the gates introduced by Toffoli, Fredkin and Peres is described.},
  archive      = {J_SOCO},
  author       = {Leporini, Roberto and Bertini, Cesarino and Fabiani, Filippo Carone},
  doi          = {10.1007/s00500-020-04870-3},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10305-10313},
  shortjournal = {Soft Comput.},
  title        = {Fuzzy representation of finite-valued quantum gates},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On residuation in paraorthomodular lattices. <em>SOCO</em>,
<em>24</em>(14), 10295–10304. (<a
href="https://doi.org/10.1007/s00500-020-04699-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Paraorthomodular lattices are quantum structures of prominent importance within the framework of the logico-algebraic approach to (unsharp) quantum theory. However, at the present time it is not clear whether the above algebras may be regarded as the algebraic semantic of a logic in its own right. In this paper, we start the investigation of material implications in paraorthomodular lattices by showing that any bounded modular lattice with antitone involution $${\mathbf {A}}$$ can be converted into a left-residuated groupoid if it satisfies a strengthened form of regularity. Moreover, the above condition turns out to be also necessary whenever $${\mathbf {A}}$$ is distributive.},
  archive      = {J_SOCO},
  author       = {Chajda, I. and Fazio, D.},
  doi          = {10.1007/s00500-020-04699-w},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10295-10304},
  shortjournal = {Soft Comput.},
  title        = {On residuation in paraorthomodular lattices},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new method to predict the interference effect in
quantum-like bayesian networks. <em>SOCO</em>, <em>24</em>(14),
10287–10294. (<a
href="https://doi.org/10.1007/s00500-020-04693-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent researches on human decision-making behaviors reveal some interesting phenomenon which are difficult to be explained under the structure of classic probability theory. The quantum-like Bayesian networks, like many other quantum models, have been developed to solve this problem. Powerful as these models are to explain the experimental results, these models usually contain unknown quantum parameters. In quantum-like Bayesian networks, such parameters represent the interference between different decisions. In this paper, a heuristic method is proposed to measure the interference effect. The proposed model also has its connection with the original quantum-like Bayesian networks. The experimental data from several Prisoners dilemma games are used to test the proposed method. The testing results illustrate the efficiency of the proposed method.},
  archive      = {J_SOCO},
  author       = {Dai, Jiongyu and Deng, Yong},
  doi          = {10.1007/s00500-020-04693-2},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10287-10294},
  shortjournal = {Soft Comput.},
  title        = {A new method to predict the interference effect in quantum-like bayesian networks},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). How images combine meaning: Quantum entanglement in visual
perception. <em>SOCO</em>, <em>24</em>(14), 10277–10286. (<a
href="https://doi.org/10.1007/s00500-020-04692-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various empirical tests performed on human participants and also by means of search engines on the Web reveal that, whenever the conceptual combination The Animal Acts is considered as a combination of the individual concepts Animal and Acts, the ‘Clauser–Horne–Shimony–Holt’ version of Bell’s inequalities (‘CHSH inequality’) is violated. We work out in this paper a quantum representation in Hilbert space for a dataset collected on the same combination of concepts using ‘Google Images’ as search engine, which ‘significantly violated’ the CHSH inequality. This result proves the existence of non-classical structures in visual perception and strongly indicates the presence of ‘quantum entanglement’ as an explanation for the meaning connection between the component concepts, also when this meaning connection is expressed through images.},
  archive      = {J_SOCO},
  author       = {Arguëlles, Jonito Aerts and Sozzo, Sandro},
  doi          = {10.1007/s00500-020-04692-3},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10277-10286},
  shortjournal = {Soft Comput.},
  title        = {How images combine meaning: Quantum entanglement in visual perception},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evolution of quantum observables: From non-commutativity to
commutativity. <em>SOCO</em>, <em>24</em>(14), 10265–10276. (<a
href="https://doi.org/10.1007/s00500-019-04546-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A fundamental aspect of the quantum-to-classical limit is the transition from a non-commutative algebra of observables to commutative one. However, this transition is not possible if we only consider unitary evolutions. One way to describe this transition is to consider the Gamow vectors, which introduce exponential decays in the evolution. In this paper, we give two mathematical models in which this transition happens in the infinite time limit. In the first one, we consider operators acting on the space of the Gamow vectors, which represent quantum resonances. In the second one, we use an algebraic formalism from scattering theory. We construct a non-commuting algebra which commutes in the infinite time limit.},
  archive      = {J_SOCO},
  author       = {Fortin, S. and Gadella, M. and Holik, F. and Losada, M.},
  doi          = {10.1007/s00500-019-04546-7},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10265-10276},
  shortjournal = {Soft Comput.},
  title        = {Evolution of quantum observables: From non-commutativity to commutativity},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An equational theory for <span
class="math display"><em>σ</em></span>-complete orthomodular lattices.
<em>SOCO</em>, <em>24</em>(14), 10257–10264. (<a
href="https://doi.org/10.1007/s00500-019-04510-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The condition of $$\sigma $$-completeness related to orthomodular lattices places an important role in the study of quantum probability theory. In the framework of algebras with infinitary operations, an equational theory for the category of $$\sigma $$-complete orthomodular lattices is given. In this structure, we study the congruences theory and directly irreducible algebras establishing an equational completeness theorem. Finally, a Hilbert style calculus related to $$\sigma $$-complete orthomodular lattices is introduced and a completeness theorem is obtained.},
  archive      = {J_SOCO},
  author       = {Freytes, Hector},
  doi          = {10.1007/s00500-019-04510-5},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10257-10264},
  shortjournal = {Soft Comput.},
  title        = {An equational theory for $$\sigma $$-complete orthomodular lattices},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Quantum and quantum-like machine learning: A note on
differences and similarities. <em>SOCO</em>, <em>24</em>(14),
10247–10255. (<a
href="https://doi.org/10.1007/s00500-019-04429-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past few decades, researchers have extensively investigated the applications of quantum computation and quantum information to machine learning with remarkable results. This, in turn, has led to the emergence of quantum machine learning as a separate discipline, whose main goal is to transform standard machine learning algorithms into quantum algorithms which can be implemented on quantum computers. One further research programme has involved using quantum information to create new quantum-like algorithms for classical computers (Sergioli et al. in Int J Theor Phys 56(12):3880–3888, 2017; PLoS ONE 14:e0216224, 2019. https://doi.org/10.1371/journal.pone.0216224; Int J Quantum Inf 16(8):1840011, 2018a; Soft Comput 22(3):691–705, 2018b). This brief survey summarises and compares both approaches and also outlines the main motivations behind them.},
  archive      = {J_SOCO},
  author       = {Sergioli, Giuseppe},
  doi          = {10.1007/s00500-019-04429-x},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10247-10255},
  shortjournal = {Soft Comput.},
  title        = {Quantum and quantum-like machine learning: A note on differences and similarities},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Faithful orthogonal representations of graphs from partition
logics. <em>SOCO</em>, <em>24</em>(14), 10239–10245. (<a
href="https://doi.org/10.1007/s00500-019-04425-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partition logics often allow a dual probabilistic interpretation: a classical one for which probabilities lie on the convex hull of the dispersion-free weights and another one, suggested independently from the quantum Born rule, in which probabilities are formed by the (absolute) square of the inner product of state vectors with the faithful orthogonal representations of the respective graph. Two immediate consequences are the demonstration that the logico-empirical structure of observables does not determine the type of probabilities alone and that complementarity does not imply contextuality.},
  archive      = {J_SOCO},
  author       = {Svozil, Karl},
  doi          = {10.1007/s00500-019-04425-1},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10239-10245},
  shortjournal = {Soft Comput.},
  title        = {Faithful orthogonal representations of graphs from partition logics},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Violation of CHSH inequality and marginal laws in mixed
sequential measurements with order effects. <em>SOCO</em>,
<em>24</em>(14), 10231–10238. (<a
href="https://doi.org/10.1007/s00500-019-04186-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We model a typical Bell-test experimental situation by considering that Alice and Bob perform incompatible measurements in a sequential way, with mixed orders of execution. After emphasizing that order effects will generally produce a violation of the marginal laws, we derive an upper limit for the observed correlations. More precisely, when Alice’s and Bob’s measurements are compatible, the marginal laws are obeyed and Tsirelson’s bound limits the quantum correlations in the Bell-CHSH inequality to $$2\sqrt{2}$$. On the other hand, when Alice and Bob perform incompatible mixed sequential measurements, the marginal laws are typically violated and the upper limit for the correlations is pushed up to $$2\sqrt{3}$$. Considering that significant violations of the marginal laws (also called no-signaling conditions) have been observed in the data of numerous Bell-test experiments, the present analysis provides a possible mechanism for their appearance, when the protocols are such that Alice’s and Bob’s measurements can be assumed to be performed in a mixed sequential way. We, however, emphasize that this does not imply that a communication with superluminal effective speed would be possible.},
  archive      = {J_SOCO},
  author       = {Sassoli de Bianchi, Massimiliano},
  doi          = {10.1007/s00500-019-04186-x},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10231-10238},
  shortjournal = {Soft Comput.},
  title        = {Violation of CHSH inequality and marginal laws in mixed sequential measurements with order effects},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Explaining versus describing human decisions: Hilbert space
structures in decision theory. <em>SOCO</em>, <em>24</em>(14),
10219–10229. (<a
href="https://doi.org/10.1007/s00500-019-04140-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the impressive success of quantum structures to model long-standing human judgement and decision puzzles, the quantum cognition research programme still faces challenges about its explanatory power. Indeed, quantum models introduce new parameters, which may fit empirical data without necessarily explaining them. Also, one wonders whether more general non-classical structures are better equipped to model cognitive phenomena. In this paper, we provide a realistic–operational foundation of decision processes using a known decision-making puzzle, the Ellsberg paradox, as a case study. Then, we elaborate a novel representation of the Ellsberg decision situation applying standard quantum correspondence rules which map realistic–operational entities into quantum mathematical terms. This result opens the way towards an independent, foundational, rather than phenomenological, motivation for a general use of quantum Hilbert space structures in human cognition.},
  archive      = {J_SOCO},
  author       = {Sozzo, Sandro},
  doi          = {10.1007/s00500-019-04140-x},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10219-10229},
  shortjournal = {Soft Comput.},
  title        = {Explaining versus describing human decisions: Hilbert space structures in decision theory},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Special issue: Quantum structures and quantum information
theory. <em>SOCO</em>, <em>24</em>(14), 10215–10217. (<a
href="https://doi.org/10.1007/s00500-020-05082-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SOCO},
  author       = {Bosyk, G. M. and Freytes, H. and Holik, F. and Sergioli, G.},
  doi          = {10.1007/s00500-020-05082-5},
  journal      = {Soft Computing},
  number       = {14},
  pages        = {10215-10217},
  shortjournal = {Soft Comput.},
  title        = {Special issue: Quantum structures and quantum information theory},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A hybrid OpenFlow with intelligent detection and prediction
models for preventing BGP path hijack on SDN. <em>SOCO</em>,
<em>24</em>(13), 10205–10214. (<a
href="https://doi.org/10.1007/s00500-019-04534-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Border Gateway Protocol (BGP) is a path vector protocol whose fundamental aim is to exchange the information across the Internet, which directs data between autonomous systems. The significant drawback of the BGP is that it does not address security; path hijacking is one of the top-rated cyber hijacks. Existing methods such as sBGP, soBGP and PGBGP have focused more on detecting path hijacking rather than preventing. Hence, we propose an intelligent model to detect abnormal behavior of a network and to predict and prevent BGP path hijacking (DPPBGP) in software-defined networks. The main objective of our proposed model is to reduce detection time and the controller workload with SFlow-integrated OpenFlow. Three modules of our model are as follows: (1) Based on the abnormal behavior of the network, we evaluated the statistics. We use the statistic features in the cumulative sum abnormal detection algorithm to detect abnormal behavior and flows proficiently and perfectly with less detection time. (2) An intelligent machine learning approach knows as a Pattern Sequence Forecasting algorithm is used to forecast the behavior of the network. (3) After the detection or the forecast of abnormality, path hijack is prevented by killing the appropriate PID based on SFlow analyzer. Simulation results show how large the network of this model can perform accurately and effectively.},
  archive      = {J_SOCO},
  author       = {Pradeepa, R. and Pushpalatha, M.},
  doi          = {10.1007/s00500-019-04534-x},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {10205-10214},
  shortjournal = {Soft Comput.},
  title        = {A hybrid OpenFlow with intelligent detection and prediction models for preventing BGP path hijack on SDN},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). ACO-IM: Maximizing influence in social networks using ant
colony optimization. <em>SOCO</em>, <em>24</em>(13), 10181–10203. (<a
href="https://doi.org/10.1007/s00500-019-04533-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online social networks play an essential role in propagating information, innovation, and ideas via word-of-mouth spreading. This word-of-mouth phenomenon leads to a fundamental problem, known as influence maximization (IM) or subset selection problem. The IM problem aims to identify a small subset of users, viz. seed nodes such that overall influence spread can be maximized. The seed selection problem is NP-hard, unfortunately. A greedy solution of IM problem is not sufficient due to the use of time-consuming Monte Carlo simulations, which is limited to small-scale networks. However, the greedy solution ensures a good approximation guarantee. In this paper, a local influence evaluation heuristic is adopted to approximate local influence within the two-hope area. With this heuristic, an expected diffusion value under the traditional diffusion models is evaluated. To optimize local influence evaluation heuristic, an influence maximization algorithm based on ant colony optimization (ACO-IM) is presented. ACO-IM redefines the representation and updates the rule of pheromone deposited by ants and heuristic information. The algorithm uses the probabilistic environment to avoid premature convergence. Finally, the experimental results show the superiority of the proposed algorithm. The statistical tests are also performed to distinguish the proposed method from the state-of-the-art methods.},
  archive      = {J_SOCO},
  author       = {Singh, Shashank Sheshar and Singh, Kuldeep and Kumar, Ajay and Biswas, Bhaskar},
  doi          = {10.1007/s00500-019-04533-y},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {10181-10203},
  shortjournal = {Soft Comput.},
  title        = {ACO-IM: Maximizing influence in social networks using ant colony optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep perceptron neural network with fuzzy PID controller for
speed control and stability analysis of BLDC motor. <em>SOCO</em>,
<em>24</em>(13), 10161–10180. (<a
href="https://doi.org/10.1007/s00500-019-04532-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speed regulation is one of the significant characteristics to be adopted in the field of brushless DC motor drive for effective and accurate speed and position control operations. In this paper, stability analysis and performance characteristics of brushless direct current motor are studied and implemented with a new deep learning neural network—fuzzy-tuned proportional integral derivative (PID) speed controller. Deep learning architecture is designed for the multi-layer perceptron network, and the output from the neural module fires the rules of the fuzzy inference system mechanism. The parameters of deep perceptron neural network (DPNN) are tuned for near optimal solutions using the unified multi-swarm particle swarm optimization, and in turn the optimized DPNN selects the parameters of the fuzzy inference system. Deep learning neural network with the fuzzy inference system tunes the gain values of the PID controller and performs an effective speed regulation. The performance characteristics of the designed speed controller are tested for a step change in input speed and also for impulsive load disturbances. Further, the stability analysis of the new proposed controller is investigated with Lyapunov stability criterion by deriving the positive definite functions. The weight parameters of DPNN model and the number of rules of fuzzy system are tuned for their near optimal solutions using multi-swarm particle swarm optimization. From the results, it is well proven that the proposed controller is more stable and guarantees consistent performance than other considered controllers in all aspects. Simulation-based comparisons illustrate that the design methodologies outperform other controller designs from the literature.},
  archive      = {J_SOCO},
  author       = {Gobinath, S. and Madheswaran, M.},
  doi          = {10.1007/s00500-019-04532-z},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {10161-10180},
  shortjournal = {Soft Comput.},
  title        = {Deep perceptron neural network with fuzzy PID controller for speed control and stability analysis of BLDC motor},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Model uncertainty quantification for diagnosis of each main
coronary artery stenosis. <em>SOCO</em>, <em>24</em>(13), 10149–10160.
(<a href="https://doi.org/10.1007/s00500-019-04531-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the main causes of death in the world is coronary artery disease (CAD). CAD occurs when there is stenosis in one or more of the three major coronary arteries: right coronary artery (RCA), left circumflex (LCX) artery, and left anterior descending (LAD) artery. The gold standard or CAD diagnosis is angiography, but it is invasive, costly, and time consuming. Therefore, researchers continually seek new machine learning methods that can screen for CAD non-invasively. For reliable and cost-effective CAD diagnosis, several algorithms have been developed. Most prior studies analyzed the presence or absence of CAD in a dichotomous manner. Herein, we studied the more complex problem of classification of stenosis in individual LAD, LCX, and RCA by applying machine learning algorithms on the Z-Alizadeh Sani dataset that comprised 303 subjects, each with 54 features. In addition, our new methodology is developed to handle model uncertainty in the prediction of individual artery stenosis. It uses the hyperplane distance from a sample and accuracy rate of the classifier during the training phase to enhance its performance. Our results demonstrate high diagnostic performance of the proposed method for diagnosis of stenosis in individual RCA, LCX, and LAD, achieving accuracy rates of 82.67\%, 83.67\% and 86.43\%, respectively. This is the best performance of ML techniques applied to the Z-Alizadeh Sani dataset.},
  archive      = {J_SOCO},
  author       = {Alizadehsani, Roohallah and Roshanzamir, Mohamad and Abdar, Moloud and Beykikhoshk, Adham and Zangooei, Mohammad Hossein and Khosravi, Abbas and Nahavandi, Saeid and Tan, Ru San and Acharya, U. Rajendra},
  doi          = {10.1007/s00500-019-04531-0},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {10149-10160},
  shortjournal = {Soft Comput.},
  title        = {Model uncertainty quantification for diagnosis of each main coronary artery stenosis},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Uncertain interval programming model for multi-objective
multi-item fixed charge solid transportation problem with budget
constraint and safety measure. <em>SOCO</em>, <em>24</em>(13),
10123–10147. (<a
href="https://doi.org/10.1007/s00500-019-04526-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents uncertain interval programming models for multi-objective multi-item fixed charge solid transportation problem with budget constraint and safety measure (MOMIFCSTPBCSM). The human languages usually involve imperfect or unknown information and are in the lack of certainty, and often, it is impossible to exactly describe an existing state or a future outcome. In using the probability theory, we must have enough historical information to estimate the probability distributions and in the case of fuzzy theory, we must have a trustworthy membership function, which is not easy to do. Thus, we often estimate the degree of belief with some hesitation that each condition may occur. To deal with such a situation, the uncertain interval theory may be very useful. Based on these facts, the parameters of the formulated problem are chosen as uncertain intervals. We consider unit transportation costs, fixed charges, transportation times, deterioration of items, supplies at origins, demands at destinations, conveyance capacities, budget at each destination, selling prices and purchasing costs, and we assume the safety factor and the desired safety measure are interval uncertain parameters. To formulate the proposed MOMIFCSTPBCSM, we use interval theory and uncertain programming techniques to develop two different models: an Expected Value Model and a Chance-Constrained Model. The equivalent deterministic models are formulated and solved using a linear weighted method, a fuzzy programming method and the goal programming method.},
  archive      = {J_SOCO},
  author       = {Sifaoui, Thiziri and Aïder, Méziane},
  doi          = {10.1007/s00500-019-04526-x},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {10123-10147},
  shortjournal = {Soft Comput.},
  title        = {Uncertain interval programming model for multi-objective multi-item fixed charge solid transportation problem with budget constraint and safety measure},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Writer identification system for pre-segmented offline
handwritten devanagari characters using k-NN and SVM. <em>SOCO</em>,
<em>24</em>(13), 10111–10122. (<a
href="https://doi.org/10.1007/s00500-019-04525-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A biometric identification system based on single and multiple modalities has been an evolving concept for solving criminal issues, security and privacy maintenance and for checking the authentication of an individual. The writer identification system is a type of biometric identification in which handwriting of an individual is taken as a biometric identifier. It is a system in which the writer can be identified based on his handwritten text. These systems employ machine learning and pattern recognition algorithms for the generation of a framework. In this paper, the authors have presented a novel system for the writer identification based upon the pre-segmented characters of Devanagari script and also presenting comprehensive state-of-the-art work. The experiment is performed on the corpus consisting of five copies of each character of Devanagari script written by 100 different writers, selected randomly at the public places and consisting of total 24,500 samples of Devanagari characters. Four feature extraction methodologies such as zoning, diagonal, transition and peak extent-based features and classification methods such as k-NN and linear SVM are used with identification accuracy of 91.53\% when using zoning, transition and peak extent-based features with a linear SVM classifier.},
  archive      = {J_SOCO},
  author       = {Dargan, Shaveta and Kumar, Munish and Garg, Anupam and Thakur, Kutub},
  doi          = {10.1007/s00500-019-04525-y},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {10111-10122},
  shortjournal = {Soft Comput.},
  title        = {Writer identification system for pre-segmented offline handwritten devanagari characters using k-NN and SVM},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Development of an intuitionistic fuzzy ranking model for
nontraditional machining processes. <em>SOCO</em>, <em>24</em>(13),
10095–10110. (<a
href="https://doi.org/10.1007/s00500-019-04523-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nontraditional machining processes (NTMPs) are capable of processing very small parts, producing intricate geometries, operating on very narrow machining areas and machining high strength materials. These capabilities lead to a very diverse and large application area for NTMPs. Such a diverse and large application area along with more than one hundred NTMPs requires development of systematic and comprehensive models to help manufacturing engineers in their NTMP selection decisions. Furthermore, fuzzy models instead of crisp ones are being used in the literature in recent years to represent preferences of decision makers more realistically. This study proposes intuitionistic and triangular fuzzy NTMP ranking models and compares their ranking results with the crisp ranking model. The comparisons show that there are statistically significant differences among all three ranking models’ NTMP ranking results.},
  archive      = {J_SOCO},
  author       = {Yurdakul, Mustafa and İç, Yusuf Tansel and Atalay, Kumru Didem},
  doi          = {10.1007/s00500-019-04523-0},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {10095-10110},
  shortjournal = {Soft Comput.},
  title        = {Development of an intuitionistic fuzzy ranking model for nontraditional machining processes},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An enhanced cuckoo optimization algorithm for task graph
scheduling in cluster-computing systems. <em>SOCO</em>, <em>24</em>(13),
10075–10093. (<a
href="https://doi.org/10.1007/s00500-019-04520-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimized task scheduling is key to achieve high performance in the cluster-computing systems whose application is broad ranging from scientific to the military purposes. This combinatorial problem is NP-hard from the time complexity perspective, where applying newly proposed metaheuristics to it deserves further investigation based on the well-known no-free-lunch theorem. Accordingly, in this paper, an enhanced version of cuckoo optimization algorithm (COA) named E-COA is proposed to cope with the static task scheduling problem in the mesh topology cluster-computing environments. The proposed approach is equipped with an efficient adaptive semi-stochastic egg-laying strategy that significantly improves the local and global search potentiality of the basic COA. The experiments on a comprehensive set of randomly generated task graphs with different structural parameters reveal the efficiency of the proposed approach from the performance point of view, especially for the small-scale samples, and where the number of clusters in the machine is very restricted, i.e., we are in the lack of computational resource.},
  archive      = {J_SOCO},
  author       = {Boveiri, Hamid Reza},
  doi          = {10.1007/s00500-019-04520-3},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {10075-10093},
  shortjournal = {Soft Comput.},
  title        = {An enhanced cuckoo optimization algorithm for task graph scheduling in cluster-computing systems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fuzzy linear programming problems: Models and solutions.
<em>SOCO</em>, <em>24</em>(13), 10043–10073. (<a
href="https://doi.org/10.1007/s00500-019-04519-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate various types of fuzzy linear programming problems based on models and solution methods. First, we review fuzzy linear programming problems with fuzzy decision variables and fuzzy linear programming problems with fuzzy parameters (fuzzy numbers in the definition of the objective function or constraints) along with the associated duality results. Then, we review the fully fuzzy linear programming problems with all variables and parameters being allowed to be fuzzy. Most methods used for solving such problems are based on ranking functions, $$\alpha $$-cuts, using duality results or penalty functions. In these methods, authors deal with crisp formulations of the fuzzy problems. Recently, some heuristic algorithms have also been proposed. In these methods, some authors solve the fuzzy problem directly, while others solve the crisp problems approximately.},
  archive      = {J_SOCO},
  author       = {Ghanbari, Reza and Ghorbani-Moghadam, Khatere and Mahdavi-Amiri, Nezam and De Baets, Bernard},
  doi          = {10.1007/s00500-019-04519-w},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {10043-10073},
  shortjournal = {Soft Comput.},
  title        = {Fuzzy linear programming problems: Models and solutions},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptive population structure learning in evolutionary
multi-objective optimization. <em>SOCO</em>, <em>24</em>(13),
10025–10042. (<a
href="https://doi.org/10.1007/s00500-019-04518-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Some recent research shows that in multi-objective evolutionary algorithms (MOEAs), mating with similar individuals can improve the quality of new solutions and accelerate the convergence of algorithms. Based on the above finding, some clustering-based mating restriction strategies are proposed. However, those clustering algorithms are not suitable for the population with non-convex structures. Therefore, it may fail to detect population structure in different evolutionary stages. To solve this problem, we propose a normalized hypervolume-based mating transformation strategy (NMTS). In NMTS, the population structure is detected by K-nearest-neighbor graph and spectral clustering before and after the mating transformation condition, respectively. And the parent solutions are chosen according to the founded population structure. The proposed algorithm has been applied to a number of test instances with complex Pareto optimal solution sets or Pareto fronts, and compared with some state-of-the-art MOEAs. The results have demonstrated its advantages over other algorithms.},
  archive      = {J_SOCO},
  author       = {Wang, Shuai and Zhang, Hu and Zhang, Yi and Zhou, Aimin},
  doi          = {10.1007/s00500-019-04518-x},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {10025-10042},
  shortjournal = {Soft Comput.},
  title        = {Adaptive population structure learning in evolutionary multi-objective optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new intelligent fault diagnosis method for bearing in
different speeds based on the FDAF-score algorithm, binary particle
swarm optimization, and support vector machine. <em>SOCO</em>,
<em>24</em>(13), 10005–10023. (<a
href="https://doi.org/10.1007/s00500-019-04516-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new hybrid intelligent technique is presented based on the improvement in the feature selection method for multi-fault classification. The bearing conditions used in this study include healthy condition, defective inner ring, defective outer ring, and the faulty rolling element at different rotating motor speeds. To form the feature matrix, at first, the vibration signals are decomposed using empirical mode decomposition and wavelet packet decomposition. Then, the time and frequency domain features are extracted from the raw signals and the components are obtained from the signal decomposition. The high-dimensional feature matrix leads to increasing the computational complexity and reducing the efficiency in the classification accuracy of faults. Therefore, in the first stage of the feature selection process, the redundant and unnecessary features are eliminated by the FDAF-score feature selection method and the preselected feature set is formed. The FDAF-score technique is a combination of both F-score and Fisher discriminate analysis (FDA) algorithms. Since there may exist the features that are not susceptible to the presence of faults, the binary particle swarm optimization (BPSO) algorithm and the support vector machine (SVM) are used to select the optimal features from the preselected features. The BPSO algorithm is used to determine the optimal feature set and SVM classifier parameters so that the predictive error of the bearing conditions and the number of selected features are minimized. The results obtained in this paper demonstrate that the selected features are able to differentiate the different bearing conditions at various speeds. Comparing the results of this article with other fault detection methods indicates the ability of the proposed method.},
  archive      = {J_SOCO},
  author       = {Nezamivand Chegini, Saeed and Bagheri, Ahmad and Najafi, Farid},
  doi          = {10.1007/s00500-019-04516-z},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {10005-10023},
  shortjournal = {Soft Comput.},
  title        = {A new intelligent fault diagnosis method for bearing in different speeds based on the FDAF-score algorithm, binary particle swarm optimization, and support vector machine},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). EEG signal classification using LSTM and improved neural
network algorithms. <em>SOCO</em>, <em>24</em>(13), 9981–10003. (<a
href="https://doi.org/10.1007/s00500-019-04515-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural network (NN) finds role in variety of applications due to combined effect of feature extraction and classification availability in deep learning algorithms. In this paper, we have chosen SVM, logistic regression machine learning algorithms and NN for EEG signal classification. Two-layer LSTM and four-layer improved NN deep learning algorithms are proposed to improve the performance in EEG classification. Novelty lies in one-dimensional gradient descent activation functions with radial basis operations used in the initial layers of improved NN which help in achieving better performance. Statistical features namely mean, standard deviation, kurtosis and skewness are extracted for input EEG collected from Bonn database and then applied for various classification techniques. Accuracy, precision, recall and F1 score are the performance metrics used for analyzing the algorithms. Improved NN and LSTM give better performance compared to all other architectures. The simulations are carried out with variety of activation functions, optimizers and loss models to analyze the performance using Python in keras.},
  archive      = {J_SOCO},
  author       = {Nagabushanam, P. and Thomas George, S. and Radha, S.},
  doi          = {10.1007/s00500-019-04515-0},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {9981-10003},
  shortjournal = {Soft Comput.},
  title        = {EEG signal classification using LSTM and improved neural network algorithms},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Some distance measures for type 2 hesitant fuzzy sets and
their applications to multi-criteria group decision-making problems.
<em>SOCO</em>, <em>24</em>(13), 9965–9980. (<a
href="https://doi.org/10.1007/s00500-019-04509-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fuzzy set has an important role in the modeling of uncertainties. However, the fuzzy set is not sufficient in modeling of the problems, when the decision makers do not have the same opinion about membership degree of an element. To overcome this problem, the concept of hesitant fuzzy set was defined by Torra and Narukawa. Recently, the concept of the type 2 hesitant fuzzy set was defined by Feng and a ranking method among elements of a type 2 hesitant fuzzy element was given. In this paper, firstly, we point out some shortcomings in the ranking method given by Feng and then we give a new ranking method among elements of a type 2 hesitant fuzzy element. The distance and similarity measures are the effective mathematical tools to solve the problems such as medical diagnosis, decision making, pattern recognition and marketing strategy selection. Therefore, we introduce some distance measure methods between two type 2 hesitant fuzzy sets based on Hamming, Euclidean and Hausdorff distance measures. We obtain some properties of the proposed distance measure methods. We also develop a multi-criteria group decision-making method by integrating the TOPSIS method and the proposed distance measure methods under the type 2 hesitant fuzzy environment. Furthermore, we present a numerical example of multi-criteria group decision-making problem to choose the best alternative among firms to invest in order to illustrate the process and validate of the proposed method.},
  archive      = {J_SOCO},
  author       = {Özlü, Şerif and Karaaslan, Faruk},
  doi          = {10.1007/s00500-019-04509-y},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {9965-9980},
  shortjournal = {Soft Comput.},
  title        = {Some distance measures for type 2 hesitant fuzzy sets and their applications to multi-criteria group decision-making problems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Application of gene expression programming and sensitivity
analyses in analyzing effective parameters in gastric cancer tumor size
and location. <em>SOCO</em>, <em>24</em>(13), 9943–9964. (<a
href="https://doi.org/10.1007/s00500-019-04507-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gastric cancer (GC) is the third reason for cancer-related deaths in the world. The late referral of patients to medical centers in an advanced stage can make the treatment procedure more difficult. Accurate diagnosis of risk factors in GC tumor size and tumor location can lead to taking preventive measures or determining a suitable treatment strategy. This study aims to present a general model to identify the correlation of different parameters in a GC tumor place and tumor size. The medical documents of GC patients consist of the dataset of this study. The effect of seven main parameters, namely age, smoking, Helicobacter pylori (H. pylori) infection, job, surgical background, sex, and nodal stage is investigated in GC tumor location and tumor size. By considering all the medical documents, data modeling is conducted using gene expression programming because of the high precision of model output. In the following, three different sensitivity analysis methods (Morris, Distributed Evaluation of Local Sensitivity Analysis (DELSA), and Sobol’–Jansen) are applied to determine the influential factors in the tumor size and location. Results show that in sequence, sex, age, and H. pylori records mostly affect tumor location; the nodal stage, smoking, and surgery record mostly affect tumor size. This method can help in identifying effective parameters and prevention of patients’ death in all types of diseases, even for terminal illnesses.},
  archive      = {J_SOCO},
  author       = {Dorosti, Shadi and Jafarzadeh Ghoushchi, Saeid and Sobhrakhshankhah, Elham and Ahmadi, Mohsen and Sharifi, Abbas},
  doi          = {10.1007/s00500-019-04507-0},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {9943-9964},
  shortjournal = {Soft Comput.},
  title        = {Application of gene expression programming and sensitivity analyses in analyzing effective parameters in gastric cancer tumor size and location},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Fuzzy portfolio optimization for time-inconsistent
investors: A multi-objective dynamic approach. <em>SOCO</em>,
<em>24</em>(13), 9927–9941. (<a
href="https://doi.org/10.1007/s00500-019-04504-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, fuzzy optimization has been widely adopted to handle the nonstatistical uncertainties in portfolio selection. Meanwhile, various risk measurements, including variance, entropy and value at risk, have been introduced in fuzzy environments to evaluate portfolio risks from different perspectives. In this study, we discuss fuzzy multi-objective dynamic portfolio optimization for time-inconsistent investors. When building the model, variance and value at risk as the representatives of different types of risk measurements are employed together with the expected return. And a dynamic investment policy is developed for time-inconsistent investors, which combines the expected return and value at risk into one objective. Then, the model is established to maximize the cumulative combined objective function and minimize the cumulative portfolio variance simultaneously. In addition, a multi-objective dynamic evolutionary algorithm is designed as a possible solution of the proposed model. The effectiveness of this research is demonstrated by using a real market data-based case study. Experimental results demonstrate that the proposed model matches the practical behavior of time-inconsistent investors and the solution algorithm is feasible to solve the complicated nonlinear problem.},
  archive      = {J_SOCO},
  author       = {Li, You and Wang, Bo and Fu, Anrui and Watada, Junzo},
  doi          = {10.1007/s00500-019-04504-3},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {9927-9941},
  shortjournal = {Soft Comput.},
  title        = {Fuzzy portfolio optimization for time-inconsistent investors: A multi-objective dynamic approach},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Integration of nonparametric fuzzy classification with an
evolutionary-developmental framework to perform music sentiment-based
analysis and composition. <em>SOCO</em>, <em>24</em>(13), 9875–9925. (<a
href="https://doi.org/10.1007/s00500-019-04503-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past years, several approaches have been developed to create algorithmic music composers. Most existing solutions focus on composing music that appears theoretically correct or interesting to the listener. However, few methods have targeted sentiment-based music composition: generating music that expresses human emotions. The few existing methods are restricted in the spectrum of emotions they can express (usually to two dimensions: valence and arousal) as well as the level of sophistication of the music they compose (usually monophonic, following translation-based, predefined templates or heuristic textures). In this paper, we introduce a new algorithmic framework for autonomous music sentiment-based expression and composition, titled MUSEC, that perceives an extensible set of six primary human emotions (e.g., anger, fear, joy, love, sadness, and surprise) expressed by a MIDI musical file and then composes (creates) new polyphonic (pseudo) thematic, and diversified musical pieces that express these emotions. Unlike existing solutions, MUSEC is: (i) a hybrid crossover between supervised learning (SL, to learn sentiments from music) and evolutionary computation (for music composition, MC), where SL serves at the fitness function of MC to compose music that expresses target sentiments, (ii) extensible in the panel of emotions it can convey, producing pieces that reflect a target crisp sentiment (e.g., love) or a collection of fuzzy sentiments (e.g., 65\% happy, 20\% sad, and 15\% angry), compared with crisp-only or two-dimensional (valence/arousal) sentiment models used in existing solutions, (iii) adopts the evolutionary-developmental model, using an extensive set of specially designed music-theoretic mutation operators (trille, staccato, repeat, compress, etc.), stochastically orchestrated to add atomic (individual chord-level) and thematic (chord pattern-level) variability to the composed polyphonic pieces, compared with traditional evolutionary solutions producing monophonic and non-thematic music. We conducted a large battery of tests to evaluate MUSEC’s effectiveness and efficiency in both sentiment analysis and composition. It was trained on a specially constructed set of 120 MIDI pieces, including 70 sentiment-annotated pieces: the first significant dataset of sentiment-labeled MIDI music made available online as a benchmark for future research in this area. Results are encouraging and highlight the potential of our approach in different application domains, ranging over music information retrieval, music composition, assistive music therapy, and emotional intelligence.},
  archive      = {J_SOCO},
  author       = {Abboud, Ralph and Tekli, Joe},
  doi          = {10.1007/s00500-019-04503-4},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {9875-9925},
  shortjournal = {Soft Comput.},
  title        = {Integration of nonparametric fuzzy classification with an evolutionary-developmental framework to perform music sentiment-based analysis and composition},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Trade credit policy of an inventory model with imprecise
variable demand: An ABC-GA approach. <em>SOCO</em>, <em>24</em>(13),
9857–9874. (<a
href="https://doi.org/10.1007/s00500-019-04502-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this research work, an inventory model with fuzzy promotional effort induced dynamic demand under two level partial trade credit policy has been developed in an imprecise planning horizon. Here, it is assumed that in the planning horizon a retailer completed a finite number full cycles. In each of the retailer’s cycle, a wholesaler offers a credit period to the retailer on the full purchased amount and in turn the retailer offers a credit period to its customers on a part of his/her purchased amount. The imprecise marketing demand is influenced by the retailer’s fuzzy promotional effort, customers’ credit period, customers’ credit amount and retail selling price. Goal of this study is to find the optimal business strategy for the retailer with respect to his/her total fuzzy financial gain from the system. Due to imprecise nature of the demand, the problem is mathematically represented following fuzzy differential equation and fuzzy Riemann integration and alpha-cut of the entire fuzzy gain from the system is derived. Its graded mean integration representation is computed and optimized with respect to customer’s credit amount credit period, and retailer’s order quantity for most appropriate marketing decision. Hence, the problem reduced to a multivariate crisp optimization problem and a heuristic, multichoice artificial bee genetic algorithm (MCABGA) has been proposed for it. The efficiency of MCABGA is tested against some other existing artificial bee colony variants using a list of benchmark test functions available in the literature. The model is illustrated with some hypothetical test problems and some managerial insights are outlined. Finally, a conclusion is drawn and some future research directions are proposed.},
  archive      = {J_SOCO},
  author       = {Pramanik, Prasenjit and Maiti, Manas Kumar},
  doi          = {10.1007/s00500-019-04502-5},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {9857-9874},
  shortjournal = {Soft Comput.},
  title        = {Trade credit policy of an inventory model with imprecise variable demand: An ABC-GA approach},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An ensemble based on neural networks with random weights for
online data stream regression. <em>SOCO</em>, <em>24</em>(13),
9835–9855. (<a
href="https://doi.org/10.1007/s00500-019-04499-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most information sources in the current technological world are generating data sequentially and rapidly, in the form of data streams. The evolving nature of processes may often cause changes in data distribution, also known as concept drift, which is difficult to detect and causes loss of accuracy in supervised learning algorithms. As a consequence, online machine learning algorithms that are able to update actively according to possible changes in the data distribution are required. Although many strategies have been developed to tackle this problem, most of them are designed for classification problems. Therefore, in the domain of regression problems, there is a need for the development of accurate algorithms with dynamic updating mechanisms that can operate in a computational time compatible with today’s demanding market. In this article, the authors propose a new bagging ensemble approach based on neural network with random weights for online data stream regression. The proposed method improves the data prediction accuracy as well as minimises the required computational time compared to a recent algorithm for online data stream regression from literature. The experiments are carried out using four synthetic datasets to evaluate the algorithm’s response to concept drift, along with four benchmark datasets from different industries. The results indicate improvement in data prediction accuracy, effectiveness in handling concept drift, and much faster updating times compared to the existing available approach. Additionally, the use of design of experiments as an effective tool for hyperparameter tuning is demonstrated.},
  archive      = {J_SOCO},
  author       = {de Almeida, Ricardo and Goh, Yee Mey and Monfared, Radmehr and Steiner, Maria Teresinha Arns and West, Andrew},
  doi          = {10.1007/s00500-019-04499-x},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {9835-9855},
  shortjournal = {Soft Comput.},
  title        = {An ensemble based on neural networks with random weights for online data stream regression},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multilayer perceptron neural networking for prediction of
quality attributes of spray-dried vegetable oil powder. <em>SOCO</em>,
<em>24</em>(13), 9821–9833. (<a
href="https://doi.org/10.1007/s00500-019-04494-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, the multilayer perceptron (MLP) artificial neural networks (ANN) method was used to predict the various physiochemical attributes based on spray drying conditions for microencapsulated synergistic vegetable oil blend. This article also presents comparative studies between an MLP ANN and response surface methodology (RSM) in the modelling and prediction of quality attributes of microencapsulated oil blend. The MLP ANN was trained using experimental data comprising of inlet temperature and feed rate as input parameters with a set of quality attributes, viz. microencapsulation efficiency, peroxide value, moisture content, bulk density, colour, hygroscopicity and porosity as output responses with one hidden layer of three units. A good relationship was established between measured and predicted values with MLP topology. The final selected ANN model was compared to the RSM model for its modelling and predictive abilities based on performance indices, viz. RMSE, MAE and R2 for each output responses. The developed neural network was able to predict efficiently different physico-chemical parameters studied for the microencapsulated vegetable oil blend with a R2 values ranging between 0.75 and 0.98. The overall relative error during training (0.75) and testing (0.55) obtained was also satisfactory. Thus, MLP neural networking can be regarded as an efficient tool for the investigation, approximation and prediction of the microencapsulated characteristics of the vegetable oil blend.},
  archive      = {J_SOCO},
  author       = {Ghosh, Mousumi and Srivastava, Shubhangi and Raigar, Rakesh Kumar and Mishra, Hari Niwas},
  doi          = {10.1007/s00500-019-04494-2},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {9821-9833},
  shortjournal = {Soft Comput.},
  title        = {Multilayer perceptron neural networking for prediction of quality attributes of spray-dried vegetable oil powder},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A robust control of a class of induction motors using rough
type-2 fuzzy neural networks. <em>SOCO</em>, <em>24</em>(13), 9809–9819.
(<a href="https://doi.org/10.1007/s00500-019-04493-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new adaptive control method is presented for a class of induction motors. The dynamics of the system are assumed to be unknown and also are perturbed by some disturbances such as variation of load torque and rotor resistance. A type-2 fuzzy system based on rough neural network (T2FRNN) is proposed to estimate uncertainties. The parameters of T2FRNN are adjusted based on the adaptation laws which are obtained from Lyaponuv stability analysis. The effects of the uncertainties and the approximation errors are compensated by the proposed control method. Simulation results verify the good performance of the proposed control method. Also a numerical comparison is provided to show the effectiveness of the proposed fuzzy system.},
  archive      = {J_SOCO},
  author       = {Sabzalian, Mohammad Hosein and Mohammadzadeh, Ardashir and Lin, Shuyi and Zhang, Weidong},
  doi          = {10.1007/s00500-019-04493-3},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {9809-9819},
  shortjournal = {Soft Comput.},
  title        = {A robust control of a class of induction motors using rough type-2 fuzzy neural networks},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Growing neural gas with random projection method for
high-dimensional data stream clustering. <em>SOCO</em>, <em>24</em>(13),
9789–9807. (<a
href="https://doi.org/10.1007/s00500-019-04492-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional data streams emerge ubiquitously in many real-world applications such as network monitoring and forest cover type. Clustering such data streams differs from traditional data clustering algorithm where given datasets are generally static and can be repeatedly read and processed, thus facing more challenges due to having to satisfy such constraints as bounded memory, single-pass, real-time response and concept drift detection. Recently, many methods of such type have been proposed. However, when dealing with high-dimensional data, they often result in high computational cost and poor performance due to the curse of dimensionality. To address the above problem, in this paper, we present a new clustering algorithm for data streams, called RPGStream, by combining the random projection method with the growing neural gas (GNG) model which is an incremental self-organizing approach, belonging to the family of topological maps such as SOM or neural gas. To gain insights into the performance improvement obtained by our algorithm, we analyze and identify the major influence of random projection on GNG. Although our method is embarrassingly simple just by incorporating the random projection into an exponential fading function of GNG, the experimental results on variety of benchmark datasets indicate that our method can still achieve comparable or even better performance than G-Stream algorithm even if the raw dimension is compressed up to 10\% of the original one (e.g., for CoverType dataset, its dimension is reduced from 54 to 5).},
  archive      = {J_SOCO},
  author       = {Zhu, Yingwen and Chen, Songcan},
  doi          = {10.1007/s00500-019-04492-4},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {9789-9807},
  shortjournal = {Soft Comput.},
  title        = {Growing neural gas with random projection method for high-dimensional data stream clustering},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Accelerating range doppler imaging algorithm for
multiple-receiver synthetic aperture sonar on multi-core-based
architectures. <em>SOCO</em>, <em>24</em>(13), 9777–9788. (<a
href="https://doi.org/10.1007/s00500-019-04490-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Synthetic aperture sonar (SAS) is an underwater high-resolution imaging method. But with the increase in resolution and mapping width, the amount of raw data used for imaging increases dramatically. To solve the problem of low imaging efficiency of SAS, an acceleration method of SAS imaging in shared memory environment is proposed. By analyzing the calculation characteristics of each step from the original data received to the synthetic aperture imaging result, the range compression, equivalent conversion from multi-receiver signal to single-receiver signal and azimuth compression are designed in parallel with OpenMP instructions, and the multi-core computing resources are fully utilized to accelerate the imaging process. Simulation experiment verifies the correctness of the parallel imaging algorithm. The experimental result of real data shows that the parallel imaging algorithm has high efficiency and can realize super real-time imaging. The efficiency of the proposed method can be changed with the number of computational kernels. The relationship between the acceleration ratio and the computational kernels is approximately linear, which improves the adaptability of the algorithm. Efficient synthetic aperture sonar imaging algorithm provides conditions for post-processing of image, such as image enhancement, image target detection and recognition.},
  archive      = {J_SOCO},
  author       = {Heping, Zhong and Jinsong, Tang and Zhen, Tian and Haoran, Wu and Mengbo, Ma},
  doi          = {10.1007/s00500-019-04490-6},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {9777-9788},
  shortjournal = {Soft Comput.},
  title        = {Accelerating range doppler imaging algorithm for multiple-receiver synthetic aperture sonar on multi-core-based architectures},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stylized human motion warping method based on
identity-independent coordinates. <em>SOCO</em>, <em>24</em>(13),
9765–9775. (<a
href="https://doi.org/10.1007/s00500-019-04489-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human motion style is a vital concept to virtual human that has a great impact on the expressiveness of the final animation. This paper presents a novel technique that transfers style between heterogeneous motions in real time. Unlike previous approaches, our stylized motion warping is capable of reusing style between heterogeneous motions. The key idea of our work is to represent human motions with identity-independent coordinates (IICs) and learn relative space–time transformations between stylistically different IICs, instead of separating style from content. Once the relative space–time transformations are estimated from a small set of stylized example motions whose contents are identical, our technique is capable of generating style-controllable human motions by applying these transformations to heterogeneous motions with simple linear operations. Experimental results demonstrate that our technique is efficient and powerful in stylized human motion generation. Besides, our technique can also be used in numerous interactive applications, such as real-time human motion style control, stylizing motion graphs and style-based human motion editing.},
  archive      = {J_SOCO},
  author       = {Lyu, Lei and Zhang, Jinling},
  doi          = {10.1007/s00500-019-04489-z},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {9765-9775},
  shortjournal = {Soft Comput.},
  title        = {Stylized human motion warping method based on identity-independent coordinates},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A high-dimensional attribute reduction method modeling and
evaluation based on green economy data: Evidence from 15 sub-provincial
cities in china. <em>SOCO</em>, <em>24</em>(13), 9753–9764. (<a
href="https://doi.org/10.1007/s00500-019-04488-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data play an increasingly crucial role in decision evaluation. However, the noise and redundant information in the data create confusion to the decision makers. To solve this problem, this paper creates a new attribute reduction model based on technique for order preference by similarity to an ideal solution (TOPSIS), grey correlation analysis and coefficient of variation approaches. First, we obtain the time weights of panel data in different years by TOPSIS and then transfer the panel data into a cross-sectional data matrix. Second, we delete the overlapping attributes by grey correlation analysis method. Third, we use the coefficient of variation to select the attributes with the highest information content. Finally, the proposed attribute reduction model has been varied based on the green economy evaluation data of 15 sub-provincial cities in China. The experimental findings provide decision-making reference for the local government policymakers to adjust or formulate green economic development strategies.},
  archive      = {J_SOCO},
  author       = {Li, Gang and Li, Jiaxiang and Liu, Yunqi and Liu, Juan and Shi, Baofeng and Zhang, Hui and Rao, Weizhen and Zhang, Zhipeng},
  doi          = {10.1007/s00500-019-04488-0},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {9753-9764},
  shortjournal = {Soft Comput.},
  title        = {A high-dimensional attribute reduction method modeling and evaluation based on green economy data: Evidence from 15 sub-provincial cities in china},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multiobjective evolutionary-based multi-kernel learner for
realizing transfer learning in the prediction of HIV-1 protease cleavage
sites. <em>SOCO</em>, <em>24</em>(13), 9727–9751. (<a
href="https://doi.org/10.1007/s00500-019-04487-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the unavailability of adequate patients and expensive labeling cost, many real-world biomedical cases have scarcity in the annotated data. This holds very true for HIV-1 protease specificity problem where only a few experimentally verified cleavage sites are present. The challenge then is to exploit the auxiliary data. However, the problem becomes more complicated when the underlying train and test data are generated from different distributions. To deal with the challenges, we formulate the HIV-1 protease cleavage site prediction problem into a bi-objective optimization problem and solving it by introducing a multiobjective evolutionary-based multi-kernel model. A solution for the optimization problem will lead us to decide the optimal number of base kernels with the best pairing of features. The bi-objective criteria encourage different individual kernels in the ensemble to mitigate the effect of distribution difference in training and test data with the ideal number of base kernels. In this paper, we considered eight different feature descriptors and three different kernel variants of support vector machines to generate the optimal multi-kernel learning model. Non-dominated sorting genetic algorithm-II is employed with bi-objective of achieving a maximum area under the receiver operating characteristic curve simultaneously with a minimum number of features. To validate the effectiveness of the model, the experiments were performed on four HIV-1 protease datasets. The performance comparison with fifteen state-of-the-art techniques on average accuracy and area under curve has been evaluated to justify the improvement of the proposed model. We then analyze Friedman and post hoc tests to demonstrate the significant improvement. The result obtained following the extensive experiment enumerates the bi-objective multi-kernel model performance enhancement on within and cross-learning over the other state-of-the-art techniques.},
  archive      = {J_SOCO},
  author       = {Singh, Deepak and Sisodia, Dilip Singh and Singh, Pradeep},
  doi          = {10.1007/s00500-019-04487-1},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {9727-9751},
  shortjournal = {Soft Comput.},
  title        = {Multiobjective evolutionary-based multi-kernel learner for realizing transfer learning in the prediction of HIV-1 protease cleavage sites},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel time-shifting method to find popular blog post
topics. <em>SOCO</em>, <em>24</em>(13), 9705–9725. (<a
href="https://doi.org/10.1007/s00500-019-04485-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blog search engines and general search engines automatically crawl Web pages from the Internet and generate search results to users. One difference between the two is that blog search engines focus on blog posts and filter general pages. This difference allows bloggers to focus only on page results for posts rather than other types of page results. Another difference is that posts involve more time-related issues than general pages. For general pages, the general search engine can only show the last update time for the page. However, for posts, the blog search engine can show all possible time clues for the post. For some frequently updated posts, time clues help bloggers find information more efficiently. In this paper, we first use some well-known semantic analysis models to analyze the performance of Google Blog Search. Next, we apply a hybrid strategy that considers the document link and time clue relationships between posts to further improve its retrieval performance. Finally, we present several experiments to simulate various possible scenarios to confirm the effectiveness of our strategy.},
  archive      = {J_SOCO},
  author       = {Chen, Lin-Chih and Chen, Da-Ren and Lai, Ming-Fong},
  doi          = {10.1007/s00500-019-04485-3},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {9705-9725},
  shortjournal = {Soft Comput.},
  title        = {A novel time-shifting method to find popular blog post topics},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A cuckoo search optimization-based forward consecutive mean
excision model for threshold adaptation in cognitive radio.
<em>SOCO</em>, <em>24</em>(13), 9683–9704. (<a
href="https://doi.org/10.1007/s00500-019-04481-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The forward consecutive mean excision (FCME) algorithm is one of the most effective adaptive threshold estimation algorithms presently deployed for threshold adaptation in cognitive radio (CR) systems. However, its effectiveness is often limited by the manual parameter tuning process and by the lack of prior knowledge pertaining to the actual noise distribution considered during the parameter modeling process of the algorithm. In this paper, we propose a new model that can automatically and accurately tune the parameters of the FCME algorithm based on a novel integration with the cuckoo search optimization (CSO) algorithm. Our model uses the between-class variance function of the Otsu’s algorithm as the objective function in the CSO algorithm in order to auto-tune the parameters of the FCME algorithm. We compared and selected the CSO algorithm based on its relatively better timing and accuracy performance compared to some other notable metaheuristics such as the particle swarm optimization, artificial bee colony (ABC), genetic algorithm, and the differential evolution (DE) algorithms. Following close performance values, our findings suggest that both the DE and ABC algorithms can be adopted as favorable substitutes for the CSO algorithm in our model. Further simulation results show that our model achieves reasonably lower probability of false alarm and higher probability of detection as compared to the baseline FCME algorithm under different noise-only and signal-plus-noise conditions. In addition, we compared our model with some other known autonomous methods with results demonstrating improved performance. Thus, based on our new model, users are relieved from the cumbersome process involved in manually tuning the parameters of the FCME algorithm; instead, this can be done accurately and automatically for the user by our model. Essentially, our model presents a fully blind signal detection system for use in CR and a generic platform deployable to convert other parameterized adaptive threshold algorithms into fully autonomous algorithms.},
  archive      = {J_SOCO},
  author       = {Abdullahi, H. and Onumanyi, A. J. and Zubair, S. and Abu-Mahfouz, A. M. and Hancke, G. P.},
  doi          = {10.1007/s00500-019-04481-7},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {9683-9704},
  shortjournal = {Soft Comput.},
  title        = {A cuckoo search optimization-based forward consecutive mean excision model for threshold adaptation in cognitive radio},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An innovative user-attentive framework for supporting
real-time detection and mining of streaming microblog posts.
<em>SOCO</em>, <em>24</em>(13), 9663–9682. (<a
href="https://doi.org/10.1007/s00500-019-04478-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a modular system capable of catching the attention of a new user, to detect in real-time events and emotions related to them in a stream of microblog posts. The system is capable of making social sensing and exploiting the information arising on the Internet through user-generated contents, and it is equipped with a conversational engine that manages the interaction with the human user. The whole approach can be applied either by a human user or a robot, which remains a future application to be further improved in the context of our proposed system.},
  archive      = {J_SOCO},
  author       = {Cuzzocrea, A. and Pilato, G.},
  doi          = {10.1007/s00500-019-04478-2},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {9663-9682},
  shortjournal = {Soft Comput.},
  title        = {An innovative user-attentive framework for supporting real-time detection and mining of streaming microblog posts},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Soft-computing-centric framework for wildfire monitoring,
prediction and forecasting. <em>SOCO</em>, <em>24</em>(13), 9651–9661.
(<a href="https://doi.org/10.1007/s00500-019-04477-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wildfires are exorbitantly cataclysmic disasters that lead to the destruction of forest cover, wildlife, land resources, human assets, reduced soil fertility and global warming. Every year wildfires wreck havoc across the globe. Therefore, there is a need of an efficient and reliable system for real-time wildfire monitoring to dilute their disastrous effects. Internet of Things (IoT) has demonstrated remarkable evolution and has been successfully adopted in environmental monitoring domain. This paper proposes a collaborative IoT–Fog–Cloud framework based on soft computing techniques for real-time wildfire monitoring, prediction and forecasting. The framework includes proposals for classifying a forest terrain into its appropriate wildfire proneness class using fuzzy K-nearest-neighbor classifier by analyzing wildfire influent attributes and wildfire consequent attributes. Moreover, real-time emergency alert generation mechanism based on temporal mining has been proposed in event of adverse wildfire conditions. Estimation of future wildfire proneness levels of a forest terrain using Holt–Winter’s forecasting model also forms an integral part of the proposed framework. Implementation results reveal that high values of accuracy, specificity, sensitivity and precision averaging to 93.97\%, 92.35\%, 93.01\% and 91.24\% are attained for determination of wildfire proneness of a forest terrain. Low values of mean absolute error (MAE), mean square error (MSE), mean absolute percentage error and root mean square error (RMSE) averaging to 0.665, 2, 11.705 and 1.405, respectively, for real-time alert generation are registered, thereby increasing the utility of the proposed framework. Wildfire proneness forecasting also yields highly accurate results with low values of MAE, MSE and RMSE averaging to 0.166667, 0.25 and 0.492799, respectively.},
  archive      = {J_SOCO},
  author       = {Kaur, Harkiran and Sood, Sandeep K.},
  doi          = {10.1007/s00500-019-04477-3},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {9651-9661},
  shortjournal = {Soft Comput.},
  title        = {Soft-computing-centric framework for wildfire monitoring, prediction and forecasting},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). ANFIS-based model for predicting actual shear rate
associated with wall slip phenomenon. <em>SOCO</em>, <em>24</em>(13),
9639–9649. (<a
href="https://doi.org/10.1007/s00500-019-04475-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wall slip can be defined as a phenomenon in the flow of suspensions due to the movement of particles away from the wall boundary, leaving a thin liquid rich layer adjacent to the wall. It should be taken into consideration in material designing, manufacturing and transportation as it may cause inaccurate rheological measurements such as shear rate and viscosity. The apparent (measured) shear rate is higher than the actual shear rate. The traditional method for actual shear rate determination is not efficient from the perspective of time and cost consumption. Therefore, there is a need to develop a mathematical model that is able to detect the complex pattern of the actual shear rate and accurately predict its value based on the available measured input variables. Volumetric concentration, particle size, temperature and shear stress are selected as the input, while the actual shear rate is kept as output while designing the architecture of ANFIS model. Sixteen ANFIS models with different architecture were designed and evaluated using different statistical indices. Model XVI with number of membership function equal to 3, input product of two sigmoid membership function, output linear membership function type integrated with hybrid optimization method appears to be the most suitable model architecture for predicting the actual shear rate.},
  archive      = {J_SOCO},
  author       = {Chin, Ren Jie and Lai, Sai Hin and Ibrahim, Shaliza and Wan Jaafar, Wan Zurina and Elshafie, Ahmed},
  doi          = {10.1007/s00500-019-04475-5},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {9639-9649},
  shortjournal = {Soft Comput.},
  title        = {ANFIS-based model for predicting actual shear rate associated with wall slip phenomenon},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Machine intelligence-based algorithms for spam filtering on
document labeling. <em>SOCO</em>, <em>24</em>(13), 9625–9638. (<a
href="https://doi.org/10.1007/s00500-019-04473-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The internet has provided numerous modes for secure data transmission from one end station to another, and email is one of those. The reason behind its popular usage is its cost-effectiveness and facility for fast communication. In the meantime, many undesirable emails are generated in a bulk format for a monetary benefit called spam. Despite the fact that people have the ability to promptly recognize an email as spam, performing such task may waste time. To simplify the classification task of a computer in an automated way, a machine learning method is used. Due to limited availability of datasets for email spam, constrained data and the text written in an informal way are the most feasible issues that forced the current algorithms to fail to meet the expectations during classification. This paper proposed a novel, spam mail detection method based on the document labeling concept which classifies the new ones into ham or spam. Moreover, algorithms like Naive Bayes, Decision Tree and Random Forest (RF) are used in the classification process. Three datasets are used to evaluate how the proposed algorithm works. Experimental results illustrate that RF has higher accuracy when compared with other methods.},
  archive      = {J_SOCO},
  author       = {Gaurav, Devottam and Tiwari, Sanju Mishra and Goyal, Ayush and Gandhi, Niketa and Abraham, Ajith},
  doi          = {10.1007/s00500-019-04473-7},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {9625-9638},
  shortjournal = {Soft Comput.},
  title        = {Machine intelligence-based algorithms for spam filtering on document labeling},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Application of bio-inspired social spider algorithm in
multi-area economic emission dispatch of solar, wind and CHP-based power
system. <em>SOCO</em>, <em>24</em>(13), 9611–9624. (<a
href="https://doi.org/10.1007/s00500-019-04468-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concept of multi-area interconnection of power systems integrating nonlinear combined heat and power generators, wind, solar and conventional units, constrained by valve point effect, has been explored for the first time to ensure enhanced reliability. Bio-inspired social spider algorithm is used to simultaneously optimize cost of energy generation and emission of such system. Position of a spider on the web (search space) is the initial solution. Distance of a spider from food location is considered as its fitness. The spider is guided towards the food location by the target vibration through a random walk taken by putting a random dimension mask. Exploration of the search space by the algorithm is effectively controlled by tuning its three control parameters: attenuation rate control parameter (ra), probability of spider to change mask (pc) and probability of changing each bit of the mask vector (pm), if mask change is accomplished. Five test systems with different situations have been designed and tested considering three interconnected areas, and the objective of minimization of cost of production; transmission loss; and emission has been achieved reliably.},
  archive      = {J_SOCO},
  author       = {Adhvaryyu, Shreya and Adhvaryyu, Pradosh Kumar},
  doi          = {10.1007/s00500-019-04468-4},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {9611-9624},
  shortjournal = {Soft Comput.},
  title        = {Application of bio-inspired social spider algorithm in multi-area economic emission dispatch of solar, wind and CHP-based power system},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A fusion of decision-making method and neutrosophic
linguistic considering multiplicative inverse matrix for coastal erosion
problem. <em>SOCO</em>, <em>24</em>(13), 9595–9609. (<a
href="https://doi.org/10.1007/s00500-019-04467-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent boom of decision-making under uncertain information has attracted many researchers to the field of integrating various types of sets with decision-making methods. In this paper, a combined decision-making trial and evaluation laboratory (DEMATEL) with single-valued neutrosophic sets is proposed to solve the decision problem. This new model combines the advantages of multiplicative inverse of decision matrix in DEMATEL and neutrosophic numbers in linguistic variables, which can find the interrelationship among factors of decision problem. Differently from the typical multiplicative inverse of DEMATEL, which directly used inverse of matrix using real numbers, this method introduces the concept of inverse of matrix using the proposed left–right neutrosophic numbers. This step will enhance the validity of multiplicative inverse of decision matrix in the DEMATEL with neutrosophic numbers. The proposed neutrosophic DEMATEL is also be compared with the DEMATEL and fuzzy DEMATEL. This paper includes a case study that demonstrates the applicability of the neutrosophic DEMATEL in establishing the relationship among influential factors of coastal erosion. Extensive empirical studies using 12 factors of coastal erosion were presented to study the benefits of the proposed method. The result unveils the cause-and-effect relationships among the factors, where seven factors are identified as cause factors and five factors are grouped as effect factors. It is discovered that the factor ‘imbalance sediment supply’ gives a significant influence to coastal erosion. It is also shown that the degree of importance of the factors is almost consistent with the other two methods despite differences in type of numbers used in defining linguistic variables.},
  archive      = {J_SOCO},
  author       = {Awang, Azzah and Abdullah, Lazim and Ab Ghani, Ahmad Termimi and Aizam, Nur Aidya Hanum and Ahmad, Mohammad Fadhli},
  doi          = {10.1007/s00500-019-04467-5},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {9595-9609},
  shortjournal = {Soft Comput.},
  title        = {A fusion of decision-making method and neutrosophic linguistic considering multiplicative inverse matrix for coastal erosion problem},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Müntz–legendre neural network construction for solving delay
optimal control problems of fractional order with equality and
inequality constraints. <em>SOCO</em>, <em>24</em>(13), 9575–9594. (<a
href="https://doi.org/10.1007/s00500-019-04465-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an artificial intelligence approach using neural networks is described to solve a class of delay optimal control problems of fractional order with equality and inequality constraints. In the proposed method, a functional link neural network based on the Müntz–Legendre polynomial is developed. The problem is first transformed into an equivalent problem with a fractional dynamical system without delay, using a Padé approximation. According to the Pontryagin’s minimum principle for optimal control problems of fractional order and by constructing an error function, the authors then define an unconstrained minimization problem. The authors use trial solutions for the states, Lagrange multipliers and control functions where these trial solutions are constructed by a single-layer Müntz–Legendre neural network model. The authors then exploit an unconstrained optimization scheme for adjusting the network parameters (weights and bias) and to minimize the computed error function. Some numerical examples are given to illustrate the effectiveness of the proposed method.},
  archive      = {J_SOCO},
  author       = {Kheyrinataj, Farzaneh and Nazemi, Alireza},
  doi          = {10.1007/s00500-019-04465-7},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {9575-9594},
  shortjournal = {Soft Comput.},
  title        = {Müntz–Legendre neural network construction for solving delay optimal control problems of fractional order with equality and inequality constraints},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dealing with the problem of null weights and scores in fuzzy
analytic hierarchy process. <em>SOCO</em>, <em>24</em>(13), 9557–9573.
(<a href="https://doi.org/10.1007/s00500-019-04464-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy Analytic Hierarchy Process (Fuzzy AHP) has been widely adopted to support decision making problems. The Fuzzy AHP approach based on the synthetic extent analysis is the most applied approach to calculate the values of the criteria weights from fuzzy comparative matrices. The min operator is used to calculate the weights based on values of degree of possibility. If any of the degrees of possibilities is zero, the output of this operator will also be zero. Thus, the criterion weight or alternative score will be set to zero. If not prevented, this problem may lead to a distorted rank. Despite the fact that there are other propositions based on synthetic extent analysis method, none of the studies found in the literature investigate how the problem of null weights and scores can be avoided. This paper investigates different approaches of the Fuzzy AHP method to evaluate whether they can avoid the problem of null weights and scores without affecting the consistency of the results. Five different approaches based on synthetic extent analysis method were implemented and evaluated. Tests were performed considering 12 decision problems. The results indicated that the Fuzzy AHP approach proposed by Ahmed and Kilic is the most appropriate to overcome the problem of null weight of criteria and scores of alternatives without affecting the consistency of the results. Other benefits of using this approach are the simplicity of the computational implementation and better ability to differentiate the importance of the criteria when the weight values are very close.},
  archive      = {J_SOCO},
  author       = {Lima-Junior, Francisco Rodrigues and Carpinetti, Luiz Cesar Ribeiro},
  doi          = {10.1007/s00500-019-04464-8},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {9557-9573},
  shortjournal = {Soft Comput.},
  title        = {Dealing with the problem of null weights and scores in fuzzy analytic hierarchy process},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A non-compensatory classification approach for
multi-criteria ABC analysis. <em>SOCO</em>, <em>24</em>(13), 9525–9556.
(<a href="https://doi.org/10.1007/s00500-019-04462-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {ABC analysis is a widespread inventory management technique designed to classify inventory items—based on their weighted scores—into three ordered categories A, B and C, where category A contains the most important items and category C includes the least important ones. This paper proposes a new ABC classification approach which involves a non-compensatory aggregation procedure, based on a simplified ELECTRE III method, to compute the score of each inventory item. A non-compensatory aggregation scheme means that the bad scores of an item on some significant criteria could not be offset by its high performances on the other criteria. This way of proceeding prohibits this kind of items from being classified into good categories and therefore generates a more realistic ABC classification of inventory items. Since the application of the simplified ELECTRE III method requires the knowledge of some parameter values, the continuous variable neighborhood search meta-heuristic will be used for their estimation. The comparative study—conducted on two real datasets—shows that the classification of items produced by our proposed approach has generated the lowest inventory cost value among those produced by all tested classification models.},
  archive      = {J_SOCO},
  author       = {Douissa, Mohamed Radhouane and Jabeur, Khaled},
  doi          = {10.1007/s00500-019-04462-w},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {9525-9556},
  shortjournal = {Soft Comput.},
  title        = {A non-compensatory classification approach for multi-criteria ABC analysis},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). 5GAuNetS: An autonomous 5G network selection framework for
industry 4.0. <em>SOCO</em>, <em>24</em>(13), 9507–9523. (<a
href="https://doi.org/10.1007/s00500-019-04460-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The megatrends within the industrial automation and global value chains expedited the adoption of “Industry 4.0 enabled by 5G” to comprehend extremely flexible and smart production systems. The pivotal challenge for the smart manufacturing leveraging on 5G is the seamless vertical handover and connectivity to a suitable network in accordance with the determined application. The existing literature reports numerous strategies to ensure “always best connected” paradigm but they suffer from a couple of limitations. The amateurish approach employed in these strategies propelled the development of an autonomous network selection model exploiting fuzzy analytical hierarchical process consolidated with the novel extended efficacy coefficient method-based Technique for Order Preference by Similarity to Ideal Solution. This article addresses the vertical handover execution under the circumstances of four typical 5G application scenarios, respectively, i.e. Tactile Internet, Bitpipe, Internet of Things and Internet Access for Regional Areas. The analytical results validated through the extensive simulation revealed that the proposed hybrid scheme is effective and efficient compared to other methods in terms of avoiding the unnecessary handover and the ranking abnormality issues.},
  archive      = {J_SOCO},
  author       = {Priya, Bhanu and Malhotra, Jyoteesh},
  doi          = {10.1007/s00500-019-04460-y},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {9507-9523},
  shortjournal = {Soft Comput.},
  title        = {5GAuNetS: An autonomous 5G network selection framework for industry 4.0},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A power system restoration method using voltage source
converter–high-voltage direct current technology, aided by time-series
neural network with firefly algorithm. <em>SOCO</em>, <em>24</em>(13),
9495–9506. (<a
href="https://doi.org/10.1007/s00500-019-04459-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Voltage source converter (VSC)–high-voltage direct current (HVDC) has become a new trend for achieving an efficient and reliable bulk power transmission. The main challenges in VSC-HVDC link are the “soft-start-up” or the restoration of power after the system blackout, with over voltage and less response delay. In this paper, VSC-HVDC link with firefly Levenberg–Marquardt-trained artificial neural network (ANN), termed as ANN-FLM, is proposed to restore the power quickly. The simulation is performed by creating blackout in the system through the introduction of a three-phase fault. The performance analysis is made on VSC-HVDC with ANN-FLM in existing proportional integral controller. The simulated results provide faster restoration and independent control of real and reactive powers. The proposed method minimizes the over voltage to 98\% in maximum point, 84\% in phase A, 61\% in phase B and 82\% in phase C, when simulated.},
  archive      = {J_SOCO},
  author       = {Shaik, Jan Bhasha and Ganesh, V.},
  doi          = {10.1007/s00500-019-04459-5},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {9495-9506},
  shortjournal = {Soft Comput.},
  title        = {A power system restoration method using voltage source converter–high-voltage direct current technology, aided by time-series neural network with firefly algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Proposing a new model to aggregate ratings in multi-source
feedback approach based on the evidence theory. <em>SOCO</em>,
<em>24</em>(13), 9479–9494. (<a
href="https://doi.org/10.1007/s00500-019-04458-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Researchers and practitioners in multi-source feedback (MSF) context generally use the average-based methods to aggregate ratings. Because of the uncertainties in the raters’ opinions, it is believed that the use of conventional averaging methods is not appropriate for aggregating MSF data. So, in MSF approach, there is a need to design a proper aggregation method that is capable to cope with the uncertainty in ratings. In this regard, in this paper, each rating group has been considered as a source of evidence, and a new aggregation model based on evidence theory has been proposed. In the proposed model, the collected data from each rating group by designing three different methods have been converted to the basic belief assignments and then aggregated using the Dempster rule of combination. In order to resolve the conflict between evidences, the discounting and compromise methods were used, and the output of the combination process was extracted using three different methods including the pignistic probability criterion, the plausibility transformation method and the expected value method. Finally, through a simulation study, the performance of the proposed model under various configurations was investigated. The results of the simulation study show that the proposed model, in almost all configurations, provides more accurate results than traditional aggregation method in MSF approach.},
  archive      = {J_SOCO},
  author       = {Nahid Titkanloo, Hossein and Keramati, Abbas and Fekri, Roxana},
  doi          = {10.1007/s00500-019-04458-6},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {9479-9494},
  shortjournal = {Soft Comput.},
  title        = {Proposing a new model to aggregate ratings in multi-source feedback approach based on the evidence theory},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new correlation coefficient of the pythagorean fuzzy sets
and its applications. <em>SOCO</em>, <em>24</em>(13), 9467–9478. (<a
href="https://doi.org/10.1007/s00500-019-04457-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a new correlation coefficient between Pythagorean fuzzy sets. We then use this new result to compute some examples through which we find that it benefits from such an outcome with some well-known results in the literature. In probability and statistical theory, the correlation coefficient indicates the strength of the linear correlation between two random variables. The correlation coefficient is equal to one in the case of a linear correlation and − 1 in the case of a linear inverse correlation. Other values in the range (− 1, 1) indicate the degree of linear dependence between variables. The closer the coefficient is to − 1 and 1, the stronger the correlation between variables. As in statistics with real variables, we refer to variance and covariance between two intuitionistic fuzzy sets. Then, we determined the formula for calculating the correlation coefficient based on the variance and covariance of the intuitionistic fuzzy set, and the value of this correlation coefficient is in [− 1, 1]. We also commented on the linear relationship between fuzzy sets affecting their correlation coefficients through examples to show the usefulness in the proposed new measure. Then, we develop this direction to build correlation coefficients between the interval-valued intuitionistic fuzzy sets and apply it in the pattern recognition problem.},
  archive      = {J_SOCO},
  author       = {Thao, Nguyen Xuan},
  doi          = {10.1007/s00500-019-04457-7},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {9467-9478},
  shortjournal = {Soft Comput.},
  title        = {A new correlation coefficient of the pythagorean fuzzy sets and its applications},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Prediction of equipment performance index based on improved
chaotic lion swarm optimization–LSTM. <em>SOCO</em>, <em>24</em>(13),
9441–9465. (<a
href="https://doi.org/10.1007/s00500-019-04456-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The lion swarm optimizer (LSO) algorithm is a novel meta-heuristic, inspired from the social behavior of lions. This paper introduces the chaos theory into the LSO algorithm with the aim of accelerating its global convergence speed. First, detailed studies are carried out on standard constrained benchmark problems with ten different chaotic maps to find out the most efficient one. Then, the improved chaotic lion swarm optimization algorithm is compared with the traditional LSO and some other popular meta-heuristics algorithms. Lastly, this paper uses the improved chaotic lion swarm algorithm to further optimize the LSTM super-parameters for the problem of equipment life prediction. In addition, for the validity of the analysis method, the comparative experiments of several typical time series prediction models and different parameter optimization algorithms are carried out to verify the proposed methods in each part, which proves that the improved chaotic lion group–LSTM model has strong generalization ability and higher accuracy in equipment life prediction.},
  archive      = {J_SOCO},
  author       = {Yang, Zhe and Wei, Chunwu},
  doi          = {10.1007/s00500-019-04456-8},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {9441-9465},
  shortjournal = {Soft Comput.},
  title        = {Prediction of equipment performance index based on improved chaotic lion swarm optimization–LSTM},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-stage multi-attribute decision-making method based on
the prospect theory and triangular fuzzy MULTIMOORA. <em>SOCO</em>,
<em>24</em>(13), 9429–9440. (<a
href="https://doi.org/10.1007/s00500-018-3017-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposed a novel multi-stage multi-attribute decision-making method, in which the period weights and attribute weights are completely unknown, and attribute values are triangular fuzzy numbers. At first, the triangular fuzzy prospect decision matrices of different periods are constructed and the period weights optimization model is built according to the time degree and the prospect value deviation of alternatives in different periods. The attribute weights are obtained by the maximum deviation method. Then, MULTIMOORA is extended into the triangular fuzzy environment. Based on the new form of MULTIMOORA and dominance theory, the final ranking of alternatives can be got. Finally, a numerical example is presented to illustrate the feasibility and effectiveness of the proposed method.},
  archive      = {J_SOCO},
  author       = {Dai, Wen-feng and Zhong, Qiu-yan and Qi, Chun-ze},
  doi          = {10.1007/s00500-018-3017-0},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {9429-9440},
  shortjournal = {Soft Comput.},
  title        = {Multi-stage multi-attribute decision-making method based on the prospect theory and triangular fuzzy MULTIMOORA},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Picture fuzzy matrix and its application. <em>SOCO</em>,
<em>24</em>(13), 9413–9428. (<a
href="https://doi.org/10.1007/s00500-020-05021-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the notions of picture fuzzy matrix, restricted picture fuzzy matrix and special restricted picture fuzzy matrix are established. Two types of $$\langle \theta , \phi , \psi \rangle $$-cut of special restricted square picture fuzzy matrix are introduced and corresponding properties are studied. Also, determinant and adjoint of square picture fuzzy matrix are established and some related properties are investigated. An application of picture fuzzy matrix in decision-making problem is presented here.},
  archive      = {J_SOCO},
  author       = {Dogra, Shovan and Pal, Madhumangal},
  doi          = {10.1007/s00500-020-05021-4},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {9413-9428},
  shortjournal = {Soft Comput.},
  title        = {Picture fuzzy matrix and its application},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Determining fuzzy distance via coupled pair of operators in
fuzzy metric space. <em>SOCO</em>, <em>24</em>(13), 9403–9412. (<a
href="https://doi.org/10.1007/s00500-020-05001-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this present study, we introduce the new class of mappings called fuzzy proximally compatible mappings and we solve the common coupled global optimization problem of finding the fuzzy distance between two subsets of a fuzzy metric space for this class of non-self-fuzzy mappings. Further, we develop the notion CLRg property (CLRg common limit in the range of g) for non-self-fuzzy mappings, and by having this idea, we derive common global minimal solution to the fuzzy coupled fixed point equations $$F(x,y) = g(x) = x$$ and $$F(y,x) = g(y) = y,$$ where the pair (F, g) is proximally fuzzy weakly compatible mappings, without the assumption of continuity on g. Finally, we find a relation between, our extended notions, proximal fuzzy E.A property and proximal fuzzy CLRg property, and we find a unique solution to the common global optimization problem with the assumption of proximal fuzzy E.A property.},
  archive      = {J_SOCO},
  author       = {Gopi, R. and Pragadeeswarar, V.},
  doi          = {10.1007/s00500-020-05001-8},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {9403-9412},
  shortjournal = {Soft Comput.},
  title        = {Determining fuzzy distance via coupled pair of operators in fuzzy metric space},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-granular soft rough covering sets. <em>SOCO</em>,
<em>24</em>(13), 9391–9402. (<a
href="https://doi.org/10.1007/s00500-020-04987-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel model that combines several interesting features in relation with rough sets, namely multi-granularity (which extends Pawlak’s single-granular approach), soft rough sets (where the granulation structure is defined by soft sets), and coverings that induce rough sets. Optimistic and pessimistic multi-granular models are the outcome of this hybridization. Their properties, relationships, and links with existing models are thoroughly explored. Finally, an application of the model to multi-criteria group decision making is put forward. Examples and graphical discussions illustrate the performance of this criterion.},
  archive      = {J_SOCO},
  author       = {Alcantud, José Carlos R. and Zhan, Jianming},
  doi          = {10.1007/s00500-020-04987-5},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {9391-9402},
  shortjournal = {Soft Comput.},
  title        = {Multi-granular soft rough covering sets},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An improved algorithm for finding the generators of the
solution space for <span
class="math display"><em>A</em> ⊗ <strong>x</strong> ≥ <strong>x</strong></span>.
<em>SOCO</em>, <em>24</em>(13), 9383–9390. (<a
href="https://doi.org/10.1007/s00500-020-04978-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with the problem of finding the generators of the solution space for a system of inequalities $$A\otimes \mathbf{x }\ge \mathbf{x }$$ in max-plus algebra. It provides an improved algorithm which can be used to find a smaller set of generators for the solution space by skipping a large number of invalid generators.},
  archive      = {J_SOCO},
  author       = {Wang, Hui-li and Yang, Yan and Wang, Xue-ping},
  doi          = {10.1007/s00500-020-04978-6},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {9383-9390},
  shortjournal = {Soft Comput.},
  title        = {An improved algorithm for finding the generators of the solution space for $$A\otimes \mathbf{x }\ge \mathbf{x }$$},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Conrad’s f-condition for partially ordered monoids.
<em>SOCO</em>, <em>24</em>(13), 9375–9381. (<a
href="https://doi.org/10.1007/s00500-020-04976-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study Conrad’s F-condition for lattice-ordered monoids, Riesz monoids, and pre-Riesz monoids.},
  archive      = {J_SOCO},
  author       = {Liu, Pengyuan and Yang, Yichuan and Zafrullah, Muhammad},
  doi          = {10.1007/s00500-020-04976-8},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {9375-9381},
  shortjournal = {Soft Comput.},
  title        = {Conrad’s F-condition for partially ordered monoids},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The mean chance conditional value at risk under interval
type-2 intuitionistic fuzzy random environment. <em>SOCO</em>,
<em>24</em>(13), 9361–9373. (<a
href="https://doi.org/10.1007/s00500-020-04975-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The interval type-2 intuitionistic fuzzy random variable is an extension of the intuitionistic fuzzy random variable such that it can be a effective tool to determine some high-uncertainty phenomena. In this paper, the interval type-2 intuitionistic fuzzy random variable is introduced for the first time, and then, a scalar expected value operator of interval type-2 intuitionistic fuzzy random variable is proposed. Moreover, the new concepts of mean chance value at risk and mean chance conditional value at risk are discussed for the interval type-2 intuitionistic fuzzy random variables which have application in uncertain optimization, like fuzzy inverse location problems. Finally, it is proven that mean chance value at risk and mean chance conditional value at risk fulfill the convex risk metric properties.},
  archive      = {J_SOCO},
  author       = {Taghikhani, Sepideh and Baroughi, Fahimeh and Alizadeh, Behrooz},
  doi          = {10.1007/s00500-020-04975-9},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {9361-9373},
  shortjournal = {Soft Comput.},
  title        = {The mean chance conditional value at risk under interval type-2 intuitionistic fuzzy random environment},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Uncertain maximum likelihood estimation with application to
uncertain regression analysis. <em>SOCO</em>, <em>24</em>(13),
9351–9360. (<a
href="https://doi.org/10.1007/s00500-020-04951-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regression analysis is a mathematical tool to estimate the relationship between explanatory variables and response variable. This paper defines a likelihood function in the sense of uncertain measure to represent the likelihood of unknown parameters. Furthermore, the method of maximum likelihood estimation is used for the parameter estimation of uncertain regression models, and the uncertainty distribution of the disturbance term is simultaneously calculated. Finally, some numerical examples are documented to illustrate the proposed method.},
  archive      = {J_SOCO},
  author       = {Lio, Waichon and Liu, Baoding},
  doi          = {10.1007/s00500-020-04951-3},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {9351-9360},
  shortjournal = {Soft Comput.},
  title        = {Uncertain maximum likelihood estimation with application to uncertain regression analysis},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A generalized belief interval-valued soft set with
applications in decision making. <em>SOCO</em>, <em>24</em>(13),
9339–9350. (<a
href="https://doi.org/10.1007/s00500-020-04949-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The belief interval-valued soft set (BIVSS) combines soft set theory and belief interval value (Dempster–Shafer theory). In this study, we propose a generalized belief interval-valued soft set (GBIVSS) approach and explore the associated properties of this approach in decision-making applications. Using the score function, the scoring function and similarity measure used to compare the relationships between GBIVSS are proposed. Then, we applied the GBIVSS to deal with multi-attribute decision making (MADM) problems. Furthermore, we used a case study of car purchase to illustrate the rationality of the proposed approach. In addition, we compare the effectiveness and advantages of our proposed approach and other existing models, which show superior performance in our proposed approach. GBIVSS provides a solution for multi-attribute problems.},
  archive      = {J_SOCO},
  author       = {Cheng, Cuiping and Cao, Zehong and Xiao, Fuyuan},
  doi          = {10.1007/s00500-020-04949-x},
  journal      = {Soft Computing},
  number       = {13},
  pages        = {9339-9350},
  shortjournal = {Soft Comput.},
  title        = {A generalized belief interval-valued soft set with applications in decision making},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Triangular gaussian mutation to differential evolution.
<em>SOCO</em>, <em>24</em>(12), 9307–9320. (<a
href="https://doi.org/10.1007/s00500-019-04455-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential evolution (DE) has been a popular algorithm for its simple structure and few control parameters. However, there are some open issues in DE regrading its mutation strategies. An interesting one is how to balance the exploration and exploitation behaviour when performing mutation, and this has attracted a growing number of research interests over a decade. To address this issue, this paper presents a triangular Gaussian mutation strategy. This strategy utilizes the physical positions and the fitness differences of the vertices in the triangular structure. Based on this strategy, a triangular Gaussian mutation to DE and its improved version (ITGDE) are suggested. Empirical studies are carried out on the 20 benchmark functions and show that, in comparison with several state-of-the-art DE variants, ITGDE obtains significantly better or at least comparable results, suggesting the proposed mutation strategy is promising for DE.},
  archive      = {J_SOCO},
  author       = {Guo, Jinglei and Wu, Yong and Xie, Wei and Jiang, Shouyong},
  doi          = {10.1007/s00500-019-04455-9},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {9307-9320},
  shortjournal = {Soft Comput.},
  title        = {Triangular gaussian mutation to differential evolution},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Enhancing differential evolution algorithm with repulsive
behavior. <em>SOCO</em>, <em>24</em>(12), 9279–9305. (<a
href="https://doi.org/10.1007/s00500-019-04454-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the real world, differential evolution (DE) algorithm can effectively solve optimization problems in engineering; thus, DE has been applied in various fields. However, in complex multimodal problems, DE may encounter stagnation during iterations. Thus, we propose an improved DE algorithm with repulsive behavior, named RBDE. The core idea of RBDE is that offsprings no longer simply learn from the current optima but continue to explore the direction in which the current optimal individual is repelled by poorer individuals. This mechanism increases the diversity of the learning direction of a population. RBDE includes two types of repulsive behaviors: In the first, RBDE selects two parents as the source of repulsion and generates two different repulsive forces to promote the offspring to explore the optimal individual; the other considers that the gradient of the repulsion between the parents is the learning direction of the offspring. The repulsive behavior can effectively alleviate the stagnation of DE when dealing with multimodal problems. To evaluate the performance of RBDE, we use CEC2017 benchmarks to test RBDE and nine other algorithms. The results show that the performance of RBDE is better than that of the other nine algorithms. In addition, RBDE is used to train an artificial neural network and is applied to the optimization problem of four-bar linkages, whose results indicate that the model obtained by RBDE is more accurate than those by the other algorithms.},
  archive      = {J_SOCO},
  author       = {Zhang, Kai and Mu, Pengcheng and Zhang, Yimin and Jin, Zhihao and Huang, Qiujun},
  doi          = {10.1007/s00500-019-04454-w},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {9279-9305},
  shortjournal = {Soft Comput.},
  title        = {Enhancing differential evolution algorithm with repulsive behavior},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). CAAS: A novel collective action-based ant system algorithm
for solving TSP problem. <em>SOCO</em>, <em>24</em>(12), 9257–9278. (<a
href="https://doi.org/10.1007/s00500-019-04452-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To solve some problems of ant system algorithm, such as the slow speed of convergence and falling into the phenomenon of “ant colony group loss” easily, we introduce the collective action into the traditional ant system algorithm. Based on the collective action, we propose a novel collective action-based ant system algorithm, namely CAAS, for solving the traveling salesman problem. In the CAAS algorithm, a collective action “optimal solution approval” is defined for ant colony and each ant of the ant colony is assigned a threshold, and then each ant decides whether to join into the collective action according to its own threshold in the iteration process. When all ants approved the same solution, the iteration is stopped and output the final optimal solution. At last, we conduct extensive experiments on six public datasets to verify the performance of the proposed CAAS algorithm. The experimental results show that the CAAS algorithm can get a better solution under a less iteration.},
  archive      = {J_SOCO},
  author       = {Li, Sicong and Cai, Saihua and Li, Li and Sun, Ruizhi and Yuan, Gang},
  doi          = {10.1007/s00500-019-04452-y},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {9257-9278},
  shortjournal = {Soft Comput.},
  title        = {CAAS: A novel collective action-based ant system algorithm for solving TSP problem},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the effects of pseudorandom and quantum-random number
generators in soft computing. <em>SOCO</em>, <em>24</em>(12), 9243–9256.
(<a href="https://doi.org/10.1007/s00500-019-04450-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we argue that the implications of pseudorandom and quantum-random number generators (PRNG and QRNG) inexplicably affect the performances and behaviours of various machine learning models that require a random input. These implications are yet to be explored in soft computing until this work. We use a CPU and a QPU to generate random numbers for multiple machine learning techniques. Random numbers are employed in the random initial weight distributions of dense and convolutional neural networks, in which results show a profound difference in learning patterns for the two. In 50 dense neural networks (25 PRNG/25 QRNG), QRNG increases over PRNG for accent classification at + 0.1\%, and QRNG exceeded PRNG for mental state EEG classification by + 2.82\%. In 50 convolutional neural networks (25 PRNG/25 QRNG), the MNIST and CIFAR-10 problems are benchmarked, and in MNIST the QRNG experiences a higher starting accuracy than the PRNG but ultimately only exceeds it by 0.02\%. In CIFAR-10, the QRNG outperforms PRNG by + 0.92\%. The n-random split of a Random Tree is enhanced towards and new Quantum Random Tree (QRT) model, which has differing classification abilities to its classical counterpart, 200 trees are trained and compared (100 PRNG/100 QRNG). Using the accent and EEG classification data sets, a QRT seemed inferior to a RT as it performed on average worse by − 0.12\%. This pattern is also seen in the EEG classification problem, where a QRT performs worse than a RT by − 0.28\%. Finally, the QRT is ensembled into a Quantum Random Forest (QRF), which also has a noticeable effect when compared to the standard Random Forest (RF). Ten to 100 ensembles of trees are benchmarked for the accent and EEG classification problems. In accent classification, the best RF (100 RT) outperforms the best QRF (100 QRF) by 0.14\% accuracy. In EEG classification, the best RF (100 RT) outperforms the best QRF (100 QRT) by 0.08\% but is extremely more complex, requiring twice the amount of trees in committee. All differences are observed to be situationally positive or negative and thus are likely data dependent in their observed functional behaviour.},
  archive      = {J_SOCO},
  author       = {Bird, Jordan J. and Ekárt, Anikó and Faria, Diego R.},
  doi          = {10.1007/s00500-019-04450-0},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {9243-9256},
  shortjournal = {Soft Comput.},
  title        = {On the effects of pseudorandom and quantum-random number generators in soft computing},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A cluster validity evaluation method for dynamically
determining the near-optimal number of clusters. <em>SOCO</em>,
<em>24</em>(12), 9227–9241. (<a
href="https://doi.org/10.1007/s00500-019-04449-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cluster validity evaluation is a hot issue in clustering algorithm research. Aiming at determining the optimal number of clusters in cluster validity evaluation, this paper proposes a new cluster validity index Ratio of Deviation of Sum-of-squares and Euclid distance (RDSED), and designs a cluster validity evaluation method based on RDSED which is suitable to dynamically determine the near-optimal number of clusters. Firstly, based on the analysis of the relationships of the intra-class and inter-class, the concepts of sum-of-squares of within-cluster, sum-of-squares of between-cluster, total sum-of-squares, sum of intra-cluster distance and average distance between clusters are proposed, and then a cluster validity index RDSED based on these concepts is constructed. Secondly, a cluster validity evaluation method based on RDSED for dynamically determining the near-optimal number of clusters is designed. In this method, RDSED value is calculated from large to small in the range of clustering number and this index value is used to dynamically terminate the clustering validity verification process, and finally the near-optimal number of clusters and clustering partition results are obtained. Experiment results of artificial datasets and real datasets show that, compared with some classical clustering validity evaluation method, the proposed cluster validity evaluation method can obtain the near-optimal number of clusters that is closest to the real cluster number in most cases and can effectively evaluate clustering partition results.},
  archive      = {J_SOCO},
  author       = {Li, Xiangjun and Liang, Wei and Zhang, Xinping and Qing, Song and Chang, Pei-Chann},
  doi          = {10.1007/s00500-019-04449-7},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {9227-9241},
  shortjournal = {Soft Comput.},
  title        = {A cluster validity evaluation method for dynamically determining the near-optimal number of clusters},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel heuristic algorithm to solve penalized
regression-based clustering model. <em>SOCO</em>, <em>24</em>(12),
9215–9225. (<a
href="https://doi.org/10.1007/s00500-019-04448-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Penalized regression-based clustering model (PRClust) is an extension of “sum-of-norms” clustering model. Three previously proposed heuristic algorithms for solving PRClust are: (1) DC-CD, which combines the difference of convex programming (DC) and a coordinate-wise descent algorithm (CD), (2) DC-ADMM, which combines DC with the alternating direction method of multipliers (ADMM), and (3) ALT, which uses alternate optimization. DC-CD uses $$ p \times \left( {n \times \left( {n - 1} \right)} \right)/2 $$ scalar slack variables to solve PRClust, where n is the number of data and p is the number of their features. In each iteration of DC-CD, these slack variables and cluster centers are updated using a second-order cone programming (SOCP). DC-ADMM uses $$ p \times n \times \left( {n - 1} \right) $$ scalar slack variables. In each iteration of DC-ADMM, these slack variables and cluster centers are updated with a standard ADMM. In this paper, first, PRClust is reformulated into an equivalent model. Then, a novel heuristic algorithm is proposed to solve the reformulated model. Our proposed algorithm needs only $$ \left( {n \times \left( {n - 1} \right)} \right)/2 $$ scalar slack variables which are much less than those of DC-CD and DC-ADMM, and updates them using a simple equation in each iteration of the algorithm. Therefore, updating slack variables in our proposed algorithm is less time-consuming than that of DC-CD and DC-ADMM. Our proposed algorithm updates only cluster centers using an unconstrained convex quadratic problem. Therefore, our proposed unconstrained convex quadratic problem is much smaller than the SOCP of DC-CD which is used to update both cluster centers and slack variables. Meanwhile, ALT updates cluster centers using a SOCP, while our proposed algorithm updates cluster centers using an unconstrained convex quadratic problem with the same number of variables. Solving an unconstrained convex quadratic problem is less time-consuming than a SOCP with the same number of variables. Our experimental results on 12 datasets confirm that the runtime of our proposed algorithm is better than that of DC-ADMM and DC-CD.},
  archive      = {J_SOCO},
  author       = {Hasanzadeh Tavakkoli, Shadi and Forghani, Yahya and Sheibani, Reza},
  doi          = {10.1007/s00500-019-04448-8},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {9215-9225},
  shortjournal = {Soft Comput.},
  title        = {A novel heuristic algorithm to solve penalized regression-based clustering model},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On possible outputs of group decision making with interval
uncertainties based on simulation techniques. <em>SOCO</em>,
<em>24</em>(12), 9205–9213. (<a
href="https://doi.org/10.1007/s00500-019-04447-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interval uncertainties are very common in group decision making (GDM), especially with the increasing complexity of decision-making systems. The aggregation approach is a widely used method for integrating interval uncertain information in a single interval output that is the basis for ranking alternatives. The ranking results are usually presented in absolute form, that is, an alternative has a 100\% probability of being superior to the alternative immediately behind it. However, it seems inadequate and unreasonable to deduce this type of absolute ranking solely since overlap is common among interval outputs, that is an alternative is not always absolutely superior (or inferior) to another one. To this problem, this paper tries to explore other types of outputs for interval GDM problems using stochastic simulation, including ranking of alternatives with probabilities, competition for each ordered position, pairwise priority comparison of alternatives, and overall advantage of alternatives. All of these outputs provide us with more information to form a complete understanding of alternatives from different aspects. Finally, a numerical example regarding the policy selection about a company expanding into a new market is introduced to illustrate the obtainment of these possible outputs.},
  archive      = {J_SOCO},
  author       = {Yi, Pingtao and Li, Weiwei and Zhang, Danning},
  doi          = {10.1007/s00500-019-04447-9},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {9205-9213},
  shortjournal = {Soft Comput.},
  title        = {On possible outputs of group decision making with interval uncertainties based on simulation techniques},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Some new information measures for hesitant fuzzy PROMETHEE
method and application to green supplier selection. <em>SOCO</em>,
<em>24</em>(12), 9179–9203. (<a
href="https://doi.org/10.1007/s00500-019-04446-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the increasing complexity and uncertainty in green supplier selection, there would be some hesitations for decision makers (DMs) to provide evaluation information of suppliers. Hesitant fuzzy set is a suitable tool to model such hesitations. This paper develops a hesitant fuzzy Preference Ranking Organization Method for Enrichment Evaluations (PROMETHEE) for multi-criteria group decision-making and applies to green supplier selection. First, a new hesitancy index of hesitant fuzzy element (HFE) is defined. Then, a generalized hesitant fuzzy Hausdorff distance is proposed considering the individual deviation of membership values and the hesitancy index simultaneously. A combined hesitant fuzzy entropy is presented integrating the defined fuzziness entropy and hesitancy entropy of HFEs. Subsequently, a linear programming model is established to derive DMs’ weights objectively. To determine the criteria weights for each DM, a nonlinear programming model is built through minimizing the relative entropy. The PROMETHEE is employed to obtain individual ranking of alternatives for each DM. To obtain the collective ranking of alternatives, a multi-objective assignment model is constructed and transformed into a single-objective assignment model for resolution. Thereby, a hesitant fuzzy PROMETHEE method is presented. A green supplier selection example is demonstrated to validate the proposed method.},
  archive      = {J_SOCO},
  author       = {Wan, Shu-ping and Zou, Wen-chang and Zhong, Long-gen and Dong, Jiu-ying},
  doi          = {10.1007/s00500-019-04446-w},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {9179-9203},
  shortjournal = {Soft Comput.},
  title        = {Some new information measures for hesitant fuzzy PROMETHEE method and application to green supplier selection},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A two-layer algorithm based on PSO for solving unit
commitment problem. <em>SOCO</em>, <em>24</em>(12), 9161–9178. (<a
href="https://doi.org/10.1007/s00500-019-04445-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is well known that electric generators consume huge amounts of energy every year. Nowadays, research for the unit commitment problem (UCP) has become a very important task in a power plant. However, the existing optimal methods for solving UCP are very easy to fall into local optimum, resulting in poor performance. Moreover, as no separate layering of economic load distribution, the existing algorithms are very inefficient. Toward this end, a new algorithm named improved simulated annealing particle swarm optimization (ISAPSO) is proposed in this paper. The proposed algorithm consists of a two-layer structure which is designed to simplify the complex problem of UCP. Specifically, in the upper layer, the algorithm based on elitist strategy PSO and SA is much easier to jump out of the local optimum when solving UCP and thus gets a better solution. In the lower layer, convex optimization approach is used to improve the search efficiency of ISAPSO. Furthermore, several methods are also designed to solve the problem-related constraints, which can save a lot of computing resources. Finally, the experimental results show that the cost performance of ISAPSO is better than that of the existing algorithms.},
  archive      = {J_SOCO},
  author       = {Zhai, Yu and Liao, Xiaofeng and Mu, Nankun and Le, Junqing},
  doi          = {10.1007/s00500-019-04445-x},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {9161-9178},
  shortjournal = {Soft Comput.},
  title        = {A two-layer algorithm based on PSO for solving unit commitment problem},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Performance analysis of six meta-heuristic algorithms over
automated test suite generation for path coverage-based optimization.
<em>SOCO</em>, <em>24</em>(12), 9143–9160. (<a
href="https://doi.org/10.1007/s00500-019-04444-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There exists a direct need to automate the process of test suite generation to get the most optimal results as testing accounts for more than 40\% of total cost. One method to solve this problem is the use of meta-heuristic algorithms which iteratively improve the test data to reach the most optimized test suites. This study focuses on the performance evaluation of six meta-heuristic algorithms namely: hill-climbing algorithm (HCA), particle swarm optimization (PSO), firefly algorithm (FA), cuckoo search algorithm (CS), bat algorithm (BA) and artificial bee colony algorithm (ABC) by using their standard implementation to optimize the path coverage and branch coverage produced by the test data. The goal of the study was to find the best-suited algorithm to narrow down the future research in the field of test automation for path coverage-based optimization approaches. Each algorithm was first implemented to automatically generate test suites based on the program under test. This was followed by the performance evaluation of each algorithm for five programs written in Java. The algorithms were compared using process metrics: average time, best time, worst time and product metrics: path coverage &amp; objective function values of the generated test suites. Results indicated ABC as the best-suited algorithm as it gave the most optimal test suites in reasonable time. BA was found to be the fastest but produced less optimal results. FA was found to be the slowest algorithm, while CS, PSO and HCA performed in between. These results show the relative performance of the six algorithms for this scenario and may be used by the future researchers to narrow down and improve the best performing algorithms for path coverage-based optimization approaches.},
  archive      = {J_SOCO},
  author       = {Khari, Manju and Sinha, Anunay and Verdú, Elena and Crespo, Ruben González},
  doi          = {10.1007/s00500-019-04444-y},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {9143-9160},
  shortjournal = {Soft Comput.},
  title        = {Performance analysis of six meta-heuristic algorithms over automated test suite generation for path coverage-based optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel life choice-based optimizer. <em>SOCO</em>,
<em>24</em>(12), 9121–9141. (<a
href="https://doi.org/10.1007/s00500-019-04443-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel metaheuristic algorithm named as life choice-based optimizer (LCBO) developed on the typical decision-making ability of humans to attain their goals while learning from fellow members. LCBO is investigated on 29 popular benchmark functions which included six CEC-2005 functions, and its performance has been benchmarked against seven optimization techniques including recent ones. Further, different abilities of LCBO optimization algorithm such as exploitation, exploration and local minima avoidance were also investigated and have been reported. In addition to this, scalability is tested for several benchmark functions where dimensions have been varied till 200. Furthermore, two engineering optimization benchmark problems, namely pressure vessel design and cantilever beam design, were also optimized using LCBO and the results have been compared with recently reported other algorithms. The obtained comparative results in all the above-mentioned experimentations revealed the clear superiority of LCBO over the other considered metaheuristic optimization algorithms. Therefore, based on the presented investigations, it is concluded that LCBO is a potential optimizer for engineering problems.},
  archive      = {J_SOCO},
  author       = {Khatri, Abhishek and Gaba, Akash and Rana, K. P. S. and Kumar, Vineet},
  doi          = {10.1007/s00500-019-04443-z},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {9121-9141},
  shortjournal = {Soft Comput.},
  title        = {A novel life choice-based optimizer},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An approach for solving fully fuzzy multi-objective linear
fractional optimization problems. <em>SOCO</em>, <em>24</em>(12),
9105–9119. (<a
href="https://doi.org/10.1007/s00500-019-04442-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents an algorithm for solving fully fuzzy multi-objective linear fractional (FFMOLF) optimization problem. Some computational algorithms have been developed for the solution of fully fuzzy single-objective linear fractional optimization problems. Veeramani and Sumathi (Appl Math Model 40:6148–6164, 2016) pointed out that no algorithm is available for solving a single-objective fully fuzzy optimization problem. Das et al. (RAIRO-Oper Res 51:285–297, 2017) proposed a method for solving single-objective linear fractional programming problem using multi-objective programming. Moreover, it is the fact that no method/algorithm is available for solving a FFMOLF optimization problem. In this article, a fully fuzzy MOLF optimization problem is considered, where all the coefficients and variables are assumed to be the triangular fuzzy numbers (TFNs). So, we are proposing an algorithm for solving FFMOLF optimization problem with the help of the ranking function and the weighted approach. To validate the proposed fuzzy intelligent algorithm, three existing classical numerical problems are converted into FFMOLF optimization problem using approximate TFNs. Then, the proposed algorithm is applied in an asymmetric way. Since there is no algorithm available in the existing literature for solving this difficult problem, we compare the obtained efficient solutions with corresponding existing methods for deterministic problems.},
  archive      = {J_SOCO},
  author       = {Arya, Rubi and Singh, Pitam and Kumari, Saru and Obaidat, Mohammad S.},
  doi          = {10.1007/s00500-019-04442-0},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {9105-9119},
  shortjournal = {Soft Comput.},
  title        = {An approach for solving fully fuzzy multi-objective linear fractional optimization problems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fuzzy bivariate triangular functions with application to
nonlinear fuzzy fredholm–volterra integral equations in two dimensions.
<em>SOCO</em>, <em>24</em>(12), 9091–9103. (<a
href="https://doi.org/10.1007/s00500-019-04439-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an iterative numerical method based on two-dimensional triangular basis functions has been presented to obtain the numerical solution of fuzzy Fredholm–Volterra integral equations in two dimensions. Error estimation of the proposed method has been gained in terms of uniform and partial modulus of continuity. Also, numerical stability with respect to choice of the starting point of iteration has been also proved under the any theorem. Finally, some numerical examples have been included to demonstrate the convergence and accuracy of the proposed method.},
  archive      = {J_SOCO},
  author       = {Karamseraji, S. and Ezzati, R. and Ziari, S.},
  doi          = {10.1007/s00500-019-04439-9},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {9091-9103},
  shortjournal = {Soft Comput.},
  title        = {Fuzzy bivariate triangular functions with application to nonlinear fuzzy Fredholm–Volterra integral equations in two dimensions},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Distance related: A procedure for applying directly
artificial bee colony algorithm in routing problems. <em>SOCO</em>,
<em>24</em>(12), 9071–9089. (<a
href="https://doi.org/10.1007/s00500-019-04438-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of the present paper is to introduce an innovative algorithmic approach, the Distance Related Artificial Bee Colony Algorithm (DRABC), as a variant of the original Artificial Bee Colony (ABC) algorithm. The aforementioned approach has been employed in the solution of the team orienteering problem (TOP). TOP fits into the category of vehicle routing problems with Profits, and such, each node is associated with a score value. The objective of the TOP is the formation of feasible routes with respect to a total travel time limit that corresponds to the total score value maximization. Summarizing the proposed approach, the algorithm applies the original equations of the ABC, on accordingly encoded solution vectors, namely on vectors that present the Euclidean distance between consecutive nodes in a route. This process is combined with a decoding method, to express the solution vector as an ordered sequence of nodes. This encoding/decoding method is referred to as “Distance Related” procedure. The proposed approach achieves most of the best known solutions of the benchmark instances found in the literature, and the performance of the DRABC algorithm is compared to others regarding the solution of the TOP.},
  archive      = {J_SOCO},
  author       = {Trachanatzi, Dimitra and Rigakis, Manousos and Marinaki, Magdalene and Marinakis, Yannis and Matsatsinis, Nikolaos},
  doi          = {10.1007/s00500-019-04438-w},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {9071-9089},
  shortjournal = {Soft Comput.},
  title        = {Distance related: A procedure for applying directly artificial bee colony algorithm in routing problems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Automating fake news detection system using multi-level
voting model. <em>SOCO</em>, <em>24</em>(12), 9049–9069. (<a
href="https://doi.org/10.1007/s00500-019-04436-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The issues of online fake news have attained an increasing eminence in the diffusion of shaping news stories online. Misleading or unreliable information in the form of videos, posts, articles, URLs is extensively disseminated through popular social media platforms such as Facebook and Twitter. As a result, editors and journalists are in need of new tools that can help them to pace up the verification process for the content that has been originated from social media. Motivated by the need for automated detection of fake news, the goal is to find out which classification model identifies phony features accurately using three feature extraction techniques, Term Frequency–Inverse Document Frequency (TF–IDF), Count-Vectorizer (CV) and Hashing-Vectorizer (HV). Also, in this paper, a novel multi-level voting ensemble model is proposed. The proposed system has been tested on three datasets using twelve classifiers. These ML classifiers are combined based on their false prediction ratio. It has been observed that the Passive Aggressive, Logistic Regression and Linear Support Vector Classifier (LinearSVC) individually perform best using TF-IDF, CV and HV feature extraction approaches, respectively, based on their performance metrics, whereas the proposed model outperforms the Passive Aggressive model by 0.8\%, Logistic Regression model by 1.3\%, LinearSVC model by 0.4\% using TF-IDF, CV and HV, respectively. The proposed system can also be used to predict the fake content (textual form) from online social media websites.},
  archive      = {J_SOCO},
  author       = {Kaur, Sawinder and Kumar, Parteek and Kumaraguru, Ponnurangam},
  doi          = {10.1007/s00500-019-04436-y},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {9049-9069},
  shortjournal = {Soft Comput.},
  title        = {Automating fake news detection system using multi-level voting model},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modeling and stability analysis methods of neutrosophic
transfer functions. <em>SOCO</em>, <em>24</em>(12), 9039–9048. (<a
href="https://doi.org/10.1007/s00500-019-04434-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncertainty is inherent property in actual control systems because parameters in actual control systems are no constants and changeable under some environments. Therefore, actual systems imply their indeterminate parameters, which can affect the control behavior and performance. Then, a neutrosophic number (NN) presented by Smarandache is very easy expressing determinate and/or indeterminate information because a NN p = c + dI is composed of its determinate term c and its indeterminate term dI for c, d ∈ R (R is all real numbers), where the symbol “I” denotes indeterminacy. Unfortunately, all uncertain modeling and analysis of practical control systems in existing literature do not provide any concept of NN models and analysis methods till now. Hence, this study firstly proposes a neutrosophic modeling method and defines a neutrosophic transfer function and a neutrosophic characteristic equation. Then, two stability analysis methods of neutrosophic linear systems are established based on the bounded range of all possible characteristic roots and the neutrosophic Routh stability criterion. Finally, the proposed methods are used for two practical examples on the RLC circuit and mass–spring–damper systems with NN parameters. The analysis results demonstrate the effectiveness and feasibility of the proposed methods.},
  archive      = {J_SOCO},
  author       = {Ye, Jun and Cui, Wenhua},
  doi          = {10.1007/s00500-019-04434-0},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {9039-9048},
  shortjournal = {Soft Comput.},
  title        = {Modeling and stability analysis methods of neutrosophic transfer functions},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Enhanced multi-objective crisscross optimization for dynamic
economic emission dispatch considering demand response and wind power
uncertainty. <em>SOCO</em>, <em>24</em>(12), 9021–9038. (<a
href="https://doi.org/10.1007/s00500-019-04431-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the dynamic economic emission dispatch problem in electric power system is formulated as a multi-objective optimization problem in a smart grid perspective. Accordingly, two additional subproblems are included in the dynamic economic emission dispatch formulation. Firstly, the wind power generation is penetrated into the system such that the uncertain power varies between a predicted upper and lower bounds. Secondly, a demand response program is implemented at the customer end, to modify the consumption pattern of electricity according to different electricity prices at valley, peak and off-peak periods. A two-level optimization is proposed to determine the optimal schedule of generating units such that the upper level solves for the minimization of cost and emission, whereas the lower level minimizes the wind power output interval reduction. An enhanced multi-objective crisscross optimization using non-dominated sorting approach is proposed as main optimizer to solve upper-level problem, and a linear programming is adopted to solve the lower-level problem. A 10-unit system is taken as a case study for demonstration, and the result shows the effectiveness of proposed formulation in terms of minimizing cost and emission.},
  archive      = {J_SOCO},
  author       = {Chinnadurrai, C L. and Victoire, T. Aruldoss Albert},
  doi          = {10.1007/s00500-019-04431-3},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {9021-9038},
  shortjournal = {Soft Comput.},
  title        = {Enhanced multi-objective crisscross optimization for dynamic economic emission dispatch considering demand response and wind power uncertainty},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Underdetermined blind source separation using CapsNet.
<em>SOCO</em>, <em>24</em>(12), 9011–9019. (<a
href="https://doi.org/10.1007/s00500-019-04430-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the problem of separating the speech source signal from the underdetermined convolutive mixture signals using capsule network (CapsNet). The objective of this paper is twofold. They are (1) to improve the underdetermined convolutive blind source separation algorithm in terms of signal-to-distortion ratio, signal-to-interference ratio and signal-to-artifact ratio; (2) to minimize the computational burden of the algorithm so that it is useful for applications like speech recognition system. The time–frequency points of the observed mixture signals are input to the first layer of CapsNet. In the first layer, single-source active point (SSP) is calculated using the ratio of mixtures. These SSPs are lower-level capsules in our system. In the second layer, we find a cluster center using a dynamic routing algorithm and these clusters are used to construct a binary mask. Finally, the algorithm solves the permutation problem by determining the correlation between the amplitudes of adjacent frequency bins. We test our algorithm on the live recording mixture signals obtained in the real environment and synthetically convoluted mixture signals. The test result shows the effectiveness of the proposed method when compared with the existing algorithms in terms of computational load, signal-to-distortion ratio and signal-to-interference ratio.},
  archive      = {J_SOCO},
  author       = {Kumar, M. and Jayanthi, V. E.},
  doi          = {10.1007/s00500-019-04430-4},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {9011-9019},
  shortjournal = {Soft Comput.},
  title        = {Underdetermined blind source separation using CapsNet},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A vertical ranking technique for linguistic hesitant fuzzy
sets. <em>SOCO</em>, <em>24</em>(12), 8997–9009. (<a
href="https://doi.org/10.1007/s00500-019-04426-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By the help of the current contribution, we are interested to present a different technique compared to the exiting ones for ranking linguistic hesitant fuzzy sets (LHFSs). In the existing techniques that are referred hereafter to as the horizontal ranking procedures of LHFSs, we sum up all the multiplications of subscript of linguistic variable by the score value of the corresponding HFS. Meanwhile, through the vertical ranking technique of LHFSs, for a fixed subscript of linguistic variable, we compare firstly the corresponding HFSs using the existing raking methods to achieve the corresponding individual preference matrix. Then, all the individual preference matrices are multiplied by the subscript of that corresponding linguistic variable to get the aggregated and collective preference matrix. Eventually, the final ranking order of LHFSs is extracted by the use of collective majority decision rule. By the way, as will be shown later, all the horizontal ranking techniques suffer drawbacks to some extent, and this is the motivation for enriching the theory of ranking LHFSs by introducing the vertical ranking technique.},
  archive      = {J_SOCO},
  author       = {Farhadinia, B. and Herrera-Viedma, Enrique},
  doi          = {10.1007/s00500-019-04426-0},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {8997-9009},
  shortjournal = {Soft Comput.},
  title        = {A vertical ranking technique for linguistic hesitant fuzzy sets},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Uncertain programming models for multi-objective shortest
path problem with uncertain parameters. <em>SOCO</em>, <em>24</em>(12),
8975–8996. (<a
href="https://doi.org/10.1007/s00500-019-04423-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The shortest path problem is considered as one of the essential problems in network optimization with a wide range of real-world applications. Modelling such real-world applications involves various indeterminate phenomena which can be estimated through human beliefs. The uncertainty theory proposed by Liu (Uncertain theory, 2nd edn., Springer, Berlin, 2007) is widely regarded as a legitimate tool to deal with such uncertainty. This paper presents an uncertain multi-objective shortest path problem (UMSPP) for a weighted connected directed graph (WCDG), where every edge weight is associated with two uncertain parameters: cost and time. These parameters are represented as uncertain variables. Here, we have formulated the expected value model and chance-constrained model of the proposed UMSPP, and the corresponding deterministic transformation of these models is also presented. Subsequently, the deterministic models are solved with a classical multi-objective solution method, namely the global criterion method. Furthermore, two multi-objective genetic algorithms (MOGAs): nondominated sorting genetic algorithm II (NSGA-II) and multi-objective cross-generational elitist selection, heterogeneous recombination and cataclysmic mutation (MOCHC), are employed to solve these models. A suitable example is provided to illustrate the proposed model. Finally, the performance of MOGAs is compared for five randomly generated instances of UMSPP.},
  archive      = {J_SOCO},
  author       = {Majumder, Saibal and Kar, Mohuya B. and Kar, Samarjit and Pal, Tandra},
  doi          = {10.1007/s00500-019-04423-3},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {8975-8996},
  shortjournal = {Soft Comput.},
  title        = {Uncertain programming models for multi-objective shortest path problem with uncertain parameters},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Clustering data stream with uncertainty using belief
function theory and fading function. <em>SOCO</em>, <em>24</em>(12),
8955–8974. (<a
href="https://doi.org/10.1007/s00500-019-04422-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data stream clustering faces major challenges such as lack of memory and time. Therefore, traditional clustering methods are not suitable for this kind of data. On the other hand, most data stream clustering methods do not consider the problems of uncertainty and ambiguity in the data. So, in this case, where an object is close to a set of clusters, this object cannot be correctly and simply categorized. The aim of this study is to provide a new method for clustering data stream, called clustering data stream using belief function, with regard to the problem of uncertain and ambiguous data. In the proposed method, the belief function theory is used to cluster objects into single clusters or a set of clusters and determines the structure of data. In addition, using window, weighted centers, and the fading function overcomes the restrictions of data stream. The results of the experiments have been compared with state-of-the-art methods, which show the superiority of the proposed method in terms of purity, error rate, and ambiguity rate measures.},
  archive      = {J_SOCO},
  author       = {Hamidzadeh, Javad and Ghadamyari, Reyhaneh},
  doi          = {10.1007/s00500-019-04422-4},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {8955-8974},
  shortjournal = {Soft Comput.},
  title        = {Clustering data stream with uncertainty using belief function theory and fading function},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A corridor selection for locating autonomous vehicles using
an interval-valued intuitionistic fuzzy AHP and TOPSIS method.
<em>SOCO</em>, <em>24</em>(12), 8937–8953. (<a
href="https://doi.org/10.1007/s00500-019-04421-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous vehicles (AVs) provide a new mobility option and have been becoming widespread around the world. They can be used not only as automobiles but also as public transport vehicles in the form of shuttles, buses and pods. One of the problem areas in implementing AVs as a public transport vehicle is to choose a suitable road for operating them. A fuzzy decision model combining analytic hierarchy process (AHP) and technique for order of preference by similarity to ideal solution (TOPSIS) techniques with intuitionistic fuzzy sets is used to solve this problem. The results show that the BRT corridor is the most suitable option for operating AVs according to the decision criteria. Furthermore, operating AVs on a BRT corridor provides an unprecedented service provision approach.},
  archive      = {J_SOCO},
  author       = {Dogan, Onur and Deveci, Muhammet and Canıtez, Fatih and Kahraman, Cengiz},
  doi          = {10.1007/s00500-019-04421-5},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {8937-8953},
  shortjournal = {Soft Comput.},
  title        = {A corridor selection for locating autonomous vehicles using an interval-valued intuitionistic fuzzy AHP and TOPSIS method},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Variable neighborhood search-based methods for integrated
hybrid flow shop scheduling with distribution. <em>SOCO</em>,
<em>24</em>(12), 8917–8936. (<a
href="https://doi.org/10.1007/s00500-019-04420-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of make-to-order pattern including E-commerce and takeout and catering service in restaurants, the study of integrated scheduling and distribution receives more and more attentions. Based on a practical order picking and distribution system, a three-stage hybrid flow shop scheduling problem with distribution is studied. Each order is processed on the hybrid flow shop which consists of identical parallel machines with sequence-dependent setup times at stage 1, identical parallel machines at stage 2 and dedicated machines at stage 3, followed by a multi-trip traveling salesman problem with capacitated vehicles for customers of different destination areas. A mixed-integer linear programming model is formulated to minimize the maximum delivery completion time. A variable neighborhood search (VNS)-based method, a four-layered constructive heuristic method (denoted by $$CH_{VNS}$$) and a hybrid heuristic method (denoted by $$CONS_{VNS}$$) which combines the VNS method and the $$CH_{VNS}$$ method are developed to solve the problems with practical size. Computational experiments show the effectiveness and efficiency of the proposed methods.},
  archive      = {J_SOCO},
  author       = {Wang, Shijin and Wu, Ruochen and Chu, Feng and Yu, Jianbo},
  doi          = {10.1007/s00500-019-04420-6},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {8917-8936},
  shortjournal = {Soft Comput.},
  title        = {Variable neighborhood search-based methods for integrated hybrid flow shop scheduling with distribution},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Supplier selection using extended IT2 fuzzy TOPSIS and IT2
fuzzy MOORA considering subjective and objective factors. <em>SOCO</em>,
<em>24</em>(12), 8899–8915. (<a
href="https://doi.org/10.1007/s00500-019-04419-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During recent years, determination of efficient supplier has become a major challenge for improving the organizational efficiency. However, determination of suitable suppliers is always a complex multiple criteria decision-making (MCDM) problem because it involves the consideration of a large number of objective and subjective factors and also the factors may be uncertain and conflict in nature. This paper presents two novel MCDM techniques in interval type-2 fuzzy (IT2F) environment capable of handling uncertain subjective and objective factors simultaneously for selection of efficient suppliers in real-life applications. Technique for order preference by similarity to the ideal solution (TOPSIS) and multi-objective optimization on the basis of ratio analysis (MOORA) methods are used in IT2F environment to evaluate subjective factors with regard to subjective factor measures (SFM), and traditional normalization technique is used to evaluate the objective factors in terms of objective factor measures (OFMs). Then, SFM and OFM are used to calculate supplier selection index (SSI) by using Brown and Gibson model. The proposed models are then demonstrated with a case study in an Indian manufacturing organization for selection of efficient suppliers. Sensitivity analysis and comparative study of the results are carried out. It is found that the model is useful and efficient for decision making and evaluation of suitable suppliers in an uncertain environment.},
  archive      = {J_SOCO},
  author       = {Bera, Ashoke Kumar and Jana, Dipak Kumar and Banerjee, Debamalya and Nandy, Titas},
  doi          = {10.1007/s00500-019-04419-z},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {8899-8915},
  shortjournal = {Soft Comput.},
  title        = {Supplier selection using extended IT2 fuzzy TOPSIS and IT2 fuzzy MOORA considering subjective and objective factors},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Terminal observer and disturbance observer for the class of
fractional-order chaotic systems. <em>SOCO</em>, <em>24</em>(12),
8881–8898. (<a
href="https://doi.org/10.1007/s00500-019-04418-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a terminal fractional-order observer and a terminal disturbance observer is proposed to estimate internal states and external disturbances of the class of fractional-order chaotic systems. The estimation of states within fixed time is achieved by employing a nonlinear feedback in terms of the observer error. The fixed convergence time is not relevant to the initial conditions and can be adjusted to any desired values by tuning the designable parameters. Finally, the numerical simulations are performed on fractional-order chaotic Liu, Chen, and Financial systems to validate the theoretical results. Moreover, some numerical simulations are provided to compare the obtained theoretical results with the other methods in the literature.},
  archive      = {J_SOCO},
  author       = {Soltanpour, Mohammad Reza and Shirkavand, Mehrdad},
  doi          = {10.1007/s00500-019-04418-0},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {8881-8898},
  shortjournal = {Soft Comput.},
  title        = {Terminal observer and disturbance observer for the class of fractional-order chaotic systems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A multi-criteria group decision making algorithm with
quadripartitioned neutrosophic weighted aggregation operators using
quadripartitioned neutrosophic numbers in IPQSVNSS environment.
<em>SOCO</em>, <em>24</em>(12), 8857–8880. (<a
href="https://doi.org/10.1007/s00500-019-04417-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, quadripartitioned neutrosophic numbers (QNNs) are introduced, operations over them have been defined and some of their properties have been studied. QNNs have been implemented in defining the quadripartitioned neutrosophic weighted arithmetic averaging operator and the quadripartitioned neutrosophic weighted geometric averaging operator for ranking the final scores of the alternatives and choosing the most suitable alternative among them. The concept of interval-valued possibility quadripartitioned single-valued neutrosophic soft sets has been utilized to propose an algorithm for a multi-criteria group decision making problem. In this approach, entropy-based weights are allocated to the elements of the universe of discourse under consideration. Finally, the obtained results are compared with existing ones by means of comparative studies.},
  archive      = {J_SOCO},
  author       = {Chatterjee, R. and Majumdar, P. and Samanta, S. K.},
  doi          = {10.1007/s00500-019-04417-1},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {8857-8880},
  shortjournal = {Soft Comput.},
  title        = {A multi-criteria group decision making algorithm with quadripartitioned neutrosophic weighted aggregation operators using quadripartitioned neutrosophic numbers in IPQSVNSS environment},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel hybrid metaheuristic optimization method: Hypercube
natural aggregation algorithm. <em>SOCO</em>, <em>24</em>(12),
8823–8856. (<a
href="https://doi.org/10.1007/s00500-019-04416-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The natural aggregation algorithm (NAA) is a new efficient population-based optimizer. The NAA has a competent performance when compared to other well-established optimizers. However, a problem of concern is NAA lack of exploitation in its local search. In this article, we propose an improved version of NAA. The modifications made are: hypercubes with displacement and shrink mechanism applied in each shelter, we designed a new movement operator to search inside the hypercubes, an improved readjustment of the algorithm’s parameters and “leave shelter” formula of NAA, to better mimic the aggregation behavior. To prove the effectiveness of the modified hypercube natural aggregation algorithm (HYNAA), we compared with classics optimizers, such as PSO, DE and ABC, state of the art, such as CMA-ES, MSA and NAA himself with a benchmark of 28 functions. The said functions consist of five unimodal, 19 multimodal and four hybrids, and we compared them on 30, 50 and 100 dimensions. We also made extra comparisons against NAA in 500 and 1000 dimensions to contrast the ability of the hypercubes to reduce the dimensional complexity. Finally, we tested two trajectory optimization problems. Experimental results and statistical tests demonstrate that the performance of HYNAA is significantly better than that of other optimizers.},
  archive      = {J_SOCO},
  author       = {Maciel, Oscar and Valdivia, Arturo and Oliva, Diego and Cuevas, Erik and Zaldívar, Daniel and Pérez-Cisneros, Marco},
  doi          = {10.1007/s00500-019-04416-2},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {8823-8856},
  shortjournal = {Soft Comput.},
  title        = {A novel hybrid metaheuristic optimization method: Hypercube natural aggregation algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Application of artificial neural networks to predict flow
velocity in a 180° sharp bend with and without a spur dike.
<em>SOCO</em>, <em>24</em>(12), 8805–8821. (<a
href="https://doi.org/10.1007/s00500-019-04413-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work has compared the performance of three well-known artificial neural network (ANN) approaches in turbulent flow pattern modeling based on geometric characteristics of the channel (angle of horizon, distance from outer bank of the bend, and distance from the bed) in a 180° sharp bend with and without a T-shaped spur dike. ANN methods discussed in this work are feed-forward neural network, cascade feed-forward neural network, and extreme learning machines. Acoustic Doppler velocimetry is used to measure the velocity components in x, y, and z directions. Conducting this research is innovative and significant from three aspects: First, the data of the flow pattern around T-shaped spur dikes in a 180° bend, given its high importance in rivers in nature, are very rarely available; second, application of neural network models for understanding the flow nature is highly efficient at other bend points where no experimental or field measurements have been conducted; and third, with these models, the cost and time required for conducting numerical and experimental modeling for prediction of the flow velocity significantly decrease. Outliers (abnormalities or anomalies) may be generated by various factors in the measured velocities. Before modeling by ANNs, the self-organizing map clustering method is used to detect outliers to obtain more accurate models. Performance of ANN models is evaluated using correlation coefficient (R) and root mean squared error criteria. In order to compare the performance of ANNs in flow velocity modeling at different locations of the bend, seven different data groups are considered using different combinations of samples by random sampling. Results of comparison of ANN models with experimental data indicate that ANNs provide reasonable results in most cases and may be employed successfully in estimating the velocity in sharp bends with and without the presence of a spur dike. Moreover, it may be concluded that ANN models without spur dikes are more accurate than those with spur dikes due to creating less turbulence flow.},
  archive      = {J_SOCO},
  author       = {Vaghefi, Mohammad and Mahmoodi, Kumars and Setayeshi, Saeed and Akbari, Maryam},
  doi          = {10.1007/s00500-019-04413-5},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {8805-8821},
  shortjournal = {Soft Comput.},
  title        = {Application of artificial neural networks to predict flow velocity in a 180° sharp bend with and without a spur dike},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). MV-algebras as sheaves of <span
class="math display"><em>ℓ</em></span>-groups on fuzzy topological
spaces. <em>SOCO</em>, <em>24</em>(12), 8793–8804. (<a
href="https://doi.org/10.1007/s00500-020-04944-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce the concept of fuzzy sheaf as a natural generalization of a sheaf over a topological space in the context of fuzzy topologies. Then, we prove a representation for a class of MV-algebras that we called “locally retractive,” in which the representing object is an MV-sheaf of lattice-ordered Abelian groups, namely a fuzzy sheaf in which the base (fuzzy) topological space is an MV-topological space and the stalks are Abelian $$\ell $$-groups. Last, we show that any MV-algebra is embeddable in a locally retractive algebra and, therefore, in the algebra of global sections of one of such sheaves.},
  archive      = {J_SOCO},
  author       = {De La Pava, Luz Victoria and Russo, Ciro},
  doi          = {10.1007/s00500-020-04944-2},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {8793-8804},
  shortjournal = {Soft Comput.},
  title        = {MV-algebras as sheaves of $$\ell $$-groups on fuzzy topological spaces},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). European option pricing under multifactor uncertain
volatility model. <em>SOCO</em>, <em>24</em>(12), 8781–8792. (<a
href="https://doi.org/10.1007/s00500-020-04919-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an uncertain stock model under the multifactor uncertain volatility framework. Based on the uncertainty theory, some closed-form and analytical formulas presented to value a European call and put option under the multifactor uncertain volatility model. Numerical tests are reported to highlight how the proposed model provides interesting results on pricing a European option. Finally, we summarize the theoretical results and some numerical experiments.},
  archive      = {J_SOCO},
  author       = {Hassanzadeh, Sabahat and Mehrdoust, Farshid},
  doi          = {10.1007/s00500-020-04919-3},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {8781-8792},
  shortjournal = {Soft Comput.},
  title        = {European option pricing under multifactor uncertain volatility model},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A fuzzy generalized power series method under generalized
hukuhara differentiability for solving fuzzy legendre differential
equation. <em>SOCO</em>, <em>24</em>(12), 8763–8779. (<a
href="https://doi.org/10.1007/s00500-020-04913-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, first the fuzzy generalized power series method, in which the coefficients are fuzzy numbers, is introduced, and then, the conditions of the uniqueness of the solution and its convergence for the fuzzy differential equation are investigated. Then, using the fuzzy generalized power series method, the fuzzy Legendre differential equation is considered as a case study, and finally, for further illustration some related examples are solved.},
  archive      = {J_SOCO},
  author       = {Sabzi, Khadijeh and Allahviranloo, Tofigh and Abbasbandy, Saeid},
  doi          = {10.1007/s00500-020-04913-9},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {8763-8779},
  shortjournal = {Soft Comput.},
  title        = {A fuzzy generalized power series method under generalized hukuhara differentiability for solving fuzzy legendre differential equation},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A characterization of pseudofinite MV-algebras.
<em>SOCO</em>, <em>24</em>(12), 8751–8761. (<a
href="https://doi.org/10.1007/s00500-020-04910-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider pseudofinite MV-algebras. As a main result, we show that an infinite MV-algebra is pseudofinite if and only if it is definably well founded, improving a result of a previous paper. Moreover, we show that the theory of pseudofinite MV-algebras has a partial form of elimination of quantifiers. Further, we show that the class of pseudofinite MV-chains and the class of pseudofinite MV-algebras are not finitely axiomatizable, we give some collapsing results for pseudofinite MV-algebras, we consider relative subalgebras of pseudofinite MV-algebras, and we study ideals of pseudofinite MV-algebras.},
  archive      = {J_SOCO},
  author       = {Farsimadan, Eslam and Lenzi, Giacomo and Rizzo, Paolo and Saeid, Arsham Borumand},
  doi          = {10.1007/s00500-020-04910-y},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {8751-8761},
  shortjournal = {Soft Comput.},
  title        = {A characterization of pseudofinite MV-algebras},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A latent variable model for two-dimensional canonical
correlation analysis and the variational inference. <em>SOCO</em>,
<em>24</em>(12), 8737–8749. (<a
href="https://doi.org/10.1007/s00500-020-04906-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The probabilistic dimension reduction has been and is a major concern. Probabilistic models provide a better interpretability of the dimension reduction methods and present a framework for their further extensions. In pattern recognition problems, data that have a matrix or tensor structure is initially transformed into a vector format. This eliminates the internal structure of the data. The available perspective is to maintain the internal structure of each data while reducing the dimensionality, which can reduce the small sample size problem. Canonical correlation analysis is one of the most important techniques in dimension reduction in multi-view data. A two-dimensional canonical correlation analysis as an extension of canonical correlation analysis has been proposed to preserve the matrix structure of the data. Here, a new probabilistic framework for two-dimensional canonical correlation analysis is proposed, where the matrix-variate distributions are applied to model the relation between the latent matrix and the two-view matrix-variate observed data. These distributions, specific to the matrix data, can provide better understanding of two-dimensional canonical correlation analysis and pave the way for further extensions. In general, there does not exist any analytical maximum likelihood solution for this model; therefore, here the two approaches, one based on the expectation maximization and other on variational expected maximization, are proposed for learning the model parameters. The synthetic data are applied to evaluate the convergence and quality of the mapping of these algorithms. The functionalities of these methods and their counterparts are compared on the real face datasets.},
  archive      = {J_SOCO},
  author       = {Safayani, Mehran and Momenzadeh, Saeid and Mirzaei, Abdolreza and Razavi, Masoomeh Sadat},
  doi          = {10.1007/s00500-020-04906-8},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {8737-8749},
  shortjournal = {Soft Comput.},
  title        = {A latent variable model for two-dimensional canonical correlation analysis and the variational inference},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On typical hesitant fuzzy automata. <em>SOCO</em>,
<em>24</em>(12), 8725–8736. (<a
href="https://doi.org/10.1007/s00500-020-04896-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study a new generalization for the notion of fuzzy automata, which we called typical hesitant fuzzy automata. First, we present the formulations of the mathematics framework for the theory of typical hesitant fuzzy automata. Second, we then show a method to transform nondeterministic typical hesitant fuzzy automata (in short nthfa) into deterministic typical hesitant fuzzy automata (in short dthfa), which is effective at removing nondeterminism but does not preserve faithfully the associated typical hesitant fuzzy language. Moreover, we show that the power of any nthfa is equivalent to a finite family of fuzzy automata.},
  archive      = {J_SOCO},
  author       = {Costa, Valdigleis S. and Bedregal, Benjamin C.},
  doi          = {10.1007/s00500-020-04896-7},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {8725-8736},
  shortjournal = {Soft Comput.},
  title        = {On typical hesitant fuzzy automata},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Residuated lattice of l-fuzzy ideals of a ring.
<em>SOCO</em>, <em>24</em>(12), 8717–8724. (<a
href="https://doi.org/10.1007/s00500-020-04894-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In 1988, given a complete Brouwerian lattice $${\mathbb {L}}:=(L;~\wedge ,~\vee ;~0,~1)$$ and a ring $${\mathcal {A}}:=(A;~+,~\cdot ;~-;~0)$$ with unity 1, Swamy and Swamy (J Math Anal Appl 134:94–103, 1988) built a lattice structure, on the set of L-fuzzy ideals of $${\mathcal {A}}$$, and investigated some of its arithmetic properties. Since the residuation theory is richer than the lattice theory [see, Ciungu (Non-commutative multiple-valued logic algebras, Springer monographs in mathematics, Springer, Berlin, 2014), Galatos et al. (An algebraic glimpse at substructural logics, volume 151 of studies in logic and the foundations of mathematics, Elsevier, Amsterdam, 2007), Jipsen and Tsinakis (in: Martinez (ed) Ordered algebraic structures, Kluwer Academic Publisher, Dordrecht, 2002), Piciu (Algebras of fuzzy logic, Editura Universitaria Craiova, Craiova, 2007)], in this paper, we consider the notion of fuzzy ideals rather under a complete Brouwerian residuated lattice $${\mathcal {L}}:=(L;~\wedge ,~\vee ,~\ominus ,~\twoheadrightarrow ,~\multimap ;~0,~1)$$. A residuated lattice $${\mathcal {F}}id({\mathcal {A}},L):=\big ( Fid({\mathcal {A}},L);~\wedge ,~+,~\otimes ,~\hookrightarrow ,~\looparrowright ; ~\chi _0,~{\underline{1}}\big )$$ is built on the set $$Fid({\mathcal {A}},L)$$ of L-fuzzy ideals of $${\mathcal {A}}$$ and it is shown that the latter is both an extension of $${\mathcal {L}}$$ and the residuated lattice $${\mathcal {I}}d({\mathcal {A}}):=\big (Id({\mathcal {A}});~\cap ,~+,~\odot ,~\rightarrow ,~\rightsquigarrow ;~{0},~A \big )$$ on the set $$Id({\mathcal {A}})$$ of ideals of $${\mathcal {A}}$$.},
  archive      = {J_SOCO},
  author       = {Foka, S. V. Tchoffo and Tonga, Marcel},
  doi          = {10.1007/s00500-020-04894-9},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {8717-8724},
  shortjournal = {Soft Comput.},
  title        = {Residuated lattice of L-fuzzy ideals of a ring},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Representation of de morgan and (semi-)kleene lattices.
<em>SOCO</em>, <em>24</em>(12), 8685–8716. (<a
href="https://doi.org/10.1007/s00500-020-04885-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Twist-structure representation theorems are established for De Morgan and Kleene lattices. While the former result relies essentially on the quasivariety of De Morgan lattices being finitely generated, the representation for Kleene lattices does not and can be extended to more general algebras. In particular, one can drop the double negation identity (involutivity). The resulting class of algebras, named semi-Kleene lattices by analogy with Sankappanavar’s semi-De Morgan lattices, is shown to be representable through a twist-structure construction inspired by the Cornish–Fowler duality for Kleene lattices. Quasi-Kleene lattices, a subvariety of semi-Kleene, are also defined and investigated, showing that they are precisely the implication-free subreducts of the recently introduced class of quasi-Nelson lattices.},
  archive      = {J_SOCO},
  author       = {Rivieccio, Umberto},
  doi          = {10.1007/s00500-020-04885-w},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {8685-8716},
  shortjournal = {Soft Comput.},
  title        = {Representation of de morgan and (Semi-)Kleene lattices},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Human body flexibility fitness test based on image edge
detection and feature point extraction. <em>SOCO</em>, <em>24</em>(12),
8673–8683. (<a
href="https://doi.org/10.1007/s00500-020-04869-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a human flexibility fitness detection algorithm based on edge detection and feature point extraction. This algorithm first improves on the deficiency of the classical Canny operator. Specifically, a hybrid filter is used instead of the original Gaussian filter to improve filtering performance. Next, the templates in the $$45^\circ $$ and $$135^\circ $$ directions are added based on the original gradient calculation templates, and Otsu algorithm is used to achieve threshold segmentation to obtain the final edge information. Then, based on the obtained edge information, a human body feature point extraction algorithm for calculating the anteflexion angle is proposed, and the feature points of the shoulder, hip, and leg of the person are extracted, and the angle formed by these points is calculated. Size is used to achieve human body flexibility and fitness testing. In order to verify the effectiveness of the edge detection algorithm proposed in this paper, experiments are performed to compare with other algorithms, and the results show that the results of our algorithm are more accurate.},
  archive      = {J_SOCO},
  author       = {Lu, Xu and Zhang, Yujing},
  doi          = {10.1007/s00500-020-04869-w},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {8673-8683},
  shortjournal = {Soft Comput.},
  title        = {Human body flexibility fitness test based on image edge detection and feature point extraction},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Incrementally updating approximations based on the graded
tolerance relation in incomplete information tables. <em>SOCO</em>,
<em>24</em>(12), 8655–8671. (<a
href="https://doi.org/10.1007/s00500-020-04838-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The incremental learning methods based on rough set theory are effective in acquiring knowledge in dynamically changing information tables. In this paper, we focus on the effective acquisition of decision rules by incrementally updating approximations when an incomplete information table changes. First of all, we present a four-step model to obtain three-way decision rules in an incomplete information table based on the graded tolerance relation. The first step presents the graded tolerance relation between objects. The second step calculates the degrees of objects belonging to approximations by using fuzzy logic operators. Besides, we propose a relation matrix to calculate the degrees efficiently. The third step gets three-way approximations by applying a pair of thresholds to the degrees. The fourth step obtains three-way decision rules based on the descriptions of objects. According to the four-step model, we find the notion of approximations plays an essential role in rule acquisition. Incrementally updating approximations are an effective method to obtain decision rules when an incomplete information changes. Accordingly, we study the incrementally updating approximations by incrementally updating the relation matrix when changing attributes, objects, and the attribute value of an object. Finally, experimental results illustrate that the incremental methods are more effective than non-incremental methods.},
  archive      = {J_SOCO},
  author       = {Luo, Junfang and Qin, Keyun and Zhang, Yimeng and Zhao, Xue Rong},
  doi          = {10.1007/s00500-020-04838-3},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {8655-8671},
  shortjournal = {Soft Comput.},
  title        = {Incrementally updating approximations based on the graded tolerance relation in incomplete information tables},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improving portfolios global performance using a cleaned and
robust covariance matrix estimate. <em>SOCO</em>, <em>24</em>(12),
8643–8654. (<a
href="https://doi.org/10.1007/s00500-020-04840-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents how the use of a cleaned and robust covariance matrix estimate can improve significantly the overall performance of maximum variety and minimum variance portfolios. We assume that the asset returns are modelled through a multi-factor model where the error term is a multivariate and correlated elliptical symmetric noise extending the classical Gaussian assumptions. The factors are supposed to be unobservable and we focus on a recent method of model order selection, based on the random matrix theory to identify the most informative subspace and then to obtain a cleaned (or de-noised) covariance matrix estimate to be used in the maximum variety and minimum variance portfolio allocation processes. We apply our methodology on real market data and show the improvements it brings if compared with other techniques especially for non-homogeneous asset returns.},
  archive      = {J_SOCO},
  author       = {Jay, Emmanuelle and Soler, Thibault and Terreaux, Eugénie and Ovarlez, Jean-Philippe and Pascal, Frédéric and De Peretti, Philippe and Chorro, Christophe},
  doi          = {10.1007/s00500-020-04840-9},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {8643-8654},
  shortjournal = {Soft Comput.},
  title        = {Improving portfolios global performance using a cleaned and robust covariance matrix estimate},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). De-risking long-term care insurance. <em>SOCO</em>,
<em>24</em>(12), 8627–8641. (<a
href="https://doi.org/10.1007/s00500-019-04658-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a de-risking strategy model for LTC insurers facing with longevity and disability risks, by constructing hedge positions with vanilla disability swaps and options. We rely on long-term care insurance in a multiple state framework. The optimal hedge level for each de-risking strategies is computed, respectively, by minimizing the total cost of the de-risking strategy under the Conditional Value-at-Risk (CVaR) constraint on the total unfunded liabilities and minimizing the CVaR under a total cost constraint. A numerical application is performed, and the results suggest that a de-risking strategy based on disability derivatives can be a viable solution to reduce the portfolio riskiness of LTC insurers.},
  archive      = {J_SOCO},
  author       = {D’Amato, Valeria and Levantesi, Susanna and Menzietti, Massimiliano},
  doi          = {10.1007/s00500-019-04658-0},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {8627-8641},
  shortjournal = {Soft Comput.},
  title        = {De-risking long-term care insurance},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Testing for non-chaoticity under noisy dynamics using the
largest lyapunov exponent. <em>SOCO</em>, <em>24</em>(12), 8617–8626.
(<a href="https://doi.org/10.1007/s00500-019-04595-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a robust procedure to test for non-chaoticity when data are contaminated by an additive noise. Under the Kalman filter framework, our procedure first amounts to compute the largest Lyapunov exponent of the extracted signal. The exponent describes the log-divergence of a dynamical system (Rosenstein et al. in Phys D 65(1–2):117–134, 1993. https://doi.org/10.1016/0167-2789(93)90009-p). Then, using the so-called simulation smoother, we generate a high number of trajectories of the state-vector, conditional on the observed series, and compute the empirical distribution of the largest Lyapunov exponent. The distribution allows for computing confidence intervals. We can thus test if the largest Lyapunov exponent is not significantly greater than zero. Using Monte Carlo simulations, we show the validity of such an approach. We provide an illustration using toy models, which depict several dynamical systems. Finally, we implement tests of non-chaoticity on financial time series. We find no empirical evidence of chaotic patterns. Our approach is simple, efficient, and tests for chaos when data are measured with errors (i.e., noisy dynamics).},
  archive      = {J_SOCO},
  author       = {Gatfaoui, Hayette and de Peretti, Philippe},
  doi          = {10.1007/s00500-019-04595-y},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {8617-8626},
  shortjournal = {Soft Comput.},
  title        = {Testing for non-chaoticity under noisy dynamics using the largest lyapunov exponent},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Determination of the financial minimum in a municipal budget
to deal with crisis situations. <em>SOCO</em>, <em>24</em>(12),
8607–8616. (<a
href="https://doi.org/10.1007/s00500-019-04527-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper offers an analysis of the mission and role of municipalities in the Czech national crisis management system. The paper clarifies the nature of population protection within the national security system accentuating resource availability. The significance of local municipal budgets as the baseline to crisis solution support within the administered area is discussed. The problem is not the system of budgets or the budgeting system itself at the level of local government. The key issue, however, is the determination of budget resources, which are primarily predetermined ex ante for the crisis prevention resolution phase. Current legislation does not address this requirement. The authors also point out the fundamental influence of local policy in the allocation of resources in the municipal budget in relation to their political preferences. Therefore, the authors of the article propose the calculation method for the standard minimum amount of financial resources allocated to coping with crises in the municipal budget at their level, as appropriate. The submitted proposal will contribute to guaranteeing a minimum level of preparedness for crisis management in ensuring the safety of all residents.},
  archive      = {J_SOCO},
  author       = {Kudlák, Aleš and Urban, Rudolf and Hošková-Mayerová, Šárka},
  doi          = {10.1007/s00500-019-04527-w},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {8607-8616},
  shortjournal = {Soft Comput.},
  title        = {Determination of the financial minimum in a municipal budget to deal with crisis situations},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A method to decompose the systemic risk in geographic areas.
<em>SOCO</em>, <em>24</em>(12), 8599–8606. (<a
href="https://doi.org/10.1007/s00500-019-04463-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a method for evaluating systemic risk in different geographic areas is presented. The proposed methodology is based on the decomposition by subpopulations of the Gini index, largely used to assess the inequality of income and wealth. This decomposition procedure follows a two-step approach that goes beyond the “classical” decomposition Within and Between components, also allowing the assessment of the contribution to the total inequality for each subpopulation.},
  archive      = {J_SOCO},
  author       = {Fiori, Anna Maria and Porro, Francesco},
  doi          = {10.1007/s00500-019-04463-9},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {8599-8606},
  shortjournal = {Soft Comput.},
  title        = {A method to decompose the systemic risk in geographic areas},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Tackling longevity risk by means of financial compensation.
<em>SOCO</em>, <em>24</em>(12), 8583–8597. (<a
href="https://doi.org/10.1007/s00500-019-04433-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The remarkable increases in life expectancy observed over the last decades have posed a major challenge to pension funds and annuity providers because of the related systematic longevity risk. This article proposes a variable payout life annuity where benefits have to follow the observed mortality and the interest rates obtained. This scheme is effective and efficient for annuity providers, who always have a fund that matches exactly the undertaken commitments to annuitants. On the other hand, potential reductions in the benefit payments can be felt by annuitants more bearable than those that include a safety loading. Specifically, the concept of observed survival probabilities is introduced and applied to: (a) translate a demographic change into the related financial adjustment; (b) decompose a demographic change into two effects, one stemming from the survival probability observations and the other from life table updates; (c) show that the financial compensation mechanism should run for single cohorts to avoid creating inequalities for older and smaller cohorts.},
  archive      = {J_SOCO},
  author       = {Di Palo, Cinzia},
  doi          = {10.1007/s00500-019-04433-1},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {8583-8597},
  shortjournal = {Soft Comput.},
  title        = {Tackling longevity risk by means of financial compensation},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Influence measures in subnetworks using vertex centrality.
<em>SOCO</em>, <em>24</em>(12), 8569–8582. (<a
href="https://doi.org/10.1007/s00500-019-04428-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work deals with the issue of assessing the influence of a node in the entire network and in the subnetwork to which it belongs as well, adapting the classical idea of vertex centrality. We provide a general definition of relative vertex centrality measure with respect to the classical one, referred to the whole network. Specifically, we give a decomposition of the relative centrality measure by including also the relative influence of the single node with respect to a given subgraph containing it. The proposed measure of relative centrality is tested in the empirical networks generated by collecting assets of the $$ S \&amp; P$$ 100, focusing on two specific centrality indices: betweenness and eigenvector centrality. The analysis is performed in a time perspective, capturing the assets influence, with respect to the characteristics of the analysed measures, in both the entire network and the specific sectors to which the assets belong.},
  archive      = {J_SOCO},
  author       = {Cerqueti, Roy and Clemente, Gian Paolo and Grassi, Rosanna},
  doi          = {10.1007/s00500-019-04428-y},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {8569-8582},
  shortjournal = {Soft Comput.},
  title        = {Influence measures in subnetworks using vertex centrality},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A random forest algorithm to improve the lee–carter
mortality forecasting: Impact on q-forward. <em>SOCO</em>,
<em>24</em>(12), 8553–8567. (<a
href="https://doi.org/10.1007/s00500-019-04427-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Increased life expectancy in developed countries has led researchers to pay more attention to mortality projection to anticipate changes in mortality rates. Following the scheme proposed in Deprez et al. (Eur Actuar J 7(2):337–352, 2017) and extended by Levantesi and Pizzorusso (Risks 7(1):26, 2019), we propose a novel approach based on the combination of random forest and two-dimensional P-spline, allowing for accurate mortality forecasting. This approach firstly provides a diagnosis of the limits of the Lee–Carter mortality model through the application of the random forest estimator to the ratio between the observed deaths and their estimated values given by a certain model, while the two-dimensional P-spline are used to smooth and project the random forest estimator in the forecasting phase. Further considerations are devoted to assessing the demographic consistency of the results. The model accuracy is evaluated by an out-of-sample test. Finally, we analyze the impact of our model on the pricing of q-forward contracts. All the analyses have been carried out on several countries by using data from the Human Mortality Database and considering the Lee–Carter model.},
  archive      = {J_SOCO},
  author       = {Levantesi, Susanna and Nigri, Andrea},
  doi          = {10.1007/s00500-019-04427-z},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {8553-8567},
  shortjournal = {Soft Comput.},
  title        = {A random forest algorithm to improve the Lee–Carter mortality forecasting: Impact on q-forward},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Polynomial goal programming and particle swarm optimization
for enhanced indexation. <em>SOCO</em>, <em>24</em>(12), 8535–8551. (<a
href="https://doi.org/10.1007/s00500-019-04378-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enhanced indexation is an investment strategy that aims to generate moderate and consistent excess returns with respect to a tracked benchmark index. In this work, we introduce an optimization approach where the risk of under-performing the benchmark is separated from the potential over-performance, and the Sharpe ratio measures the profitability of the active management. In addition, a cardinality constraint controls the number of active positions in the portfolio, while a turnover threshold limits the transaction costs. We adopt a polynomial goal programming approach to combine these objectives with the investor’s preferences. An improved version of the particle swarm optimization algorithm with a novel constraint-handling mechanism is proposed to solve the optimization problem. A numerical example, where the Euro Stoxx 50 Index is used as the benchmark, shows that our method consistently produces larger returns, with reduced costs and risk exposition, than the standard indexing strategies over a 10-year backtesting period.},
  archive      = {J_SOCO},
  author       = {Kaucic, Massimiliano and Barbini, Fabrizio and Camerota Verdù, Federico Julian},
  doi          = {10.1007/s00500-019-04378-5},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {8535-8551},
  shortjournal = {Soft Comput.},
  title        = {Polynomial goal programming and particle swarm optimization for enhanced indexation},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A quantile regression approach for the analysis of the
diversification in non-life premium risk. <em>SOCO</em>,
<em>24</em>(12), 8523–8534. (<a
href="https://doi.org/10.1007/s00500-019-04291-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper concerns the study of the diversification effect involved in a portfolio of non-life policies priced via traditional premium principles when individual pure premiums are calculated via Quantile Regression. Our aim is to use Quantile Regression to estimate the individual conditional loss distribution given a vector of rating factors. To this aim, we make a comparison of the outcomes obtained via Quantile Regression with the widely used industry standard method based on generalized linear models. Then, considering a specific premium principle, we calculate individual pure premium by means of a specific functional of the conditional loss distribution, the standard deviation. We determine the portfolio risk margin according to the Solvency 2 framework and then we allocate it over each policy in a way consistent with his/her riskiness. Indeed, considering a portfolio of heterogeneous policies, we determine the individual reduction of the safety loading, due to the diversification, and we measure the risk contribution of each individual.},
  archive      = {J_SOCO},
  author       = {Baione, Fabio and Biancalana, Davide and De Angelis, Paolo},
  doi          = {10.1007/s00500-019-04291-x},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {8523-8534},
  shortjournal = {Soft Comput.},
  title        = {A quantile regression approach for the analysis of the diversification in non-life premium risk},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Option valuation with IG-GARCH model and a u-shaped pricing
kernel. <em>SOCO</em>, <em>24</em>(12), 8505–8522. (<a
href="https://doi.org/10.1007/s00500-019-04236-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Empirical and theoretical studies have attempted to establish the U-shape of the log-ratio of conditional risk-neutral and physical probability density functions. The main subject of this paper is to question the use of such a U-shaped pricing kernel to improve option pricing performances in a non-Gaussian setting. Starting from the so-called inverse Gaussian GARCH model (IG-GARCH), known to provide semi-closed-form formulas for classical European derivatives when an exponential-affine pricing kernel is used, we build a new pricing kernel that is non-monotonic and that still has this remarkable property. Using a daily dataset of call options written on the S&amp;P500 index, we compare the pricing performances of these two IG-GARCH models proving, in this framework, that the new exponential U-shaped stochastic discount factor clearly outperforms the classical exponential-affine one. What is more, several estimation strategies including options or VIX information are evaluated taking advantage of the analytical tractability of these models. We prove that the parsimonious estimation approach using returns and VIX historical data remains competitive without having to work with the cross section of options.},
  archive      = {J_SOCO},
  author       = {Chorro, Christophe and Fanirisoa, Rahantamialisoa H.},
  doi          = {10.1007/s00500-019-04236-4},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {8505-8522},
  shortjournal = {Soft Comput.},
  title        = {Option valuation with IG-GARCH model and a U-shaped pricing kernel},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Special issue on dynamics of socioeconomic systems: Systemic
risk—finance. <em>SOCO</em>, <em>24</em>(12), 8503. (<a
href="https://doi.org/10.1007/s00500-020-04983-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SOCO},
  author       = {de Peretti, Philippe and Cavallo, Bice and Simonetti, Biagio and Squillante, Massimo and Vitting-Andersen, Jorgen},
  doi          = {10.1007/s00500-020-04983-9},
  journal      = {Soft Computing},
  number       = {12},
  pages        = {8503},
  shortjournal = {Soft Comput.},
  title        = {Special issue on dynamics of socioeconomic systems: Systemic risk—finance},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Energy management of the energy storage-based
micro-grid-connected system: An SOGSNN strategy. <em>SOCO</em>,
<em>24</em>(11), 8481–8494. (<a
href="https://doi.org/10.1007/s00500-019-04412-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel hybrid algorithm is implemented for the system modelling and the optimal management of the micro-grid (MG)-connected systems with low cost. The increasing number of renewable energy sources and distributed generators requires new strategies for their operations in order to maintain the energy balance between the renewable sources and MG. Therefore, an efficient hybrid technique is proposed in the paper. The main objective of the process was the optimum operation of micro-sources for decreasing the electricity production cost by hourly day-ahead and real-time scheduling. The proposed hybrid technique is to manage the power flows between the energy sources and the grid. To achieve this point, demand response and minimum cost of energy are determined. The proposed hybrid technique is the combined performance of both the gravitational search algorithm (GSA)-based artificial neural network (ANN) and squirrel search algorithm (SSA), and it is named as SOGSNN. This technique is involved with the mathematical optimization problems that necessitate more than one fitness function to be optimized simultaneously. By using the inputs of MG-like wind turbine, photovoltaic array, fuel cell, micro-turbine, diesel generator and battery storage with corresponding cost functions, the GSA-based ANN learning phase is employed to predict the load demand. SSA clarifies the squirrel in optimizing the configuration of MG based on the load demand. The proposed hybrid technique is implemented in MATLAB/Simulink working platform and compared with other solution techniques like ANFASO method. The comparison result reveals that the superiority of the proposed technique confirms its ability to solve the problem.},
  archive      = {J_SOCO},
  author       = {Roy, Kallol and Mandal, Kamal Krishna and Mandal, Atis Chandra},
  doi          = {10.1007/s00500-019-04412-6},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {8481-8494},
  shortjournal = {Soft Comput.},
  title        = {Energy management of the energy storage-based micro-grid-connected system: An SOGSNN strategy},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An intelligent and generic approach for detecting human
emotions: A case study with facial expressions. <em>SOCO</em>,
<em>24</em>(11), 8467–8479. (<a
href="https://doi.org/10.1007/s00500-019-04411-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several studies in the field of human–computer interaction have focused on the importance of emotional factors related to the interaction of humans with computer systems. According to the knowledge of the users’ emotions, intelligent software can be developed for interacting and even influencing users. However, such a scenario is still a challenge in the field of human–computer interaction. This article endeavors to enhance intelligence in such types of systems by adopting an ensemble-based model that is able to identify and classify emotions. We developed a system (music player) that can be used as a mechanism to interact and/or persuade someone to “change” his/her current emotional state. In order to do this, we also designed a generic model that accepts any kind of interaction or persuasion mechanism (e.g., preferred YouTube channel videos, games, etc.) to be deployed at runtime based on the needs of each user. We showed that the approach based on a genetic algorithm for the weight assignment of the ensemble achieved an accuracy average of 80\%. Moreover, the results showed a 60\% increase in the level of user’s satisfaction regarding the interaction with users’ emotions.},
  archive      = {J_SOCO},
  author       = {Mano, Leandro Y. and Faiçal, Bruno S. and Gonçalves, Vinícius P. and Pessin, Gustavo and Gomes, Pedro H. and de Carvalho, André C. P. L. F. and Ueyama, Jó},
  doi          = {10.1007/s00500-019-04411-7},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {8467-8479},
  shortjournal = {Soft Comput.},
  title        = {An intelligent and generic approach for detecting human emotions: A case study with facial expressions},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Electron radar search algorithm: A novel developed
meta-heuristic algorithm. <em>SOCO</em>, <em>24</em>(11), 8443–8465. (<a
href="https://doi.org/10.1007/s00500-019-04410-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a new optimization algorithm called electron radar search algorithm (ERSA) inspired by the electron discharge mechanism. It is based on the natural phenomenon of electric flow as the form of electron discharge through a gas, liquid, or solid environment. When the voltage between separated electrodes (anode and cathode) increases, electrons tendency to emission from a low potential state to the higher potential condition is grown up. However, electrons are trying to find the best path with the least resistance in the medium. At each point, electrons evaluate the surrounding environment with a radar mechanism and least resistance path is selected for the next move. Hence, in this paper, a novel developed meta-heuristic algorithm based on the electrons’ search approach is presented and the algorithm is benchmarked on 20 mathematical functions with four well-known methods for validation and verification tests. Moreover, the algorithm is implemented in two engineering design problems (tension/expression spring and welded beam design optimization) and the results demonstrate that the ERSA performs more efficiently for solving unknown search spaces and the algorithm found best solution in approximately 95\% of the reviewed benchmark functions.},
  archive      = {J_SOCO},
  author       = {Rahmanzadeh, Sajjad and Pishvaee, Mir Saman},
  doi          = {10.1007/s00500-019-04410-8},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {8443-8465},
  shortjournal = {Soft Comput.},
  title        = {Electron radar search algorithm: A novel developed meta-heuristic algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A parallel genetic approach to path-planning with
upstream-current avoidance for multi-AUG deployment. <em>SOCO</em>,
<em>24</em>(11), 8427–8441. (<a
href="https://doi.org/10.1007/s00500-019-04409-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous underwater gliders are robotic underwater vehicles that do not require operator input. They are frequently deployed in large-scale, long-term ocean-sampling missions that take advantage of their buoyancy-driven engines and very low power consumption. A limitation of the buoyancy-driven engine design is that the glider must travel at slow speeds and is unable to confront strong upstream currents. Optimal path-planning to minimize the upstream-current effect and distance traversed is helpful to guide the glider navigating in the ocean. In a glider path-planning problem, reachability signifies that a minimal upstream-current effect along a path is achieved, while efficiency refers to optimizing path distance, to make it as short as possible. Reachability and efficiency are sometimes inconsistent goals in glider path-planning, and obtaining an optimal solution between both aspects of path-planning constitutes a multi-objective optimization problem. In order to discover an optimal path for glider safety, a parallel genetic approach to the glider path-planning is developed here. We present a novel scheme of upstream-current avoidance to solve the critical path-planning problem in deployment of multiple gliders. The benefits of the proposed approach are used to produce characteristic curves that express how improved cruising capability benefits path diversity. The reachability of an important scheme of upstream-current avoidance is validated by a maximum likelihood function. Moreover, a new crossover operator is proposed to encourage individuals of offspring in solution diversity. Numeric results demonstrate that the proposed path-planning approach determines an optimal path that reduces the upstream-current effect, and also shortens the cruising distance in multi-glider path-planning solutions.},
  archive      = {J_SOCO},
  author       = {Shih, Chien-Chou and Horng, Mong-Fong and Chen, Chun-Yu},
  doi          = {10.1007/s00500-019-04409-1},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {8427-8441},
  shortjournal = {Soft Comput.},
  title        = {A parallel genetic approach to path-planning with upstream-current avoidance for multi-AUG deployment},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modeling and simulation of novel dynamic control strategy
for PV–wind hybrid power system using FGS−PID and RBFNSM methods.
<em>SOCO</em>, <em>24</em>(11), 8403–8425. (<a
href="https://doi.org/10.1007/s00500-019-04408-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the past years, hybrid solar-wind power systems containing photovoltaic (PV) and wind generators are used to minimize the intermittency problem of renewable power generation units. The improved modeling and control schemes for a grid-tied hybrid PV–wind system is presented in the current research work. The maximum power point tracking namely “MPPT” algorithm together with controlling the pitch angle are used, respectively, for the PV system and wind power generation to attain the maximum power for any given external weather conditions. A radial basis function network sliding mode known as the RBFNSM method is used to control the pitch angle in the wind energy system, while the PV system uses a proportional–integral–derivative controller equipped with the fuzzy gain scheduling in order to enhance the transient state and mitigate the settling time to ensure the stability of the mentioned system. To test the suggested control scheme’s effectiveness, MATLAB simulations are carried out under various scenarios of the wind speed as well as solar irradiation. The obtained results show the efficiency of the adaptive MPPT method to harness the highest power under very challenging scenarios. The merits of the developed schemes are quickly and precisely tracking the maximum power output of the hybrid PV–wind system. Besides, the power flowing between the utility grid and the hybrid source with a fast transient response and improved stability performance is effectively controlled using the offered schemes.},
  archive      = {J_SOCO},
  author       = {Wu, Di and Nariman, Goran Saman and Mohammed, Salim Qadir and Shao, Zehui and Rezvani, Alireza and Mohajeryami, Saeed},
  doi          = {10.1007/s00500-019-04408-2},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {8403-8425},
  shortjournal = {Soft Comput.},
  title        = {Modeling and simulation of novel dynamic control strategy for PV–wind hybrid power system using FGS−PID and RBFNSM methods},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Scheduling two-stage assembly flow shop with random machines
breakdowns: Integrated new self-adapted differential evolutionary and
simulation approach. <em>SOCO</em>, <em>24</em>(11), 8377–8401. (<a
href="https://doi.org/10.1007/s00500-019-04407-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper takes random machines breakdowns and the two-stage assembly flow shop problem into consideration as a realistic assumption in industrial environments. In practical manufacturing environment, disruptions and unforeseen incidents occur, so a schedule being built based on deterministic information is not practical and may lead to poor performance. In this paper, machines in manufacturing and assembly stages are not always available due to random machines breakdowns which occur during processing of each operation. The goal is to minimize the expected the weighted sum of makespan and mean of completion time. Owning to its problem complexity and since the problem belongs to NP-hard class, use of meta-heuristic algorithms is justified to tackle the potential complexity of the problem considered, and hence, we proposed four meta-heuristics algorithms entitled: genetic algorithm, imperialist competitive algorithm, cloud theory-based simulated annealing and new self-adapted differential evolutionary (NSDE) to solve it. Machine breakdown and dynamic nature of the problem, the structural complexity increases markedly. In this regard, to overcome this form of complexity, simulation techniques are typically employed. Eventually, since the proposed problem has both types of complexities (algorithm complexity and structural complexity), simulation is integrated into the proposed meta-heuristic approaches to handle the complexities. We apply artificial neural network as a tuning tool for predicting the input parameters of each proposed meta-heuristics algorithms in uncertain condition. Also, we suggest Taguchi method as one the most important adjusting approaches for analyzing the effect of input parameters in each algorithm. The computational results show which proposed NSDE statistically is better than other proposed meta-heuristics algorithms according two important indicators: quality of solution and computational time.},
  archive      = {J_SOCO},
  author       = {Seidgar, Hany and Fazlollahtabar, Hamed and Zandieh, Mostafa},
  doi          = {10.1007/s00500-019-04407-3},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {8377-8401},
  shortjournal = {Soft Comput.},
  title        = {Scheduling two-stage assembly flow shop with random machines breakdowns: Integrated new self-adapted differential evolutionary and simulation approach},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). RETRACTED ARTICLE: Analysis on the construction of
ideological and political education system for college students based on
mobile artificial intelligence terminal. <em>SOCO</em>, <em>24</em>(11),
8365–8375. (<a
href="https://doi.org/10.1007/s00500-020-04932-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of modern mobile communication, artificial intelligence (AI) has begun to enter people’s life, and it is also constantly changing the modern education mode. First, the structure of BPN (back-propagation network) is designed in this paper. On this basis, genetic algorithm is applied to optimize, which can accelerate the convergence speed and achieve the effect of global optimization. The results obtained from the research also meet the expected value, realizing the purpose of optimizing the BP algorithm. This paper analyzes the AI teaching expert system, summarizes their functions and characteristics, and points out that the college students’ ideological and political teaching system based on the mobile AI terminal can be used as the teaching manager, teaching assistant, and even as the teaching object to guide students’ learning. At the same time, the article also points out that the application and development direction of artificial intelligence in the teaching field can be divided into three stages: primary application, intermediate application, and advanced application, so as to provide theoretical guidance for the construction and analysis of ideological and political teaching system for college students using mobile artificial intelligence terminals.},
  archive      = {J_SOCO},
  author       = {Wang, Yuting},
  doi          = {10.1007/s00500-020-04932-6},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {8365-8375},
  shortjournal = {Soft Comput.},
  title        = {RETRACTED ARTICLE: Analysis on the construction of ideological and political education system for college students based on mobile artificial intelligence terminal},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Applying improved k-means algorithm into official service
vehicle networking environment and research. <em>SOCO</em>,
<em>24</em>(11), 8355–8363. (<a
href="https://doi.org/10.1007/s00500-020-04893-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to improve the traffic efficiency of official vehicles in the traffic road network, a backpressure routing control strategy for multi-commodity flow (official traffic flow) using official vehicle network environmental data information is proposed. Firstly, the road network composed of official service vehicle-mounted wireless network nodes is used to collect information on road conditions and official service vehicles. In order to improve the real-time and forward-looking route control, an official service vehicle flow forecasting method is introduced to construct a virtual official service vehicle queue. A multi-commodity flow (official service vehicle flow) backpressure route method is proposed, and an official service vehicle control strategy is designed to improve the self-adaptive route of K-means algorithm. In addition, the weight of backpressure strategy is improved according to traffic pressure conditions, and the adaptability of backpressure route algorithm is improved by using optimized parameters. Finally, the simulation results show that the proposed method can effectively control traffic vehicles and improve traffic smoothness.},
  archive      = {J_SOCO},
  author       = {Meng, Xiangxi and Lv, Jianghua and Ma, Shilong},
  doi          = {10.1007/s00500-020-04893-w},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {8355-8363},
  shortjournal = {Soft Comput.},
  title        = {Applying improved K-means algorithm into official service vehicle networking environment and research},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Analysis on the construction of sports match prediction
model using neural network. <em>SOCO</em>, <em>24</em>(11), 8343–8353.
(<a href="https://doi.org/10.1007/s00500-020-04823-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To grasp the development of sports events in time and adjust the strategy in the process of match in time, the traditional back-propagation neural network (BPNN) algorithm was improved, and the match prediction model was constructed by using the adaptive BPNN. Taking the football match data of the Union of European Football Associations Champions League 2016–2017 as the prediction sample, the match was predicted. Moreover, taking some match data of Barcelona in 2016–2017 as an example, the fitting accuracy of the improved adaptive BPNN prediction model, multiple linear regression (MLR) model and grey degree prediction model were compared and analyzed. The research results showed that the prediction model built by the improved adaptive BPNN algorithm had smaller prediction error after rolling prediction. By comparing with the fitting accuracy of MLR model and grey prediction model, it was also found that the prediction error of the prediction model proposed was almost zero, and the error of the other two models was large. It showed that the prediction model proposed had high accuracy and reliability. Therefore, applying neural network to build a sports match prediction model and then predict the match results can provide a certain theoretical basis for sports match practice and the prediction and analysis of the match results.},
  archive      = {J_SOCO},
  author       = {Li, Hang},
  doi          = {10.1007/s00500-020-04823-w},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {8343-8353},
  shortjournal = {Soft Comput.},
  title        = {Analysis on the construction of sports match prediction model using neural network},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Prediction of fundraising outcomes for crowdfunding projects
based on deep learning: A multimodel comparative study. <em>SOCO</em>,
<em>24</em>(11), 8323–8341. (<a
href="https://doi.org/10.1007/s00500-020-04822-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a new financing model, crowdfunding has been developed rapidly in recent years and has attracted the attention of investors and small- and medium-sized enterprises and entrepreneurs. However, many projects fail to be funded; thus, crowdfunding project fundraising outcomes forecasting and multimodel comparisons are meaningful ways to identify project quality and reduce market risk. It is important to reduce participation risk through automated methods, which is of great significance to the sustainable development of Internet finance. First, based on the data from the Kickstarter, preprocessing and exploratory analysis are conducted. Then, we introduce a deep learning algorithm (multilayer perceptron) and apply it to the prediction of crowdfunding financing performance. We compare deep learning with other commonly used machine learning algorithms, including decision tree, random forest, logistic regression, support vector machine, and K-nearest neighbors algorithm. We tune each machine learning algorithm to get the best parameters. The experimental results show that the deep learning model can obtain the best prediction results, with an accuracy of 92.3\% when predicting the fundraising outcomes of crowdfunding financing, followed by the decision tree. Deep learning shows significant advantages in many evaluation criteria, which demonstrates the potential for crowdfunding project financing predictions. This study combines machine learning with Internet finance, providing inspiration for future research and resulting in many practical implications.},
  archive      = {J_SOCO},
  author       = {Wang, Wei and Zheng, Hongsheng and Wu, Yenchun Jim},
  doi          = {10.1007/s00500-020-04822-x},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {8323-8341},
  shortjournal = {Soft Comput.},
  title        = {Prediction of fundraising outcomes for crowdfunding projects based on deep learning: A multimodel comparative study},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improving decision-making efficiency of image game based on
deep q-learning. <em>SOCO</em>, <em>24</em>(11), 8313–8322. (<a
href="https://doi.org/10.1007/s00500-020-04820-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To promote effective decision-making in video games and win high scores in a short time, the deep learning algorithms are integrated into game image processing for reinforcement learning. By changing the mapping function from priority to probability, a deep Q-learning priority experience replay algorithm is deduced, which is then compared with the single mapping function. Various researches have proved that the improved algorithm can reproduce the mapping function with higher probability of playback learning of the unit. The advantage of the agent is that it can master the most complete game strategy and ultimately obtain higher scores with the help of the strategy. Therefore, the proposed algorithm is to help the agent formulate a more useful strategy when playing video games. On the one hand, the agent can get better game records. On the other hand, the energy consumed in the game is greatly reduced.},
  archive      = {J_SOCO},
  author       = {Ji, Zhe and Xiao, Wenjun},
  doi          = {10.1007/s00500-020-04820-z},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {8313-8322},
  shortjournal = {Soft Comput.},
  title        = {Improving decision-making efficiency of image game based on deep Q-learning},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). RETRACTED ARTICLE: Prediction research of financial time
series based on deep learning. <em>SOCO</em>, <em>24</em>(11),
8295–8312. (<a
href="https://doi.org/10.1007/s00500-020-04788-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, the world economics develops rapidly, and the finance business also develops promptly. As there are more financial activities, the uncertainty of change trend in financial activities is also increased constantly. How to study and grasp the laws of banking activity and calculate their coming tendency has grown into the concentrate and major study substance of scientific and monetary ring. On the one hand, available finance prediction can supply base for making finance plans and relevant decisions, thus ensuring the laudable expansion of the finance market and maximizing the benefits of profit organizations. However, on the other hand, convolution neural network (CNN) is a multilayer neural network composition that can simulate the operation machine-made of biological field system, which can be used to obtain effective feature description. Meanwhile, the features are extracted from the original data. Now, CNN has turned into a study hot point in the fields of giving a lecture discriminate, figure distinguishing, and classifying, and natural language handling. Moreover, it is widely used in these fields, and its application effect has been recognized by most people. Consequently, CNN composition is adopted to predict the finance time succession data. Firstly, the research means of financial time series are summarized, and then, the artificial neural network (ANN) and deep learning methods are briefly introduced. Afterward, the prediction model of stock index according to CNN model is proposed, and the influences of historical factors on model are analyzed. Finally, a few stock indexes are predicted to verify validity and effectiveness of the proposed CNN model through experimental comparison. And a hybrid model combined with CNN is found, thus further improving the cable CNN network model.},
  archive      = {J_SOCO},
  author       = {Xu, Zhaoyi and Zhang, Jia and Wang, Junyao and Xu, Zhiming},
  doi          = {10.1007/s00500-020-04788-w},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {8295-8312},
  shortjournal = {Soft Comput.},
  title        = {RETRACTED ARTICLE: Prediction research of financial time series based on deep learning},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Image recognition method of building wall cracks based on
feature distribution. <em>SOCO</em>, <em>24</em>(11), 8285–8294. (<a
href="https://doi.org/10.1007/s00500-019-04644-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to solve the building damage caused by cracks in the wall surface, based on feature distribution and SAR image segmentation technology, the cracks in the building wall were identified by extracting feature data images, de-noising and enhancing image edges, and segmenting target images. The validity and feasibility of the method are verified by the actual concrete wall image. The results show that the recognition accuracy of cracks in non-cracked walls is 100\%, and that of longitudinal cracks is 78.2\%. Compared with the color feature discrimination, this method has a good processing effect on the image, clear crack line, good coincidence degree with the original image, and crack width is close to the width of the original image. After processing the image with rough set, the recognition rate of the image is 98.1\%, the false reject rate is 1.9\%, the recognition time is 12 min, and the execution time of the algorithm is 126 s. After the processing of gray histogram, the feature distribution of image set has a certain distribution transfer, but the transfer effect is not particularly obvious. It can be found that this method has advantages of high recognition accuracy, short time, and practical application value, significantly enhancing pretreatment effect.},
  archive      = {J_SOCO},
  author       = {Zhang, Yuhua and Zheng, Jiaqi and Sun, Wei and Shan, Liang},
  doi          = {10.1007/s00500-019-04644-6},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {8285-8294},
  shortjournal = {Soft Comput.},
  title        = {Image recognition method of building wall cracks based on feature distribution},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evaluation feedback information for optimization of mental
health courses with deep learning methods. <em>SOCO</em>,
<em>24</em>(11), 8275–8283. (<a
href="https://doi.org/10.1007/s00500-019-04569-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to give full play to the value of mental health education courses in colleges and universities and help students understand the relevant knowledge, thus helping to alleviate their own psychological problems, this paper uses the evaluation feedback of mental health courses in colleges and universities to conduct in-depth learning, and further optimize the mental health education courses in colleges and universities. College students, as a seemingly relaxed group, actually bear tremendous pressure. Many pressures, such as study, life, emotion, interpersonal communication, and graduate employment, have seriously affected the mental health of college students. Increasingly prominent mental health problems have attracted the attention of colleges and universities. Domestic colleges and universities have gradually opened mental health education courses, aiming at helping students find breakthroughs in the problem, thereby promoting students’ physical and mental development and adapting to the current and developing social environment with the positive and normal psychological state. However, the existing mental health education curriculum in colleges and universities cannot play its role effectively. The general evaluation criteria make the teaching activities less effective, and the students fail to understand the content of the mental health education curriculum well. Therefore, this paper uses the evaluation feedback information of the mental health curriculum in colleges and universities to conduct an in-depth study, optimize the mental health curriculum, and improve the mental health of colleges and universities. The teaching mode of health course enables students to have a deeper understanding of the content of mental health education. It can really help students alleviate psychological pressure and solve psychological problems, which is conducive to the healthy development of universities and society.},
  archive      = {J_SOCO},
  author       = {Liu, Wenhua and Zhang, Yijie},
  doi          = {10.1007/s00500-019-04569-0},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {8275-8283},
  shortjournal = {Soft Comput.},
  title        = {Evaluation feedback information for optimization of mental health courses with deep learning methods},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Image semantic segmentation with an improved fully
convolutional network. <em>SOCO</em>, <em>24</em>(11), 8253–8273. (<a
href="https://doi.org/10.1007/s00500-019-04537-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of deep learning and the emergence of unmanned driving, fully convolutional networks are a feasible and effective for image semantic segmentation. DeepLab is an algorithm based on the fully convolutional networks. However, DeepLab algorithm still has room for improvement, and we design three improved methods: (1) the global context structure module, (2) highly efficient decoder module, and (3) multi-scale feature fusion module. The experimental results show that the three improved methods that we proposed in this paper can make the model obtain more expressive features and improve the accuracy of the algorithm. At the same time, we do some experiments on the Cityscapes dataset to further verify robustness and effectiveness of the improved algorithm. Finally, the improved algorithm is applied to the actual scene and has certain practical value.},
  archive      = {J_SOCO},
  author       = {Tseng, Kuo-Kun and Sun, Haichuan and Liu, Junwu and Li, Jiaqi and Yung, K. L. and Ip, W. H.},
  doi          = {10.1007/s00500-019-04537-8},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {8253-8273},
  shortjournal = {Soft Comput.},
  title        = {Image semantic segmentation with an improved fully convolutional network},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new fuzzy time series method based on an ARMA-type
recurrent pi-sigma artificial neural network. <em>SOCO</em>,
<em>24</em>(11), 8243–8252. (<a
href="https://doi.org/10.1007/s00500-019-04506-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As it known in many studies, the fuzzy time series methods do not need assumptions such as stationary and the linearity required for classical time series approaches, so there is a huge field of study on fuzzy time series methods in the time series literature. Fuzzy time series literature has the studies which use both the various models of artificial neural networks and the different optimization methods of artificial intelligence jointly. In this study, a new fuzzy time series algorithm based on an ARMA-type recurrent Pi-Sigma artificial neural network is introduced. It is expected that the proposed method increases the forecasting performance for many real-life time series because of using more input which is the error term obtained from Pi-Sigma artificial neural network with recurrent structure. Therefore, it can be considered that the proposed method is based on an ARMA-type fuzzy time series forecasting model. In the proposed method, the training of recurrent ARMA-type Pi-Sigma neural network is performed by particle swarm optimization. The proposed method has been applied to a real-data set as well as simulated data sets of a real-life time series, and the obtained results have been compared with some other methods in the literature.},
  archive      = {J_SOCO},
  author       = {Kocak, Cem and Dalar, Ali Zafer and Cagcag Yolcu, Ozge and Bas, Eren and Egrioglu, Erol},
  doi          = {10.1007/s00500-019-04506-1},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {8243-8252},
  shortjournal = {Soft Comput.},
  title        = {A new fuzzy time series method based on an ARMA-type recurrent pi-sigma artificial neural network},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A deep extraction model for an unseen keyphrase detection.
<em>SOCO</em>, <em>24</em>(11), 8233–8242. (<a
href="https://doi.org/10.1007/s00500-019-04486-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The keyphrase represents the basic concepts for a text. In many natural language processing tasks, it is necessary to extract qualitative keyphrases. Considering previous studies regarding text modeling, the meanings and concepts associated with the text had not been particularly considered as significant. According to recent research, cluster-related documents have a good subscription, especially in the keyphrases that are not directly appearing in a text document. Therefore, in this study, the main structure of the proposed model is based on the keyphrases disappearing in the document. We called it unseen keyphrase. Considering the proposed method, a model is developed to extract the basic concepts of the text using the same text estimates and through adding keyphrases to the deep network hidden layers of training. The main purpose of this structure is to first make visible unseen keyphrase and then to use an RNN to predict them. Considering the proposed method, the problem of not representing basic concepts and the unseen keyphrase are significantly solved. This study provides new insight into the concept of text. This mechanism is used by highlighting the role of unseen keyphrase that appears directly without the need for external knowledge. This method is tested on four public datasets in this field. The results revealed an average improvement of 12\% compared to the public methods such as TF-IDF, KEA, and RNN.},
  archive      = {J_SOCO},
  author       = {Ghazi Zahedi, Amin and Zahedi, Morteza and Fateh, Mansoor},
  doi          = {10.1007/s00500-019-04486-2},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {8233-8242},
  shortjournal = {Soft Comput.},
  title        = {A deep extraction model for an unseen keyphrase detection},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A network representation method based on edge information
extraction. <em>SOCO</em>, <em>24</em>(11), 8223–8231. (<a
href="https://doi.org/10.1007/s00500-019-04451-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, network representation learning has attracted extensive attention in the academic field due to its significant application potential. However, most of the methods cannot explore edge information in the network deeply, resulting in poor performance at downstream tasks such as classification, clustering and link prediction. In order to solve this problem, we propose a novel way to extract network information. First, the original network is transformed into an edge network with structure and edge information. Then, edge representation vectors can be obtained directly by using an existing network representation model with edge network as its input. Node representation vectors can also be obtained by utilizing the relationships between edges and nodes. Compared with the structure of original network, the edge network is denser, which can help solving the problems caused by sparseness. Extensive experiments on several real-world networks demonstrate that edge network outperforms original network in various graph mining tasks, i.e., node classification and node clustering.},
  archive      = {J_SOCO},
  author       = {Fan, Wei and Wang, Hui Min and Xing, Yan and Huang, Rui and Ip, W. H. and Yung, Kai Leung},
  doi          = {10.1007/s00500-019-04451-z},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {8223-8231},
  shortjournal = {Soft Comput.},
  title        = {A network representation method based on edge information extraction},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new intuitionistic fuzzy functions approach based on
hesitation margin for time-series prediction. <em>SOCO</em>,
<em>24</em>(11), 8211–8222. (<a
href="https://doi.org/10.1007/s00500-019-04432-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are various studies in which a variety of prediction tools have been introduced in time-series prediction literature. Non-probabilistic approaches which are based on fuzzy set theory, especially in recent years, have been put forward. Although these approaches including adaptive network fuzzy inference system, fuzzy functions approach, and fuzzy regression can be successfully utilized as a prediction tool, they have not been designed for prediction problem and they pass over the dependency structure of time-series observations. From this point forth, designing a prediction tool that considers the dependency structure of the observations of time series will procure to get predictions more accurately. Although the membership values, in the analysis process, are taken into account in almost all fuzzy methods, the non-membership and hesitation values are not considered. However, using as much information as possible on time series may be another positive factor that gives more accurate predictions. The primary aim of this study, for time-series prediction, is to introduce an intuitionistic fuzzy regression functions approach based on hesitation margin (I-FRF-HM). In the introduced intuitionistic fuzzy regression functions approach, two inference systems are separately constituted such that while one of them uses membership, other one uses non-membership values as inputs of inference system in addition with the crisp observations of time series. Predictions obtained from each system are converted into final predictions of whole inference system via an approach based on hesitation margin. Intuitionistic fuzzy C-means are utilized to get membership and non-membership values in the proposed model. The proposed I-FRF-HM has been applied to various real-world time series. The obtained findings are evaluated along with the results of some other time-series prediction models. The results show that the proposed I-FRF-HM has superior prediction performance to other prediction models.},
  archive      = {J_SOCO},
  author       = {Cagcag Yolcu, Ozge and Bas, Eren and Egrioglu, Erol and Yolcu, Ufuk},
  doi          = {10.1007/s00500-019-04432-2},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {8211-8222},
  shortjournal = {Soft Comput.},
  title        = {A new intuitionistic fuzzy functions approach based on hesitation margin for time-series prediction},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Applying genetic algorithm and ant colony optimization
algorithm into marine investigation path planning model. <em>SOCO</em>,
<em>24</em>(11), 8199–8210. (<a
href="https://doi.org/10.1007/s00500-019-04414-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Marine resources are vital to the development of a country. Marine investigation can obtain more marine resources and acquire more marine environmental information. A common method used in the marine investigation consumes a large amount of both time and money. Thus, the scientific path planning is important for improving the efficiency and reducing the costs of the marine investigation. Currently, the most commonly used algorithms for path planning are the genetic algorithm (GA) and the ant colony optimization algorithm (ACOA). Through continuous iterations, the initial solutions obtained by GA and ACOA gradually approach the optimal solutions. However, the final solutions of both algorithms are often suboptimal solutions or local optimal solutions. In particular, in terms of the marine investigation path planning that involves enormous stations, both GA and ACOA are prone to premature and local optimal solutions, leading to the stagnation of the searching. Therefore, in order to solve these problems and save the costs of marine investigation, the ACOA and GA are combined to propose a hybrid algorithm for the further improvement in the quality of the solutions. Through the experiments and software implementation, the proposed hybrid algorithm is proved of high effectiveness and robustness, which could obtain the optimal path for single or multiple research vessels, thereby saving the time and costs of marine investigation path planning.},
  archive      = {J_SOCO},
  author       = {Liang, Ye and Wang, Lindong},
  doi          = {10.1007/s00500-019-04414-4},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {8199-8210},
  shortjournal = {Soft Comput.},
  title        = {Applying genetic algorithm and ant colony optimization algorithm into marine investigation path planning model},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Exploration of social media for sentiment analysis using
deep learning. <em>SOCO</em>, <em>24</em>(11), 8187–8197. (<a
href="https://doi.org/10.1007/s00500-019-04402-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth of web content from social media, such studies as online opinion mining or sentiment analysis of text have started receiving attention from government, industry, and academic sectors. In recent years, sentiment analysis has not only emerged under knowledge fusion in the big data era, but has also become a popular research topic in the area of artificial intelligence and machine learning. This study used the Militarylife PTT board of Taiwan’s largest online forum as the source of its experimental data. The purpose of this study was to construct a sentiment analysis framework and processes for social media in order to propose a self-developed military sentiment dictionary for improving sentiment classification and analyze the performance of different deep learning models with various parameter calibration combinations. The experimental results show that the accuracy and F1-measure of the model that combines existing sentiment dictionaries and the self-developed military sentiment dictionary are better than the results from using existing sentiment dictionaries only. Furthermore, the prediction model trained using the activation function, Tanh, and when the number of Bi-LSTM network layers is two, the accuracy and F1-measure have an even better performance for sentiment classification.},
  archive      = {J_SOCO},
  author       = {Chen, Liang-Chu and Lee, Chia-Meng and Chen, Mu-Yen},
  doi          = {10.1007/s00500-019-04402-8},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {8187-8197},
  shortjournal = {Soft Comput.},
  title        = {Exploration of social media for sentiment analysis using deep learning},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Visualization analysis of big data research based on
citespace. <em>SOCO</em>, <em>24</em>(11), 8173–8186. (<a
href="https://doi.org/10.1007/s00500-019-04384-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, with the massive growth of data, the world today has entered the era of big data. Big data has brought tremendous value to all fields of today’s society, and it has also brought enormous challenges, which has attracted great attention from all walks of life. Analyze and forecast the research hotspots and future development trends in the field of big data, and understand the development changes and priorities in the field of big data research, which will play a significant role in promoting the development of social development and scientific research. In the era of big data, how to extract information from huge amounts of complex data and present complex information more clearly and clearly, the most effective way is to use visualization technology. The article uses the information visualization software Citespace to study the data related to big data in the Web of Science and CNKI database from 2008 to 2017 for 10 years, from macro to micro to the representative countries of the literature, keywords and co-cited documents. Through visualization analysis, the article clarifies the key research directions, key documents and hot spot frontiers in the field of big data research, forecasts the future development trends in this field, and compares the research situation at home and abroad, in order to provide readers and other researchers with certain reference and help.},
  archive      = {J_SOCO},
  author       = {Wang, Weihong and Lu, Chang},
  doi          = {10.1007/s00500-019-04384-7},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {8173-8186},
  shortjournal = {Soft Comput.},
  title        = {Visualization analysis of big data research based on citespace},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A fused CNN model for WBC detection with MRMR feature
selection and extreme learning machine. <em>SOCO</em>, <em>24</em>(11),
8163–8172. (<a
href="https://doi.org/10.1007/s00500-019-04383-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {White blood cell (WBC) test is used to diagnose many diseases, particularly infections, ranging from allergies to leukemia. A physician needs clinical experience to detect and classify the amount of WBCs in human blood. WBCs are divided into four subclasses: eosinophils, lymphocytes, monocytes, and neutrophils. In the present study, pre-trained architectures, namely AlexNet, VGG-16, GoogleNet, and ResNet, were used as feature extractors. The features obtained from the last fully connected layers of these architectures were combined. Efficient features were selected using the minimum redundancy maximum relevance method. Finally, unlike classical convolutional neural network (CNN) architectures, the extreme learning Machine (ELM) classifier was used in the classification stage thanks to the efficient features obtained from CNN architectures. Experimental results indicated that efficient CNN features yielded satisfactory results in a shorter execution time via ELM classification with an accuracy rate of 96.03\%.},
  archive      = {J_SOCO},
  author       = {Özyurt, Fatih},
  doi          = {10.1007/s00500-019-04383-8},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {8163-8172},
  shortjournal = {Soft Comput.},
  title        = {A fused CNN model for WBC detection with MRMR feature selection and extreme learning machine},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Feature extraction method of 3D art creation based on deep
learning. <em>SOCO</em>, <em>24</em>(11), 8149–8161. (<a
href="https://doi.org/10.1007/s00500-019-04353-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to study the method of feature extraction of 3D art design model based on deep learning, in this study, a network community media communication research on 3D art creation based on deep learning and evolution strategy was proposed. The research results showed that the two feature extraction methods were reliable and robust. Based on the evolutionary strategy, the evolution matrix function was used to extract the characteristics of people’s preferences. The experimental results showed that the process is feasible. It can be concluded that the method based on the method of deep learning and interactive evolution strategy, the feasibility of social media communication research of 3D art creation network based on deep learning and evolution strategy was verified by the combination of scientific creation and artistic creation by sacrificing time expenditure.},
  archive      = {J_SOCO},
  author       = {Chen, Kaiqing and Huang, Xiaoqin},
  doi          = {10.1007/s00500-019-04353-0},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {8149-8161},
  shortjournal = {Soft Comput.},
  title        = {Feature extraction method of 3D art creation based on deep learning},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Differential privacy data publishing in the big data
platform of precise poverty alleviation. <em>SOCO</em>, <em>24</em>(11),
8139–8147. (<a
href="https://doi.org/10.1007/s00500-019-04352-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to study the application of differential privacy data release for the data platform of precise poverty alleviation (PPA), in this study, the data was protected by using differential privacy protection algorithm, and combined with artificial neural network to construct the algorithm model. And then based on MATLAB simulation experiment, the operation effect of the simulation model was verified through multiple angles. From the relationship between budget and coefficient, it can be concluded that compared with extraction procedure and noprivacy by statistical test, the algorithm proposed in this study was found to be more practical, and the result was close to the original data, and the effect was better; the error rate was also the lowest, not higher than 0.075. Comparing the accuracy of the algorithm with other algorithms, the result showed that other methods made the precision lower, but the function mechanism designed in this study did not; from the perspective of time, it is found that the time consumption of algorithm designed in this study was greatly reduced compared with other methods. Through the research in this paper, the model designed by combining artificial neural network and differential privacy achieved the expected effect. Although there are some shortcomings in the experimental process, in general, it can provide direction and guidance for the subsequent PPA work, and its social development has important guiding significance.},
  archive      = {J_SOCO},
  author       = {Gao, Suwei and Zhou, Changchun},
  doi          = {10.1007/s00500-019-04352-1},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {8139-8147},
  shortjournal = {Soft Comput.},
  title        = {Differential privacy data publishing in the big data platform of precise poverty alleviation},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel quality-of-service-aware web services composition
using biogeography-based optimization algorithm. <em>SOCO</em>,
<em>24</em>(11), 8125–8137. (<a
href="https://doi.org/10.1007/s00500-019-04266-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of technology and computer systems, web services are used to develop business processes. Since a web service only performs a simple operation, web services composition has become important to respond to these business processes. In recent times, the number of existing web services has grown increasingly; therefore, similar services are presented increasingly. These similar web services are discriminated based on the various quality of service (QoS) parameters. These quality parameters include cost, execution time, availability, and reliability. In order to have the best QoS, each user should select a subset of services that presents best quality parameters. On the other hand, due to huge number of services, selecting web services for composition is an NP-hard optimization problem. This paper presents an efficient method for solving this problem using biogeography-based optimization (BBO). BBO is a very simple algorithm with few control parameters and effective exploit. The proposed method offers promising solutions to this problem. Evaluation and simulation results indicate efficiency and feasibility of the proposed algorithm.},
  archive      = {J_SOCO},
  author       = {Sangaiah, Arun Kumar and Bian, Gui-Bin and Bozorgi, Seyed Mostafa and Suraki, Mohsen Yaghoubi and Hosseinabadi, Ali Asghar Rahmani and Shareh, Morteza Babazadeh},
  doi          = {10.1007/s00500-019-04266-y},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {8125-8137},
  shortjournal = {Soft Comput.},
  title        = {A novel quality-of-service-aware web services composition using biogeography-based optimization algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Using big data computing framework and parallelized PSO
algorithm to construct the reservoir dispatching rule optimization.
<em>SOCO</em>, <em>24</em>(11), 8113–8124. (<a
href="https://doi.org/10.1007/s00500-019-04188-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper aims to study how to realize the rational allocation and efficient utilization of water resources among reservoirs and coordinate the balanced optimization of benefit among dispatching objectives under the premise of ensuring flood control safety. A multi-objective optimal dispatching system for reservoirs in Jinsha River basin based on the Spark big data computing framework and parallelized particle swarm optimization (PSO) is proposed. The characteristics of multiple objectives of water resources optimal dispatching system in Jinsha River basin are analyzed. The multiple objectives have been transformed into single objectives, and the solving model of the problem is obtained. Secondly, the parallel algorithm programming model, the PSO algorithm and its parallel strategy for solving optimization problems, and the parallel method of PSO based on Spark big data computing framework are studied. The results show that the research work provides a scientific theoretical basis and a feasible optimization method for the management and dispatch of cascade hydropower stations. Therefore, this study plays a decisive role in promoting the efficient operation of water resources optimal dispatching system and has good reference value for the development and application of big data parallel programming based on Spark platform.},
  archive      = {J_SOCO},
  author       = {Zhang, Wenjuan and Huang, Yingping},
  doi          = {10.1007/s00500-019-04188-9},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {8113-8124},
  shortjournal = {Soft Comput.},
  title        = {Using big data computing framework and parallelized PSO algorithm to construct the reservoir dispatching rule optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Using grey relational analysis and grey integrated
multi-objective strategy to evaluate the risk factors of falling of
aboriginal elders in taiwan. <em>SOCO</em>, <em>24</em>(11), 8097–8112.
(<a href="https://doi.org/10.1007/s00500-019-04178-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aboriginal elders falls have been a widely discussed topic; however, factors such as emotional and physical functions, and social and cultural backgrounds are lacking. Most studies focusing on fall correlations concentrate on medical institutions or non-tribal community areas. Few studies focus on falling of elders in mountainous areas. Applying grey relational and multi-objective decision making to predict the prevalence of falls and associated risk factors for aboriginal elders is the purpose of this study. We targeted the Atayal and Tsuo aboriginal elders in central Taiwan, involving 160 members settled in mountainous townships in Taiwan. For this research study, the components are as follows: The grey theory predicts and evaluates the commonly used fall risk assessment tools, that is, quantative questionaires include: (1) focused history: medication history and Brief Symptom Rating Scale questionnaire, BSRS-5; (2) functional Assessment: ADL (Barthel Index) and IADL; (3) prevention of falls health beliefs; and (4) prevention of falls self-efficacy. With qualitative and in-depth interviews, 18 tribal elders, 55 years and above, were interviewed: 9 from the Atayal and 9 from the Tsou. Based on the Nvivo 12.0 data analysis software, this study concluded that the most predictable fall risk assessment tool is Downton Fall Risk Index (weighting: 0.8657), followed by BSR-5 (weighting: 0.5701), prevention of falls health beliefs (weighting: 0.448), Barthel scale (weighting: 0.4296), IADL (weighting: 0.1661), prevention of falls self-efficacy (weighting: 0.1391) and medical history (weighting: 0.0615). Further, qualitative results indicated that the issue of health inequalities under the influence of ethnic culture, including physical and disease characteristics, tend to be more than the proportion of heart and hypertension diseases, healthy behaviors such as unbalanced diet, cultural beliefs in gender division of labor and ethnic communication barriers and lack of cultural adaptability care resources. The risky tribal environment of mountainous areas is a major factor that leads to falls. The results provide an accurate assessment tool suitable for Taiwanese aboriginal elders’ falls for future medical policy making and fall prevention intervention in cultural safety.},
  archive      = {J_SOCO},
  author       = {Huang, Hsiao-Ching and Tsai, Tsai-Fu and Subeq, Yi-Maun},
  doi          = {10.1007/s00500-019-04178-x},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {8097-8112},
  shortjournal = {Soft Comput.},
  title        = {Using grey relational analysis and grey integrated multi-objective strategy to evaluate the risk factors of falling of aboriginal elders in taiwan},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). RETRACTED ARTICLE: Financial information prediction and
information sharing supervision based on trend assessment and neural
network. <em>SOCO</em>, <em>24</em>(11), 8087–8096. (<a
href="https://doi.org/10.1007/s00500-019-04176-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to help financial users to invest, and to provide users with comprehensive and accurate information about financial securities, information about financial securities from multi-heterogeneous information is obtained. The characteristics of financial information are analyzed to provide valuable investment advice to users. According to the financial characteristics of the user’s interest, the characteristics of the investor’s interest are extracted from the heterogeneous information. Then, the multi-level model is proposed to analyze the characteristics. Through the multi-level model, the conversion of convertible bonds and the net value of closed funds are predicted. In the first level, based on the characteristics of convertible bonds and closed funds, three models of trend evaluation model, SVR (Support Vector Regression) model and neural network backpropagation network (BPN) model are used to predict financial characteristics. In the second level, the results produced by the three models in the first level are fused by the neural network. The third level optimizes the neural network based on the second level. The optimal initial weights and thresholds are selected by genetic algorithm to obtain better prediction results. The results show that the model can predict the characteristics of convertible bonds and closed funds more accurately. Therefore, the model provides a certain reference for financial users’ investment.},
  archive      = {J_SOCO},
  author       = {Gao, Xingyu and Zhang, Pu and Huang, Guanhua and Jiang, Hui and Zhang, Zhuo},
  doi          = {10.1007/s00500-019-04176-z},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {8087-8096},
  shortjournal = {Soft Comput.},
  title        = {RETRACTED ARTICLE: Financial information prediction and information sharing supervision based on trend assessment and neural network},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). RETRACTED ARTICLE: Visual communication design elements of
internet of things based on cloud computing applied in graffiti art
schema. <em>SOCO</em>, <em>24</em>(11), 8077–8086. (<a
href="https://doi.org/10.1007/s00500-019-04171-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to create more attractive graffiti works, the Internet of Things technology is used to collect people’s preference information data, and then cloud computing and big data analysis are applied to calculate and analyze the data, so as to get more design elements in line with people’s preferences, providing more material for the creators of graffiti art and facilitating their further creation of graffiti. In recent years, graffiti art, as a kind of postmodern marginal cultural art, has great expressiveness and creativity, which makes graffiti art widely used. Particularly in visual communication design, graffiti art has more characteristics and is deeply loved by the people. With the continuous development of science and technology, Internet of Things technology and cloud computing have acquired more information for many fields, thus assisting the field to complete deeper analysis and research. However, there are few applications in the field of graffiti art. Therefore, this paper combines cloud computing and Internet of Things to obtain more visual communication design elements to provide material for the creator, which is conductive for their continuing creation.},
  archive      = {J_SOCO},
  author       = {Wu, Haotian and Li, Guangan},
  doi          = {10.1007/s00500-019-04171-4},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {8077-8086},
  shortjournal = {Soft Comput.},
  title        = {RETRACTED ARTICLE: Visual communication design elements of internet of things based on cloud computing applied in graffiti art schema},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Applying data-mining techniques for discovering association
rules. <em>SOCO</em>, <em>24</em>(11), 8069–8075. (<a
href="https://doi.org/10.1007/s00500-019-04163-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data mining has become a hot research topic, and how to mine valuable knowledge from such huge volumes of data remains an open problem. Processing huge volumes of data presents a challenge to existing computation software and hardware. This study proposes a model using association rule mining (ARM) which is a kind of data-mining technique for discovering association rules of chronic diseases from the enormous data that are collected continuously through health examination and medical treatment. This study makes three critical contributions: (1) It suggests a systematical model of exploring huge volumes of data using ARM, (2) it shows that helpful implicit rules are discovered through data-mining techniques, and (3) the results proved that the proposed model can act as an expert system for discovering useful knowledge from huge volumes of data for the references of doctors and patients to the specific chronic diseases prognosis and treatments.},
  archive      = {J_SOCO},
  author       = {Huang, Mu-Jung and Sung, Hsiu-Shu and Hsieh, Tsu-Jen and Wu, Ming-Cheng and Chung, Shao-Hsi},
  doi          = {10.1007/s00500-019-04163-4},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {8069-8075},
  shortjournal = {Soft Comput.},
  title        = {Applying data-mining techniques for discovering association rules},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). ArWordVec: Efficient word embedding models for arabic
tweets. <em>SOCO</em>, <em>24</em>(11), 8061–8068. (<a
href="https://doi.org/10.1007/s00500-019-04153-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the major advances in artificial intelligence nowadays is to understand, process and utilize the humans’ natural language. This has been achieved by employing the different natural language processing (NLP) techniques along with the aid of the various deep learning approaches and architectures. Using the distributed word representations to substitute the traditional bag-of-words approach has been utilized very efficiently in the last years for many NLP tasks. In this paper, we present the detailed steps of building a set of efficient word embedding models called ArWordVec that are generated from a huge repository of Arabic tweets. In addition, a new method for measuring Arabic word similarity is introduced that has been used in evaluating the performance of the generated ArWordVec models. The experimental results show that the performance of the ArWordVec models overcomes the recently available models on Arabic Twitter data for the word similarity task. In addition, two of the large Arabic tweets datasets are used to examine the performance of the proposed models in the multi-class sentiment analysis task. The results show that the proposed models are very efficient and help in achieving a classification accuracy ratio exceeding 73.86\% with a high average F1 value of 74.15.},
  archive      = {J_SOCO},
  author       = {Fouad, Mohammed M. and Mahany, Ahmed and Aljohani, Naif and Abbasi, Rabeeh Ayaz and Hassan, Saeed-Ul},
  doi          = {10.1007/s00500-019-04153-6},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {8061-8068},
  shortjournal = {Soft Comput.},
  title        = {ArWordVec: Efficient word embedding models for arabic tweets},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Developing GAHP concepts for measurement of travel agency
organizational performance. <em>SOCO</em>, <em>24</em>(11), 8051–8059.
(<a href="https://doi.org/10.1007/s00500-019-04115-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A model for organizational performance evaluation is proposed. Organizational performance support can reduce barriers to applications of multi-criteria decision-making procedures. The relevant criteria of the proposed model were derived from an expert group interview to include the analytic hierarchy process (AHP), which is performed to determine the weights of evaluation, and grey relational analysis (GRA), which is then performed to rank the organizational performance of the travel agency. The AHP is a measurement theory that prioritizes the hierarchy and consistency of judgmental data provided by a group of decision-makers. It incorporates the evaluations of all decision-makers into a final decision through pair-wise comparisons of the alternatives, without eliciting their utility functions on subjective and objective criteria. GRA examines the extent of connections between two digits through departing and scattering measurement methods. The combined AHP and GRA decision-making method can provide decision-makers with a valuable data analysis when evaluating organizational performance. Because the proposed model can inform organizational performance assessments, it is highly applicable to both academic and commercial organizational evaluation and development.},
  archive      = {J_SOCO},
  author       = {Liu, Jing-Wei},
  doi          = {10.1007/s00500-019-04115-y},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {8051-8059},
  shortjournal = {Soft Comput.},
  title        = {Developing GAHP concepts for measurement of travel agency organizational performance},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). RETRACTED ARTICLE: Application of cloud-based visual
communication design in internet of things image. <em>SOCO</em>,
<em>24</em>(11), 8041–8050. (<a
href="https://doi.org/10.1007/s00500-019-04111-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to apply cloud computing to study visual communication design, high-resolution remote sensing image features and applications were analyzed. A high-resolution remote sensing image storage model in the cloud computing environment was designed. Afterward, deep analysis and comparison were made toward the current mainstream cloud platform. Based on the characteristics of high-resolution remote sensing images, the key technologies in the design of high-resolution remote sensing image storage model in cloud computing environment were discussed. The results showed that the integration of cloud platform Hadoop and virtualization management cloud platform provided corresponding transparent use of distributed computing resources for different remote sensing image applications. Therefore, this method provides a new way for other industries to apply cloud computing environments.},
  archive      = {J_SOCO},
  author       = {Liu, Xixia},
  doi          = {10.1007/s00500-019-04111-2},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {8041-8050},
  shortjournal = {Soft Comput.},
  title        = {RETRACTED ARTICLE: Application of cloud-based visual communication design in internet of things image},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Online sequential pattern mining and association discovery
by advanced artificial intelligence and machine learning techniques.
<em>SOCO</em>, <em>24</em>(11), 8021–8039. (<a
href="https://doi.org/10.1007/s00500-019-04100-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advances in information science, vast amounts of financial time series data can been collected and analyzed. In modern time series analysis, sequential pattern mining (SPM) and association discovery (AD) are the most important techniques to predict the future trends. This study aims at developing advanced SPM and AD for financial data by cutting edge techniques from artificial intelligence and machine learning. The nonlinearity and non-stationarity of financial time series dynamics pose a major challenge for SPM and AD. This study employs time–frequency analysis to extract features for SPM. Then, a sparse multi-manifold clustering (SMMC) is used to partition the feature space into several disjointed regions for better AD. Finally, local relevance vector machines (RVMs) are employed for AD and perform the forecasting. Different from traditional methods, the novel forecasting system operates on multiple resolutions and multiple dynamic regimes. SMMC finds both the neighbors and the weights automatically by a sparse solution, which approximately spans a low-dimensional affine subspace at that point. RVM, the Bayesian kernel machines, can produce parsimonious models with excellent generalization properties. Taking multiple time series data from financial markets as an example, the empirical results demonstrate that the proposed model outperforms traditional models and significantly reduces the forecasting errors. The framework is effective and suitable for other time series forecasting.},
  archive      = {J_SOCO},
  author       = {Huang, Shian-Chang and Chiou, Chei-Chang and Chiang, Jui-Te and Wu, Cheng-Feng},
  doi          = {10.1007/s00500-019-04100-5},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {8021-8039},
  shortjournal = {Soft Comput.},
  title        = {Online sequential pattern mining and association discovery by advanced artificial intelligence and machine learning techniques},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Analysis of multi-level capital market linkage driven by
artificial intelligence and deep learning methods. <em>SOCO</em>,
<em>24</em>(11), 8011–8019. (<a
href="https://doi.org/10.1007/s00500-019-04095-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence has a very wide application in modern society. Deep learning algorithms promote the development of artificial intelligence industry. The development of artificial intelligence industry needs the support of capital market. As far as the relationship between the three is concerned, the artificial intelligence industry is in the middle position. In short, the computer deep learning algorithm is the technical basis for the development of artificial intelligence, and the capital market is an important guarantee for the development of the artificial intelligence industry. However, under the current development background of China, the capital market is far from meeting the improvement and development of high-tech industries. Therefore, in order to further clarify the important role of deep learning algorithms in the development of artificial intelligence and capital markets, this paper systematically analyzes these three relationships and proposes measures from the perspective of supporting theoretical research and development and improving capital markets.},
  archive      = {J_SOCO},
  author       = {Jing, Xinxin and Peng, Pin and Huang, Zhe},
  doi          = {10.1007/s00500-019-04095-z},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {8011-8019},
  shortjournal = {Soft Comput.},
  title        = {Analysis of multi-level capital market linkage driven by artificial intelligence and deep learning methods},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Auto-encoder-based generative models for data augmentation
on regression problems. <em>SOCO</em>, <em>24</em>(11), 7999–8009. (<a
href="https://doi.org/10.1007/s00500-019-04094-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, auto-encoder-based generative models have been widely used successfully for image processing. However, there are few studies on the realization of continuous input–output mappings for regression problems. Lack of a sufficient amount of training data plagues regression problems, which is also a notable problem in machine learning, which affects its application in the field of materials science. Using variational auto-encoders (VAEs) as generative models for data augmentation, we address the issue of small data size for regression problems. VAEs are popular and powerful auto-encoder-based generative models. Generative auto-encoder models such as VAEs use multilayer neural networks to generate sample data. In this study, we demonstrate the effectiveness of multi-task learning (auto-encoding and regression tasks) relating to regression problems. We conducted experiments on seven benchmark datasets and on one ionic conductivity dataset as an application in materials science. The experimental results show that the multi-task learning for VAEs improved the generalization performance of multivariable linear regression model trained with augmented data.},
  archive      = {J_SOCO},
  author       = {Ohno, Hiroshi},
  doi          = {10.1007/s00500-019-04094-0},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {7999-8009},
  shortjournal = {Soft Comput.},
  title        = {Auto-encoder-based generative models for data augmentation on regression problems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Constructing the regional intelligent economic decision
support system based on fuzzy c-mean clustering algorithm.
<em>SOCO</em>, <em>24</em>(11), 7989–7997. (<a
href="https://doi.org/10.1007/s00500-019-04091-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to help decision-making departments to know the information of regional economic development in time, the economic prediction and early warning model and economic policy simulation model of the decision-making system are constructed by analyzing the influencing factors of regional economy and taking the fuzzy C-means clustering as the main algorithm. Based on the data in the statistical yearbook, the corresponding module functions of the system are completed. Then, the system is applied to predict the recent economic development indicators. The results show that the forecasting data and the real data of the indicators are on the same level as a whole. When the growth rate of foreign trade export, fixed assets investment, fiscal expenditure and total retail sales of social consumer goods are increased by 1 percentage point, respectively, the GDP growth rate will increase by 0.105, 0.113, 0.134, 0.087 and 0.075 percentage points. The research suggests that the support system basically meets the requirements, can achieve the purpose of prediction, and has certain practicability.},
  archive      = {J_SOCO},
  author       = {Wang, Jia and Yu, Chuangang and Zhang, Juying},
  doi          = {10.1007/s00500-019-04091-3},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {7989-7997},
  shortjournal = {Soft Comput.},
  title        = {Constructing the regional intelligent economic decision support system based on fuzzy C-mean clustering algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A high-performance CNN method for offline handwritten
chinese character recognition and visualization. <em>SOCO</em>,
<em>24</em>(11), 7977–7987. (<a
href="https://doi.org/10.1007/s00500-019-04083-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent researches introduced fast, compact and efficient convolutional neural networks (CNNs) for offline handwritten Chinese character recognition (HCCR). However, many of them did not address the problem of network interpretability. We propose a new architecture of a deep CNN with high recognition performance which is capable of learning deep features for visualization. A special characteristic of our model is the bottleneck layers which enable us to retain its expressiveness while reducing the number of multiply-accumulate operations and the required storage. We introduce a modification of global weighted average pooling (GWAP)—global weighted output average pooling (GWOAP). This paper demonstrates how they allow us to calculate class activation maps (CAMs) in order to indicate the most relevant input character image regions used by our CNN to identify a certain class. Evaluating on the ICDAR-2013 offline HCCR competition dataset, we show that our model enables a relative 0.83\% error reduction while having 49\% fewer parameters and the same computational cost compared to the current state-of-the-art single-network method trained only on handwritten data. Our solution outperforms even recent residual learning approaches.},
  archive      = {J_SOCO},
  author       = {Melnyk, Pavlo and You, Zhiqiang and Li, Keqin},
  doi          = {10.1007/s00500-019-04083-3},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {7977-7987},
  shortjournal = {Soft Comput.},
  title        = {A high-performance CNN method for offline handwritten chinese character recognition and visualization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On construction of the air pollution monitoring service with
a hybrid database converter. <em>SOCO</em>, <em>24</em>(11), 7955–7975.
(<a href="https://doi.org/10.1007/s00500-019-04079-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Air pollution has a severe impact on human health, pollution harms human health, and people start to pay attention to how to use the monitoring system in real-time recording for analysis. To maintain smooth monitoring and analysis, we have to manage the historical data separated from the incoming data. Historical data is used when we need to analyze the data, while real-time incoming data is used to visualize the real condition. To achieve this objective, we need to collect real-time data from environmental protection open data resource. However, the data might grow faster and become huge; in this case, the relational database was not designed to process a large amount of data. Therefore, we require a database technology that can handle massive volume data, that is not only Structured Query Language (NoSQL). This method raises an important point regarding how to dump the data to NoSQL without change relational database (RDB) system. Accordingly, this paper proposed an air pollution monitoring system combines Hadoop cluster to dump data from RDB to NoSQL and data backup. By this way, it will not only reduce the performance of RDB loading but also keep the service status. Dump data to NoSQL need to process without affecting the real-time monitoring of air pollution monitoring system. In this part, we focus on without interruption web service, and it can be up to 60\%, through optimizing it with dump method and backup data service, MapReduce can restart the service and distribute the database when RDB is impairing. Besides that, through three different types of conversion mode, we can get the best data conversion in our system. Finally, air pollution monitoring service provides a variant of air pollution factor as an essential basis of environment detection and analysis to serve people living in a more comfortable environment.},
  archive      = {J_SOCO},
  author       = {Yang, Chao-Tung and Chen, Shuo-Tsung and Liu, Jung-Chun and Sun, Pei-Lun and Yen, Neil Y.},
  doi          = {10.1007/s00500-019-04079-z},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {7955-7975},
  shortjournal = {Soft Comput.},
  title        = {On construction of the air pollution monitoring service with a hybrid database converter},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hybridized neural network and decision tree based classifier
for prognostic decision making in breast cancers. <em>SOCO</em>,
<em>24</em>(11), 7947–7953. (<a
href="https://doi.org/10.1007/s00500-019-04066-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence techniques and algorithms are applied at various fields such as face recognition, self-driving cars, industrial robots and health care. These real-world conundrums are solved employing artificial intelligence since it focuses on narrow tasks, and AI-driven tasks are very reliable and efficient because of its automated problem-solving techniques. Breast cancer is considered as the most common type of cancer among women. The well-known technique for detection of breast cancer is mammography which can diagnosis anomalies and determine cancerous cells. However, in the present breast cancer screenings, the retrospective studies reveal that approximately 20–40\% of breast cancer cases are missed by radiologists. The main objective of the proposed algorithm is to exactly forecast the misclassified malignant cancers employing radial basis function network and decision tree. In order to obtain the effective classification algorithm, this work is compared with three widely employed algorithms, namely K-nearest neighbors, support vector machine and Naive Bayes algorithm, and the proposed algorithm achieves a high accuracy.},
  archive      = {J_SOCO},
  author       = {Suresh, A. and Udendhran, R. and Balamurgan, M.},
  doi          = {10.1007/s00500-019-04066-4},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {7947-7953},
  shortjournal = {Soft Comput.},
  title        = {Hybridized neural network and decision tree based classifier for prognostic decision making in breast cancers},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Constructing rural e-commerce logistics model based on ant
colony algorithm and artificial intelligence method. <em>SOCO</em>,
<em>24</em>(11), 7937–7946. (<a
href="https://doi.org/10.1007/s00500-019-04046-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to study the application of ant colony algorithm in rural e-commerce logistics mode, the third-party distribution model was adopted as the logistics method with Xuzhou City’s fruit and vegetable agricultural products as the key research object. Through the model construction, the problem of the third-party distribution model is analyzed. Based on the ant colony algorithm, the shortest path and cost are calculated using MATLAB software. The cost and efficiency problems under different variables are analyzed and the model evaluation is carried out. Finally, the difficulties at the urban and rural end of the third-party distribution model are solved. The results show that the method improves the distribution efficiency and reduces the logistics cost. Therefore, it is conducive to the advancement of rural e-commerce.},
  archive      = {J_SOCO},
  author       = {Feng, Zhitan},
  doi          = {10.1007/s00500-019-04046-8},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {7937-7946},
  shortjournal = {Soft Comput.},
  title        = {Constructing rural e-commerce logistics model based on ant colony algorithm and artificial intelligence method},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). RETRACTED ARTICLE: Building the electronic evidence analysis
model based on association rule mining and FP-growth algorithm.
<em>SOCO</em>, <em>24</em>(11), 7925–7936. (<a
href="https://doi.org/10.1007/s00500-019-04032-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In China’s criminal procedure law, electronic data is a kind of independent evidence. With the development of big data technology, more and more attention has been paid to the examination and application of electronic evidence in criminal trials. In order to obtain hidden knowledge from confused electronic evidence, an electronic evidence analysis model based on data mining is proposed. The main research is to apply the association rule technology of data mining to the analysis of electronic evidence, analyze the shortcomings of the existing association rule mining algorithm, and put forward the improved algorithm of the existing algorithm and a new idea of the algorithm. Based on FP-growth algorithm, an improved algorithm (ISPO-tree algorithm) is put forward and the theoretical proof is given. This algorithm only needs to browse the database once and adds the function of supporting a small amount of modified evidence. This algorithm improves the time efficiency of data pre-processing by making similar rules to make unequal attribute values equal and can mine more association rules under the optimum conditions of support and redundancy, and it improves the effectiveness of electronic evidence and the accuracy of criminal trial.},
  archive      = {J_SOCO},
  author       = {Wu, Yilan and Zhang, Jing},
  doi          = {10.1007/s00500-019-04032-0},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {7925-7936},
  shortjournal = {Soft Comput.},
  title        = {RETRACTED ARTICLE: Building the electronic evidence analysis model based on association rule mining and FP-growth algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Recognizing important factors of influencing trust in O2O
models: An example of OpenTable. <em>SOCO</em>, <em>24</em>(11),
7907–7923. (<a
href="https://doi.org/10.1007/s00500-019-04019-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online-to-offline/offline-to-online (O2O) business models have attracted lots of enterprisers to enter this market. In such a fast-growing competition, some studies indicated that lack of trust will bring a great damage to O2O business. Related works already confirm trust is the key factor to the success of O2O. Besides, social media has been changing the way providers communicate with consumers. Negative comments in social media will decrease the consumers’ trust to O2O companies and platforms. Available O2O studies are almost always conducted by means of questionnaires or interviews, which cannot provide immediate customer response and require a lot of manpower and time. Since online reviews are the main information source for consumers. Therefore, this study presented a text mining-based scheme which uses text mining technique to find important factors from online electronic word-of-mouth, to replace the traditional questionnaire survey method of collecting data. Two feature selection methods, Support Vector Machines Recursive Feature Elimination and Least Absolute Shrinkage and Selection Operator have employed to select important factors that affect O2O trust. We also evaluate the performance of extracted feature subsets by Support Vector Machines. The findings can be referenced for O2O market enterprises to carefully response customers’ comments to avoid hurting customers’ trust and improve service quality.},
  archive      = {J_SOCO},
  author       = {Chang, Jing-Rong and Chen, Mu-Yen and Chen, Long-Sheng and Chien, Wan-Ting},
  doi          = {10.1007/s00500-019-04019-x},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {7907-7923},
  shortjournal = {Soft Comput.},
  title        = {Recognizing important factors of influencing trust in O2O models: An example of OpenTable},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust optimization and mixed-integer linear programming
model for LNG supply chain planning problem. <em>SOCO</em>,
<em>24</em>(11), 7885–7905. (<a
href="https://doi.org/10.1007/s00500-019-04010-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A constant development of gas utilization in domestic households, industry, and power plants has slowly transformed gaseous petrol into a noteworthy wellspring of energy. Supply and transportation planning of liquefied natural gas (LNG) need a great attention from the management of the supply chain to provide a significant development of gas trading. Therefore, this paper addresses a robust mixed-integer linear programming model for LNG sales planning over a given time horizon aiming to minimize the costs of the vendor. Since the parameter of the manufacturer supply has an uncertain nature in the real world, and this parameter is regarded to be interval-based uncertain. To validate the model, various illustrative examples are solved using CPLEX solver of GAMS software under different uncertainty levels. Furthermore, a novel metaheuristic algorithm, namely cuckoo optimization algorithm (COA), is designed to solve the problem efficiently. The obtained comparison results demonstrate that the proposed COA can generate high-quality solutions. Furthermore, the comparison results of the deterministic and robust models are evaluated, and sensitivity analyses are performed on the main parameters to provide the concluding remarks and managerial insights of the research. Finally, a comparison evaluation is done between the total vendor profit and the robustness cost to find the optimal robustness level.},
  archive      = {J_SOCO},
  author       = {Sangaiah, Arun Kumar and Tirkolaee, Erfan Babaee and Goli, Alireza and Dehnavi-Arani, Saeed},
  doi          = {10.1007/s00500-019-04010-6},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {7885-7905},
  shortjournal = {Soft Comput.},
  title        = {Robust optimization and mixed-integer linear programming model for LNG supply chain planning problem},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Exploration of artistic creation of chinese ink style
painting based on deep learning framework and convolutional neural
network model. <em>SOCO</em>, <em>24</em>(11), 7873–7884. (<a
href="https://doi.org/10.1007/s00500-019-03985-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the purpose of applying information technology to the creation of ink style painting, the algorithm of ink painting rendering based on the deep learning framework and convolutional neural network model is designed and improved. Firstly, the ink style rendering program is written in Python. Secondly, VGG under Caffe architecture and Illustration 2Vec models are transplanted to TensorFlow architecture, and the image is rendered in ink style based on deep learning framework and convolutional neural network model. Finally, based on Node.js, the server-side program for image ink style rendering is built. Among them, Express is adopted as the Web-side framework, and the front-end page effect is completed. The results show that the ink rendering logic program is applicable, and the expected purpose is achieved.},
  archive      = {J_SOCO},
  author       = {Chen, Shuangshuang},
  doi          = {10.1007/s00500-019-03985-6},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {7873-7884},
  shortjournal = {Soft Comput.},
  title        = {Exploration of artistic creation of chinese ink style painting based on deep learning framework and convolutional neural network model},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Design of visual communication based on deep learning
approaches. <em>SOCO</em>, <em>24</em>(11), 7861–7872. (<a
href="https://doi.org/10.1007/s00500-019-03954-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the problem of object recognition caused by small object scale, multi-interaction (occlusion), and strong hiding characteristics in the scene analysis task, an object-region-enhanced network based on deep learning was proposed. The network integrated two core modules designed for the task: object area enhancement strategy and black-hole-filling strategy. The former directly corresponded the object region with high semantic confidence to the local region of the specific category channel of the convolutional feature image. Weighted features were used to improve contextual relationships, and difficult object regions were identified. The latter avoided the mistake of identifying some difficult areas as additional background classes by masking additional background classes. The results showed that the modular design scheme improved the overall parsing performance of the model by replacing the modules, and the two strategies were applied to other existing scenario parsing networks. A unified framework is proposed for handling scene resolution tasks. Benefiting from the modular design approach, the proposed algorithm improves overall performance by replacing convolution or detection modules. Object enhancement and black hole filling are applied to other systems to improve the system’s ability to parse objects. Object area enhancement methods are used to recall objects that are not recognized in a standard split network. Black hole fill techniques can be used to resolve pixels that are incorrectly categorized into additional background classes that do not exist. Therefore, a variety of contextual semantic fusion strategies have certain reference value in the theoretical level of computer vision. More critically, this method has certain reference significance for the design and development of robust and practical application systems.},
  archive      = {J_SOCO},
  author       = {Lu, Lu},
  doi          = {10.1007/s00500-019-03954-z},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {7861-7872},
  shortjournal = {Soft Comput.},
  title        = {Design of visual communication based on deep learning approaches},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Exploration of stock index change prediction model based on
the combination of principal component analysis and artificial neural
network. <em>SOCO</em>, <em>24</em>(11), 7851–7860. (<a
href="https://doi.org/10.1007/s00500-019-03918-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to establish an accurate effective stock forecasting model, the principal component analysis (PCA) was first used to analyze the main financial index data of some listed companies and the comprehensive score of evaluation index was obtained in this study. Then, the financial indicator data and the transaction indicator data were simultaneously used as the input variables of the stock price prediction research, three back propagation (BP) neural network algorithms were used for experiment, and its prediction situation was compared. Results show that the BP neural network based on Bayesian regularization algorithm has the highest prediction accuracy and can avoid over-fitting phenomenon in the training process of the model; the error between the predicted value and the actual value is small. Finally, this study constructed a stock price prediction study based on PCA and BP neural network algorithm as well as an investment stock selection strategy based on traditional stock selection analysis method. As a result, the proposed model is proved to be effective.},
  archive      = {J_SOCO},
  author       = {Cao, Jiasheng and Wang, Jinghan},
  doi          = {10.1007/s00500-019-03918-3},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {7851-7860},
  shortjournal = {Soft Comput.},
  title        = {Exploration of stock index change prediction model based on the combination of principal component analysis and artificial neural network},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Design of building construction safety prediction model
based on optimized BP neural network algorithm. <em>SOCO</em>,
<em>24</em>(11), 7839–7850. (<a
href="https://doi.org/10.1007/s00500-019-03917-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to solve the safety problem of the construction industry, the construction safety prediction model based on the optimized BP neural network algorithm is designed in this study. First, the characteristics of the construction industry were analyzed. As a labor-intensive industry, the construction industry is characterized by numerous factors such as large investment, long construction period and complicated construction environment. Due to the increasingly serious security problem, widespread concern over such problem has been aroused in society. Second, the problem of building construction safety management was summarized, six influencing factors were explored and a building construction safety prediction model based on rough set-genetic-BP neural network was established. Finally, the model was validated by a combination of multiparty consultation, empirical analysis and model comparison. The results showed that the model accurately predicted the risk factors during the construction process and effectively reduced casualties. Therefore, the model is feasible, effective and accurate.},
  archive      = {J_SOCO},
  author       = {Shen, Tao and Nagai, Yukari and Gao, Chan},
  doi          = {10.1007/s00500-019-03917-4},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {7839-7850},
  shortjournal = {Soft Comput.},
  title        = {Design of building construction safety prediction model based on optimized BP neural network algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep learning: Emerging trends, applications and research
challenges. <em>SOCO</em>, <em>24</em>(11), 7835–7838. (<a
href="https://doi.org/10.1007/s00500-020-04939-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SOCO},
  author       = {Chen, Mu-Yen and Chiang, Hsiu-Sen and Lughofer, Edwin and Egrioglu, Erol},
  doi          = {10.1007/s00500-020-04939-z},
  journal      = {Soft Computing},
  number       = {11},
  pages        = {7835-7838},
  shortjournal = {Soft Comput.},
  title        = {Deep learning: Emerging trends, applications and research challenges},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Computerized grading of brain tumors supplemented by
artificial intelligence. <em>SOCO</em>, <em>24</em>(10), 7827–7833. (<a
href="https://doi.org/10.1007/s00500-019-04403-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For effective diagnosis of health conditions, there is a need to process medical images to obtain meaningful information. The diagnosis of brain tumors begins with magnetic resonance imaging (or MRI) scan. This is followed by segmentation of the medical images so obtained which can prove cumbersome if it were to be performed manually. Determining the best approach to do segmentation remains challenge among multiple computerized approaches. This paper combines both the identification and classification of tumors from the MRI results and is backed by a cloud-based framework to provision the same. The phase of extraction of features includes the utilization of a Hadoop framework and Gabor filter along with variations in terms of orientation and scale. Artificial bee colony algorithm and support vector machine classifier have been used to designate the degree of optimal features and categorize the same. The grading of brain tumors from MRI images can be fulfilled by the aforementioned approach. The said approach is believed to deliver promising results in terms of accuracy, which has also been verified experimentally.},
  archive      = {J_SOCO},
  author       = {Aruna, S. K. and Sindhanaiselvan, K. and Madhusudhanan, B.},
  doi          = {10.1007/s00500-019-04403-7},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7827-7833},
  shortjournal = {Soft Comput.},
  title        = {Computerized grading of brain tumors supplemented by artificial intelligence},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Firms’ pricing strategies under different decision sequences
in dual-format online retailing. <em>SOCO</em>, <em>24</em>(10),
7811–7826. (<a
href="https://doi.org/10.1007/s00500-019-04399-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {E-commerce platforms are increasingly adopting a dual-format retailing mode, not only acting as a reseller, but also providing manufacturers a platform (i.e., marketplace) to access consumers. Based on platforms’ offers, manufacturers can choose to operate either dual-format or single-format retailing. To figure out this problem, we first investigate channel selecting strategy for a manufacturer based on consumer value and further consider the impacts of power structure and pricing timing on firms’ optimal pricing policies under dual-format retailing. Our findings suggest the manufacturer prefers to operate marketplace channel when utility discount factor is sufficiently high, while operate dual-format retailing channels when utility discount factor is moderate. An interesting observation is that more market power does not always create higher profit. Under some certain conditions, the e-commerce platform could obtain maximum profit when his rival is the leader, so does the manufacturer. In addition, we also explore leader’s optimal pricing timing under different power structures. If the manufacturer is the leader, she should either let platform pricing early or set her own retail price early, depending on estimated utility discount and given platform fee. Being the leader, the e-commerce platform shouldn’t set his retail price early in any case, which is consistent with “last mover” advantage.},
  archive      = {J_SOCO},
  author       = {Liu, Jinjin and Ke, Hua},
  doi          = {10.1007/s00500-019-04399-0},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7811-7826},
  shortjournal = {Soft Comput.},
  title        = {Firms’ pricing strategies under different decision sequences in dual-format online retailing},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multiattribute decision making based on the binary
connection number in set pair analysis under an interval-valued
intuitionistic fuzzy set environment. <em>SOCO</em>, <em>24</em>(10),
7801–7809. (<a
href="https://doi.org/10.1007/s00500-019-04398-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new multiattribute decision-making (MADM) methodology based on set pair analysis (SPA) for an interval-valued intuitionistic fuzzy set environment is developed in this paper. The connection number, which is known as a major component of SPA, provides a quantitative analysis to integrate the certainty and uncertainty as a combined system. First, we briefly review the concepts of interval-valued intuitionistic fuzzy sets (IVIFS) and the binary connection number (BCN). Then, the transformation method of interval-valued intuitionistic fuzzy numbers into BCNs is studied. Finally, we present a new MADM method where interval-valued intuitionistic fuzzy values are used to express evaluating values of alternatives on attributes, and weights are represented with real numbers or IVIFS. Some typical examples are presented to illustrate the feasibility and validity of the proposed approach.},
  archive      = {J_SOCO},
  author       = {Shen, Qing and Huang, Xu and Liu, Yong and Jiang, Yunliang and Zhao, Keqin},
  doi          = {10.1007/s00500-019-04398-1},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7801-7809},
  shortjournal = {Soft Comput.},
  title        = {Multiattribute decision making based on the binary connection number in set pair analysis under an interval-valued intuitionistic fuzzy set environment},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evaluation of and improvement planning for smart homes using
rough knowledge-based rules on a hybrid multiple attribute
decision-making model. <em>SOCO</em>, <em>24</em>(10), 7781–7800. (<a
href="https://doi.org/10.1007/s00500-019-04396-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes fuzzy integral-based decision methods to identify the core factors and their relationships for smart homes product improvement. The dominance-based rough set approach was used to retrieve core attributes and obtain rough knowledge-based rules. The decision-making trial and evaluation laboratory (DEMATEL) technique was used to build an influential network relationship map, and influential weights were determined through the DEMATEL-based analytic network process. Subsequently, the inter-relationships among criteria were calculated. Finally, the fuzzy integral method was used to measure the plausible synergy effects among the criteria, evaluate/rank alternatives for smart homes, and then provide suggestions for product improvement. The main innovation is the use of rough knowledge-based rule retrieval procedures and fuzzy measures for exploring the synergy effects on smart home improvement. Three smart home products/systems were examined to illustrate their performance on each criterion for improvement planning. This study contributes knowledge to research on consumer adoption of smart homes and presents improvement strategies.},
  archive      = {J_SOCO},
  author       = {Liu, Yupeng and Li, Manyu and Chen, Yifei and Tzeng, Gwo-Hshiung},
  doi          = {10.1007/s00500-019-04396-3},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7781-7800},
  shortjournal = {Soft Comput.},
  title        = {Evaluation of and improvement planning for smart homes using rough knowledge-based rules on a hybrid multiple attribute decision-making model},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-view reconstructive preserving embedding for dimension
reduction. <em>SOCO</em>, <em>24</em>(10), 7769–7780. (<a
href="https://doi.org/10.1007/s00500-019-04395-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of feature extraction technique, one sample always can be represented by multiple features which are located in different high-dimensional spaces. Because multiple features can reflect one same sample from various perspectives, there must be compatible and complementary information among the multiple views. Therefore, it’s natural to learn information from multiple views to obtain better performance. However, most multi-view dimension reduction methods cannot handle multiple features from nonlinear space with high dimensions. To address this problem, we propose a novel multi-view dimension reduction method named multi-view reconstructive preserving embedding (MRPE) in this paper. MRPE reconstructs each sample by utilizing its k nearest neighbors. The similarities between each sample and its neighbors are mapped into lower-dimensional space in order to preserve the underlying neighborhood structure of the original manifold. MRPE fully exploits correlations between each sample and its neighbors from multiple views by linear reconstruction. Furthermore, MRPE constructs an optimization problem and derives an iterative procedure to obtain the low-dimensional embedding. Various evaluations based on the applications of document classification, face recognition and image retrieval demonstrate the effectiveness of our proposed approach on multi-view dimension reduction.},
  archive      = {J_SOCO},
  author       = {Wang, Huibing and Feng, Lin and Kong, Adong and Jin, Bo},
  doi          = {10.1007/s00500-019-04395-4},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7769-7780},
  shortjournal = {Soft Comput.},
  title        = {Multi-view reconstructive preserving embedding for dimension reduction},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Combining quality function deployment with simple additive
weighting for interval-valued fuzzy multi-criteria decision-making with
dependent evaluation criteria. <em>SOCO</em>, <em>24</em>(10),
7757–7767. (<a
href="https://doi.org/10.1007/s00500-019-04394-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past, lots of multi-criteria decision-making (MCDM) methods included simple additive weighting (SAW) extended under fuzzy environment into multi-criteria decision-making (FMCDM) methods to encompass uncertainty and vagueness of data. The extensions were first used in FMCDM with independent evaluation criteria, and then, FMCDM could be associated with quality function deployment (QFD) to break the tie of dependent evaluation criteria. Commonly, alternative ratings and criteria weights in FMCDM were expressed by general fuzzy numbers (i.e., triangular or trapezoidal fuzzy numbers). Recently, some approaches proposed FMCDM with independent evaluation criteria under interval-valued fuzzy environment. For interval-valued fuzzy numbers, FMCDM with dependent evaluation criteria was scarcely elaborated due to computation complexity. Besides, QFD was also generalized under some fuzzy environments consisting of triangular fuzzy numbers or trapezoidal fuzzy numbers, but not interval-valued fuzzy environment. Practically, interval-valued fuzzy numbers are deemed as a kind of fuzzy number that can grasp more information than other fuzzy numbers, but the kind of fuzzy number is more complex on computation than others. Based on above, we desire to extend QFD and SAW under interval-valued fuzzy environment for FMCDM with dependent evaluation criteria. By a rational technique of combining QFD with SAW under fuzzy environment, the computation tie of interval-valued fuzzy numbers corresponding to dependent evaluation criteria is resolved, and more messages are grasped than using other fuzzy numbers in FMCDM.},
  archive      = {J_SOCO},
  author       = {Wang, Yu-Jie},
  doi          = {10.1007/s00500-019-04394-5},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7757-7767},
  shortjournal = {Soft Comput.},
  title        = {Combining quality function deployment with simple additive weighting for interval-valued fuzzy multi-criteria decision-making with dependent evaluation criteria},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Aggregation of pragmatic operators to support probabilistic
linguistic multi-criteria group decision-making problems. <em>SOCO</em>,
<em>24</em>(10), 7735–7755. (<a
href="https://doi.org/10.1007/s00500-019-04393-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a multi-attribute group decision-making method based on aggregation operators is presented to solve the decision-making problems which the evaluation values take the form of probabilistic linguistic terms sets (PLTSs). Firstly, some properties of the PLTS are defined, such as the concept and the linguistic terms transformation function, the existing comparison methods and the proposed score function and distance. Secondly, some novel operators are proposed by combining the Heronian mean operator with the centered OWA operator and the power average operator under probabilistic linguistic environment, such as the probabilistic linguistic weighted centered order weighted generalized Heronian mean operator and the probabilistic linguistic weighted power generalized Heronian mean operator. Thirdly, the model of deriving the criteria weight is put forward based on the ideology of deviation maximizing and customized individual attitudinal. Furthermore, based on the proposed aggregation operators and EDAS method, a scientific group decision-making procedure is put forward under probabilistic linguistic environment. Finally, an illustrative example is also given to demonstrate the feasibility and practicality of the proposed method.},
  archive      = {J_SOCO},
  author       = {Feng, Xiangqian and Zhang, Qian and Jin, Lesheng},
  doi          = {10.1007/s00500-019-04393-6},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7735-7755},
  shortjournal = {Soft Comput.},
  title        = {Aggregation of pragmatic operators to support probabilistic linguistic multi-criteria group decision-making problems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Implementation of fuzzy-based integrated framework for
sesame seed separator development. <em>SOCO</em>, <em>24</em>(10),
7715–7734. (<a
href="https://doi.org/10.1007/s00500-019-04392-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the current scenario, mechatronics-based new product development requires a multi-disciplinary approach for the interaction of mechanics, electronics and software requirements in order to enhance the system effectiveness. This work aims in developing a strategic methodology for making decisions during mechatronics-based new product development. This methodology integrates six different stages of processes, namely identification of the need for new product; conceptual design and development of the new product through fuzzy Delphi method, fuzzy interpretive structural modeling, fuzzy analytical network process and fuzzy quality function deployment algorithms; development of detailed design using computer-aided design/computer-aided engineering and control system software; development of prototype model; analysis of the developed prototype model and finally provide recommendations for product commercialization. The proposed methodology is applied for the design and development of mechatronics-based new product, namely sesame seed separator for agricultural sector. The performance of the developed prototype model of sesame seed separator is analyzed for the potential failures using Fuzzy VIKOR-based fuzzy failure mode and effect analysis (FMEA). Based on the results of fuzzy FMEA, the developed prototype model is redesigned and then finally recommended for commercialization. The framework enhances the product development process and reduces repair and rework.},
  archive      = {J_SOCO},
  author       = {Baskar, C. and Parameshwaran, R. and Nithyavathy, N.},
  doi          = {10.1007/s00500-019-04392-7},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7715-7734},
  shortjournal = {Soft Comput.},
  title        = {Implementation of fuzzy-based integrated framework for sesame seed separator development},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Assessing the quality of mobile graphical user interfaces
using multi-objective optimization. <em>SOCO</em>, <em>24</em>(10),
7685–7714. (<a
href="https://doi.org/10.1007/s00500-019-04391-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aesthetic defects are a violation of quality attributes that are symptoms of bad interface design programming decisions. They lead to deteriorating the perceived usability of mobile user interfaces and negatively impact the User’s eXperience (UX) with the mobile app. Most existing studies relied on a subjective evaluation of aesthetic defects depending on end-users feedback, which makes the manual evaluation of mobile user interfaces human-centric, time-consuming, and error-prone. Therefore, recent studies have dedicated their effort to focus on the definition of mathematical formulas that each targets a specific structural quality of the interface. As the UX is tightly dependent on the user profile, the combination and calibration of quality attributes, formulas, and user’s characteristics, when defining a defect, are not straightforward. In this context, we propose a fully automated framework which combines literature quality attributes with the user’s profile to identify aesthetic defects of MUI. More precisely, we consider the mobile user interface evaluation as a multi-objective optimization problem where the goal is to maximize the number of detected violations while minimizing the detection complexity of detection rules and enhancing the interfaces overall quality in means of guidance and coherence coverage. We conducted a comparative study of several evolutionary algorithms in terms of accurately identifying aesthetic defects. We reported their performance in solving the proposed search-based multi-objective optimization problem. The results confirm the efficiency of the indicator-based evolutionary algorithm in terms of assessing the developers in detecting typical defects and also in generating the most accurate detection rules.},
  archive      = {J_SOCO},
  author       = {Soui, Makram and Chouchane, Mabrouka and Mkaouer, Mohamed Wiem and Kessentini, Marouane and Ghedira, Khaled},
  doi          = {10.1007/s00500-019-04391-8},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7685-7714},
  shortjournal = {Soft Comput.},
  title        = {Assessing the quality of mobile graphical user interfaces using multi-objective optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Selfish herd optimization algorithm based on chaotic
strategy for adaptive IIR system identification problem. <em>SOCO</em>,
<em>24</em>(10), 7637–7684. (<a
href="https://doi.org/10.1007/s00500-019-04390-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The design method of adaptive infinite impulse response (IIR) filter is a challenging problem. Its design principle is to determine the filter parameters by the iteration process of the adaptive algorithm, which is to obtain an optimal model for unknown plant based on minimizing mean square error (MSE). However, many adaptive algorithms cannot adjust the parameters of IIR filter to the minimum MSE. Therefore, a more efficient adaptive optimization algorithm is required to adjust the parameters of IIR filter. In this paper, we propose a selfish herd optimization algorithm based on chaotic strategy (CSHO) and apply it to solving IIR system identification problem. In CSHO, we add a chaotic search strategy, which is a better local optimization strategy. Its function is to search for better candidate solutions around the global optimal solution, which makes the local search of the algorithm more precise and finds out potential global optimal solutions. We use solving IIR system identification problem to verify the effectiveness of CSHO. Ten typical IIR filter models with the same order and reduced order are selected for experiments. The experimental results of CSHO compare with those of bat algorithm (BA), cellular particle swarm optimization and differential evolution (CPSO-DE), firefly algorithm (FFA), hybrid particle swarm optimization and gravitational search algorithm (HPSO-GSA), improved particle swarm optimization (IPSO) and opposition-based harmony search algorithm (OHS), respectively. The experimental results show that CSHO has better optimization accuracy, convergence speed and stability in solving most of the IIR system identification problems. At the same time, it also obtains better optimization parameters and achieves smaller difference between actual output and expected output in test samples.},
  archive      = {J_SOCO},
  author       = {Zhao, Ruxin and Wang, Yongli and Liu, Chang and Hu, Peng and Jelodar, Hamed and Yuan, Chi and Li, YanChao and Masood, Isma and Rabbani, Mahdi and Li, Hao and Li, Bo},
  doi          = {10.1007/s00500-019-04390-9},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7637-7684},
  shortjournal = {Soft Comput.},
  title        = {Selfish herd optimization algorithm based on chaotic strategy for adaptive IIR system identification problem},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evidential model for intuitionistic fuzzy multi-attribute
group decision making. <em>SOCO</em>, <em>24</em>(10), 7615–7635. (<a
href="https://doi.org/10.1007/s00500-019-04389-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the uncertainty existing in real-world, intuitionistic fuzzy sets (IFSs) are used to model uncertain information in multi-attribute group decision making (MAGDM). The intuitionistic fuzzy MAGDM problems have gained great popularity recently. But, most of the current methods depend on various aggregation operators that may provide unreasonable collective intuitionistic fuzzy values of alternatives to be ranked. To solve such problem, a new method is developed based on evidence theory and IFSs. First, the mathematical relation between IFSs and evidence theory is analyzed, followed by the transformation from intuitionistic fuzzy evaluation information to basic belief assignment in evidence theory. Then, a new intuitionistic fuzzy weighted evidential (IFWE) average operator is introduced based on the operation of evidence discounting and evidence combination rule. We also develop a possibility-based ranking method for intuitionistic fuzzy values (IFVs) to obtain the linear ordering of IFVs. The proposed evidential model uses the IFWE average operator to aggregate the decision matrix and the attribute weight that is given by each decision maker, based on which each decision maker’s aggregated decision matrix can be obtained. Based on the decision matrices of all decision makers and the weights of the decision makers, the aggregated intuitionistic fuzzy value of each alternative can be obtained by the IFWE average operator. Finally, the preference order of all alternatives can be obtained by the possibility-based ranking method. Comparative analysis based on several application examples of MAGDM demonstrates that the proposed method can overcome the drawbacks of existing methods for MAGDM in intuitionistic fuzzy environments.},
  archive      = {J_SOCO},
  author       = {Fu, Qiang and Song, Yafei and Fan, Cheng-li and Lei, Lei and Wang, Xiaodan},
  doi          = {10.1007/s00500-019-04389-2},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7615-7635},
  shortjournal = {Soft Comput.},
  title        = {Evidential model for intuitionistic fuzzy multi-attribute group decision making},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A fault diagnosis model of marine diesel engine cylinder
based on modified genetic algorithm and multilayer perceptron.
<em>SOCO</em>, <em>24</em>(10), 7603–7613. (<a
href="https://doi.org/10.1007/s00500-019-04388-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cylinder of marine diesel engine, as the power supply to the marine diesel engine, would lead dramatically damage to the engine once faults occurred. To avoid the situation, we develop a novel combinational approach using an improved genetic algorithm (GA) and multilayer perceptron (MLP). Firstly, chaos theory is carried out on the standard GA to prevent premature convergence. The improvements on the GA consist of population initialized by chaotic mapping, chaotic crossover, and chaotic mutation operator. Secondly, the Levenberg–Marquardt algorithm is used to train the MLP to accelerate the convergence speed of the MLP. Thirdly, the improved GA is used to optimize the initial weights and thresholds of MLP to further improve the performance of MLP. Finally, the proposed model is applied to the cylinder of a marine diesel engine for fault diagnosis. Compared with traditional approaches, the proposed method obtains more ideal solutions. Results demonstrate that the proposed method could effectively identify ten common faults of the marine diesel engine cylinder, and the average correct ratio of fault diagnosis can exceed 95\%.},
  archive      = {J_SOCO},
  author       = {Hou, Liangsheng and Zou, Jiaqi and Du, Changjiang and Zhang, Jundong},
  doi          = {10.1007/s00500-019-04388-3},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7603-7613},
  shortjournal = {Soft Comput.},
  title        = {A fault diagnosis model of marine diesel engine cylinder based on modified genetic algorithm and multilayer perceptron},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hyperparameter optimization in CNN for learning-centered
emotion recognition for intelligent tutoring systems. <em>SOCO</em>,
<em>24</em>(10), 7593–7602. (<a
href="https://doi.org/10.1007/s00500-019-04387-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An intelligent tutoring system is used as an efficient self-learning tutor, where decisions are based on the affective state of the user. These detected emotions are what experts call basic emotions and the best-known recognition technique is the recognition of facial expressions. A convolutional neural network (CNN) can be used to identify emotions through facial gestures with very high precision. One problem with convolutional networks, however, is the high number of hyperparameters to define, which can range from a hundred to a thousand. This problem is usually solved by an expert experience combined with trial and error optimization. In this work, we propose a methodology using genetic algorithms for the optimization of hyperparameters of a CNN, used to identify the affective state of a person. In addition, we present the optimized network embedded into an intelligent tutoring system running on a mobile phone. The training process of the CNN was carried out on a PC with a GPU and the trained neural network was embedded into a mobile environment. The results show an improvement of 8\% (from 74 to 82\%) with genetic algorithms compared to a previous work that utilized a trial and error method.},
  archive      = {J_SOCO},
  author       = {Zatarain Cabada, Ramon and Rodriguez Rangel, Hector and Barron Estrada, Maria Lucia and Cardenas Lopez, Hector Manuel},
  doi          = {10.1007/s00500-019-04387-4},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7593-7602},
  shortjournal = {Soft Comput.},
  title        = {Hyperparameter optimization in CNN for learning-centered emotion recognition for intelligent tutoring systems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Estimation of number of foreign visitors with ANFIS by using
ABC algorithm. <em>SOCO</em>, <em>24</em>(10), 7579–7591. (<a
href="https://doi.org/10.1007/s00500-019-04386-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {ANFIS is an artificial intelligence technique which is composed of a combination of artificial neural networks and fuzzy inference system. Due to its structure, it is used in modeling and identifying numerous systems in various fields. The training process of ANFIS is important to obtain effective results with it. So, a successful training algorithm should be used. In this study, the ANFIS is trained by using ABC algorithm for the solution of the real-world problem. For this purpose, the number of foreign visitors coming to Turkey from the USA, Germany, Bulgaria, France, Georgia, the Netherlands, England, Iran and Russia is estimated. In addition, total number of visitors coming to Turkey is also predicted. In applications, 150 months of data between July 2002 and December 2014 are utilized and a time series is created using these data. The results obtained using ABC algorithm are compared with GA, DE, HS and PSO. As a conclusion, it is seen that the results obtained using ABC algorithm for estimation of number of foreign visitors are more successful than other optimization methods.},
  archive      = {J_SOCO},
  author       = {Karaboga, Dervis and Kaya, Ebubekir},
  doi          = {10.1007/s00500-019-04386-5},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7579-7591},
  shortjournal = {Soft Comput.},
  title        = {Estimation of number of foreign visitors with ANFIS by using ABC algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A composite machine-learning-based framework for supporting
low-level event logs to high-level business process model activities
mappings enhanced by flexible BPMN model translation. <em>SOCO</em>,
<em>24</em>(10), 7557–7578. (<a
href="https://doi.org/10.1007/s00500-019-04385-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Process mining is an emerging discipline that aims to analyze business processes using event data logged by IT systems. In process mining, the focus is on how to effectively and efficiently predict the next process/trace to be activated among all the possible processes/traces that are available in the process schema (usually modeled as a graph). Most of the existing process mining techniques assume that there is a one-to-one mapping between process model activities and the events that are recorded during process execution. However, event logs and process model activities are at different level of granularity. In this paper, we present a machine-learning-based approach to map low-level event logs to high-level activities. With this work, we can bridge the abstraction levels when the high-level labels of the low-level events are not available. The proposed approach consists of two main phases: automatic labeling and machine-learning-based classification. In automatic labeling, a modified k-prototypes clustering approach has been used in order to obtain the labeled examples. Then, in the second phase, we trained different ML classifiers using the obtained labeled examples. Since, in real-life applications and systems, business processes are expressed according to the Business Process Model and Notation (BPMN) format, we improve our proposed framework by means of an innovative, flexible BPMN model translation methodology that acts at the first phase. We demonstrate the applicability of our proposed framework using two case studies with real-world event logs, and provide its experimental assessment and analysis.},
  archive      = {J_SOCO},
  author       = {Al-Ali, H. and Cuzzocrea, A. and Damiani, E. and Mizouni, R. and Tello, G.},
  doi          = {10.1007/s00500-019-04385-6},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7557-7578},
  shortjournal = {Soft Comput.},
  title        = {A composite machine-learning-based framework for supporting low-level event logs to high-level business process model activities mappings enhanced by flexible BPMN model translation},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An extension to fuzzy ELECTRE. <em>SOCO</em>,
<em>24</em>(10), 7541–7555. (<a
href="https://doi.org/10.1007/s00500-019-04381-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An extension to fuzzy ELECTRE is proposed in this paper, where ratings of alternatives versus qualitative criteria and the importance weights of criteria are assessed in linguistic values represented by fuzzy numbers. Formulas for the membership functions of fuzzy weighted ratings of alternatives under criteria can be obtained, and some properties are investigated. The ranking method of mean of maximum and minimum based on the Chen method is suggested to rank those fuzzy weighted ratings to produce concordance and discordance sets to complete the model. A numerical example will be used to demonstrate feasibility of the proposed fuzzy ELECTRE method, in which the outranking relationships among the alternatives can be clearly displayed. A comparison between the proposed ranking method and the Chen method will also be conducted to show advantage of the proposed method.},
  archive      = {J_SOCO},
  author       = {Chu, Ta-Chung and Le, Hanh Thao},
  doi          = {10.1007/s00500-019-04381-w},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7541-7555},
  shortjournal = {Soft Comput.},
  title        = {An extension to fuzzy ELECTRE},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A fast parallel genetic programming framework with
adaptively weighted primitives for symbolic regression. <em>SOCO</em>,
<em>24</em>(10), 7523–7539. (<a
href="https://doi.org/10.1007/s00500-019-04379-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Genetic programming (GP) is a popular and powerful optimization algorithm that has a wide range of applications, such as time series prediction, classification, data mining, and knowledge discovery. Despite the great success it enjoyed, selecting the proper primitives from high-dimension primitive set for GP to construct solutions is still a time-consuming and challenging issue that limits the efficacy of GP in real-world applications. In this paper, we propose a multi-population GP framework with adaptively weighted primitives to address the above issues. In the proposed framework, the entire population consists of several sub-populations and each has a different vector of primitive weights to determine the probability of using the corresponding primitives in a sub-population. By adaptively adjusting the weights of the primitives and periodically sharing information between sub-populations, the proposed framework can efficiently identify important primitives to assist the search. Furthermore, based on the proposed framework and the graphics processing unit computing technique, a high-performance self-learning gene expression programming algorithm (HSL-GEP) is developed. The HSL-GEP is tested on fifteen problems, including four real-world problems. The experimental results have demonstrated that the proposed HSL-GEP outperforms several state-of-the-art GPs, in terms of both solution quality and search efficiency.},
  archive      = {J_SOCO},
  author       = {Huang, Zhixing and Zhong, Jinghui and Feng, Liang and Mei, Yi and Cai, Wentong},
  doi          = {10.1007/s00500-019-04379-4},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7523-7539},
  shortjournal = {Soft Comput.},
  title        = {A fast parallel genetic programming framework with adaptively weighted primitives for symbolic regression},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimization of power quality in wind energy conversion
system using hybrid modulation. <em>SOCO</em>, <em>24</em>(10),
7511–7522. (<a
href="https://doi.org/10.1007/s00500-019-04377-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generation of power from renewable sources of energy is being more actively researched in recent times due to fast depletion of non-renewable energy resources. One among the renewable energy resource is tapping of energy from wind turbines where wind energy is converted into ample electrical energy. However, power generation systems are often influenced by several attributes which affect the quality of power generated. One among them is the crucial harmonics which if present in significant measures tends to degrade power quality. This research paper proposes a control technique which operates at voltage source inverter level incorporated in a wind energy conversion system to reduce the overall THD\%. A hybrid control mechanism is employed in the proposed work which actively works to reduce the harmonic spread factor as well as voltage harmonics by providing precise decision of carrier states which form an integral part of the feedback shift register present in the system. The emphasis therefore extricates to arrive at an appropriate choice of the carrier and ensembles a comparative analysis of the voltage harmonic reduction strategy that includes sinusoidal PWM, random PWM, space vector PWM and hybrid SVPWM techniques. The framework evaluates the performance using MATLAB simulation and validates the results through a prototype to establish the suitability of the scheme for use in practice.},
  archive      = {J_SOCO},
  author       = {Boopathi, R. and Jayanthi, R. and Ansari, M. Mohamed Thameem},
  doi          = {10.1007/s00500-019-04377-6},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7511-7522},
  shortjournal = {Soft Comput.},
  title        = {Optimization of power quality in wind energy conversion system using hybrid modulation},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). HSOS: A novel hybrid algorithm for solving the
transient-stability-constrained OPF problem. <em>SOCO</em>,
<em>24</em>(10), 7481–7510. (<a
href="https://doi.org/10.1007/s00500-019-04374-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a new algorithm aimed toward effective handling of the transient-stability-constrained optimal power flow (TSC_OPF) problem. The algorithm is a hybridized version of the existing differential evolution (DE) and symbiotic organism search (SOS) algorithms. It combines exploration and exploitation ability of both algorithms which results in its better performance as compared to DE and SOS acting alone. It was tested on IEEE 30 bus test system and the New England 39 bus test system. The results obtained by the proposed approach were compared with conventional TSC_OPF and also with other algorithms available in the literature. Results obtained using the proposed approach demonstrates superiority in comparison with other available algorithms in the literature.},
  archive      = {J_SOCO},
  author       = {Saha, Anulekha and Bhattacharya, Aniruddha and Das, Priyanath and Chakraborty, Ajoy Kumar},
  doi          = {10.1007/s00500-019-04374-9},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7481-7510},
  shortjournal = {Soft Comput.},
  title        = {HSOS: A novel hybrid algorithm for solving the transient-stability-constrained OPF problem},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An exponential jerk system, its fractional-order form with
dynamical analysis and engineering application. <em>SOCO</em>,
<em>24</em>(10), 7469–7479. (<a
href="https://doi.org/10.1007/s00500-019-04373-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A simple jerk system with only one exponential nonlinearity is proposed and discussed. Dynamic analysis of the integer-order jerk system shows the existence of chaotic oscillations. A model for the fractional-order jerk system is derived. The Adomian decomposition method is used to analyse the fractional-order jerk system. Stability analysis of the fractional-order jerk system shows that chaotic oscillations exist in orders less than one and bifurcation analysis shows the range of fractional orders for periodic and chaotic oscillations. To show the randomness of the fractional-order jerk system, a pseudorandom number generator is designed and tested. The NIST-800-22 tests show that the proposed fractional-order jerk system is effective in showing randomness. Finally, an image hiding application to the audio data has been realized by using the developed RNG algorithm. The encrypted image is hidden by being embedded in the audio data, and then, on the receiver side, the data are recovered by taking the image data from the hidden audio file.},
  archive      = {J_SOCO},
  author       = {Rajagopal, Karthikeyan and Akgul, Akif and Jafari, Sajad and Karthikeyan, Anitha and Cavusoglu, Unal and Kacar, Sezgin},
  doi          = {10.1007/s00500-019-04373-w},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7469-7479},
  shortjournal = {Soft Comput.},
  title        = {An exponential jerk system, its fractional-order form with dynamical analysis and engineering application},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Indeterminate likert scale: Feedback based on neutrosophy,
its distance measures and clustering algorithm. <em>SOCO</em>,
<em>24</em>(10), 7459–7468. (<a
href="https://doi.org/10.1007/s00500-019-04372-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Likert scale is the most widely used psychometric scale for obtaining feedback. The major disadvantage of Likert scale is information distortion and information loss problem that arise due to its ordinal nature and closed format. Real-world responses are mostly inconsistent, imprecise and indeterminate depending on the customers’ emotions. To capture the responses realistically, the concept of neutrosophy (study of neutralities and indeterminacy) is used. Indeterminate Likert scale based on neutrosophy is introduced in this paper. Clustering according to customer feedback is an effective way of classifying customers and targeting them accordingly. Clustering algorithm for feedback obtained using indeterminate Likert scaling is proposed in this paper. While dealing real-world scenarios, indeterminate Likert scaling is better in capturing the responses accurately.},
  archive      = {J_SOCO},
  author       = {Kandasamy, Ilanthenral and Kandasamy, W. B. Vasantha and Obbineni, Jagan M. and Smarandache, Florentin},
  doi          = {10.1007/s00500-019-04372-x},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7459-7468},
  shortjournal = {Soft Comput.},
  title        = {Indeterminate likert scale: Feedback based on neutrosophy, its distance measures and clustering algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). RETRACTED ARTICLE: Sentiment classification using harmony
random forest and harmony gradient boosting machine. <em>SOCO</em>,
<em>24</em>(10), 7451–7458. (<a
href="https://doi.org/10.1007/s00500-019-04370-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The building of a system for exploring the opinions of users that are made in the blog posts, tweets, reviews or comments regarding a particular topic, policy or a product is known as sentiment analysis. The primary aim of this is the determination of the user attitude regarding a certain topic. The harmony search algorithm has proved to be extremely useful in a varied range of problems in optimization. This shows better performance compared to the other techniques of optimization. Another very powerful technique that is applied to machine learning which is now getting extremely popular is gradient boosting. There are several tree parameters which have been optimized for the random forest and the gradient boosting machine that make use of the harmony search algorithm.},
  archive      = {J_SOCO},
  author       = {Sridharan, K. and Komarasamy, G.},
  doi          = {10.1007/s00500-019-04370-z},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7451-7458},
  shortjournal = {Soft Comput.},
  title        = {RETRACTED ARTICLE: Sentiment classification using harmony random forest and harmony gradient boosting machine},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Linking granular computing, big data and decision making: A
case study in urban path planning. <em>SOCO</em>, <em>24</em>(10),
7435–7450. (<a
href="https://doi.org/10.1007/s00500-019-04369-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Granular computing, an emerging information processing paradigm transforming complex data into information granules at different scales so that different features and regularities can be revealed, offers an essential linkage between big data and decision making. By using innovative technologies of granular computing that transforms big data collections into information granules, we would be at position of recognizing and exploiting the meaningful pieces of knowledge present in data, and produce sound, and practically supported decisions. In this study, we first summarize a general scheme of big data–granular computing–decision making and then present a case study where we detect the important traffic event information by collecting and analyzing social media data, and transform them into probabilistic information granules that can be used for urban routing navigation. We propose a robust fastest path optimization model to incorporate the impact of traffic events and generate the optimal routing strategy. Real-life experiments are carried out in regional Chaoyang District, Beijing, as well as the backbone roadway network of Beijing, which illustrate the effectiveness of our proposed big data-driven decision-making method. Our study provides new evidence demonstrating that big data can be efficiently used to enhance decisions and granular computing with this regard. The concept of the proposed scheme can be easily extended for decision-making modeling in other domains.},
  archive      = {J_SOCO},
  author       = {Li, Xiang and Zhou, Jiandong and Pedrycz, Witold},
  doi          = {10.1007/s00500-019-04369-6},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7435-7450},
  shortjournal = {Soft Comput.},
  title        = {Linking granular computing, big data and decision making: A case study in urban path planning},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). SP-BRAIN: Scalable and reliable implementations of a
supervised relevance-based machine learning algorithm. <em>SOCO</em>,
<em>24</em>(10), 7417–7434. (<a
href="https://doi.org/10.1007/s00500-019-04366-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, new implementations of the U-BRAIN (Uncertainty-managing Bach Relevance-Based Artificial Intelligence) supervised machine learning algorithm are described. The implementations, referred as SP-BRAIN (SP stands for Spark), aim to efficiently process large datasets. Given the iterative nature of the algorithm together with its dependence on in-memory data, a non-standard MapReduce paradigm is applied, taking into account several memory and performance problems, e.g., the granularity of the MAP task, the reduction in the shuffling operation, caching, partial data recomputing, and usage of clusters. The implementations benefit the whole Hadoop ecosystem components, such as HDFS, Yarn, and streaming. Testing is performed in cloud execution environments, using different configurations with up to 128 cores. The performance of the new implementations is evaluated on three known datasets, and the findings are compared to the ones of a previous U-BRAIN parallel implementation. The results show a speedup up to 20 × with a good scalability and reliability in cluster environments.},
  archive      = {J_SOCO},
  author       = {Morfino, Valerio and Rampone, Salvatore and Weitschek, Emanuel},
  doi          = {10.1007/s00500-019-04366-9},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7417-7434},
  shortjournal = {Soft Comput.},
  title        = {SP-BRAIN: Scalable and reliable implementations of a supervised relevance-based machine learning algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Grid-based dynamic robust multi-objective brain storm
optimization algorithm. <em>SOCO</em>, <em>24</em>(10), 7395–7415. (<a
href="https://doi.org/10.1007/s00500-019-04365-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rich works have been done on brain storm optimization algorithm solving static single- or multi-objective optimization problems, but less reports for dynamic multi-objective optimization problems. Based on this, a grid-based multi-objective brain storming algorithm with hybrid mutation operation is proposed to find the robust Pareto-optimal solution set over time. Grid-based clustering method partitions the objective space evenly along each objective and classifies the individuals located in the same grid into a cluster. Its computational complexity is less than k-means- and group-based clustering strategies. Traditional Gaussian-, Cauchy- and Chaotic-based mutation operators have different mutation steps and generate the new individuals with various diversity. In order to enhance the diversity and avoiding the premature convergence, a hybrid mutation strategy integrating above three mutation operators is presented. Experimental results for eight dynamic multi-objective benchmark functions show that the proposed algorithm can find robust Pareto-optimal solutions approximating the true Pareto front under more subsequent environments with the acceptable fitness threshold. The longer survival time also indicates that grid-based clustering method and hybrid mutation strategy are apt to better robustness.},
  archive      = {J_SOCO},
  author       = {Guo, Yinan and Yang, Huan and Chen, Meirong and Gong, Dunwei and Cheng, Shi},
  doi          = {10.1007/s00500-019-04365-w},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7395-7415},
  shortjournal = {Soft Comput.},
  title        = {Grid-based dynamic robust multi-objective brain storm optimization algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Performance comparison of metaheuristic algorithms using a
modified gaussian fitness landscape generator. <em>SOCO</em>,
<em>24</em>(10), 7383–7393. (<a
href="https://doi.org/10.1007/s00500-019-04363-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various metaheuristic optimization algorithms are being developed to obtain optimal solutions to real-world problems. Metaheuristic algorithms are inspired by various metaphors, resulting in different search mechanisms, operators, and parameters, and thus algorithm-specific strengths and weaknesses. Newly developed algorithms are generally tested using benchmark problems. However, for existing traditional benchmark problems, it is difficult for users to freely modify the characteristics of a problem. Thus, their shapes and sizes are limited, which is a disadvantage. In this study, a modified Gaussian fitness landscape generator is proposed based on a probability density function, to make up for the disadvantages of traditional benchmark problems. The fitness landscape developed in this study contains a total of six features and can be employed to easily create various problems depending on user needs, which is an important advantage. It is applied to quantitatively evaluate the performance and reliability of eight reported metaheuristic algorithms. In addition, a sensitivity analysis is performed on the population size for population-based algorithms. Furthermore, improved versions of the metaheuristic algorithm are considered, to investigate which performance aspects are enhanced by applying the same fitness landscape. The modified Gaussian fitness landscape generator can be employed to compare the performances of existing optimization algorithms and to evaluate the performances of newly developed algorithms. In addition, it can be employed to develop methods of improving algorithms by evaluating their strengths and weaknesses.},
  archive      = {J_SOCO},
  author       = {Lee, Ho Min and Jung, Donghwi and Sadollah, Ali and Kim, Joong Hoon},
  doi          = {10.1007/s00500-019-04363-y},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7383-7393},
  shortjournal = {Soft Comput.},
  title        = {Performance comparison of metaheuristic algorithms using a modified gaussian fitness landscape generator},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Algorithm for solving group decision-making problems based
on the similarity measures under type 2 intuitionistic fuzzy sets
environment. <em>SOCO</em>, <em>24</em>(10), 7361–7381. (<a
href="https://doi.org/10.1007/s00500-019-04359-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Type 2 intuitionistic fuzzy set (T2IFS) is one of the most important concepts to describe fuzzy information by providing an additional degree of freedom to the decision maker to decide the decision-making process. The fundamental superiority of the T2IFS, over the intuitionistic fuzzy set, has been its ability to capture the degrees of membership of relevant membership values, where the uncertainty is handled more accurately, and hence accommodate more uncertainties. Keeping these features in mind, this paper explores the theory of T2IFS by defining some families of the similarity measures to measure the degree of similarity between the two or more T2IFSs. For this, the characteristic of each object is measured in terms of degrees of primary membership and non-membership, secondary membership and non-membership and the variance margin function between them. Based on that, several formulations of the similarities measures are defined and their properties are investigated . Also, some fundamental relation between the proposed measures is stated. Further, based on the similarity measure, a group decision-making approach is explored to rank the alternatives. An illustrative example is provided to demonstrate the approach, and the comparative analysis with some of the existing measures is performed to explore the results.},
  archive      = {J_SOCO},
  author       = {Garg, Harish and Singh, Sukhveer},
  doi          = {10.1007/s00500-019-04359-8},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7361-7381},
  shortjournal = {Soft Comput.},
  title        = {Algorithm for solving group decision-making problems based on the similarity measures under type 2 intuitionistic fuzzy sets environment},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Using data mining techniques to improve replica management
in cloud environment. <em>SOCO</em>, <em>24</em>(10), 7335–7360. (<a
href="https://doi.org/10.1007/s00500-019-04357-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective data management is a crucial problem in distributed systems such as data grid and cloud. This can be achieved by replicating file in a wise manner, which reduces data access time, increases data availability, reliability and system load balancing. Determining a reasonable number and appropriate location of replicas is essential decision in cloud computing. In this paper, a new dynamic replication strategy called Data Mining-based Data Replication (DMDR) is proposed, which determines the correlation of the data files accessed using the file access history. We focus particularly on how extracted knowledge with maximal frequent correlated pattern mining improves data replication. We can group files with high dependency in the same replica set. Through the DMDR strategy, replicas can be stored in the suitable locations, with reduced access latency according to the centrality factor. In addition, due to the finite storage space of each node, replicas that are useful for future tasks can be wastefully deleted and replaced with less beneficial ones. Results of simulation using CloudSim indicate that DMDR strategy has a relative advantage in effective network usage, average response time, hit ratio in comparison with current methods. It can be concluded from this investigation that data mining technique is effective and helpful in the finding of users’ future access behavior in cloud environment.},
  archive      = {J_SOCO},
  author       = {Mansouri, N. and Javidi, M. M. and Mohammad Hasani Zade, B.},
  doi          = {10.1007/s00500-019-04357-w},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7335-7360},
  shortjournal = {Soft Comput.},
  title        = {Using data mining techniques to improve replica management in cloud environment},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Ranking methodology of induced pythagorean trapezoidal fuzzy
aggregation operators based on einstein operations in group decision
making. <em>SOCO</em>, <em>24</em>(10), 7319–7334. (<a
href="https://doi.org/10.1007/s00500-019-04356-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Pythagorean fuzzy number is a new tool for uncertainty and vagueness. It is a generalization of fuzzy numbers and intuitionistic fuzzy numbers. In this paper, we define some Einstein operations on Pythagorean trapezoidal fuzzy set and develop two averaging aggregation operators, which is an induced Pythagorean trapezoidal fuzzy Einstein ordered weighted averaging operator and an induced Pythagorean trapezoidal fuzzy Einstein hybrid averaging (I-PTFEHA) operator. We presented some new methods to deal with the multi-attribute group decision-making problems under the Pythagorean trapezoidal fuzzy environment. Finally, we used some practical examples to illustrate the validity and feasibility of the proposed methods by comparing with existing method. It shows that the proposed I-PTFEHA operator is much better and reliable than the existing one.},
  archive      = {J_SOCO},
  author       = {Shakeel, Muhammad and Abdullah, Saleem and Aslam, Muhammad and Jamil, Muhammad},
  doi          = {10.1007/s00500-019-04356-x},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7319-7334},
  shortjournal = {Soft Comput.},
  title        = {Ranking methodology of induced pythagorean trapezoidal fuzzy aggregation operators based on einstein operations in group decision making},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptive kaniadakis entropy thresholding segmentation
algorithm based on particle swarm optimization. <em>SOCO</em>,
<em>24</em>(10), 7305–7318. (<a
href="https://doi.org/10.1007/s00500-019-04351-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kaniadakis entropy is a kind of generalized entropy based on the $$ \kappa $$ probability distribution, which has a good ability to deal with the distribution of long tail. The image thresholding algorithm based on Kaniadakis entropy can effectively segment images with long-tailed distribution histograms, such as nondestructive testing image. However, Kaniadakis entropy is a generalized information entropy with parameter. How to choose appropriate parameter $$ \kappa $$ is a problem to be solved. In this paper, we proposed an adaptive parameter selection Kaniadakis entropy thresholding algorithm. Based on a clustering effectiveness evaluation index, we transform the parameter selection problem into an optimization problem, then use particle swarm optimization search algorithm to optimize it and finally obtain the segmentation threshold under the optimal parameter. The presented algorithm can adaptively select parameters according to different images and obtain the optimal segmentation images. In order to show the effectiveness of the proposed method, the segmentation results are compared with several existing entropy-based thresholding algorithms. Experimental results both qualitatively and quantitatively demonstrate that the proposed method is effective.},
  archive      = {J_SOCO},
  author       = {Lei, Bo and Fan, Jiu-lun},
  doi          = {10.1007/s00500-019-04351-2},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7305-7318},
  shortjournal = {Soft Comput.},
  title        = {Adaptive kaniadakis entropy thresholding segmentation algorithm based on particle swarm optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modeling autoregressive fuzzy time series data based on
semi-parametric methods. <em>SOCO</em>, <em>24</em>(10), 7295–7304. (<a
href="https://doi.org/10.1007/s00500-019-04349-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In time series analysis, such as other statistical problems, we may confront imprecise quantity. One case is a situation in which the observations related to underlying systems are imprecise. This paper proposes a semi-parametric autoregressive model for those real-world applications whose observed data are reported by fuzzy numbers. To this end, a hybrid method including nonparametric kernel-based approach and the least absolute deviations is suggested which allows us to estimate the parameters of the model and the fuzzy nonlinear function of the innovations, simultaneously. In order to examine the performance and effectiveness of the proposed fuzzy semi-parametric time series model, some common goodness-of-fit criteria are employed. The obtained results based on a practical example of simulated fuzzy time series data indicated that the proposed method is potentially effective for predicting fuzzy time series data.},
  archive      = {J_SOCO},
  author       = {Zarei, R. and Akbari, M. Gh. and Chachi, J.},
  doi          = {10.1007/s00500-019-04349-w},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7295-7304},
  shortjournal = {Soft Comput.},
  title        = {Modeling autoregressive fuzzy time series data based on semi-parametric methods},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A machine learning evolutionary algorithm-based formula to
assess tumor markers and predict lung cancer in cytologically negative
pleural effusions. <em>SOCO</em>, <em>24</em>(10), 7281–7293. (<a
href="https://doi.org/10.1007/s00500-019-04344-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Malignant pleural effusion is diagnostically challenging in presence of negative cytology. The assessment of tumor markers in serum has become a standard tool in cancer diagnosis, while pleural fluid sampling has not met universal consensus. The evaluation of a panel of markers both in serum and pleural fluid may be crucial to improve the diagnostic accuracy. Using a machine learning-based approach, we provide a mathematical formula capable to express the complex relation existing among the expressed markers in serum and pleural effusion and the presence of lung cancer. The formula indicates CEA and CYFRA21-1 in pleural fluid as the best diagnostic markers, with 97\% accuracy, 98\% sensitivity, 95\% specificity, 96\% area under curve, 98\% positive predictive value, and 92\% MCC (Matthews correlation coefficient).},
  archive      = {J_SOCO},
  author       = {Elia, Stefano and D’Angelo, Gianni and Palmieri, Francesco and Sorge, Roberto and Massoud, Renato and Cortese, Claudio and Hardavella, Georgia and De Stefano, Alessandro},
  doi          = {10.1007/s00500-019-04344-1},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7281-7293},
  shortjournal = {Soft Comput.},
  title        = {A machine learning evolutionary algorithm-based formula to assess tumor markers and predict lung cancer in cytologically negative pleural effusions},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modeling and state of health estimation of nickel–metal
hydride battery using an EPSO-based fuzzy c-regression model.
<em>SOCO</em>, <em>24</em>(10), 7265–7279. (<a
href="https://doi.org/10.1007/s00500-019-04343-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prognostic and health management of the batteries continued to attract interest from automobile manufacturers as the key for lowering life-cycle costs, reducing unexpected power outages, and one of the most important and efficient ways for energy storage for electric vehicle applications. Indeed, an effective battery health monitoring depends on accurate estimation of state of health (SOH). However, the SOH cannot be directly measured by sensors in the battery management system. Moreover, the SOH estimation based on a standard resistor–capacitor (RC) battery model is not so accurate because a RC model is obtained with some approximations and without taking into account more detailed knowledge about the chemical reactions happening inside the battery. In this paper, a combined battery modeling and SOH estimation method over the lifespan of a nickel–metal hydride (Ni–MH) battery is proposed. First, a fuzzy c-regression model based on Euclidean particle swarm optimization is applied to modeling a Ni–MH battery. Second, the SOH monitoring is determined according to the discharge rate of the battery model. The performance of the proposed method has been analyzed through the modeling and the estimation of the SOH using a real data set of the Ni–MH battery.},
  archive      = {J_SOCO},
  author       = {Telmoudi, Achraf Jabeur and Soltani, Moez and Ben Belgacem, Yassin and Chaari, Abdelkader},
  doi          = {10.1007/s00500-019-04343-2},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7265-7279},
  shortjournal = {Soft Comput.},
  title        = {Modeling and state of health estimation of nickel–metal hydride battery using an EPSO-based fuzzy c-regression model},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The extraction algorithm of color disease spot image based
on otsu and watershed. <em>SOCO</em>, <em>24</em>(10), 7253–7263. (<a
href="https://doi.org/10.1007/s00500-019-04339-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an extraction algorithm of color disease spot image based on Otsu and watershed is proposed to overcome the problem of excessive segmentation in the traditional watershed algorithm. The proposed algorithm converts the color space of the color spot image to calculate the component gradient that is not interfered by the reflected light in the new color space. Then, final gradient image is obtained from the gradient image reconstructed by open and close operation under the different-sized structural elements. The label from the final gradient image is extracted by Otsu algorithm, and then, the H-minima transform is used to modify the labeled image. The modified gradient image is transformed with a label by the watershed algorithm. Finally, the extraction of the disease spot is implemented. The experimental results show that the proposed approach obtains accurate and continuous target contour and reaches the requirement of human visual characteristics. Compared with other similar algorithms, the proposed algorithm can effectively suppress the impact of reflected light, optimize the extraction results of disease spot, better maintain the information of disease spot image, and improve the robustness and the applicability.},
  archive      = {J_SOCO},
  author       = {Xiong, Lu and Zhang, Dongbo and Li, Kangshun and Zhang, Lixia},
  doi          = {10.1007/s00500-019-04339-y},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7253-7263},
  shortjournal = {Soft Comput.},
  title        = {The extraction algorithm of color disease spot image based on otsu and watershed},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Using an evolutionary approach based on shortest common
supersequence problem for loop fusion. <em>SOCO</em>, <em>24</em>(10),
7231–7252. (<a
href="https://doi.org/10.1007/s00500-019-04338-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the literature, loop fusion is an effective optimization technique which tries to enhance parallelizing compilers’ performance via memory hierarchy management, and all its competing criteria create an NP-hard problem. This paper proposes an evolutionary algorithm that aims to achieve a profitable loop order which maximizes fusion taking into account register size, parallelism and data reuse advancement. Besides, this method preserves prerequisite relations between the loops by encoding each distinct loop sequence as the shortest common supersequence (SCS) of the related dependence graph. Regarding the related optimization methods that only focus on fusion, this set of metrics, an evolutionary algorithm and also the shortest common supersequence problem have not been considered before in this area. Despite all the envisaged complexities, experimental results confirm the accuracy and advantage of the proposed approach. But due to evolutionary methods effect on raising the compilation time, the proposed algorithm is only applicable when this issue is not prominent, in comparison with the quality of the outcome.},
  archive      = {J_SOCO},
  author       = {Ziraksima, Mahsa and Lotfi, Shahriar and Izadkhah, Habib},
  doi          = {10.1007/s00500-019-04338-z},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7231-7252},
  shortjournal = {Soft Comput.},
  title        = {Using an evolutionary approach based on shortest common supersequence problem for loop fusion},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A co-evolutionary hybrid decomposition-based algorithm for
bi-level combinatorial optimization problems. <em>SOCO</em>,
<em>24</em>(10), 7211–7229. (<a
href="https://doi.org/10.1007/s00500-019-04337-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bi-level programming problems are a special class of optimization problems with two levels of optimization tasks. These problems have been widely studied in the literature and often appear in many practical problem solving tasks. Although many applications fit the bi-level framework, however, real-life implementations are scarce, due mainly to the lack of efficient algorithms able to handle effectively this NP-hard problem. Several solution approaches have been proposed to solve these problems; however, most of them are restricted to the continuous case. Motivated by this observation, we have recently proposed a Co-evolutionary Decomposition-based Algorithm (CODBA) to solve bi-level combinatorial problems. CODBA scheme has been able to bring down the computational expense significantly as compared to other competitive approaches within this research area. In this paper, we further improve CODBA approach by incorporating a local search procedure to make the search process more efficient. The proposed extension called CODBA-LS includes a variable neighborhood search to the lower-level task to help in faster convergence of the algorithm. Further experimental tests based on the bi-level production–distribution problems in supply chain management model on a set of artificial and real-life data turned out to be effective on both computation time and solution quality.},
  archive      = {J_SOCO},
  author       = {Chaabani, Abir and Bechikh, Slim and Ben Said, Lamjed},
  doi          = {10.1007/s00500-019-04337-0},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7211-7229},
  shortjournal = {Soft Comput.},
  title        = {A co-evolutionary hybrid decomposition-based algorithm for bi-level combinatorial optimization problems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). GORTS: Genetic algorithm based on one-by-one revision of two
sides for dynamic travelling salesman problems. <em>SOCO</em>,
<em>24</em>(10), 7197–7210. (<a
href="https://doi.org/10.1007/s00500-019-04335-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dynamic travelling salesman problem (DTSP) is a natural extension of the standard travelling salesman problem, and it has attracted significant interest in recent years due to is practical applications. In this article, we propose an efficient solution for DTSP, based on a genetic algorithm (GA), and on the one-by-one revision of two sides (GORTS). More specifically, GORTS combines the global search ability of GA with the fast convergence feature of the method of one-by-one revision of two sides, in order to find the optimal solution in a short time. An experimental platform was designed to evaluate the performance of GORTS with TSPLIB. The experimental results show that the efficiency of GORTS compares favourably against other popular heuristic algorithms for DTSP. In particular, a prototype logistics system based on GORTS for a supermarket with an online map was designed and implemented. It was shown that this can provide optimised goods distribution routes for delivery staff, while considering real-time traffic information.},
  archive      = {J_SOCO},
  author       = {Xu, Xiaolong and Yuan, Hao and Matthew, Peter and Ray, Jeffrey and Bagdasar, Ovidiu and Trovati, Marcello},
  doi          = {10.1007/s00500-019-04335-2},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7197-7210},
  shortjournal = {Soft Comput.},
  title        = {GORTS: Genetic algorithm based on one-by-one revision of two sides for dynamic travelling salesman problems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An approach based on knowledge exploration for state space
management in checking reachability of complex software systems.
<em>SOCO</em>, <em>24</em>(10), 7181–7196. (<a
href="https://doi.org/10.1007/s00500-019-04334-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model checking is one of the most efficient techniques in software system verification. However, state space explosion is a big challenge while using this technique to check different properties like safety ones. In this situation, one can search the state space to find a reachable state in which the safety property is violated. Hence, reachability checking can be done instead of checking safety property. However, checking reachability in the worst case may cause state space explosion again. To handle this problem, our idea is based on generating a small model consistent with the main model. Then by exploring the state space entirely, we search it to find the goal states. After finding the goal states, we label the paths which start from the initial state and leading to a goal state. Then using the ensemble classification technique, the necessary knowledge is extracted from these paths to intelligently explore the state space of the bigger model. Ensemble machine learning technique uses Boosting method along with decision trees. It follows sampling techniques by replacement. This method generates k predictive models after sampling k times. Finally, it uses a voting mechanism to predict the labels of the final path. Our proposed approach is implemented in GROOVE, which is an open source toolset for designing and model checking graph transformation systems. Our experiments show a significant improvement in terms of both speed and memory usage. In average, our approach consumes nearly 42\% fewer memory than other approaches. Also, it generates witnesses nearly 20\% shorter than others, in average.},
  archive      = {J_SOCO},
  author       = {Partabian, Jaafar and Rafe, Vahid and Parvin, Hamid and Nejatian, Samad},
  doi          = {10.1007/s00500-019-04334-3},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7181-7196},
  shortjournal = {Soft Comput.},
  title        = {An approach based on knowledge exploration for state space management in checking reachability of complex software systems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A clustering algorithm based on emotional preference and
migratory behavior. <em>SOCO</em>, <em>24</em>(10), 7163–7179. (<a
href="https://doi.org/10.1007/s00500-019-04333-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a clustering algorithm based on emotional preference and migratory behavior (EPMC) is proposed for data clustering. The algorithm consists of four models: the migration model, the emotional preference model, the social group model and the inertial learning model. First, the migration model calculates the probability of individuals being learned, so that individuals can learn from the superior. Second, the emotional preference model is introduced to help individuals find the most suitable neighbor for learning. Third, the social group model divides the whole population into different groups and enhances the mutual cooperation between individuals under different conditions. Finally, the inertial learning model balances the exploration and exploitation during the optimization, so that the algorithm can avoid falling into the local optimal solution. In addition, the convergence of EPMC algorithm is verified by theoretical analysis, and the algorithm is compared with four clustering algorithms. Experimental results validate the effectiveness of EPMC algorithm.},
  archive      = {J_SOCO},
  author       = {Feng, Xiang and Zhong, Dajian and Yu, Huiqun},
  doi          = {10.1007/s00500-019-04333-4},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7163-7179},
  shortjournal = {Soft Comput.},
  title        = {A clustering algorithm based on emotional preference and migratory behavior},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hybrid context aware recommendation system for e-health care
by merkle hash tree from cloud using evolutionary algorithm.
<em>SOCO</em>, <em>24</em>(10), 7149–7161. (<a
href="https://doi.org/10.1007/s00500-019-04322-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Privacy preservation permits doctors to outsource the huge encrypted reports to the cloud and permits the authenticated patients to have a safe search over the reports without leaking the private information. The doctors in our proposed have used the merkle hash tree for storing the reports of all the patients in the hospital. The existing schemes have used many types of trees like binary tree, red–black tree, spanning tree, B+ tree, etc., for the index generation purpose. Since the security is less and the searching time is high for the above said trees, we have proposed the index generation phase based on the merkle hash tree based on the evolutionary algorithm and it takes less time for searching and highly secure for storing the patient reports. The evolutionary algorithm is used for breeding the new data’s through crossover as well as mutation operations to give confinement to new children. When the patient submits the search request for specialized doctor, based on the patient disease our protocol will recommend the specialized doctors and send the recommended doctors information to the patients who have the highest rating in the online social networks. After receiving the recommended results, the patient can have the treatment via online booking appointment, video call or in person based on the appointment booked. After completely cured, the patients can rate the doctors based on the medicine satisfaction, doctors’ fees and doctor’s response over the call. In this mechanism, we have used the hybrid context aware recommendation system collaborative filtering for rating the doctors based on their performance. After rating the doctors, our protocol has measured the accuracy based on the predicted rating and the true rating. This kind of accuracy metrics is used for ranking the good doctors in the top rank for the patient use. Our proposed work Hybrid Context Aware Recommendation System for E-Health Care (HCARS-EHC) is implemented, and the implementation results of HCARS-EHC illustrate that our protocol is efficient based on the privacy preservation, recommendation and ranking with less computation and communication complexity.},
  archive      = {J_SOCO},
  author       = {Deepa, N. and Pandiaraja, P.},
  doi          = {10.1007/s00500-019-04322-7},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7149-7161},
  shortjournal = {Soft Comput.},
  title        = {Hybrid context aware recommendation system for E-health care by merkle hash tree from cloud using evolutionary algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-facility-based improved closed-loop supply chain
network for handling uncertain demands. <em>SOCO</em>, <em>24</em>(10),
7125–7147. (<a
href="https://doi.org/10.1007/s00500-020-04868-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Globalization has enlightened market with both opportunity and risk by bringing a more connected business environment, which ensures more customers and new markets. In contrast, it also brought a larger extent of competitors. The more collaborative environment can help companies to focus on their core competence to simultaneously reduce cost and participate more profitably in their trade. Uncertainty is a major outcome of the globalization process; firms are developing new methods and strategies to deal with risk and take control of uncertainty factors. This work introduces a novel approach that could help in collecting the end-of-life and end-of-use products from the end-users. These collected products enter the value chain and help in reducing the overall cost of the supply chain. A mixed-integer linear programming model has been formulated to assess the overall cost of the supply chain for the presented study. Due to the NP-hardness of the problem, few well-known metaheuristics and hybrid approaches are proposed as solution techniques for the first time. The Taguchi method is used to obtain the best combinations of algorithm parameters. In addition, problem instances are generated to validate the proposed model for a real-world case. Finally, the effectiveness of the algorithms is compared by using different criteria.},
  archive      = {J_SOCO},
  author       = {Chouhan, Vivek Kumar and Khan, Shahul Hamid and Hajiaghaei-Keshteli, Mostafa and Subramanian, Saminathan},
  doi          = {10.1007/s00500-020-04868-x},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7125-7147},
  shortjournal = {Soft Comput.},
  title        = {Multi-facility-based improved closed-loop supply chain network for handling uncertain demands},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stability for feedback loops containing complex algorithms.
<em>SOCO</em>, <em>24</em>(10), 7113–7124. (<a
href="https://doi.org/10.1007/s00500-020-04851-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of neural networks, fuzzy logic, genetic algorithms, and other soft computing methodologies, many researchers have demonstrated successful designs for intelligent control strategies that appear to outperform traditional linear feedback controls; however, industry has mostly ignored the new technology due to the lack of stability guarantees (required in most formal engineering risk-management processes). In this paper, we offer a Lyapunov-stability framework where one can place any arbitrary computational algorithm and still get guarantees of uniformly ultimately bounded (UUB) signals. We would expect an intelligent algorithm to be well-designed such that the proposed framework would not come into play unless unanticipated disturbances affect the system. But even if the intelligent algorithm was poorly designed, the resulting performance (inside our framework) would just look similar to that of a typical nonlinear neural-adaptive control. In our strategy, the intelligent algorithm trains a cerebellar model articulation controller (CMAC) neural network with arbitrarily bounded weights in order to achieve good performance, while a second CMAC trains in parallel using direct-adaptive-control laws in order to provide stability (even in the case of the first CMAC weights reaching their imposed bound). We test the strategy using a previously proposed ad hoc CMAC weight smoothing strategy, serving as the intelligent algorithm, with simulations and experiment controlling a two-link flexible-joint robot.},
  archive      = {J_SOCO},
  author       = {Razmi, M. and Macnab, C. J. B.},
  doi          = {10.1007/s00500-020-04851-6},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7113-7124},
  shortjournal = {Soft Comput.},
  title        = {Stability for feedback loops containing complex algorithms},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A computational formulation of distribution reducts in
probabilistic rough set models. <em>SOCO</em>, <em>24</em>(10),
7093–7111. (<a
href="https://doi.org/10.1007/s00500-020-04849-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conceptual and computational formulations are the two sides of the theory of rough sets. Conceptual formulation focuses on the meaning and interpretation of the concepts. Computational formulation focuses on procedures and algorithms for constructing these notions. In probabilistic rough set models, a distribution reduct is defined as a minimal subset of attributes that preserves the probabilistic lower or upper approximations of all decision classes. The definition is a conceptual formulation that provides an essential understanding of distribution reducts, but it does not directly give a computationally efficient method. In this paper, we study the computational formulation of distribution reducts in probabilistic rough set models by constructing monotonic measures, resulting in a more efficient computational method. We first construct two monotonic measures called the probabilistic low and upper approximation distribution measures, respectively, from which the computational formulation of distribution reducts can be obtained. We then propose the granularity-based probabilistic low and upper approximation distribution measures to evaluate the significance of attributes more effectively. On this basis, we develop two algorithms for finding distribution reducts based on addition–deletion method and deletion method, respectively. Finally, the experimental results show the effectiveness of the proposed measures.},
  archive      = {J_SOCO},
  author       = {Ma, Xi-Ao},
  doi          = {10.1007/s00500-020-04849-0},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7093-7111},
  shortjournal = {Soft Comput.},
  title        = {A computational formulation of distribution reducts in probabilistic rough set models},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Solution of heterogeneous multi-attribute case-based
decision making problems by using method based on TODIM. <em>SOCO</em>,
<em>24</em>(10), 7081–7091. (<a
href="https://doi.org/10.1007/s00500-020-04844-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous multi-attribute case-based decision making (HMCBDM) is a type of complex and important problem encountered in many decision applications, and such problems involve real numbers, interval numbers, triangular fuzzy numbers, linguistic variables, and intuitionistic fuzzy numbers. However, heterogeneous multi-attributes are not fully considered in case-based decision making. Moreover, in the decision making process, the psychological behavior of the decision maker must be considered. To this end, this paper proposes a novel method for HMCBDM problems based on the TODIM (an acronym in Portuguese for interactive and multi-criteria decision making) method. First, the problem similarity and solution similarity are formulated. Next, a similar case set is constructed according to the problem and solution similarities. Further, the utility of the result of the historical solution is calculated. In addition, a ranking method based on TODIM is proposed, in which the problem similarity, solution similarity, and utility of the result of the historical solution are considered, and subsequently, the suitable solution(s) is obtained. Finally, a case study considering a gas explosion and pertaining to decision making in emergency situations is described to illustrate the use of the proposed method.},
  archive      = {J_SOCO},
  author       = {Zheng, Jing and Wang, Ying-ming and Zhang, Kai},
  doi          = {10.1007/s00500-020-04844-5},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7081-7091},
  shortjournal = {Soft Comput.},
  title        = {Solution of heterogeneous multi-attribute case-based decision making problems by using method based on TODIM},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Combined fitness–violation epsilon constraint handling for
differential evolution. <em>SOCO</em>, <em>24</em>(10), 7063–7079. (<a
href="https://doi.org/10.1007/s00500-020-04835-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over recent decades, several efficient constraint-handling methods have been proposed in the area of evolutionary computation, and the $$\varepsilon $$ constraint method is considered as a state-of-the-art method for both single and multiobjective optimization. Still, very few attempts have been made to improve this method when applied to the differential evolution algorithm. This study proposes several novel constraint-handling methods following similar ideas, where the $$\varepsilon $$ level is defined based on the current violation in the population, individual $$\varepsilon $$ levels are maintained for every constraint, and a combination of fitness and constraint violation is used for determining infeasible solutions. The proposed approaches demonstrate superior performance compared to other approaches in terms of the feasibility rate in high-dimensional search spaces, as well as convergence to global optima. The experiments are performed using the CEC’2017 constrained suite benchmark functions and a set of Economic Load Dispatch problems.},
  archive      = {J_SOCO},
  author       = {Stanovov, Vladimir and Akhmedova, Shakhnaz and Semenkin, Eugene},
  doi          = {10.1007/s00500-020-04835-6},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7063-7079},
  shortjournal = {Soft Comput.},
  title        = {Combined fitness–violation epsilon constraint handling for differential evolution},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A sub-concept-based feature selection method for one-class
classification. <em>SOCO</em>, <em>24</em>(10), 7047–7062. (<a
href="https://doi.org/10.1007/s00500-020-04828-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Similarly to binary classification methods, one-class classification methods could benefit from feature selection. However, the feature selection algorithms for the binary or multi-class are not applicable to one-class classification situations since only one class of instances is provided. Few techniques have been proposed so far for feature selection in one-class classification. This paper focuses on designing a filter-based feature selection method for one-class classification. Our approach is based on the observation that for some tasks such as outlier detection, anomaly detection, the training data (normal data) may contain multiple sub-concepts. The sub-concept is a source of data complexity. Our approach aims at searching the features that characterize the instances of the sub-concepts more compact, so as to reduce the data complexity. It firstly finds the sub-concepts using a clustering algorithm with a fixed cluster number and then applies combined feature measures to evaluate the relevance between each feature and the sub-concepts. A fixed number of features—those with the highest relevance scores—are selected as a feature subset. In the searching process, the Davies–Bouldin Index is used to assess the data complexity on the sub-concepts obtained with different number of clusters. The feature subset with the lowest DBI is selected as the final feature subset. Experiments on UCI benchmark and cyber security datasets demonstrate that our feature selection algorithm can select relevant features and improve the performance of one-class classification on multimodal data.},
  archive      = {J_SOCO},
  author       = {Liu, Zhen and Japkowicz, Nathalie and Wang, Ruoyu and Liu, Li},
  doi          = {10.1007/s00500-020-04828-5},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7047-7062},
  shortjournal = {Soft Comput.},
  title        = {A sub-concept-based feature selection method for one-class classification},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On <span class="math display"><em>ε</em></span>-soft
topological semigroups. <em>SOCO</em>, <em>24</em>(10), 7035–7046. (<a
href="https://doi.org/10.1007/s00500-020-04826-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce e-right, e-left, e-semi and $$\varepsilon $$-soft topological semigroups and examine the way these are related to each other. To do so, we need to define $$\bigtriangleup $$-soft and point open soft topologies, which are defined in the third and fourth sections, respectively. Also, soft separation axioms on these soft topologies will be studied.},
  archive      = {J_SOCO},
  author       = {Bahredar, A. A. and Kouhestani, N.},
  doi          = {10.1007/s00500-020-04826-7},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7035-7046},
  shortjournal = {Soft Comput.},
  title        = {On $$\varepsilon $$-soft topological semigroups},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multiplicative derivations and d-filters of commutative
residuated lattices. <em>SOCO</em>, <em>24</em>(10), 7029–7033. (<a
href="https://doi.org/10.1007/s00500-020-04825-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider some properties of multiplicative derivations and d-filters of commutative residuated lattices and show that, for an ideal derivation d of a residuated lattice $$L=(L,\wedge , \vee , \odot , \rightarrow , 0,1)$$, (1) the set $$\hbox {Fix}_d(L)= (\hbox {Fix}_d(L), \wedge , \vee , \odot , \mapsto , 0, d1)$$ of all fixed points of d forms a residuated lattice and d is a homomorphism from L to $$\hbox {Fix}_d(L)$$, (2) for a d-filter F, a map $$d/F: L/F \rightarrow L/F$$ defined by $$(d/F)(x/F) = dx/F$$ is also an ideal derivation of L/F and (3) two quotient residuated lattices $$\hbox {Fix}_{d/F}(L/F)$$ and $$\hbox {Fix}_d (L)/d(F)$$ are isomorphic as residuated lattices, that is, $$\hbox {Fix}_{d/F}(L/F) \cong \hbox {Fix}_d (L)/d(F)$$.},
  archive      = {J_SOCO},
  author       = {Kondo, Michiro},
  doi          = {10.1007/s00500-020-04825-8},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7029-7033},
  shortjournal = {Soft Comput.},
  title        = {Multiplicative derivations and d-filters of commutative residuated lattices},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Probabilistic norms on the homeomorphisms of a group.
<em>SOCO</em>, <em>24</em>(10), 7021–7028. (<a
href="https://doi.org/10.1007/s00500-020-04818-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a probabilistic metric on the set of all auto-homeomorphisms of a group is presented. We show that the defined probabilistic group metric is right invariant and it implies a probabilistic group norm. In addition, by the probabilistic norm admissibility condition, we study the uniform continuity of homeomorphisms, and finally, we prove some theorems about topologically equivalent probabilistic norms.},
  archive      = {J_SOCO},
  author       = {Pourmoslemi, Alireza and Ferrara, Massimiliano and Pansera, Bruno Antonio and Salimi, Mehdi},
  doi          = {10.1007/s00500-020-04818-7},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7021-7028},
  shortjournal = {Soft Comput.},
  title        = {Probabilistic norms on the homeomorphisms of a group},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On pseudo-eBE-algebras. <em>SOCO</em>, <em>24</em>(10),
7005–7020. (<a
href="https://doi.org/10.1007/s00500-020-04810-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we define the notion of a pseudo-eBE-algebra as an extension of a pseudo-BE-algebra, and it is studied in detail. The construction of an eBE-algebra from a pseudo-eBE-algebra is given. Further, the notions of filters and ideals are considered. The classes of distributive and commutative pseudo-eBE-algebras are introduced and investigated. We prove that for a distributive pseudo-eBE-algebra filters coincide with ideals. Also, some types of filters are defined and the relationship between these is investigated.},
  archive      = {J_SOCO},
  author       = {Sayyad, Shokofeh and Babaei, Hojat and Rezaei, Akbar},
  doi          = {10.1007/s00500-020-04810-1},
  journal      = {Soft Computing},
  number       = {10},
  pages        = {7005-7020},
  shortjournal = {Soft Comput.},
  title        = {On pseudo-eBE-algebras},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Reliability analysis of general systems with bi-uncertain
variables. <em>SOCO</em>, <em>24</em>(9), 6975–6986. (<a
href="https://doi.org/10.1007/s00500-019-04331-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the lifetimes of system components are assumed to have independent and nonidentical uncertainty distributions with uncertain parameters. The reliability functions and mean time to failure of the general systems are investigated according to the uncertainty theory. Basic models of the general systems with bi-uncertain variables are established and analyzed, including series, parallel and series–parallel systems. The explicit expressions of reliability function and mean time to failure of each model are presented. Some numerical examples are given to illustrate the applications of the developed models and perform a comparison for the models with uncertain and bi-uncertain variables.},
  archive      = {J_SOCO},
  author       = {Liu, Zhaocai and Hu, Linmin and Liu, Sijia and Wang, Yuyu},
  doi          = {10.1007/s00500-019-04331-6},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6975-6986},
  shortjournal = {Soft Comput.},
  title        = {Reliability analysis of general systems with bi-uncertain variables},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Infinite lattice learner: An ensemble for incremental
learning. <em>SOCO</em>, <em>24</em>(9), 6957–6974. (<a
href="https://doi.org/10.1007/s00500-019-04330-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The state of the art in supervised learning has developed effective models for learning, generalizing, recognizing faces and images, time series prediction, and more. However, most of these powerful models cannot effectively learn incrementally. Infinite Lattice Learner (ILL) is an ensemble model that extends state-of-the-art machine learning methods into incremental learning models. With ILL, even batch models can learn incrementally with exceptional data retention ability. Instead of continually revisiting past instances to retain learned information, ILL allows existing methods to converge on new information without overriding previous knowledge. With ILL, models can efficiently chase a drifting function without continually revisiting a changing dataset. Models wrapped in ILL can operate in continuous real-time environments where millions of unique samples are seen every day. Big datasets too large to fit in memory, or even a single machine, can be learned in portions. ILL utilizes an infinite Cartesian grid of points with an underlying model tiled upon it. Efficient algorithms for discovering nearby points and lazy evaluation make this seemingly impossible task possible. Extensive empirical evaluation reveals impressive retention ability for all ILL models. ILL similarly proves its generalization ability on a variety of datasets from classification and regression to image recognition.},
  archive      = {J_SOCO},
  author       = {Lovinger, Justin and Valova, Iren},
  doi          = {10.1007/s00500-019-04330-7},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6957-6974},
  shortjournal = {Soft Comput.},
  title        = {Infinite lattice learner: An ensemble for incremental learning},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A quantum-behaved particle swarm optimization algorithm with
the flexible single-/multi-population strategy and multi-stage
perturbation strategy based on the characteristics of objective
function. <em>SOCO</em>, <em>24</em>(9), 6909–6956. (<a
href="https://doi.org/10.1007/s00500-019-04328-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The characteristics of objective functions have important impacts on the search process of the optimization algorithm. Many multimodal functions tend to make the algorithm fall into local optima, and the local search accuracy is usually affected by the coupling of the objective functions in different dimensions. A novel quantum-behaved particle swarm optimization algorithm with the flexible single-/multi-population strategy and the multi-stage perturbation strategy (QPSO_FM) is proposed in the present paper. This algorithm aims to adjust the optimization strategies based on the characteristics of the objective functions. The number of sub-populations is determined by the monotonicity variations of the objective functions, and two mechanisms are introduced to balance the diversity and the convergent speed for the multi-population case. The strategy of multi-stage perturbation is applied to enhance the search ability. At the first stage, the main target of the perturbation is to broaden the search range. The second stage applies the univariate perturbation (relying on the coupling degree of the objective function) to raise the local search accuracy. Performance comparisons between the proposed and existing algorithms are carried out through the experiments on the standard functions. The results show that the proposed algorithm can generally provide excellent global search ability and high local search accuracy.},
  archive      = {J_SOCO},
  author       = {Guo, Yunhua and Chen, Nian-Zhong and Mou, Junmin and Zhang, Ben},
  doi          = {10.1007/s00500-019-04328-1},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6909-6956},
  shortjournal = {Soft Comput.},
  title        = {A quantum-behaved particle swarm optimization algorithm with the flexible single-/multi-population strategy and multi-stage perturbation strategy based on the characteristics of objective function},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Two-degree-of-freedom ellsberg urn problem. <em>SOCO</em>,
<em>24</em>(9), 6903–6908. (<a
href="https://doi.org/10.1007/s00500-019-04327-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional model assumes there is only randomness existing in the urn problem. However, if the numbers of the colored balls are unknown, then they should be regarded as uncertain variable. Since a ball is drawn randomly, Ellsberg urn problem is essentially a complicated system with randomness and uncertainty. Instead of psychological experiment, this paper applies uncertainty theory and chance theory to provide a rigorous mathematical method for formulating the general case of a one-degree-of-freedom Ellsberg urn problem. Furthermore, a two-degree-of-freedom Ellsberg urn problem is proposed, and the formulation for the problem is given to deal with three unknown numbers of colored balls.},
  archive      = {J_SOCO},
  author       = {Lio, Waichon and Cheng, Guangquan},
  doi          = {10.1007/s00500-019-04327-2},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6903-6908},
  shortjournal = {Soft Comput.},
  title        = {Two-degree-of-freedom ellsberg urn problem},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dealing with small sample size problems in process industry
using virtual sample generation: A kriging-based approach.
<em>SOCO</em>, <em>24</em>(9), 6889–6902. (<a
href="https://doi.org/10.1007/s00500-019-04326-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The operational data of advanced process systems have met with explosive growth, but its fluctuations are so slight that the number of the extracted representative samples is quite limited, making it difficult to reflect the nature of the process and to establish prediction models. In this study, inspired by the process of fisherman repairing nets, a Kriging-based virtual sample generation (VSG) named Kriging-VSG is proposed to generate feasible virtual samples in data sparse regions. Then, the accuracy of prediction models is further enhanced by applying the generated virtual samples. In order to reasonably find data sparse regions, a distance-based criterion is imposed on each dimension to identify important samples with large information gaps. Similar to the process of fisherman repairing nets, a certain dimension is initially fixed at different quantiles. A dimension-wise interpolation process using Kriging is then performed on the center between important samples with large information gaps. To validate the performance of the proposed Kriging-VSG, two numerical simulations and a real-world application from a cascade reaction process for high-density polyethylene are carried out. The results indicate that the proposed Kriging-VSG outperforms other methods.},
  archive      = {J_SOCO},
  author       = {Zhu, Qun-Xiong and Chen, Zhong-Sheng and Zhang, Xiao-Han and Rajabifard, Abbas and Xu, Yuan and Chen, Yi-Qun},
  doi          = {10.1007/s00500-019-04326-3},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6889-6902},
  shortjournal = {Soft Comput.},
  title        = {Dealing with small sample size problems in process industry using virtual sample generation: A kriging-based approach},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new formulation for prediction of the shear capacity of
FRP in strengthened reinforced concrete beams. <em>SOCO</em>,
<em>24</em>(9), 6871–6887. (<a
href="https://doi.org/10.1007/s00500-019-04325-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of fiber-reinforced polymer (FRP) to strength the concrete beams is an efficient method in retrofitting of preexisting structures. The application of FRP sheets makes to have higher shear strength, but the common equations in determining the shear strength are no longer effective. In this paper, a new formulation is presented to predict the shear contribution of FRP in strengthened reinforced concrete beams. The formula is produced using the multigene genetic programming (MGP) machine. For this purpose, a set of experimental data is collected from the literature. The shear capacity of FRP in reinforced concrete (RC) beams is considered as the output data, while other variables are considered as the input data. MGP is trained with the experimental data and a formula is produced. The results of the proposed formula are compared with the experimental data to show the ability of the proposed formula. Also, these results are compared with those obtained from the available formulas, approximation models and published researches. Results show that the proposed formula is able to predict the shear capacity of FRP in strengthened RC beams with a higher precision than the other evaluated methods such as CIDAR, Fib.TG9.3, ACI and CSA. The mean absolute percentage error for the MGP formula was reduced about 74\% in comparison with the CIDAR equations. Also, the root-mean-squared-error of the MGP formula was decreased near 71\% in comparison with the Fib.TG9.3 equations.},
  archive      = {J_SOCO},
  author       = {Kamgar, Reza and Bagherinejad, Mohammad Hadi and Heidarzadeh, Heisam},
  doi          = {10.1007/s00500-019-04325-4},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6871-6887},
  shortjournal = {Soft Comput.},
  title        = {A new formulation for prediction of the shear capacity of FRP in strengthened reinforced concrete beams},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). A dividing-based many-objective evolutionary algorithm for
large-scale feature selection. <em>SOCO</em>, <em>24</em>(9), 6851–6870.
(<a href="https://doi.org/10.1007/s00500-019-04324-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is a critical preprocess for constructing model in computer vision and machine learning, yet it is difficult to simultaneously satisfy both reducing features’ number and maintaining classification accuracy. Toward this problem, we propose dividing-based many-objective evolutionary algorithm for large-scale feature selection (DMEA-FS). Firstly, four novel objectives are established for exploring the optimal feature’s subsets. Meanwhile, we design two structures of wrapper for high accuracy and filter for low computation cost in DMEA-FS. Secondly, two new recombination methods are presented for rapid convergence. Mapping-based variable dividing is presented for precise related variables. Thirdly, based on minimum Manhattan distance, a triangle-approximating decision-making is proposed for assisting users’ determination with/without preference information. Numerical experiments against several state-of-the-art feature selection algorithms demonstrate that the proposed DMEA-FS outperforms its competitors in terms of both classification accuracy and metrics of features’ number.},
  archive      = {J_SOCO},
  author       = {Li, Haoran and He, Fazhi and Liang, Yaqian and Quan, Quan},
  doi          = {10.1007/s00500-019-04324-5},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6851-6870},
  shortjournal = {Soft Comput.},
  title        = {A dividing-based many-objective evolutionary algorithm for large-scale feature selection},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Time series prediction based on intuitionistic fuzzy
cognitive map. <em>SOCO</em>, <em>24</em>(9), 6835–6850. (<a
href="https://doi.org/10.1007/s00500-019-04321-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series exist widely in either nature or society such that the research on analysis of time series has great significance. However, considering the nonlinearity and uncertainty, the prediction of time series is still an open problem. In this paper, by means of the intuitionistic fuzzy set theory, we proposed a novel time series prediction scheme based on intuitionistic fuzzy cognitive map. In the previous research, intuitionistic fuzzy cognitive map, as a kind of knowledge-based modeling tool, is mainly used in decision-making field, where concept structure and weight matrix are usually obtained from experience of experts. To tackle with the diversity of time series, the proposed algorithm constructs the conceptual structure of cognitive map and weight matrix directly from raw sequential data, which effectively enlarges the application range by reducing human participation. Moreover, in order to appropriately calculate the hesitation degree, which is the key role for the application of intuitionistic fuzzy sets, we propose a real-time adjustable hesitation degree calculation scheme. By using this proposed method, hesitation degree can be adaptively adjusted by combining Femi formula with dynamic membership degree. A number of experiments are implemented to reveal feasibility and effectiveness of the proposed schemes.},
  archive      = {J_SOCO},
  author       = {Luo, Chao and Zhang, Nannan and Wang, Xingyuan},
  doi          = {10.1007/s00500-019-04321-8},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6835-6850},
  shortjournal = {Soft Comput.},
  title        = {Time series prediction based on intuitionistic fuzzy cognitive map},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimum design of shallow foundation using evolutionary
algorithms. <em>SOCO</em>, <em>24</em>(9), 6809–6833. (<a
href="https://doi.org/10.1007/s00500-019-04316-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the current study, the performance of three evolutionary algorithms, differential algorithm (DE), evolution strategy (ES), and biogeography-based optimization algorithm (BBO), is examined for foundation design optimization. Moreover, four recent variations of evolutionary-based algorithms [i.e., improved differential evolution algorithm based on an adaptive mutation scheme, weighted differential evolution algorithm (WDE), linear population size reduction success-history-based adaptive differential evolution algorithm, and biogeography-based optimization with covariance matrix-based migration] have been tackled for handling the current problem. The objective function is based on the cost of shallow foundation designs that satisfy ACI 318-05 requirements is formulated as the objective function. This study addresses shallow footing optimization with two attitudes, routine optimization, and sensitivity analysis. As a further study, the effect of the location of the column at the top of the foundation is examined by adding two additional design variables. Three numerical case studies are used for both routine and sensitivity analysis. Moreover, the most common evolutionary-based technique, genetic algorithm (GA), is considered as a benchmark to evaluate the proposed methods’ efficiency. Based on the results, there is no algorithm which works as the most efficient solver over all the cases; while, BBO and WDE showed an acceptable performance because of satisfying records in most cases. There were several cases in which GA, DE, and ES were incapable of finding a valid solution which meets all the constraints simultaneously.},
  archive      = {J_SOCO},
  author       = {Kashani, Ali R. and Gandomi, Mostafa and Camp, Charles V. and Gandomi, Amir H.},
  doi          = {10.1007/s00500-019-04316-5},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6809-6833},
  shortjournal = {Soft Comput.},
  title        = {Optimum design of shallow foundation using evolutionary algorithms},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Reducing overlapped pixels: A multi-objective color
thresholding approach. <em>SOCO</em>, <em>24</em>(9), 6787–6807. (<a
href="https://doi.org/10.1007/s00500-019-04315-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a general multi-objective thresholding segmentation methodology for color images and a quality metric designed to prevent and quantify the overlapping effect of segmented images. Multi-level thresholding (MTH) has been used to segment color images in recent years; this process considers each channel as a single grayscale image and applies the MTH independently. Although this method provides competitive results, the inherent relationship among color channels is disregarded. Such approaches generate spurious classes on overlapping regions, where new colors are generated, especially on the borders of the objects. The proposed multi-objective color thresholding (MOCTH) approach performs image segmentation while preserving the relationship between image channels. MOCTH is aimed to reduce the overlapping effect on segmented color images without performing additional post-processing. To measure the overlapping classes on a thresholded color image, the overlapping index is proposed to quantify the pixels affected. The presented approach is analyzed on two color spaces (RGB and CIE L*a*b*) using three multi-objective algorithms; they are NSGA-III, SPEA-2, and MOPSO. Results provide evidence pointing out to a better segmentation from MOCTH over the traditional single-objective approaches while reducing overlapped areas on the image.},
  archive      = {J_SOCO},
  author       = {Hinojosa, Salvador and Oliva, Diego and Cuevas, Erik and Pajares, Gonzalo and Zaldivar, Daniel and Pérez-Cisneros, Marco},
  doi          = {10.1007/s00500-019-04315-6},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6787-6807},
  shortjournal = {Soft Comput.},
  title        = {Reducing overlapped pixels: A multi-objective color thresholding approach},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Performance of genetic algorithms with different selection
operators for solving short-term optimized reservoir scheduling problem.
<em>SOCO</em>, <em>24</em>(9), 6771–6785. (<a
href="https://doi.org/10.1007/s00500-019-04313-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The tournament operator genetic algorithm (TGA) often shows poor convergence and easily gets trapped in a local optimum when solving optimized reservoir scheduling problems. The selection operation is the most important operation determining an algorithm’s convergence; therefore, this study proposes a proportional reproduction selection-based operator genetic algorithm (RGA) and a steady-state reproduction selection-based operator genetic algorithm (SGA) as alternatives to TGA. This study used TGA, RGA, and SGA to solve the maximum power generation model for the Gezhouba hydropower station, the largest runoff hydropower station in the world. Then, by using the maximum hydropower station output under a given typical runoff scenario as the optimization criterion, this study evaluated the optimized solution performance of the GA using different selection operators. The results show that TGA, SGA, and RGA can be applied to solve the short-term reservoir scheduling model. As the number of iterations increases, the hydropower station output optimized by these three GAs increases. Based on the maximum power generated by the Gezhouba hydropower station, SGA and RGA provide better results than TGA, and between SGA and RGA, the former provides better results.},
  archive      = {J_SOCO},
  author       = {Shang, Ling and Shang, Yizi and Hu, Lianxing and Li, Jianlin},
  doi          = {10.1007/s00500-019-04313-8},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6771-6785},
  shortjournal = {Soft Comput.},
  title        = {Performance of genetic algorithms with different selection operators for solving short-term optimized reservoir scheduling problem},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The new optimization algorithm for the vehicle routing
problem with time windows using multi-objective discrete learnable
evolution model. <em>SOCO</em>, <em>24</em>(9), 6741–6769. (<a
href="https://doi.org/10.1007/s00500-019-04312-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new multi-objective discreet learnable evolution model (MODLEM) to address the vehicle routing problem with time windows (VRPTW). Learnable evolution model (LEM) includes a machine learning algorithm, like the decision trees, that can discover the correct directions of the evolution leading to significant improvements in the fitness of the individuals. We incorporate a robust strength Pareto evolutionary algorithm in the LEM presented here to govern the multi-objective property of this approach. A new priority-based encoding scheme for chromosome representation in the LEM as well as corresponding routing scheme is introduced. To improve the quality and the diversity of the initial population, we propose a novel heuristic manner which leads to a good approximation of the Pareto fronts within a reasonable computational time. Moreover, a new heuristic operator is employed in the instantiating process to confront incomplete chromosome formation. Our proposed MODLEM is tested on the problem instances of Solomon’s VRPTW benchmark. The performance of this proposed MODLEM for the VRPTW is assessed against the state-of-the-art approaches in terms of both the quality of solutions and the computational time. Experimental results and comparisons indicate the effectiveness and efficiency of our proposed intelligent routing approach.},
  archive      = {J_SOCO},
  author       = {Moradi, Behzad},
  doi          = {10.1007/s00500-019-04312-9},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6741-6769},
  shortjournal = {Soft Comput.},
  title        = {The new optimization algorithm for the vehicle routing problem with time windows using multi-objective discrete learnable evolution model},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Real-time hook selection: A soft computing enabled future
location protection mechanism in WSN using LTR measures and random
seeding approach. <em>SOCO</em>, <em>24</em>(9), 6735–6740. (<a
href="https://doi.org/10.1007/s00500-019-04309-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of location protection has been well studied in recent research articles, and a number of approaches are prescribed for the development of Quality of Service in Wireless Sensor Network (WSN). However, the previous approaches failed to achieve higher performance toward location protection which led to deficiency in the quality of service of WSN. To overcome the deficiency in location protection, an efficient real-time hook selection algorithm based on Latency Throughput Retransmission measure has been presented. First, this method monitors the quality of service parameters like latency, throughput and retransmission. Based on the information collected, the method identifies the list of routes being used to perform data transmission. For each route, the method estimates the latency support, throughput support and retransmission frequency support. Based on the measures estimated, the method computes a transmission support measure to perform route selection. Similarly, the method performs hook selection based on the location of suspected adversary. The newly selected hook will be just around the eccentric of old one. The proposed algorithm improves the performance of location protection as well as the entire network.},
  archive      = {J_SOCO},
  author       = {Prasanna, D. and Santhosh, R.},
  doi          = {10.1007/s00500-019-04309-4},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6735-6740},
  shortjournal = {Soft Comput.},
  title        = {Real-time hook selection: A soft computing enabled future location protection mechanism in WSN using LTR measures and random seeding approach},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A robust system for road sign detection and classification
using LeNet architecture based on convolutional neural network.
<em>SOCO</em>, <em>24</em>(9), 6721–6733. (<a
href="https://doi.org/10.1007/s00500-019-04307-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we are reporting a system for detection and classification of road signs. This system consists of two parts. The first part detects the road signs in real time. The second part classifies the German traffic signs (GTSRB) dataset and makes the prediction using the road signs detected in the first part to test the effectiveness. We used HOG and SVM in the detection part to detect the road signs captured by the camera. Then we used a convolutional neural network based on the LeNet model in which some modifications were added in the classification part. Our system obtains an accuracy rate of 96.85\% in the detection part and 96.23\% in the classification part.},
  archive      = {J_SOCO},
  author       = {Bouti, Amal and Mahraz, Med Adnane and Riffi, Jamal and Tairi, Hamid},
  doi          = {10.1007/s00500-019-04307-6},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6721-6733},
  shortjournal = {Soft Comput.},
  title        = {A robust system for road sign detection and classification using LeNet architecture based on convolutional neural network},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Human–robot collisions detection for safe human–robot
interaction using one multi-input–output neural network. <em>SOCO</em>,
<em>24</em>(9), 6687–6719. (<a
href="https://doi.org/10.1007/s00500-019-04306-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a multilayer feedforward neural network-based approach is proposed for human–robot collision detection taking safety standards into consideration. One multi-output neural network is designed and trained using data from the coupled dynamics of the manipulator with and without external contacts to detect unwanted collisions and to identify the collided link using only the intrinsic joint position and torque sensors of the manipulator. The proposed method is applied to the collaborative robots, which will be very popular in the near future, and is implemented and evaluated in 3D space motion taking into account the effect of the gravity. KUKA LWR manipulator is an example of the collaborative robots, and it is used for doing the experiments. The experimental results prove that the developed system is considerably efficient and very fast in detecting the collisions in the safe region and identifying the collided link along the entire workspace of the three-joint motion of the manipulator. Separate/uncoupled neural networks, one for each joint, are also designed and trained using the same data, and their performance is compared with the coupled one.},
  archive      = {J_SOCO},
  author       = {Sharkawy, Abdel-Nasser and Koustoumpardis, Panagiotis N. and Aspragathos, Nikos},
  doi          = {10.1007/s00500-019-04306-7},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6687-6719},
  shortjournal = {Soft Comput.},
  title        = {Human–robot collisions detection for safe human–robot interaction using one multi-input–output neural network},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Failure mode and effects analysis: An integrated approach
based on rough set theory and prospect theory. <em>SOCO</em>,
<em>24</em>(9), 6673–6685. (<a
href="https://doi.org/10.1007/s00500-019-04305-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Failure mode and effect analysis (FMEA), a bottom-up method, is one of risk assessment tools to eliminate or reduce failures in design and process. It has been applied to many industries due to its flexibility and effectiveness. However, the conventional FMEA considers less about the subjectivity and vagueness in the process of risk assessment and assumes that three risk factors’ importance is the same. Although a lot of approaches based on fuzzy logic are proposed to deal with vague information in previous literature, they need priori assumptions leading to fixed intervals to express vagueness. In addition, most of the previous methods suppose that decision makers are totally rational without considering their psychological factors. To solve the problems, an extended technique for order performance by similarity to ideal solution (TOPSIS) is developed to improve FMEA approach, which combines the advantage of variable precision rough number in dealing with vague information and the strength of prospect theory (PT) in considering decision maker’s bounded rationality. The proposed method consists of two stages: one is the determination of risk factors’ weight function values; and the other is ranking risk priority of failure modes with the PT-based TOPSIS. Finally, a case study of a steam valve system is used to demonstrate the effectiveness and efficiency of the proposed method.},
  archive      = {J_SOCO},
  author       = {Fang, Hong and Li, Jing and Song, Wenyan},
  doi          = {10.1007/s00500-019-04305-8},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6673-6685},
  shortjournal = {Soft Comput.},
  title        = {Failure mode and effects analysis: An integrated approach based on rough set theory and prospect theory},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A hybrid model of dynamic time wrapping and hidden markov
model for forecasting and trading in crude oil market. <em>SOCO</em>,
<em>24</em>(9), 6655–6672. (<a
href="https://doi.org/10.1007/s00500-019-04304-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, a hybrid model of hidden Markov model (HMM) and dynamic time wrapping (DTW) is proposed to predict the return of crude oil price movements and trading. First, three indicators are used as inputs of HMM to determine the market state for each month; next, DTW algorithm is applied to match similar price sequences which have the same market state in historical time series, and then to calculate expected returns; Finally, it forecasts the crude oil spot price direction and executes related simulation trading. For design of the trading strategy, we adopt different parameters such as trading thresholds and position-closing thresholds for each market state, and the particle swarm optimization algorithm is applied for parameter optimization of our trading strategy. In experiments, the proposed method is applied for direction forecasting and simulation trading of WTI and Brent crude oil market. Experimental results show that the proposed method yielded the best forecasting and trading performances in average. For instance, in the WTI market, the proposed method produced a hit ratio of about 62.74\% and a yield of 34.3\% profit per year, and a Sharpe ratio value of 2.274. Furthermore, experimental results of the proposed method were significantly superior to other benchmark methods, demonstrating that the proposed method is not only good at direction prediction and profit making, but also return/risk ratio.},
  archive      = {J_SOCO},
  author       = {Deng, Shangkun and Xiang, Youtao and Nan, Boyang and Tian, Hongyu and Sun, Zhe},
  doi          = {10.1007/s00500-019-04304-9},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6655-6672},
  shortjournal = {Soft Comput.},
  title        = {A hybrid model of dynamic time wrapping and hidden markov model for forecasting and trading in crude oil market},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Pre-production box-office success quotient forecasting.
<em>SOCO</em>, <em>24</em>(9), 6635–6653. (<a
href="https://doi.org/10.1007/s00500-019-04303-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hollywood enjoys the position of being the biggest movie producers when it comes to global recognition among movie-making industries. Despite being the biggest movie producer, it has been facing high revenue losses lately since most of the films that it has created have failed to capture viewer’s attention in the first few weeks of its release resulting in a box-office flop. It has been observed in a recent study that Hollywood is estimated to witness a loss of around 1 billion to almost 10 billion US dollars till 2020. Revenue risks have created immense pressure on movie producing stakeholders. They feel a constant pressure to come up with a formula to make a successful movie, however, to date; there are no fixed ingredients that can ensure the success of a movie. Researchers and movie producers constantly feel a need to have some expert systems which would predict the fate of the movie prior to its production with reasonable accuracy. Regardless of the difficult nature of the issue area, few researchers have created expert systems to forecast the financial success of movies using different approaches, but most of them are targeted pre-release forecasting or have low prediction accuracy. Such predictions are of a seminal nature as of their limited prediction scope, and non-ability to reduce revenue loss risk. Therefore, there is a constant demand from investors to have pre-production forecasting tools with high accuracy which can help them plan and make necessary alterations to save huge investments. In this study, we proposed eighteen new features to forecast box-office success, as soon as the quotient (director and cast) signs an agreement. This proposed forecasting time is the earliest prediction that has ever been reported in the movie forecasting literature. The decision support system ranks director and lead cast by utilizing their performances of the last 100 years (1915–2015). The processed output file is a table that ranks each director and cast into four categories based on cast experience, journalist critics, media reporting, user ratings, and revenue generated by associating movie. To produce more accurate results, learner-based feature selection is also performed to select the best subsets of features. This system is intended to be a dynamic tool, integrating further data for real-time adaptation. The system has the ability to incorporate different feature selection algorithm for the progressive improvement of movie success forecasting We demonstrate the effectiveness of extracting features and explain how they improve forecasting accuracy over existing models. The adaptive behaviour of the presented system is achieved by incorporating conceptually different machine learning classifiers, i.e. support vector machine, gradient boosting, extreme boosting classifier, and random forest. A voting system is used to make the prediction by averaging the output class-probabilities. To assess the adequacy of new features, a cross-validation test is directed. Our classification results are evaluated by using two performance measures, i.e. average per cent success rate, or within one class away from its actual prediction. The new features have achieved the most noteworthy accuracy of 85\% with an expansion of a 46.43\% (average per cent success rate) and 5.56\% (within a class away) in comparison with other state-of-the-art feature sets.},
  archive      = {J_SOCO},
  author       = {Ahmed, Usman and Waqas, Humaira and Afzal, Muhammad Tanvir},
  doi          = {10.1007/s00500-019-04303-w},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6635-6653},
  shortjournal = {Soft Comput.},
  title        = {Pre-production box-office success quotient forecasting},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal shape synthesis of a metallic flywheel using
non-dominated sorting jaya algorithm. <em>SOCO</em>, <em>24</em>(9),
6623–6634. (<a
href="https://doi.org/10.1007/s00500-019-04302-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study describes the shape synthesis of a metallic flywheel using a non-dominated sorting Jaya algorithm. Generally, the flywheel is used to store the kinetic energy in the machines. Kinetic energy is an essential parameter to measure flywheel performance and can be improved by the optimal shape of the flywheel. In order to the optimal shape of the flywheel, the multi-objective problem with the maximization of the kinetic energy and minimization of von Mises stresses is formulated under appropriate design constraints using the cubic B-spline curve. A flowchart is proposed to solve the two-point boundary value differential equation for the calculation of von Mises stress at each point between the inner and outer radii of the flywheel. The design variables are represented by the control points of the cubic B-spline curve. A posteriori approach-based algorithm as non-dominated sorting Jaya algorithm (NSJaya) is used to solve the formulated optimization problem. This algorithm is based on the concepts of crowding distance and non-dominated sorting approach and gives the optimal Pareto set. The proposed method is applied to the flywheel of the agricultural thresher. The performance of the proposed algorithm is compared with that of non-dominated sorting genetic algorithm (NSGA-II) using hyper-volume performance metric. It is found that the NSJaya algorithm gives better results compared to NSGA-II and a posteriori approach-based algorithms such as genetic algorithm (GA), particle swarm optimization (PSO), and Jaya. The optimal Pareto set for the optimal shape of the flywheel is calculated and outlined in this paper. The designer can choose any solution from the Pareto set for the optimal shape of the flywheel. ANSYS parameter design language (APDL) software is used for the validation of the von Mises stresses in the optimized shapes of the flywheel.},
  archive      = {J_SOCO},
  author       = {Singh, Prem and Chaudhary, Himanshu},
  doi          = {10.1007/s00500-019-04302-x},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6623-6634},
  shortjournal = {Soft Comput.},
  title        = {Optimal shape synthesis of a metallic flywheel using non-dominated sorting jaya algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Statistical convergence in measure for double sequences of
fuzzy-valued functions. <em>SOCO</em>, <em>24</em>(9), 6613–6622. (<a
href="https://doi.org/10.1007/s00500-020-04805-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this paper is to define two sorts of convergence in measure, that is, outer and inner statistical convergence, for double sequences of fuzzy-valued measurable functions and demonstrate that both kinds of convergence are equivalent in a finite measurable set. We also define the notion of statistical convergence in measure for double sequences of fuzzy-valued measurable functions and establish several interesting results. In addition, we prove the statistical version of Egorov’s theorem for double sequences of fuzzy-valued functions defined on a finite measure space.},
  archive      = {J_SOCO},
  author       = {Hazarika, Bipan and Alotaibi, Abdullah and Mohiuddine, S. A.},
  doi          = {10.1007/s00500-020-04805-y},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6613-6622},
  shortjournal = {Soft Comput.},
  title        = {Statistical convergence in measure for double sequences of fuzzy-valued functions},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The fractional non-equidistant grey opposite-direction model
with time-varying characteristics. <em>SOCO</em>, <em>24</em>(9),
6603–6612. (<a
href="https://doi.org/10.1007/s00500-020-04799-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The grey opposite-direction model with fractional-order accumulation ($$ {\text{GOM}}^{\text{r}} (1,1) $$) has been appealed and interested in non-equidistant cases. However, there exists the drawback that it does not consider the effect of time-varying factor. In other words, the fixed grey control parameter defined as a certain constant limits the prediction performance of the model. By fully studying modelling procedure of the model, the optimized non-equidistant $$ {\text{GOM}}^{\text{r}} (1,1) $$ model with time-varying characteristics is proposed in this paper, which is abbreviated as $$ {\text{NTVGOM}}^{\text{r}} (1,1) $$ model. In the new model, a polynomial with time-varying characteristics is applied on grey control parameter, and the optimal fractional order could be automatically determined by minimizing the mean absolute percentage error. Then, the two empirical examples are employed to verify the effectiveness of the proposed model, and the numerical results show the proposed model has a better prediction performance.},
  archive      = {J_SOCO},
  author       = {Xie, Wanli and Liu, Chong and Wu, Wen-Ze},
  doi          = {10.1007/s00500-020-04799-7},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6603-6612},
  shortjournal = {Soft Comput.},
  title        = {The fractional non-equidistant grey opposite-direction model with time-varying characteristics},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Quasicomplemented residuated lattices. <em>SOCO</em>,
<em>24</em>(9), 6591–6602. (<a
href="https://doi.org/10.1007/s00500-020-04778-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the class of quasicomplemented residuated lattices is introduced and investigated, as a subclass of residuated lattices in which any prime filter not containing any dense element is a minimal prime filter. The notion of a disjunctive residuated lattice is introduced, and it is observed that a residuated lattice is Boolean if and only if it is disjunctive and quasicomplemented. Finally, some characterizations for quasicomplemented residuated lattices are given by means of the new notion of $$\alpha $$-filters.},
  archive      = {J_SOCO},
  author       = {Rasouli, Saeed},
  doi          = {10.1007/s00500-020-04778-y},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6591-6602},
  shortjournal = {Soft Comput.},
  title        = {Quasicomplemented residuated lattices},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A density-core-based clustering algorithm with local
resultant force. <em>SOCO</em>, <em>24</em>(9), 6571–6590. (<a
href="https://doi.org/10.1007/s00500-020-04777-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering analysis has been widely used in image segmentation, face recognition, protein identification, intrusion detection, document clustering and so on. Most of the previous clustering algorithms are not suitable for complex situations with manifold structure and large variations in density. Clustering by density core (DCore) turns out to be a very effective clustering method for complex structure. However, DCore must set too many parameters for better results, which often fails when the shape of data is complex and the density of data varies too much. Inspired by universal gravitation, we propose a novel clustering algorithm (called DCLRF) based on density core and local resultant force. In this algorithm, each data point is viewed as an object with a local resultant force (LRF) generated by its neighbors and a local measure named centrality is proposed based on LRF and natural neighbors. Firstly, we extract core points using the CE value. Then, we use the natural neighbor structure information of core points to get the final clustering results. Excluding the influence of noise, core points can well represent the structure of clusters. Therefore, DCLRF can obtain the optimal cluster numbers for the datasets which contain clusters of arbitrary shapes. Both synthetic datasets and real datasets are used for experiments to verify the efficiency and accuracy of the DCLRF.},
  archive      = {J_SOCO},
  author       = {Wang, Xiao-Xia and Zhang, Yu-Fang and Xie, Jiang and Dai, Qi-Zhu and Xiong, Zhong-Yang and Dan, Jing-Pei},
  doi          = {10.1007/s00500-020-04777-z},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6571-6590},
  shortjournal = {Soft Comput.},
  title        = {A density-core-based clustering algorithm with local resultant force},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Joint label completion and label-specific features for
multi-label learning algorithm. <em>SOCO</em>, <em>24</em>(9),
6553–6569. (<a
href="https://doi.org/10.1007/s00500-020-04775-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label correlations have always been one of the hotspots of multi-label learning. Using label correlations to complete the original label can enrich the information of the label matrix. At the same time, label-specific features give a thought that different labels have inherent characteristics that can be distinguished, and we can use label correlations to enhance the learning process of label-specific features among similar labels. At present, most of the algorithms combine label correlations and label-specific features to improve the multi-label learning effect, but do not consider the impact of label marking errors or defaults in data sets. In fact, the label completion method can further enrich the information of label matrix, and then the joint learning framework of joint label-specific features can effectively improve the robustness of the multi-label learning algorithm. Based on this, this paper proposes a multi-label learning algorithm for joint label completion and label-specific features, and constructs a new multi-label learning algorithm framework by means of joint label completion and label-specific features. Completion matrix and label-specific features are obtained by alternating iteration method, and the label matrix updating the optimization framework fully considers the label correlations. The algorithm in this paper has been demonstrated and trained on several benchmark multi-label data sets by extensive experiments, which verifies the effectiveness of the algorithm.},
  archive      = {J_SOCO},
  author       = {Wang, Yibin and Zheng, Weijie and Cheng, Yusheng and Zhao, Dawei},
  doi          = {10.1007/s00500-020-04775-1},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6553-6569},
  shortjournal = {Soft Comput.},
  title        = {Joint label completion and label-specific features for multi-label learning algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Single axioms for (s, t)-fuzzy rough approximation operators
with fuzzy product operations. <em>SOCO</em>, <em>24</em>(9), 6539–6551.
(<a href="https://doi.org/10.1007/s00500-020-04774-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are two different perspectives to study single axioms for (S, T)-fuzzy rough approximation operators, that is, ordinary fuzzy operations and fuzzy product operations. However, it is too complex and tedious to characterize (S, T)-fuzzy rough approximation operators with ordinary fuzzy operations, such as intersection, union and so on. To remedy these defects, this paper further investigates single axioms for (S, T)-fuzzy rough approximation operators with fuzzy product operations, where fuzzy relation is not limited into either a general fuzzy relation or a symmetric one. Considering a left-continuous t-norm T, we describe T-upper fuzzy rough approximation operators with fuzzy product operations by only one axiom. When t-conorm S is right-continuous and fuzzy negation N is strict, S-lower fuzzy rough approximation operators are characterized with fuzzy product operations by a single axiom.},
  archive      = {J_SOCO},
  author       = {Wang, Chun Yong and Gong, Yu Li},
  doi          = {10.1007/s00500-020-04774-2},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6539-6551},
  shortjournal = {Soft Comput.},
  title        = {Single axioms for (S, t)-fuzzy rough approximation operators with fuzzy product operations},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An efficient key authentication procedure for IND-CCA2
secure paillier-based cryptosystem. <em>SOCO</em>, <em>24</em>(9),
6531–6537. (<a
href="https://doi.org/10.1007/s00500-020-04768-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Public key cryptosystems more recently developed have to be strong against newer and more advanced forms of attacks. The security protection of a public key cryptosystem relies heavily on the design of the public key. The key authentication procedure is one of the easiest and most advantageous authentication mechanisms used over insecure networks and widely applied for the remote login with various operation systems, computer networks, wireless networks, database management systems, and many others. In a typical key authentication procedure, however, there is at least one authority involved to authenticate the keys. In this paper, we shall propose a new key authentication procedure built on the basis of the decisional composite residuosity assumption. As with ordinary certificate-based procedures, the proposed procedure involves no authorities. With the certificate of the public key of a client being a blend of his/her private key and password, the proposed procedure is exceptionally secure, and the authentication process is very simple.},
  archive      = {J_SOCO},
  author       = {Meshram, Chandrashekhar and Obaidat, Mohammad S. and Lee, Cheng-Chi and Meshram, Sarita Gajbhiye},
  doi          = {10.1007/s00500-020-04768-0},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6531-6537},
  shortjournal = {Soft Comput.},
  title        = {An efficient key authentication procedure for IND-CCA2 secure paillier-based cryptosystem},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Conditional probability on full łukasiewicz tribes.
<em>SOCO</em>, <em>24</em>(9), 6521–6529. (<a
href="https://doi.org/10.1007/s00500-020-04762-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study notions of conditional probability and stochastic dependence/independence in an upgraded probability model in which the space of events is modeled by a full Łukasiewicz tribe of all measurable functions from some measurable space into [0, 1]. Our study is based on properties of joint experiments and the notion of stochastic channel, a construct equivalent to the notion of Markov kernel between two measurable spaces. Using the notion of a degenerated stochastic channel, a channel transmitting no stochastic information between two spaces, we define an asymmetrical independence of random experiments. Finally, we define the notion of conditional probability on full Łukasiewicz tribes.},
  archive      = {J_SOCO},
  author       = {Eliaš, Peter and Frič, Roman},
  doi          = {10.1007/s00500-020-04762-6},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6521-6529},
  shortjournal = {Soft Comput.},
  title        = {Conditional probability on full Łukasiewicz tribes},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). A bayesian network model for the reliability control of
fresh food e-commerce logistics systems. <em>SOCO</em>, <em>24</em>(9),
6499–6519. (<a
href="https://doi.org/10.1007/s00500-020-04666-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the reliability of intelligent logistics for fresh food e-commerce. Based on the development of fresh food e-commerce, this paper analyses the factors that influence the reliability of fresh food logistics from the aspects of information technology, facilities and equipment, personnel operation and external environment. A Bayesian network is used to analyse the influence of each factor on system reliability, and the degree of importance of each factor is calculated. Based on the importance of each influential factor in fresh food e-commerce logistics systems, an intelligent logistics model for reliability control of fresh food is established. The purpose of this model is to improve the economic efficiency and the intelligent level of the fresh food e-commerce logistics system on the premise of meeting the system reliability requirements. Finally, simulation results show that the developed intelligent logistics reliability control model can significantly improve the reliability of fresh food e-commerce logistics systems, and provide practical suggestions for fresh food e-commerce enterprises.},
  archive      = {J_SOCO},
  author       = {Zhang, Hao and Liu, Yu and Zhang, Qian and Cui, Yan and Xu, Shensi},
  doi          = {10.1007/s00500-020-04666-5},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6499-6519},
  shortjournal = {Soft Comput.},
  title        = {A bayesian network model for the reliability control of fresh food e-commerce logistics systems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Supply chain pricing and effort decisions with the
participants’ belief under the uncertain demand. <em>SOCO</em>,
<em>24</em>(9), 6483–6497. (<a
href="https://doi.org/10.1007/s00500-019-04633-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the pricing and effort decisions of a supply chain consisting of a manufacturer and a retailer. All the parties make optimal decisions to maximize their profits with uncertainty of demand under their confidence levels. Taking this into account, Stackelberg models are formulated to study the impact of the confidence levels on pricing and effort decisions for the decentralized and centralized supply chains. We obtain that the confidence levels of participants have a significant impact on the pricing and effort decisions. Specifically, when the retailer’s confidence level is increasing, the retail price, the wholesales price, the sales effort, the profit of each member and the total profit of supply chain are all increasing. However, the manufacturer’s confidence level is not independent of the power structure, i.e., there are different characteristics under the different power structures. The power structure has an outstanding effect on the profit of each member in the supply chain. The leader’s profit is always more than that of the follower, and the profit of upstream is more than that of the downstream when they have the same power. We use numerical experiments to verify the validity of the model.},
  archive      = {J_SOCO},
  author       = {Yang, Xiaohu and Jing, Fan and Ma, Nana and Nie, Fapeng},
  doi          = {10.1007/s00500-019-04633-9},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6483-6497},
  shortjournal = {Soft Comput.},
  title        = {Supply chain pricing and effort decisions with the participants’ belief under the uncertain demand},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimizing stop plan and tickets allocation for high-speed
railway based on uncertainty theory. <em>SOCO</em>, <em>24</em>(9),
6467–6482. (<a
href="https://doi.org/10.1007/s00500-019-04617-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming to provide a generic modeling framework for finding stop plan and tickets allocation of high-speed railway, we first propose a stop plan and tickets allocation collaborative optimization model in this paper, which is established to maximize the passenger satisfaction degree and the average seated occupancy rate. Due to the randomness and uncertainty of passenger demand, uncertain variables are set and the primal model is an uncertain model. And then, the model is transformed into equivalent deterministic model based on uncertainty theory. Because of the computational complexity of the model, especially for the large-scale real-world instances, we develop a Lagrangian relaxation (LR-based) heuristic algorithm that decomposes the primal problem into two sub-problems and thus is able to find good solutions in short time. Finally, a numerical experiment based on the operation data of high-speed railway from Beijing south Station to Shanghai Hongqiao Station is implemented to verify the effectiveness and feasibility of the proposed approaches.},
  archive      = {J_SOCO},
  author       = {Han, Bing and Ren, Shuang},
  doi          = {10.1007/s00500-019-04617-9},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6467-6482},
  shortjournal = {Soft Comput.},
  title        = {Optimizing stop plan and tickets allocation for high-speed railway based on uncertainty theory},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The dilemma phenomenon, logistics for monetary independence
policy and foreign exchange reserves. <em>SOCO</em>, <em>24</em>(9),
6457–6466. (<a
href="https://doi.org/10.1007/s00500-019-04587-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of financial integration makes a country’s economic links difficult. This is especially so for emerging market countries, which are more vulnerable to economic shocks. The objective of this paper is to explore whether the emerging market countries which adopt floating exchange rate system have realized, at the same time, in the aftermath of a crisis, free movement of capital flow and independence of monetary policy. This is done by introducing foreign exchange reserves into Mundell–Fleming model to do derivation. The approach is supported by empirical research based on 20 emerging countries including China, Brazil, Poland and South Africa and others. It was found that: (1) after the crisis, the emerging market countries that implemented floating exchange rate system did not achieve monetary policy independence. Rapid accumulation of foreign exchange reserves weakened the positive effect of the increase in money supply on output; (2) As a result of holding foreign exchange reserves, the independence of monetary policy in emerging market countries has been challenged, independently of the type of exchange rate system adopted, which proves the existence of dilemma phenomenon. Finally, this study puts forward policy recommendations on the exchange rate system and capital account convertibility for China.},
  archive      = {J_SOCO},
  author       = {Mei, Yu and Kun, Zhang and Ralescu, Anca L.},
  doi          = {10.1007/s00500-019-04587-y},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6457-6466},
  shortjournal = {Soft Comput.},
  title        = {The dilemma phenomenon, logistics for monetary independence policy and foreign exchange reserves},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Strategy analysis of governments and new energy product
manufacturers and consumers based on evolutionary game model.
<em>SOCO</em>, <em>24</em>(9), 6445–6455. (<a
href="https://doi.org/10.1007/s00500-019-04571-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {New energy products (NEPs) are important driving forces for promoting economic transformation and green development. The current trend of NEPs development is propelled by consumers, spurred by governmental regulations, and implemented by manufacturers. However, the previous studies rarely discussed the behavioral strategies of consumers. The relationships among consumers, manufacturers, and governments need to be researched in depth. In this paper, we focus on analyzing the impact factors of these three groups strategic selection of NEPs. In bounded rationality, by jointly considering the interactions among the customers’ purchases, the manufacturers’ product strategies, and the regulation policies, we develop three scenarios based on the evolutionary game model. The equilibrium results show that the production cost of NEPs and the profit from NEPs, government subsidies, and the taxation imposed on the manufacturers are the key influencing factors of the manufacturers’ strategy. The critical factors affecting the consumers’ purchase behavior are the benefits obtained from NEPs, government subsidies to consumers, and taxation on traditional energy products (TEPs). The influencing factors of governmental regulations include consumer satisfaction with the government, the environmental loss caused by TEPs, the cost of regulations, the coefficient of taxation, and subsidies. According to the research results, the countermeasures put forward will be more helpful for government to regulate the development of NEPs.},
  archive      = {J_SOCO},
  author       = {Liu, Changyu and Xia, Tongshui},
  doi          = {10.1007/s00500-019-04571-6},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6445-6455},
  shortjournal = {Soft Comput.},
  title        = {Strategy analysis of governments and new energy product manufacturers and consumers based on evolutionary game model},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Supply chain partnership, inter-organizational knowledge
trading and enterprise innovation performance: The theoretical and
empirical research in project-based supply chain. <em>SOCO</em>,
<em>24</em>(9), 6433–6444. (<a
href="https://doi.org/10.1007/s00500-019-04548-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on relational exchange theory and transaction cost theory, a conceptual model for the relationships among supply chain partnership, inter-organizational knowledge trading and enterprise innovation performance is proposed and empirically tested using the data collected from 256 Chinese manufacturing enterprises in project-based supply chain with the structural equation model. The dimension of supply chain partnership in this model is described from shared goal, trust and relationship commitment. Inter-organizational knowledge trading is categorized into explicit knowledge trading and tacit knowledge trading. The results showed that: (1) there are significant and positive effects of shared goal and trust on explicit knowledge trading, tacit knowledge trading and enterprise innovation performance, while trust has a stronger positive effect on tacit knowledge trading than explicit knowledge trading; (2) although relationship commitment has significant and positive effects on tacit knowledge trading and enterprise innovation performance, it does not affect explicit knowledge trading significantly; (3) it is also proved that inter-organizational knowledge trading (explicit knowledge trading and tacit knowledge trading) has significant and positive effects on enterprise innovation performance; (4) the mediating effects of inter-organizational knowledge trading (explicit knowledge trading and tacit knowledge trading) are proved on the relationships between supply chain partnership (shared goal, trust and relationship commitment) and enterprise innovation performance, excluding the mediating effect of explicit knowledge trading between relationship commitment and enterprise innovation performance. The findings provide a theoretical basis for inter-organizational knowledge trading participants selecting an appropriate relational mechanism to promote knowledge trading, and these also guide the inter-organizational knowledge trading among members of project-based supply chain in practice.},
  archive      = {J_SOCO},
  author       = {Yang, Hong and Chen, Wei and Hao, Yi-fei},
  doi          = {10.1007/s00500-019-04548-5},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6433-6444},
  shortjournal = {Soft Comput.},
  title        = {Supply chain partnership, inter-organizational knowledge trading and enterprise innovation performance: The theoretical and empirical research in project-based supply chain},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An unsupervised ensemble framework for node anomaly behavior
detection in social network. <em>SOCO</em>, <em>24</em>(9), 6421–6431.
(<a href="https://doi.org/10.1007/s00500-019-04547-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale and dynamic networks arise in cyberspace and financial security. Given a dynamic network, it is crucial to detect structural anomalies, such as node behaviors deviate from underlying majority of the network. However, anomaly analysis for dynamic networks is difficult to precisely detect the anomalous behaviors of nodes because it usually ignores the evolutionary behaviors of different nodes. Our work taps into this gap and proposes an unsupervised ensemble framework for node temporal behavior modeling and node behavior real-time anomaly detection. Specifically, a latent space model is used to model the node behavior; each node is assigned a probability distribution across a small set of roles based on that node’s features. The evolutionary behavior of node is represented as node roles change over time and the anomalies of node are identified as deviations from expected roles. The entropy-based ensembles method is proposed to combine with multiple unsupervised anomaly detectors to yield robust performances, which achieves the real-time anomaly detection for different types of node behaviors. Finally, we show the effectiveness of the proposed method on Enron network in the experiments.},
  archive      = {J_SOCO},
  author       = {Cheng, Qing and Zhou, Yun and Feng, Yanghe and Liu, Zhong},
  doi          = {10.1007/s00500-019-04547-6},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6421-6431},
  shortjournal = {Soft Comput.},
  title        = {An unsupervised ensemble framework for node anomaly behavior detection in social network},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Port collaborative development based on rough set theory.
<em>SOCO</em>, <em>24</em>(9), 6409–6419. (<a
href="https://doi.org/10.1007/s00500-019-04201-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a strategic resource for the region to participate in global economic cooperation and competition, the coordinated development of ports within the port group is of great practical significance to promote its own and regional economic development. In order to better promote the port’s rational development and resource allocation, this paper uses the rough set reduction method based on information entropy to determine the attribute weight and importance of the system order parameter index and uses the port group system coupling measure model to obtain the port coupling degree. Then, different coupling states are distinguished according to the coupling degree of the port, and the level of the coordinated development of the port is described. Finally, through the empirical analysis of the three major port groups in the Bohai Rim region, the level of coordinated development of ports within the three major port groups is analyzed.},
  archive      = {J_SOCO},
  author       = {Lu, Bo and Wang, Qian},
  doi          = {10.1007/s00500-019-04201-1},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6409-6419},
  shortjournal = {Soft Comput.},
  title        = {Port collaborative development based on rough set theory},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Change points detection and parameter estimation for
multivariate time series. <em>SOCO</em>, <em>24</em>(9), 6395–6407. (<a
href="https://doi.org/10.1007/s00500-019-04135-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a method to estimate the number and locations of change points and further estimate parameters of different regions for piecewise stationary vector autoregressive models. The procedure decomposes the problem of change points detection and parameter estimation along the component series. By reformulating the change point detection problem as a variable selection one, we apply group Lasso method to estimate the change points initially. Then, from the preliminary estimate of change points, a subset is selected based on the loss functions of Lasso method and a backward elimination algorithm. Finally, we propose a Lasso + OLS method to estimate the parameters in each segmentation for high-dimensional VAR models. The consistent properties of the estimation for the number and the locations of the change points and the VAR parameters are proved. Simulation experiments and real data examples illustrate the performance of the method.},
  archive      = {J_SOCO},
  author       = {Gao, Wei and Yang, Haizhong and Yang, Lu},
  doi          = {10.1007/s00500-019-04135-8},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6395-6407},
  shortjournal = {Soft Comput.},
  title        = {Change points detection and parameter estimation for multivariate time series},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An improved diffusion model for supply chain emergency in
uncertain environment. <em>SOCO</em>, <em>24</em>(9), 6385–6394. (<a
href="https://doi.org/10.1007/s00500-019-04134-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emergencies will bring the great threat to the stability and coordination of supply chain, such as temporary interruption of raw materials supply, strong fluctuation of demand and distorted information transmission, which will lead to the breakdown of whole supply chain and threaten the survival of enterprises in supply chain. Based on the influence factors of emergency diffusion and supply chain structure in uncertain environment, this paper studies the diffusion effect of emergency and establishes an improved Bass diffusion model. On this basis, information diffusion simulation is carried out. Finally, management suggestions are proposed on supply chain emergency diffusion in uncertain environment.},
  archive      = {J_SOCO},
  author       = {Deng, Yirui and Jiang, Mingyue and Ling, Chen},
  doi          = {10.1007/s00500-019-04134-9},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6385-6394},
  shortjournal = {Soft Comput.},
  title        = {An improved diffusion model for supply chain emergency in uncertain environment},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The risk path selection problem in uncertain network.
<em>SOCO</em>, <em>24</em>(9), 6375–6383. (<a
href="https://doi.org/10.1007/s00500-019-04132-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper characterizes the minimum risk path selection problem in an uncertain network. Assuming the accidental losses are the uncertain variables, we first present three types of uncertain risk indexes. After that, some uncertain risk programming models are built based on the proposed risk indexes. In order to obtain the minimum risk path, we convert these uncertain programming models to their corresponding deterministic forms by the operational law of uncertain variables. At last, a numerical example is given to demonstrate the models.},
  archive      = {J_SOCO},
  author       = {Li, Shengguo and Peng, Jin and Zhang, Bo},
  doi          = {10.1007/s00500-019-04132-x},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6375-6383},
  shortjournal = {Soft Comput.},
  title        = {The risk path selection problem in uncertain network},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Agency models based on different measures with comparison.
<em>SOCO</em>, <em>24</em>(9), 6363–6373. (<a
href="https://doi.org/10.1007/s00500-019-04044-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal contract regulates the expected activities of both principals and agents, and influences how the gains from the cooperation are shared between the two participators. Thus, it is necessary and wise for principals to seek for the optimal contracts during the period of negotiations. To determine the optimal contracts, there are several kinds of agency models based on different measures, such as probability measure, capacity measure, credibility measure and uncertainty measure. This paper primarily presents a comparative review of random agency model, fuzzy agency model and uncertain agency model. This comparative review is aimed at not only summarizing the structure and feature of each agency model but also guiding on how to identify the most suitable agency model for each specific principal agent problem. Motivated by this idea, these three classes of agency models are respectively investigated about their structure, feature and application, and then an empirical comparison among these models is basically carried out from several aspects, such as information diversity, decision rule and calculation. As a significant contribution, the comparative result in this paper provides the guidance for the principals on how to identify the most suitable agency model for each special principal agent problem in a certain setting.},
  archive      = {J_SOCO},
  author       = {Wu, Xiaoli and Wang, Guoli and Wang, Xiulan and Yu, Xinning},
  doi          = {10.1007/s00500-019-04044-w},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6363-6373},
  shortjournal = {Soft Comput.},
  title        = {Agency models based on different measures with comparison},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Constructing a multilayer network for stock market.
<em>SOCO</em>, <em>24</em>(9), 6345–6361. (<a
href="https://doi.org/10.1007/s00500-019-04026-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we discuss the stock network construction problem under simultaneous consideration of linear and nonlinear relations between stocks. A novel method based on the conditional probability is proposed to describe the nonlinear relation between stocks. Furthermore, by considering both the linear and nonlinear relations between stocks, a multilayer network is constructed to characterize stock market, in which Pearson correlation network, Granger causality network, and our proposed nonlinear relation network are combined. Finally, several experiments are conducted to illustrate the effectiveness of the proposed approaches. The results show that the proposed multilayer network not only covers more nodes than the Pearson correlation network, but also better balances the relation between prediction accuracy and the number of predictable nodes.},
  archive      = {J_SOCO},
  author       = {Chen, Wei and Jiang, Manrui and Jiang, Cheng},
  doi          = {10.1007/s00500-019-04026-y},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6345-6361},
  shortjournal = {Soft Comput.},
  title        = {Constructing a multilayer network for stock market},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A dynamic line generation and vehicle scheduling method for
airport bus line based on multi-source big travel data. <em>SOCO</em>,
<em>24</em>(9), 6329–6344. (<a
href="https://doi.org/10.1007/s00500-019-03987-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Airport bus is an important public transportation mode for large international airport. To improve the bus station coverage, passenger demand compatibility and the scheduling flexibility of Beijing International Airport bus line, a dynamic line generation and vehicle scheduling method is proposed in this paper. Firstly, based on multi-source big data from the airport (including data from taxi, ride-hailing service, subway, regular bus, airport bus, etc.), we accurately extract candidate stations, which are very popular with passengers and convenient for parking and transfer, through public transportation demand level calculation, iterative clustering and POI matching. Then, the candidate stations need to be partitioned appropriately by selecting suitable features and calculating the similarity of candidate stations, so as to make the stations within each group a moderate size and have a consistent spatial orientation. Finally, a line generation and vehicle scheduling algorithm, which is compatible with multi-vehicle, high success rate of ride-sharing matching and low cost, is designed to realize accurate and rapid operation scheduling within each group according to the situation of passengers booking tickets. We have carried out experiments in Wangjing and Yayuncun, and the results show that our method can satisfy passenger demand fast and accurately.},
  archive      = {J_SOCO},
  author       = {Yu, Haitao and Lv, Weifeng and Liu, Hangou and Fu, Xiaoning and Xiao, Randong},
  doi          = {10.1007/s00500-019-03987-4},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6329-6344},
  shortjournal = {Soft Comput.},
  title        = {A dynamic line generation and vehicle scheduling method for airport bus line based on multi-source big travel data},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Urban hazmat transportation with multi-factor.
<em>SOCO</em>, <em>24</em>(9), 6307–6328. (<a
href="https://doi.org/10.1007/s00500-019-03956-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an urban hazmat transportation problem considering multiple factors that tangle with real-world applications (i.e., weather conditions, traffic conditions, population density, time window, link closure and half link closure) is investigated. Based on multiple depot capacitated vehicle routing problem, we provide a multi-level programming formulation for urban hazmat transportation. To obtain the Pareto optimal solution, an improved biogeography-based optimization (improved BBO) algorithm is designed, comparing with the original BBO and genetic algorithm, with both simulated numerical examples and a real-world case study, demonstrating the effectiveness of the proposed approach.},
  archive      = {J_SOCO},
  author       = {Du, Jiaoman and Li, Xiang and Li, Lei and Shang, Changjing},
  doi          = {10.1007/s00500-019-03956-x},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6307-6328},
  shortjournal = {Soft Comput.},
  title        = {Urban hazmat transportation with multi-factor},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). A new uncertain regression model and its application.
<em>SOCO</em>, <em>24</em>(9), 6297–6305. (<a
href="https://doi.org/10.1007/s00500-019-03938-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncertain linear regression (ULR) model based on symmetric triangular uncertain set has been studied early. This paper extends the symmetric triangular uncertain coefficients to asymmetric triangular uncertain coefficients and builds two methods for estimating the parameters of ULR model. Our aim is to minimize the differences of the uncertain membership functions between the observed and estimated values. Firstly, we propose a linear programming method, whose principle is to minimize the sum of the absolute values of the differences between left width and right width of two triangular uncertain sets for each index i. Secondly, we develop a new nonlinear programming method by maximizing the overlaps of acreage of the estimated and real triangular uncertain sets in a particular $$h_i$$-cut. Then, a criterion is established to evaluate the performance of the proposed approaches. Finally, we use an example based on industrial water demand data of China to illustrate our proposed approaches which are reasonable and compare the explanatory power of the ULR model and traditional linear regression (TLR) model using the presented evaluation criteria, which shows that the performance of the ULR model is obviously better than the TLR model.},
  archive      = {J_SOCO},
  author       = {Wang, Xiaosheng and Li, Haiyan and Guo, Haiying},
  doi          = {10.1007/s00500-019-03938-z},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6297-6305},
  shortjournal = {Soft Comput.},
  title        = {A new uncertain regression model and its application},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An adaptive differential evolution with combined strategy
for global numerical optimization. <em>SOCO</em>, <em>24</em>(9),
6277–6296. (<a
href="https://doi.org/10.1007/s00500-019-03934-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential evolution (DE) is a simple yet powerful evolutionary algorithm for numerical optimization. However, the performance of DE significantly relies on its mutation operator and control parameters (scaling factor and crossover rate). In this paper, we propose a novel DE variant by introducing a series of combined strategies into DE, called CSDE. Specifically, in CSDE, to obtain a proper balance between global exploration ability and local exploitation ability, we adopt two mutation operators with different characteristics to produce the mutant vector, and provide a mechanism based on their own historical success rate to coordinate the two adopted mutation operators. Moreover, we combine a periodic function based on one modulo operation, an individual-independence macro-control function and an individual-dependence function based on individual’s fitness value information to adaptively produce scaling factor and crossover rate. To verify the effectiveness of the proposed CSDE, comparison experiments contained seven other state-of-the-art DE variants are tested on a suite of 30 benchmark functions and four real-world problems. The simulation results demonstrate that CSDE achieves the best overall performance among the eight DE variants.},
  archive      = {J_SOCO},
  author       = {Sun, Gaoji and Yang, Bai and Yang, Zuqiao and Xu, Geni},
  doi          = {10.1007/s00500-019-03934-3},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6277-6296},
  shortjournal = {Soft Comput.},
  title        = {An adaptive differential evolution with combined strategy for global numerical optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust multi-product inventory optimization under support
vector clustering-based data-driven demand uncertainty set.
<em>SOCO</em>, <em>24</em>(9), 6259–6275. (<a
href="https://doi.org/10.1007/s00500-019-03927-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A robust multi-product inventory optimization approach is developed with an uncertainty set constructed from the available data using support vector clustering (SVC). The multi-product inventory problem is subject to demand uncertainties in a newsvendor setting with the historical demand data as the only available information. By using SVC, the uncertainty set to which the uncertain demands belong is constructed with a certain confidence in a data-driven approach. The associated robust counterpart model is then developed using the absolute robustness criterion. Through mathematical deduction, the proposed counterpart model is transformed into a tractable linear programming model which can be solved efficiently. The transformed and the original models are proved to be mathematically equivalent. Numerical studies are conducted to illustrate the effectiveness and practicality of the proposed SVC-based data-driven robust optimization approach for dealing with demand uncertainties. The results show that the robust optimization approach under the proposed SVC-based uncertainty set outperforms those under the traditional, i.e., the box and the ellipsoid, uncertainty sets. These results provide evidences that the proposed data-driven robust optimization approach can better hedge against demand uncertainties in multi-product inventory problems.},
  archive      = {J_SOCO},
  author       = {Qiu, Ruozhen and Sun, Yue and Fan, Zhi-Ping and Sun, Minghe},
  doi          = {10.1007/s00500-019-03927-2},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6259-6275},
  shortjournal = {Soft Comput.},
  title        = {Robust multi-product inventory optimization under support vector clustering-based data-driven demand uncertainty set},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Coordination of port service chain with an integrated
contract. <em>SOCO</em>, <em>24</em>(9), 6245–6258. (<a
href="https://doi.org/10.1007/s00500-019-03839-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Port, carriers and many other departments are involved in the whole water transportation service system, and these departments tend to have conflicts of interest in the process of service, which results in a difficult coordination phenomenon. We propose an integrated contract that combines the revenue sharing and service cost allocation to coordinate the port service chain. We explore the effects of the contract decision variables in the different scenarios. The results show that two sharing factors exist “blind zone,” but the improved contract reveals that revenue sharing and cost allocation contract combining with the fixed payment mechanism can be more effective to coordinate the port service chain.},
  archive      = {J_SOCO},
  author       = {Liu, Fan and Wang, Junjin and Liu, Jiaguo and Kong, Yudan},
  doi          = {10.1007/s00500-019-03839-1},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6245-6258},
  shortjournal = {Soft Comput.},
  title        = {Coordination of port service chain with an integrated contract},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mapping the evaluation results between quantitative metrics
and meta-synthesis from experts’ judgements: Evidence from the supply
chain management and logistics journals ranking. <em>SOCO</em>,
<em>24</em>(9), 6227–6243. (<a
href="https://doi.org/10.1007/s00500-019-03837-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Meta-syntheses from experts’ judgements and quantitative metrics are two main forms of evaluation. But they both have limitations. This paper constructs a framework for mapping the evaluation results between quantitative metrics and experts’ judgements such that they may be solved. In this way, the weights of metrics in quantitative evaluation are objectively obtained, and the validity of the results can be testified. Weighted average percentile (WAP) is employed to aggregate different experts’ judgements into standard WAP scores. The Technique for Order Preference by Similarity to an Ideal Solution (TOPSIS) method is used to map quantitative results into experts’ judgements, while WAP scores are equal to the final closeness coefficients generated by the TOPSIS method. However, the closeness coefficients of TOPSIS rely on the weights of quantitative metrics. In this way, the mapping procedure is transformed into an optimization problem, and a genetic algorithm is introduced to search for the best weights. An academic journal ranking in the field of Supply Chain Management and Logistics (SCML) is used to test the validity obtained by mapping results. Four prominent ranking lists from Association of Business Schools, Australian Business Deans Council, German Academic Association for Business Research, and Comité National de la Recherche Scientifique were selected to represent different experts’ judgements. Twelve indices including IF, Eigenfactor Score (ES), H-index, Scimago Journal Ranking, and Source Normalized Impact per Paper (SNIP) were chosen for quantitative evaluation. The results reveal that the mapping results possess high validity for the relative error of experts’ judgements, the quantitative metrics are 43.4\%, and the corresponding best weights are determined in the meantime. Thus, some interesting findings are concluded. First, H-index, Impact Per Publication (IPP), and SNIP play dominant roles in the SCML journal’s quality evaluation. Second, all the metrics are positively correlated, although the correlation varies among metrics. For example, ES and NE are perfectly, positively correlated with each other, yet they have the lowest correlation with the other metrics. Metrics such as IF, IFWJ, 5-year IF, and IPP are highly correlated. Third, some highly correlated metrics may perform differently in quality evaluation, such as IPP and 5-year IF. Therefore, when mapping the quantitative metrics and experts’ judgements, academic fields should be treated distinctively.},
  archive      = {J_SOCO},
  author       = {Yuan, Lili and Li, Jianping and Li, Ruoyun and Lu, Xiaoli and Wu, Dengsheng},
  doi          = {10.1007/s00500-019-03837-3},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6227-6243},
  shortjournal = {Soft Comput.},
  title        = {Mapping the evaluation results between quantitative metrics and meta-synthesis from experts’ judgements: Evidence from the supply chain management and logistics journals ranking},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Product sales forecasting using macroeconomic indicators and
online reviews: A method combining prospect theory and sentiment
analysis. <em>SOCO</em>, <em>24</em>(9), 6213–6226. (<a
href="https://doi.org/10.1007/s00500-018-03742-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Macroeconomic conditions and users’ word of mouth have significant impacts on the purchase decisions of consumers, and they can be potentially used to conduct better sales forecasts, but study on this aspect is relatively scarce. In this paper, a novel method for forecasting product sales based on macroeconomic indicators and online reviews is developed. Firstly, an algorithm is given to select proper macroeconomic indicators to capture the long-term trends of sales. Subsequently, an algorithm for sentiment analysis is given to convert textual online reviews into numerical digits, and the word-of-mouth effect is calculated by incorporating the data related to online reviews (e.g., ratings, browsing numbers, and approval numbers). The sentiment index of word-of-mouth effect is measured based on the prospect theory, which can accurately reflect the phenomenon whereby negative reviews seriously affect the purchasing decisions of consumers. Further, according to the selected macroeconomic indicators and the obtained sentiment index, a logarithmic autoregressive model for product sales forecasting is constructed, and the model parameters are estimated by the Adam optimizer. Finally, experimental studies on forecasting the sales volume of the Audi A6L in the next three quarters are conducted. The experimental results show that the performance of the proposed method is significantly better than the existing methods.},
  archive      = {J_SOCO},
  author       = {Zhang, Chuan and Tian, Yu-Xin and Fan, Zhi-Ping and Liu, Yang and Fan, Ling-Wei},
  doi          = {10.1007/s00500-018-03742-1},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6213-6226},
  shortjournal = {Soft Comput.},
  title        = {Product sales forecasting using macroeconomic indicators and online reviews: A method combining prospect theory and sentiment analysis},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Impact of decision style on newsvendor ordering behaviors:
Mean anchoring, demand chasing and overconfidence. <em>SOCO</em>,
<em>24</em>(9), 6197–6212. (<a
href="https://doi.org/10.1007/s00500-018-03676-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prior experimental studies have shown that individuals’ actual ordering decisions significantly deviate from theoretically-proved optimums in newsvendor problems. Several ordering behaviors like mean anchoring, demand chasing, reference dependence, mental accounting and overconfidence have been demonstrated to be the main causes for such deviations. However, less attention has been focused on the impact of decision style on ordering behaviors. To address such challenging issue, we conduct a between-subjects experiment and compare decision results between different groups of individuals, who are characterized by their decision styles, i.e., rational style and experiential style, as well as their tendencies to the three typical behaviors, i.e., mean anchoring, demand chasing and overconfidence. We show that individuals with high rational style or low experiential style can make better inventory order decisions. Furthermore, decision style and profit margin conditions are demonstrated to actually affect individuals’ tendencies to mean anchoring, demand chasing and overconfidence, which subsequently affects their order decisions. More importantly, compared to mean anchoring and demand chasing, overconfidence is identified as a dominated factor in affecting the order decisions. This research sheds light on how to select right inventory managers and how to improve their ordering decision performance more efficiently through recognizing the impact of decision style and their behavioral tendencies in different profit margin conditions in the newsvendor problem.},
  archive      = {J_SOCO},
  author       = {Han, Xiaohua and Bian, Yiwen and Shang, Jennifer},
  doi          = {10.1007/s00500-018-03676-8},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6197-6212},
  shortjournal = {Soft Comput.},
  title        = {Impact of decision style on newsvendor ordering behaviors: Mean anchoring, demand chasing and overconfidence},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Soft computing in smart logistics. <em>SOCO</em>,
<em>24</em>(9), 6193–6195. (<a
href="https://doi.org/10.1007/s00500-020-04836-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SOCO},
  author       = {Li, Xiang and Ma, Hongguang},
  doi          = {10.1007/s00500-020-04836-5},
  journal      = {Soft Computing},
  number       = {9},
  pages        = {6193-6195},
  shortjournal = {Soft Comput.},
  title        = {Soft computing in smart logistics},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A simple two-phase differential evolution for improved
global numerical optimization. <em>SOCO</em>, <em>24</em>(8), 6151–6167.
(<a href="https://doi.org/10.1007/s00500-020-04750-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the evolutionary computing community, differential evolution (DE) is well appreciated as a simple yet versatile population-based, non-convex optimizer designed for continuous optimization problems. A simple two-phase DE algorithm is presented in this article, which aims to identify promising basins of attraction on a non-convex functional landscape in the first phase, and starting from those previously identified search regions, a success history-based switch parameter DE is employed to further fine tune the search process leading to the optima of the landscape. Our proposed framework has been validated on the well-known IEEE Congress on Evolutionary Computation (CEC) benchmark suites (CEC 2013, 2014 and 2017). Results of the proposed method are compared with corresponding CEC winners (SHADE for CEC 2013, L-SHADE for CEC 2014 and jSO for CEC 2017).},
  archive      = {J_SOCO},
  author       = {Ghosh, Arka and Das, Swagatam and Das, Asit Kr.},
  doi          = {10.1007/s00500-020-04750-w},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {6151-6167},
  shortjournal = {Soft Comput.},
  title        = {A simple two-phase differential evolution for improved global numerical optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An enhanced heuristic ant colony optimization for mobile
robot path planning. <em>SOCO</em>, <em>24</em>(8), 6139–6150. (<a
href="https://doi.org/10.1007/s00500-020-04749-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To realize a fast and efficient path planning for mobile robot in complex environment, an enhanced heuristic ant colony optimization (EH-ACO) algorithm is proposed. Four strategies are introduced to accelerate the ACO algorithm and optimize the final path. Firstly, the heuristic distance in the local visibility formula is improved by considering the heuristic distance from ant’s neighbor points to target. Secondly, a new pheromone diffusion gradient formula is designed, which emphasizes that pheromones left the path would spread into a region and the pheromone density would present a gradient distribution in the region. Thirdly, backtracking strategy is introduced to enable ants to find new path when their search is blocked. Finally, path merging strategy is designed to further obtain an optimal path. Simulations are carried out to verify each individual strategy, and comparisons are made with the state-of-the-art algorithms. The results show our proposed EH-ACO algorithm outperforms other algorithms in both optimality and efficiency, especially when the map is large and complex.},
  archive      = {J_SOCO},
  author       = {Gao, Wenxiang and Tang, Qing and Ye, Beifa and Yang, Yaru and Yao, Jin},
  doi          = {10.1007/s00500-020-04749-3},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {6139-6150},
  shortjournal = {Soft Comput.},
  title        = {An enhanced heuristic ant colony optimization for mobile robot path planning},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Generic extended multigranular sets for mixed and incomplete
information systems. <em>SOCO</em>, <em>24</em>(8), 6119–6137. (<a
href="https://doi.org/10.1007/s00500-020-04748-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Granular computing is a widely used computational paradigm nowadays. Particularly, within the rough set theory, granular computing plays a key role. In this paper, we propose a generic approach of rough sets, the granular extended multigranular sets (GEMS) for dealing with both mixed and incomplete information systems. Not only our proposal does use the traditional optimistic and pessimistic granulations with respect to single attributes, but also we introduce granulations with respect to attribute sets, as well as two new ways of granulating: the optimistic + pessimistic granulation and the pessimistic + optimistic granulation. In addition, we have developed a particular case of the proposed GEMS: the multigranular maximum similarity rough sets (MMSRS). We have proved some of the properties of the MMSRS, and we tested its effectiveness with respect to other existing granular rough sets models. The experimental results show the flexibility and the capabilities of the proposed model, while handling mixed and incomplete information systems.},
  archive      = {J_SOCO},
  author       = {Villuendas-Rey, Yenny and Yáñez-Márquez, Cornelio and Velázquez-Rodríguez, José Luis},
  doi          = {10.1007/s00500-020-04748-4},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {6119-6137},
  shortjournal = {Soft Comput.},
  title        = {Generic extended multigranular sets for mixed and incomplete information systems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fast clustering-based weighted twin support vector
regression. <em>SOCO</em>, <em>24</em>(8), 6101–6117. (<a
href="https://doi.org/10.1007/s00500-020-04746-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Construction of an effective model for regression to fit data samples with noise or outlier is a challenging work. In this paper, in order to reduce the influence of noise or outlier on regression and further improve the prediction performance of standard twin support vector regression (TSVR), we proposed a fast clustering-based weighted TSVR, termed as FC-WTSVR. First, we use a fast clustering algorithm to quickly classify samples into different categories based on their similarities. Secondly, to reflect the prior structural information and distinguish contributions of samples located at different positions to regression, we introduce the covariance matrix and weighted diagonal matrix into the primal problems of FC-WTSVR, respectively. Finally, to shorten the training time, we adopt the successive over-relaxation algorithm to solve the quadratic programming problems. The results show that the proposed FC-WTSVR can obtain better prediction performance and anti-interference capability than some state-of-the-art algorithms.},
  archive      = {J_SOCO},
  author       = {Gu, Binjie and Fang, Jianwen and Pan, Feng and Bai, Zhonghu},
  doi          = {10.1007/s00500-020-04746-6},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {6101-6117},
  shortjournal = {Soft Comput.},
  title        = {Fast clustering-based weighted twin support vector regression},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A rough set model based on fuzzifying neighborhood systems.
<em>SOCO</em>, <em>24</em>(8), 6085–6099. (<a
href="https://doi.org/10.1007/s00500-020-04744-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The notion of neighborhood systems is abstracted from the geometric notion of “near,” and it is primitive in the theory of topological spaces. Now, the notion of neighborhood systems has been extensively applied in the study of rough set. The notion of fuzzifying neighborhood systems is a fuzzification of the notion of neighborhood systems, and it is initially in the theory of fuzzifying topological spaces. Said briefly, each element x and each subset A of a universe are associated with a number in the unit interval, interpreted as the degree of A being a neighborhood of x. In this paper, a model of rough sets derived from fuzzifying neighborhood systems is developed. It is shown that this model unifies many well-known rough sets such as binary relation-based rough sets, covering-based rough sets and neighborhood system-based rough sets into one framework. The new rough sets are studied from two approaches: the constructive and axiomatic approaches. Furthermore, when the fuzzifying neighborhood system is serial, reflexive, unary, transitive, symmetric and Euclidean, then the corresponding rough sets are discussed and characterized, respectively. At last, the reduction theory of this rough set model is established.},
  archive      = {J_SOCO},
  author       = {Li, Lingqiang and Jin, Qiu and Yao, Bingxue and Wu, Jiachao},
  doi          = {10.1007/s00500-020-04744-8},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {6085-6099},
  shortjournal = {Soft Comput.},
  title        = {A rough set model based on fuzzifying neighborhood systems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fuzzy bezier splines with application to fuzzy functional
integral equations. <em>SOCO</em>, <em>24</em>(8), 6069–6084. (<a
href="https://doi.org/10.1007/s00500-020-04740-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present the description of fuzzy Bezier splines and as an application we propose an iterative numerical method for approximating the solution of fuzzy functional integral equations of Fredholm type. The convergence of the method is proved by providing an error estimate and it is tested on some numerical examples. The numerical stability regarding the choice of the first iteration is investigated.},
  archive      = {J_SOCO},
  author       = {Bica, Alexandru Mihai and Popescu, Constantin},
  doi          = {10.1007/s00500-020-04740-y},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {6069-6084},
  shortjournal = {Soft Comput.},
  title        = {Fuzzy bezier splines with application to fuzzy functional integral equations},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The zero-divisor graphs of MV-algebras. <em>SOCO</em>,
<em>24</em>(8), 6059–6068. (<a
href="https://doi.org/10.1007/s00500-020-04738-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we will introduce and study the zero-divisor graphs of MV-algebras. Let $$(A, \oplus , *, 0)$$ be an MV-algebra, and $$(A, \odot , 0)$$ be the associated semigroup. Define the zero-divisor graph $$\Gamma (A)$$ of A to be the simple graph with vertices $$V(\Gamma (A))={x\in A ~|~ (\exists ~y\in A {\setminus } {0}) ~x\odot y=0}$$, and edges $$E(\Gamma (A))={\text {the edge with ends } x~ \text {and } y ~|~ (x\ne y, x,y\in A) ~x\odot y=0}$$. We show that $$\Gamma (A)$$ is connected with $$diam(\Gamma (A))\le 3$$, where $$diam(\Gamma (A))$$ denotes the diameter of $$\Gamma (A)$$. Moreover, we characterize A with $$diam(\Gamma (A))$$ equal to 0, 1, 2 or 3. Finally, using the zero-divisor graph, we classify all MV-algebras of cardinality up to seven.},
  archive      = {J_SOCO},
  author       = {Gan, Aiping and Yang, Yichuan},
  doi          = {10.1007/s00500-020-04738-6},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {6059-6068},
  shortjournal = {Soft Comput.},
  title        = {The zero-divisor graphs of MV-algebras},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Wajsberg algebras arising from binary block codes.
<em>SOCO</em>, <em>24</em>(8), 6047–6058. (<a
href="https://doi.org/10.1007/s00500-019-04653-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we presented some connections between BCK commutative bounded algebras, MV-algebras, Wajsberg algebras and binary block codes. Using connections between these three algebras, we will associate to each of them a binary block code and, in some circumstances, we will prove that the converse is also true.},
  archive      = {J_SOCO},
  author       = {Flaut, Cristina and Vasile, Radu},
  doi          = {10.1007/s00500-019-04653-5},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {6047-6058},
  shortjournal = {Soft Comput.},
  title        = {Wajsberg algebras arising from binary block codes},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An improved MPPT control strategy based on incremental
conductance method. <em>SOCO</em>, <em>24</em>(8), 6039–6046. (<a
href="https://doi.org/10.1007/s00500-020-04723-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Photovoltaic cells efficiency can be effectively improved by maximum power point tracking (MPPT) technology. An improved MPPT control strategy is proposed to solve the current problems of poor convergence speed and accuracy of incremental conductance method. In this method, the P–U characteristic curve is divided into three sections: non-MPP sections, MPP-like section and MPP sections. In the non-MPP section, the constant voltage method is adopted to reduce the tracking time. In the MPP-like section, the incremental conductance method is adopted and its step size is improved, which effectively reduces the tracking time. In MPP section, particle swarm algorithm is adopted to improve tracking accuracy. Taking light intensity and temperature variation as examples, the proposed method and the traditional method are simulated respectively. Simulation results show that compared with the constant voltage method, the accuracy can be improved by more than 4\% when the temperature or light intensity is changed, while maintaining the tracking speed. Compared with the traditional incremental conductivity method, the method can reduce the tracking time by 33\% and improve the tracking accuracy by 1\% when the light intensity or temperature changes.},
  archive      = {J_SOCO},
  author       = {Shengqing, Li and Fujun, Li and Jian, Zheng and Wen, Chen and Donghui, Zhang},
  doi          = {10.1007/s00500-020-04723-z},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {6039-6046},
  shortjournal = {Soft Comput.},
  title        = {An improved MPPT control strategy based on incremental conductance method},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal control of DAB converter backflow power based on
phase-shifting strategy. <em>SOCO</em>, <em>24</em>(8), 6031–6038. (<a
href="https://doi.org/10.1007/s00500-020-04715-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to solve the problems such as high backflow power and current stress of bidirectional DC–DC converter under the traditional single phase-shifting control, an optimized dual phase-shifting control method is proposed. Compared with the conventional phase-shifting control, this method can not only reduce the loss of the converter but also increase the flexibility of the control and realize full voltage range transmission. Firstly, the working principle of dual phase-shifting control and the mathematical model of backflow power are analyzed in detail. Then, the different operating range of return power according to the range of transmission power and voltage transformation ratio are derived. So as to achieve the goal of optimal operation of return power in full mode, the optimal solution of local return power and the corresponding combination of phase-shifting angle are found out. Finally, the superiorities of the control strategy are verified by the experimental results.},
  archive      = {J_SOCO},
  author       = {Zeng, Jinhui and He, Yuan and Lan, Zheng and Yi, Zongao and Liu, Jing},
  doi          = {10.1007/s00500-020-04715-z},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {6031-6038},
  shortjournal = {Soft Comput.},
  title        = {Optimal control of DAB converter backflow power based on phase-shifting strategy},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). DroidDeep: Using deep belief network to characterize and
detect android malware. <em>SOCO</em>, <em>24</em>(8), 6017–6030. (<a
href="https://doi.org/10.1007/s00500-019-04589-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Android operating system and corresponding applications (app) are becoming increasingly popular, because the characteristics (open source, support the third-party app markets, etc.) of the Android platform, which cause the amazing pace of Android malware, poses a great threat to this platform. To solve this security issue, a comprehensive and accurate detection approach should be designed. Many research works dedicate to achieve this goal, including code analysis and machine learning methods, but these kinds of works cannot analyze large amount of Android applications comprehensively and effectively. We propose DroidDeep, which uses a Deep Belief Network model to classify Android malicious app. This proposed approach first collects 11 different kinds of static behavioral characteristics from a large amount of Android applications. Second, we design a Deep Belief Network algorithm to select unique behavioral characteristics from the collected static behavioral characteristics. Third, we detect zero-day Android malicious applications based on selected behavioral characteristics. We choose a dataset which mix with Android benign and malicious applications to evaluate the proposed method. The laboratory results show that the proposed method can obtain a higher detection accuracy (99.4\%). Moreover, the proposed approach costs 6 s in average when analyzing and detecting each Android application.},
  archive      = {J_SOCO},
  author       = {Su, Xin and Shi, Weiqi and Qu, Xilong and Zheng, Yi and Liu, Xuchong},
  doi          = {10.1007/s00500-019-04589-w},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {6017-6030},
  shortjournal = {Soft Comput.},
  title        = {DroidDeep: Using deep belief network to characterize and detect android malware},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Correction to: Leveraging cloud computing for the semantic
web: Review and trends. <em>SOCO</em>, <em>24</em>(8), 6015. (<a
href="https://doi.org/10.1007/s00500-020-04816-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unfortunately, the given names and the family name of the author Uchitha Jayawickrama are incorrectly published in the original article.},
  archive      = {J_SOCO},
  author       = {Adedugbe, Oluwasegun and Benkhelifa, Elhadj and Campion, Russell and Al-Obeidat, Feras and Bani Hani, Anoud and Jayawickrama, Uchitha},
  doi          = {10.1007/s00500-020-04816-9},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {6015},
  shortjournal = {Soft Comput.},
  title        = {Correction to: leveraging cloud computing for the semantic web: review and trends},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Leveraging cloud computing for the semantic web: Review and
trends. <em>SOCO</em>, <em>24</em>(8), 5999–6014. (<a
href="https://doi.org/10.1007/s00500-019-04559-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic and cloud computing technologies have become vital elements for developing and deploying solutions across diverse fields in computing. While they are independent of each other, they can be integrated in diverse ways for developing solutions and this has been significantly explored in recent times. With the migration of web-based data and applications to cloud platforms and the evolution of the web itself from a social, web 2.0 to a semantic, web 3.0 comes as the convergence of both technologies. While several concepts and implementations have been provided regarding interactions between the two technologies from existing research, without an explicit classification of the modes of interaction, it can be quite challenging to articulate the interaction modes; hence, building upon them can be a very daunting task. Hence, this research identifies and describes the modes of interaction between them. Furthermore, a “cloud-driven” interaction mode which focuses on fully maximising cloud computing characteristics and benefits for driving the semantic web is described, providing an approach for evolving the semantic web and delivering automated semantic annotation on a large scale to web applications.},
  archive      = {J_SOCO},
  author       = {Adedugbe, Oluwasegun and Benkhelifa, Elhadj and Campion, Russell and Al-Obeidat, Feras and Bani Hani, Anoud and Jayawickrama, Uchitha},
  doi          = {10.1007/s00500-019-04559-2},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {5999-6014},
  shortjournal = {Soft Comput.},
  title        = {Leveraging cloud computing for the semantic web: Review and trends},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An efficient virtual CPU scheduling in cloud computing.
<em>SOCO</em>, <em>24</em>(8), 5987–5997. (<a
href="https://doi.org/10.1007/s00500-019-04551-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In cloud computing, fine-grained virtual CPU scheduling techniques are essential in hiding physical resources from running applications and mitigating the decrease in performance upon virtualization. However, evaluating and predicting the behaviors of virtual processors is getting harder because of the diverse QoS requirements of cloud applications. In this paper, we propose a novel virtual CPU scheduling scheme to provide a high I/O performance for cloud applications. We present an evaluation function that evaluates the task characteristics of virtual machines by observing the amount of resource consumption of each virtual processor. Based on the evaluation function, the proposed scheduling scheme controls the priorities of virtual machines adaptively for fair distribution in handling I/O requests. Because our scheme evaluates both CPU-intensiveness and I/O-intensiveness of virtual machines, it provides high performance in terms of responsiveness even for various types of tasks. We implemented and experimented the proposed scheme on a virtual machine monitor. The experimental results showed that the proposed scheme increases the responsiveness and I/O bandwidth of virtual machines.},
  archive      = {J_SOCO},
  author       = {Jang, Joonhyouk and Jung, Jinman and Hong, Jiman},
  doi          = {10.1007/s00500-019-04551-w},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {5987-5997},
  shortjournal = {Soft Comput.},
  title        = {An efficient virtual CPU scheduling in cloud computing},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Weakly supervised facial expression recognition via
transferred DAL-CNN and active incremental learning. <em>SOCO</em>,
<em>24</em>(8), 5971–5985. (<a
href="https://doi.org/10.1007/s00500-019-04530-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, facial expression recognition (FER) has becoming a growing topic in computer vision with promising applications on virtual reality and human–robot interaction. Due to the influence of illumination, individual differences, attitude variation, etc., facial expression recognition with robust accuracy in complex environment is still an unsolved problem. Meanwhile, with the wide use of social communication, massive data are uploaded to the Internet; the effective utilization of those data is still a challenge due to noisy label phenomenon in the study of FER. To resolve the above-mentioned problems, firstly, a double active layer-based CNN is established to recognize the facial expression with high accuracy by learning robust and discriminative features from the data, which could enhance the robustness of network. Secondly, an active incremental learning method was utilized to tackle the problem of using Internet data. During the training phase, a two-stage transfer learning method is explored to transfer the relative information from face recognition to FER task to alleviate the inadequate training data in deep convolution network. Besides, in order to make better use of facial expression data from Web site and further improve the FER accuracy, Unconstrained Facial Expression Database from Web site database is built in this paper. Extensive experiments performed on two public facial expression recognition databases FER 2013 and SFEW 2.0 have demonstrated that the proposed scheme outperforms the state-of-the-art methods, which could achieve 67.08\% and 51.90\%, respectively.},
  archive      = {J_SOCO},
  author       = {Xu, Ying and Liu, Jian and Zhai, Yikui and Gan, Junying and Zeng, Junying and Cao, He and Scotti, Fabio and Piuri, Vincenzo and Labati, Ruggero Donida},
  doi          = {10.1007/s00500-019-04530-1},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {5971-5985},
  shortjournal = {Soft Comput.},
  title        = {Weakly supervised facial expression recognition via transferred DAL-CNN and active incremental learning},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Tactical maneuver trajectory optimization for unmanned
combat aerial vehicle using improved differential evolution.
<em>SOCO</em>, <em>24</em>(8), 5959–5970. (<a
href="https://doi.org/10.1007/s00500-019-04522-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous air combat is an inevitable trend in the development of unmanned combat aerial vehicle (UCAV) equipment. Its purpose is to generate maneuver trajectory so that UCAVs obtain better air combat situation. Therefore, aiming to solve a tactical maneuver trajectory optimization problem for an UCAV in autonomous air combat, this paper proposed a novel method by converting the problem to an optimization problem of characteristic parameters. On the one hand, the paper analyses the tactical maneuver trajectory and combines the situation evaluation model to construct a tactical maneuver trajectory optimization function based on characteristic parameters. On the other hand, multi-population rotation strategy differential evolution (MPRDE) algorithm is designed to search for the optimal characteristic parameters. The experimental results showed that the MPRDE algorithm has outstanding performance in convergence speed, global optimization ability and robustness, and the method based on characteristic parameters could effectively and quickly represent the tactical maneuver trajectory of UCAV by using MPRDE. Meanwhile, it satisfies the real-time requirements for generating tactical manoeuvring trajectory for UCAV autonomous air combat.},
  archive      = {J_SOCO},
  author       = {Huang, Hanqiao and Dong, Kangsheng and Yan, Tian and Han, Bo},
  doi          = {10.1007/s00500-019-04522-1},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {5959-5970},
  shortjournal = {Soft Comput.},
  title        = {Tactical maneuver trajectory optimization for unmanned combat aerial vehicle using improved differential evolution},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Nickel foam surface defect detection based on
spatial-frequency multi-scale MB-LBP. <em>SOCO</em>, <em>24</em>(8),
5949–5957. (<a
href="https://doi.org/10.1007/s00500-019-04513-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {According to the nickel foam surface defect images with the typical characteristics of complex geometry and texture distribution, a nickel foam surface defect detection method based on spatial-frequency multi-scale block local binary pattern is proposed. First, nonsubsampled contourlet is used to carry out foam nickel image multi-scale decomposition, and therefore, low-frequency sub-band images and high-frequency sub-band images are obtained. The multi-scale block local binary pattern is then used to extract the feature histogram vectors of each block region of low- and high-frequency sub-bands, and the histogram feature vectors of the whole image after cascade are formed. The kernel principal component analysis and support vector machine are adopted to reduce the dimension of the feature histogram vectors and used for the defect classification. Experimental results show that the proposed method of feature extraction can extract more detailed texture information, and the average recognition rate reaches to 90\%, which meets an enterprise’s needs.},
  archive      = {J_SOCO},
  author       = {Cao, Bin-fang and Li, Jian-qi and Qiao, Nao-sheng},
  doi          = {10.1007/s00500-019-04513-2},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {5949-5957},
  shortjournal = {Soft Comput.},
  title        = {Nickel foam surface defect detection based on spatial-frequency multi-scale MB-LBP},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Random orthocenter strategy in interior search algorithm and
its engineering application. <em>SOCO</em>, <em>24</em>(8), 5933–5948.
(<a href="https://doi.org/10.1007/s00500-019-04498-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Determining how to improve the global search ability and adaptability of an algorithm without reducing the convergence speed is still a major challenge for most meta-heuristic algorithms. This paper proposes a new random orthocenter strategy combined with a Levy flight strategy to improve the interior search algorithm (ISA). The random orthocenter strategy is to randomly select a point outside the element and mirror to form a triangle and to solve the image of the element based on the orthocentre, which offsets the unique control parameters in the algorithm. The Levy flight strategy further prevents the algorithm from falling into local optimization. Thirteen benchmark functions and two engineering problems are selected for simulation tests. The experimental results show that the random orthocenter ISA significantly improves the global optimization and adaptability and has advantages on application in complex practical engineering optimization problems.},
  archive      = {J_SOCO},
  author       = {Han, Bo and Huang, Changqiang and Tang, Shangqin and Xuan, Yongbo and Zhang, Zhuoran and Huan, Zhou},
  doi          = {10.1007/s00500-019-04498-y},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {5933-5948},
  shortjournal = {Soft Comput.},
  title        = {Random orthocenter strategy in interior search algorithm and its engineering application},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Scalable influence maximization based on influential seed
successors. <em>SOCO</em>, <em>24</em>(8), 5921–5931. (<a
href="https://doi.org/10.1007/s00500-019-04483-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Influence maximization is a fundamental problem, which is aimed to specify a small subset of individuals as the seed set to influence the individuals as much as possible under a certain influence cascade model. Most existing works on influence maximization assume that all of the seeds would like to spread the designated information. However, in reality, a small number of the seeds may be unwilling to spread this information, which may waste unnecessary resources. Thus, it is important for us to find a series of successors to replace these useless seeds. To deal with this challenge, we put forward a new method, which utilizes the degree discount algorithm to find the original seed set firstly. Moreover, we design a candidate selection strategy to select a large number of candidate seeds combining the largest degree nodes and the neighbors of removed nodes. At last, by optimizing the combination of original seeds and candidate seeds, our algorithm can select the combination of the most influential seeds by simulated annealing method. Furthermore, exhaustive experiments demonstrate that our proposal performs better than the other conventional algorithms in the aspects of influence spread and running time.},
  archive      = {J_SOCO},
  author       = {Chengai, Sun and Weinan, Niu and Liqing, Qiu and Liangyu, Lv},
  doi          = {10.1007/s00500-019-04483-5},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {5921-5931},
  shortjournal = {Soft Comput.},
  title        = {Scalable influence maximization based on influential seed successors},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Indoor li-DAR 3D mapping algorithm with semantic-based
registration and optimization. <em>SOCO</em>, <em>24</em>(8), 5909–5920.
(<a href="https://doi.org/10.1007/s00500-019-04482-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The method proposed in this paper using a two-dimensional Li-DAR which moves in six degrees of freedom to construct a three-dimensional point cloud map of the laser traversed environment which includes point cloud feature extraction and registration, global optimization and back-end optimization algorithm, and the constructed 3D point cloud map and the laser trajectory are given. First, the hardware platform of the simultaneous localization and 3D mapping system based on Li-DAR is introduced; then, a semantic-based point cloud feature extraction algorithm is proposed according to the scale invariance of the laser point cloud, the point clouds are registered using the equivalence relation of triangles, and the motion of the laser is calculated between two consecutive scans. Then, a global optimization algorithm is proposed to reduce the cumulative error caused by inter-frame registration. The general map optimization is used to optimize the pose of the Li-DAR, and the comparison results are given. Finally, the three-dimensional point cloud of extraction, registration, laser trajectory, as well as the final 3D point cloud is given. Experimental results show that the proposed Li-DAR-based SLAM system can accurately estimate the trajectory of the Li-DAR and construct a high-quality 3D point cloud in real time. The relative accuracy in the indoor environment is about 2\%.},
  archive      = {J_SOCO},
  author       = {Sun, Wei and Liu, Lixin and Ji, Xiaofeng and Sun, Changhao},
  doi          = {10.1007/s00500-019-04482-6},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {5909-5920},
  shortjournal = {Soft Comput.},
  title        = {Indoor li-DAR 3D mapping algorithm with semantic-based registration and optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Small-scale moving target detection in aerial image by deep
inverse reinforcement learning. <em>SOCO</em>, <em>24</em>(8),
5897–5908. (<a
href="https://doi.org/10.1007/s00500-019-04404-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It proposes a deep inverse reinforcement learning method for slow and weak moving targets detection in aerial video. Differential gray images of adjacent frames are used as the network model input, and the feature network layer extracts the candidate moving target regions through the multi-layer convolution. The candidate target information is used as the initial layer of the policy network. The expert trajectory is used to adjust and optimize the feature convolution network model and the policy fully connected network model to realize the training the reward return function and the expert policy. In the stage of autonomous improvement policy, the policy model is re-optimized by unmarked aerial video, and deep inverse reinforcement learning and nonlinear policy network are used to make decision on moving target position and size information. The target size of the multi-group aerial video test set is 10 * 10 pixels. Experimental results show that the proposed algorithm has the advantage of the nonlinear policy of the neural network compared with the traditional moving target detection algorithm, and the detection result is more accurate. At the same time, compared with the traditional marginal programming (MMP) method and the structured classification based (SCIRL) method, the proposed algorithm shows obvious advantages in the accuracy of aerial video moving target detection.},
  archive      = {J_SOCO},
  author       = {Sun, Wei and Yan, Dashuai and Huang, Jie and Sun, Changhao},
  doi          = {10.1007/s00500-019-04404-6},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {5897-5908},
  shortjournal = {Soft Comput.},
  title        = {Small-scale moving target detection in aerial image by deep inverse reinforcement learning},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cloud-assisted secure biometric identification with
sub-linear search efficiency. <em>SOCO</em>, <em>24</em>(8), 5885–5896.
(<a href="https://doi.org/10.1007/s00500-019-04401-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing has been one of the critical solutions to reduce heavy storage and computation burden of biometric identification. To protect the privacy of biometric data against untrusted cloud servers, outsourced biometric databases are usually encrypted by users. Performing biometric identification over encrypted data without revealing privacy to cloud servers attracts more and more attention. Several secure biometric identification solutions have been proposed to solve this challenging problem. However, these schemes still suffer from various limitations, such as low search efficiency and heavy computation burden on users. In this paper, we propose a novel cloud-assisted biometric identification scheme based on the asymmetric scalar-product preserving encryption (ASPE) and spatial data structures such as the R-tree index, which simultaneously achieves sub-linear search efficiency and low computation burden on users. Specifically, we construct an R-tree index on the biometric dataset and encrypt the index with ASPE. Then we modify the original search algorithm in the R-tree index and design a secure search algorithm based on ASPE to find the nearest neighbor result over the encrypted R-tree index. Through theoretical analysis and extensive experiments, we demonstrate the effectiveness and efficiency of our proposed approach.},
  archive      = {J_SOCO},
  author       = {Zhu, Youwen and Li, Xingxin and Wang, Jian and Li, Jing},
  doi          = {10.1007/s00500-019-04401-9},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {5885-5896},
  shortjournal = {Soft Comput.},
  title        = {Cloud-assisted secure biometric identification with sub-linear search efficiency},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Adaptive wavelet transform model for time series data
prediction. <em>SOCO</em>, <em>24</em>(8), 5877–5884. (<a
href="https://doi.org/10.1007/s00500-019-04400-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of cloud computing and big data, stock prediction has become a hot topic of research. In the stock market, the daily trading activities of stocks are carried out at different frequencies and cycles, resulting in a multi-frequency trading mode of stocks , which provides useful clues for future price trends: short-term stock forecasting relies on high-frequency trading data, while long-term forecasting pays more attention to low-frequency data. In addition, stock series have strong volatility and nonlinearity, so stock forecasting is very challenging. In order to explore the multi-frequency mode of the stock , this paper proposes an adaptive wavelet transform model (AWTM). AWTM integrates the advantages of XGboost algorithm, wavelet transform, LSTM and adaptive layer in feature selection, time–frequency decomposition, data prediction and dynamic weighting. More importantly, AWTM can automatically focus on different frequency components according to the dynamic evolution of the input sequence, solving the difficult problem of stock prediction. This paper verifies the performance of the model using S&amp;P500 stock dataset. Compared with other advanced models, real market data experiments show that AWTM has higher prediction accuracy and less hysteresis.},
  archive      = {J_SOCO},
  author       = {Liu, Xin and Liu, Hui and Guo, Qiang and Zhang, Caiming},
  doi          = {10.1007/s00500-019-04400-w},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {5877-5884},
  shortjournal = {Soft Comput.},
  title        = {Adaptive wavelet transform model for time series data prediction},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Weighted-fusion feature of MB-LBPUH and HOG for facial
expression recognition. <em>SOCO</em>, <em>24</em>(8), 5859–5875. (<a
href="https://doi.org/10.1007/s00500-019-04380-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Obtaining a useful and discriminative feature for facial expression recognition (FER) is a hot research topic in computer vision. In this paper, we propose a novel facial expression representation for FER. Firstly, we select the appropriate parameter of multi-scale block local binary pattern uniform histogram (MB-LBPUH) operator to filter the facial images for representing the holistic structural features. Then, normalizing the filtered images into a uniform basis reduces the computational complexity and remains the full information. An MB-LBPUH feature and a HOG feature are concatenated to fuse a new feature representation for characterizing facial expressions. At the same time, weighting the MB-LBPUH feature can remove the data unbalance from a fusion feature. The weighted-fusion feature reflects not only global facial expressions structure patterns but also characterizes local expression texture appearance and shape. Finally, we utilize principal component analysis for dimensionality reduction and employ support vector machine to classification. Experimental results demonstrate that the proposed algorithm exhibits superior performance compared with the existing algorithms on JAFFE, CK+, and BU-3DFE datasets.},
  archive      = {J_SOCO},
  author       = {Wang, Yan and Li, Ming and Zhang, Congxuan and Chen, Hao and Lu, Yuming},
  doi          = {10.1007/s00500-019-04380-x},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {5859-5875},
  shortjournal = {Soft Comput.},
  title        = {Weighted-fusion feature of MB-LBPUH and HOG for facial expression recognition},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). RETRACTED ARTICLE: Research on north gulf distributed big
data submarine 3D terrain computing system based on remote sensing and
multi-beam. <em>SOCO</em>, <em>24</em>(8), 5847–5857. (<a
href="https://doi.org/10.1007/s00500-019-04371-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {North Gulf is China’s important sea route to Asia and Europe, and the seabed is rich in resources. For various reasons, the detection and mapping of submarine terrain are blank. The traditional multi-beam measurement method has high accuracy but uneven spatial distribution. Although the detection line process has high sampling and measurement accuracy, there is a large blank area between adjacent routes, which is difficult to achieve full-scale large area measurement due to environmental, time and budget constraints. On the other hand, the accuracy of the remote sensing inversion depth method is not high, but it can achieve a wide range of coverage, which is characterized by low cost, short cycle and convenient dynamic monitoring. This paper takes North Gulf as the research area, uses remote sensing data to construct the seabed topography, uses multi-beam data for checksum correction and uses distributed computing technology to distribute big data in different computing nodes, and the data are refined and reconstructed in three dimensions to form a 3D seabed topography. The method improves the efficiency and accuracy of multi-beam data processing and can construct a large area, high-resolution submarine DEM and realize database management.},
  archive      = {J_SOCO},
  author       = {Dong, Yuan and Hu, BaoQing and Zhang, ShiLun and Huang, YuanLin and Nong, GuoCai and Xin, Han},
  doi          = {10.1007/s00500-019-04371-y},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {5847-5857},
  shortjournal = {Soft Comput.},
  title        = {RETRACTED ARTICLE: Research on north gulf distributed big data submarine 3D terrain computing system based on remote sensing and multi-beam},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An attention mechanism and multi-granularity-based bi-LSTM
model for chinese q&amp;a system. <em>SOCO</em>, <em>24</em>(8),
5831–5845. (<a
href="https://doi.org/10.1007/s00500-019-04367-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural language processing (NLP) is one of the key techniques in intelligent question-answering (Q&amp;A) systems. Although recurrent neural networks and long short-term memory (LSTM) networks exhibit obvious advantages on well-known English Q&amp;A datasets, they still suffer from several defects including indeterminateness, polysemy and the lack of changing morphology in Chinese, which results in complex NLP on large and diverse Chinese Q&amp;A datasets. In this paper, we first analyze limitations of applying LSTM and bidirectional LSTM (Bi-LSTM) models to noisy Chinese Q&amp;A datasets. Then, we focus on integrating attention mechanisms and multi-granularity word segmentation into Bi-LSTM and propose an attention mechanism and multi-granularity-based Bi-LSTM model (AM–Bi-LSTM) which combines the improved attention mechanism with a novel processing of multi-granularity word segmentation to handle the complex NLP in Chinese Q&amp;A datasets. Furthermore, similarity of questions and answers is formulated to implement the quantitative computation which helps to achieve better performance in Chinese Q&amp;A systems. Finally, we verify the proposed model on a noisy Chinese Q&amp;A dataset. The experimental results demonstrate that the novel AM–Bi-LSTM model achieves significant improvement on evaluation metrics of accuracy, mean average precision and so on. Moreover, the experimental results indicate that the novel AM–Bi-LSTM model outperforms baseline methods and other LSTM-based models.},
  archive      = {J_SOCO},
  author       = {Yu, Xiao-mei and Feng, Wen-zhi and Wang, Hong and Chu, Qian and Chen, Qi},
  doi          = {10.1007/s00500-019-04367-8},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {5831-5845},
  shortjournal = {Soft Comput.},
  title        = {An attention mechanism and multi-granularity-based bi-LSTM model for chinese Q&amp;A system},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). MABAC method for multiple attribute group decision making
under picture 2-tuple linguistic environment. <em>SOCO</em>,
<em>24</em>(8), 5819–5829. (<a
href="https://doi.org/10.1007/s00500-019-04364-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we extend multi-attributive border approximation area comparison (MABAC) approach to the multiple attribute group decision making with picture 2-tuple linguistic numbers. We review the concept of picture 2-tuple linguistic sets and introduce its corresponding score function, accuracy function, and operational laws. In addition, we propose two aggregation operators of picture 2-tuple linguistic numbers and then develop a method by combining traditional MABAC model with the overall picture 2-tuple linguistic evaluation information. Our proposed method is increasingly accurate and valid even when the conflicting attributes are considered. We also provide a numerical instance for assessing and selecting the renewable energy power generation project to demonstrate the efficacy of our novel model. Finally, we compare our proposed approach with other traditional operators to further show its benefits.},
  archive      = {J_SOCO},
  author       = {Zhang, Siqi and Wei, Guiwu and Alsaadi, Fuad E. and Hayat, Tasawar and Wei, Cun and Zhang, Zuopeng},
  doi          = {10.1007/s00500-019-04364-x},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {5819-5829},
  shortjournal = {Soft Comput.},
  title        = {MABAC method for multiple attribute group decision making under picture 2-tuple linguistic environment},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). RobNet: Real-time road-object 3D point cloud segmentation
based on SqueezeNet and cyclic CRF. <em>SOCO</em>, <em>24</em>(8),
5805–5818. (<a
href="https://doi.org/10.1007/s00500-019-04355-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to realize real-time 3D environment perception of UAVs and autopilot in low-altitude complex road scenes, a neural network model RobNet based on SqueezeNet and cyclic CRF for real-time 3D point cloud segmentation is proposed to segment the road objects in real time. Firstly, the unordered, scattered 3D point cloud data are preprocessed into a standard data format similar to an image by a spherical mapping method. Then, at the macro-level of the model design, the SqueezeNet network with the residual connection optimization is selected as the basic network of the model, and then, the conditional random field (CRF) algorithm which is processed into the cyclic network structure is used to refine the segmentation result. Finally, the construction of the basic network, the cyclic network and the network parameter settings in the model is elaborated at the micro-level. The experimental results show that the RobNet model proposed in this paper can segment the target in the road scene better. The segmentation callback rate of the three types of vehicles, pedestrians and cyclists is increased by 28, 2 and 17\%, respectively, compared with the VoxelNet network. The higher callback rate is in line with the safe movement specifications for drones and autonomous driving. At the same time, the proposed model parameters are small, 98.5\% smaller than the classic network AlexNet, and are easy to deploy on a platform with limited computing resources. The RobNet model in the Robot Operating System (ROS) framework engineering deployment and implementation experimental data shows that the model meets the real-time and stability requirements of the drone and automatic driving application, engineering code can run in real time at 12 Hz, the standard deviation of each frame’s running time is around 4.5 ms.},
  archive      = {J_SOCO},
  author       = {Sun, Wei and Zhang, Zhenhao and Huang, Jie},
  doi          = {10.1007/s00500-019-04355-y},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {5805-5818},
  shortjournal = {Soft Comput.},
  title        = {RobNet: Real-time road-object 3D point cloud segmentation based on SqueezeNet and cyclic CRF},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Research on key issues of gesture recognition for artificial
intelligence. <em>SOCO</em>, <em>24</em>(8), 5795–5803. (<a
href="https://doi.org/10.1007/s00500-019-04342-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gesture recognition has become a hot spot in the direction of artificial intelligence and has great research significance. At present, some classical algorithms, such as the neural network method and the hidden Markov method, have the disadvantages of large computational complexity and long training time. This paper proposes the support vector machine (SVM) algorithm to realize gesture recognition. In order to make the recognition more accurate, SVM is combined with the principal component analysis (PCA) algorithm, performs the dimensionality reduction on the gesture image to form the PCA + SVM algorithm for gesture recognition. At the same time, a new dynamic gesture recognition processing method is proposed, and its effectiveness is proved by various methods. Using open-source computer vision library (OPENCV), the algorithm is simulated on visual studio 2015 environment. The results show that the algorithm has an excellent recognition effect.},
  archive      = {J_SOCO},
  author       = {Mo, Taiping and Sun, Peng},
  doi          = {10.1007/s00500-019-04342-3},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {5795-5803},
  shortjournal = {Soft Comput.},
  title        = {Research on key issues of gesture recognition for artificial intelligence},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Development and assessment of a haptic-enabled holographic
surgical simulator for renal biopsy training. <em>SOCO</em>,
<em>24</em>(8), 5783–5794. (<a
href="https://doi.org/10.1007/s00500-019-04341-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a high-immersive surgical training system for renal biopsy using holographic demonstration and haptic feedback is presented to push the limitation of virtual medical training development. Proposed system is including: holographic visual rendering pipeline reconstructed by the patient-specific CT images; haptic rendering pipeline implemented by the dual-hands 6-DOF haptic devices connected with surgical instruments of image guide and immersive 3D display learning operating room environment. Twenty-four medical students and eight experienced thoracic surgeons from the Yunnan First People’s Hospital are invited to evaluate our holographic-based training system through the subjective and objective assessment test, respectively. Experiment result from the face, content, improvement, and construct evaluations demonstrated a high performance than the existing VR-based trainer, especially the puncture accuracy of medical students’ group, was improved by 30.8\% after training.},
  archive      = {J_SOCO},
  author       = {Guo, Zhaoxiang and Tai, Yonghang and Qin, Zhibao and Huang, Xiaoqiao and Li, Qiong and Peng, Jun and Shi, Junsheng},
  doi          = {10.1007/s00500-019-04341-4},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {5783-5794},
  shortjournal = {Soft Comput.},
  title        = {Development and assessment of a haptic-enabled holographic surgical simulator for renal biopsy training},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A dynamic trust model in internet of things. <em>SOCO</em>,
<em>24</em>(8), 5773–5782. (<a
href="https://doi.org/10.1007/s00500-019-04319-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Indicating trust or distrust of a node is a key issue in the trust management of IoT. However, there are some challenges for the management with anonymous nodes, inaccurate communication, etc. Due to huge number of nodes in IoT, one of the possible solutions is predicting trust and distrust values. In this paper, we propose a dynamic trust model based on direct and indirect trust computation, and the most important part of a model, trust prediction. The prediction method mainly depends on the combination of exponential smoothing and a Markov chain. We employ exponential smoothing to predict trustiness and a Markov chain to fix the deviation of the prediction. To test our scheme, we create a simulation to evaluate its performance and effectiveness. The simulation results are encouraging.},
  archive      = {J_SOCO},
  author       = {Wang, Eric Ke and Chen, Chien-Ming and Zhao, Dongning and Ip, Wai Hung and Yung, Kai Leung},
  doi          = {10.1007/s00500-019-04319-2},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {5773-5782},
  shortjournal = {Soft Comput.},
  title        = {A dynamic trust model in internet of things},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A watermarking scheme based on rotating vector for image
content authentication. <em>SOCO</em>, <em>24</em>(8), 5755–5772. (<a
href="https://doi.org/10.1007/s00500-019-04318-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-fragile watermarking technique for digital image, as a technology for content authentication, aims at telling malicious tampering from content-preserving operators. However, with the resolution of imaging sensors increasing and the explosive growth of digital images on the internet, before authorization, watermarked images tend to undergo such double-compression environments as: first compression (JPEG/JPEG2000) for release, decoding, application processing (conventional signal processing such as nosing, filtering, cropping, and scaling/security attack/malicious tampering), and second compression (JPEG2000/JPEG) for release again. In this paper, based on rotating vector, we propose a novel watermarking expression method that can describe carrier semantics to a certain extent and its modulation algorithm for digital image, and analyze the stability of the watermarked data theoretically. Then, a semi-fragile watermarking scheme is proposed for image content authentication to effectively distinguish malicious content manipulation from content-preserving operations in the double-compression application environment, which expands the application scope of content authentication based on watermarking technology.},
  archive      = {J_SOCO},
  author       = {Fu, Jianjing and Mao, Jiafa and Xue, Dawen and Chen, Deren},
  doi          = {10.1007/s00500-019-04318-3},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {5755-5772},
  shortjournal = {Soft Comput.},
  title        = {A watermarking scheme based on rotating vector for image content authentication},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Application of kalman filter to model-based prognostics for
solenoid valve. <em>SOCO</em>, <em>24</em>(8), 5741–5753. (<a
href="https://doi.org/10.1007/s00500-019-04311-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solenoid valves (SVs) are electromechanical components, which are used as actuators in various application environments and play crucial roles in control systems, and their breakdown may result in a system crash. Therefore, this paper explores a Kalman filter (KF)-based method to predict the remaining useful life (RUL) of SVs, so that the SVs can be replaced or maintained before their failure bringing a catastrophic consequence for engineering system. In this paper, a degradation signal is extracted from the driven current, which can be monitored conveniently with a non-contact current sensor. Based on an empirical linear degradation model, the KF is adopted to track the degradation state and the degradation rate and to capture the uncertainties. The Monte Carlo sampling and kernel density estimation are used to propagate the uncertainties and estimate the probability distribution of RUL, respectively. To verify our methods, a degradation experiment is designed. The experiment results show that the degradation signal extracted from the driven current can indeed reflect the degradation state of SVs. By comparing the proposed method with other state of the arts prognostic approaches, it shows that the proposed KF method preforms better and has a higher prediction accuracy than other methods.},
  archive      = {J_SOCO},
  author       = {Tang, Xilang and Xiao, Mingqing and Hu, Bin},
  doi          = {10.1007/s00500-019-04311-w},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {5741-5753},
  shortjournal = {Soft Comput.},
  title        = {Application of kalman filter to model-based prognostics for solenoid valve},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Using the DEMATEL model to expose core causal items of
LibQUAL for improving library service quality: From the perspective of
big data. <em>SOCO</em>, <em>24</em>(8), 5729–5739. (<a
href="https://doi.org/10.1007/s00500-019-04308-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to expose the “causal core” items of LibQUAL+™ from professional librarians’ views. The objective is to prioritize limited resources to improve the most influential factors affecting the library service quality. Valid LibQUAL+™ questionnaires from thirty-two university library administrators in Taiwan are collected for analysis. The Decision Making Trial and Evaluation Laboratory (DEMATEL) technique is employed to build causal maps that can clearly locate the twenty-two LibQUAL+™ question items into four quadrants: core causal, inferior causal, inferior effect, and core effect. The DEMATEL causal maps can facilitate the library administrators to prioritize the limited resources for improvement. Five “causal core” items of LibQUAL+™ are identified, including the library staff should be motivated with high willingness to help users and giving users individual attention; the library amenities should provide a quiet space for individual activities; the library Web site should allow users to locate and access information easily and individually. The survey data represent what professional librarians’ think of the service quality in their libraries. The findings may serve as useful guidance to allocate limited budgets for library service improvement. This paper has pinpointed the “core causal” items of LibQUAL+™ for advancing library administration. It is the first of its kind in the literature to use the DEMATEL technique to identify the “core causal” items of LibQUAL+™ for improving library service quality.},
  archive      = {J_SOCO},
  author       = {Wu, Chia-Huei and Yuan, Yu-Hsi and Tsai, Sang-Bing},
  doi          = {10.1007/s00500-019-04308-5},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {5729-5739},
  shortjournal = {Soft Comput.},
  title        = {Using the DEMATEL model to expose core causal items of LibQUAL for improving library service quality: From the perspective of big data},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An empirical study on effects of electronic word-of-mouth
and internet risk avoidance on purchase intention: From the perspective
of big data. <em>SOCO</em>, <em>24</em>(8), 5713–5728. (<a
href="https://doi.org/10.1007/s00500-019-04300-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigated the influence of the usefulness of E-word-of-mouth (eWOM) and Internet risk avoidance on consumers’ purchase intention. In particular, because consumers typically exhibit gender difference in their purchase intentions, this study adopted a quasi-experimental design and developed four situational questionnaires on gender difference. The objective of this study was to understand the influence of related factors on consumers’ hotel reservation intention. A total of 512 effective data were collected via online questionnaires. The results showed that eWOM and Internet risk avoidance were significantly and positively correlated with consumers’ purchase intention, and eWOM had higher predictive power than Internet risk avoidance did. The results reveal that both male and female respondents emphasized hotel facilities, and their purchase intention was positively influenced by related positive comments. However, female respondents paid more attention to hotel service quality than male respondents did.},
  archive      = {J_SOCO},
  author       = {Yuan, Yu-Hsi and Tsao, Sheng-Hao and Chyou, Jiin-Tian and Tsai, Sang-Bing},
  doi          = {10.1007/s00500-019-04300-z},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {5713-5728},
  shortjournal = {Soft Comput.},
  title        = {An empirical study on effects of electronic word-of-mouth and internet risk avoidance on purchase intention: From the perspective of big data},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). IoT transaction processing through cooperative concurrency
control on fog–cloud computing environment. <em>SOCO</em>,
<em>24</em>(8), 5695–5711. (<a
href="https://doi.org/10.1007/s00500-019-04220-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In cloud–fog environments, the opportunity to avoid using the upstream communication channel from the clients to the cloud server all the time is possible by fluctuating the conventional concurrency control protocols. Through the present paper, the researcher aimed to introduce a new variant of the optimistic concurrency control protocol. Through the deployment of augmented partial validation protocol, IoT transactions that are read-only can be processed at the fog node locally. For final validation, update transactions are the only ones sent to the cloud. Moreover, the update transactions go through partial validation at the fog node which makes them more opportunist to commit at the cloud. This protocol reduces communication and computation at the cloud as much as possible while supporting scalability of the transactional services needed by the applications running in such environments. Based on numerical studies, the researcher assessed the partial validation procedure under three concurrency protocols. The study’s results indicate that employing the proposed mechanism shall generate benefits for IoT users. These benefits are obtained from transactional services. We evaluated the effect of deployment the partial validation at the fog node for the three concurrency protocols, namely AOCCRBSC, AOCCRB and STUBcast. We performed a set of intensive experiments to compare the three protocols with and without such deployment. The result reported a reduction in miss rate, restart rate and communication delay in all of them. The researcher found that the proposed mechanism reduces the communication delay significantly. They found that the proposed mechanism shall enable low-latency fog computing services of the IoT applications that are a delay sensitive.},
  archive      = {J_SOCO},
  author       = {Al-Qerem, Ahmad and Alauthman, Mohammad and Almomani, Ammar and Gupta, B. B.},
  doi          = {10.1007/s00500-019-04220-y},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {5695-5711},
  shortjournal = {Soft Comput.},
  title        = {IoT transaction processing through cooperative concurrency control on fog–cloud computing environment},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Core-reviewer recommendation based on pull request topic
model and collaborator social network. <em>SOCO</em>, <em>24</em>(8),
5683–5693. (<a
href="https://doi.org/10.1007/s00500-019-04217-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pull Request (PR) is a major contributor to external developers of open-source projects in GitHub. PR reviewing is an important part of open-source software developments to ensure the quality of project. Recommending suitable candidates of reviewer to the new PRs will make the PR reviewing more efficient. However, there is not a mechanism of automatic reviewer recommendation for PR in GitHub. In this paper, we propose an automatic core-reviewer recommendation approach, which combines PR topic model with collaborators in the social network. First PR topics will be extracted from PRs by the latent Dirichlet allocation, and then the collaborator–PR network will be constructed with the connection between collaborators and PRs, and the influence of each collaborator will be calculated via the improved PageRank algorithm which combines with HITS. Finally, the relationship between topics and collaborators will also be built by the history of PR reviewing. When a new PR presents, a collaborator will be chosen as a core reviewer according to the influence of collaborators and the relationship between the new PR and collaborators. The experiment results show in the matching score calculation processing, the influence of collaborators shows higher than that with the expert, and the recommendation precision is better than 70\%.},
  archive      = {J_SOCO},
  author       = {Liao, Zhifang and Wu, ZeXuan and Li, Yanbing and Zhang, Yan and Fan, Xiaoping and Wu, Jinsong},
  doi          = {10.1007/s00500-019-04217-7},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {5683-5693},
  shortjournal = {Soft Comput.},
  title        = {Core-reviewer recommendation based on pull request topic model and collaborator social network},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Secure and efficient big data deduplication in fog
computing. <em>SOCO</em>, <em>24</em>(8), 5671–5682. (<a
href="https://doi.org/10.1007/s00500-019-04215-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of the Internet of Things, the massive amount of big data generated by the Internet of Things terminals and the real-time processing requirements have brought enormous challenges. A two-tier computing model consisting solely of two entities, cloud and user, will not be sufficient to support processing large numbers of concurrent data requests. Therefore, fog computing was proposed. How to realize the secure and efficient deduplication of ciphertext in fog computing has become a new research topic. In this paper, we firstly present a new decentralized deduplication structure and then show how to apply it to construct a secure and efficient big data deduplication scheme in fog computing. The cloud server, in the proposed paper, can quickly determine which fog server needs to be traversed to search duplicate data, and instead of traversing all fog servers. This significantly improves the efficiency of big data deduplication in fog computing. Furthermore, the proposed scheme allows fog server to verify whether the user possesses the ownership of the data. Performance analysis and experimental results show the proposed scheme has less overheads than existing schemes.},
  archive      = {J_SOCO},
  author       = {Yan, Jiajun and Wang, Xiaoming and Gan, Qingqing and Li, Suyu and Huang, Daxin},
  doi          = {10.1007/s00500-019-04215-9},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {5671-5682},
  shortjournal = {Soft Comput.},
  title        = {Secure and efficient big data deduplication in fog computing},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On one-time cookies protocol based on one-time password.
<em>SOCO</em>, <em>24</em>(8), 5657–5670. (<a
href="https://doi.org/10.1007/s00500-019-04138-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cookies are used for tracking user sessions in Web servers. Though, the security vulnerability of cookies may cause session being hijacked. To resist attacks, Dacosta et al. proposed one-time cookies (OTC) protocol. Unfortunately, one primary weakness is its availability relying on time synchronization between two machines, while the other is using a fixed session key to generate OTC during session period, turning possible adversaries to crack the key. Motivated by these shortcomings, a novel OTC protocol based on a one-time password (OTP) is proposed in the paper. The protocol adopts the OTP algorithm based on a hash chain to avoid time synchronization problems and generate a dynamic key for improving the security of OTC. For efficiency, we also enhanced the OTP algorithm. Security analysis and experimental results show that the proposed OTC protocol is promising to deliver high security and minimal burden on performance.},
  archive      = {J_SOCO},
  author       = {He, Junhui and Han, Dezhi and Li, Kuan-Ching},
  doi          = {10.1007/s00500-019-04138-5},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {5657-5670},
  shortjournal = {Soft Comput.},
  title        = {On one-time cookies protocol based on one-time password},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel metaheuristic inspired by hitchcock birds’ behavior
for efficient optimization of large search spaces of high
dimensionality. <em>SOCO</em>, <em>24</em>(8), 5633–5655. (<a
href="https://doi.org/10.1007/s00500-019-04102-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new optimization algorithm called the Hitchcock bird-inspired algorithm (HBIA) is proposed. It is inspired by the aggressive bird behavior portrayed by Alfred Hitchcock in the 1963 thriller “The Birds.” It is noteworthy to emphasize that the bird’s behavior as shown in the movie is itself inspired by a considered natural birds behavior when faced with extreme conditions. HBIA is a stochastic swarm intelligence algorithm that captures the essence of the fictional behavior of the phenomenon of birds throughout the Hitchcock’s film and model an optimization mechanism. The algorithm is based on the attack pattern of birds in the film, which has the stages of lurking, attack and reorganization, defined by the initialization, movement strategies in the search space and strategy of local minimum escape, respectively. The technique has as differential the use of adaptive parameters, a discretized random initialization and the use of the beta distribution. In contrast to the existing ones, the proposed technique provides an efficient optimization in high-dimensionality cost functions, using adaptive parameters, a discretized random initialization and the use of the beta distribution. Its performance is analyzed and compared to classic techniques, such as PSO, ABC and CS, as well as to the existing adaptive techniques, such as sine cosine algorithm, whale optimization algorithm, teaching–learning-based optimization and vortex search. HBIA’s performance is investigated by several experiments implemented through eight cost functions. The results show that the HBIA can find more satisfactory solutions in large search spaces and high dimensionality of the evaluated cost functions when compared to the existing optimization methods.},
  archive      = {J_SOCO},
  author       = {Morais, Reinaldo G. and Nedjah, Nadia and Mourelle, Luiza M.},
  doi          = {10.1007/s00500-019-04102-3},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {5633-5655},
  shortjournal = {Soft Comput.},
  title        = {A novel metaheuristic inspired by hitchcock birds’ behavior for efficient optimization of large search spaces of high dimensionality},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A privacy-preserving multi-keyword search approach in cloud
computing. <em>SOCO</em>, <em>24</em>(8), 5609–5631. (<a
href="https://doi.org/10.1007/s00500-019-04033-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing provides the users with the ability to outsource their data to a third-party cloud storage for cost-effective management of resources and on-demand network access. However, outsourcing the data to a third-party location may raise concerns about data privacy. To maintain the user’s privacy, users tend to encrypt their sensitive data before outsourcing it. Encrypting the data will preserve its privacy, but at the same time, it makes the searching process for a specific keyword a time-consuming and challenging process, mainly if the encryption key is not provided. On the other hand, the data owner should be able to perform multiple keyword searches to retrieve specific documents that are relevant to the search query. This paper proposes a new privacy-preserving multi-keyword search approach for the cloud outsourced data. The objective of the proposed approach is to allow the data owners and the authorized users to retrieve the most relevant data with minimum computation and communication overhead, and reduced false positives (irrelevant documents) and searching time. To evaluate the proposed approach, the NSF research dataset is used. Results demonstrate that the proposed method achieves better searching time and overall performance of the cloud environment regarding computation and communication overhead as well as false positives in comparison with other approaches.},
  archive      = {J_SOCO},
  author       = {Manasrah, Ahmed M. and Abu Nasir, Mahmoud and Salem, Maher},
  doi          = {10.1007/s00500-019-04033-z},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {5609-5631},
  shortjournal = {Soft Comput.},
  title        = {A privacy-preserving multi-keyword search approach in cloud computing},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Automatic keyphrase extraction using word embeddings.
<em>SOCO</em>, <em>24</em>(8), 5593–5608. (<a
href="https://doi.org/10.1007/s00500-019-03963-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised random-walk keyphrase extraction models mainly rely on global structural information of the word graph, with nodes representing candidate words and edges capturing the co-occurrence information between candidate words. However, using word embedding method to integrate multiple kinds of useful information into the random-walk model to help better extract keyphrases is relatively unexplored. In this paper, we propose a random-walk-based ranking method to extract keyphrases from text documents using word embeddings. Specifically, we first design a heterogeneous text graph embedding model to integrate local context information of the word graph (i.e., the local word collocation patterns) with some crucial features of candidate words and edges of the word graph. Then, a novel random-walk-based ranking model is designed to score candidate words by leveraging such learned word embeddings. Finally, a new and generic similarity-based phrase scoring model using word embeddings is proposed to score phrases for selecting top-scoring phrases as keyphrases. Experimental results show that the proposed method consistently outperforms eight state-of-the-art unsupervised methods on three real datasets for keyphrase extraction.},
  archive      = {J_SOCO},
  author       = {Zhang, Yuxiang and Liu, Huan and Wang, Suge and Ip., W. H. and Fan, Wei and Xiao, Chunjing},
  doi          = {10.1007/s00500-019-03963-y},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {5593-5608},
  shortjournal = {Soft Comput.},
  title        = {Automatic keyphrase extraction using word embeddings},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). WOA + BRNN: An imbalanced big data classification framework
using whale optimization and deep neural network. <em>SOCO</em>,
<em>24</em>(8), 5573–5592. (<a
href="https://doi.org/10.1007/s00500-019-03901-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, big data plays a substantial part in information knowledge analysis, manipulation, and forecasting. Analyzing and extracting knowledge from such big datasets are a very challenging task due to the imbalance of data distribution, which could lead to a biased classification results and wrong decisions. The standard classifiers are not capable of handling such datasets. Hence, a new technique for dealing with such datasets is required. This paper proposes a novel classification framework for big data that consists of three developed phases. The first phase is the feature selection phase, which uses the Whale optimization algorithm (WOA) for finding the best set of features. The second phase is the preprocessing phase, which uses the SMOTE algorithm and the LSH-SMOTE algorithm for solving the class imbalance problem. Lastly, the third phase is WOA + BRNN algorithm, which is using the Whale optimization algorithm for training a deep learning approach called bidirectional recurrent neural network for the first time. Our proposed algorithm WOA-BRNN has been tested against nine highly imbalanced datasets one of them is big dataset in terms of area under curve (AUC) against four of the most common use machine learning algorithms (Naïve Bayes, AdaBoostM1, decision table, random tree), in addition to GWO-MLP (training multilayer perceptron using Gray Wolf Optimizer), then we test our algorithm over four well-known datasets against GWO-MLP and particle swarm optimization (PSO-MLP), genetic algorithm (GA-MLP), ant colony optimization (ACO-MLP), evolution strategy (ES-MLP), and population-based incremental learning (PBIL-MLP) in terms of classification accuracy. Experimental results proved that our proposed algorithm WOA + BRNN has achieved promising accuracy and high local optima avoidance, and outperformed four of the most common use machine learning algorithms, and GWO-MLP in terms of AUC.},
  archive      = {J_SOCO},
  author       = {Hassib, Eslam. M. and El-Desouky, Ali. I. and Labib, Labib. M. and El-kenawy, El-Sayed M.},
  doi          = {10.1007/s00500-019-03901-y},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {5573-5592},
  shortjournal = {Soft Comput.},
  title        = {WOA + BRNN: An imbalanced big data classification framework using whale optimization and deep neural network},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Identity-based data storage scheme with anonymous key
generation in fog computing. <em>SOCO</em>, <em>24</em>(8), 5561–5571.
(<a href="https://doi.org/10.1007/s00500-018-3593-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identity-based proxy pre-encryption is a good candidate to achieve data sharing. When it is deployed to fog computing scenarios, it can provide more flexible access control service than being deployed to cloud computing for end-users since fog nodes are physically close to end-users. However, the existing IB-PRE schemes exist several security flaws. First, all IB-PRE schemes exist key escrow problem, which makes that the PKG can decrypt all ciphertexts of the users. Second, one re-encryption key can transform all ciphertexts of the delegator into all ciphertexts of the delegatee, which makes the scheme cannot provide fine-grained access control. Third, most of IB-PRE schemes cannot provide the user revocation and prevent collusion attacks. To overcome the above problems, in the paper, we propose an identity-based data storage scheme with anonymous key generation which is applied to fog computing. And then it is shown to provably secure in the random oracle model. By comparing with other existing schemes, our scheme has some advantages over the other schemes in terms of security properties. Finally, by experiment analysis, the result shows our scheme is efficient with respect to computational cost and communication overhead.},
  archive      = {J_SOCO},
  author       = {Zhang, Jianhong and Bai, Wenle and Wang, Xianmin},
  doi          = {10.1007/s00500-018-3593-z},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {5561-5571},
  shortjournal = {Soft Comput.},
  title        = {Identity-based data storage scheme with anonymous key generation in fog computing},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Information retrieval methodology for aiding scientific
database search. <em>SOCO</em>, <em>24</em>(8), 5551–5560. (<a
href="https://doi.org/10.1007/s00500-018-3568-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During literature reviews, and specially when conducting systematic literature reviews, finding and screening relevant papers during scientific document search may involve managing and processing large amounts of unstructured text data. In those cases where the search topic is difficult to establish or has fuzzy limits, researchers require to broaden the scope of the search and, in consequence, data from retrieved scientific publications may become huge and uncorrelated. However, through a convenient analysis of these data the researcher may be able to discover new knowledge which may be hidden within the search output, thus exploring the limits of the search and enhancing the review scope. With that aim, this paper presents an iterative methodology that applies text mining and machine learning techniques to a downloaded corpus of abstracts from scientific databases, combining automatic processing algorithms with tools for supervised decision-making in an iterative process sustained on the researchers’ judgement, so as to adapt, screen and tune the search output. The paper ends showing a working example that employs a set of developed scripts that implement the different stages of the proposed methodology.},
  archive      = {J_SOCO},
  author       = {Marcos-Pablos, Samuel and García-Peñalvo, Francisco J.},
  doi          = {10.1007/s00500-018-3568-0},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {5551-5560},
  shortjournal = {Soft Comput.},
  title        = {Information retrieval methodology for aiding scientific database search},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An efficient index structure for distributed k-nearest
neighbours query processing. <em>SOCO</em>, <em>24</em>(8), 5539–5550.
(<a href="https://doi.org/10.1007/s00500-018-3548-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many location-based services are supported by the moving k-nearest neighbour (k-NN) query, which continuously returns the k-nearest data objects for a query point. Most of existing approaches to this problem have focused on a centralized setting, which show poor scalability to work around massive-scale and distributed data sets. In this paper, we propose an efficient distributed solution for k-NN query over moving objects to tackle the increasingly large scale of data. This approach includes a new grid-based index called Block Grid Index (BGI), and a distributed k-NN query algorithm based on BGI. There are three advantages of our approach: (1) BGI can be easily constructed and maintained in a distributed setting; (2) the algorithm is able to return the results set in only two iterations. (3) the efficiency of k-NN query is improved. The efficiency of our solution is verified by extensive experiments with millions of nodes.},
  archive      = {J_SOCO},
  author       = {Yang, Min and Ma, Kun and Yu, Xiaohui},
  doi          = {10.1007/s00500-018-3548-4},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {5539-5550},
  shortjournal = {Soft Comput.},
  title        = {An efficient index structure for distributed k-nearest neighbours query processing},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Scalable detection of botnets based on DGA. <em>SOCO</em>,
<em>24</em>(8), 5517–5537. (<a
href="https://doi.org/10.1007/s00500-018-03703-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Botnets are evolving, and their covert modus operandi, based on cloud technologies such as the virtualisation and the dynamic fast-flux addressing, has been proved challenging for classic intrusion detection systems and even the so-called next-generation firewalls. Moreover, dynamic addressing has been spotted in the wild in combination with pseudo-random domain names generation algorithm (DGA), ultimately leading to an extremely accurate and effective disguise technique. Although these concealing methods have been exposed and analysed to great extent in the past decade, the literature lacks some important conclusions and common-ground knowledge, especially when it comes to Machine Learning (ML) solutions. This research horizontally navigates the state of the art aiming to polish the feature discovery process, which is the single most time-consuming part of any ML approach. Results show that only a minor fraction of the defined features are indeed practical and informative, especially when considering 0-day botnet identification. The contributions described in this article will ease the detection process, ultimately enabling improved and more scalable solutions for DGA-based botnets detection.},
  archive      = {J_SOCO},
  author       = {Zago, Mattia and Gil Pérez, Manuel and Martínez Pérez, Gregorio},
  doi          = {10.1007/s00500-018-03703-8},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {5517-5537},
  shortjournal = {Soft Comput.},
  title        = {Scalable detection of botnets based on DGA},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Study on a storage location strategy based on clustering and
association algorithms. <em>SOCO</em>, <em>24</em>(8), 5499–5516. (<a
href="https://doi.org/10.1007/s00500-018-03702-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the improvement of a storage location strategy through the use of big data technology, including data collection, cluster analysis and association analysis, to improve order picking efficiency. A clustering algorithm is used to categorize the types of goods in orders. Classification is performed based on the turnover of goods, value, sales volume, favorable commodity ratings, whether free shipping is provided and whether cash on delivery is supported. An association algorithm is used to determine the relationships among goods by studying the habits of consumers who buy them. A method for improving the class-based storage strategy is proposed. The picking distance of the improved storage strategy is compared with that of the traditional strategy via simulation experiments. The picking efficiency is shown to be enhanced by the improved strategy.},
  archive      = {J_SOCO},
  author       = {Zhou, Li and Sun, Lili and Li, Zhaochan and Li, Weipeng and Cao, Ning and Higgs, Russell},
  doi          = {10.1007/s00500-018-03702-9},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {5499-5516},
  shortjournal = {Soft Comput.},
  title        = {Study on a storage location strategy based on clustering and association algorithms},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improving traffic flow forecasting with relevance vector
machine and a randomized controlled statistical testing. <em>SOCO</em>,
<em>24</em>(8), 5485–5497. (<a
href="https://doi.org/10.1007/s00500-018-03693-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-accuracy traffic flow forecasting is vital to the development of intelligent city transportation systems. Recently, traffic flow forecasting models based on the kernel method have been widely applied due to their great generalization capability. The aim of this article is twofold: A novel kernel learning method, relevance vector machine, is employed to short-term traffic flow forecasting so as to capture the inner correlation between sequential traffic flow data, it is a type of nonlinear model which is accurate and using only a small number of relevant basis functions automatically selected. So that it can find concise data representations which are adequate for the learning task retaining as much information as possible. On the other hand, the sample size for learning has a significant impact on forecasting accuracy. How to balancing the relationship between the sample size and the forecasting accuracy is an important research topic. A randomized controlled statistical testing is layout to evaluating the impacts of sample size of the new proposed traffic flow forecasting model. The experimental results show that the new model achieves similar or better forecasting and generalization performance compared to some old ones; besides, it is less sensitive to the size of learning sample.},
  archive      = {J_SOCO},
  author       = {Lou, Jungang and Shen, Zhangguo and Shen, Qing and Hu, Wenjun and Chen, Zhijun},
  doi          = {10.1007/s00500-018-03693-7},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {5485-5497},
  shortjournal = {Soft Comput.},
  title        = {Improving traffic flow forecasting with relevance vector machine and a randomized controlled statistical testing},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Soft computing techniques for big data and cloud computing.
<em>SOCO</em>, <em>24</em>(8), 5483–5484. (<a
href="https://doi.org/10.1007/s00500-020-04766-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SOCO},
  author       = {Gupta, B. B. and Agrawal, Dharma P. and Yamaguchi, Shingo and Sheng, Michael},
  doi          = {10.1007/s00500-020-04766-2},
  journal      = {Soft Computing},
  number       = {8},
  pages        = {5483-5484},
  shortjournal = {Soft Comput.},
  title        = {Soft computing techniques for big data and cloud computing},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Lyapunov stability-dynamic back propagation-based
comparative study of different types of functional link neural networks
for the identification of nonlinear systems. <em>SOCO</em>,
<em>24</em>(7), 5463–5482. (<a
href="https://doi.org/10.1007/s00500-019-04496-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the performance comparison of various types of functional link neural networks (FLNNs) has been done for the nonlinear system identification. The FLNNs being compared in the present study are: trigonometry FLNN, Legendre FLNN (LeFLNN), Chebyshev FLNN, power series FLNN (PSFLNN) and Hermite FLNN. The recursive weights adjustment equations are derived using the combination of Lyapunov stability criterion and dynamic back propagation algorithm. In the simulation study, a total of three nonlinear systems (both static and dynamic systems) are considered for testing and comparing the approximation ability and computational complexity of the above-mentioned FLNNs. From the simulation results, it is observed that the LeFLNN has given better approximation accuracy and PSFLNN offered least computational load as compared to the rest models.},
  archive      = {J_SOCO},
  author       = {Kumar, Rajesh and Srivastava, Smriti and Mohindru, Amit},
  doi          = {10.1007/s00500-019-04496-0},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {5463-5482},
  shortjournal = {Soft Comput.},
  title        = {Lyapunov stability-dynamic back propagation-based comparative study of different types of functional link neural networks for the identification of nonlinear systems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Two-stage three-machine assembly scheduling problem with
sum-of-processing-times-based learning effect. <em>SOCO</em>,
<em>24</em>(7), 5445–5462. (<a
href="https://doi.org/10.1007/s00500-019-04301-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Researchers claim that the processing of most products can be formulated as a two-stage assembly scheduling model. The literature states that cumulative learning experience is neglected in solving two-stage assembly scheduling problems. The sum-of-processing-times-based learning effect means that the actual processing time of a job becomes shorter when it is scheduled later, which depends on the sum of processing time of the jobs already processed. Motivated by this observation, we investigate a novel two-stage assembly scheduling with three machines and sum-of-processing-times-based learning effect to minimize the makespan criterion, where two machines operate at the first stage and an assembly machine operates at the second stage. To solve this NP-hard problem, a branch-and-bound method incorporating with ten dominance properties and a lower bound procedure is first derived to obtain an optimal solution. Three heuristics based on Johnson’s rule with and without improvement are then applied separately to a genetic algorithm and a cloud theory-based simulated annealing algorithm, which are further modified with an interchange pairwise method for finding near-optimal solutions. Finally, the numerical results obtained using all proposed algorithms are reported and evaluated.},
  archive      = {J_SOCO},
  author       = {Zou, Yunqing and Wang, Dujuan and Lin, Win-Chin and Chen, Jia-Yang and Yu, Pay-Wen and Wu, Wen-Hsiang and Chao, Yuan-Po and Wu, Chin-Chia},
  doi          = {10.1007/s00500-019-04301-y},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {5445-5462},
  shortjournal = {Soft Comput.},
  title        = {Two-stage three-machine assembly scheduling problem with sum-of-processing-times-based learning effect},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Tampering detection using hybrid local and global features
in wavelet-transformed space with digital images. <em>SOCO</em>,
<em>24</em>(7), 5427–5443. (<a
href="https://doi.org/10.1007/s00500-019-04298-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread availability of advanced digital image technology and powerful image editing tools has made it extremely easy to manipulate image content. One popular technique that is challenging for tampering detection methods is the copy–move forgery. Here, one part of the image is copied and is pasted into another part of the same image. Image tampering is very difficult to detect with the naked eye. The authenticity of digital images is critical when they are used as evidence in court, for news reports or insurance claims, as they have the power to influence decisions and outcomes. Hence, this paper presents an efficient method for copy–move forgery detection by means of a HOG descriptor and local binary pattern variance algorithms. The copy–move forgery detection (CMFD) approach is introduced and is applied to the forged region by determining suitable post-processing techniques. The proposed technique is evaluated using MICC-F220, MICC-F2000, UCID, CoMoFoD and CASIA TIDE data sets in which translation, flipping, rotation, scaling, color reduction, brightness change and JPEG compression are applied to an image. The experimental performance of the proposed technique is assessed in terms of the true- and false-detection rates. Ultimately, our proposed method is highly suitable for detecting the altered region, and accurate CMFD results are obtained in forensic image applications.},
  archive      = {J_SOCO},
  author       = {Nirmal Jothi, J. and Letitia, S.},
  doi          = {10.1007/s00500-019-04298-4},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {5427-5443},
  shortjournal = {Soft Comput.},
  title        = {Tampering detection using hybrid local and global features in wavelet-transformed space with digital images},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Forensic document examination system using boosting and
bagging methodologies. <em>SOCO</em>, <em>24</em>(7), 5409–5426. (<a
href="https://doi.org/10.1007/s00500-019-04297-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Document forgery has increased enormously due to the progression of information technology and image processing software. Critical documents are protected using watermarks or signatures, i.e., active approach. Other documents need passive approach for document forensics. Most of the passive techniques aim to detect and fix the source of the printed document. Other techniques look for the irregularities present in the document. This paper aims to fix the document source printer using passive approach. Hand-crafted features based on key printer noise features (KPNF), speeded up robust features (SURF) and oriented FAST rotated and BRIEF (ORB) are used. Then, feature-based classifiers are implemented using K-NN, decision tree, random forest and majority voting. The document classifier proposed model can efficiently classify the questioned documents to their respective printer class. Further, adaptive boosting and bootstrap aggregating methodologies are used for the improvement in classification accuracy. The proposed model has achieved the best accuracy of 95.1\% using a combination of KPNF + ORB + SURF with random forest classifier and adaptive boosting methodology.},
  archive      = {J_SOCO},
  author       = {Gupta, Surbhi and Kumar, Munish},
  doi          = {10.1007/s00500-019-04297-5},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {5409-5426},
  shortjournal = {Soft Comput.},
  title        = {Forensic document examination system using boosting and bagging methodologies},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A low-carbon-orient product design schemes MCDM method
hybridizing interval hesitant fuzzy set entropy theory and coupling
network analysis. <em>SOCO</em>, <em>24</em>(7), 5389–5408. (<a
href="https://doi.org/10.1007/s00500-019-04296-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The product low-carbon design is the key to decrease carbon emissions in manufacturing. The multiple criteria decision-making (MCDM) method has been widely used in solving the design schemes preference choosing problems. However, the existed MCDM method has two primary problems facing the product low-carbon design cases: (i) How to clarify the coupling relationship between low-carbon decision criteria? (ii) How to fuzzily express the low-carbon-orient product design schemes? To solve these problems, we proposed a novel MCDM method for product low-carbon design. It combines the coupling network analysis with the interval hesitant fuzzy set entropy theory into MCDM process. We used a case study of injection molding machine low-carbon design to verify the proposed MCDM method. It turns out that the proposed MCDM method can help us make more rational and equitable decisions among alternative low-carbon schemes.},
  archive      = {J_SOCO},
  author       = {Wang, Zili and Zhang, Shuyou and Qiu, Lemiao and Gu, Ye and Zhou, Huifang},
  doi          = {10.1007/s00500-019-04296-6},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {5389-5408},
  shortjournal = {Soft Comput.},
  title        = {A low-carbon-orient product design schemes MCDM method hybridizing interval hesitant fuzzy set entropy theory and coupling network analysis},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Partial belong relation on soft separation axioms and
decision-making problem, two birds with one stone. <em>SOCO</em>,
<em>24</em>(7), 5377–5387. (<a
href="https://doi.org/10.1007/s00500-019-04295-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Here, we employ partial belong and total non-belong relations to construct a study consisting of two parts: one of them is related to soft topologies, and the other one is concerned with real-life applications. In the first part, we define a new class of soft separation axioms, namely e-soft $$T_i$$-spaces $$(i=0, 1, 2, 3, 4)$$. We formulate these spaces with respect to distinct ordinary points using partial belong and total non-belong relations. The merits of using these two relations are that they help to generate a wider class of soft spaces and open up the way for more real-life applications. With the help of examples, we show the relationships between them and investigate the interrelations between them and their parametric topological spaces. Also, we study under what condition the concepts of soft $$T_i$$, p-soft $$T_i$$ and e-soft $$T_i$$ are equivalent. Furthermore, we scrutinize their behaviours in terms of soft subspaces, soft topological properties and finite soft product spaces. In the second part, we introduce an algorithm using partial belong relations in a decision-making problem in order to bring out the optimal choices.},
  archive      = {J_SOCO},
  author       = {Al-shami, T. M. and El-Shafei, M. E.},
  doi          = {10.1007/s00500-019-04295-7},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {5377-5387},
  shortjournal = {Soft Comput.},
  title        = {Partial belong relation on soft separation axioms and decision-making problem, two birds with one stone},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Constraint programming model for resource-constrained
assembly line balancing problem. <em>SOCO</em>, <em>24</em>(7),
5367–5375. (<a
href="https://doi.org/10.1007/s00500-019-04294-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The literature studies assume that resources used to be perform the tasks are certain and homogenous in any assembly line. However, tasks may need to be processed by general resource requirements in real life. These general resources could be classified by usage of resources such as simple or multiple, alternative and concurrent. The problem which is related to assignment of the task to any workstation and assignment of resources needed by the task simultaneously is defined as resource-constrained assembly line balancing problems (RCALBPs). In this study, a multiobjective model with minimization of cycle time and resource usage for a given number of stations is modeled to solve the RCALBP for the first time. Alternative and general resource types for tasks and using more than two resource type requirements are also considered. A constraint programming model is developed and solved to find the optimal solutions of these problems. The proposed models are tested with sample scenarios to show the effectiveness of the model.},
  archive      = {J_SOCO},
  author       = {Alakaş, Hacı Mehmet and Pınarbaşı, Mehmet and Yüzükırmızı, Mustafa},
  doi          = {10.1007/s00500-019-04294-8},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {5367-5375},
  shortjournal = {Soft Comput.},
  title        = {Constraint programming model for resource-constrained assembly line balancing problem},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Computational intelligence-based model for diarrhea
prediction using demographic and health survey data. <em>SOCO</em>,
<em>24</em>(7), 5357–5366. (<a
href="https://doi.org/10.1007/s00500-019-04293-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diarrhea is one of the leading public health problems and the third main cause of death among young children in developing countries. Solutions to tackling the infectious disease require both preventive and control efforts. However, efforts toward improving the control measures require comprehending the factors associated with diarrhea incidence and the ability to accurately forecast the incidence of the disease. Therefore, the present study develops a diarrhea incidence prediction model based on the 2013 Nigeria Demographic and Health Survey data using artificial neural network. The empirical results of the model indicate that, by using only 44 demographic, socioeconomic and environmental variables, diarrhea incidence can be predicted with high accuracy of 95.78 and 95.63\% during training and testing phases, respectively. The model is useful for health policymakers in devising proactive intervention measures, including preparing healthcare systems and improving diarrhea prevention and control capabilities. It could also benefit future studies in predicting epidemics that are affected by similar variables.},
  archive      = {J_SOCO},
  author       = {Abubakar, Ismaila Rimi and Olatunji, Sunday Olusanya},
  doi          = {10.1007/s00500-019-04293-9},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {5357-5366},
  shortjournal = {Soft Comput.},
  title        = {Computational intelligence-based model for diarrhea prediction using demographic and health survey data},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hybrid wind speed prediction model based on recurrent long
short-term memory neural network and support vector machine models.
<em>SOCO</em>, <em>24</em>(7), 5345–5355. (<a
href="https://doi.org/10.1007/s00500-019-04292-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Renewable energy has gained its significance in the recent years due to the increasing power demand and the requirement in various distribution and utilization sectors. To meet the energy demand, renewable energy resources which include wind and solar have attained significant attractiveness and remarkable expansions are carried out all over the world to enhance the power generation using wind and solar energy. This research paper focuses on predicting the wind speed so that it results in forecasting the possible wind power that can be generated from the wind resources which facilitates to meet the growing energy demand. In this work, a recurrent neural network model called as long short-term memory network model and variants of support vector machine models are used to predict the wind speed for the considered locations where the windmill has been installed. Both these models are tuned for the weight parameters and kernel variational parameters using the proposed hybrid particle swarm optimization algorithm and ant lion optimization algorithm. Experimental simulation results attained prove the validity of the proposed work compared with the methods developed in the early literature.},
  archive      = {J_SOCO},
  author       = {Vinothkumar, T. and Deeba, K.},
  doi          = {10.1007/s00500-019-04292-w},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {5345-5355},
  shortjournal = {Soft Comput.},
  title        = {Hybrid wind speed prediction model based on recurrent long short-term memory neural network and support vector machine models},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A unified method for pythagorean fuzzy multicriteria group
decision-making using entropy measure, linear programming and extended
technique for ordering preference by similarity to ideal solution.
<em>SOCO</em>, <em>24</em>(7), 5333–5344. (<a
href="https://doi.org/10.1007/s00500-019-04282-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an innovative method for solving Pythagorean fuzzy (PF) multicriteria group decision-making problems with completely unknown weight information about criteria using entropy weight model, linear programming (LP) and modified technique for ordering preference by similarity to ideal solution (TOPSIS). At first, a new distance measure for PF sets is defined considering their degree of hesitancy and based on weighted Hamming distance and Hausdorff metric. To handle the fuzziness in criteria weights, PF entropy weight model is used to find the initial weights of the criteria in PF format. Following the concept of TOPSIS, an LP model is constructed on the basis of the view point that the chosen alternative should have the smallest distance from the positive ideal solution and the largest distance from the negative ideal solution. Then, the LP model is utilized to find optimal weights of the criteria. Using the newly defined distance measure, entropy weight model and LP model, TOPSIS is extended in PF environments. The existing methods are able to find criteria weights in the form of crisp values only, whereas proposed method is able to obtain those weights in PF format. Thus, the proposed method can overcome the drawback in computing criteria weight for multicriteria group decision-making in PF environments and reduce the information loss significantly. Several numerical examples are considered and solved to validate the superiority of the proposed methodology.},
  archive      = {J_SOCO},
  author       = {Sarkar, Biswajit and Biswas, Animesh},
  doi          = {10.1007/s00500-019-04282-y},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {5333-5344},
  shortjournal = {Soft Comput.},
  title        = {A unified method for pythagorean fuzzy multicriteria group decision-making using entropy measure, linear programming and extended technique for ordering preference by similarity to ideal solution},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new teaching–learning-based chicken swarm optimization
algorithm. <em>SOCO</em>, <em>24</em>(7), 5313–5331. (<a
href="https://doi.org/10.1007/s00500-019-04280-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chicken Swarm Optimization (CSO) is a novel swarm intelligence-based algorithm known for its good performance on many benchmark functions as well as real-world optimization problems. However, it is observed that CSO sometimes gets trapped in local optima. This work proposes an improved version of the CSO algorithm with modified update equation of the roosters and a novel constraint-handling mechanism. Further, the work also proposes synergy of the improved version of CSO with Teaching–Learning-based Optimization (TLBO) algorithm. The proposed ICSOTLBO algorithm possesses the strengths of both CSO and TLBO. The efficacy of the proposed algorithm is tested on eight basic benchmark functions, fifteen computationally expensive benchmark functions as well as two real-world problems. Further, the performance of ICSOTLBO is also compared with a number of state-of-the-art algorithms. It is observed that the proposed algorithm performs better than or as good as many of the existing algorithms.},
  archive      = {J_SOCO},
  author       = {Deb, Sanchari and Gao, Xiao-Zhi and Tammi, Kari and Kalita, Karuna and Mahanta, Pinakeswar},
  doi          = {10.1007/s00500-019-04280-0},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {5313-5331},
  shortjournal = {Soft Comput.},
  title        = {A new Teaching–Learning-based chicken swarm optimization algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel multi-criteria analysis model for the performance
evaluation of bank regions: An application to turkish agricultural
banking. <em>SOCO</em>, <em>24</em>(7), 5289–5311. (<a
href="https://doi.org/10.1007/s00500-019-04279-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The banks serve in a highly dynamic and competitive environment and need to systematically evaluate their performance to improve their competitiveness. Performance evaluation is an important and complex process that requires flexible and analytic methods while handling the multidimensionality of the problem. This study presents a hybrid multi-criteria performance evaluation model for banking sector which combines two multi-criteria decision making methods that are simulation-integrated hesitant fuzzy linguistic term sets-based analytic hierarchy process method to determine the importance level of each criterion according to the decision makers’ subjective judgements and grey relational analysis method to rank bank regions according to their performance values. The presented model is based on both probability theory and fuzzy sets theory and thus better represents all the dimensions of the uncertainty inherent in decision making process. A real-life application of the proposed performance evaluation model for a private bank operating in agricultural banking sector in Turkey is also given to illustrate the effectiveness and the applicability of the model.},
  archive      = {J_SOCO},
  author       = {Tüysüz, Fatih and Yıldız, Nurdan},
  doi          = {10.1007/s00500-019-04279-7},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {5289-5311},
  shortjournal = {Soft Comput.},
  title        = {A novel multi-criteria analysis model for the performance evaluation of bank regions: An application to turkish agricultural banking},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An information set-based robust text-independent speaker
authentication. <em>SOCO</em>, <em>24</em>(7), 5271–5287. (<a
href="https://doi.org/10.1007/s00500-019-04277-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a method for the extraction of twofold information set (TFIS) features for the text-independent speaker recognition. The method takes the Mel frequency cepstral coefficients from the frames of a sample speech signal and forms a matrix. From this, both spatial and temporal information components are derived based on the information set concept using the entropy framework. The TFIS features comprising their combination of two components are less in number thus reducing the computational time, complexity and improving the performance under the noisy environment. The proposed approach is tested on three datasets namely NIST-2003, VoxForge 2014 speech corpus and VCTK speech corpus in terms of speed, computational complexity, memory requirement and accuracy. Its performance is validated under different noisy environments at different signal-to-noise ratios.},
  archive      = {J_SOCO},
  author       = {Medikonda, Jeevan and Bhardwaj, Saurabh and Madasu, Hanmandlu},
  doi          = {10.1007/s00500-019-04277-9},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {5271-5287},
  shortjournal = {Soft Comput.},
  title        = {An information set-based robust text-independent speaker authentication},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Forecasting the multifactorial interval grey number
sequences using grey relational model and GM (1, n) model based on
effective information transformation. <em>SOCO</em>, <em>24</em>(7),
5255–5269. (<a
href="https://doi.org/10.1007/s00500-019-04276-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of data eruption, the data often show a short-term pattern and change rapidly which makes it difficult to use a single real value to express. For this kind of small-sample and interval data, how to analyze and predict multi-factor sequences efficiently becomes a problem. By this means, grey system theory (GST) is developed in which the interval grey numbers, as a typical object of GST, characterize the range of data and the grey relational and prediction models analyze the relations of multiple grey numbers and forecast the future. However, traditional grey relative relational model has some limitations: the results obtained always show low resolution, and there are no extractions for the interval feature information from the interval grey number sequence. In this paper, the grey relational analysis model (GRA) based on effective information transformation of interval grey numbers is established, which contains comprehensive information of area differences and slope variances and optimizes the resolution of traditional grey degree. Then, according to the relational results, the multivariable GM model (GM (1, N)) is proposed to forecast the interval grey number sequence. To verify the effectiveness of this novel model, it is established to analyze the relationship between the degree of traffic congestion and its relevant factors in the Yangtze River Delta of China and predict the development of urban traffic congestion degrees in this area over the next 5 years. In addition, some traditional statistical methods (principal component analysis, multiple linear regression models and curve regression models) are established for comparisons. The results show high performances of the novel GRA model and GM (1, N) model, which means the models proposed in this paper are suitable for interval grey numbers from regional data. The strengths which recommend the use of this novel method lie in its high recognition mechanism and multi-angle information transformation for interval grey numbers as well as its characteristic of timeliness in information processing.},
  archive      = {J_SOCO},
  author       = {Ye, Jing and Dang, Yaoguo and Yang, Yingjie},
  doi          = {10.1007/s00500-019-04276-w},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {5255-5269},
  shortjournal = {Soft Comput.},
  title        = {Forecasting the multifactorial interval grey number sequences using grey relational model and GM (1, n) model based on effective information transformation},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A greedy screening test strategy to accelerate solving LASSO
problems with small regularization parameters. <em>SOCO</em>,
<em>24</em>(7), 5245–5253. (<a
href="https://doi.org/10.1007/s00500-019-04275-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of big data remarked by high dimensionality and large sample size, the least absolute shrinkage and selection operator (LASSO) problems demand efficient algorithms. Both static and dynamic strategies based on screening test principle have been proposed recently, in order to safely filter out irrelevant atoms from the dictionary. However, such strategies only work well for LASSO problems with large regularization parameters, and lose their efficiency for those with small regularization parameters. This paper presents a novel greedy screening test strategy to accelerate solving LASSO problems with small regularization parameters, as well as its effectiveness through adoption of a relatively larger regularization parameter which filters out irrelevant atoms in every iteration. Further more, the convergence proof of the greedy strategy is given, and the computational complexity of LASSO solvers integrated with this strategy is investigated. Numerical experiments on both synthetic and real data sets support the effectiveness of this greedy strategy, and the results show it outperforms both the static and dynamic strategies for LASSO problems with small regularization parameters.},
  archive      = {J_SOCO},
  author       = {Shen, Hai-Wei and Chai, Hua and Xia, Liang-Yong and Wu, Sheng-Bing and Qu, Wei and Liang, Yong and Liu, Xiang-Tao},
  doi          = {10.1007/s00500-019-04275-x},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {5245-5253},
  shortjournal = {Soft Comput.},
  title        = {A greedy screening test strategy to accelerate solving LASSO problems with small regularization parameters},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Toward recursive spherical harmonics issued bi-filters: Part
II: An associated spherical harmonics entropy for optimal modeling.
<em>SOCO</em>, <em>24</em>(7), 5231–5243. (<a
href="https://doi.org/10.1007/s00500-019-04274-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image processing continues to be a challenging topic in many scientific fields such as medicine, computational physics and informatics especially with the discovery and development of 3D cases. Therefore, development of suitable tools that guarantee a best treatment is a necessity. Spherical shapes are a big class of 3D images whom processing necessitates adoptable tools. This encourages researchers to develop special mathematical bases suitable for 3D spherical shapes. The present work lies in this whole topic with the application of special spherical harmonics bases. In Jallouli et al. (Soft Comput 2018. https://doi.org/10.1007/s00500-018-3596-9), theoretical framework of spherical harmonics filters adapted to image processing has been developed. In the present paper, new approach based on Jallouli et al. (Soft Comput 2018. https://doi.org/10.1007/s00500-018-3596-9) is proposed for the reconstruction of images provided with spherical harmonics Shannon-type entropy to evaluate the order/disorder of the reconstructed image. Efficiency and accuracy of the approach are demonstrated by a simulation study on several spherical models.},
  archive      = {J_SOCO},
  author       = {Jallouli, Malika and Bel Hadj Khélifa, Wafa and Ben Mabrouk, Anouar and Mahjoub, Mohamed Ali},
  doi          = {10.1007/s00500-019-04274-y},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {5231-5243},
  shortjournal = {Soft Comput.},
  title        = {Toward recursive spherical harmonics issued bi-filters: part II: an associated spherical harmonics entropy for optimal modeling},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A distance-similarity method to solve fuzzy sets and fuzzy
soft sets based decision-making problems. <em>SOCO</em>, <em>24</em>(7),
5217–5229. (<a
href="https://doi.org/10.1007/s00500-019-04273-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Similarity measure plays an important role in fuzzy environment. Motivating from usual Euclidean distance measure, it introduces a new distance-similarity approach to get a solution of a fuzzy sets and fuzzy soft sets based maximization decision-making problems. Also, three algorithms have been proposed connected to fuzzy sets and fuzzy soft sets. Then using these algorithms, different types of decision-making problems can be solved. To check the efficiency of our approach, we consider an example and solve it by different existing methods, and the results are compared.},
  archive      = {J_SOCO},
  author       = {Paik, Biplab and Mondal, Shyamal Kumar},
  doi          = {10.1007/s00500-019-04273-z},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {5217-5229},
  shortjournal = {Soft Comput.},
  title        = {A distance-similarity method to solve fuzzy sets and fuzzy soft sets based decision-making problems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A nifty mean chart method based on median ranked set
sampling design. <em>SOCO</em>, <em>24</em>(7), 5199–5216. (<a
href="https://doi.org/10.1007/s00500-019-04272-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the case of contamination for skewed distributions, the modified Shewhart, modified weighted variance, and modified skewness correction methods are newly introduced by Karagöz (Hacet J Math Stat 47(1):223–242, 2018). In this study, we propose to modify these methods by considering simple random sampling (SRS), ranked set sampling (RSS) and median ranked set sampling (MRSS) designs under the contaminated type I Marshall–Olkin bivariate Weibull and lognormal distributions. These bivariate distributions are chosen since they can represent a wide variety of shapes from nearly symmetric to highly skewed. We evaluate the performance of proposed modified methods based on different ranked set sampling designs by using Monte Carlo Simulation. The type I risks of $${\bar{X}}$$ charts for existing and newly proposed modified methods by using SRS, RSS and MRSS designs in the case of contamination for these distributions are obtained via simulation study. The proposed modified methods using RSS and MRSS designs for the $${\bar{X}}$$ chart can be a favorable substitute in process monitoring when the distribution is highly skewed and contaminated.},
  archive      = {J_SOCO},
  author       = {Karagöz, Derya and Koyuncu, Nursel},
  doi          = {10.1007/s00500-019-04272-0},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {5199-5216},
  shortjournal = {Soft Comput.},
  title        = {A nifty mean chart method based on median ranked set sampling design},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Supply chain management under uncertainty with the
combination of fuzzy multi-objective planning and real options
approaches. <em>SOCO</em>, <em>24</em>(7), 5177–5198. (<a
href="https://doi.org/10.1007/s00500-019-04271-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concentration of this paper is to measure and break supply chain planning decisions under market and/or technical uncertainty. A three-level supply chain with manufacturers–distributors–customer’s loops is considered that customer demands, percent of back products from customers and shipping time of products from distributors to customers are considered as fuzzy variables. The main approach considers suppliers and distributor selection and determines the affected customers in the system problems simultaneously under uncertain conditions. The objects of the proposed model are maximizing the quality of products and income and minimizing the total cost and the shipping time from distributors to customers. Also, in the proposed model we consider some constraints such as lack of orders, production capacity and customer demands. Also, a two-organize, stochastic programming methodology is proposed for joining request vulnerability in multisite midterm store network arranging issues. The assessment of the normal second-stage expenses is accomplished by expository reconciliation yielding an equivalent convex mixed-integer nonlinear problem. At long last, a real options-based valuation (ROV) system for supporting under vulnerability is produced. Multistage stochastic writing computer programs are utilized to fuse vulnerability and a quantitative correlation of the ROV approach, and the customary net-present-value approach is given.},
  archive      = {J_SOCO},
  author       = {Arasteh, Abdollah},
  doi          = {10.1007/s00500-019-04271-1},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {5177-5198},
  shortjournal = {Soft Comput.},
  title        = {Supply chain management under uncertainty with the combination of fuzzy multi-objective planning and real options approaches},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Partial label learning via low-rank representation and label
propagation. <em>SOCO</em>, <em>24</em>(7), 5165–5176. (<a
href="https://doi.org/10.1007/s00500-019-04269-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In partial label learning, each training instance is assigned with a set of candidate labels, among which only one is correct. An intuitive strategy to learn from such ambiguous data is disambiguation. Existing methods following such strategy either identify the ground-truth label via treating each candidate label equally or disambiguate the candidate label set via assuming latent variable and optimizing it iteratively. In this paper, we propose a novel two-stage method called partial label learning via low-rank representation and label propagation, where instance similarity and label confidence are taken into consideration to improve the disambiguation ability of the model. In the first stage, we first build the global instance–similarity relationship via low rank representation and sparse constraint and then obtain the accurate instance-label assignments via iterative label propagation strategy. In the second stage, we utilize the Adaboost.R2 to make prediction for unseen instances, where CART is incorporated as the weak classifier. Extensive experiments on the artificial and real-world data sets demonstrate that the proposed method can achieve superior or comparable performance than the comparing state-of-the-art approaches.},
  archive      = {J_SOCO},
  author       = {Lyu, Gengyu and Feng, Songhe and Huang, Wenying and Dai, Guojun and Zhang, Hua and Chen, Baifan},
  doi          = {10.1007/s00500-019-04269-9},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {5165-5176},
  shortjournal = {Soft Comput.},
  title        = {Partial label learning via low-rank representation and label propagation},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). A structure evolution-based design for stable IIR digital
filters using AMECoDEs algorithm. <em>SOCO</em>, <em>24</em>(7),
5151–5163. (<a
href="https://doi.org/10.1007/s00500-019-04268-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a subsystem-based structure evolution algorithm for stable IIR digital filter design. The method designs the IIR digital filter through optimizing the filter structure. A filter structure is defined as the connection of the subsystems. A subsystem is a 2-order IIR digital structure with uncertain parameters. Subsystems are randomly connected with the constraints of no feedback branches between subsystems. The subsystem’s parameters and the connections between subsystems are optimized by evolutionary algorithms. An adaptive multiple-elites-guided composite differential evolution algorithm (AMECoDEs) is used to optimize this problem. Four classic types of filters, lowpass, highpass, bandpass and bandstop filters are designed. Five state-of-the-art evolutionary algorithms are compared. The simulation results show that AMECoDEs holds the first place on comprehensive performance and convergence rate. At the same time, the poles of filters all reside within the unit circle, which validates the stability of the IIR digital filters.},
  archive      = {J_SOCO},
  author       = {Chen, Lijia and Liu, Mingguo and Wang, Zan and Dai, Zhen},
  doi          = {10.1007/s00500-019-04268-w},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {5151-5163},
  shortjournal = {Soft Comput.},
  title        = {A structure evolution-based design for stable IIR digital filters using AMECoDEs algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modelling and simulation of coal gases in a nano-porous
medium: A biologically inspired stochastic simulation. <em>SOCO</em>,
<em>24</em>(7), 5133–5150. (<a
href="https://doi.org/10.1007/s00500-019-04267-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to study the dynamics of the unsteady pressure flow of coal gases caused by the temperature conditions and compressibility in the presence of a nano-porous medium using soft computing technique. To immaculately understand the mechanism, a novelty in the partial differential equation is augmented by considering the fractional-order Caputo derivative, which produces theoretically significant and accurate approximation. Subsequently, the constructed model is experimentally simulated by means of artificial neural network (ANN) and a stochastic process based on a firefly algorithm (FFA). ANN has the ability to approximate and transform the differential equation into an error minimization problem, while FFA efficiently minimizes the error function and optimizes the unknown weights of the constructed network. Furthermore, two error measuring tools; mean absolute error and root mean square error, is also formulated to evaluate the performance index of the designed scheme. Accordingly, the designed scheme is systematically elaborated to assess the pressure sorption of coal gases such as nitrogen (N2) and carbon dioxide (CO2). The accuracy of the obtained approximation shows the competitiveness of the considered scheme. Notably, the deliberation provides substantial indications about the dynamical behaviour of coal gases, which can be implemented significantly on various dynamical problems.},
  archive      = {J_SOCO},
  author       = {Khan, Najeeb Alam and Hameed, Tooba and Razzaq, Oyoon Abdul},
  doi          = {10.1007/s00500-019-04267-x},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {5133-5150},
  shortjournal = {Soft Comput.},
  title        = {Modelling and simulation of coal gases in a nano-porous medium: A biologically inspired stochastic simulation},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Certain indices of graphs under bipolar fuzzy environment
with applications. <em>SOCO</em>, <em>24</em>(7), 5119–5131. (<a
href="https://doi.org/10.1007/s00500-019-04265-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Connectivity index of graph plays a significant role in chemistry, pharmacology, etc. This paper brings in connectivity index of a bipolar fuzzy graph (BFG) with its boundedness. We examine the changes of connectivity index for a BFG when a vertex or an edge is removed. Some theorems related to these are established. The parameter, average connectivity index of a BFG, is introduced with some theorems. Some special types of nodes like bipolar fuzzy connectivity-enhancing node, bipolar fuzzy connectivity-reducing node, bipolar fuzzy connectivity-neutral node with their properties are introduced. Keeping in mind bipolar judgemental thinking, two applications of these thoughts are bestowed to increase the popularity of women football league in India and another is to determine the order of the places to build colleges in a town.},
  archive      = {J_SOCO},
  author       = {Poulik, Soumitra and Ghorai, Ganesh},
  doi          = {10.1007/s00500-019-04265-z},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {5119-5131},
  shortjournal = {Soft Comput.},
  title        = {Certain indices of graphs under bipolar fuzzy environment with applications},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The verification model of multi-focus image fusion by
simulating subjective evaluation. <em>SOCO</em>, <em>24</em>(7),
5111–5118. (<a
href="https://doi.org/10.1007/s00500-019-04263-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a model to simulate the subjective evaluation and compare various fusion algorithms. First, we produce an all-focus image and two multi-focus images by the help of two filters. Second, we fuse two multi-focus images with two representative algorithms WT and CT. Third, we decide the optimal fusion rules of WT and CT by comparing the fused images with an all-focus image. Finally, we improve the performances of fused images by combining several algorithms. Simulation shows the verification model can compare various fusion algorithms or rules. Meanwhile, our fusion model can get better performances than other algorithms or rules.},
  archive      = {J_SOCO},
  author       = {Li, Weitong and Song, Ruijie},
  doi          = {10.1007/s00500-019-04263-1},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {5111-5118},
  shortjournal = {Soft Comput.},
  title        = {The verification model of multi-focus image fusion by simulating subjective evaluation},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The influences of channel subsidy on consumers in a
dual-channel supply chain. <em>SOCO</em>, <em>24</em>(7), 5101–5110. (<a
href="https://doi.org/10.1007/s00500-019-04260-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper examines the influence of subsidies provided by traditional (e.g., a bricks-and-mortar retail mall) and electronic (e.g., Alibaba and Amazon) retail platforms to consumers. We look at the competition between traditional retailers, who sell in a shopping mall, and e-tailers, who sell on the electronic platform. Our focus is on analyzing and demonstrating how these channel subsidies influence (1) pricing behaviors for the e-tailer and the traditional retailer and (2) consumers utilities and channel choices. The main findings are as follows. Whether from the perspective of consumers utilities or from the perspective of consumer channel choice, consumers with different WTP are influenced differently by channel subsidies. While both types of subsidy help the two channels attract some low willingness to pay consumers, the electronic channel subsidy can help the electronic channel attract consumers who are willing to pay more from the traditional channel. The results can help retailers and channel subsidy providers to understand how channel subsidies work, and the differences in the WTP of consumers who purchase products before and after subsidies. This understanding informs retailers’ segmentation, targeting and pricing decisions and helps subsidy providers to make channel subsidy-related decisions.},
  archive      = {J_SOCO},
  author       = {Zhao, Zhang and Chen, Ming-Hsiang and Ke, Hua and Sa Vinhas, Alberto},
  doi          = {10.1007/s00500-019-04260-4},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {5101-5110},
  shortjournal = {Soft Comput.},
  title        = {The influences of channel subsidy on consumers in a dual-channel supply chain},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). An r2 indicator and weight vector-based evolutionary
algorithm for multi-objective optimization. <em>SOCO</em>,
<em>24</em>(7), 5079–5100. (<a
href="https://doi.org/10.1007/s00500-019-04258-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A two-stage R2 indicator-based evolution algorithm (TS-R2EA) was proposed in the recent years. A good balance between convergence and diversity can be achieved, due to the R2 indicator and reference vector-guided selection strategy. However, TSR2-EA is sensitive to problem geometries. In order to address this issue, a weight vector-based selection strategy is introduced, and a weight vector adaptive strategy based on population partition is proposed. In the selection strategy, each candidate solution is ranked according to the scalarizing function values in the corresponding neighbor, and the candidate solutions with good performance can be selected. In the adaptive strategy, the population is partitioned by associating each individual with its closest weight vector, and the weight vectors with a worse performance are adjusted. Similar to TS-R2EA, these strategies are combined with the R2 indicator to solve multi-objective optimization problems. The performance of proposed algorithm has been validated and compared with four related algorithms on a variety of benchmark test problems. The experimental results have demonstrated that the proposed algorithm has high competition and is less sensitive to problem geometries.},
  archive      = {J_SOCO},
  author       = {Liu, Yuanchao and Liu, Jianchang and Li, Tianjun and Li, Qian},
  doi          = {10.1007/s00500-019-04258-y},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {5079-5100},
  shortjournal = {Soft Comput.},
  title        = {An r2 indicator and weight vector-based evolutionary algorithm for multi-objective optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Classification in the multiple instance learning framework
via spherical separation. <em>SOCO</em>, <em>24</em>(7), 5071–5077. (<a
href="https://doi.org/10.1007/s00500-019-04255-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a multiple instance learning problem where the objective is the binary classifications of bags of instances, instead of single ones. We adopt spherical separation as a classification tool and come out with an optimization model which is of difference-of-convex type. We tackle the model by resorting to a specialized nonsmooth optimization algorithm, recently proposed in the literature which is based on objective function linearization and bundling. The results obtained by applying the proposed approach to some benchmark test problems are also reported.},
  archive      = {J_SOCO},
  author       = {Gaudioso, M. and Giallombardo, G. and Miglionico, G. and Vocaturo, E.},
  doi          = {10.1007/s00500-019-04255-1},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {5071-5077},
  shortjournal = {Soft Comput.},
  title        = {Classification in the multiple instance learning framework via spherical separation},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A production inventory supply chain model with partial
backordering and disruption under triangular linguistic dense fuzzy lock
set approach. <em>SOCO</em>, <em>24</em>(7), 5053–5069. (<a
href="https://doi.org/10.1007/s00500-019-04254-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on a three-level distribution process in a supply chain (SC) modeling where the raw materials are received batchwise with imperfect quality. Defective batches are rejected instantly under “all or none” policy. Allowing partial backlogging and random disruption in supply, we develop an expected average cost function of the production inventory SC model first. Then, considering the several cost components of the model as linguistic triangular dense fuzzy lock set, the cost function itself has been fuzzified according to the needs of the problem defined at case study. Utilizing the proper application (growth) of key vectors, the objective function has been solved under crisp, general fuzzy, dense fuzzy, dense fuzzy lock of single and double keys environment, respectively. For managerial importance, numerical results and graphical illustrations are made to justify the novelty.},
  archive      = {J_SOCO},
  author       = {De, Sujit Kumar and Mahata, Gour Chandra},
  doi          = {10.1007/s00500-019-04254-2},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {5053-5069},
  shortjournal = {Soft Comput.},
  title        = {A production inventory supply chain model with partial backordering and disruption under triangular linguistic dense fuzzy lock set approach},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An improved flower pollination algorithm to the urban
transit routing problem. <em>SOCO</em>, <em>24</em>(7), 5043–5052. (<a
href="https://doi.org/10.1007/s00500-019-04253-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The urban transit routing problem is NP-Hard, referring to the design of effective bus routes on the existing road networks. Current studies mainly focus on the models and the application of algorithms, and the improvements in the operation process in the algorithm such as the construction of initial solutions and the transformation methods are not investigated in detail. In order to optimize bus routes, the initial bus route set generation method, the local search, and the global search of the flower pollination algorithm were improved. Taking the average travel time of passengers and the proportion of the number of transfers as the optimization objective, an improved initial population generative method and an improved framework of flower pollination algorithm were applied to obtain a better set of bus routes. Finally, the effectiveness of the improved algorithm was verified based on some experimental results and compared to the previous bus networks such as Mandl’s Switzerland network.},
  archive      = {J_SOCO},
  author       = {Fan, Lang and Chen, Hui and Gao, Ying},
  doi          = {10.1007/s00500-019-04253-3},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {5043-5052},
  shortjournal = {Soft Comput.},
  title        = {An improved flower pollination algorithm to the urban transit routing problem},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Effective collaborative strategies to setup tuners.
<em>SOCO</em>, <em>24</em>(7), 5019–5041. (<a
href="https://doi.org/10.1007/s00500-019-04252-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parameter setting problem has demonstrated being a relevant problem related to the use of metaheuristics. ParamILS and I-Race are sophisticated tuning methods that can provide valuable information for designers as well as manage conditional parameters. However, the quality of parameter configurations they can find strongly depends on a proper definition of parameter search space. Evoca is a recently proposed tuner which has demonstrated being less sensitive to the setup of parameters search space. In this paper, we propose an effective collaborative approach that combines Evoca and I-Race as well as Evoca and ParamILS. In both collaborative strategies, Evoca is used to define a proper parameter search space for each tuner. Results demonstrated that the collaborative approaches studied are able to find good parameter configurations reducing the effort required to properly define the parameter search space.},
  archive      = {J_SOCO},
  author       = {Montero, Elizabeth and Riff, María-Cristina},
  doi          = {10.1007/s00500-019-04252-4},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {5019-5041},
  shortjournal = {Soft Comput.},
  title        = {Effective collaborative strategies to setup tuners},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel distance-based multiple attribute decision-making
with hesitant fuzzy sets. <em>SOCO</em>, <em>24</em>(7), 5005–5017. (<a
href="https://doi.org/10.1007/s00500-019-04250-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Up to now, various types of distance measures have been developed and investigated in-depth for hesitant fuzzy sets (HFSs). The analytical study of the existing distance measures for HFSs shows that they have still some limitations. In an attempt to overcome the limitations, this study develops a class of Hausdorff-based distances to measure the distance among HFSs which are not restricted to the same length of their hesitant fuzzy elements (HFEs) and of course the arranging order of values in the HFEs. Furthermore, these HFS distance measures do satisfy all well-known and essential axioms, specially, the triangle inequality property. Eventually, we present some examples to illustrate the efficiency of the new developed HFS distance measures together with a comparative analysis with other existing ones.},
  archive      = {J_SOCO},
  author       = {Farhadinia, Bahram and Xu, Zeshui},
  doi          = {10.1007/s00500-019-04250-6},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {5005-5017},
  shortjournal = {Soft Comput.},
  title        = {A novel distance-based multiple attribute decision-making with hesitant fuzzy sets},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel method for day-ahead solar power prediction based on
hidden markov model and cosine similarity. <em>SOCO</em>,
<em>24</em>(7), 4991–5004. (<a
href="https://doi.org/10.1007/s00500-019-04249-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, with the emergence of new technologies such as smart grid and increasing the use of renewable energy in the grid, energy prediction has become more important in the electricity industry. Furthermore, with growing the integration of power generated from renewable energy sources into grids, an accurate forecasting tool for the reduction in undesirable effects of this scenario is essential. This study has developed a novel approach based on the hidden Markov model (HMM) for forecasting day-ahead solar power. The aim is to find a pattern of solar power changes at a given time in consecutive days. The proposed approach consists of two steps. In the first step, the cosine similarity is used to determine the similarity of solar power variations on consecutive days to a particular vector. In the second step, the obtained information from the first step is fed to HMM as a feature vector. These data are used for training and forecasting day-ahead solar power. After obtaining the preliminary results of the prediction, two known filters are utilized as post-processing to remove spikes and smooth the results. Finally, the performance of the proposed method is tested on real NREL data. No meteorological data (even solar radiation) are used; moreover, the model is fed only from the solar power of the past 23 days. To evaluate the proposed method, a feed-forward neural network and a simple HMM are examined with the same data and conditions. All three methods are tested with and without the post-processing. The results show that the proposed model is superior to other examined methods in terms of accuracy and computational time.},
  archive      = {J_SOCO},
  author       = {Ghasvarian Jahromi, Khatereh and Gharavian, Davood and Mahdiani, Hamidreza},
  doi          = {10.1007/s00500-019-04249-z},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {4991-5004},
  shortjournal = {Soft Comput.},
  title        = {A novel method for day-ahead solar power prediction based on hidden markov model and cosine similarity},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The grey generalized verhulst model and its application for
forecasting chinese pig price index. <em>SOCO</em>, <em>24</em>(7),
4977–4990. (<a
href="https://doi.org/10.1007/s00500-019-04248-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Verhulst model is used in many natural and social systems. When simulating and predicting system sequences with an inverted U shape or a signal peak feature by the grey Verhulst model (abbreviated as GVM), such as the pig price index, a drift phenomenon happens sometimes. We introduce a grey generalized Verhulst model named as GGVM to address this problem. Compared with the GVM, the GGVM contains a constant as the grey action quantity. Besides, the multivariable grey generalized Verhulst model is also given. Three cases containing Glipizide tablets blood drug concentration series, the number of traffic deaths, and consumer price index (abbreviated as CPI) sequences are utilized to demonstrate that GGVM can eliminate the drift phenomenon effectively. Given that the pork is the most consumed meat for Chinese residents and the fluctuation of its price is closely related to the interests of residents and pig-breeding enterprises, it is important to predict the pork price. So the prediction of pork price index whose time series possesses an inverted U shape is carried out by GGVM, GVM, and intelligent algorithm models, including LSSVR, $$\varepsilon $$-SVR, and RBF in the empirical part. The results show that GGVM produces higher accurate simulation and prediction than the models as given above.},
  archive      = {J_SOCO},
  author       = {Zhou, Weijie and Pei, Lingling},
  doi          = {10.1007/s00500-019-04248-0},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {4977-4990},
  shortjournal = {Soft Comput.},
  title        = {The grey generalized verhulst model and its application for forecasting chinese pig price index},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Utilizing data science techniques to analyze skill and
demand changes in healthcare occupations: Case study on USA and UAE
healthcare sector. <em>SOCO</em>, <em>24</em>(7), 4959–4976. (<a
href="https://doi.org/10.1007/s00500-019-04247-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {New technologies are emerging on a continual basis with drastic trajectories and wider penetration into the job market. Health care is among the top ten sectors in terms of talent turnover rates. Hence, being proactive—by predicting what skills will be in demand, is essential to be prepared for these changes. To predict such transitions, this paper aims to develop a job analysis system with an example from the healthcare field in two countries; United States of America and United Arab Emirates. This empirical research consists of using data science with the help of multiple techniques. To study changes in job demand, we deployed Latent Semantic Indexing (LSI) and Latent Dirichlet Allocation (LDA) models; while for the skill changes we used techniques Factor Analysis and Non-Negative Matrix Factorization. Using different heatmaps visualizations of the LSI and LDA weights, results provided significant insights into the skill sets and demand changes in both job markets. The study concludes that low-skilled jobs are constantly being replaced by automated systems, while some of the high skill sets are also at risk.},
  archive      = {J_SOCO},
  author       = {Alibasic, Armin and Simsekler, Mecit Can Emre and Kurfess, Thomas and Woon, Wei Lee and Omar, Mohammad Atif},
  doi          = {10.1007/s00500-019-04247-1},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {4959-4976},
  shortjournal = {Soft Comput.},
  title        = {Utilizing data science techniques to analyze skill and demand changes in healthcare occupations: Case study on USA and UAE healthcare sector},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel switching function approach for data mining
classification problems. <em>SOCO</em>, <em>24</em>(7), 4941–4957. (<a
href="https://doi.org/10.1007/s00500-019-04246-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rule induction (RI) is one of the known classification approaches in data mining. RI extracts hidden patterns from instances in terms of rules. This paper proposes a logic-based rule induction (LBRI) classifier based on a switching function approach. LBRI generates binary rules by using a novel minimization function, which depends on simple and powerful bitwise operations. Initially, LBRI generates instance codes by encoding the dataset with standard binary code and then generates prime cubes (PC) for all classes from the instance codes by the proposed reduced offset method. Finally, LBRI selects the most effective PC of the current classes and adds them into the binary rule set that belongs to the current class. Each binary rule represents an If–Then rule for the rule induction classifiers. The proposed LBRI classifier is based on basic logic functions. It is a simple and effective method, and it can be used by intelligent systems to solve real-life classification/prediction problems in areas such as health care, online/financial banking, image/voice recognition, and bioinformatics. The performance of the proposed algorithm is compared to six rule induction algorithms; decision table, Ripper, C4.5, REPTree, OneR, and ICRM by using nineteen different datasets. The experimental results show that the proposed algorithm yields better classification accuracy than the other rule induction algorithms on ten out of nineteen datasets.},
  archive      = {J_SOCO},
  author       = {Ibrahim, Mohammed Hussein and Hacibeyoglu, Mehmet},
  doi          = {10.1007/s00500-019-04246-2},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {4941-4957},
  shortjournal = {Soft Comput.},
  title        = {A novel switching function approach for data mining classification problems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel cuckoo search algorithm under adaptive parameter
control for global numerical optimization. <em>SOCO</em>,
<em>24</em>(7), 4917–4940. (<a
href="https://doi.org/10.1007/s00500-019-04245-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cuckoo search (CS) is a well-known population-based stochastic search technique for solving global numerical optimization problems. At each iteration process, CS searches for new solutions by Lévy flights random walk together with a local random walk (LRW). For LRW, mutation proceeds with a uniformly distributed random number in the interval [0, 1] as its mutation factor, which plays an important role in controlling the population diversity and the explorative power of the algorithm. However, this mutation factor generally results in sensitivity to the given optimization problem and thus fails to balance well these two aspects. In view of this consideration, we introduce a simple adaptive parameter control mechanism to LRW, and propose a novel adaptive cuckoo search (CSAPC) algorithm in this paper to improve the optimization performance of CS. The adaptive parameter control mechanism dynamically updates the control parameters based on a Cauchy distribution and the Lehmer mean during the iteration. To verify the performance of CSAPC, simulations and comparisons are conducted on 48 benchmark functions from two well-known test suites. In order to further test its efficacy, CSAPC is applied to solve the problem of parameter estimation of two typical uncertain fractional-order chaotic systems. The numerical, statistical and graphical analysis demonstrates the great competency of CSAPC, and hence can be regarded as an efficient and promising tool for solving the real-world complex optimization problems besides the benchmark problems.},
  archive      = {J_SOCO},
  author       = {Wei, Jiamin and Yu, Yongguang},
  doi          = {10.1007/s00500-019-04245-3},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {4917-4940},
  shortjournal = {Soft Comput.},
  title        = {A novel cuckoo search algorithm under adaptive parameter control for global numerical optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-criteria decision making approach based on PROMETHEE
with probabilistic simplified neutrosophic sets. <em>SOCO</em>,
<em>24</em>(7), 4899–4915. (<a
href="https://doi.org/10.1007/s00500-019-04244-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic simplified neutrosophic set $$ \left( {PSNS} \right) $$ is an important tool to describe the vagueness existing in the real life. In this study, we define a PSNS and discuss some of theoretical set operations of $$ PSNSs $$. Also we propose the concepts of module on $$ PSNSs $$, as well as inner product and projection operator between two $$ PSNSs $$. In relation to this new set, we introduce a probabilistic simplified neutrosophic number $$ \left( {PSNN} \right) $$. A $$ PSNN $$ has three components which is called probabilistic-valued truth membership degree, probabilistic-valued indeterminacy membership degree and probabilistic-valued falsity membership degree, respectively. We give some of algebraic operational rules, a score function and an accuracy function on $$ PSNNs $$. Furthermore, we introduce two aggregation operators called the probabilistic simplified neutrosophic weighted arithmetic average operator and the probabilistic simplified weighted geometric average operator on $$ PSNNs $$. Furthermore, we determine weights of criteria with a method that is based on fuzzy measure and develop a method based on preference function to determine weight of each decision maker. We present an extended PROMETHEE method based on $$ PSNSs $$ for group decision problems. Finally, as an application of this theory, we give a practice on a multi-criteria group decision making problem based on $$ PSNNs $$ by using extended PROMETHEE method to ensure stability of the proposed method.},
  archive      = {J_SOCO},
  author       = {Altun, Fatma and Şahin, Rıdvan and Güler, Coşkun},
  doi          = {10.1007/s00500-019-04244-4},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {4899-4915},
  shortjournal = {Soft Comput.},
  title        = {Multi-criteria decision making approach based on PROMETHEE with probabilistic simplified neutrosophic sets},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cuckoo search and firefly algorithms in terms of generalized
net theory. <em>SOCO</em>, <em>24</em>(7), 4877–4898. (<a
href="https://doi.org/10.1007/s00500-019-04241-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the presented paper, the functioning and the results of the work of two metaheuristic algorithms, namely cuckoo search algorithm (CS) and firefly algorithm (FA), are described using the apparatus of generalized nets (GNs), which is an appropriate and efficient tool for describing the essence of various optimization methods. The two developed GN-models mimic the optimization processes based on the nature of cuckoos and fireflies, respectively. The proposed GN-models execute the two considered metaheuristic algorithms conducting basic steps and performing optimal search. Building upon these two GN-models, a universal GN-model is constructed that can be used for describing and simulating both the CS and the FA by setting different characteristic functions of the GN-tokens. Moreover, the universal GN-model itself can be transformed to each of the herewith presented GN-models by applying appropriate hierarchical operators. In order to validate the proposed universal GN-model, numerical experiments are performed for the operating of the universal GN-model (CS and FA) on benchmark mathematical functions. The obtained results are compared with the results of the GN-model of CS, GN-model of FA, as well as the results of the standard CS and FA.},
  archive      = {J_SOCO},
  author       = {Roeva, Olympia and Zoteva, Dafina and Atanassova, Vassia and Atanassov, Krassimir and Castillo, Oscar},
  doi          = {10.1007/s00500-019-04241-7},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {4877-4898},
  shortjournal = {Soft Comput.},
  title        = {Cuckoo search and firefly algorithms in terms of generalized net theory},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). GuASPSO: A new approach to hold a better
exploration–exploitation balance in PSO algorithm. <em>SOCO</em>,
<em>24</em>(7), 4855–4875. (<a
href="https://doi.org/10.1007/s00500-019-04240-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new variant of particle swarm optimization (PSO) algorithm named guided adaptive search-based particle swarm optimizer (GuASPSO). In this algorithm, the personal best particles are all divided into a linearly decreasing number of clusters. Then, the unique global best guide of a given particle located at a cluster is obtained as the weighted average calculated over other clusters’ best particles. Since the clustered particles are being well-distributed over the whole search space in the clustering process, there would be a moderate distance between each particle and its unique global best guide, contributing the particles neither to be trapped in local optima nor engaged in a drift leading to lose diversity in the search space. In this approach, the number of clusters is high at the early iterations and is gradually decreased by lapse of iterations to less stress the diversity factor and further stress the fitness role to cause the particles to better converge to the optimal point. Holding this balance between global and personal bests’ role to attract the particles, on the one hand and between convergence and diversity, on the other hand, can hold a better exploration–exploitation balance in the proposed algorithm. To test the performance of GuASPSO, four popular meta-heuristic algorithms, including genetic algorithm, gravitational search algorithm, gray wolf optimizer, and PSO algorithm as well as 23 standard benchmark functions as the test beds, are employed. The experimental results validated GuASPSO as a robust well-designed algorithm to handle various optimization problems.},
  archive      = {J_SOCO},
  author       = {Rezaei, Farshad and Safavi, Hamid R.},
  doi          = {10.1007/s00500-019-04240-8},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {4855-4875},
  shortjournal = {Soft Comput.},
  title        = {GuASPSO: A new approach to hold a better exploration–exploitation balance in PSO algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A soft computing model based on asymmetric gaussian mixtures
and bayesian inference. <em>SOCO</em>, <em>24</em>(7), 4841–4853. (<a
href="https://doi.org/10.1007/s00500-019-04238-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel unsupervised Bayesian learning framework based on asymmetric Gaussian mixture (AGM) statistical model is proposed since AGM is shown to be more effective compared to the classic Gaussian mixture model. The Bayesian learning framework is developed by adopting sampling-based Markov chain Monte Carlo (MCMC) methodology. More precisely, the fundamental learning algorithm is a hybrid Metropolis–Hastings within Gibbs sampling solution which is integrated within a reversible jump MCMC learning framework, a self-adapted sampling-based implementation, that enables model transfer throughout the mixture parameters learning process and therefore automatically converges to the optimal number of data groups. Furthermore, in order to handle high-dimensional vectors of features, a dimensionality reduction algorithm based on mixtures of distributions is included to tackle the irrelevant and extraneous features. The performance comparison between AGM and other popular models is given, and both synthetic and real datasets extracted from challenging applications such as intrusion detection, spam filtering and image categorization are evaluated to show the merits of the proposed approach.},
  archive      = {J_SOCO},
  author       = {Fu, Shuai and Bouguila, Nizar},
  doi          = {10.1007/s00500-019-04238-2},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {4841-4853},
  shortjournal = {Soft Comput.},
  title        = {A soft computing model based on asymmetric gaussian mixtures and bayesian inference},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dynamic economic dispatch incorporating renewable energy
sources and pumped hydroenergy storage. <em>SOCO</em>, <em>24</em>(7),
4829–4840. (<a
href="https://doi.org/10.1007/s00500-019-04237-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to mounting infiltration of solar and wind energy sources, it becomes essential to investigate its brunt on the dynamic economic dispatch. Here, solar–wind–thermal system integrating pumped-storage hydraulic unit has been considered. This work recommends chaotic fast convergence evolutionary programming (CFCEP) rooted in Tent equation for solving dynamic economic dispatch problem incorporating renewable energy sources and pumped-storage hydraulic unit. Chaotic sequences increase the exploitation ability in the searching space and enhance the convergence property. In the recommended technique, chaotic sequences have been pertained for acquiring the dynamic scaling factor setting in fast convergence evolutionary programming (FCEP). The efficiency of the recommended technique is revealed on two test systems. Simulation outcomes of the suggested technique have been matched up to those acquired by FCEP, differential evolution and particle swarm optimization. It has been observed from the comparison that the recommended CFCEP technique has the capability to confer with better quality solution.},
  archive      = {J_SOCO},
  author       = {Basu, Mousumi},
  doi          = {10.1007/s00500-019-04237-3},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {4829-4840},
  shortjournal = {Soft Comput.},
  title        = {Dynamic economic dispatch incorporating renewable energy sources and pumped hydroenergy storage},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). M-MBOA: A novel butterfly optimization algorithm enhanced
with mutualism scheme. <em>SOCO</em>, <em>24</em>(7), 4809–4827. (<a
href="https://doi.org/10.1007/s00500-019-04234-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The simplicity and effectiveness of a recently proposed metaheuristic, butterfly optimization algorithm (BOA) have gained huge popularity among research community and are being used to solve optimization problems in various disciplines. However, the algorithm is suffering from poor exploitation ability and has a tendency to show premature convergence to local optima. On the other hand, the mutualism phase of another popular metaheuristic symbiosis organisms search (SOS) is known for its exploitation capability. In this paper, a novel hybrid algorithm, namely m-MBOA is proposed to enhance the exploitation ability of BOA with the help of mutualism phase of SOS. To evaluate the effectiveness of m-MBOA, thirty-seven (37) classical benchmark functions are considered and the performance of m-MBOA is compared with the performance of ten (10) state-of-the-art algorithms. Statistical tools have been employed to observe the efficiency of the m-MBOA qualitatively, and obtained results confirm the superiority of the proposed algorithm compared to the state-of-the-art metaheuristic algorithms. Finally, four real-life optimization problem, namely gear train design problem, gas compressor design problem, cantilever beam design problem and three-bar truss design problem are solved with the help of the newly proposed algorithm, and the results are compared with the obtained results of different popular state-of-the-art optimization techniques and found that the proposed algorithm is more efficient than the compared algorithms.},
  archive      = {J_SOCO},
  author       = {Sharma, Sushmita and Saha, Apu Kumar},
  doi          = {10.1007/s00500-019-04234-6},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {4809-4827},
  shortjournal = {Soft Comput.},
  title        = {M-MBOA: A novel butterfly optimization algorithm enhanced with mutualism scheme},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Identification in the delta domain: A unified approach via
GWOCFA. <em>SOCO</em>, <em>24</em>(7), 4791–4808. (<a
href="https://doi.org/10.1007/s00500-019-04232-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The identification of linear dynamic systems in the delta domain has been proposed in this paper with the help of a hybrid metaheuristic algorithm combining chaotic firefly algorithm (CFA) and grey wolf optimiser (GWO). GWO performs the global search, while CFA fine-tunes the solutions through its local search abilities, thereby balancing exploration and exploitation features. Linear systems with static nonlinearities at the input are termed as the Hammerstein model, whereas linear systems with static nonlinearities at the output are known as the Wiener model. A test case with continuous polynomial nonlinearities has been taken up for Hammerstein and Wiener system identification in the delta domain. Delta operator parameterisation unifies identification of continuous-time systems with the discrete domain at a higher sampling rate. Pseudo-random binary sequence (PRBS), polluted with white Gaussian noise of fixed signal-to-noise ratio (SNR), has been considered as the input signal to estimate the unknown model parameters as well as static nonlinear coefficients. The hybrid algorithm not only supersedes the parent heuristics of which it is constituted but also proves better in comparison with some standard and latest heuristic approaches reported in the literature. Nonparametric statistical tests are performed to validate the results. The plots of fitness function (normalised value) against the number of iterations also support the convergence speed and accuracy of the results.},
  archive      = {J_SOCO},
  author       = {Ganguli, Souvik and Kaur, Gagandeep and Sarkar, Prasanta},
  doi          = {10.1007/s00500-019-04232-8},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {4791-4808},
  shortjournal = {Soft Comput.},
  title        = {Identification in the delta domain: A unified approach via GWOCFA},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modeling, simulation, estimation and boundedness analysis of
discrete event systems. <em>SOCO</em>, <em>24</em>(7), 4775–4789. (<a
href="https://doi.org/10.1007/s00500-019-04231-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a particular state model allowing describing the system evolution in time is proposed. This state model contains two inequalities describing the evolution in time of the system state and input. The system simulation is based on the resolution of this state model. After that, a state estimator is proposed in order to estimate the whole system state and inputs. The state model and the observer are both proposed following count and dater approaches successively. In this work, the considered state is the number of transition firing if a count approach is followed and the dates of firing if the dater approach is considered. It is proved, using an illustrative example, that the proposed observer estimates well the system state by comparing the simulated and the estimated states. A boundedness analysis of the system trajectory is proposed in the case of FCF Petri nets. This analysis is based on an algorithm which gives the bounded transitions knowing the system input. Some particular tables are elaborated to describe the proposed algorithm. Theses tables give the bounded transitions after each iteration of the algorithm.},
  archive      = {J_SOCO},
  author       = {Khedher, Atef and BenOthman, Kamal},
  doi          = {10.1007/s00500-019-04231-9},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {4775-4789},
  shortjournal = {Soft Comput.},
  title        = {Modeling, simulation, estimation and boundedness analysis of discrete event systems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An ANFIS–TLBO criterion for shear failure of rock joints.
<em>SOCO</em>, <em>24</em>(7), 4759–4773. (<a
href="https://doi.org/10.1007/s00500-019-04230-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The strength behavior of a rock mass is often controlled by different discontinuities therein, along which the structural failures may threaten rock structures. Thus, the shear strength criteria for rock joints have always been a fundamental topic in rock mechanics. Knowing the different aspects of the rock joint shear strength based on the previously presented criteria, it is time to try different approaches other than the regression analysis in order to model the nonlinear behavior of rock joints. This research focuses on the estimation of the shear strength of rock joints using the computational intelligence. A total of 84 direct shear tests were first performed on replicas of natural rock fractures with various mechanical and morphological characteristics under several normal stress levels. Then, an adaptive neuro-fuzzy inference system (ANFIS) combined with a teaching–learning-based optimization (TLBO) algorithm was used to establish a new shear strength criterion. The results demonstrated that the ANFIS–TLBO criterion provided an accurate estimation of rock joint shear strength. A comparison between the ANFIS–TLBO criterion and the Barton’s empirical equation revealed a better performance of the suggested model in mapping the experimental data. The ANFIS–TLBO model’s residual indicated a random pattern, and its histogram exhibited a symmetric bell-shaped distribution around zero, supporting the appropriateness of the model.},
  archive      = {J_SOCO},
  author       = {Babanouri, Nima and Fattahi, Hadi},
  doi          = {10.1007/s00500-019-04230-w},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {4759-4773},
  shortjournal = {Soft Comput.},
  title        = {An ANFIS–TLBO criterion for shear failure of rock joints},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Grayscale images colorization with convolutional neural
networks. <em>SOCO</em>, <em>24</em>(7), 4751–4758. (<a
href="https://doi.org/10.1007/s00500-020-04711-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous approaches to the colorization of grayscale images rely on human manual labor and often produce desaturated results that are not likely to be true colorizations. Inspired by Matías Richart’s paper, we proposed an automatic approach based on deep neural networks to color the image in grayscale. We have studied several models, approaches and loss functions to understand the best practices for producing a plausible colorization. By noting that some loss functions work better than others, we used the VGG-16 CNN model based on the classification with the loss of cross-entropy. The experiment shows that our model can produce a plausible colorization.},
  archive      = {J_SOCO},
  author       = {An, Jiancheng and Kpeyiton, Koffi Gagnon and Shi, Qingnan},
  doi          = {10.1007/s00500-020-04711-3},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {4751-4758},
  shortjournal = {Soft Comput.},
  title        = {Grayscale images colorization with convolutional neural networks},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An application of soft computing for the earth stress
analysis in hydropower engineering. <em>SOCO</em>, <em>24</em>(7),
4739–4749. (<a
href="https://doi.org/10.1007/s00500-019-04542-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a soft computing of integrating artificial neural networks (ANNs) and genetic algorithms (GAs) to back analyze the earth stress field based on hydraulic fracturing. In this method, the ANN model is employed to map the relationship between the earth stress parameters and hydraulic fracturing behavior instead of numerical computation, and the advantage of this work is that it can conveniently conduct the integration of ANN and optimization algorithm and effectively reduce the workload of numerical computation by using directly the field-measured information to build learning samples. In addition, this can also improve accuracy of earth stress determination from field test data sets for ANN model. The GA is applied to implement multi-objective earth stress parameters optimization on the basis of the objective function. The field monitoring information in a practical project of hydropower engineering is used to verify the proposed soft computing in this study. Investigation results demonstrate that the proposed methodology is capable and valuable in addressing geomechanical parameters determination in hydropower engineering.},
  archive      = {J_SOCO},
  author       = {Zhang, Shike and Yuan, Yuan and Fang, Hongyuan and Wang, Fuming},
  doi          = {10.1007/s00500-019-04542-x},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {4739-4749},
  shortjournal = {Soft Comput.},
  title        = {An application of soft computing for the earth stress analysis in hydropower engineering},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Effects of direct input–output connections on multilayer
perceptron neural networks for time series prediction. <em>SOCO</em>,
<em>24</em>(7), 4729–4738. (<a
href="https://doi.org/10.1007/s00500-019-04480-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feedforward neural network prediction is the most commonly used method in time series prediction. In view of the low prediction accuracy of the conventional BPNN model when the time series data contain a certain linear relationship, this paper describes a neural network approach for time series prediction, that is BPNN–DIOC (back-propagation neural network with direct input-to-output connections). Eight different datasets were used to verify the validity of BPNN–DIOC model in time series prediction. In this paper, the BPNN was extended to four variants based on the presence or absence of output layer bias and input-to-output connections firstly, and the prediction accuracy of eight datasets are analyzed by statistic method secondly. Finally, the experimental results demonstrate that the BPNN–DIOC has better prediction accuracy compared to the conventional BPNN while the output layer bias has no significant effect. Therefore, the input-to-output connections can significantly improve the prediction ability of time series.},
  archive      = {J_SOCO},
  author       = {Wang, Yaoli and Wang, Lipo and Chang, Qing and Yang, Chunxia},
  doi          = {10.1007/s00500-019-04480-8},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {4729-4738},
  shortjournal = {Soft Comput.},
  title        = {Effects of direct input–output connections on multilayer perceptron neural networks for time series prediction},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Ensemble learning via constraint projection and
undersampling technique for class-imbalance problem. <em>SOCO</em>,
<em>24</em>(7), 4711–4727. (<a
href="https://doi.org/10.1007/s00500-019-04501-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensemble learning is an effective technique for the class-imbalance problem, and the key for obtaining a successful ensemble is to create individual base classifiers with high accuracy and diversity. In this paper, we propose a novel ensemble learning method via constraint projection and undersampling technique, constructing each base classifier through the following two steps: 1) constructing a set of pairwise constraints by undersampling examples from the minority/majority class set and learning a projection matrix from the pairwise constraint set and 2) undersampling the original training set to obtaining a new training set on which a base classifier is constructed in the new feature space defined by the projection matrix. For the first step, the projection matrix is mainly used to enhance the separability between the diverse class examples and thus to improve the performance of the base classifier, and the undersampling technique is used to create diverse sets of pairwise constraints to train diverse projection matrices, thus introducing diversity to base classifiers. For the second step, the undersampling technique aims to improve the performance of base classifiers on the minority class and further increase the diversity between the individual base classifiers. The experimental results show that the proposed method shows significantly better performance on the measures of recall, g-mean, f-measure and AUC than other state-of-the-art methods for 29 datasets with various data distributions and imbalance ratios.},
  archive      = {J_SOCO},
  author       = {Guo, Huaping and Zhou, Jun and Wu, Chang-an},
  doi          = {10.1007/s00500-019-04501-6},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {4711-4727},
  shortjournal = {Soft Comput.},
  title        = {Ensemble learning via constraint projection and undersampling technique for class-imbalance problem},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Editorial for special section on ICNC-FSKD 2017.
<em>SOCO</em>, <em>24</em>(7), 4709. (<a
href="https://doi.org/10.1007/s00500-020-04817-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SOCO},
  author       = {Wang, Lipo},
  doi          = {10.1007/s00500-020-04817-8},
  journal      = {Soft Computing},
  number       = {7},
  pages        = {4709},
  shortjournal = {Soft Comput.},
  title        = {Editorial for special section on ICNC-FSKD 2017},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A dynamic expert contribution-based consensus model for
hesitant fuzzy group decision making with an application to water
resources allocation selection. <em>SOCO</em>, <em>24</em>(6),
4693–4708. (<a
href="https://doi.org/10.1007/s00500-019-04229-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research focuses on group decision making (GDM) under hesitant fuzzy condition. All experts (decision makers) are allowed to use hesitant fuzzy preference relations (HFPRs) to express their opinions. Subsequently, a dynamically expert contribution-based consensus model is developed for GDM with HFPRs. In the proposed method, a combination of a weight update model and a preference adjustment model is applied to consensus reaching processes (CRPs). In the weight update model, we propose to dynamically update experts’ weights according to their contributions in the CRPs. In the preference adjustment model, only the preferences which are far away from the expected values are modified, aiming to retain the experts’ original information as much as possible. Finally, the proposed model is applied to water resources allocation selection to show how it works in practice. And some comparisons and discussions are given to show the advantages of the proposed method.},
  archive      = {J_SOCO},
  author       = {Xu, Yejun and Liu, Xia and Xu, Lizhong},
  doi          = {10.1007/s00500-019-04229-3},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4693-4708},
  shortjournal = {Soft Comput.},
  title        = {A dynamic expert contribution-based consensus model for hesitant fuzzy group decision making with an application to water resources allocation selection},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A fuzzy similarity-based rough set approach for attribute
selection in set-valued information systems. <em>SOCO</em>,
<em>24</em>(6), 4675–4691. (<a
href="https://doi.org/10.1007/s00500-019-04228-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Databases obtained from different search engines, market data, patients’ symptoms and behaviours, etc., are some common examples of set-valued data, in which a set of values are correlated with a single entity. In real-world data deluge, various irrelevant attributes lower the ability of experts both in speed and in predictive accuracy due to high dimension and insignificant information, respectively. Attribute selection is the concept of selecting those attributes that ideally are necessary as well as sufficient to better describe the target knowledge. Rough set-based approaches can handle uncertainty available in the real-valued information systems after the discretization process. In this paper, we introduce a novel approach for attribute selection in set-valued information system based on tolerance rough set theory. The fuzzy tolerance relation between two objects using a similarity threshold is defined. We find reducts based on the degree of dependency method for selecting best subsets of attributes in order to obtain higher knowledge from the information system. Analogous results of rough set theory are established in case of the proposed method for validation. Moreover, we present a greedy algorithm along with some illustrative examples to clearly demonstrate our approach without checking for each pair of attributes in set-valued decision systems. Examples for calculating reduct of an incomplete information system are also given by using the proposed approach. Comparisons are performed between the proposed approach and fuzzy rough-assisted attribute selection on a real benchmark dataset as well as with three existing approaches for attribute selection on six real benchmark datasets to show the supremacy of proposed work.},
  archive      = {J_SOCO},
  author       = {Singh, Shivani and Shreevastava, Shivam and Som, Tanmoy and Somani, Gaurav},
  doi          = {10.1007/s00500-019-04228-4},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4675-4691},
  shortjournal = {Soft Comput.},
  title        = {A fuzzy similarity-based rough set approach for attribute selection in set-valued information systems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Parameterized utility functions on interval-valued
intuitionistic fuzzy numbers with two kinds of entropy and their
application in multi-criteria decision making. <em>SOCO</em>,
<em>24</em>(6), 4667–4674. (<a
href="https://doi.org/10.1007/s00500-019-04227-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, the entropy of interval-valued intuitionistic fuzzy numbers (IVIFNs) is analyzed, and two kinds of entropy factors are proposed. By using the normalized score function, normalized Type-1 entropy factor, and normalized Type-2 entropy factor, a series of utility functions on IVIFNs are proposed. In particular, one of the proposed utility functions is structured based on integral. By using the proposed utility functions, IVIFNs can be compared and ranked. The characteristic of these proposed utility functions is that they are objective on comparing IVIFNs from the point of probability. Thereafter, two kinds of fuzzy multi-criteria decision-making methods in interval-valued intuitionistic fuzzy setting are introduced by using the proposed entropy functions. Finally, an example is given to demonstrate the effectiveness of the proposed utility functions and the fuzzy multi-criteria decision-making methods.},
  archive      = {J_SOCO},
  author       = {Zhang, Fangwei and Huang, Weiwei and Li, Qiang and Wang, Shuhong and Tan, Guoqiang},
  doi          = {10.1007/s00500-019-04227-5},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4667-4674},
  shortjournal = {Soft Comput.},
  title        = {Parameterized utility functions on interval-valued intuitionistic fuzzy numbers with two kinds of entropy and their application in multi-criteria decision making},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel hybrid GA–PSO framework for mining quantitative
association rules. <em>SOCO</em>, <em>24</em>(6), 4645–4666. (<a
href="https://doi.org/10.1007/s00500-019-04226-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discovering association rules is a useful and common technique for data mining in which dependencies among datasets are shown. Discovering the rules from continuous numeric datasets is one of the common challenges in data mining. Furthermore, another restriction imposed by algorithms in this area is the need to determine the minimum threshold for the criteria of support and confidence. By drawing on two heuristic optimization techniques, to wit, the genetic algorithm (GA) and particle swarm optimization (PSO) algorithm, a hybrid algorithm for extracting quantitative association rules was developed in this research. Accurate and interpretable rules result from the integration of the multiple objectives GA with the multiple objective PSO algorithms, which redresses the balance in the exploitation and exploration tasks. The useful and appropriate rules and the most suitable numerical intervals are discovered by proposing a multi-criteria method in which there is no need to discretize numerical values and to determine threshold values of minimum support and confidence. Different criteria are used to determine appropriate rules. In this algorithm, the selected rules are extracted based on confidence, interestingness and comprehensibility. The results gained over five real-world datasets evidence the effectiveness of the proposed method. By hybridization of the GA and the PSO algorithm, the proposed approach has achieved considerable improvements compared with the basic algorithms in the criteria of the number of extracted rules from dataset, high confidence measure and support percentage.},
  archive      = {J_SOCO},
  author       = {Moslehi, Fateme and Haeri, Abdorrahman and Martínez-Álvarez, Francisco},
  doi          = {10.1007/s00500-019-04226-6},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4645-4666},
  shortjournal = {Soft Comput.},
  title        = {A novel hybrid GA–PSO framework for mining quantitative association rules},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An adaptive sliding mode controller based on online support
vector regression for nonlinear systems. <em>SOCO</em>, <em>24</em>(6),
4623–4643. (<a
href="https://doi.org/10.1007/s00500-019-04223-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel adaptive sliding mode controller (SMC) based on support vector regression (SVR) is introduced for nonlinear systems. The closed-loop margin notion introduced for self-tuning regulators is rearranged in order to optimize the parameters of SMC. The proposed adjustment mechanism consists of an online SVR to identify the forward dynamics of the controlled system and SMC parameter estimators realized by separate online SVRs to approximate each tunable controller parameter. The performance of the proposed control architecture has been evaluated by simulations performed on a nonlinear continuously stirred tank reactor system, and the obtained results indicate that the SMC based on SVR provides robust and stable closed-loop performance.},
  archive      = {J_SOCO},
  author       = {Uçak, Kemal and Öke Günel, Gülay},
  doi          = {10.1007/s00500-019-04223-9},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4623-4643},
  shortjournal = {Soft Comput.},
  title        = {An adaptive sliding mode controller based on online support vector regression for nonlinear systems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel spherical fuzzy analytic hierarchy process and its
renewable energy application. <em>SOCO</em>, <em>24</em>(6), 4607–4621.
(<a href="https://doi.org/10.1007/s00500-019-04222-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The extensions of ordinary fuzzy sets such as intuitionistic fuzzy sets, Pythagorean fuzzy sets, and neutrosophic sets, whose membership functions are based on three dimensions, aim at collecting experts’ judgments more informatively and explicitly. In the literature, generalized three-dimensional spherical fuzzy sets have been introduced by Kutlu Gündoğdu and Kahraman (J Intell Fuzzy Syst 36(1):337–352, 2019a), including their arithmetic operations, aggregation operators, and defuzzification operations. In this paper, our aim is to extend classical analytic hierarchy process (AHP) to spherical fuzzy AHP (SF-AHP) method and to show its applicability and validity through a renewable energy location selection example and a comparative analysis between neutrosophic AHP and SF-AHP.},
  archive      = {J_SOCO},
  author       = {Kutlu Gündoğdu, Fatma and Kahraman, Cengiz},
  doi          = {10.1007/s00500-019-04222-w},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4607-4621},
  shortjournal = {Soft Comput.},
  title        = {A novel spherical fuzzy analytic hierarchy process and its renewable energy application},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Adaptively secure efficient broadcast encryption with
constant-size secret key and ciphertext. <em>SOCO</em>, <em>24</em>(6),
4589–4606. (<a
href="https://doi.org/10.1007/s00500-019-04219-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In those broadcast application scenarios with a great quantity of receivers, e.g., the data access control system in cloud storage service, the single sender is apt to become the efficiency bottleneck of the system, because the computation and storage overhead of the sender will grow rapidly with the amount of qualified receivers. In order to overcome this problem, we first introduce the novel conception of complete binary identity tree which is adopted to manage the qualified receivers. Then we design the prune-merge algorithm to further optimize the structure of the tree and cut down the amount of receivers. The algorithm effectively reduces the computation and storage cost of the trusted authority in the system. Subsequently, in virtue of composite-order bilinear groups, we bring forward an efficient public key broadcast encryption scheme combined its application to the system of data access control in cloud storage service. Compared with the existing schemes, the lengths of system public parameters, secret key and ciphertext in our scheme are all constant. In addition, the number of secret keys in our scheme increases logarithmically with the maximum amount of receivers, while the numbers of secret keys in the existing schemes increase linearly with the maximum amount of receivers. Furthermore, the proposed scheme is proved to guarantee adaptive security under general subgroup decision assumption in the standard model. The performance analysis manifests that our scheme is feasible for those broadcast applications with fixed senders.},
  archive      = {J_SOCO},
  author       = {Chen, Liqing and Li, Jiguo and Zhang, Yichen},
  doi          = {10.1007/s00500-019-04219-5},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4589-4606},
  shortjournal = {Soft Comput.},
  title        = {Adaptively secure efficient broadcast encryption with constant-size secret key and ciphertext},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient feature selection using one-pass generalized
classifier neural network and binary bat algorithm with a novel fitness
function. <em>SOCO</em>, <em>24</em>(6), 4575–4587. (<a
href="https://doi.org/10.1007/s00500-019-04218-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In high-dimensional data, many of the features are either irrelevant to the machine learning task or are redundant. These situations lead to two problems, firstly overfitting and secondly high computational overhead. The paper proposes a feature selection method to identify the relevant subset of features for the machine-learning task using wrapper approach. The wrapper approach uses the Binary Bat algorithm to select the set of features and One-pass Generalized Classifier Neural Network (OGCNN) to evaluate the selected set of features using a novel fitness function. The proposed fitness function accounts for the entropy of sensitivity and specificity along with accuracy of classifier and fraction of selected features. The fitness function is compared using four classifiers (Radial Basis Function Neural Network, Probabilistic Neural Network, Extreme Learning Machine and OGCNN) on six publicly available datasets. One-pass classifiers are chosen as these are computationally faster. The results suggest that OGCNN along with the novel fitness function performs well in the majority of cases.},
  archive      = {J_SOCO},
  author       = {Naik, Akshata K. and Kuppili, Venkatanareshbabu and Edla, Damodar Reddy},
  doi          = {10.1007/s00500-019-04218-6},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4575-4587},
  shortjournal = {Soft Comput.},
  title        = {Efficient feature selection using one-pass generalized classifier neural network and binary bat algorithm with a novel fitness function},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Color quantization with particle swarm optimization and
artificial ants. <em>SOCO</em>, <em>24</em>(6), 4545–4573. (<a
href="https://doi.org/10.1007/s00500-019-04216-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article describes a color quantization algorithm that combines two swarm-based methods: Particle swarm optimization and artificial ants. The proposed method is based on a previous method that solves the quantization problem by combining the Particle swarm optimization algorithm with the K-means algorithm. K-means is a popular clustering method that has been applied to solve a variety of problems, including the color quantization problem. Nevertheless, it is a time-consuming method, which makes combining the Particle swarm optimization algorithm and K-means less suitable than other color quantization techniques. The proposed method, however, discards the K-means algorithm and applies the Ant-tree for color quantization algorithm in order to reduce execution time. This article shows that the new method outperforms the original one, since it requires less time to obtain higher quality images. In addition, the images produced are also of better quality than those produced by other well-known color quantization methods, such as Neuquant, Octree, Median-cut, Variance-based, Binary splitting and Wu’s methods.},
  archive      = {J_SOCO},
  author       = {Pérez-Delgado, María-Luisa},
  doi          = {10.1007/s00500-019-04216-8},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4545-4573},
  shortjournal = {Soft Comput.},
  title        = {Color quantization with particle swarm optimization and artificial ants},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). The <span class="math display"><em>λ</em></span>-additive
measure in a new light: The <span
class="math display"><em>Q</em><sub><em>ν</em></sub></span> measure and
its connections with belief, probability, plausibility, rough sets,
multi-attribute utility functions and fuzzy operators. <em>SOCO</em>,
<em>24</em>(6), 4523–4543. (<a
href="https://doi.org/10.1007/s00500-019-04212-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this paper is twofold. On the one hand, the $$\lambda $$-additive measure (Sugeno $$\lambda $$-measure) is revisited, and a state-of-the-art summary of its most important properties is provided. On the other hand, the so-called $$\nu $$-additive measure as an alternatively parameterized $$\lambda $$-additive measure is introduced. Here, the advantages of the $$\nu $$-additive measure are discussed, and it is demonstrated that these two measures are closely related to various areas of science. The motivation for introducing the $$\nu $$-additive measure lies in the fact that its parameter $$\nu \in (0,1)$$ has an important semantic meaning as it is the fix point of the complement operation. Here, by utilizing the $$\nu $$-additive measure, some well-known results concerning the $$\lambda $$-additive measure are put into a new light and rephrased in more advantageous forms. It is discussed here how the $$\nu $$-additive measure is connected with the belief-, probability- and plausibility measures. Next, it is also shown that two $$\nu $$-additive measures, with the parameters $$\nu _1$$ and $$\nu _2$$, are a dual pair of belief- and plausibility measures if and only if $$\nu _1+\nu _2 = 1$$. Furthermore, it is demonstrated how a $$\nu $$-additive measure (or a $$\lambda $$-additive measure) can be transformed to a probability measure and vice versa. Lastly, it is discussed here how the $$\nu $$-additive measures are connected with rough sets, multi-attribute utility functions and certain operators of fuzzy logic.},
  archive      = {J_SOCO},
  author       = {Dombi, József and Jónás, Tamás},
  doi          = {10.1007/s00500-019-04212-y},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4523-4543},
  shortjournal = {Soft Comput.},
  title        = {The $$\lambda $$-additive measure in a new light: The $$Q_{\nu }$$ measure and its connections with belief, probability, plausibility, rough sets, multi-attribute utility functions and fuzzy operators},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Inverse analysis and multi-objective optimization of
single-point incremental forming of AA5083 aluminum alloy sheet.
<em>SOCO</em>, <em>24</em>(6), 4505–4521. (<a
href="https://doi.org/10.1007/s00500-019-04211-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents soft computing-based modeling and multi-objective optimization of process parameters in single-point incremental forming (SPIF) of aluminum alloy sheet in order to obtain desired deformed shape with optimal formability satisfying multiple objectives. Response surface methodology and adaptive neuro-fuzzy inference system (ANFIS)-based models were developed to predict the responses based on the experimental data collected according to central composite design of experiments considering tool diameter, feed rate and step height as inputs, and outputs, namely forming wall angle, deformed sheet thickness and surface roughness. Inverse analyses were also performed to determine the set of input parameters to achieve desired outputs. Two different algorithms, namely back-propagation and hybrid, were employed to train the ANFIS in batch mode with the help of experimental data. The performances of the developed models were tested through real experimental data and also cross-validation methods. ANFIS trained by hybrid algorithm was found to be slightly better than that trained by the back-propagation algorithm in terms of prediction accuracy. Desirability function and a non-dominated sorting genetic algorithm were utilized for performing multi-objective optimization in SPIF, and the obtained optimal results were found satisfactory compared to the experimental data. The proposed approach could provide a reliable guidance for selection of suitable parameters in SPIF to achieve desired formed parts.},
  archive      = {J_SOCO},
  author       = {Maji, Kuntal and Kumar, Gautam},
  doi          = {10.1007/s00500-019-04211-z},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4505-4521},
  shortjournal = {Soft Comput.},
  title        = {Inverse analysis and multi-objective optimization of single-point incremental forming of AA5083 aluminum alloy sheet},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new preference disaggregation method for clustering
problem: DISclustering. <em>SOCO</em>, <em>24</em>(6), 4483–4503. (<a
href="https://doi.org/10.1007/s00500-019-04210-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering, a famous technique in data analysis and data mining, attempts to find valuable patterns in datasets. In this technique, a set of alternatives is partitioned into logical groups which are called clusters. The partitioning is based on some predefined attributes to find clusters in which their alternatives are similar to each other comparing to other clusters. In conventional methods, the similarity is usually defined by a distance-based measurement, whereas in this study, we have proposed a new multi-attribute preference disaggregation method called DISclustering in which a new measurement named global utility is introduced for cluster similarity. In DISclustering, the global utility of each alternative is calculated through a feed-forward neural network in which its parameters are determined using SA algorithm. Each alternative is assigned to a cluster based on comparing the obtained global utility with cluster boundaries, called utility thresholds; aim to minimize the intra-cluster distances (ICD). For this purpose, all utility thresholds are estimated using PSO algorithm. The performance of the proposed method is compared with 18 clustering algorithms on 14 real datasets based on F-measure and object function values (ICD values using intra-cluster or Gower distances). The experimental results and hypothesis statistical test indicate that DISclustering algorithm significantly improved clustering results on F-measure criteria in which outperforms in almost 13 compared algorithms out of 18. Note that, DISclustering calculates cluster centroid in a different way comparing to other algorithms. Hence, its ICD values are less eligible to perform a fair comparison.},
  archive      = {J_SOCO},
  author       = {Esmaelian, Majid and Shahmoradi, Hadi and Nemati, Fateme},
  doi          = {10.1007/s00500-019-04210-0},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4483-4503},
  shortjournal = {Soft Comput.},
  title        = {A new preference disaggregation method for clustering problem: DISclustering},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A locally based feature descriptor for abnormalities
detection. <em>SOCO</em>, <em>24</em>(6), 4469–4481. (<a
href="https://doi.org/10.1007/s00500-019-04208-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless capsule endoscopy (WCE) is a novel imaging technique that can view the entire small bowel in human body. Therefore, it has been gradually adopted compared with traditional endoscopies for gastrointestinal diseases. However, the task of reviewing the vast amount of images produced by a WCE test is exhaustive for the physicians. This paper presents a new feature extraction scheme for pathological inflammation and ulcer regions discrimination in WCE images. In addition, the novel approach is adopted for polyp recognition in colonoscopy videos. A novel idea based on extracting certain local features from the image is proposed. Then, the occurrence histogram of these features is used as descriptor of the image. The new feature descriptor scheme is grayscale rotation invariant and computationally simple as the operator can be realized with a few operations in a small neighborhood. The proposed operator does not discard the contrast information. Besides, we propose to test the quality of the model using logarithmic loss metric and show how calibration can be useful in reducing the aforementioned measure. Extensive classification experiments have been applied on different datasets, which prove that the occurrence histogram of the extracted features is powerful. The proposed method achieved 99.1\%, 99.7\% and 99.2\% in terms of the precision in the first, second and third datasets, respectively, and surpassed some known local descriptors on a texture dataset.},
  archive      = {J_SOCO},
  author       = {Charfi, Said and El Ansari, Mohamed},
  doi          = {10.1007/s00500-019-04208-8},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4469-4481},
  shortjournal = {Soft Comput.},
  title        = {A locally based feature descriptor for abnormalities detection},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Design of fuzzy logic system framework using evolutionary
techniques. <em>SOCO</em>, <em>24</em>(6), 4455–4468. (<a
href="https://doi.org/10.1007/s00500-019-04207-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing fuzzy logic system is one of the most popular and research-demanding NP-hard problems. It involves numerous parameters like shape and location of fuzzy sets, antecedents and consequents of fuzzy rule base and other strategic parameters like aggregation, implication and defuzzification methods. Time series forecasting has also become increasingly popular for the applications like share market prediction, weather forecasting. Many researchers have investigated the use of fuzzy logic system for forecasting of time series. In this paper, the authors have investigated the design framework of fuzzy logic systems for forecasting benchmark Mackey–Glass time series. Designing fuzzy logic systems is a class of NP-hard problems which is evolved using most popular and recent evolutionary algorithms. Authors have evolved fuzzy logic system using genetic algorithm, particle swarm optimization, artificial bee colony optimization, firefly algorithm and whale optimization algorithm. Finally, from simulations, it is found that whale optimization algorithm requires less time and shows fuzzy system predictions are more precise than others.},
  archive      = {J_SOCO},
  author       = {Singh, Sarabjeet and Singh, Satvir and Banga, Vijay Kumar},
  doi          = {10.1007/s00500-019-04207-9},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4455-4468},
  shortjournal = {Soft Comput.},
  title        = {Design of fuzzy logic system framework using evolutionary techniques},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Tuning of reinforcement learning parameters applied to SOP
using the scott–knott method. <em>SOCO</em>, <em>24</em>(6), 4441–4453.
(<a href="https://doi.org/10.1007/s00500-019-04206-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a technique to tune the reinforcement learning (RL) parameters applied to the sequential ordering problem (SOP) using the Scott–Knott method. The RL has been widely recognized as a powerful tool for combinatorial optimization problems, such as travelling salesman and multidimensional knapsack problems. It seems, however, that less attention has been paid to solve the SOP. Here, we have developed a RL structure to solve the SOP that can partially fill that gap. Two traditional RL algorithms, Q-learning and SARSA, have been employed. Three learning specifications have been adopted to analyze the performance of the RL: algorithm type, reinforcement learning function, and $$\epsilon $$ parameter. A complete factorial experiment and the Scott–Knott method are used to find the best combination of factor levels, when the source of variation is statistically different in analysis of variance. The performance of the proposed RL has been tested using benchmarks from the TSPLIB library. In general, the selected parameters indicate that SARSA overwhelms the performance of Q-learning.},
  archive      = {J_SOCO},
  author       = {Ottoni, André L. C. and Nepomuceno, Erivelton G. and de Oliveira, Marcos S. and de Oliveira, Daniela C. R.},
  doi          = {10.1007/s00500-019-04206-w},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4441-4453},
  shortjournal = {Soft Comput.},
  title        = {Tuning of reinforcement learning parameters applied to SOP using the Scott–Knott method},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Learning path combination recommendation based on the
learning networks. <em>SOCO</em>, <em>24</em>(6), 4427–4439. (<a
href="https://doi.org/10.1007/s00500-019-04205-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discovering useful hidden learning behavior pattern from learning data for online learning platform is valuable in education technology. Studies on learning path recommendation to recommend an appropriate resource for different users are particularly important for the development of advanced online education. However, it may suffer from low recommendation quality for beginners or learner with low participation. In order to improve the recommendation quality, a learning path combination recommendation method based on the learning network (LPCRLN) is proposed. In LPCRLN, it introduces complex network technology. Based on the characteristics of courses and learners, the course network and learner network, respectively, are constructed, and then learners are divided into three types. Finally, the recommendation is made in different scenarios according to the learner’s learning records. In this study, a series of experiments have been carried out. By comparisons, experimental results indicate that our proposed method is able to make sound recommendations on appropriate courses for different types of learners with significant improvement in terms of accuracy and efficiency.},
  archive      = {J_SOCO},
  author       = {Liu, Hong and Li, Xiaojun},
  doi          = {10.1007/s00500-019-04205-x},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4427-4439},
  shortjournal = {Soft Comput.},
  title        = {Learning path combination recommendation based on the learning networks},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Feature selection by recursive binary gravitational search
algorithm optimization for cancer classification. <em>SOCO</em>,
<em>24</em>(6), 4407–4425. (<a
href="https://doi.org/10.1007/s00500-019-04203-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {DNA microarray technology has become a prospective tool for cancer classification. However, DNA microarray datasets typically have very large number of genes (usually more than tens of thousands) and less number of samples (often less than one hundred). This raises the issue of getting the most relevant genes prior to cancer classification. In this paper, we have proposed a two-phase feature selection method for cancer classification. This method selects a low-dimensional set of genes to classify biological samples of binary and multi-class cancers by integrating ReliefF with recursive binary gravitational search algorithm (RBGSA). The proposed RBGSA refines the gene space from a very coarse level to a fine-grained one at each recursive step of the algorithm without degrading the accuracy. We evaluate our method by comparing it with state-of-the-art methods on 11 benchmark microarray datasets of different cancer types. Comparison results show that our method selects only a small number of genes while yielding substantial improvements in accuracy over other methods. In particular, it achieved up to 100\% classification accuracy for 7 out of 11 datasets with a very small size of gene subset (up to &lt; 1.5\%) for all 11 datasets.},
  archive      = {J_SOCO},
  author       = {Han, Xiaohong and Li, Dengao and Liu, Ping and Wang, Li},
  doi          = {10.1007/s00500-019-04203-z},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4407-4425},
  shortjournal = {Soft Comput.},
  title        = {Feature selection by recursive binary gravitational search algorithm optimization for cancer classification},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Supervised machine learning techniques and genetic
optimization for occupational diseases risk prediction. <em>SOCO</em>,
<em>24</em>(6), 4393–4406. (<a
href="https://doi.org/10.1007/s00500-019-04200-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Workers healthcare gained a lot of attention recently as many countries are increasingly concerning about welfare. This paper faces the problem of predicting occupational disease risks by means of computational intelligence and pattern recognition techniques. Specifically, three different machine learning approaches are compared: the first one is based on the k-means algorithm, in charge to determine a set of meaningful labelled clusters as the final model. The latter two are based on fully supervised techniques, namely Support Vector Machines and K-Nearest Neighbours. Real data regarding both the worker and the workplace by mixing numerical and categorical attributes have been used for testing. The three approaches are automatically tuned by means of genetic algorithms in order to simultaneously find the optimal hyperparameters for the classification systems and the optimal ad-hoc dissimilarity measure weights in order to maximize the classification performances. Computational results show that the three approaches are rather comparable in terms of performances, but a clustering-based approach allows a deeper knowledge discovery phase, helpful for further risk assessment and forecasting.},
  archive      = {J_SOCO},
  author       = {Di Noia, Antonio and Martino, Alessio and Montanari, Paolo and Rizzi, Antonello},
  doi          = {10.1007/s00500-019-04200-2},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4393-4406},
  shortjournal = {Soft Comput.},
  title        = {Supervised machine learning techniques and genetic optimization for occupational diseases risk prediction},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Missing value imputation using unsupervised machine learning
techniques. <em>SOCO</em>, <em>24</em>(6), 4361–4392. (<a
href="https://doi.org/10.1007/s00500-019-04199-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In data mining, preprocessing is one of the essential processes which involves data normalization, noise removal, handling missing values, etc. This paper focuses on handling missing values using unsupervised machine learning techniques. Soft computation approaches are combined with the clustering techniques to form a novel method to handle the missing values, which help us to overcome the problems of inconsistency. Rough K-means centroid-based imputation method is proposed and compared with K-means centroid-based imputation method, fuzzy C-means centroid-based imputation method, K-means parameter-based imputation method, fuzzy C-means parameter-based imputation method, and rough K-means parameter-based imputation methods. The experimental analysis is carried out on four benchmark datasets, viz. Dermatology, Pima, Wisconsin, and Yeast datasets, which have taken from UCI data repository. The proposed method proves the efficacy of different datasets, and the results are also promising one.},
  archive      = {J_SOCO},
  author       = {Raja, P. S. and Thangavel, K.},
  doi          = {10.1007/s00500-019-04199-6},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4361-4392},
  shortjournal = {Soft Comput.},
  title        = {Missing value imputation using unsupervised machine learning techniques},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A holistic optimization approach for inverted cart-pendulum
control tuning. <em>SOCO</em>, <em>24</em>(6), 4343–4359. (<a
href="https://doi.org/10.1007/s00500-019-04198-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The inverted cart-pendulum (ICP) is a nonlinear underactuated system, which dynamics are representative of many applications. Therefore, the development of ICP control laws is important since these laws are suitable to other systems. Indeed, many nonlinear control strategies have emerged from the control of the ICP. For these reasons, the ICP remains a canonical and fundamental benchmark problem in control theory and robotics that is of interest to the scientific community. Till now, the trial-and-error method is still widely applied for ICP controller tuning as well as the sequential tuning referring to tune the swing-up controller and thereafter, the stabilization controller. Therefore, the aim of this paper is to automate and facilitate the ICP control in one step. Thus, this paper proposes to holistically optimize ICP controllers. The holistic optimization is performed by a simplified Ant Colony Optimization method with a constrained Nelder–Mead algorithm (ACO-NM). Holistic optimization refers to a simultaneous tuning of the swing-up, stabilization and switching mode parameters. A new cost function is designed to minimize swing-up time, achieve high stabilization performance and consider system constraints. The holistic approach optimizes four controller structures, which include controllers that have never been tuned by a specific method besides by the trial-and-error method. Simulation results on a ICP nonlinear model show that ACO-NM in the holistic approach is effective compared to other algorithms. In addition, contrary to the majority of work on the subject, all the optimized controllers are validated experimentally. The simulation and experimental results obtained confirm that the holistic approach is an efficient optimization tool and specifically responds to the need of optimization technique for the potential-well controller structure and for the Q [diagonal of the matrix and the full matrix] in the linear–quadratic regulator (LQR) technique. Moreover, ICP experimental response analysis demonstrates that using the full Q provides greater experimental stabilization performance than using its diagonal terms in the LQR technique.},
  archive      = {J_SOCO},
  author       = {Blondin, Maude J. and Pardalos, Panos M.},
  doi          = {10.1007/s00500-019-04198-7},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4343-4359},
  shortjournal = {Soft Comput.},
  title        = {A holistic optimization approach for inverted cart-pendulum control tuning},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hopf bifurcation of forced chen system and its stability via
adaptive control with arbitrary parameters. <em>SOCO</em>,
<em>24</em>(6), 4333–4341. (<a
href="https://doi.org/10.1007/s00500-019-04197-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, forced Chen system is analyzed for nonlinear dynamical behavior. The chaotic behavior of forced Chen system is verified by phase portraits and sensitivity dependence of system upon initial condition. Hopf bifurcation for the complex system is derived and theorem of first Lyapunov coefficient is used to investigate the type of Hopf bifurcation. It is further shown that Hopf bifurcation exists only on two equilibrium points for the proposed chaotic model. In addition, an adaptive control technique is used to control unpredictable behavior for the forced Chen system. Global stability is achieved by constructing an energy type function through Lyapunov theory, whereas its error dynamics is used to synchronize two identical forced Chen systems. Numerical simulation results are used to validate analytical results given in this article and also to demonstrate effectiveness of the considered chaotic system.},
  archive      = {J_SOCO},
  author       = {Marwan, Muhammad and Mehboob, Memoona and Ahmad, Salman and Aqeel, Muhammad},
  doi          = {10.1007/s00500-019-04197-8},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4333-4341},
  shortjournal = {Soft Comput.},
  title        = {Hopf bifurcation of forced chen system and its stability via adaptive control with arbitrary parameters},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cloud service selection based on QoS-aware logistics.
<em>SOCO</em>, <em>24</em>(6), 4323–4332. (<a
href="https://doi.org/10.1007/s00500-019-04196-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of technologies such as cloud computing, Big Data, the Internet of Things, etc., Internet + logistics models are being sought by all parties, leading to the current rise of cloud service platforms for logistics. As such platforms combine many logistics services with similar functions, identification of methods to choose from among a large number of similar services to meet the personalized needs of customers has become especially important. In the work presented herein, QoS data are quantified and filtered through the establishment of quality of service (QoS) decision information systems. Meanwhile, using the variable precision rough set method, the weight of each QoS attribute index is calculated, then the similarity of services, to obtain a comprehensive sequence in terms of service quality that provides a basis for selection of the optimal service. The calculation and analysis results show that this method can effectively choose the best logistics service according to specific business needs.},
  archive      = {J_SOCO},
  author       = {Ran, Wenxue and Liu, Huijuan},
  doi          = {10.1007/s00500-019-04196-9},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4323-4332},
  shortjournal = {Soft Comput.},
  title        = {Cloud service selection based on QoS-aware logistics},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improving predictive uncertainty estimation using
dropout–hamiltonian monte carlo. <em>SOCO</em>, <em>24</em>(6),
4307–4322. (<a
href="https://doi.org/10.1007/s00500-019-04195-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating predictive uncertainty is crucial for many computer vision tasks, from image classification to autonomous driving systems. Hamiltonian Monte Carlo (HMC) is an sampling method for performing Bayesian inference. On the other hand, Dropout regularization has been proposed as an approximate model averaging technique that tends to improve generalization in large-scale models such as deep neural networks. Although HMC provides convergence guarantees for most standard Bayesian models, it do not handle discrete parameters arising from Dropout regularization. In this paper, we present a robust methodology for improving predictive uncertainty in classification problems, based on Dropout and HMC. Even though Dropout induces a non-smooth energy function with no such convergence guarantees, the resulting discretization of the Hamiltonian proves empirical success. The proposed method allows to effectively estimate the predictive accuracy and to provide better generalization for difficult test examples.},
  archive      = {J_SOCO},
  author       = {Hernández, Sergio and Vergara, Diego and Valdenegro-Toro, Matías and Jorquera, Felipe},
  doi          = {10.1007/s00500-019-04195-w},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4307-4322},
  shortjournal = {Soft Comput.},
  title        = {Improving predictive uncertainty estimation using Dropout–Hamiltonian monte carlo},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A hybrid method for evaluating the effectiveness of giant
systems with indicator correlations: An application for naval formation
decision making in multiple scenarios. <em>SOCO</em>, <em>24</em>(6),
4295–4306. (<a
href="https://doi.org/10.1007/s00500-019-04194-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article discusses the giant system effectiveness evaluation (GSEE) problem with inevitable correlation in indicator systems due to their high specificity and complexity and proposes a hybrid method that is then applied to the naval formation decision-making process in multiple scenarios. The indicator correlation in a large-scale system will generate bias in its evaluation of effectiveness; the proposal that the lower the correlation is, the better the performance of the evidential reasoning approach (ERA) has been proven mathematically. In light of this proposition, a corollary was put forward: Fewer indicators would improve the precision of the result of the ERA application when considering the correlation. Considering that the giant system can be split into respective subsystems, which can then be analyzed by experts in their own fields, a hybrid method was developed for the GSEE problem based on the ERA and prospect theory. The core of the method is the construction of a nonlinear optimization model (NOM) aimed at minimizing the correlation and maximizing the evaluation ability of the prospect value of the indicator system. By constraint, the NOM also includes the optimized weight value of each indicator. For demonstration purposes, a naval formation operation effectiveness evaluation (NFOEE) was performed to assess the feasibility of the proposed method and the NOM. The results show that the proposed method can solve the NFOEE effectively and allow the decision maker to obtain useful information for naval formation-type decisions in multiple scenarios. Furthermore, the evaluation method is a general tool that can be applied to other GSEE problems.},
  archive      = {J_SOCO},
  author       = {Xu, Xiaowei and Xie, Xinlian and Zhang, Bofei and Pan, Wei},
  doi          = {10.1007/s00500-019-04194-x},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4295-4306},
  shortjournal = {Soft Comput.},
  title        = {A hybrid method for evaluating the effectiveness of giant systems with indicator correlations: An application for naval formation decision making in multiple scenarios},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). MCDM based on new membership and non-membership accuracy
functions on trapezoidal-valued intuitionistic fuzzy numbers.
<em>SOCO</em>, <em>24</em>(6), 4283–4293. (<a
href="https://doi.org/10.1007/s00500-019-04193-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ranking of trapezoidal-valued intuitionistic fuzzy numbers (TVIFNs) plays an important role in multi-criteria decision making (MCDM) based on the TVIFNs. The main objective of this paper is to introduce new membership and non-membership accuracy functions on the classes of interval-valued intuitionistic fuzzy numbers (IVIFNs) and TVIFNs by which the orderings on IVIFNs and TVIFNs are done. This paper reveals the better part of the proposed accuracy functions than the existing or previous functions. Further, some operations on IVIFNs and TVIFNs are defined. Finally, a new method is proposed to solve the MCDM problem based on the multi-criteria trapezoidal-valued intuitionistic fuzzy index matrix and illustrated through numerical examples.},
  archive      = {J_SOCO},
  author       = {Sivaraman, Geetha and Vishnukumar, P. and Raj, M. Edwin Antony},
  doi          = {10.1007/s00500-019-04193-y},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4283-4293},
  shortjournal = {Soft Comput.},
  title        = {MCDM based on new membership and non-membership accuracy functions on trapezoidal-valued intuitionistic fuzzy numbers},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The effects of consumer confusion on hotel brand loyalty: An
application of linguistic nonlinear regression model in the hospitality
sector. <em>SOCO</em>, <em>24</em>(6), 4269–4281. (<a
href="https://doi.org/10.1007/s00500-019-04192-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of the study is to estimate the interaction and quadratic relationships between dimensions by estimating a model for the confusion dimensions that affect hotel brand loyalty, thus providing the interested parties with a perspective and direction regarding consumer confusion. This study also aimed to strengthen the use of FLS in the field of social sciences and will use this method to transform the discrete ordinal variable into a continuous variable while preserving the semantic meaning. Four hundred and six individuals participated in the study. Hypotheses demonstrating the interaction and quadratic effects between the continuous variables have been analysed using nonlinear multiple regression analysis. This study proposes a survey-based method to estimate a model for the confusion dimensions that affect hotel brand loyalty. The results demonstrated that ambiguity confusion, overload confusion, similarity confusion, quadratic effect of similarity confusion and interaction of ambiguity, overload and similarity confusion decrease the hotel brand loyalty. Also, quadratic effect of ambiguity confusion, interaction of ambiguity and overload confusion, interaction of overload and similarity confusion, interaction of ambiguity and similarity confusion increase the hotel brand loyalty. Despite its importance for marketing and consumer behaviour, the definition, measurement, dimensions and existing results of consumer confusion have begun to be discussed and examined recently in a limited scope. Studies have demonstrated that consumer confusion about tourism products is a non-functional and under-evaluated area but also is utmost prominent for tourism product. This study aimed to obtain a stronger model in which all the interactions between variables and their (quadratic) increasing effects are considered using a nonlinear regression model.},
  archive      = {J_SOCO},
  author       = {Kurtulmuşoğlu, Feride Bahar and Atalay, Kumru Didem},
  doi          = {10.1007/s00500-019-04192-z},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4269-4281},
  shortjournal = {Soft Comput.},
  title        = {The effects of consumer confusion on hotel brand loyalty: An application of linguistic nonlinear regression model in the hospitality sector},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). A multivariate grey prediction model with grey relational
analysis for bankruptcy prediction problems. <em>SOCO</em>,
<em>24</em>(6), 4259–4268. (<a
href="https://doi.org/10.1007/s00500-019-04191-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regarding bankruptcy prediction as a kind of grey system problem, this study aims to develop multivariate grey prediction models based on the most representative GM(1, N) for bankruptcy prediction. There are several distinctive features of the proposed grey prediction model. First, to improve the prediction performance of the GM(1, N), grey relational analysis is used to sift relevant features that have the strongest relationship with the class feature. Next, the proposed model effectively extends the multivariate grey prediction model for time series to bankruptcy prediction irrespective of time series. It turns out that the proposed model uses the genetic algorithms to avoid indexing by time and using the ordinary least squares with statistical assumptions for the traditional GM(1, N). The empirical results obtained from the financial data of Taiwanese firms in the information and technology industry demonstrated that the proposed prediction model performs well compared with other GM(1, N) variants considered.},
  archive      = {J_SOCO},
  author       = {Hu, Yi-Chung},
  doi          = {10.1007/s00500-019-04191-0},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4259-4268},
  shortjournal = {Soft Comput.},
  title        = {A multivariate grey prediction model with grey relational analysis for bankruptcy prediction problems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An integrated decision making model for supplier and carrier
selection with emphasis on the environmental factors. <em>SOCO</em>,
<em>24</em>(6), 4243–4258. (<a
href="https://doi.org/10.1007/s00500-019-04190-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A suitable green supply chain network can significantly affect both the supply chain and the environment. Such network should guide the supply chain toward an efficient and effective management to increase the profit, desirable impacts on the environments and responsiveness to the customers’ requests. In this research, a green supply chain with limited greenhouse gas emission was designed which could reduce the chain costs by simultaneous selection of the supplier and carriers with various capacities. Thus, in this research a bi-objective nonlinear programming model was proposed which is aimed to select the carriers between the chain levels and select the supplier based on the quality of the consumed material. Moreover, the delivery time to customers and emission from transportation and production were the other constraints of the problem. The first goal was to minimize the total chain costs while reduction in the rejection of the consumed material was in the second rank. In order to validate the proposed model, several numerical problems were randomly generated and solved using GAMS optimization software. Since the problem is NP-hard and its solution time increased exponentially by increase in the problem dimension, a multi-objective meta-heuristic imperialist competitive algorithm was proposed to solve the problem in large scales. Crowding distance was also used to rank the solutions of one front. The computational results and comparisons by indices like mean distance from the ideal were employed to describe the algorithm efficiency. The results showed that features such as carrier selection and environmental factors can enable the decision process of supplier selection to be well approximated with the real-world situation, showing the potential usefulness of these concepts.},
  archive      = {J_SOCO},
  author       = {Eydi, Alireza and Fathi, Arezoo},
  doi          = {10.1007/s00500-019-04190-1},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4243-4258},
  shortjournal = {Soft Comput.},
  title        = {An integrated decision making model for supplier and carrier selection with emphasis on the environmental factors},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An efficient neural network for solving convex optimization
problems with a nonlinear complementarity problem function.
<em>SOCO</em>, <em>24</em>(6), 4233–4242. (<a
href="https://doi.org/10.1007/s00500-019-04189-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a one-layer recurrent neural network (NN) for solving convex optimization problems by using the Mangasarian and Solodov (MS) implicit Lagrangian function. In this paper by using Krush–Kuhn–Tucker conditions and MS function the NN model was derived from an unconstrained minimization problem. The proposed NN model is one layer and compared to the available NNs for solving convex optimization problems, which has a better performance in convergence time. The proposed NN model is stable in the sense of Lyapunov and globally convergent to optimal solution of the original problem. Finally, simulation results on several numerical examples are presented and the validity of the proposed NN model is demonstrated.},
  archive      = {J_SOCO},
  author       = {Ranjbar, M. and Effati, S. and Miri, S. M.},
  doi          = {10.1007/s00500-019-04189-8},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4233-4242},
  shortjournal = {Soft Comput.},
  title        = {An efficient neural network for solving convex optimization problems with a nonlinear complementarity problem function},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Hesitant fuzzy soft multisets and their applications in
decision-making problems. <em>SOCO</em>, <em>24</em>(6), 4223–4232. (<a
href="https://doi.org/10.1007/s00500-019-04187-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce some important and basic issues of hesitant fuzzy soft multisets and present some results for hesitant fuzzy sets. The main results of the current branch are studied, and some of its structural properties are established such as the neighborhood hesitant fuzzy soft multisets, interior hesitant fuzzy soft multisets, hesitant fuzzy soft multi-topological spaces and hesitant fuzzy soft multi-basis. Therefore, we show that how to apply the concept of hesitant fuzzy soft multisets in decision-making problems.},
  archive      = {J_SOCO},
  author       = {Kandil, A. and El-Sheikh, S. A. and Hosny, M. and Raafat, M.},
  doi          = {10.1007/s00500-019-04187-w},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4223-4232},
  shortjournal = {Soft Comput.},
  title        = {Hesitant fuzzy soft multisets and their applications in decision-making problems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Reconstructing gene regulatory networks via memetic
algorithm and LASSO based on recurrent neural networks. <em>SOCO</em>,
<em>24</em>(6), 4205–4221. (<a
href="https://doi.org/10.1007/s00500-019-04185-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reconstructing gene regulatory networks (GRNs) from gene expression data is an important and challenging problem in system biology. In general, the problem of reconstructing GRNs can be modeled as an optimization problem. Recurrent neural network (RNN) has been widely used for GRNs. However, in a real GRN, the number of genes is very large and the relationships between genes are usually very sparse. In this paper, we design a memetic algorithm to learn partial parameters of RNN, and develop a framework based on the least absolute shrinkage and selection operator (LASSO) to reconstruct GRNs based on RNN, which is termed as MALASSORNN-GRN. In the LASSO, the task of reconstructing GRNs is decomposed into a sparse signal reconstructing problem. In the experiments, MALASSORNN-GRN is applied on synthetic data and well-known benchmark datasets DREAM3 and DREAM4. The effect of parameters on MALASSORNN-GRN is discussed, and MALASSORNN-GRN is compared with three other algorithms which are all state-of-the-art RNN learning algorithms. The results show that MALASSORNN-GRN performs best and is capable of reconstructing large-scale GRNs.},
  archive      = {J_SOCO},
  author       = {Liu, Luowen and Liu, Jing},
  doi          = {10.1007/s00500-019-04185-y},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4205-4221},
  shortjournal = {Soft Comput.},
  title        = {Reconstructing gene regulatory networks via memetic algorithm and LASSO based on recurrent neural networks},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A game-based resource pricing and allocation mechanism for
profit maximization in cloud computing. <em>SOCO</em>, <em>24</em>(6),
4191–4203. (<a
href="https://doi.org/10.1007/s00500-019-04183-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In cloud computing environment, Software as a Service (SaaS) providers offer diverse software services to customers and commonly host their applications and data on the infrastructures supplied by Infrastructure as a Service (IaaS) providers. From the perspective of economics, the basic challenges for both SaaS and IaaS providers are to design resource pricing and allocation policies to maximize their own final revenue. However, IaaS providers seek an optimal price policy of virtual machines to generate more revenue, while SaaS providers want to minimize the cost of using infrastructure resources, and comply with service-level agreement contracts with users at the same time. In this situation, there exists conflict in maximizing revenue of both IaaS and SaaS providers simultaneously. In this paper, we model this revenue maximization problem as the Stackelberg game and analyze the existence and uniqueness of the game equilibrium. Moreover, considering the impact of resource price on users’ willing to access service, we propose a dynamic pricing mechanism to maximize the revenue of both SaaS and IaaS providers. The simulation results demonstrate that, compared to fixed pricing and auction-based pricing mechanisms, the proposed mechanism is superior in the revenue maximization and resource utilization.},
  archive      = {J_SOCO},
  author       = {Zhu, Zhengfa and Peng, Jun and Liu, Kaiyang and Zhang, Xiaoyong},
  doi          = {10.1007/s00500-019-04183-0},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4191-4203},
  shortjournal = {Soft Comput.},
  title        = {A game-based resource pricing and allocation mechanism for profit maximization in cloud computing},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dynamic urban land-use change management using
multi-objective evolutionary algorithms. <em>SOCO</em>, <em>24</em>(6),
4165–4190. (<a
href="https://doi.org/10.1007/s00500-019-04182-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Frequent land-use changes in urban areas require an efficient and dynamic approach to reform and update detailed plans by re-arrangement of surrounding land-uses in case of change in one or several urban land-uses. However, re-arrangement of land-uses is problematic, since a variety of conflicting criteria must be considered and satisfied. This paper proposes and examines a two-step approach to resolve the issue. The first step adopts a multi-objective optimization technique to obtain an optimal arrangement of surrounding land-uses in case of change in one or several urban land-uses, whereas the second step uses clustering analysis to produce appropriate solutions for decision makers from the outputs of the first step. To present and assess the approach, a case study was conducted in Tehran, the capital of Iran. To satisfy the first step, four conflicting objective functions including maximization of consistency, maximization of dependency, maximization of suitability and maximization of compactness were defined and optimized using non-dominated sorting genetic algorithm. Per-capita demand was also employed as a constraint in the optimization process. Clustering analysis based on ant colony optimization was used to satisfy the second step. The results of the optimization were satisfactory both from a convergence and from a repeatability point of view. Furthermore, the objective functions of optimized arrangements were better than existing land-use arrangement in the area, with the per-capita demand deficiency significantly compensated. The approach was also communicated to urban planners in order to assess its usefulness. In conclusion, the proposed approach can extensively support and facilitate decision making of urban planners and policy makers in reforming and updating existing detailed plans after land-use changes.},
  archive      = {J_SOCO},
  author       = {Masoumi, Zohreh and Coello Coello, Carlos A. and Mansourian, Ali},
  doi          = {10.1007/s00500-019-04182-1},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4165-4190},
  shortjournal = {Soft Comput.},
  title        = {Dynamic urban land-use change management using multi-objective evolutionary algorithms},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Formalizing UML/OCL structural features with FoCaLiZe.
<em>SOCO</em>, <em>24</em>(6), 4149–4164. (<a
href="https://doi.org/10.1007/s00500-019-04181-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unified Modeling Language (UML) is the de facto standard for the development of software models, and Object Constraint Language (OCL) is used within UML models to specify model constraints. Several UML/OCL tools provide Model-Driven Engineering transformation into general object-oriented programming languages such as Java and C++. But the latter did not provide mechanisms for the specification and the verification of OCL constraints. In this context, formal methods are largely used for the specification of UML/OCL models and the verification of their OCL constraints. However, the divergence between UML (object-oriented modeling) and formal methods (mathematical- and logical-based tools) leads in general to ignore most UML/OCL architectural and conceptual features such as OCL constraints simple and multiple inheritance, late binding, template binding and dependencies. To address the formalization of these features, we have used FoCaLiZe, an object-oriented development environment using a proof-based formal approach. More precisely, we propose a formal transformation of the essential UML/OCL features into FoCaLiZe specifications. The derived formal model reflects perfectly the structural features of the original UML/OCL model. In addition, it is possible to check and prove model properties using Zenon, the automatic theorem prover of FoCaLiZe.},
  archive      = {J_SOCO},
  author       = {Abbas, Messaoud and Ben-Yelles, Choukri-Bey and Rioboo, Renaud},
  doi          = {10.1007/s00500-019-04181-2},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4149-4164},
  shortjournal = {Soft Comput.},
  title        = {Formalizing UML/OCL structural features with FoCaLiZe},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Minimizing the state of health degradation of li-ion
batteries onboard low earth orbit satellites. <em>SOCO</em>,
<em>24</em>(6), 4131–4147. (<a
href="https://doi.org/10.1007/s00500-019-04180-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Satellites have a tangible impact on our daily lives; they provide us with many services like communication, global positioning, etc. Satellite batteries are expected to deliver the power demand at any time during the period of an eclipse, or when the power received from the onboard solar panels is not sufficient. The focus of this research is to develop an energy management mathematical model that reduces the state of health degradation of a battery in a low earth orbit (LEO) satellite. This improves the battery lifetime; thus, increasing the length of time a LEO satellite can stay in service. The developed model for a LEO satellite is solved separately for meeting three different objectives. In addition to the model, a heuristic approach is developed, and the results are compared to those obtained from the above-mentioned model. In this endeavor, data are collected for an existing LEO satellite, Nayif-1, in order to analyze the current battery behavior in space and to compare it with the developed model and heuristics. Sensitivity analysis is conducted to observe the effects of altering different parameters of the model. The results presented in this research show that minimizing the sum of products of the battery state switches and the battery current yields the best results by enhancing the lifetime of the battery by 8 days and providing 122 more cycles than that observed in the data from Nayif-1, assuming that the DOD of the battery remains constant throughout all orbits.},
  archive      = {J_SOCO},
  author       = {Lami, Mahmoud and Shamayleh, Abdulrahim and Mukhopadhyay, Shayok},
  doi          = {10.1007/s00500-019-04180-3},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4131-4147},
  shortjournal = {Soft Comput.},
  title        = {Minimizing the state of health degradation of li-ion batteries onboard low earth orbit satellites},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Solution of a fuzzy global optimization problem by fixed
point methodology using a weak coupled contraction. <em>SOCO</em>,
<em>24</em>(6), 4121–4129. (<a
href="https://doi.org/10.1007/s00500-019-04179-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the present work, we consider the global optimization problem of obtaining distance between two subsets of a fuzzy metric space and solve it by fixed point methodology through the determination of two different pairs of points each of which determines the fuzzy distance. We use fuzzy weak coupled contractions for that purpose. The problem is well studied in metric spaces where it is known as a proximity point problem. We use geometric notions in fuzzy metric spaces. Our result is valid for arbitrary continuous t-norms associated with the fuzzy metric space. The problem is solved by reducing it to that of finding optimal approximate solution of a fuzzy coupled fixed point equation. We also obtain a coupled fixed point result as a consequence of our main theorem. The main result is illustrated with an example.},
  archive      = {J_SOCO},
  author       = {Saha, P. and Guria, S. and Choudhury, Binayak S. and Das, Pradyut},
  doi          = {10.1007/s00500-019-04179-w},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4121-4129},
  shortjournal = {Soft Comput.},
  title        = {Solution of a fuzzy global optimization problem by fixed point methodology using a weak coupled contraction},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Some new performance definitions of second-order fuzzy
systems. <em>SOCO</em>, <em>24</em>(6), 4109–4120. (<a
href="https://doi.org/10.1007/s00500-019-04177-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The mathematical models are usually considered for the assessment of a dynamical system performance. Using such models often is based on an assumption which takes all the system parameter values as crisp values into account. However, the parameter values may not be always determined exactly. Since fuzzy logic has been well known as an effective tool in modeling uncertainty, in this paper, fuzzy numbers are used in modeling of dynamical systems. In this paper, concentrate on second-order dynamical systems with fuzzy parameters as they play a major role in many aspects of control theory. New performance definitions such as fuzzy rise time, fuzzy settling time, and fuzzy maximum overshoot are presented. The new definitions for such systems provide a more comprehensive view of the system output which helps for designing a better control. Also, the solutions of an RLC circuit and intelligent transformer with fuzzy parameter based on these definitions are considered.},
  archive      = {J_SOCO},
  author       = {Abbasi, Seyed Mohammad Mehdi and Jalali, Aliakbar},
  doi          = {10.1007/s00500-019-04177-y},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4109-4120},
  shortjournal = {Soft Comput.},
  title        = {Some new performance definitions of second-order fuzzy systems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Solving multi-objective optimization problems using
self-adaptive harmony search algorithms. <em>SOCO</em>, <em>24</em>(6),
4081–4107. (<a
href="https://doi.org/10.1007/s00500-019-04175-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, there have been many multi-objective evolutionary algorithms proposed to solve multi-objective optimization problems. These evolutionary algorithms generate many solutions for iterations and move to the true Pareto optimal region gradually. As expected, since the harmony search algorithm can also iterate over a large number of solutions (in HM memory) and moves to the true Pareto optimal region, we use it to solve multi-objective optimization problems. In this paper, the proposed system architecture can be divided into two phases. In the first phase, we aim to search feasible solution regions as widely as possible in the entire process. In the second phase, we focus on searching optimized solutions stepwise in the feasible solution regions. Since the proposed algorithm uses many parameters, we adjust some of them in a self-adaptive way and call the algorithm self-adaptive. In the experiments, we use the eleven well-known multi-objective problems and three many-objective problems to examine the proposed algorithm and other existing algorithms, based on five performance indicators. As a result, our algorithm achieves better performances than the others in inverted generational distance, hypervolume, and spread indicators.},
  archive      = {J_SOCO},
  author       = {Huang, Yin-Fu and Chen, Sih-Hao},
  doi          = {10.1007/s00500-019-04175-0},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4081-4107},
  shortjournal = {Soft Comput.},
  title        = {Solving multi-objective optimization problems using self-adaptive harmony search algorithms},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Convolutional neural networks for sleep stage scoring on a
two-channel EEG signal. <em>SOCO</em>, <em>24</em>(6), 4067–4079. (<a
href="https://doi.org/10.1007/s00500-019-04174-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sleeping problems have become one of the major diseases all over the world. To tackle this issue, the basic tool used by specialists is the polysomnogram, which is a collection of different signals recorded during sleep. After its recording, the specialists have to score the different signals according to one of the standard guidelines. This process is carried out manually, which can be a high-time-consuming task and very prone to annotation errors. Therefore, over the years, many approaches have been explored in an attempt to support the specialists in this task. In this paper, an approach based on convolutional neural networks is presented, where an in-depth comparison is made in order to determine the convenience of using more than one signal simultaneously as input. This approach is similar to the one made in other problems although, additionally to those models, they were also used as parts of an ensemble model to check whether any useful information can be extracted from processing a single signal at a time which the dual-signal model cannot identify. Tests have been performed by using a well-known dataset called sleep-EDF-expanded, which is the most commonly used dataset as benchmark for this problem. The tests were carried out with a leave-one-out cross-validation over the patients, which ensures that there is no possible contamination between training and testing. The resulting proposal is a network smaller than previously published ones, but it overcomes the results of any previous models on the same dataset. The best result shows an accuracy of 92.67\% and a Cohen’s kappa value over 0.84 compared to human experts.},
  archive      = {J_SOCO},
  author       = {Fernandez-Blanco, Enrique and Rivero, Daniel and Pazos, Alejandro},
  doi          = {10.1007/s00500-019-04174-1},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4067-4079},
  shortjournal = {Soft Comput.},
  title        = {Convolutional neural networks for sleep stage scoring on a two-channel EEG signal},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Learning fuzzy cognitive maps with convergence using a
multi-agent genetic algorithm. <em>SOCO</em>, <em>24</em>(6), 4055–4066.
(<a href="https://doi.org/10.1007/s00500-019-04173-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy cognitive maps (FCMs) are generally applied to model and analyze complex dynamical systems. Recently, many evolutionary-based algorithms are proposed to learn FCMs from historical data by optimizing Data_Error, which is used to evaluate the difference between available response sequences and generated response sequences. However, when Data_Error is adopted as the fitness function for learning FCMs, two problems arise. One is that the optimization reaches the desired result slowly; the other is that the learned FCMs have high link density. To solve these problems, we propose another objective named as convergence error, which is inspired by the convergence of FCMs, to evaluate the difference between the convergent value of available response sequences and that of generated response sequences. In addition, a multi-agent genetic algorithm (MAGA), which is effective for large-scale global numerical optimization, is adopted to optimize convergence error for learning FCMs. To this end, a novel learning approach, a multi-agent genetic algorithm based on the convergence error (MAGA-Convergence), is proposed for learning FCMs. MAGA-Convergence needs less data, because the only initial value and convergent value of the available response sequences are needed for learning FCMs. In the experiments, MAGA-Convergence is applied to learn the FCMs of synthetic data and the benchmarks DREAM3 and DREAM4 for gene regulatory network reconstruction. The experimental results show that the learned FCMs are sparse and could be learned in much fewer generations than other learning algorithms.},
  archive      = {J_SOCO},
  author       = {Yang, Ze and Liu, Jing},
  doi          = {10.1007/s00500-019-04173-2},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4055-4066},
  shortjournal = {Soft Comput.},
  title        = {Learning fuzzy cognitive maps with convergence using a multi-agent genetic algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Palmprint identification combining hierarchical multi-scale
complete LBP and weighted SRC. <em>SOCO</em>, <em>24</em>(6), 4041–4053.
(<a href="https://doi.org/10.1007/s00500-019-04172-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Palmprint is one of the most reliable biometrics and has been widely used for human identification due to its high recognition accuracy and convenience for practical application. But the existing palmprint-based human identification system often suffers from image misalignment, pixel corruption and much computational time on the large database. An effective palmprint recognition method is proposed by combining hierarchical multi-scale complete local binary pattern (HMS-CLBP) and weighted sparse representation-based classification (WSRC). The hierarchical multi-scale local invariant texture features are extracted firstly from each palmprint by multi-scale local binary pattern (MS-LBP) and multi-scale complete local binary pattern (MS-CLBP) and are concatenated into one hierarchical multi-scale fusion feature vector. Then, WSRC is constructed by the Gaussian kernel distance, and use the Gaussian kernel distances between the fusion feature vectors of the training and testing samples. Finally, the sparse decomposition of testing samples is implemented by solving the optimization problem based on l1 norm, and the palmprints are recognized by the minimum residuals. The proposed method inherits the advantages of CLBP and WSRC and has good rotation, illumination and occlusion invariance. The results on the PolyU and CASIA palmprint databases illustrate the good performance and rationale interpretation of the proposed method.},
  archive      = {J_SOCO},
  author       = {Zhang, Shanwen and Wang, Harry and Huang, Wenzhun},
  doi          = {10.1007/s00500-019-04172-3},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4041-4053},
  shortjournal = {Soft Comput.},
  title        = {Palmprint identification combining hierarchical multi-scale complete LBP and weighted SRC},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A heuristic fuzzy algorithm for assessing and managing
tourism sustainability. <em>SOCO</em>, <em>24</em>(6), 4027–4040. (<a
href="https://doi.org/10.1007/s00500-019-04170-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {“Smartness” and “sustainability” are gaining growing attention from both practitioners and policy makers. “Smartness” and “sustainability” assessments are of crucial importance for directing, in a systemic perspective, the decision-making process toward sustainability and smart growth objectives. Sustainability assessment is a major challenge due to the multidisciplinary aspects involved that make the evaluation process complex and hinder the effectiveness of available monitoring tools. To achieve the assessment objective, we introduce an enhanced fuzzy logic-based framework for handling the inherent uncertainty and vagueness of the involved variables: we apply our approach to Italy, and we compare it with two other sustainability methodologies. We also perform a correlation analysis to assess the relationship between our ranking results and the attained quality of life scores. Our approach ensures a high level of versatility that makes its use possible jointly with (or alternatively to) other existing methodologies such as the Global Sustainable Tourism Council Criteria and the United Nations World Tourism Organization destination-level indicators.},
  archive      = {J_SOCO},
  author       = {Andria, Joseph and di Tollo, Giacomo and Pesenti, Raffaele},
  doi          = {10.1007/s00500-019-04170-5},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4027-4040},
  shortjournal = {Soft Comput.},
  title        = {A heuristic fuzzy algorithm for assessing and managing tourism sustainability},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Kernel intuitionistic fuzzy entropy clustering for MRI image
segmentation. <em>SOCO</em>, <em>24</em>(6), 4003–4026. (<a
href="https://doi.org/10.1007/s00500-019-04169-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy entropy clustering (FEC) is a variant of hard c-means clustering which utilizes the concept of entropy. However, the performance of the FEC method is sensitive to the noise and the fuzzy entropy parameter as it gives incorrect clustering and coincident cluster sometimes. In this work, a variant of the FEC method is proposed which incorporates advantage of intuitionistic fuzzy set and kernel distance measure termed as kernel intuitionistic fuzzy entropy c-means (KIFECM). While intuitionistic fuzzy set allows to handle uncertainty and vagueness associated with data, kernel distance measure helps to reveal the inherent nonlinear structures present in data without increasing the computational complexity. In this work, two popular intuitionistic fuzzy sets generators, Sugeno and Yager’s negation function, have been utilized for generating intuitionistic fuzzy sets corresponding to data. The performance of the proposed method has been evaluated over two synthetic datasets, Iris dataset, publicly available simulated human brain MRI dataset and IBSR real human brain MRI dataset. The experimental results show the superior performance of the proposed KIFECM over FEC, FCM, IFCM, UPCA, PTFECM and KFEC in terms of several performance measures such as partition coefficient, partition entropy, average segmentation accuracy, dice score, Jaccard score, false positive ratio and false negative ratio.},
  archive      = {J_SOCO},
  author       = {Kumar, Dhirendra and Agrawal, R. K. and Verma, Hanuman},
  doi          = {10.1007/s00500-019-04169-y},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {4003-4026},
  shortjournal = {Soft Comput.},
  title        = {Kernel intuitionistic fuzzy entropy clustering for MRI image segmentation},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Incorporating decision makers’ preferences into DEA and
common weight DEA models based on the best–worst method (BWM).
<em>SOCO</em>, <em>24</em>(6), 3989–4002. (<a
href="https://doi.org/10.1007/s00500-019-04168-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incorporating decision makers’ (DMs’) judgments and preferences into DEA models is very important in some real-world problems. This paper presents an integrated data envelopment analysis (DEA)—best–worst method (BWM)—for considering DMs’ preferences in DEA and reducing flexibility in weights of inputs and outputs. First, the preferences vectors are designed using BWM, and then, a multi-objective DEA-BWM model is introduced. The proposed DEA-BWM model simultaneously maximizes the efficiency scores of DMUs and considers DMs’ preferences about weights of inputs and outputs. Finally, a goal programming model is suggested for extending the DEA-BWM model and finding common weights of inputs and outputs based on the DMs’ judgments. The proposed common weight DEA-BWM (CWDEA-BWM) model maximizes the efficiencies of DMUs, considers DMs’ preferences and uses a set of common weights. In order to illustrate the capability of proposed models, a numerical example is solved. Moreover, the proposed DEA-BWM and common weight DEA-BWM models are applied to evaluate 39 Iranian electricity distribution companies, and the results are analyzed and compared. The results indicate that the proposed DEA-BWM and CWDEA-BWM models are suitable for incorporating DMs’ preferences into DEA and fully ranking of DMUs.},
  archive      = {J_SOCO},
  author       = {Omrani, Hashem and Alizadeh, Arash and Naghizadeh, Fatemeh},
  doi          = {10.1007/s00500-019-04168-z},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {3989-4002},
  shortjournal = {Soft Comput.},
  title        = {Incorporating decision makers’ preferences into DEA and common weight DEA models based on the best–worst method (BWM)},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Rough set-based feature selection for credit risk prediction
using weight-adjusted boosting ensemble method. <em>SOCO</em>,
<em>24</em>(6), 3975–3988. (<a
href="https://doi.org/10.1007/s00500-019-04167-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the tremendous development of financial institutions, credit risk prediction (CRP) plays an essential role in granting loans to customers and helps them to minimize their loss because credit approval sometimes results in massive financial loss. So extra attention is needed to identify risky customer. Researchers have designed complex CRP models using artificial intelligence (AI) and statistical techniques to support the financial institutions to take correct business decisions. Though there are various statistical and AI methods available, the recent literature shows that the ensemble-based CRP model provides improved prediction results than single classifier system. The small increase in the performance of CRP model could result in a significant improvement in the profit of financial institutions and banks. This work proposes a weight-adjusted boosting ensemble method (WABEM) using rough set (RS)-based feature selection (FS) technique with the balancing and regression-based preprocessing called RS$$\_$$RFS-WABEM. Regression is used to fill missing value in the records to improve the performance of CRP. Three credit datasets (Australia, German and Japanese) are chosen to validate the feasibility and effectiveness of the proposed ensemble method. The trade-off between the uncertainty and imprecise probability of the proposed classifier model is evaluated using the performance measures such as accuracy and area under the curve. Experimental results show that the proposed ensemble method performs better than other base and ensemble classifier methods.},
  archive      = {J_SOCO},
  author       = {Sivasankar, E. and Selvi, C. and Mahalakshmi, S.},
  doi          = {10.1007/s00500-019-04167-0},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {3975-3988},
  shortjournal = {Soft Comput.},
  title        = {Rough set-based feature selection for credit risk prediction using weight-adjusted boosting ensemble method},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fuzzy minimum spanning tree with interval type 2 fuzzy arc
length: Formulation and a new genetic algorithm. <em>SOCO</em>,
<em>24</em>(6), 3963–3974. (<a
href="https://doi.org/10.1007/s00500-019-04166-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy minimum spanning tree (FMST) has emerged from various real-life applications in different areas by considering uncertainty that exists in arc lengths of a fuzzy graph. In most relevant studies regarding FMST, type 1 fuzzy set was used to represent edge weights. Nonetheless, its membership values are totally crisp which is hard to determine its exact value by human perception. Interval type 2 fuzzy set (IT2FS) increases the number of degrees of freedom to express uncertainty of the edge weight and has more capacity to describe fuzzy information in a logically correct manner. In this paper, we propose the minimum spanning tree problem with undirected connected weighted interval type 2 fuzzy graph (FMST-IT2FS). Herein, the interval type 2 fuzzy set is used to represent the arc lengths of a fuzzy graph. Then, a new genetic algorithm is proposed to solve the FMST-IT2FS problem with the addition, ranking and defuzzification of IT2FSs being used. Illustrative examples are included to demonstrate the effectiveness of the proposed algorithm.},
  archive      = {J_SOCO},
  author       = {Dey, Arindam and Son, Le Hoang and Pal, Anita and Long, Hoang Viet},
  doi          = {10.1007/s00500-019-04166-1},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {3963-3974},
  shortjournal = {Soft Comput.},
  title        = {Fuzzy minimum spanning tree with interval type 2 fuzzy arc length: Formulation and a new genetic algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A unified algorithm based on HTS and self-adapting PSO for
the construction of octagonal and rectilinear SMT. <em>SOCO</em>,
<em>24</em>(6), 3943–3961. (<a
href="https://doi.org/10.1007/s00500-019-04165-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Steiner minimal tree (SMT) problem is an NP-hard problem, which is the best connection model for a multi-terminal net in global routing problem. This paper presents a unified algorithm for octagonal and rectilinear SMT construction based on hybrid transformation strategy (HTS) and self-adapting particle swarm optimization. Firstly, an effective HTS is proposed to enlarge the search space and improve the convergence speed. Secondly, the proposed HTS in the evolutionary process may produce an ineffective solution, and consequently the crossover and mutation operators of genetic algorithm (GA) based on union-find sets is proposed. Thirdly, a self-adapting strategy that can adjust the acceleration coefficients is proposed to further improve the convergence and the quality of the proposed algorithm. Finally, the hybrid transformation can be applied to GA and the proposed algorithm can be applied to rectilinear architecture. To our best knowledge, the proposed algorithm is the first unified algorithm to solve the SMT construction under both octagonal and rectilinear architecture. The experimental results show that the proposed algorithm can efficiently provide a better solution for SMT problem both in octagonal and rectilinear architectures than others. Moreover, the algorithm can obtain several topologies of SMT, which is beneficial for optimizing congestion in VLSI global routing stage.},
  archive      = {J_SOCO},
  author       = {Liu, Genggeng and Chen, Zhisheng and Zhuang, Zhen and Guo, Wenzhong and Chen, Guolong},
  doi          = {10.1007/s00500-019-04165-2},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {3943-3961},
  shortjournal = {Soft Comput.},
  title        = {A unified algorithm based on HTS and self-adapting PSO for the construction of octagonal and rectilinear SMT},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A note on “picture 2-tuple linguistic aggregation operators
in multiple attribute decision making.” <em>SOCO</em>, <em>24</em>(6),
3937–3941. (<a
href="https://doi.org/10.1007/s00500-019-04162-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By combining picture fuzzy set and 2-tuple linguistic representation model, Wei et al. (Soft Comput 22(3):989–1002, 2018) proposed the concept of picture 2-tuple linguistic set and presented some operational laws of picture 2-tuple linguistic numbers (P2TLNs). On the basis of operational laws of P2TLNs, some picture 2-tuple linguistic aggregation operators have been further developed. However, some operational laws and results derived by aggregation operators proposed by Wei et al. (Soft Comput 22(3):989–1002, 2018) are conflict with definition of picture 2-tuple linguistic number (P2TLN). In this short note, we propose some novel operational laws of P2TLNs and develop one adjusted picture 2-tuple linguistic aggregation operator, i.e., the adjusted picture 2-tuple linguistic weighted averaging operator.},
  archive      = {J_SOCO},
  author       = {Ju, Yanbing and Ju, Dawei and Wang, Aihua},
  doi          = {10.1007/s00500-019-04162-5},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {3937-3941},
  shortjournal = {Soft Comput.},
  title        = {A note on “Picture 2-tuple linguistic aggregation operators in multiple attribute decision making”},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An improved fuzzy risk analysis by using a new similarity
measure with center of gravity and area of trapezoidal fuzzy numbers.
<em>SOCO</em>, <em>24</em>(6), 3923–3936. (<a
href="https://doi.org/10.1007/s00500-019-04160-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is to develop a new similarity measure of generalized trapezoidal fuzzy numbers (GTFNs). Firstly, a new method to calculate the center of gravity (COG) of GTFNs is put forward. Then, based on the drawbacks of existing similarity measures, a new similarity measure is proposed by using the COGs, areas, heights and geometric distances of GTFNs. Some properties of the proposed similarity measure are investigated. Moreover, with 32 different sets of GTFNs, we make a comparison between the proposed similarity measure and the existing similarity measures. Furthermore, two fuzzy risk analysis problems are analyzed by utilizing the new similarity measure and the results indicate that it is effective to deal with fuzzy risk analysis problems.},
  archive      = {J_SOCO},
  author       = {Wu, Peng and Zhou, Ligang and Chen, Huayou and Zhou, Han},
  doi          = {10.1007/s00500-019-04160-7},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {3923-3936},
  shortjournal = {Soft Comput.},
  title        = {An improved fuzzy risk analysis by using a new similarity measure with center of gravity and area of trapezoidal fuzzy numbers},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A comparative review of meta-heuristic approaches to
optimize the SLA violation costs for dynamic execution of cloud
services. <em>SOCO</em>, <em>24</em>(6), 3909–3922. (<a
href="https://doi.org/10.1007/s00500-019-04155-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents comparative analysis results of research work done using the five most popular meta-heuristic techniques to optimize the service-level agreement (SLA) violation cost in cloud computing. The meta-heuristic algorithms have the ability to handle multifarious types of constraints and offer better results. The Quality of Service criteria, SLA penalty cost and the cloud-domain-specific constraints have been mathematically formulated in this paper. The sole motivation of this paper is that the constraints of feasible domain must be satisfied and the profit of cloud service provider should be maximized. An effort has been made to experimentally demonstrate the comparative performance of five meta-heuristic algorithms, namely Ant Colony Optimization, Particle Swarm Optimization, Genetic Algorithm, Gray Wolf Optimizer and Harmony Search. Eleven test benchmark functions have been applied to demonstrate the efficiency and performance. The best solutions of each meta-heuristic technique have been reported in four performance metric cases: worst, best, average and standard deviation.},
  archive      = {J_SOCO},
  author       = {Kumar, Ajay and Bawa, Seema},
  doi          = {10.1007/s00500-019-04155-4},
  journal      = {Soft Computing},
  number       = {6},
  pages        = {3909-3922},
  shortjournal = {Soft Comput.},
  title        = {A comparative review of meta-heuristic approaches to optimize the SLA violation costs for dynamic execution of cloud services},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Power-law fitness scaling on multi-objective evolutionary
algorithms: Interpretations of experimental results. <em>SOCO</em>,
<em>24</em>(5), 3893–3907. (<a
href="https://doi.org/10.1007/s00500-019-04242-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The effect of power-law fitness scaling method on the convergence and distribution of MOEAs is investigated in a systematic fashion. The proposed method is named as gamma (γ) correction-based fitness scaling (GCFS). What scaling does is that the selection pressure of a population can be efficiently regulated. Hence, fit and unfit individuals may be separated well in fitness-wise before going to the selection mechanism. It is then applied to Strength Pareto Evolutionary Algorithm 2 (SPEA2) and Domination Power of an individual Genetic Algorithm (DOPGA). Firstly, the effectiveness of GCFS is tested by 11 static gamma values (including 0.5, 1, 2, …, 9, 10) on nine well-known benchmarks. Simulated study safely states that SPEA2 and DOPGA may perform generally better with the square (γ = 2) and the cubic (γ = 3) of original fitness value, respectively. Secondly, an adaptive version of GCFS is proposed based on statistical merits (standard deviation and mean of fitness values) and implemented to the selected MOEAs. Generally speaking, fitness scaling significantly improves the convergence properties of MOEAs without extra computational burdens. It is observed that the convergence ability of existing MOEAs with fitness scaling (static or adaptive) can be improved. Simulated results also show that GCFS is only effective when fitness proportional selection methods (such as stochastic universal sampling—SUS) are used. GCFS is not effective when tournament selection is used.},
  archive      = {J_SOCO},
  author       = {Ergul, Engin Ufuk and Eminoglu, Ilyas},
  doi          = {10.1007/s00500-019-04242-6},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3893-3907},
  shortjournal = {Soft Comput.},
  title        = {Power-law fitness scaling on multi-objective evolutionary algorithms: Interpretations of experimental results},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptive multi-population inflationary differential
evolution. <em>SOCO</em>, <em>24</em>(5), 3861–3891. (<a
href="https://doi.org/10.1007/s00500-019-04154-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a multi-population adaptive version of inflationary differential evolution algorithm. Inflationary differential evolution algorithm (IDEA) combines basic differential evolution (DE) with some of the restart and local search mechanisms of Monotonic Basin Hopping (MBH). In the adaptive version presented in this paper, the DE parameters $${ CR}$$ and F are automatically adapted together with the size of the local restart bubble and the number of local restarts of MBH. The proposed algorithm implements a simple but effective mechanism to avoid multiple detections of the same local minima. The novel mechanism allows the algorithm to decide whether to start or not a local search. The algorithm has been extensively tested over more than fifty test functions from the competitions of the Congress on Evolutionary Computation (CEC), CEC 2005, CEC 2011 and CEC 2014, and compared against all the algorithms participating in those competitions. For each test function, the paper reports best, worst, median, mean and standard deviation values of the best minimum found by the algorithm. Comparisons with other algorithms participating in the CEC competitions are presented in terms of relative ranking, Wilcoxon tests and success rates. For completeness, the paper presents also the single population adaptive IDEA, that can adapt only $$\textit{CR}$$ and F, and shows that this simpler version can outperform the multi-population one if the radius of the restart bubble and the number of restarts are properly chosen.},
  archive      = {J_SOCO},
  author       = {Di Carlo, Marilena and Vasile, Massimiliano and Minisci, Edmondo},
  doi          = {10.1007/s00500-019-04154-5},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3861-3891},
  shortjournal = {Soft Comput.},
  title        = {Adaptive multi-population inflationary differential evolution},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robotic manipulator control based on an optimal
fractional-order fuzzy PID approach: SiL real-time simulation.
<em>SOCO</em>, <em>24</em>(5), 3849–3860. (<a
href="https://doi.org/10.1007/s00500-019-04152-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic manipulator control is a challenging task due to its nonlinear, interacting multi-input–multi-output dynamics. In this paper, we proposed an optimal robust fractional-order fuzzy PID controller based on multi-objective particle swarm optimization (MOPSO) algorithm for a two-link robotic manipulator. In order to minimize position and trajectory-tracking error, MOPSO finds the optimal parameters of fuzzy membership functions and order of the fractional operators. To show the effectiveness of the proposed controller, the software-in-the-loop real-time simulation is executed, and the results are compared to conventional fuzzy PID, fractional-order PID, and linear PID controllers.},
  archive      = {J_SOCO},
  author       = {Ardeshiri, Reza Rouhi and Khooban, Mohammad Hassan and Noshadi, Amin and Vafamand, Navid and Rakhshan, Mohsen},
  doi          = {10.1007/s00500-019-04152-7},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3849-3860},
  shortjournal = {Soft Comput.},
  title        = {Robotic manipulator control based on an optimal fractional-order fuzzy PID approach: SiL real-time simulation},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new image encryption algorithm using random numbers
generation of two matrices and bit-shift operators. <em>SOCO</em>,
<em>24</em>(5), 3829–3848. (<a
href="https://doi.org/10.1007/s00500-019-04151-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we proposed a new approach to encrypt color images using two matrices with size of 16 × 16 whose integer values are between 0 and 255 generated randomly, and the bit-shift operators. These matrices are used to perform the first encryption phase. The first value of the first matrix is calculated from the pixels of each channel (red, green and blue) of the original image; the rest of the values are randomly generated; each value must be unique; the values of the second matrix are unique and generated randomly. The first encryption phase of the original image is done by digraph (two-digit sequence). We take the first digit in the first matrix, the second digit in the second matrix; then, we look in these matrices for the numbers that complete the rectangle. In the second encryption phase, we used a right circular shift of bits; the number of bits to shift is calculated according to a function which considers the values of the two matrices as well as their positions (row and column). Therefore, any change in the two keys (two matrices) will completely change the encrypted image. Our encryption system is resistant against brute force attacks, statistical attacks as well as differential attacks. The results are justified by applying several safety criteria, such as correlation coefficient, entropy and peak signal-to-noise ratio (PSNR). In addition, our method is very sensitive to the change made, either in the original image or in the two keys used for the encryption, which was justified by calculating the number of changing pixel rate (NPCR &gt; 99.69) and the unified averaged changed intensity (UACI &gt; 33.54).},
  archive      = {J_SOCO},
  author       = {Es-Sabry, Mohammed and El Akkad, Nabil and Merras, Mostafa and Saaidi, Abderrahim and Satori, Khalid},
  doi          = {10.1007/s00500-019-04151-8},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3829-3848},
  shortjournal = {Soft Comput.},
  title        = {A new image encryption algorithm using random numbers generation of two matrices and bit-shift operators},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A recognition–verification system for noisy faces based on
an empirical mode decomposition with green’s functions. <em>SOCO</em>,
<em>24</em>(5), 3809–3827. (<a
href="https://doi.org/10.1007/s00500-019-04150-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face recognition or verification remains a real challenge in the area of pattern recognition and image processing. The image acquisition process is a crucial step in which noise will inevitably be introduced, and in most cases this noise drastically decreases the accuracy of the classification rate of recognition systems, making them ineffective. This paper presents a novel approach to face recognition or verification, which increases the recognition rate in noisy environmental conditions. The latter is achieved by using the intrinsic face mode functions that result from applying a bi-dimensional empirical mode decomposition with Green’s functions in tension to noisy images. Each image is individually decomposed, and noisy modes are discarded or filtered during reconstruction. Then, the extracted modes are used for classification purposes with canonical classifiers such as vector support machines or k-nearest neighbor classifiers. Experimental results show that this method achieves very stable results, almost independently of the amount of noise added to the image, due to the ability of decomposition to capture the noise in the first mode. Classification results using noisy images are at the same level as other algorithms proposed for the same databases but working on clean images and therefore are better than those obtained using classic image filters in noisy images. Moreover, unlike most of the available algorithms, the algorithm proposed in this paper is based on the input data (without the need to adjust parameters), making it transparent to the user. Finally, the proposed new approach achieves good results independently of the type of noise, the level of noise and the type of the database, which is not possible with other classical methods requiring parameter adjustment.},
  archive      = {J_SOCO},
  author       = {Al-Baddai, Saad and Marti-Puig, Pere and Gallego-Jutglà, Esteve and Al-Subari, Karema and Tomé, Ana Maria and Ludwig, Bernd and Lang, Elmar Wolfgang and Solé-Casals, Jordi},
  doi          = {10.1007/s00500-019-04150-9},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3809-3827},
  shortjournal = {Soft Comput.},
  title        = {A recognition–verification system for noisy faces based on an empirical mode decomposition with green’s functions},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Some inequalities and limit theorems for fuzzy random
variables adopted with <span
class="math display"><em>α</em></span>-values of fuzzy numbers.
<em>SOCO</em>, <em>24</em>(5), 3797–3807. (<a
href="https://doi.org/10.1007/s00500-019-04149-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, some essential stochastic inequalities and several convergence theorems were investigated for fuzzy random variables. The classical counterpart relationship between the proposed convergence theorems was also discussed in the fuzzy environment. The main advantage of the proposed method is its minimal requirements for such limit theorems and inequalities compared to the conventional methods used in the fuzzy environments. The previous methods mostly rely on the lower and upper bounds of the $$\alpha $$-cuts of fuzzy random variables, while the proposed method utilizes a unified quantity called $$\alpha $$-value.},
  archive      = {J_SOCO},
  author       = {Hesamian, Gholamreza and Akbari, Mohammad Ghasem and Ranjbar, Vahid},
  doi          = {10.1007/s00500-019-04149-2},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3797-3807},
  shortjournal = {Soft Comput.},
  title        = {Some inequalities and limit theorems for fuzzy random variables adopted with $$\alpha $$-values of fuzzy numbers},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Green supplier selection of electric vehicle charging based
on choquet integral and type-2 fuzzy uncertainty. <em>SOCO</em>,
<em>24</em>(5), 3781–3795. (<a
href="https://doi.org/10.1007/s00500-019-04147-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a framework under interval type-2 fuzzy (IT2F) environment is proposed to select the optimal green supplier of electric vehicle charging facility (EVCF). In the primary stage, a decision committee consisting of senior executives and experts is established, and qualified suppliers are also selected. The second stage aims to solve the problem of inherent uncertainties and criteria interactions. So, firstly, IT2F numbers are adopted for the performance evaluation since the criteria value cannot be adequately represented by type-1 fuzzy numbers. Then, $$ \lambda $$-fuzzy measure is adopted to measure the fuzzy densities of criteria by considering the interactions. After that, these fuzzy densities and aggregated IT2F matrix are as inputs to a proposed IT2F Choquet integral (IT2FCI) operator to evaluate the suppliers. Finally, to illustrate the validity of the proposed framework, a case study with a sensitivity analysis is presented. The weighting results indicate that the criterion of “production cost” owns the largest fuzzy density of 0.65, and the sorting results show that none of these alternatives are optimal in all criteria and the results are relatively stable for a change in fuzzy density.},
  archive      = {J_SOCO},
  author       = {Wu, Yunna and Xu, Chuanbo and Huang, Yong and Li, Xinying},
  doi          = {10.1007/s00500-019-04147-4},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3781-3795},
  shortjournal = {Soft Comput.},
  title        = {Green supplier selection of electric vehicle charging based on choquet integral and type-2 fuzzy uncertainty},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new approach for the rainbow spanning forest problem.
<em>SOCO</em>, <em>24</em>(5), 3771–3780. (<a
href="https://doi.org/10.1007/s00500-019-04145-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given an edge-colored graph G, a tree with all its edges with different colors is called a rainbow tree. The rainbow spanning forest (RSF) problem consists of finding a spanning forest of G, with the minimum number of rainbow trees. In this paper, we present an integer linear programming model for the RSF problem that improves a previous formulation for this problem. A GRASP metaheuristic is also implemented for providing fast primal bounds for the exact method. Computational experiments carried out over a set of random instances show the effectiveness of the strategies adopted in this work, solving problems in graphs with up to 100 vertices.},
  archive      = {J_SOCO},
  author       = {Moreno, Jorge and Martins, Simone and Frota, Yuri},
  doi          = {10.1007/s00500-019-04145-6},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3771-3780},
  shortjournal = {Soft Comput.},
  title        = {A new approach for the rainbow spanning forest problem},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-level cognitive concept learning method oriented to
data sets with fuzziness: A perspective from features. <em>SOCO</em>,
<em>24</em>(5), 3753–3770. (<a
href="https://doi.org/10.1007/s00500-019-04144-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a new interdisciplinary field induced by formal concept analysis, rough set, granular computing and cognitive computing, cognitive concept learning has received a great attention in recent years. Cognitive concept learning refers to the acquisition of specific concepts through specific cognitive concept learning approaches. The processes of concept learning mainly focus on simulating human brain recognizing concepts through the modeling of brain intelligence. In this paper, we investigate the mechanism of multi-level cognitive concept learning method oriented to data sets with fuzziness by discussing the process of human cognition. Through a newly defined fuzzy focal feature set, we put forward a corresponding structure of feature-oriented multi-level cognitive concept learning method in data sets with fuzziness from a perspective of philosophical and psychological views of human cognition. To make the presented cognitive concept learning approach much easier to understand and to apply it to practice widely, we establish an algorithm to recognize fuzzy concepts and incomplete fuzzy concepts. In addition, we present a case study about how to recognize and distinguish any two different micro-expressions from an information system with quantitative description to use our proposed method and theory to solve conceptual cognition problems, and also we perform an experimental evaluation on five data sets downloaded from the University of California-Irvine databases. Compared with the existing granular computing approach to two-way learning, we obtain more concepts than the two-way learning approach, which shows the feasibility and effectiveness of our feature-oriented multi-level cognitive learning method in data sets with fuzziness.},
  archive      = {J_SOCO},
  author       = {Tsang, Eric C. C. and Fan, Bingjiao and Chen, Degang and Xu, Weihua and Li, Wentao},
  doi          = {10.1007/s00500-019-04144-7},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3753-3770},
  shortjournal = {Soft Comput.},
  title        = {Multi-level cognitive concept learning method oriented to data sets with fuzziness: A perspective from features},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptive fuzzy observer-based cooperative control of unknown
fractional-order multi-agent systems with uncertain dynamics.
<em>SOCO</em>, <em>24</em>(5), 3737–3752. (<a
href="https://doi.org/10.1007/s00500-019-04142-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In our paper, a new cooperative control for unknown fractional-order multi-agent systems is proposed. In addition to unknown dynamics, for the first time, the values of the fractional orders are also assumed to be unknown, and a new robust observer-based cooperative method for consensus issue of multi-agent systems (MASs) is presented. The unknown functions in the dynamics of the systems in all agents are estimated with the proposed interval type 2 fuzzy self-structuring radial basis function neural network (IT2F-SRBFNN). The free parameters of all IT2F-SRBFNN in all agents are adjusted using the adaptation laws which can be derived from the Lyapunov stability analysis. The strength of the proposed strategy is verified by a number of simulation examples.},
  archive      = {J_SOCO},
  author       = {Afaghi, A. and Ghaemi, S. and Ghiasi, A. R. and Badamchizadeh, M. A.},
  doi          = {10.1007/s00500-019-04142-9},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3737-3752},
  shortjournal = {Soft Comput.},
  title        = {Adaptive fuzzy observer-based cooperative control of unknown fractional-order multi-agent systems with uncertain dynamics},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An ensemble learning framework for convolutional neural
network based on multiple classifiers. <em>SOCO</em>, <em>24</em>(5),
3727–3735. (<a
href="https://doi.org/10.1007/s00500-019-04141-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional machine learning methods have certain limitations in constructing high-precision estimation models and improving generalization ability, but ensemble learning that combines multiple different single models into one model is significantly better than that obtained by a single machine learning model. When the types of data sets are diversified and the scale is increasing, the ensemble learning algorithm has the problem of incomplete representation of features. At this time, convolutional neural network (CNN) with excellent feature learning ability makes up for the shortcomings of ensemble learning. In this paper, an ensemble learning framework for convolutional neural network based on multiple classifiers is proposed. First, this method mainly classifies UCI data sets using the ensemble learning algorithms based on multiple classifiers. Then, feature extraction is performed on the image data set MNIST using a convolutional neural network, and the extracted features are applied as input to be classified using an ensemble learning framework. The experimental results show that the accuracy of ensemble learning is higher than the accuracy of a single classifier and the accuracy of CNN + ensemble learning framework is higher than the accuracy of ensemble learning framework.},
  archive      = {J_SOCO},
  author       = {Guo, Yanyan and Wang, Xin and Xiao, Pengcheng and Xu, Xinzheng},
  doi          = {10.1007/s00500-019-04141-w},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3727-3735},
  shortjournal = {Soft Comput.},
  title        = {An ensemble learning framework for convolutional neural network based on multiple classifiers},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stability analysis of chemotaxis dynamics in bacterial
foraging optimization over multi-dimensional objective functions.
<em>SOCO</em>, <em>24</em>(5), 3711–3725. (<a
href="https://doi.org/10.1007/s00500-019-04139-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bacterial foraging optimization (BFO) has been proved to be an efficient optimization method and successfully applied to a variety of fields in the real world. In BFO, the chemotaxis process is a complex and close combination of swimming and tumbling and plays a crucial role in searching better solutions. A previous study has modeled the dynamics of the chemotaxis mechanism mathematically and investigated the stability and convergence behavior of the chemotaxis dynamics over the one-dimensional objective function by Lyapunov stability theorem. However, this study appears to be very limited from a practical point of view, and how to extend their study to the multi-dimensional objective function is a challenge. To solve it, we present a stability analysis of chemotaxis dynamics in BFO over the multi-dimensional objective function in this paper. First, the general mathematical model of the chemotaxis mechanism over the multi-dimensional objective function is created. Secondly, this paper uses the general descent search to analyze the general mathematical model and points out two necessary conditions for avoiding the bacterium to trap into a non-optimal solution. And then, the stability and convergence of the chemotaxis dynamics, represented by the general mathematical model, are proved by using Lyapunov stability theorem. Finally, empirical research is conducted to validate the above theoretical analysis.},
  archive      = {J_SOCO},
  author       = {Yang, Cuicui and Ji, Junzhong and Li, Sanjiang},
  doi          = {10.1007/s00500-019-04139-4},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3711-3725},
  shortjournal = {Soft Comput.},
  title        = {Stability analysis of chemotaxis dynamics in bacterial foraging optimization over multi-dimensional objective functions},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Uncertain multi-objective optimization for the
water–rail–road intermodal transport system with consideration of hub
operation process using a memetic algorithm. <em>SOCO</em>,
<em>24</em>(5), 3695–3709. (<a
href="https://doi.org/10.1007/s00500-019-04137-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the multi-objective optimization of water–rail–road (WRR) intermodal transport system under uncertainty by explicitly capturing intermodal hub operation activities. Through the use of hub-and-spoke-type network, we formulate an uncertain multi-objective programming model for the WRR intermodal transportation network design problem, in which the cost, time and reliability objectives are simultaneously considered. Subsequently, we turn the original model into a deterministic equivalent multi-objective programming model under mild assumptions. Eventually, we utilize the $$\varepsilon $$-constraint method to reformulate the crisp multi-objective programming model to a modified mono objective one, which has proven to be NP-hard. Hence, we develop a memetic algorithm (MA) by combining a genetic algorithm and local intensification to solve the proposed problem. When designing the MA, we propose a combination encoding scheme to represent the location of intermodal hubs, the allocation of the demand nodes and the assignment of transportation modes. Moreover, we provide two local intensification operators to enhance exploitation ability. Finally, we implement a series of numerical experiments based on the Turkish network data set to verify the practicability of the proposed model and effectiveness of the solution approach developed in the paper.},
  archive      = {J_SOCO},
  author       = {Zhang, Wenying and Wang, Xifu and Yang, Kai},
  doi          = {10.1007/s00500-019-04137-6},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3695-3709},
  shortjournal = {Soft Comput.},
  title        = {Uncertain multi-objective optimization for the water–rail–road intermodal transport system with consideration of hub operation process using a memetic algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Extended dissipativity and event-triggered synchronization
for t–s fuzzy markovian jumping delayed stochastic neural networks with
leakage delays via fault-tolerant control. <em>SOCO</em>,
<em>24</em>(5), 3675–3694. (<a
href="https://doi.org/10.1007/s00500-019-04136-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper concentrates on the extended dissipativity and event-triggered synchronization for T–S fuzzy Markovian jumping delayed stochastic neural networks with leakage delays and fault-tolerant control. We present an event-triggered communication scheme, which utilizes the effect of transmission delay with different failure rates. After giving a foundation to the stochastic model, the paper establishes some fundamental results on quadratically stable and extended dissipativity utilizing the Lyapunov functional, free-weight matrices, as well as the relationship between time-varying delay and leakage delays. The explicit expression of the desired controller gains and event-triggered parameters can be obtained by solving the established LMIs. The novel extended dissipative inequality contains several weighting matrices, by converting the weighting matrices in a new performance index, and the extended dissipativity will be degraded to the $$H_{\infty }$$ performance, $$L_2-L_{\infty }$$ performance, passivity and dissipativity, respectively. Finally, interesting numerical examples are given to show the effectiveness of the theoretical results.},
  archive      = {J_SOCO},
  author       = {Ali, M. Syed and Vadivel, R. and Alsaedi, Ahmed and Ahmad, Bashir},
  doi          = {10.1007/s00500-019-04136-7},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3675-3694},
  shortjournal = {Soft Comput.},
  title        = {Extended dissipativity and event-triggered synchronization for T–S fuzzy markovian jumping delayed stochastic neural networks with leakage delays via fault-tolerant control},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Group-based whale optimization algorithm. <em>SOCO</em>,
<em>24</em>(5), 3647–3673. (<a
href="https://doi.org/10.1007/s00500-019-04131-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Meta-heuristic algorithms are divided into two categories: biological and non-biological. Biological algorithms are divided into evolutionary and swarm-based intelligence, where the latter is divided into imitation based and sign based. The whale algorithm is a meta-heuristic biological swarm-based intelligence algorithm (based on imitation). This algorithm suffers from the early convergence problem which means the population convergences early to an unfavorable optimum point. Usually, the early convergence occurs because of the weakness in exploration capability (global search). In this study, an optimized version of the whale algorithm is proposed that introduces a new idea in grouping of whales (called GWOA) to overcome the early convergence problem. The proposed whale optimization algorithm is compared with the standard whale algorithm (WOA), CWOA improved whale algorithm, particle swarm optimization, and BAT algorithms applying CEC2017 functions. The results of the experiments show that the proposed method applying Friedman’s test on 30 standard benchmark functions has a better performance than the other baseline algorithms.},
  archive      = {J_SOCO},
  author       = {Hemasian-Etefagh, Farinaz and Safi-Esfahani, Faramarz},
  doi          = {10.1007/s00500-019-04131-y},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3647-3673},
  shortjournal = {Soft Comput.},
  title        = {Group-based whale optimization algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bipolar fuzzy dombi prioritized aggregation operators in
multiple attribute decision making. <em>SOCO</em>, <em>24</em>(5),
3631–3646. (<a
href="https://doi.org/10.1007/s00500-019-04130-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, used Dombi t-norm (TN) and t-conorm (TCN) which can generate more complex and more flexible operation rules by adjusting a parameter to combine with prioritized aggregation operators (AOs) in bipolar fuzzy (BF) environment. In this study, introduced bipolar fuzzy Dombi prioritized AOs, namely bipolar fuzzy Dombi prioritized averaging operator, bipolar fuzzy Dombi geometric operator, bipolar fuzzy Dombi prioritized weighted averaging operator and bipolar fuzzy Dombi prioritized weighted geometric operator as these operators along with proofs to aggregate various preferences of the decision makers. In this purpose, we designed a multiple attribute decision-making technique for the proposed study. Finally, an illustrative example is given to demonstrate proposed approach under BF environment and a sensitivity analysis is considered for the working parameter on the ordering of the alternatives. A comparative study is provided for the choice best decision of the proposed approach with the existing problems. Finally, it is concluded that the proposed approach gives a more practical nature to aggregate the information process during the data analysis, and hence they take an alternative way for solving decision-making problems.},
  archive      = {J_SOCO},
  author       = {Jana, Chiranjibe and Pal, Madhumangal and Wang, Jian-qiang},
  doi          = {10.1007/s00500-019-04130-z},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3631-3646},
  shortjournal = {Soft Comput.},
  title        = {Bipolar fuzzy dombi prioritized aggregation operators in multiple attribute decision making},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hierarchical fuzzy design by a multi-objective evolutionary
hybrid approach. <em>SOCO</em>, <em>24</em>(5), 3615–3630. (<a
href="https://doi.org/10.1007/s00500-019-04129-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new tree hierarchical representation of type-2 fuzzy systems. The proposed system is called the type-2 hierarchical flexible beta fuzzy system (T2HFBFS) and is trained based on two-phase optimization mechanism. The first optimization step is a multi-objective structural learning phase. This phase is based on the multi-objective extended immune programming algorithm and aims to obtain an improved T2HFBFS structure with good interpretability-accuracy trade-off. The second optimization step is a parameter tuning phase. Using a hybrid evolutionary algorithm, this phase allows the adjustment of antecedent and consequent membership function parameters of the obtained T2HFBFS. By interleaving the two learning steps, an optimal and accurate hierarchical type-2 fuzzy system is derived with the least number of possible rules. The performance of the system is evaluated by conducting case studies for time series prediction problems and high-dimensional classification problems. Results prove that the T2HFBFS could attain superior performance than other existing approaches in terms of achieving high accuracy with a significant rule reduction.},
  archive      = {J_SOCO},
  author       = {Jarraya, Yosra and Bouaziz, Souhir and Alimi, Adel M. and Abraham, Ajith},
  doi          = {10.1007/s00500-019-04129-6},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3615-3630},
  shortjournal = {Soft Comput.},
  title        = {Hierarchical fuzzy design by a multi-objective evolutionary hybrid approach},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Determining optimal designs for geosynthetic-reinforced soil
bridge abutments. <em>SOCO</em>, <em>24</em>(5), 3601–3614. (<a
href="https://doi.org/10.1007/s00500-019-04127-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The article presents a parametric study of optimal designs for geosynthetic-reinforced soil (GRS) bridge abutments. A mixed integer design optimization model GRS-BA was developed, which is comprised of an accurate objective function of the construction costs. The cost objective function was constrained by a set of geotechnical and design conditions that were in accordance with current practice rules and recommendations. The optimal design recommendation for GRS bridge abutments was developed. A typical example of such an abutment is presented in order to compare design solutions derived from conventional design methods with solutions obtained from the proposed optimal design procedure.},
  archive      = {J_SOCO},
  author       = {Jelušič, Primož and Žlender, Bojan},
  doi          = {10.1007/s00500-019-04127-8},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3601-3614},
  shortjournal = {Soft Comput.},
  title        = {Determining optimal designs for geosynthetic-reinforced soil bridge abutments},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Public information, heterogeneous attention and market
instability. <em>SOCO</em>, <em>24</em>(5), 3591–3599. (<a
href="https://doi.org/10.1007/s00500-019-04126-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate how market instability is formed with investment decision models of heterogeneous agents who are characterized by different selectivities of attention to public information. In the nonlinear dynamic decision model, agents make decisions on trading volume based on their own volume and marginal payoff of the previous period, as well as their selective attention to public information. One goal of this paper is to use the model to explore the condition under which public information could trigger the market instability. A second, related, goal is to study whether there is other investor behavior factor that leads to market instability. We find that some traders’ significant attention to bad news or most traders’ significant attention to good news can lead to market instability. We also find that whole market also may develop into chaos through bifurcation, with increasing relative trading adjustment speed responding to marginal payoff for some traders, although all traders pay no attention to public information. The relative trading adjustment speed responding to marginal payoff is more likely to cause market instability than public information. Our findings reveal an extremely simple stylized fact that market instability always occurs when there is no public information.},
  archive      = {J_SOCO},
  author       = {Wu, Chengyao and Chen, Huiyang and Peng, Peng and Cen, Yonghua},
  doi          = {10.1007/s00500-019-04126-9},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3591-3599},
  shortjournal = {Soft Comput.},
  title        = {Public information, heterogeneous attention and market instability},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The grid-to-neighbourhood relationship in cellular GAs: From
design to solving complex problems. <em>SOCO</em>, <em>24</em>(5),
3569–3589. (<a
href="https://doi.org/10.1007/s00500-019-04125-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cellular genetic algorithms (cGAs) are a class of evolutionary algorithms in which the population is structured as a grid and interactions between individuals are restricted to the neighbourhood. Like any other optimisation algorithm, the cGA’s efficiency lies in its ability to find an adequate balance between its exploratory and exploitive capabilities. The search selection pressure represents a good indicator of the state of that balance. From that point of view, it has been shown that the cGA’s grid-to-neighbourhood relationship can be used to reflect this property. Until today, not much has been done in that area of research and many questions still surround this grid-to-neighbourhood effect. This paper describes a systematic study on the effects of that ratio on the efficiency of the cGA. This is done by proposing a dynamic cGA that adapts its ratio through evolving its grid structure using some strategy. The study is conducted using a wide range of dynamic and static ratio-control policies and, for the first time, by considering both synchronous and asynchronous cGAs. As a validation problem, we have opted for a real-world complex problem in advanced cellular networks: the users’ mobility management. A wide set of differently sized and realistic instances of this problem have been used, and several comparisons have been conducted against other top-ranked solvers. The experiments showed that the ratio strategy rules the cGA’s convergence, efficiency and scalability. Its effectiveness is correlated with the ratio-adaptation policy and the replacement synchronism being used. Indeed, our proposals that are based on deterministic and dynamic strategies with an asynchronous replacement were able to outperform most of the state-of-the-art algorithms.},
  archive      = {J_SOCO},
  author       = {Dahi, Zakaria Abdelmoiz and Alba, Enrique},
  doi          = {10.1007/s00500-019-04125-w},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3569-3589},
  shortjournal = {Soft Comput.},
  title        = {The grid-to-neighbourhood relationship in cellular GAs: From design to solving complex problems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel parallel local search algorithm for the maximum
vertex weight clique problem in large graphs. <em>SOCO</em>,
<em>24</em>(5), 3551–3567. (<a
href="https://doi.org/10.1007/s00500-019-04122-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a new parallel local search algorithm (Par-LS) for solving the maximum vertex weight clique problem (MVWCP) in large graphs. Solving the MVWCP in a large graph with millions of edges and vertices is an intractable problem. Parallel local search methods are powerful tools to deal with such problems with their high-performance computation capability. The Par-LS algorithm is developed on a distributed memory environment by using message passing interface libraries and employs a different exploration strategy at each processor. The Par-LS introduces new operators parallel($$\omega $$,1)-swap and parallel(1,2)-swap, for searching the neighboring solutions while improving the current solution through iterations. During our experiments, 172 of 173 benchmark problem instances from the DIMACS, BHOSLIB and Network Data Repository graph libraries are solved optimally with respect to the best/optimal reported results. A new best solution for the largest problem instance of the BHOSLIB benchmark (frb100-40) is discovered. The Par-LS algorithm is reported as one of the best performing algorithms in the literature for the solution of the MVWCP in large graphs.},
  archive      = {J_SOCO},
  author       = {Sevinc, Ender and Dokeroglu, Tansel},
  doi          = {10.1007/s00500-019-04122-z},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3551-3567},
  shortjournal = {Soft Comput.},
  title        = {A novel parallel local search algorithm for the maximum vertex weight clique problem in large graphs},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A fuzzy application of the group <span
class="math display">ℤ<sub><em>n</em></sub></span> to complete
hypergroups. <em>SOCO</em>, <em>24</em>(5), 3543–3550. (<a
href="https://doi.org/10.1007/s00500-019-04121-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of this paper is the study of intuitionistic fuzzy subhypergroups of some special finite complete hypergroups. More exactly, in this paper we determine all m-tuples, characterizing the considered complete hypergroups, such that the grade intuitionistic fuzzy set $$(\overline{\mu },\overline{\lambda })$$ is an intuitionistic fuzzy subhypergroup of such hypergroups. Here, we deal with complete hypergroups obtained from groups isomorphic with the additive groups of integers modulo $$p^2$$ or modulo pq, with p and q distinct odd primes. This article is a continuation of a previous work, concerning the complete hypergroups obtained from groups isomorphic with the additive groups of integers modulo p or modulo 2p, with p a prime number. It represents the starting point, the mathematical base, for writing a general algorithm for characterizing all complete hypergroups obtained from a group G and having the grade intuitionistic fuzzy set as an intuitionistic fuzzy subhypergroup.},
  archive      = {J_SOCO},
  author       = {Cristea, Irina and Hassani Sadrabadi, Elhan and Davvaz, Bijan},
  doi          = {10.1007/s00500-019-04121-0},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3543-3550},
  shortjournal = {Soft Comput.},
  title        = {A fuzzy application of the group $$\mathbb {Z}_n$$ to complete hypergroups},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An uncertain two-echelon fixed charge transportation
problem. <em>SOCO</em>, <em>24</em>(5), 3529–3541. (<a
href="https://doi.org/10.1007/s00500-019-04119-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the present study, a two-echelon fixed charge transportation problem is investigated under uncertainty. Due to the existence of considerable amount of uncertainties, the demands, supplies, availabilities, fixed charges and transported quantities in this problem are assumed as uncertain variables. The aim is to maximize the total profit under uncertain environments. The expected value model, chance-constrained model and measure chance model are developed, and the deterministic equivalent forms of these models are obtained by inverse uncertainty distribution. Genetic algorithm and particle swarm optimization are proposed to solve the equivalent forms of the models based on the structure of the problem. To verify the effectiveness of these proposed approaches, numerical experiments are performed.},
  archive      = {J_SOCO},
  author       = {Shen, Jiayu and Zhu, Kai},
  doi          = {10.1007/s00500-019-04119-8},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3529-3541},
  shortjournal = {Soft Comput.},
  title        = {An uncertain two-echelon fixed charge transportation problem},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hyperparameter tuning in convolutional neural networks for
domain adaptation in sentiment classification (HTCNN-DASC).
<em>SOCO</em>, <em>24</em>(5), 3511–3527. (<a
href="https://doi.org/10.1007/s00500-019-04117-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In-domain adaptation (DA), the knowledge trained in one domain, is used to test an unknown domain. Existing approaches use limited efforts on DA in sentiment classification (SC) using neural networks. The challenging task here is the dissimilarity in the semantic behavior across domains. In this paper, convolutional neural networks (CNNs) learn the knowledge of a particular domain using Doc2Vec feature representation which provides good performance for DA in SC for the target domain. Our empirical analysis with one-layer CNN exhibits significant change in the accuracy by tuning the hyperparameters involved with the CNN. This paper derives into a suitable CNN architecture accompanying hyperparameters which favor DA between different domains. Our empirical analysis with multi-domain dataset demonstrates that with suitable hyperparameters, CNN works well for DASC problems. The comparative study shows that CNN with Doc2Vec model provides a strong capability of learning large data representation semantically with other state-of-the-art methods for the DASC.},
  archive      = {J_SOCO},
  author       = {Krishnakumari, K. and Sivasankar, E. and Radhakrishnan, Sam},
  doi          = {10.1007/s00500-019-04117-w},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3511-3527},
  shortjournal = {Soft Comput.},
  title        = {Hyperparameter tuning in convolutional neural networks for domain adaptation in sentiment classification (HTCNN-DASC)},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Semi-supervised data clustering using particle swarm
optimisation. <em>SOCO</em>, <em>24</em>(5), 3499–3510. (<a
href="https://doi.org/10.1007/s00500-019-04114-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we propose the semi-supervised particle swarm optimisation (ssPSO) algorithm for data clustering. The algorithm takes advantage of the strengths of semi-supervised fuzzy c-means (ssFCM) and particle swarm optimisation (PSO) to allow for a more informed search using labelled data across small number of iterations while maintaining diversity in the search process. ssFCM algorithms can find meaningful clusters using available labelled data to guide the learning process. PSOs are often chosen to solve clustering problems due to their versatility in problem representation and exploration capabilities. To verify the goodness of ssPSOs and provide practical insights to researchers, the clustering performances and clustering behaviours of ssPSOs are investigated and compared with PSO variants and ssFCMs. Two approaches of ssPSO were studied, one applied at initialisation only and the other throughout the learning process. Evaluated based on accuracy and quantisation error (QE), the ssPSO, PSOs and ssFCM algorithms were tested on 13 UCI datasets with different sizes, dimensions, number of classes and distribution, exploring several swarm size and maximum iteration settings over 100 runs. Visual examination of biplots and convergence graphs was conducted. ssPSOs were found to perform competitively well with ssFCM in most datasets in terms of accuracy and outperform ssFCM in terms of QE using swarm size 20 and maximum iteration 20. The results demonstrate that ssPSOs perform particularly well in sparsely distributed datasets with overlapping clusters and produce clusters with better structures in terms of QE. Furthermore, ssPSOs were demonstrated to perform competitively well as ssFCM in datasets with more than three clusters, while QPSO performed poorly in such datasets.},
  archive      = {J_SOCO},
  author       = {Lai, Daphne T. C. and Miyakawa, Minami and Sato, Yuji},
  doi          = {10.1007/s00500-019-04114-z},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3499-3510},
  shortjournal = {Soft Comput.},
  title        = {Semi-supervised data clustering using particle swarm optimisation},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Opinion spam detection framework using hybrid classification
scheme. <em>SOCO</em>, <em>24</em>(5), 3475–3498. (<a
href="https://doi.org/10.1007/s00500-019-04107-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of social networking sites, opinion-mining applications have attracted the interest of the online community on review sites to know about products for their purchase decisions. However, due to increasing trend of posting spam (fake) reviews to promote the target products or defame the specific brands of competitors, Opinion Spam detection and classification has emerged as a hot issue in the community of opinion mining and sentiment analysis. We investigate the issue of Opinion Spam detection by using different combinations of entities, features, and their sentiment scores. We enrich the feature set of a baseline Spam detection method with Spam detection features (Opinion Spam, Opinion Spammer, Item Spam). Using a dataset of reviews from the Amazon site and sentences labeled for Spam detection, we evaluate the role of spamicity-related features in detecting and classifying spam (fake) clues and distinguishing them from genuine reviews. For this purpose, we introduce a rule-based feature weighting scheme and propose a method for tagging the review sentence as spam and non-spam. Experiments results depict that spam-related features improve Spam detection in review sentences posted on product review sites. Adding a revised feature weighting scheme achieved an accuracy increase from 93 to 96\%. Furthermore, a hybrid set of features are shown to improve the performance of Opinion Spam detection in terms of better precision, recall, and F-measure values. This work shows that combining spam-related features with rule-based weighting scheme can improve the performance of even baseline Spam detection method. This improvement can be of use to Opinion Spam detection systems, due to the growing interest of individuals and companies in isolating fake (spam) and genuine (non-spam) reviews about products. The outcome of this work will provide an insight into spam-related features and feature weighting and will assist in developing more advanced applications for Opinion Spam detection. In the field of Opinion Spam detection, previous state-of-the-art studies used less number of spamicity-related features and less efficient feature weighting scheme. However, we provided a revised feature selection and a revised feature weighting scheme with normalized spamicity score computation technique. Therefore, our contribution is novel to the field because it provides a significant improvement over the comparing methods.},
  archive      = {J_SOCO},
  author       = {Asghar, Muhammad Zubair and Ullah, Asmat and Ahmad, Shakeel and Khan, Aurangzeb},
  doi          = {10.1007/s00500-019-04107-y},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3475-3498},
  shortjournal = {Soft Comput.},
  title        = {Opinion spam detection framework using hybrid classification scheme},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Applying hybrid genetic–PSO technique for tuning an adaptive
PID controller used in a chemical process. <em>SOCO</em>,
<em>24</em>(5), 3455–3474. (<a
href="https://doi.org/10.1007/s00500-019-04106-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The conventional PID controller has static parameters that cannot be changed at different operating conditions. As a result, the term ‘adaptive PID controller’ has appeared to solve this problem. This controller can be tuned using intelligent techniques such as Fuzzy Logic Control, Neural Network Control, or Adaptive Neuro-Fuzzy Inference Systems. However, the choice of the suitable parameters for these intelligent controllers has a direct effect on their performance. Metaheuristics algorithms—with their powerful performance, speed, and optimal parameter selection—can be applied for choosing controller parameters efficiently. In this paper, a hybrid of genetic algorithm and particle swarm optimization is proposed to tune the parameters of different adaptive PID controllers. To evaluate the performance of the proposed hybrid optimization method on the different adaptive PID controllers, these controllers are applied to control the operation of one of the most difficult chemical processes, the divided wall distillation column. The proposed column used in this work separates a ternary mixture of ethanol, propanol, and n-butanol. Our proposed hybrid optimization technique is compared with the genetic algorithm, and simulation results show that our proposed hybrid genetic-particle swarm technique outperforms genetic algorithm for different disturbances.},
  archive      = {J_SOCO},
  author       = {El-Gendy, Eman M. and Saafan, Mahmoud M. and Elksas, Mohamed S. and Saraya, Sabry F. and Areed, Fayez F. G.},
  doi          = {10.1007/s00500-019-04106-z},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3455-3474},
  shortjournal = {Soft Comput.},
  title        = {Applying hybrid genetic–PSO technique for tuning an adaptive PID controller used in a chemical process},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-criteria group decision making based on ELECTRE i
method in pythagorean fuzzy information. <em>SOCO</em>, <em>24</em>(5),
3425–3453. (<a
href="https://doi.org/10.1007/s00500-019-04105-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {ELECTRE is a family of multi-criteria decision analysis techniques which has the ability to provide as much as possible precise and suitable set of actions or alternatives to the underlying problem by eliminating the alternatives which are outranked by others. Group decision making is an effective process to provide the most appropriate solution to real-world decision-making scenarios by considering and merging the expert opinions of multiple individuals on problem. The purpose of this research study is to extend the ELECTRE I method to Pythagorean fuzzy ELECTRE I (PF-ELECTRE I) method in group decision-making environment, as Pythagorean fuzzy set model is more superior tool to capture vagueness and incompleteness in human evaluations. The developed method has ability to solve multi-criteria group decision-making problems in which the assessment information on available alternatives, provided by the experts, is presented as Pythagorean fuzzy decision matrices having each entry characterized by Pythagorean fuzzy number (PFN). The approach is formulated by introducing the concepts of strong, midrange and weak Pythagorean fuzzy concordance and discordance sets to elaborate the outranking relation among alternatives with respect to conflicting criteria. Framework of group decision supporting system based on PF-ELECTRE I is demonstrated by a flowchart. Finally, two illustrative examples in the field of health safety and environment management are given to verify and demonstrate the applicability of our proposed approach.},
  archive      = {J_SOCO},
  author       = {Akram, Muhammad and Ilyas, Farwa and Garg, Harish},
  doi          = {10.1007/s00500-019-04105-0},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3425-3453},
  shortjournal = {Soft Comput.},
  title        = {Multi-criteria group decision making based on ELECTRE i method in pythagorean fuzzy information},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Use of choquet integrals in multivalued contexts.
<em>SOCO</em>, <em>24</em>(5), 3413–3423. (<a
href="https://doi.org/10.1007/s00500-019-04104-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, multivalued contexts are studied, in which the different observations are related to each other. Continuing the studies already carried out in previous works, the use of Choquet integrals can be an adequate tool for this situations. If in addition the set of objects or attributes of these contexts represent a temporal sequence, we can also represent these contexts as sequences of contexts that evolve in time and we can use tools in this field to extract information. Finally, as illustrative application, the developed theory is used to measure student progress in learning.},
  archive      = {J_SOCO},
  author       = {Alcalde, Cristina and Burusco, Ana},
  doi          = {10.1007/s00500-019-04104-1},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3413-3423},
  shortjournal = {Soft Comput.},
  title        = {Use of choquet integrals in multivalued contexts},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Shear strength prediction of reinforced concrete beams by
baseline, ensemble, and hybrid machine learning models. <em>SOCO</em>,
<em>24</em>(5), 3393–3411. (<a
href="https://doi.org/10.1007/s00500-019-04103-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The shear strength of reinforced concrete (RC) beams is critical in the design of structural members. Developing an effective mathematical method for accurately estimating shear strength of RC beams is beneficial for civil engineers. This work presents a hybrid artificial intelligent (AI) model for effectively predicting the shear strength of various types of RC beam. The hybrid AI model was developed by integrating an optimization algorithm [smart firefly algorithm (SFA)] and machine learning [least squares support vector regression (LSSVR)], in which the SFA was used to optimize the hyperparameters of LSSVR, improving its predictive accuracy. Three large datasets were used to train and test the hybrid AI model in predicting shear strength of RC beams. The predictive accuracy of the hybrid AI model was compared comprehensively with those of single AI models, ensemble AI models, and empirical methods. The comparison results show that the hybrid AI model outperformed the others in predicting the shear strength of a wide range of RC beam types. In particular, with the test data of RC beams without stirrups, the hybrid AI model yielded a mean absolute percentage error (MAPE) of 21.703\%. In predicting shear strength of RC beams with stirrups, the hybrid AI model yielded an MAPE of 12.941\%. For RC beams with FRP reinforcement, the hybrid AI model yielded an MAPE 18.951\%. Therefore, this hybrid AI model can be a better alternative method to help civil engineers in designing RC beams.},
  archive      = {J_SOCO},
  author       = {Chou, Jui-Sheng and Pham, Thi-Phuong-Trang and Nguyen, Thi-Kha and Pham, Anh-Duc and Ngo, Ngoc-Tri},
  doi          = {10.1007/s00500-019-04103-2},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3393-3411},
  shortjournal = {Soft Comput.},
  title        = {Shear strength prediction of reinforced concrete beams by baseline, ensemble, and hybrid machine learning models},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Analysis of microchannel resistance factor based on
automated simulation framework and BP neural network. <em>SOCO</em>,
<em>24</em>(5), 3379–3391. (<a
href="https://doi.org/10.1007/s00500-019-04101-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, self-design automated simulation and artificial neural network (ANN) model were developed to analyze and estimate the resistance factor in rectangle cross-section microchannels. The main purpose is to obtain a universal solution method through numerical simulation which can solve the resistance factor problem for invariant cross-section microchannels. Through Python language, the automatic coalescent of preprocessing Gambit, computing software CFD and post-processing Tecplot make the simulation framework realize the automatic acquisition of microchannel resistance factor samples. Then, 100 simulation samples with different aspect ratios for Reynolds numbers ranging from 50 to 500 were obtained. After validation, the width and height of microchannels were applied as input data set of the ANN model, and the resistance factor was determined as the target data. In order to improve BP algorithm for training ANN, a new swarm evolution algorithm was realized by combining the strong point of gradient descent method, genetic algorithm and particle swarm optimization, which is called particle swarm evolution algorithm. Finally, the result of resistance factor model was established and verified by several existing measurement value of pressure drop from remarkable experimental.},
  archive      = {J_SOCO},
  author       = {Shen, Teng and Chang, Jiaqing and Xie, Jinlong and Huang, Liu},
  doi          = {10.1007/s00500-019-04101-4},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3379-3391},
  shortjournal = {Soft Comput.},
  title        = {Analysis of microchannel resistance factor based on automated simulation framework and BP neural network},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimizing the trade-off between performance measures and
operational risk in a food supply chain environment. <em>SOCO</em>,
<em>24</em>(5), 3365–3378. (<a
href="https://doi.org/10.1007/s00500-019-04099-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of a growing world population and the need to use limited resources responsibly, this study is motivated by the increasing pressures on the food industry, which include issues of food security, safety, and waste. In the context of a global food supply chain, we combine processing time and cost (PT&amp;C) with operational risk (ORk) in a novel integrated approach to designing and optimizing monitoring systems. This study of a flagship product widely consumed around the world provides quantitative analysis and results based on real-world data from an international food company. The findings indicate that our multi-objective methodology provides quantitative insights into—and is capable of quantifying—an unexpected nonlinear relationship between PT&amp;C and ORk. We show numerically how to decrease PT&amp;C significantly by means of a minor increase in ORk, an outcome which is highly appealing for the industry. In addition, we provide accurate measurements of the impact of each individual monitoring activity, which allows the identification of the monitoring activities that are most critical. Generalizable insights for practitioners are derived from a step-by-step optimization of the entire monitoring system.},
  archive      = {J_SOCO},
  author       = {Voldrich, Simone and Wieser, Philippe and Zufferey, Nicolas},
  doi          = {10.1007/s00500-019-04099-9},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3365-3378},
  shortjournal = {Soft Comput.},
  title        = {Optimizing the trade-off between performance measures and operational risk in a food supply chain environment},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Two-dimensional perceptrons. <em>SOCO</em>, <em>24</em>(5),
3355–3364. (<a
href="https://doi.org/10.1007/s00500-019-04098-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) have made remarkable success in image classification. However, it is still an open problem how to develop new models instead of CNNs. Here, we propose a novel model, namely two-dimensional perceptron (TDP), to get direct input of 2D data for further processing. A TDP computes hidden neurons from the input via left/right matrix multiplication, producing left-weighted TDP and right-weighted TDP, respectively. Experimental results on MNIST and COIL-20 datasets show that, in cases with the same number of hidden neurons, the model obtains 5\%–45\% relative performance improvement and 2 ×–36× speedup in comparison with the corresponding multilayer perceptron and convolutional neural network. Hence, it is a promising and potential model that may open some new directions for deep neural networks, particularly alternatives to CNNs.},
  archive      = {J_SOCO},
  author       = {Ou, Jun and Li, Yujian and Shan, Chuanhui},
  doi          = {10.1007/s00500-019-04098-w},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3355-3364},
  shortjournal = {Soft Comput.},
  title        = {Two-dimensional perceptrons},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). New work of trapezoidal cubic linguistic uncertain fuzzy
einstein hybrid weighted averaging operator and decision making.
<em>SOCO</em>, <em>24</em>(5), 3331–3354. (<a
href="https://doi.org/10.1007/s00500-019-04096-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we define some Einstein operations on trapezoidal cubic linguistic uncertain fuzzy numbers and develop two arithmetic averaging operators, that is, trapezoidal cubic linguistic uncertain fuzzy Einstein weighted averaging operator and trapezoidal cubic linguistic uncertain fuzzy Einstein hybrid weighted averaging (TrCLUFEHWA) operator, for aggregating trapezoidal cubic linguistic uncertain fuzzy information. Furthermore, we establish various properties of these operators and derive the relationship between the proposed operators and the exiting aggregation operators. We apply the TrCLUFEHWA operator to multiple-attribute decision making with trapezoidal cubic linguistic uncertain fuzzy information. Finally, a numerical example is provided to demonstrate the submission of the established approach.},
  archive      = {J_SOCO},
  author       = {Aslam, Muhammad and Fahmi, Aliya},
  doi          = {10.1007/s00500-019-04096-y},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3331-3354},
  shortjournal = {Soft Comput.},
  title        = {New work of trapezoidal cubic linguistic uncertain fuzzy einstein hybrid weighted averaging operator and decision making},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Parameter estimation of regression model with AR(p) error
terms based on skew distributions with EM algorithm. <em>SOCO</em>,
<em>24</em>(5), 3309–3330. (<a
href="https://doi.org/10.1007/s00500-019-04089-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the linear regression model, the errors are usually assumed to be uncorrelated. However, in real-life data, this assumption is not often plausible. In this study, first, we will assume that the errors of the regression model have autoregressive structure. This type of regression models has been considered before. However, in those papers under this assumption usually, the symmetric distributions are used as error distribution. The main contribution of this work is to use skew distributions instead of symmetric distributions as error distribution in regression models with autoregressive errors. We provide expectation maximization algorithm to compute the maximum likelihood estimates for the parameters. The performances of the proposed estimators are demonstrated with a simulation study and a real data example. We also provide the confidence intervals using the observed Fisher information matrix for the corresponding estimators.},
  archive      = {J_SOCO},
  author       = {Tuaç, Y. and Güney, Y. and Arslan, O.},
  doi          = {10.1007/s00500-019-04089-x},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3309-3330},
  shortjournal = {Soft Comput.},
  title        = {Parameter estimation of regression model with AR(p) error terms based on skew distributions with EM algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sequence- and structure-based prediction of amyloidogenic
regions in proteins. <em>SOCO</em>, <em>24</em>(5), 3285–3308. (<a
href="https://doi.org/10.1007/s00500-019-04087-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning methods are increasingly used in proteomics research, especially in analyzing and predicting protein structures, functions, subcellular localizations and interactions. However, much research in recent years has focused on protein misfolding problem and the impact of unfolded and defective proteins on cell dysfunction, due to its considerable importance for molecular medicine. These abnormal proteins degradation and deposition often result in the formation of certain plaque cores among them the so-called amyloid fibrils which are responsible for an increasing number of highly debilitating disorders in humans. Yet, a significant challenge remains, especially in understanding the underlying causes and major risk factors of these harmful deposits in vital organs and tissues. This paper explores the potential of string kernel-based support vector machines in the prediction of amyloidogenic regions in proteins by incorporating the most informative features of the protein sequence such as predicted secondary structure and solvent accessibility, with a special focus on $$\alpha $$-helical conformations which seem to be primarily concerned with amyloidogenesis. The performances compared with the most popular methods on Pep424 and Reg33 benchmark datasets indicate the robustness of the predictive model. Furthermore, the results showed accurate prediction of regions promoting fibrillogenesis for experimentally determined amyloid proteins and revealed that the five amino acids Leucine, Glycine, Alanine, Valine and Serine are predominantly present in amyloid-prone regions and confirm that the core regions of an amyloid aggregate are not necessarily fully buried.},
  archive      = {J_SOCO},
  author       = {Bouziane, Hafida and Chouarfia, Abdallah},
  doi          = {10.1007/s00500-019-04087-z},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3285-3308},
  shortjournal = {Soft Comput.},
  title        = {Sequence- and structure-based prediction of amyloidogenic regions in proteins},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Finite-time stability for uncertain differential equations:
A first investigation on a new class of multi-agent systems.
<em>SOCO</em>, <em>24</em>(5), 3275–3284. (<a
href="https://doi.org/10.1007/s00500-019-04086-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we discuss a new kind of stability, that is, finite-time stability, for uncertain differential equations, by formalizing some properties. As a possible application, we define a new class of uncertain multi-agent systems, according to the Liu’s uncertainty theory, as a counterpart of stochastic multi-agent systems. We formalize the governing equations, driven by canonical process, which is a type of uncertain process with stationary and independent increments. The concept of finite-time consensus in the context of uncertainty theory is consequently derived. A numerical procedure to estimate the settling time is proposed. The case with proportional delay was also considered.},
  archive      = {J_SOCO},
  author       = {Tomasiello, S. and Marín Mejía, S. and Gossili, N.},
  doi          = {10.1007/s00500-019-04086-0},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3275-3284},
  shortjournal = {Soft Comput.},
  title        = {Finite-time stability for uncertain differential equations: A first investigation on a new class of multi-agent systems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Generating trading rules on US stock market using strongly
typed genetic programming. <em>SOCO</em>, <em>24</em>(5), 3257–3274. (<a
href="https://doi.org/10.1007/s00500-019-04085-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracting rules from stock market data is an important and exciting problem, where investment decisions should be as clear and intuitive as possible in order for investors to choose the composition of their portfolios. Thus, it is important to guarantee that this process is done with a good framework and reliable techniques. In this context, portfolio composition is a puzzle with respect to selecting the appropriate assets and the optimal timing to invest. There are several models and algorithms to make these decisions, and in recent years, machine learning applications have been used to solve this puzzle with exceptional results. This technique allows a large amount of data to be processed, resulting in more informed recommendations on which asset to choose. Our study uses strongly typed genetic programming to generate rules to buy, hold and sell stocks in the US stock market, considering a rolling windows approach. We propose a different training approach, focusing the fitness function on a ternary decision based on the return prediction of each stock analyzed. The ternary rule matches perfectly with the three decisions: buy, hold and sell. Therefore, the rules are simple, intuitive, and easy for investors to understand. The results show that the proposed algorithm generates higher profits than the classical optimization approach. Moreover, the profits obtained are higher than the buy-and-hold strategy and the return of the indexes representative of the US stock market.},
  archive      = {J_SOCO},
  author       = {Michell, Kevin and Kristjanpoller, Werner},
  doi          = {10.1007/s00500-019-04085-1},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3257-3274},
  shortjournal = {Soft Comput.},
  title        = {Generating trading rules on US stock market using strongly typed genetic programming},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hospital service quality evaluation: An integrated model
based on pythagorean fuzzy AHP and fuzzy TOPSIS. <em>SOCO</em>,
<em>24</em>(5), 3237–3255. (<a
href="https://doi.org/10.1007/s00500-019-04084-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Providing better hospital service quality is one of the major concerns of healthcare industry in the world. Since health services in Turkey are provided in a very competitive environment, for making a better choice, the services delivered by the public and private hospitals should be evaluated according to the viewpoint of stakeholders in terms of satisfaction. In this study, a model proposal is presented based on the concept of Pythagorean fuzzy analytic hierarchy process and Pythagorean fuzzy technique for order preference by similarity to ideal solution method to provide an accurate decision-making process for evaluating the hospital service quality. We study under fuzzy environment to reduce uncertainty and vagueness, and use linguistic variables parameterized by Pythagorean fuzzy numbers. The proposed approach is separated from others with the integration of the methods in a way providing a systematic fuzzy decision-making process. A case study including 32 service quality criteria and two public and one private hospitals in Turkey assessed by 32 evaluators by medical staff, hospital executives, auxiliaries, and patients is performed to demonstrate the applicability and validity of the proposed approach. On conclusion, integrated model produces reliable and suggestive outcomes better representing the vagueness of decision-making process.},
  archive      = {J_SOCO},
  author       = {Yucesan, Melih and Gul, Muhammet},
  doi          = {10.1007/s00500-019-04084-2},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3237-3255},
  shortjournal = {Soft Comput.},
  title        = {Hospital service quality evaluation: An integrated model based on pythagorean fuzzy AHP and fuzzy TOPSIS},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A robust fuzzy control approach for path-following control
of autonomous vehicles. <em>SOCO</em>, <em>24</em>(5), 3223–3235. (<a
href="https://doi.org/10.1007/s00500-019-04082-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a robust fuzzy control approach for the lateral path-following of autonomous road vehicles (ARVs). The dynamics of the ARV is estimated online thorough a new non-singleton fuzzy system based on the non-stationary fuzzy sets. The asymptotic stability of the proposed method is ensured, and the adaptation laws for the proposed fuzzy system are derived based on the Lyapunov stability theorem. The robustness of the proposed control method is verified for a vehicle system performing a double-lane-change maneuver at different forward speeds subjected to structured and unmodeled uncertainties and different disturbances. The effectiveness of the proposed approach is further investigated under different measurement noise levels. Based on the obtained results, it is concluded that the proposed control strategy can be effectively applied to the path-following task of ARVs under a wide range of operating conditions and external disturbances.},
  archive      = {J_SOCO},
  author       = {Mohammadzadeh, Ardashir and Taghavifar, Hamid},
  doi          = {10.1007/s00500-019-04082-4},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3223-3235},
  shortjournal = {Soft Comput.},
  title        = {A robust fuzzy control approach for path-following control of autonomous vehicles},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dual-information-based evolution and dual-selection strategy
in evolutionary multiobjective optimization. <em>SOCO</em>,
<em>24</em>(5), 3193–3221. (<a
href="https://doi.org/10.1007/s00500-019-04081-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiobjective evolutionary algorithm based on decomposition (MOEA/D) decomposes a multiobjective optimization problem into a number of scalar optimization subproblems and optimizes them simultaneously in a collaborative manner in one run. The recently proposed stable matching (STM)-based selection is a variant of MOEA/D that achieves one-to-one STM between subproblems and solutions on the basis of mutual preferences. However, the STM has a high probability of matching a good convergence solution with a subproblem, which results in an imbalance between convergence and diversity of selection result. In this study, we propose a new variant of MOEA/D with dual-information and dual-selection (DS) strategy (MOEA/D-DIDS). Different from other evolutionary operations, we use an adaptive historical and neighboring information in generating new individuals to avoid local optima and accelerate convergence rate. In the selection operation, we use the adaptive limited STM ($$ \beta {\text{LSTM}} $$) strategy, where parameter β is adaptive in accordance with the evolutionary process, as a guideline to select a population from the mixed population that survives as the next parent population. In addition to $$ \beta {\text{LSTM}} $$, we use an STM to select competitive individuals as the members of the next mixed population. This DS strategy not only balances convergence and diversity but also holds the elite solutions. The effectiveness and competitiveness of MOEA/D-DIDS are validated and compared with several state-of-the-art evolutionary multiobjective optimization algorithms on benchmark problems.},
  archive      = {J_SOCO},
  author       = {Yang, Yu and Huang, Min and Wang, Zhen-Yu and Zhu, Qi-Bing},
  doi          = {10.1007/s00500-019-04081-5},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3193-3221},
  shortjournal = {Soft Comput.},
  title        = {Dual-information-based evolution and dual-selection strategy in evolutionary multiobjective optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Topological residuated lattices. <em>SOCO</em>,
<em>24</em>(5), 3179–3192. (<a
href="https://doi.org/10.1007/s00500-020-04709-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The notion of a (semi)topological residuated lattice is introduced, and its properties are investigated. Some separation axioms on topological residuated lattices are studied. The notion of completion of a residuated lattice is introduced and characterized by means of the inverse limit of an inverse system. A residuated lattice with a given system of filters is illustrated with the linear topology, and it is shown that a compact and Hausdorff residuated lattice with the linear topology is complete.},
  archive      = {J_SOCO},
  author       = {Rasouli, Saeed and Dehghani, Amin},
  doi          = {10.1007/s00500-020-04709-x},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3179-3192},
  shortjournal = {Soft Comput.},
  title        = {Topological residuated lattices},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Filter topologies on MV-algebras II. <em>SOCO</em>,
<em>24</em>(5), 3173–3177. (<a
href="https://doi.org/10.1007/s00500-020-04682-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show in this paper that the filter topology on an MV-chain is precisely the order topology when the filter is non-principal and has an infimum in the MV-chain. Then, we show that for an arbitrary MV-algebra A which is complete, the canonical monomorphism h of A into its subdirect product must be a continuous mapping. As a result, we give a sufficient condition for a complete MV-algebra equipped with the filter topology to be Hausdorff.},
  archive      = {J_SOCO},
  author       = {Wu, Sifan and Luan, Wei and Yang, Yichuan},
  doi          = {10.1007/s00500-020-04682-5},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3173-3177},
  shortjournal = {Soft Comput.},
  title        = {Filter topologies on MV-algebras II},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Generalized trapezoidal cubic linguistic fuzzy ordered
weighted average operator and group decision-making. <em>SOCO</em>,
<em>24</em>(5), 3155–3171. (<a
href="https://doi.org/10.1007/s00500-020-04672-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we define aggregation operators for trapezoidal cubic linguistic fuzzy sets which includes generalized cubic linguistic fuzzy averaging (geometric) operator, generalized trapezoidal cubic linguistic fuzzy weighted averaging (GTrCLFWA) operator, generalized trapezoidal cubic linguistic fuzzy weighted geometric (GTrCFWG) operator, generalized trapezoidal cubic linguistic fuzzy ordered weighted average (GTrCLFOWA) operator, generalized trapezoidal cubic linguistic fuzzy ordered weighted geometric (GTrCLFOWG) operator, generalized trapezoidal cubic linguistic fuzzy hybrid averaging (GTrCLFHA) operator and generalized trapezoidal cubic linguistic fuzzy hybrid geometric (GTrCLFHG) operator. Furthermore, we relate these aggregation operators to develop an approach to multiple attribute group decision-making with trapezoidal cubic linguistic fuzzy information. Finally, a numerical example is providing to demonstrate the submission of the established approach.},
  archive      = {J_SOCO},
  author       = {Abdullah, Saleem and Fahmi, Aliya and Aslam, Muhammad},
  doi          = {10.1007/s00500-020-04672-7},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3155-3171},
  shortjournal = {Soft Comput.},
  title        = {Generalized trapezoidal cubic linguistic fuzzy ordered weighted average operator and group decision-making},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Ant colony systems optimization applied to BNF grammars rule
derivation (ACORD algorithm). <em>SOCO</em>, <em>24</em>(5), 3141–3154.
(<a href="https://doi.org/10.1007/s00500-020-04670-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ant colony systems have been widely employed in optimization issues primarily focused on path finding optimization, such as travelling salesman problem. The main advantage lies in the choice of the edge to be explored, defined using pheromone trails. This paper proposes the use of ant colony systems to explore a Backus–Naur form grammar whose elements are solutions to a given problem. Similar models, without using ant colonies, have been used to solve optimization problems or to automatically generate programs such as grammatical swarm (based on particle swarm optimization) and grammatical evolution (based on genetic algorithms). This work presents the application of proposed ant colony rule derivation algorithm and benchmarks this novel approach in a well-known deceptive problem, the Santa Fe Trail. Proposed algorithm opens the way to a new branch of research in swarm intelligence, which until now has been almost nonexistent, using ant colony algorithms to generate solutions of a given problem described by a BNF grammar with the advantage of genotype/phenotype mapping, described in grammatical evolution. In this case, such mapping is performed based on the pheromone concentration for each production rule. The experimental results demonstrate proposed algorithm outperforms grammatical evolution algorithm in the Santa Fe Trail problem with higher success rates and better solutions in terms of the required steps.},
  archive      = {J_SOCO},
  author       = {de Mingo López, Luis Fernando and Gómez Blas, Nuria and Morales Lucas, Clemencio},
  doi          = {10.1007/s00500-020-04670-9},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3141-3154},
  shortjournal = {Soft Comput.},
  title        = {Ant colony systems optimization applied to BNF grammars rule derivation (ACORD algorithm)},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An interactive nonparametric evidential regression algorithm
with instance selection. <em>SOCO</em>, <em>24</em>(5), 3125–3140. (<a
href="https://doi.org/10.1007/s00500-020-04667-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The nonparametric evidential regression (EVREG) method provides flexible forms of prediction regarding the value of output, allowing the output of training instances to be partially unknown. However, the superfluous training instances still have negative effects on the parameter learning in EVREG. To relax this limitation, this paper introduces an interactive nonparametric evidential regression (IEVREG) algorithm with instance selection. More specifically, the significance of an instance is firstly measured by defining the evaluation functions, taking into account both the prediction accuracy of regression model and the spatial information between that instance with other ones. According to a search strategy, the instances with high degree of significance are then selected to maximize an objective function. Different from existing instance selection methods, the selection of training instances is synchronously accomplished with the parameter learning in IEVREG, rather than just a separated data preprocessing operation as traditional methods do. Furthermore, the noise and redundant instances can be simultaneously removed and the performance of IEVREG is robust to the order of presentation of instances in raw data set. Experimental results show that the proposed IEVREG algorithm has appropriate prediction accuracy, while performing well selection of the representative training instances from the raw data set. Simulations on synthetic and UCI real-world data sets validate our conclusions.},
  archive      = {J_SOCO},
  author       = {Gong, Chaoyu and Wang, Pei-hong and Su, Zhi-gang},
  doi          = {10.1007/s00500-020-04667-4},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3125-3140},
  shortjournal = {Soft Comput.},
  title        = {An interactive nonparametric evidential regression algorithm with instance selection},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). On interval-valued fuzzy soft set theory applied to
semigroups. <em>SOCO</em>, <em>24</em>(5), 3113–3123. (<a
href="https://doi.org/10.1007/s00500-019-04655-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we focus on combining the theories of interval-valued fuzzy soft sets over semigroups, and establishing a new framework for interval-valued fuzzy soft semigroups. The aim of this manuscript is to apply interval-valued fuzzy soft set for dealing with several kinds of theories in semigroups. First, we present the concepts of interval-valued fuzzy soft sets, interval-valued fuzzy soft semigroups, interval-valued fuzzy soft ideals, interval-valued fuzzy soft quasi-ideals, interval-valued fuzzy soft interior ideals and interval-valued fuzzy soft bi-ideals. Meanwhile, some illustrative examples are given to show the rationality of the definitions introduced in this paper. Also, we prove that a non-empty subset of a semigroup S is a subsemigroup (left ideal, right ideal, ideal) of S if and only if the interval-valued fuzzy soft set over S is the interval-valued fuzzy soft subsemigroup (interval-valued fuzzy soft left ideal, interval-valued fuzzy soft right ideal, interval-valued fuzzy soft ideal) over S. Second, several new kinds of generalized fuzzy soft sets over semigroups are proposed, and related properties and mutual relationships are also investigated. Moreover, we study relation between quasi-ideals and interval-valued fuzzy soft quasi-ideals over semigroups. Finally, we obtain necessary and sufficient conditions of an interval-valued fuzzy soft ideal in order to be an interval-valued fuzzy soft interior ideal.},
  archive      = {J_SOCO},
  author       = {Yiarayong, Pairote},
  doi          = {10.1007/s00500-019-04655-3},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3113-3123},
  shortjournal = {Soft Comput.},
  title        = {On interval-valued fuzzy soft set theory applied to semigroups},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). General l-fuzzy aggregation functions based on complete
residuated lattices. <em>SOCO</em>, <em>24</em>(5), 3087–3112. (<a
href="https://doi.org/10.1007/s00500-019-04642-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a vital tool in data analysis, aggregation functions have been widely studied in many papers. In particular, one of the recent research topics for aggregation functions is the study of the various extension forms of those useful functions. This paper continues to research this topic from the theoretical point of view. First, we introduce the notions of L-fuzzy aggregation functions and general L-fuzzy aggregation functions based on complete residuated lattices. Then we present the upper and lower general L-fuzzy aggregation approximation functions of the general L-fuzzy aggregation functions, which are the pointwise extension of an L-fuzzy aggregation function. Moreover, we consider some vital properties of those aggregation approximation functions and investigate the relationship between those aggregation approximation functions and the corresponding L-fuzzy relations. Finally, we show that the approach of axiomatizations of the upper and lower general L-fuzzy aggregation approximation functions ensures the existence of corresponding L-fuzzy relations which generate the functions.},
  archive      = {J_SOCO},
  author       = {Dan, Yexing and Hu, Bao Qing and Qiao, Junsheng},
  doi          = {10.1007/s00500-019-04642-8},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3087-3112},
  shortjournal = {Soft Comput.},
  title        = {General L-fuzzy aggregation functions based on complete residuated lattices},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). L-algebras in logic, algebra, geometry, and topology.
<em>SOCO</em>, <em>24</em>(5), 3077–3085. (<a
href="https://doi.org/10.1007/s00500-019-04616-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An intuitive introduction to L-algebras and their relationship to groups with a one- or two-sided lattice ordering is given, with applications in algebra, analysis, and geometry.},
  archive      = {J_SOCO},
  author       = {Rump, Wolfgang},
  doi          = {10.1007/s00500-019-04616-w},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3077-3085},
  shortjournal = {Soft Comput.},
  title        = {L-algebras in logic, algebra, geometry, and topology},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Category of soft lie algebra. <em>SOCO</em>, <em>24</em>(5),
3067–3076. (<a
href="https://doi.org/10.1007/s00500-019-04583-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we consider category $${\mathbf {LA}}({\mathbb {F}})$$ of all Lie algebras over a field $${\mathbb {F}}$$ and Lie algebra homomorphisms and obtain some basic results of this category, such as the existence of product, equalizer, coequalizer, and pullback. Then, we introduce a subcategory of the category of soft sets, whose objects are soft Lie algebras and morphisms are soft Lie algebra homomorphisms and study some properties. In particular, we show that this category does not have a product. Also, we characterize injective objects in category soft set and category of soft Lie algebras over $${\mathbb {F}}$$.},
  archive      = {J_SOCO},
  author       = {Estaji, Ali Akbar and Eghdami, Hossien and Haghdadi, Toktam},
  doi          = {10.1007/s00500-019-04583-2},
  journal      = {Soft Computing},
  number       = {5},
  pages        = {3067-3076},
  shortjournal = {Soft Comput.},
  title        = {Category of soft lie algebra},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-objective stochastic fractal search: A powerful
algorithm for solving complex multi-objective optimization problems.
<em>SOCO</em>, <em>24</em>(4), 3037–3066. (<a
href="https://doi.org/10.1007/s00500-019-04080-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic Fractal Search (SFS) is a novel and powerful metaheuristic algorithm. This paper presents a Multi-Objective Stochastic Fractal Search (MOSFS) for the first time, to solve complex multi-objective optimization problems. The presented algorithm uses an external archive to collect efficient Pareto optimal solutions during the optimization process. Using dominance rules, leader selection and grid mechanisms, MOSFS precisely approximates the true Pareto optimal front. The MOSFS is implemented on nine multi-objective benchmark functions (CEC 2009) with multimodal, convex, discrete and non-convex optimal Pareto fronts. Performance of the proposed algorithm is compared to well-known algorithms. In addition, different performance measures are considered to evaluate the convergence and coverage abilities of the algorithms including Inverted Generational Distance, Maximum Spread and Spacing. Furthermore, statistical analyses are utilized to determine the superior algorithm. The results revealed that the MOSFS performs significantly better than other algorithms in both convergence and coverage and it is able to approximate true Pareto front precisely. In the end, MOSFS is implemented to solve a real-world engineering design problem called welded beam design problem and efficiency of the algorithm is compared to recently developed algorithms. The results of simulations and the Wilcoxon rank-sum test showed that the MOSFS is able to provide the most promising Pareto front for the problem considering various performance metrics at a 95\% confidence level.},
  archive      = {J_SOCO},
  author       = {Khalilpourazari, Soheyl and Naderi, Bahman and Khalilpourazary, Saman},
  doi          = {10.1007/s00500-019-04080-6},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {3037-3066},
  shortjournal = {Soft Comput.},
  title        = {Multi-objective stochastic fractal search: A powerful algorithm for solving complex multi-objective optimization problems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fuzzy descriptive evaluation system: Real, complete and fair
evaluation of students. <em>SOCO</em>, <em>24</em>(4), 3025–3035. (<a
href="https://doi.org/10.1007/s00500-019-04078-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, descriptive evaluation has been introduced as a new model for educational evaluation of Iranian students. The current descriptive evaluation method is based on four-valued logic. Assessing all students with only four values is led to a lack of relative justice and creation of unrealistic equality. Also, the complexity of the evaluation process in the current method increases teacher error’s likelihood. As a suitable solution, in this paper, a fuzzy descriptive evaluation system has been proposed. The proposed method is based on fuzzy logic, which is an infinite-valued logic, and it can perform approximate reasoning on natural language propositions. By the proposed fuzzy system, student assessment is performed over the school year with infinite values instead of four values. In order to eliminate the diversity of assigned values to students, at the end of the school year, the calculated values for each student will be rounded to the nearest value of the four standard values of the current descriptive evaluation method. It can be implemented in an appropriate smartphone application, which makes it much easier for teachers to assess the educational process of students. In this paper, the evaluation process of the elementary third-grade mathematics course in Iran during the period from the beginning of the MEHR (the seventh month of Iran) to the end of BAHMAN (the eleventh month of Iran) is examined by the proposed system. To evaluate the validity of this system, the proposed method has been simulated in MATLAB software.},
  archive      = {J_SOCO},
  author       = {Annabestani, Mohsen and Rowhanimanesh, Alireza and Mizani, Aylar and Rezaei, Akram},
  doi          = {10.1007/s00500-019-04078-0},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {3025-3035},
  shortjournal = {Soft Comput.},
  title        = {Fuzzy descriptive evaluation system: Real, complete and fair evaluation of students},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-objective optimal power flow solutions using a
constraint handling technique of evolutionary algorithms. <em>SOCO</em>,
<em>24</em>(4), 2999–3023. (<a
href="https://doi.org/10.1007/s00500-019-04077-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In power systems, optimal power flow (OPF) is a complex and constrained optimization problem in which quite often multiple and conflicting objectives are required to be optimized. The traditional way of dealing with multi-objective OPF (MOOPF) is the weighted sum method which converts the multi-objective OPF into a single-objective problem and provides a single solution from the set of Pareto solutions. This paper presents MOOPF study applying multi-objective evolutionary algorithm based on decomposition (MOEA/D) where a set of non-dominated solutions (Pareto solutions) can be obtained in a single run of the algorithm. OPF is formulated with two or more objectives among fuel (generation) cost, emission, power loss and voltage deviation. The other important aspect in OPF problem is about satisfying power system constraints. As the search process adopted by evolutionary algorithms is unconstrained, for a constrained optimization problem like OPF, static penalty function approach has been extensively employed to discard infeasible solutions. This approach requires selection of a suitable penalty coefficient, largely done by trial-and-error, and an improper selection may often lead to violation of system constraints. In this paper, an effective constraint handling method, superiority of feasible solutions (SF), is used in conjunction with MOEA/D to handle network constraints in MOOPF study. The algorithm MOEA/D-SF is applied to standard IEEE 30-bus and IEEE 57-bus test systems. Simulation results are analyzed, especially for constraint violation and compared with recently reported results on OPF.},
  archive      = {J_SOCO},
  author       = {Biswas, Partha P. and Suganthan, P. N. and Mallipeddi, R. and Amaratunga, Gehan A. J.},
  doi          = {10.1007/s00500-019-04077-1},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2999-3023},
  shortjournal = {Soft Comput.},
  title        = {Multi-objective optimal power flow solutions using a constraint handling technique of evolutionary algorithms},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A minimum entropy deconvolution-enhanced convolutional
neural networks for fault diagnosis of axial piston pumps.
<em>SOCO</em>, <em>24</em>(4), 2983–2997. (<a
href="https://doi.org/10.1007/s00500-019-04076-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Condition monitoring of piston pumps has great significance to ensure the reliability and security of hydraulic systems. However, the complex working conditions of the integrated electromechanical systems make the fault mechanism unclear which is difficult for fault diagnosis by feature matching techniques. In this paper, a novel minimum entropy deconvolution (MED)-based convolutional neural network (CNN) is presented to classify faults in axial piston pumps. Firstly, the collected raw signals are preprocessed using the MED technique. Then, the filtered signals are used to construct training samples and testing samples. Finally, the constructed samples are fed into the CNN to classify the multi-faults of axial piston pumps. With the convolution and subsampling operations, the present model can automatically obtain data features via iterative learning processes, which is suitable for the unknown fault mechanism problems. The learned features are visualized by t-distributed stochastic neighbor embedding technique. A benchmark data simulation of mechanical transmission systems and an experimental data investigation of an axial piston pump are performed to manifest the superiority of the present method by comparing with the traditional CNN.},
  archive      = {J_SOCO},
  author       = {Wang, Shuhui and Xiang, Jiawei},
  doi          = {10.1007/s00500-019-04076-2},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2983-2997},
  shortjournal = {Soft Comput.},
  title        = {A minimum entropy deconvolution-enhanced convolutional neural networks for fault diagnosis of axial piston pumps},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Teaching–learning-based optimisation algorithm and its
application in capturing critical slip surface in slope stability
analysis. <em>SOCO</em>, <em>24</em>(4), 2969–2982. (<a
href="https://doi.org/10.1007/s00500-019-04075-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The identification of ideal values for algorithm-specific parameters required for the functioning of metaheuristic approaches at their optimum performance is a difficult task. This paper presents the application of a recently proposed teaching–learning-based optimisation (TLBO) algorithm to determine the lowest factor of safety (FS) along a critical slip surface for soil slope. TLBO is a nature-inspired search algorithm based on the teaching–learning phenomenon of a classroom. Four benchmark slopes are reanalysed to test the performance of the TLBO approach. The results indicate that the present technique can detect the critical failure surface and can be easily implemented by practitioners without fine-tuning the parameters that affect the convergence of results. Statistical analyses indicate a drastic decrease in uncertainty and the number of function evaluations in the estimation of the FS over previous approaches.},
  archive      = {J_SOCO},
  author       = {Mishra, Mayank and Gunturi, Venkata Ramana and Maity, Damodar},
  doi          = {10.1007/s00500-019-04075-3},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2969-2982},
  shortjournal = {Soft Comput.},
  title        = {Teaching–learning-based optimisation algorithm and its application in capturing critical slip surface in slope stability analysis},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dense adaptive cascade forest: A self-adaptive deep ensemble
for classification problems. <em>SOCO</em>, <em>24</em>(4), 2955–2968.
(<a href="https://doi.org/10.1007/s00500-019-04073-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent researches have shown that deep forest ensemble achieves a considerable increase in classification accuracy compared with the general ensemble learning methods, especially when the training set is small. In this paper, we take advantage of deep forest ensemble and introduce the dense adaptive cascade forest (daForest). Our model has a better performance than the original cascade forest with three major features: First, we apply SAMME.R boosting algorithm to improve the performance of the model. It guarantees the improvement as the number of layers increases. Second, our model connects each layer to the subsequent ones in a feed-forward fashion, which enhances the capability of the model to resist performance degeneration. Third, we add a hyper-parameter optimization layer before the first classification layer, making our model spend less time to set up and find the optimal hyper-parameters. Experimental results show that daForest performs significantly well and, in some cases, even outperforms neural networks and achieves state-of-the-art results.},
  archive      = {J_SOCO},
  author       = {Wang, Haiyang and Tang, Yong and Jia, Ziyang and Ye, Fei},
  doi          = {10.1007/s00500-019-04073-5},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2955-2968},
  shortjournal = {Soft Comput.},
  title        = {Dense adaptive cascade forest: A self-adaptive deep ensemble for classification problems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A multi-start ILS–RVND algorithm with adaptive solution
acceptance for the CVRP. <em>SOCO</em>, <em>24</em>(4), 2941–2953. (<a
href="https://doi.org/10.1007/s00500-019-04072-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a novel hybrid algorithm based on Iterated Local Search (ILS) and Random Variable Neighborhood Descent (RVND) metaheuristics for the purpose of solving the Capacitated Vehicle Routing Problem (CVRP). The main contribution of this work is that two new search rules have been developed for multi-starting and adaptive acceptance strategies, and applied together to enhance the power of the algorithm. A comprehensive experimental work has been conducted on two common CVRP benchmarks. Computational results demonstrate that both multi-start and adaptive acceptance strategies provide a significant improvement on the performance of pure ILS–RVND hybrid. Experimental work also shows that our algorithm is highly effective in solving CVRP and comparable with the state of the art.},
  archive      = {J_SOCO},
  author       = {Gokalp, Osman and Ugur, Aybars},
  doi          = {10.1007/s00500-019-04072-6},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2941-2953},
  shortjournal = {Soft Comput.},
  title        = {A multi-start ILS–RVND algorithm with adaptive solution acceptance for the CVRP},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Analysis of semi-asynchronous multi-objective evolutionary
algorithm with different asynchronies. <em>SOCO</em>, <em>24</em>(4),
2917–2939. (<a
href="https://doi.org/10.1007/s00500-019-04071-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel master–slave parallel evolutionary algorithm (EA) approach with different asynchrony and provides its detailed analyses on multi-objective optimization problems. We express the proposed EA with different asynchrony as a semi-asynchronous EA. A semi-asynchronous EA generates new solutions whenever evaluations of the predefined number of solutions complete, unlike a conventional synchronous EA waits for evaluations of all solutions to generate the next population. To establish a semi-asynchronous EA, this paper introduces an asynchrony parameter that is used to decide how many solutions are waited to generate new solutions. We conduct an experiment to verify the effectiveness of the proposed semi-asynchronous EA on benchmark problems with the several variances of the evaluation time. In the experiment, we apply a semi-asynchronous EA to NSGA-II and NSGA-III, which are well-known multi-objective EAs. The semi-asynchronous NSGA-IIs and the semi-asynchronous NSGA-IIIs with different asynchronies are compared on multi-objective optimization benchmark problems. The experimental result reveals that semi-asynchronous approaches with an appropriate asynchrony have possibility to outperform the asynchronous and the synchronous ones. Additionally, detailed analysis reveals that an appropriate asynchrony may vary not only depends on a target problem but also depends on the degree of the evolution process.},
  archive      = {J_SOCO},
  author       = {Harada, Tomohiro and Takadama, Keiki},
  doi          = {10.1007/s00500-019-04071-7},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2917-2939},
  shortjournal = {Soft Comput.},
  title        = {Analysis of semi-asynchronous multi-objective evolutionary algorithm with different asynchronies},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new framework for reliable control placement in
software-defined networks based on multi-criteria clustering approach.
<em>SOCO</em>, <em>24</em>(4), 2897–2916. (<a
href="https://doi.org/10.1007/s00500-019-04070-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In large-scale software-defined networks (SDNs), multiple controllers are deployed. Each controller has a logically centralized vision of the network that is used to manage a set of switches. In SDN, a challenge known as controller placement problem arises which is very important to specify the number of controllers that are needed and where they should be deployed. These specifications affect the performance of the network. Meanwhile, the assignment of switches to the controllers plays key role in the quality of solution in this problem. However, recent studies focus more on simply assigning switches to their closest controllers based on propagation delay between controller and switches. In this paper, a new controller placement framework is designed which considers both control plane architecture and relation between control and data planes. This framework is considered as a multi-objective optimization model with two objective functions to minimize the flow setup time and inter-controller latency. Furthermore, we propose a new model for flow setup time function that considers all affected metrics in the placement. To solve the framework, a multi-objective algorithm called non-dominated sorting moth flame controller placement optimizer is designed. To this end, we adapt the best–worst multi-criteria decision-making method considering three metrics, namely hop count, propagation latency and link utilization, to assign switches to controllers. A heuristic approach is also used to assign a path between switch and its controller using above three metrics and path reliability. We run theses three models iteratively to find the best location for controllers, the best switch assignment to controller and also find the best route in the network. We compare our proposed framework with other models using expected path loss and link load balancing metrics. Our performance evaluations on real wide area network topologies show the efficiency of the proposed framework.},
  archive      = {J_SOCO},
  author       = {Jalili, Ahmad and Keshtgari, Manijeh and Akbari, Reza},
  doi          = {10.1007/s00500-019-04070-8},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2897-2916},
  shortjournal = {Soft Comput.},
  title        = {A new framework for reliable control placement in software-defined networks based on multi-criteria clustering approach},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A spatial oligopolistic electricity model under uncertain
demands. <em>SOCO</em>, <em>24</em>(4), 2887–2895. (<a
href="https://doi.org/10.1007/s00500-019-04665-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper mainly investigates a single-period spatial oligopolistic model of electricity generators under uncertain demands. We maximize the $$\beta $$-optimistic value of each generator’s uncertain profit function in this game. Emphasis is first put on computing the $$\beta $$-optimistic value of the uncertain profit function through the inverse uncertainty distribution of the uncertain variable in the inverse demand function. We later focus on transforming the single-period spatial oligopolistic game, which is a generalized Nash equilibrium (short for GNE ) problem, into a variational inequality problem. Then the model is applied to simulate the transmission price of the electricity system of America, which reveals that our model is effective.},
  archive      = {J_SOCO},
  author       = {Chen, Qiqiong and Zhu, Yuanguo},
  doi          = {10.1007/s00500-019-04665-1},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2887-2895},
  shortjournal = {Soft Comput.},
  title        = {A spatial oligopolistic electricity model under uncertain demands},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Global well-posedness for the nonlinear damped wave equation
with logarithmic type nonlinearity. <em>SOCO</em>, <em>24</em>(4),
2873–2885. (<a
href="https://doi.org/10.1007/s00500-019-04660-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The initial boundary value problem for the nonlinear wave equations with damping and logarithmic nonlinearity is investigated in this paper. By making use of modified potential well theory and the technique of Logarithmic-Sobolev inequality, we establish global existence as well as asymptotic behavior of solution, under the assumption that the initial energy is small. Moreover, we obtain an exponential decay which is much faster than the decay in polynomial nonlinear case of Gazzola and Squassina (Ann I H Poincaré AN 23:185–207, 2006). These results generalize and extend work in application of potential well theory to wave equations.},
  archive      = {J_SOCO},
  author       = {Yang, Lu and Gao, Wei},
  doi          = {10.1007/s00500-019-04660-6},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2873-2885},
  shortjournal = {Soft Comput.},
  title        = {Global well-posedness for the nonlinear damped wave equation with logarithmic type nonlinearity},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Human performance modeling and its uncertainty factors
affecting decision making: A survery. <em>SOCO</em>, <em>24</em>(4),
2851–2871. (<a
href="https://doi.org/10.1007/s00500-019-04659-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces the background and connotation of human performance modeling (HPM), HPM models, and the application of artificial intelligence algorithms in HPM. It deeply analyzes the connotation and uncertainty of each model and finally puts forward its military application. The aim is to provide relevant researchers in the field with an in-depth understanding of domain knowledge and related uncertainties and to indicate future research directions. The first part is a general overview of human factors engineering, where the definition, origin, research field, importance, and general problems of HPM are elaborated. The composition of the man–machine system and its corresponding relationship with the observe–orient–decide–act loop are described. The second part reviews the models of perception, cognition, understanding, and decision making. Among them, models of cognition consist of visual search, visual sampling, mental workload, and goals, operators, methods, and selection rules; models of action consist of Hick–Hyman law, Fitts’s law, and manual control theory. The third part is a review of the source and importance of the integrated models and focuses on the principles, composition, and successful application cases of the three models, namely SAINT, IMPRINT, and ACT-R. The fourth part is a review of the application of the algorithms and models in the fields of artificial intelligence, deep learning, and data mining in analyzing multivariate datasets in HPM. In addition, future HPM military applications are presented.},
  archive      = {J_SOCO},
  author       = {Li, Ning and Huang, Jincai and Feng, Yanghe},
  doi          = {10.1007/s00500-019-04659-z},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2851-2871},
  shortjournal = {Soft Comput.},
  title        = {Human performance modeling and its uncertainty factors affecting decision making: A survery},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Correction to: A new uncertain DEA model and application to
scientific research personnel. <em>SOCO</em>, <em>24</em>(4), 2849. (<a
href="https://doi.org/10.1007/s00500-019-04615-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The article “A new uncertain DEA model and application to scientific research personnel”, written by Meilin Wen, Xue Yu and Fei Wang, was originally published electronically on the publisher’s Internet portal (currently SpringerLink) on 26 November 2019 with open access. With the author(s)’ decision to step back from Open Choice, the copyright of the article changed on 12 December 2019 to © Springer-Verlag GmbH Germany, part of Springer Nature 2019, and the article is forthwith distributed under the terms of copyright.},
  archive      = {J_SOCO},
  author       = {Wen, Meilin and Yu, Xue and Wang, Fei},
  doi          = {10.1007/s00500-019-04615-x},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2849},
  shortjournal = {Soft Comput.},
  title        = {Correction to: A new uncertain DEA model and application to scientific research personnel},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). A new uncertain DEA model and application to scientific
research personnel. <em>SOCO</em>, <em>24</em>(4), 2841–2847. (<a
href="https://doi.org/10.1007/s00500-019-04555-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data envelopment analysis (DEA), which has been widely used since it was introduced by Charnes et al. (J Econom 30:91–107, 1985), is an effective method for evaluating the relative efficiency of decision-making units. DEA models require accurate input data and output data; however, if no sample is available to estimate accurate data, then uncertain DEA is introduced. This paper reports on several new studies on uncertain DEA using the Hurwicz criterion, which attempts to find the intermediate area between extremes. Some uncertain DEA models, as well as their crisp equivalent models, are presented. Then, the Hurwicz ranking method is proposed based on these models, which can give an evaluation to all the decision-making units. By varying the parameter $$\beta $$ in the Hurwicz criterion, which reflects the optimism of the decision maker, the new ranking method can exhibit various forms. Finally, an application to scientific personnel is provided to prove the advantage of the proposed method.},
  archive      = {J_SOCO},
  author       = {Wen, Meilin and Yu, Xue and Wang, Fei},
  doi          = {10.1007/s00500-019-04555-6},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2841-2847},
  shortjournal = {Soft Comput.},
  title        = {A new uncertain DEA model and application to scientific research personnel},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The stability analysis for uncertain heat equations based on
p-th moment. <em>SOCO</em>, <em>24</em>(4), 2833–2839. (<a
href="https://doi.org/10.1007/s00500-019-04529-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stability in p-th moment plays a vital role in uncertain heat equation (UHE). However, little is known about the definition and properties of stability in p-th moment for UHE. This paper fills this gap and advances the concept of stability in p-th moment for UHE. Based on Markov inequality, this study shows the relationship between stability in p-th moment and stability in measure, that is if an UHE is stable in p-th moment, then it is stable in measure, but not vice versa. Our analysis further reveals that if the coefficients of UHE satisfy strong Lipschitz condition, and meanwhile, the Lipschitz coefficients meet some integral constraints, then the UHE is stable in p-th moment. This study provides a strong theoretically foundation for understanding the stability in p-th moment of UHE.},
  archive      = {J_SOCO},
  author       = {Liu, Jin and Zhang, Yi},
  doi          = {10.1007/s00500-019-04529-8},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2833-2839},
  shortjournal = {Soft Comput.},
  title        = {The stability analysis for uncertain heat equations based on p-th moment},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A hybrid combinatorial approach to a two-stage stochastic
portfolio optimization model with uncertain asset prices. <em>SOCO</em>,
<em>24</em>(4), 2809–2831. (<a
href="https://doi.org/10.1007/s00500-019-04517-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Portfolio optimization is one of the most important problems in the finance field. The traditional Markowitz mean-variance model is often unrealistic since it relies on the perfect market information. In this work, we propose a two-stage stochastic portfolio optimization model with a comprehensive set of real-world trading constraints to address this issue. Our model incorporates the market uncertainty in terms of future asset price scenarios based on asset return distributions stemming from the real market data. Compared with existing models, our model is more reliable since it encompasses real-world trading constraints and it adopts CVaR as the risk measure. Furthermore, our model is more practical because it could help investors to design their future investment strategies based on their future asset price expectations. In order to solve the proposed stochastic model, we develop a hybrid combinatorial approach, which integrates a hybrid algorithm and a linear programming (LP) solver for the problem with a large number of scenarios. The comparison of the computational results obtained with three different metaheuristic algorithms and with our hybrid approach shows the effectiveness of the latter. The superiority of our model is mainly embedded in solution quality. The results demonstrate that our model is capable of solving complex portfolio optimization problems with tremendous scenarios while maintaining high solution quality in a reasonable amount of time and it has outstanding practical investment implications, such as effective portfolio constructions.},
  archive      = {J_SOCO},
  author       = {Cui, Tianxiang and Bai, Ruibin and Ding, Shusheng and Parkes, Andrew J. and Qu, Rong and He, Fang and Li, Jingpeng},
  doi          = {10.1007/s00500-019-04517-y},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2809-2831},
  shortjournal = {Soft Comput.},
  title        = {A hybrid combinatorial approach to a two-stage stochastic portfolio optimization model with uncertain asset prices},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Correction to: Optimal operational strategies of
capital-constrained supply chain with logistics service and price
dependent demand under 3PL financing service. <em>SOCO</em>,
<em>24</em>(4), 2807. (<a
href="https://doi.org/10.1007/s00500-019-04560-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The text c1 should read as Cl.},
  archive      = {J_SOCO},
  author       = {Zhang, Chuan and Fan, Ling-Wei and Tian, Yu-Xin},
  doi          = {10.1007/s00500-019-04560-9},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2807},
  shortjournal = {Soft Comput.},
  title        = {Correction to: Optimal operational strategies of capital-constrained supply chain with logistics service and price dependent demand under 3PL financing service},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Optimal operational strategies of capital-constrained
supply chain with logistics service and price dependent demand under 3PL
financing service. <em>SOCO</em>, <em>24</em>(4), 2793–2806. (<a
href="https://doi.org/10.1007/s00500-019-04500-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a supply chain finance (SCF) system composed of a manufacturer, a retailer and a third-party logistics (3PL) enterprise, the market demand is dependent on the logistics service level and the retail price. This paper investigates the optimal operational strategies for the SCF system with the 3PL financing service when the retailer or the manufacturer is stuck with capital constraint, respectively. By constructing and solving Stackelberg game models, we obtain the optimal operational strategies of the above two scenarios, and combined with the sensitivity analysis of relevant parameters, we obtain the following conclusions. (1) For the SCF system with a capital-constrained retailer, except the manufacturer’s optimal wholesale price remains unchanged, other participants’ optimal decisions and the optimal profits of each participant increase with the logistics service sensitivity coefficient; except the manufacturer’s optimal wholesale price remains unchanged, other participants’ optimal decisions and the optimal profits of each participant decrease with the logistics service cost efficiency. (2) For the SCF system with a capital-constrained manufacturer, the optimal decisions and profits of supply chain participants increase with the logistics service sensitivity coefficient; the optimal decisions and profits of supply chain participants decrease with the logistics service cost efficiency. Our analysis suggests that the retailer and manufacturer must take into account 3PL enterprise’s decisions (logistics service level and logistics service price) under the 3PL financing service mode before making decisions.},
  archive      = {J_SOCO},
  author       = {Zhang, Chuan and Fan, Ling-Wei and Tian, Yu-Xin},
  doi          = {10.1007/s00500-019-04500-7},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2793-2806},
  shortjournal = {Soft Comput.},
  title        = {Optimal operational strategies of capital-constrained supply chain with logistics service and price dependent demand under 3PL financing service},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Chance constrained programming models for uncertain hub
covering location problems. <em>SOCO</em>, <em>24</em>(4), 2781–2791.
(<a href="https://doi.org/10.1007/s00500-019-04476-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hub covering location problem is a typical strategic decision with the purpose of locating hubs and determining the assignments of other nodes to ensure the travel time is not exceeding a specific threshold. Since the parameters such as flows and travel times are difficult to be precisely obtained in advance, a feasible way is to estimate them following the experts’ subjective beliefs. Hence, this paper is devoted to study hub covering location problem by using uncertain measure to characterize the subjective belief and considering the flows and travel times by uncertain variables. The uncertain hub set covering location problem is first discussed under the purpose of covering the flows entirely with the minimum setup cost of hubs. Then the uncertain hub maximal covering problem is studied by maximizing the total flow covered when the number of hubs is confirmed previously. Chance constrained programming models for both problems are constructed, respectively, and their corresponding deterministic forms are derived. A hybrid intelligence algorithm named GA–VNS is proposed by combing the variable neighborhood search with the genetic algorithm. Finally, several numerical experiments are presented to indicate the efficiency of GA–VNS.},
  archive      = {J_SOCO},
  author       = {Wang, Junbin and Qin, Zhongfeng},
  doi          = {10.1007/s00500-019-04476-4},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2781-2791},
  shortjournal = {Soft Comput.},
  title        = {Chance constrained programming models for uncertain hub covering location problems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-period multi-scenario optimal design for closed-loop
supply chain network of hazardous products with consideration of
facility expansion. <em>SOCO</em>, <em>24</em>(4), 2769–2780. (<a
href="https://doi.org/10.1007/s00500-019-04435-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Increased concern for the environment has led to urgent need to design the closed-loop supply chain network of hazardous products economically and ecologically. In this paper, we focus on the optimal design problem of multi-period closed-loop supply chain network of hazardous products considering uncertain demands and returns, expandable facility capacities and social acceptable risk simultaneously. In each period, the built facilities have the ability to expand within a certain scope. The problem is formulated as a mixed-integer nonlinear programming model, which can determine the number, location and expansion scale of the facilities and the forward and reverse logistics quantities between the facilities in each period simultaneously. The goal is to minimize the expected cost over the multi-period planning horizon, including the facilities building, operating and expansion costs and the costs related to manufacturing, collection, processing, recovery and transportation. In order to solve the proposed model, two classes of dummy variables are introduced to equivalently transform it into a mixed-integer linear programming, which can be optimally solved by LINGO. A case study is presented to illustrate the validity of the proposed model. The dynamic design with expansion strategy addressed in this paper is compared with two different strategies of static design and dynamic design without expansion. The results highlight that the dynamic design with expansion strategy has the advantages in saving expenses and raising the average expected collection rate of hazardous wastes.},
  archive      = {J_SOCO},
  author       = {Ma, Hongguang and Li, Xiang and Liu, Yankui},
  doi          = {10.1007/s00500-019-04435-z},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2769-2780},
  shortjournal = {Soft Comput.},
  title        = {Multi-period multi-scenario optimal design for closed-loop supply chain network of hazardous products with consideration of facility expansion},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A distributionally robust optimization model for designing
humanitarian relief network with resource reallocation. <em>SOCO</em>,
<em>24</em>(4), 2749–2767. (<a
href="https://doi.org/10.1007/s00500-019-04362-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since natural disasters often cause the loss of lives and property, it is necessary to design a reasonable relief network to distribute relief supplies after a disaster. The shortage of relief supplies and timely transportation are the main difficulties in the whole relief network. To overcome these difficulties, we introduce a three-level humanitarian relief network design problem with resource reallocation of relief supplies. Based on the existing relief network system before a disaster, this problem determines the positions of candidate local distribution centers and points of distribution, while considering the relief distribution in the network under an uncertain post-disaster environment. For the uncertain variables, we consider a distributionally robust model with mean absolute semi-deviation (MASD) as a risk measure taken into the transportation time function. Under the partial probability distribution information of the uncertainties, we deduce a tractable framework of the distributionally robust model. Specifically, we derive the worse case form of the MASD objective under an ambiguity set and the safe approximations of the chance constraints under a box + ellipsoid + generalized budget perturbation set. Finally, we demonstrate the efficacy of the model by a real case in Anambra flood.},
  archive      = {J_SOCO},
  author       = {Zhang, Peiyu and Liu, Yankui and Yang, Guoqing and Zhang, Guoqing},
  doi          = {10.1007/s00500-019-04362-z},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2749-2767},
  shortjournal = {Soft Comput.},
  title        = {A distributionally robust optimization model for designing humanitarian relief network with resource reallocation},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A simple differential evolution with time-varying strategy
for continuous optimization. <em>SOCO</em>, <em>24</em>(4), 2727–2747.
(<a href="https://doi.org/10.1007/s00500-019-04159-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel simple variant of differential evolution (DE) algorithm and call it TVDE because it is a time-varying strategy-based DE algorithm. In our TVDE, three functions with time-varying characteristics are applied to create a new mutation operator and automatically tune the values of two key control parameters (scaling factor and crossover rate) during the evolutionary process. To verify its availability, the proposed TVDE has been tested on the CEC 2014 benchmark sets and four real-life problems and compared to seven state-of-the-art DE variants. The experimental results indicate that the proposed TVDE algorithm obtains the best overall performance among the eight DE algorithms.},
  archive      = {J_SOCO},
  author       = {Sun, Gaoji and Xu, Geni and Jiang, Nan},
  doi          = {10.1007/s00500-019-04159-0},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2727-2747},
  shortjournal = {Soft Comput.},
  title        = {A simple differential evolution with time-varying strategy for continuous optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Analytic solution of uncertain autoregressive model based on
principle of least squares. <em>SOCO</em>, <em>24</em>(4), 2721–2726.
(<a href="https://doi.org/10.1007/s00500-019-04128-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncertain time series is a method to predict future values based on previously uncertain observed values, which is firstly proposed by Yang and Liu (Fuzzy Optim Decis Mak, 2019. https://doi.org/10.1007/s10700-018-9298-z). This paper continues to study a special uncertain time series—uncertain autoregressive model, and gives an analytic solution of uncertain autoregressive model based on the principle of least squares. Moreover, this paper proves another equivalent form to calculate the unknown parameters of uncertain autoregressive model via uncertainty distribution and also analyzes the disturbance term via uncertainty distribution.},
  archive      = {J_SOCO},
  author       = {Zhao, Xin and Peng, Jin and Liu, Jie and Zhou, Xuejun},
  doi          = {10.1007/s00500-019-04128-7},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2721-2726},
  shortjournal = {Soft Comput.},
  title        = {Analytic solution of uncertain autoregressive model based on principle of least squares},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Uncertain johnson–schumacher growth model with imprecise
observations and k-fold cross-validation test. <em>SOCO</em>,
<em>24</em>(4), 2715–2720. (<a
href="https://doi.org/10.1007/s00500-019-04090-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regression is a powerful tool to study how the response variables vary due to changes of explanatory variables. Unlike traditional statistics or mathematics where data are assumed fairly accurate, we notice that the real-world data are messy and obscure; thus, the uncertainty theory seems more appropriate. In this paper, we focus on the residual analysis of the Johnson–Schumacher growth model, with parameter estimation performed by the least squares method, followed by the prediction intervals for new explanatory variables. We also propose a k-fold cross-validation method for model selection with imprecise observations. A numerical example illustrates that our approach will achieve better prediction accuracy.},
  archive      = {J_SOCO},
  author       = {Fang, Liang and Liu, Shiqin and Huang, Zhiyong},
  doi          = {10.1007/s00500-019-04090-4},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2715-2720},
  shortjournal = {Soft Comput.},
  title        = {Uncertain Johnson–Schumacher growth model with imprecise observations and k-fold cross-validation test},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bi-level programming problem in the supply chain and its
solution algorithm. <em>SOCO</em>, <em>24</em>(4), 2703–2714. (<a
href="https://doi.org/10.1007/s00500-019-03930-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enterprise-wide supply chain planning problems naturally exhibit a multi-level decision network structure, where the upper level of a hierarchy may have his objective function and decision space partly determined by other levels. In addition, each planner’s control instruments may allow him to influence the policies at other levels and thereby to improve his own objective function. As a tool, bi-level programming is applied for modeling decentralized decisions in which two decision makers make decisions successively. In this paper, we specifically address bi-level decision-making problems with budget constraint as an attractive feature in the context of enterprise-wide supply chain. We first describe the typical bi-level linear programming problem (BLLPP) and its optimal solution to the penalty function problem, and then, a cooperative decision-making problem in supply chain is modeled as BLLPP. A particle swarm optimization-based computational algorithm is designed to solve the problem, and the numerical example is presented to illustrate the proposed framework.},
  archive      = {J_SOCO},
  author       = {Luo, Haiyan and Liu, Linzhong and Yang, Xun},
  doi          = {10.1007/s00500-019-03930-7},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2703-2714},
  shortjournal = {Soft Comput.},
  title        = {Bi-level programming problem in the supply chain and its solution algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Incentive contracts of knowledge investment for cooperative
innovation in project-based supply chain with double moral hazard.
<em>SOCO</em>, <em>24</em>(4), 2693–2702. (<a
href="https://doi.org/10.1007/s00500-019-03894-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The degree of knowledge investment of partners is the key to success for cooperative innovation in project-based supply chain. The intangibility and unverifiability of their knowledge investment lead to the double moral hazard which will hinder the smooth progress of cooperative innovation. In order to stimulate the knowledge investment of partners for cooperative innovation in project-based supply chain, this paper has designed formal contract and relational contract of knowledge investment with principal-agent theory, and then the incentive effects of contracts are analyzed. We find that the formal contract cannot motivate their knowledge investment effectively; the degree of knowledge investment and the revenue of participants for cooperative innovation under the relational contract are not less than that under the formal contract for all discount rate; the incentive effect of the relational contract is getting more obvious as the discount rate increases. When the discount rate reaches a certain threshold value, the optimal degree of knowledge investment and revenue of participants for cooperative innovation can be achieved through the relational contract. At last, the effectiveness of the conclusions is verified through numerical example.},
  archive      = {J_SOCO},
  author       = {Chen, Yin-zhong and Chen, Wei},
  doi          = {10.1007/s00500-019-03894-8},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2693-2702},
  shortjournal = {Soft Comput.},
  title        = {Incentive contracts of knowledge investment for cooperative innovation in project-based supply chain with double moral hazard},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Green fresh product cost sharing contracts considering
freshness-keeping effort. <em>SOCO</em>, <em>24</em>(4), 2671–2691. (<a
href="https://doi.org/10.1007/s00500-019-03828-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, along with increased public demands on the high-quality green fresh product, the downstream retailer has to spend in the packaging and cold chain transportation and the upstream farmer needs to invest more in green fresh products producing. In this paper, we investigate a green fresh product supply chain problem, in which the retailer transports and sells green fresh products to the ultimate consumer while the farmer produces green fresh product through spending a greenness improvement investment and sells green fresh products to the retailer. Since the fresh product is perishable, the retailer needs to make a costly freshness-keeping effort. Obviously, the freshness-keeping effort, the price, and the greenness improvement level will affect the demand. Thus, to demonstrate the game structure between the retailer and the farmer, a decentralized model without cost sharing, a decentralized Stackelberg cost sharing model, and a Nash bargaining model with cost sharing are formulated. Results show that: (1) The equilibrium decisions under Stackelberg model with cost sharing are larger than that of the Nash bargaining model with cost sharing, while equilibrium decisions in the decentralized model without cost sharing are the least. (2) Both greenness improvement levels in Stackelberg cost sharing contract and Nash bargaining are greater than that in decentralized model without cost sharing. (3) The retailer’s profits in Stackelberg cost sharing contract and Nash bargaining are larger than that in decentralized case without cost sharing, while the farmer’s profits in Stackelberg cost sharing contract and Nash bargaining are larger than in decentralized model without cost sharing in certain conditions. Meanwhile, a numerical example is given to illustrate the results we obtained in the theoretical analysis process.},
  archive      = {J_SOCO},
  author       = {Wang, Guoli and Ding, Peiqi and Chen, Huiru and Mu, Jing},
  doi          = {10.1007/s00500-019-03828-4},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2671-2691},
  shortjournal = {Soft Comput.},
  title        = {Green fresh product cost sharing contracts considering freshness-keeping effort},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Uncertain revised regression analysis with responses of
logarithmic, square root and reciprocal transformations. <em>SOCO</em>,
<em>24</em>(4), 2655–2670. (<a
href="https://doi.org/10.1007/s00500-019-03821-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regression models are often called for to quantify relationships between the explanatory variables and the response variable. Mathematically, data should be collected and recorded as their true values, which turns out to be unrealistic for the real world. In this paper, we introduce uncertain variables to characterize such imprecise data, apply the most useful logarithmic, square root or reciprocal transformation to alleviate possible nonlinearity problems and estimate the disturbance terms for the obtained uncertain regression models, followed by confidence interval estimations and point predictions. For each type of models being proposed, namely the uncertain revised regression models, uncertain revised asymptotic regression models and uncertain revised Michaelis–Menten kinetics regression models, we give a numerical example, respectively, to illustrate our approach.},
  archive      = {J_SOCO},
  author       = {Fang, Liang and Hong, Yiping},
  doi          = {10.1007/s00500-019-03821-x},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2655-2670},
  shortjournal = {Soft Comput.},
  title        = {Uncertain revised regression analysis with responses of logarithmic, square root and reciprocal transformations},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A transportation planning problem with transfer costs in
uncertain environment. <em>SOCO</em>, <em>24</em>(4), 2647–2653. (<a
href="https://doi.org/10.1007/s00500-019-03813-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a generalization of existing uncertain transportation models, this paper proposes a new uncertain transportation model with transfer costs, of which the demands and the transportation costs as well as the transfer costs are uncertain variables. The model is presented in a form with expected-value objective and chance constraints. Based on the operational laws of uncertain variables, the presented model is transformed into an equivalent crisp model. After that, a numerical experiment is performed to illustrate the application of the model.},
  archive      = {J_SOCO},
  author       = {Zhao, Guihong and Pan, Dingyi},
  doi          = {10.1007/s00500-019-03813-x},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2647-2653},
  shortjournal = {Soft Comput.},
  title        = {A transportation planning problem with transfer costs in uncertain environment},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Roman domination problem with uncertain positioning and
deployment costs. <em>SOCO</em>, <em>24</em>(4), 2637–2645. (<a
href="https://doi.org/10.1007/s00500-019-03811-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a connected simple graph, the weighted Roman domination problem is considered at which the cost of positioning at each vertex is imposed in addition to the costs of potential deployments from a vertex to some of its neighboring vertices. Proper decision in practice is prone to a high degree of indeterminacy, mostly raised by unpredictable events that do not obey the rules and prerequisites of the probability theory. In this study, we model this problem with such assumptions in the context of the uncertainty theory initiated by Liu (Uncertainty theory. Studies in fuzziness and soft computing, Springer, Berlin, 2007). Two different optimization models are presented, and a concrete example is provided for illustrative purposes. Weaknesses of the probability theory and fuzzy theory in dealing with this problem are also mentioned in detail.},
  archive      = {J_SOCO},
  author       = {Ghaffari-Hadigheh, Alireza},
  doi          = {10.1007/s00500-019-03811-z},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2637-2645},
  shortjournal = {Soft Comput.},
  title        = {Roman domination problem with uncertain positioning and deployment costs},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Green supply chain analysis under cost sharing contract with
uncertain information based on confidence level. <em>SOCO</em>,
<em>24</em>(4), 2617–2635. (<a
href="https://doi.org/10.1007/s00500-019-03801-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study supply chain coordination issues arising out of green supply chain consisting of a manufacturer and a retailer under cost sharing contract with uncertain information. Instead of expected utility maximization, we present an alternative decision rule based on confidence level, that is, both the manufacturer’s and the retailer’s aims are to maximize the potential incomes under their confidence levels. First, we obtain the equilibrium values for the decentralized and the centralized channel cases under the given confidence levels, then compare the equilibrium values between the decentralized channel case and the centralized channel case to motivate cost sharing contract framework. Second, we consider the retailer participates in the green channel and obtain that the manufacturer and the retailer incur higher profits in the cost sharing contract case than the decentralized supply chain case. Third, we propose a cost sharing contract between the players who bargain on the cost sharing parameter, and the contract benefits the manufacturer significantly through sharing of costs with the retailer.},
  archive      = {J_SOCO},
  author       = {Ma, Nana and Gao, Rong and Wang, Xiaobin and Li, Ping},
  doi          = {10.1007/s00500-019-03801-1},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2617-2635},
  shortjournal = {Soft Comput.},
  title        = {Green supply chain analysis under cost sharing contract with uncertain information based on confidence level},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A credibilistic failure indicator for modeling structural
reliability design optimization. <em>SOCO</em>, <em>24</em>(4),
2609–2615. (<a
href="https://doi.org/10.1007/s00500-019-03781-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural reliability design optimization under epistemic uncertainty has attracted the attention of many researchers, which plays a pivotal role both in theory and engineering application. However, many traditional fuzzy reliability indicators are formulated by fuzzy measure without self-duality. For this reason, we reconsider structural system with fuzzy parameters, and a new credibilistic failure indicator (CFI) is presented based on self-dual credibility measure, which provides the exact expression of structural failure degree under fuzzy environment. Then, for the structure with fuzzy trapezoidal parameters, the explicit expressions of the CFI formulations are presented under fuzzy linear limit-state function and nonlinear limit-state function. Furthermore, CFI-based design optimization is formulated to obtain the optimal structural design under the given reliability level. Meanwhile, one theorem on the reliability constraint is provided to facilitate us to obtain the equivalent deterministic constraint of the reliability constraint. Finally, two illustrative examples are performed to demonstrate the efficiency of the proposed CFI formulation and the corresponding computational methods.},
  archive      = {J_SOCO},
  author       = {Zhai, Hao and Zhang, Jianguo},
  doi          = {10.1007/s00500-019-03781-2},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2609-2615},
  shortjournal = {Soft Comput.},
  title        = {A credibilistic failure indicator for modeling structural reliability design optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Green investment in a supply chain based on price and
quality competition. <em>SOCO</em>, <em>24</em>(4), 2589–2608. (<a
href="https://doi.org/10.1007/s00500-019-03777-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Along with the significant improvement of environmental consciousness, consumers not only consider the price and quality level of products, but also pay more attention to their green level. In order to strengthen the competitive advantage, the manufacturers should consider the green level of products in addition to their price and the quality level. In this paper, we investigate the green investment of two competing manufacturers in a supply chain based on price and quality competition and analyze the effect of green investment on the quality level of the product. The research shows that the manufacturer is willing to make a green investment with a relatively low value of green sensitivity regardless of whether the manufacturer’s rival makes a green investment. Further, we find that the profit of the manufacturer who makes a green investment is greater than the profit of the manufacturer who does not invest regardless of the market size. When both competing manufacturers make green investments, the profit of the manufacturer who is in a large potential market is higher than that of the manufacturer who is in a small potential market. While in a same potential market, the profits of the two competing manufacturers are the same. Finally, we conclude that the green investment counterintuitively will not always improve the quality level of the products.},
  archive      = {J_SOCO},
  author       = {Yang, Shanxue and Ding, Peiqi and Wang, Guoli and Wu, Xiaoli},
  doi          = {10.1007/s00500-019-03777-y},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2589-2608},
  shortjournal = {Soft Comput.},
  title        = {Green investment in a supply chain based on price and quality competition},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Price discrimination based on purchase behavior and service
cost in competitive channels. <em>SOCO</em>, <em>24</em>(4), 2567–2588.
(<a href="https://doi.org/10.1007/s00500-019-03760-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the recent emergence of cloud computing and big data technologies, collection of consumers’ information is widespread. Retailers use consumers’ purchase history and consumptive habits data to price discriminate between current and new, high-cost and low-cost consumers. We investigate behavior-based pricing (BBP) and consumers cost-based pricing (CCP) simultaneously in a competitive two-period market in which bricks and clicks retailers sell products to high-cost-type and low-cost-type consumers during two periods. We examine how the price discrimination affects the channel members’ prices, market shares and profits. We find that dual price discriminations (BBP and CCP) decrease the service cost advantage retailer’s profit, but increase the service cost disadvantage retailer’s profit if the consumer’s travel cost is low. Compared the market shares of retailers, it is interesting that a cost advantage retailer serves more type-H consumers under the case of BBP and CCP than other cases. In addition, our results illustrate that cost disadvantage retailers prefer to reward the current consumers in the second period. Additionally, we find that consumers may benefit from price discrimination that they face a lower price in the case of BBP and CCP than other cases under certain conditions. Even more egregious, the current type-H consumers served by the cost advantage retailer enjoy a lower price than the type-L consumers served by the competitor.},
  archive      = {J_SOCO},
  author       = {Xu, Man and Tang, Wansheng and Zhou, Chi},
  doi          = {10.1007/s00500-019-03760-7},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2567-2588},
  shortjournal = {Soft Comput.},
  title        = {Price discrimination based on purchase behavior and service cost in competitive channels},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The impact of online referral on brand market strategies
with consumer search and spillover effect. <em>SOCO</em>,
<em>24</em>(4), 2551–2565. (<a
href="https://doi.org/10.1007/s00500-018-3661-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies how online referral affects the brand market management and investigates the spillover conditions from national brand to store brand market. We develop the game models without and with online referral, and derive the equilibrium strategies under the uniform pricing strategy and the differential pricing strategy. The results show that as the brand awareness increases, the presence of online referral would reduce the national brand’s selling price, market demand and profit, and raise the store brand’s selling price and market demand. Moreover, the differential pricing strategy could be better for the store brand than the uniform pricing strategy. Under the differential pricing strategy, the infomediary decides a higher referral commission only when the brand awareness is lower. In addition, the results also demonstrate that as the brand awareness increases, the spillover condition would be reduced under the differential pricing strategy and show a first declining and then rising trend under the uniform pricing strategy. To mitigate the spillover effect, the national brand should reduce the consumer’s search cost in the national brand market.},
  archive      = {J_SOCO},
  author       = {Zhou, Chi and Ma, Nana and Cui, Xin and Liu, Zhibing},
  doi          = {10.1007/s00500-018-3661-4},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2551-2565},
  shortjournal = {Soft Comput.},
  title        = {The impact of online referral on brand market strategies with consumer search and spillover effect},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Uncertain gompertz regression model with imprecise
observations. <em>SOCO</em>, <em>24</em>(4), 2543–2549. (<a
href="https://doi.org/10.1007/s00500-018-3611-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regression is widely applied in many fields. Regardless of the types of regression, we often assume that the observations are precise. However, in real-life circumstances, this assumption can only be met sometimes, which means the traditional regression methods can result in significant imprecise or biased predictions. Consequently, uncertain regression models might provide more accurate and meaningful results under these circumstances. In this article, we provide the residual analysis of uncertain Gompertz regression model, as well as the corresponding forecast value and confidence interval. Finally, we give a numerical example of uncertain Gompertz regression model.},
  archive      = {J_SOCO},
  author       = {Hu, Zeyu and Gao, Jinwu},
  doi          = {10.1007/s00500-018-3611-1},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2543-2549},
  shortjournal = {Soft Comput.},
  title        = {Uncertain gompertz regression model with imprecise observations},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Estimation of dynamic mixed double factors model in
high-dimensional panel data. <em>SOCO</em>, <em>24</em>(4), 2527–2541.
(<a href="https://doi.org/10.1007/s00500-018-3603-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper endeavors to develop some dimension reduction techniques in panel data analysis when the numbers of individuals and indicators are very large. We use principal component analysis method to represent a large number of indicators via minority common factors in the factor models. We propose the dynamic mixed double factor model (DMDFM for short) to reflect cross section and time series correlation with the interactive factor structure. DMDFM not only reduces the dimension of indicators but also deals with the time series and cross section mixed effect. Different from other models, mixed factor models have two styles of common factors. The regressors factors reflect common trend and the dimension reducing, while the error components factors reflect difference and weak correlation of individuals. The results of Monte Carlo simulation show that generalized method of moments estimators have good properties of unbiasedness and consistency. Simulation results also show that the DMDFM can improve the prediction power of the models effectively.},
  archive      = {J_SOCO},
  author       = {Fang, Guobin and Zhang, Bo and Chen, Kani},
  doi          = {10.1007/s00500-018-3603-1},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2527-2541},
  shortjournal = {Soft Comput.},
  title        = {Estimation of dynamic mixed double factors model in high-dimensional panel data},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). A comprehensive model for fuzzy multi-objective portfolio
selection based on DEA cross-efficiency model. <em>SOCO</em>,
<em>24</em>(4), 2515–2526. (<a
href="https://doi.org/10.1007/s00500-018-3595-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we discuss the fuzzy portfolio selection problems in multi-objective frameworks. A comprehensive model for multi-objective portfolio selection in fuzzy environment is proposed by incorporating mean-semivariance model and data envelopment analysis cross-efficiency model. In the proposed model, the cross-efficiency model is formulated within the framework of Sharpe ratio; bounds on holdings, and cardinality constraints are also considered. The nonlinear constrained multi-objective portfolio optimization problem cannot be efficiently solved by using traditional approaches. Thus, a multi-objective firefly algorithm is developed to solve the relevant model. Finally, an example verifies the validity of the proposed approaches.},
  archive      = {J_SOCO},
  author       = {Chen, Wei and Li, Si-Si and Zhang, Jun and Mehlawat, Mukesh Kumar},
  doi          = {10.1007/s00500-018-3595-x},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2515-2526},
  shortjournal = {Soft Comput.},
  title        = {A comprehensive model for fuzzy multi-objective portfolio selection based on DEA cross-efficiency model},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sustainability efficiency evaluation of seaports in china:
An uncertain data envelopment analysis approach. <em>SOCO</em>,
<em>24</em>(4), 2503–2514. (<a
href="https://doi.org/10.1007/s00500-018-3559-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sustainability is regarded as achieving economic, environmental, and social dimensions simultaneously that support an organization for long-term competitiveness. Port sustainability has attracted increasing attention because it is related to the issues of climate change and public health and safety. Therefore, it is urgent to measure the sustainability of ports. However, some variables (for instance, air pollutants and the neighboring relationship with surrounding communities) cannot be measured precisely by collecting quantitative data. This led us to select 23 seaports of China and use uncertain variables and uncertain data envelopment analysis model to measure their sustainability efficiency. Moreover, we captured the quantity to be improved of each output. The results show that 14 seaports such as Shanghai Port and Qingdao Port are deemed to be inefficient in terms of their sustainability. And our results can identify whether economic, environmental, or social dimensions contribute to the sustainability inefficiency of each seaport. On the basis of the results, we point out the managerial implications and put forward measures toward enhancing the efficiency of seaports with respect to these two dimensions.},
  archive      = {J_SOCO},
  author       = {Jiang, Bao and Li, Yu and Lio, Waichon and Li, Jian},
  doi          = {10.1007/s00500-018-3559-1},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2503-2514},
  shortjournal = {Soft Comput.},
  title        = {Sustainability efficiency evaluation of seaports in china: An uncertain data envelopment analysis approach},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Tail value-at-risk in uncertain random environment.
<em>SOCO</em>, <em>24</em>(4), 2495–2502. (<a
href="https://doi.org/10.1007/s00500-018-3492-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chance theory is a rational tool to be used in the systems which contain not only uncertainty but also randomness. In this paper, the concept of tail value-at-risk in uncertain random risk analysis is proposed and some theorems are provided for its calculation. Moreover, the tail value-at-risk is applied as the right-tail in the parallel system, series system, standby system, k-out-of-n system and structural system.},
  archive      = {J_SOCO},
  author       = {Liu, Yuhan and Ralescu, Dan A. and Xiao, Chen and Lio, Waichon},
  doi          = {10.1007/s00500-018-3492-3},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2495-2502},
  shortjournal = {Soft Comput.},
  title        = {Tail value-at-risk in uncertain random environment},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Internationalization strategy, social responsibility
pressure and enterprise value. <em>SOCO</em>, <em>24</em>(4), 2487–2494.
(<a href="https://doi.org/10.1007/s00500-018-3425-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years has seen Chinese enterprises competing to broaden the scope of business through the internationalization strategy. The proliferation of the strategy is attributable to the favorable environment created by the Chinese government with the increasingly stringent requirements on corporate social responsibility. The external pressure of social responsibility has also stimulated the fulfillment of social responsibility within the enterprises. Against this backdrop, this paper constructs a mathematical model with the constraint of external social responsibility pressure and applies the model to examine the effect of the internationalization strategy of Chinese enterprises on enterprise value. The research finds that: First, the internationalization strategy enhances the enterprise value; the stakeholders will jointly promote the strategy once they are aware of its significance. Second, with the increase in the external pressure of social responsibility, the enterprises will promote enterprise value through the implementation of social responsibility. Third, the fulfillment of corporate social responsibility contributes to the proliferation of internationalization strategy and further enhances the long-term enterprise value. These modeling conclusions are validated through an empirical test. This research enriches the exploration into the internationalization strategy of enterprises in emerging markets and pioneers the study on the fulfillment of corporate social responsibility from the external angle.},
  archive      = {J_SOCO},
  author       = {Yang, Bai and Lin, Chuan and Ren, Chenglin},
  doi          = {10.1007/s00500-018-3425-1},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2487-2494},
  shortjournal = {Soft Comput.},
  title        = {Internationalization strategy, social responsibility pressure and enterprise value},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Static uncertain behavioral game with application to
investment problem. <em>SOCO</em>, <em>24</em>(4), 2479–2485. (<a
href="https://doi.org/10.1007/s00500-018-03737-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncertain game considers situations in which payoffs are characterized by uncertain variables. This paper goes further by taking into account players’ behaviors. For uncertain game with normal form, we define a new spectrum of uncertain behavioral game. Then, with the frame work of behavioral game theory and uncertainty theory, the expected Nash equilibrium is proposed. A necessary condition is provided in order to find the expected Nash equilibrium. Finally, an example is provided for illustrating purpose.},
  archive      = {J_SOCO},
  author       = {Zhao, Hua and Li, Jiang and Jiang, Xinyu},
  doi          = {10.1007/s00500-018-03737-y},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2479-2485},
  shortjournal = {Soft Comput.},
  title        = {Static uncertain behavioral game with application to investment problem},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Benchmarking framework for command and control mission
planning under uncertain environment. <em>SOCO</em>, <em>24</em>(4),
2463–2478. (<a
href="https://doi.org/10.1007/s00500-018-03732-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the core of the military information system, the command and control (C2) mission planning suffers from the high complexity, environmental uncertainty. To address this problem, many studies highlight the agility and resilience of C2-organizations and propose many solutions. However, there is no benchmark to compare these models and methods. In order to understand such organization’s dynamic and emergence behaviors, this paper presents a benchmark framework of C2 decision-making under uncertainty environment. This is a basic case on multi-force joint operation. We present an optimization model and a horizon partition algorithm aimed to plan an optimal organizational structure with higher operational flexibility, low cost and high performance. Finally, we explore the main traditional models on the benchmark case. The result shows the proposed model is competitive under uncertain environment.},
  archive      = {J_SOCO},
  author       = {Feng, Yanghe and Shi, Wei and Cheng, Guangquan and Huang, Jincai and Liu, Zhong},
  doi          = {10.1007/s00500-018-03732-3},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2463-2478},
  shortjournal = {Soft Comput.},
  title        = {Benchmarking framework for command and control mission planning under uncertain environment},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A comparison of milestone contract and royalty contract
under critical value criterion in r&amp;d alliance. <em>SOCO</em>,
<em>24</em>(4), 2447–2462. (<a
href="https://doi.org/10.1007/s00500-018-03727-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper attempts to better understand contract type and risk attitude in R&amp;D alliance under information asymmetry, that is, how the marketer designs and chooses optimal contract between royalty contract and milestone contract and how the innovator’s risk attitude and asymmetric information affect the marketer’s optimal contract strategies and profits. We use principal–agent models to formulate the marketer’s contracting problem under asymmetric information about the innovator’s innovation expertise and unobservable efforts. We find that, compared to the case under full information in both contracting structures, the marketer should distort the commission rate upwards under dual asymmetric information when the innovator is risk averse or downwards to lower innovation–expertise and risk-loving innovator; nevertheless, the marketer should offer the first-best contract. Furthermore, investigating the impacts of information asymmetry on the marketer’s profits under two information structures, we find that dual asymmetric information harms the marketer’s profit, especially when the innovator’s effort marginal efficiency is higher. Finally, by comparing the marketer’s profits in two types of contracts, we give the specific regions that milestone contract or royalty contract benefits the marketer better under different information structures.},
  archive      = {J_SOCO},
  author       = {Fu, Yiping and Chen, Zhihua and Liu, Zhibing and Yang, Shanxue},
  doi          = {10.1007/s00500-018-03727-0},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2447-2462},
  shortjournal = {Soft Comput.},
  title        = {A comparison of milestone contract and royalty contract under critical value criterion in R&amp;D alliance},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel uncertain bimatrix game with hurwicz criterion.
<em>SOCO</em>, <em>24</em>(4), 2441–2446. (<a
href="https://doi.org/10.1007/s00500-018-03715-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In an uncertain bimatrix game, different uncertain equilibrium strategies have been proposed based on different criterions, such as expected value criterion, optimistic value criterion and uncertain measure criterion. This paper further presents an uncertain bimatrix game with Hurwicz criterion and defines a new solution concept Hurwicz Nash equilibrium. Furthermore, its existence theorem is also proved, and a sufficient and necessary condition is presented to find the Hurwicz Nash equilibrium. Finally, an example is provided for illustrating the usefulness of Hurwicz Nash equilibrium.},
  archive      = {J_SOCO},
  author       = {Tang, Min and Li, Zhiguo},
  doi          = {10.1007/s00500-018-03715-4},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2441-2446},
  shortjournal = {Soft Comput.},
  title        = {A novel uncertain bimatrix game with hurwicz criterion},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Uncertain random shortest path problem. <em>SOCO</em>,
<em>24</em>(4), 2431–2440. (<a
href="https://doi.org/10.1007/s00500-018-03714-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The shortest path is an important problem in network optimization theory. This paper considers the shortest path problem under the situation where weights of edges in a network include both uncertainty and randomness and focuses on the case that the weights of edges are expressed by uncertain random variables. Some optimization models based on chance theory are proposed in order to find the shortest path which fully reflects uncertain and random information. This paper proposes also an intelligent algorithm to calculate the shortest path for an uncertain random network. A numerical example is given to illustrate its effectiveness.},
  archive      = {J_SOCO},
  author       = {Sheng, Yuhong and Mei, Xuehui},
  doi          = {10.1007/s00500-018-03714-5},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2431-2440},
  shortjournal = {Soft Comput.},
  title        = {Uncertain random shortest path problem},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Uncertain pursuit-evasion game. <em>SOCO</em>,
<em>24</em>(4), 2425–2429. (<a
href="https://doi.org/10.1007/s00500-018-03689-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pursuit-evasion game deals with the situation in which a pursuer tries to catch an evader. Taking into account the subjectivity of the players’ strategies and the fact that the noise of system state does not obey the statistical regularity, this paper employs an uncertain differential equation to describe the dynamics of the pursuit-evasion system, and introduces an uncertain pursuit-evasion game. Within the framework of uncertain differential game theory, a solution for the uncertain pursuit-evasion game is derived via the corresponding Riccati equation. At last, as an application, a target interception problem is proposed.},
  archive      = {J_SOCO},
  author       = {Feng, Yanghe and Dai, Lanruo and Gao, Jinwu and Cheng, Guangquan},
  doi          = {10.1007/s00500-018-03689-3},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2425-2429},
  shortjournal = {Soft Comput.},
  title        = {Uncertain pursuit-evasion game},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Uncertain population model. <em>SOCO</em>, <em>24</em>(4),
2417–2423. (<a
href="https://doi.org/10.1007/s00500-018-03678-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering that the population size is always influenced by various uncertain factors in varying environment, we present some new types of uncertain population models: uncertain population growth model and uncertain logistic population growth model which are described by uncertain differential equations. And some properties of these uncertain population models are discussed within the framework of uncertainty theory.},
  archive      = {J_SOCO},
  author       = {Zhang, Zhiqiang and Yang, Xiangfeng},
  doi          = {10.1007/s00500-018-03678-6},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2417-2423},
  shortjournal = {Soft Comput.},
  title        = {Uncertain population model},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Effects of risk attitudes and investment spillover on
supplier encroachment. <em>SOCO</em>, <em>24</em>(4), 2395–2416. (<a
href="https://doi.org/10.1007/s00500-018-03677-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of e-commerce, a growing number of suppliers have begun to initially establish their own direct channels, competing with their retail channels. However, while this encroachment endows the suppliers with an efficient method to control downstream competition and total production output directly, it may hurt the retailer due to the loss of monopoly in the retail market. This inconsistency presents a difficulty in reaching equilibrium. In this paper, we focus on the combined effects of the risk attitudes and upstream production investment of supply chain members on supplier encroachment and verify the existence of “win–win” results for both supplier and retailer. We find that, while the two parties cannot simultaneously benefit from supplier encroachment in the absence of upstream investment, they can obtain a Pareto improvement from it in the presence of upstream investment and spillover effect. Regarding risk attitudes, we find that both the supplier and the retailer can reach agreement on the supplier encroachment in the case of a moderate confidence level. In other words, the not too risk-loving and not too risk-averse supply chain members are more likely to obtain a Pareto improvement.},
  archive      = {J_SOCO},
  author       = {Chen, Huiru and Yan, Yingchen and Ma, Nana and Liu, Jie},
  doi          = {10.1007/s00500-018-03677-7},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2395-2416},
  shortjournal = {Soft Comput.},
  title        = {Effects of risk attitudes and investment spillover on supplier encroachment},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Special issue on decision making and uncertainty.
<em>SOCO</em>, <em>24</em>(4), 2391–2393. (<a
href="https://doi.org/10.1007/s00500-020-04702-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SOCO},
  author       = {Zhao, Hua and Yao, Kai and Yang, Xiangfeng and Ni, Yaodong},
  doi          = {10.1007/s00500-020-04702-4},
  journal      = {Soft Computing},
  number       = {4},
  pages        = {2391-2393},
  shortjournal = {Soft Comput.},
  title        = {Special issue on decision making and uncertainty},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Active constraint spectral clustering based on hessian
matrix. <em>SOCO</em>, <em>24</em>(3), 2381–2390. (<a
href="https://doi.org/10.1007/s00500-019-04069-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applying the pairwise constraint algorithm to spectral clustering has become a hot topic in data mining research in recent years. In this paper, a clustering algorithm is proposed, called an active constraint spectral clustering based on Hessian matrix (ACSCHM); this algorithm not only use Hessian matrix instead of Laplacian matrix to free the parameter but also use an active query function to dynamically select constraint pairs and use these constraints to tune and optimize data points. In this paper, we used active query strategy to replace the previous random query strategy, which overcame the instability of the clustering results brought by the random query and enhanced the robustness of the algorithm. The unique parameter in the Hessian matrix was obtained by the spectral radius of the matrix, and the parameter selection problem in the original spectral clustering algorithm was also solved. Experiments on multiple UCI data sets can prove the effectiveness of this algorithm.},
  archive      = {J_SOCO},
  author       = {Wang, Xiaoyu and Ding, Shifei and Jia, Weikuan},
  doi          = {10.1007/s00500-019-04069-1},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {2381-2390},
  shortjournal = {Soft Comput.},
  title        = {Active constraint spectral clustering based on hessian matrix},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new fallback beetle antennae search algorithm for path
planning of mobile robots with collision-free capability. <em>SOCO</em>,
<em>24</em>(3), 2369–2380. (<a
href="https://doi.org/10.1007/s00500-019-04067-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of technology, mobile robots are becoming more and more common in industrial production and daily life. Various rules are set to ensure that mobile robots can move without collision. This paper proposes a novel intelligent optimization algorithm, named fallback beetle antennae search algorithm. Based on the analysis of biological habits, when the creature enters blind alley during the foraging process, it will retreat a distance and then restart the search process. We introduce a fallback mechanism in the traditional beetle antenna search algorithm. In addition, the proposed algorithm possesses the characteristic of low time complexity. It can plan a collision-free path in a short period of time. Moreover, the effectiveness and superiority of the algorithm are verified by simulations in different types of environments and comparisons with existing path planning algorithms.},
  archive      = {J_SOCO},
  author       = {Wu, Qing and Lin, Hao and Jin, Yuanzhe and Chen, Zeyu and Li, Shuai and Chen, Dechao},
  doi          = {10.1007/s00500-019-04067-3},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {2369-2380},
  shortjournal = {Soft Comput.},
  title        = {A new fallback beetle antennae search algorithm for path planning of mobile robots with collision-free capability},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel WASPAS approach for multi-criteria physician
selection problem with intuitionistic fuzzy type-2 sets. <em>SOCO</em>,
<em>24</em>(3), 2355–2367. (<a
href="https://doi.org/10.1007/s00500-019-04065-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to innovative and practical technology, the selection of a right physician is an important issue for patients. However, uncertainty and vagueness frequently arise during the process of selecting physicians. Intuitionistic fuzzy type-2 sets (IFT2Ss) (recently named as Pythagorean fuzzy sets) provide an important tool to handle the uncertainty arises in real-life decision-making problems. This paper presents an extended weighted aggregated sum product assessment (WASPAS) method based on novel information measures (entropy and divergence measures) and operators under IFT2Ss context. In the proposed WASPAS method, entropy and divergence measure-based formula is developed to find the criteria weights. For this, several intuitionistic fuzzy entropy and divergence measures are developed for IFT2Ss. To increase the stability of the proposed methodology, the criteria’s weights are calculated in the form of objective and subjective weights. Further, to reveal the applicability and effectiveness of proposed method, an uncertain multi-criteria decision-making problem of physician selection is executed with intuitionistic fuzzy information of second type. Finally, the validity of the proposed method is implemented by comparison with existing methods and sensitivity analysis and also proves that the proposed method is valid and feasible in the physician selection processes with information given in intuitionistic fuzzy type-2 numbers (IFT2Ns).},
  archive      = {J_SOCO},
  author       = {Rani, Pratibha and Mishra, Arunodaya Raj and Pardasani, Kamal Raj},
  doi          = {10.1007/s00500-019-04065-5},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {2355-2367},
  shortjournal = {Soft Comput.},
  title        = {A novel WASPAS approach for multi-criteria physician selection problem with intuitionistic fuzzy type-2 sets},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Gas chimney and hydrocarbon detection using combined BBO and
artificial neural network with hybrid seismic attributes. <em>SOCO</em>,
<em>24</em>(3), 2341–2354. (<a
href="https://doi.org/10.1007/s00500-019-04064-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exact interpretation of structure of the Earth is essential to avoid drilling of dry holes or locating hydrocarbon reservoirs in faulty regions. The economic approaches are required to locate the reservoirs without damaging the tectonic plates of the Earth. The identification of gas chimneys provides an impressive approach to indirectly interpret the hydrocarbon reservoirs as the chimneys form the migration pathway for gas from reservoirs, and it looks like a gas cloud in the seismic data. The proposed method using biogeography-based optimization (BBO) with supervised neural networks enables the effective interpretation of chimneys and hydrocarbons. Seismic attributes are measured on the pre-processed seismic data, where the attributes play an important role in providing qualitative information on structure of the Earth. Continuity, instantaneous and amplitude attributes are measured to provide the details on the areas of discontinuity, bright-spot regions with high amplitude and low frequency. The calculated attributes are picked from selected locations in the pre-processed seismic data, and the hybrid combination of attributes enables effective, economic chimney identification and provides indications to locate the reservoirs. The redundant and highly correlated features are eliminated using BBO which in turn improves the classification accuracy. BBO algorithm retains the best solution in each generation, and the fitness of the algorithm is verified with supervised neural networks. The proposed algorithm is applied on F3 block dataset, and BBO selects 20 predominant features among 75 features. The optimal solution after 50 generations enables the classification of chimneys through multilayer feed-forward supervised neural network. The results indicate that the chimney classification accuracy is improved by 90\%, and the mean square error is minimized with BBO as a feature selection algorithm compared to other evolutionary algorithms.},
  archive      = {J_SOCO},
  author       = {Ramya, J. and Somasundareswari, D. and Vijayalakshmi, P.},
  doi          = {10.1007/s00500-019-04064-6},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {2341-2354},
  shortjournal = {Soft Comput.},
  title        = {Gas chimney and hydrocarbon detection using combined BBO and artificial neural network with hybrid seismic attributes},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Weighted belief function of sensor data fusion in engine
fault diagnosis. <em>SOCO</em>, <em>24</em>(3), 2329–2339. (<a
href="https://doi.org/10.1007/s00500-019-04063-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault diagnosis (the process of finding out whether system or equipment is in fault and where the corresponding fault is by using various inspection and testing method) on the engine is a typical information fusion (the process of integrating multiple data sources to produce more consistent, accurate, and useful information than that provided by any individual data source) problem where the information can be obtained from engine vibration, temperature, pressure, etc. Due to the efficiency of data fusion, Dempster–Shafer evidence theory is widely used in fault diagnosis. One key step to using evidence theory is to obtain the so-called basic probability assignment (BPA), or belief function. In this article, a new mathematical framework is presented to determine weighted BPA (WBPA). This WBPA function is obtained by weighting the distance between sample data and empirical data. With the assumption that the empirical data are normally distributed, the weighting factor can be determined. Then, the WBPA can be combined with D–S evidence theory to determine the status of the engine. Finally, a case in fault diagnosis and comparison with Song and Jiang (Adv Mech Eng 8(10):1–16, 2016) method illustrate the efficiency of the proposed method.},
  archive      = {J_SOCO},
  author       = {Zhang, Hepeng and Deng, Yong},
  doi          = {10.1007/s00500-019-04063-7},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {2329-2339},
  shortjournal = {Soft Comput.},
  title        = {Weighted belief function of sensor data fusion in engine fault diagnosis},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A robust 2D-cochlear transform-based palmprint recognition.
<em>SOCO</em>, <em>24</em>(3), 2311–2328. (<a
href="https://doi.org/10.1007/s00500-019-04062-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a noise-robust palmprint recognition system is discussed with a novel feature extraction technique: two-dimensional Cochlear transform (2D-CT) based on the textural analysis of image sample. Orthogonality of 2D-CT is proved which shows the high robustness of the proposed 2D-CT to noise. To validate the proposed feature extraction technique, palmprint recognition has been tested on both left and right palm of IITD database of 230 persons, CASIA palmprint database of 312 persons, polyU palmprint database of 386 persons and achieved high accuracy. The proposed 2D-CT method is compared with discriminative and robust competitive code, double orientation code, competitive coding, ordinal coding, Gabor transform, Gaussian membership-based features, absolute average deviation and mean features. Further, K-nearest neighbor is used to validate the matching stage. The results show superiority of the proposed method over other feature extraction methods.},
  archive      = {J_SOCO},
  author       = {Chaudhary, Gopal and Srivastava, Smriti},
  doi          = {10.1007/s00500-019-04062-8},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {2311-2328},
  shortjournal = {Soft Comput.},
  title        = {A robust 2D-cochlear transform-based palmprint recognition},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Tauberian theorems for <span
class="math display">$$(\overline{N},p,q)$$</span> summable double
sequences of fuzzy numbers. <em>SOCO</em>, <em>24</em>(3), 2301–2310.
(<a href="https://doi.org/10.1007/s00500-019-04060-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we define the weighted mean method $$(\overline{N},p,q)$$ of double sequences of fuzzy numbers and give necessary and sufficient Tauberian conditions under which convergence in Pringsheim’s sense of a double sequence of fuzzy numbers follows from its $$(\overline{N},p,q)$$ summability. These conditions are weaker than the weighted analogues of Landau’s conditions and Schmidt’s slow oscillation condition in some senses for two-dimensional case.},
  archive      = {J_SOCO},
  author       = {Totur, Ümit and Çanak, İbrahim},
  doi          = {10.1007/s00500-019-04060-w},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {2301-2310},
  shortjournal = {Soft Comput.},
  title        = {Tauberian theorems for $$(\overline{N},p,q)$$ summable double sequences of fuzzy numbers},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel interval-valued intuitionistic trapezoidal fuzzy
combinative distance-based assessment (CODAS) method. <em>SOCO</em>,
<em>24</em>(3), 2287–2300. (<a
href="https://doi.org/10.1007/s00500-019-04059-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple Attribute Decision Making (MADM) problems have received great attention from many researchers over the past decades. Many useful models and methods have been developed and applied in diverse fields. The objective of this paper is to integrate newly developed COmbinative Distance-based ASsessment (CODAS) method and Interval-Valued Intuitionistic Trapezoidal Fuzzy Set (IVITrFS) to cope with MADM problems. In the proposed method, IVITrFS is used considering membership and non-membership degrees of elements to handle more complex and flexible data than the ordinary fuzzy sets and their extensions. In addition, there has been no work extending CODAS method with IVITrFS to solve MADM problems in the literature. To illustrate applicability and effectiveness of the proposed method, a numerical example is employed for the selection of the most suitable investment project. A sensitivity analysis is applied to examine the stability and validity of the proposed approach. Then, the obtained results of the proposed method are compared with the existing methods to confirm the efficiency and reliability of the proposed method. Accordingly, the proposed IVITrFS-CODAS method is superior to CODAS, ordinary fuzzy CODAS and interval-valued Atanassov intuitionistic fuzzy CODAS (IVAIF-CODAS) methods since IVITrFS-CODAS deals with the hesitancy and fuzziness of human thinking better in decision-making process and provides larger domain for decision makers by assigning membership and non-membership scores in the interval between 0 (non-membership) and 1 (full membership). Finally, concluding remarks are presented at the end of the study.},
  archive      = {J_SOCO},
  author       = {Seker, Sukran},
  doi          = {10.1007/s00500-019-04059-3},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {2287-2300},
  shortjournal = {Soft Comput.},
  title        = {A novel interval-valued intuitionistic trapezoidal fuzzy combinative distance-based assessment (CODAS) method},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel parallel object-tracking behavior algorithm based on
dynamics for data clustering. <em>SOCO</em>, <em>24</em>(3), 2265–2285.
(<a href="https://doi.org/10.1007/s00500-019-04058-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, many evolutionary algorithms (EAs) have been used to solve clustering problem. However, compared to K-means which is a simple and fast clustering algorithm, these EA-based clustering algorithms take too much computation time. In addition, the parameters of most EAs are fixed or dynamical adjustment by a simple method on different datasets, and it will cause that the performance of these algorithms is good on some datasets but bad on others. In order to overcome these disadvantages, a novel parallel object-tracking behavior algorithm (POTBA) based on dynamics is proposed in this paper. The proposed algorithm consists of three different models which are parallel object-tracking model, parameters self-learning model and energy model, respectively. First, the parallel object-tracking model is designed to accelerate the computation speed and avoid local minima. Second, the parameters of POTBA are self-adjusted by the parameters self-learning model. Third, the energy model is introduced to depict energy changes of POTBA during the evolutionary process. The correctness and convergence properties of POTBA are analyzed theoretically. Moreover, the effectiveness and parallelism of POTBA are evaluated through several standard datasets, and the experimental results demonstrate that POTBA exhibits superior overall performance than five other state-of-the-art algorithms. In the aspect of search performance, the results of POTBA are better than other comparison algorithms on most used datasets. In the aspect of time performance, the time overhead of POTBA is significantly reduced through parallel computing. When the number of processors increases to 32, the computation time of POTBA is less or close to K-means which is the fastest comparison algorithm.},
  archive      = {J_SOCO},
  author       = {Feng, Xiang and Lai, Zhaolin and Yu, Huiqun},
  doi          = {10.1007/s00500-019-04058-4},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {2265-2285},
  shortjournal = {Soft Comput.},
  title        = {A novel parallel object-tracking behavior algorithm based on dynamics for data clustering},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Design concept evaluation using soft sets based on
acceptable and satisfactory levels: An integrated TOPSIS and shannon
entropy. <em>SOCO</em>, <em>24</em>(3), 2229–2263. (<a
href="https://doi.org/10.1007/s00500-019-04055-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Among several phases of new product development, concept selection is the most crucial activity and it gives perfection to further progress of a product. Customer’s ideas and linguistic requirements are often substantial in concept specifications to assess quantitative criteria, which gives satisfaction for a product to progress in the markets. This work aggregates concept selection on design parameters values by merging acceptable- and satisfactory-level needs of the customers. A promising framework is developed based on soft sets, TOPSIS and the Shannon entropy. Customer’s preferences on incorporating design values are identified based on acceptable- and satisfactory-level needs, and these preferences are weighted through Shannon entropy. By performing AND operation on the soft set of level requirements of one customer with the soft set of requirements of another customer, several weighted tables of soft sets are obtained on the pair of design parameters values. To obtain the best concept on different levels of requirements, TOPSIS is performed which provides several integrated evaluations. An illustration is considered for the demonstration of the method, brings the best concept for two customers which is acceptable for both of the customers, satisfactory for both the customers and vise-versa. Finally, the comparisons are presented with recent major existing methods.},
  archive      = {J_SOCO},
  author       = {Hayat, Khizar and Ali, Muhammad Irfan and Karaaslan, Faruk and Cao, Bing-Yuan and Shah, Mubashar Hussain},
  doi          = {10.1007/s00500-019-04055-7},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {2229-2263},
  shortjournal = {Soft Comput.},
  title        = {Design concept evaluation using soft sets based on acceptable and satisfactory levels: An integrated TOPSIS and shannon entropy},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Intuitionistic fuzzy TOPSIS method for green supplier
selection problem. <em>SOCO</em>, <em>24</em>(3), 2215–2228. (<a
href="https://doi.org/10.1007/s00500-019-04054-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most important functions of supply chain management is to enhance competitive pressure. Competition conditions and customer perception have changed in favor of environmentalist attitude. Therefore, green supplier selection (GSS) has become an important issue. In this study, the problem of GSS aiming for lean, agile, environmentally sensitive, sustainability, and durability is addressed. The environmental criteria considered in GSS and classical supplier selection are different from each other in terms of carbon footprint, water consumption, environmental applications, and recycling applications. The Technique for Order Preference by Similarity to Ideal Solution (TOPSIS) method has been used in the problem of GSS by considering the multi-criteria decision-making (MCDM) method since MCDM is very effective in many aspects such as evaluating and selecting the classical and environmental criteria. Due to linguistic criteria and no possibility to measure all criteria, it is needed to consolidate the fuzzy approach with the TOPSIS method to reduce the effects of ambiguity and instability. The Intuitionistic Fuzzy TOPSIS method is used because this method makes evaluating decision-makers and criteria convenient. According to the criteria determined by the order of importance, the hybrid method resulting from combining the Intuitionistic Fuzzy Set and TOPSIS is very effective to select which supplier is more suitable among the alternatives and also this method can be integrated to similar problems.},
  archive      = {J_SOCO},
  author       = {Rouyendegh, Babak Daneshvar and Yildizbasi, Abdullah and Üstünyer, Pelin},
  doi          = {10.1007/s00500-019-04054-8},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {2215-2228},
  shortjournal = {Soft Comput.},
  title        = {Intuitionistic fuzzy TOPSIS method for green supplier selection problem},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Peer-induced fairness capacitated vehicle routing scheduling
using a hybrid optimization ACO–VNS algorithm. <em>SOCO</em>,
<em>24</em>(3), 2201–2213. (<a
href="https://doi.org/10.1007/s00500-019-04053-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address the problem of delivering a given amount of goods in emergency relief distribution. This problem is considered to be a specific case of capacitated vehicle routing. As a novel issue, peer-induced fairness concern is aimed at securing more customers’ needs by introducing the peer-induced fairness coefficient, which is the value of the population size divided by direct travel time. Thus, a peer-induced fairness capacitated vehicle routing scheduling model is proposed to handle the trade-off between timeliness and fairness in emergency material delivery. To solve the specific NP-hard capacitated vehicle routing problem, the properties of this problem are analysed, and an improved hybrid ACO–VNS algorithm based on ant colony optimization and variable neighbourhood search algorithm with five neighbourhood structures is accordingly presented. A comparison of the proposed algorithm with CPLEX and common optimization algorithms demonstrates that this method achieves better performance in a shorter time and is an efficient way to solve the vehicle routing scheduling problem in emergency relief distribution.},
  archive      = {J_SOCO},
  author       = {Wu, Yifan and Pan, Fan and Li, Shuxia and Chen, Zhen and Dong, Ming},
  doi          = {10.1007/s00500-019-04053-9},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {2201-2213},
  shortjournal = {Soft Comput.},
  title        = {Peer-induced fairness capacitated vehicle routing scheduling using a hybrid optimization ACO–VNS algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). SCRM: Self-correlated representation model for visual
tracking. <em>SOCO</em>, <em>24</em>(3), 2187–2199. (<a
href="https://doi.org/10.1007/s00500-019-04052-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse representation (SR) as a seminal model for visual tracking explores the relationship between all candidates and the observed templates. Different from SR-based trackers, we propose a self-correlated representation model for robust visual tracking. Firstly, we learn a low-dimensional subspace representation from highly correlated templates to model the object, which aims at eliminating the redundant information and reducing the influence of noisy templates. Then, we represent the subspace by itself to learn the inner underlying features from subspace vectors. To further enhance model’s discriminating power, a new observation model is developed by considering both error distribution and large outliers. Experiments are conducted on some challenging video clips and demonstrate the favorable performance of our tracking system compared to some state-of-the-art representation-based trackers.},
  archive      = {J_SOCO},
  author       = {Jiang, Shengqin and Lu, Xiaobo and Cheng, Fengna},
  doi          = {10.1007/s00500-019-04052-w},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {2187-2199},
  shortjournal = {Soft Comput.},
  title        = {SCRM: Self-correlated representation model for visual tracking},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A hybrid genetic algorithm for the degree-constrained
minimum spanning tree problem. <em>SOCO</em>, <em>24</em>(3), 2169–2186.
(<a href="https://doi.org/10.1007/s00500-019-04051-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given an undirected, connected, edge-weighted graph G and a positive integer d, the degree-constrained minimum spanning tree (dc-MST) problem aims to find a minimum spanning tree T on G subject to the constraint that each vertex is either a leaf vertex or else has degree at most d in T, where d is a given positive integer. The dc-MST is $$\mathcal {NP}$$-hard problem for d$$\ge $$ 2 and finds several real-world applications. This paper proposes a hybrid approach ($$\mathcal {H}$$SSGA) combining a steady-state genetic algorithm and local search strategies for the this problem. An additional step (based on perturbation strategy at a regular interval of time) in the replacement strategy is applied in order to maintain diversity in the population throughout the search process. On a set of available 107 benchmark instances, computational results show the superiority of our proposed $$\mathcal {H}$$SSGA in comparison with the state-of-the-art metaheuristic techniques.},
  archive      = {J_SOCO},
  author       = {Singh, Kavita and Sundar, Shyam},
  doi          = {10.1007/s00500-019-04051-x},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {2169-2186},
  shortjournal = {Soft Comput.},
  title        = {A hybrid genetic algorithm for the degree-constrained minimum spanning tree problem},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). FuzzyCIE: Fuzzy colour image enhancement for low-exposure
images. <em>SOCO</em>, <em>24</em>(3), 2151–2167. (<a
href="https://doi.org/10.1007/s00500-019-04048-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Colour image enhancement not only is of high importance in consumer electronics, but also plays significant role in medical imaging, remotely sensed imaging, etc. Moreover, low-exposure colour images inherently lack sufficient image details which are exclusively necessary for workings in these domains. To address this less explored problem, a novel enhancement algorithm involving estimation of the fuzzy histogram with thresholding based on the computed effect of exposure value has been proposed. The algorithm operates on the lightness ($$L^{*}$$) component of the input image in $$L^{*}a^{*}b^{*}$$ colour space, while preserving the colour-opponent dimensions ($$a^{*} $$ and $$ b^{*}$$) to maintain the natural outlook of the image. This technique has been experimentally demonstrated over a dataset consisting of images generated at different exposure levels. Quantitative and qualitative analysis of the relative performance of the proposed algorithm has been shown with respect to state-of-the-art enhancement algorithms over the $$L^{*}a^{*}b^{*}$$ space.},
  archive      = {J_SOCO},
  author       = {Mandal, Soham and Mitra, Sushmita and Shankar, B. Uma},
  doi          = {10.1007/s00500-019-04048-6},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {2151-2167},
  shortjournal = {Soft Comput.},
  title        = {FuzzyCIE: Fuzzy colour image enhancement for low-exposure images},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An effective quality analysis of XML web data using hybrid
clustering and classification approach. <em>SOCO</em>, <em>24</em>(3),
2139–2150. (<a
href="https://doi.org/10.1007/s00500-019-04045-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An effective quality analysis of XML web data using clustering and classification approach is used in our proposed method. XML is turning into a standard in representation of data, it is attractive to support keyword search in XML database. A keyword search searches for words anyplace in record. It is developed as best worldview for finding data on web. The most imperative prerequisite for the keyword search is to rank the consequences of question so that the most pertinent outcomes show up. Here, we gather more XML documents. Followed by that, feature extraction occurs. Since the selected feature contains both relevant as well as irrelevant features it is essential to filter the irrelevant features. For the purpose of selecting, the relevant features probability-based feature selection method is used. Then for clustering the relevant features on the basis of keywords weighted fuzzy c means clustering algorithm is used. In order to assess the XML data quality, optimal neural network (ONN) classifier is utilized. In this ONN classifier in order to select the optimal weights, whale optimization algorithm is used. Thus, the web pages are effectively ranked. The efficiency of the proposed method is assessed using clustering and classification accuracy, RMSE, and search time. The proposed method is implemented in JAVA.},
  archive      = {J_SOCO},
  author       = {Gopianand, M. and Jaganathan, P.},
  doi          = {10.1007/s00500-019-04045-9},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {2139-2150},
  shortjournal = {Soft Comput.},
  title        = {An effective quality analysis of XML web data using hybrid clustering and classification approach},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). On generalizations of fuzzy quasi-prime ideals in <span
class="math display">ℒ𝒜</span>-semigroups. <em>SOCO</em>,
<em>24</em>(3), 2125–2137. (<a
href="https://doi.org/10.1007/s00500-019-04043-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we extend the concept of fuzzy subsets given by Zadeh (Inf Control 8:338–353, 1965) to the context of $$^{\alpha }$$-fuzzy and $$_{\alpha }$$-fuzzy subsets. The aim of this paper is to investigate the concept of $$^{\alpha }$$-fuzzy and $$_{\alpha }$$-fuzzy subsets in $${{\mathcal {L}}}{{\mathcal {A}}}$$-semigroups. Some characterizations of $$(\alpha , \beta )$$-fuzzy $${{\mathcal {L}}}{{\mathcal {A}}}$$-subsemigroup, $$(\alpha , \beta )$$-fuzzy left, $$(\alpha , \beta )$$-fuzzy completely prime and $$(\alpha , \beta )$$-fuzzy quasi-prime ideals are obtained. Moreover, we investigate relationships between $$(\alpha , \beta )$$-fuzzy completely prime and $$(\alpha , \beta )$$-fuzzy quasi-prime ideals of $${{\mathcal {L}}}{{\mathcal {A}}}$$-semigroups. Finally, we obtain sufficient conditions of an $$(\alpha , \beta )$$-fuzzy quasi-prime ideal in order to be an $$(\alpha , \beta )$$-fuzzy completely prime subset.},
  archive      = {J_SOCO},
  author       = {Yiarayong, Pairote},
  doi          = {10.1007/s00500-019-04043-x},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {2125-2137},
  shortjournal = {Soft Comput.},
  title        = {On generalizations of fuzzy quasi-prime ideals in $${{\mathcal {L}}}{{\mathcal {A}}}$$-semigroups},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Application of artificial neural network (ANN) for
estimating reliable service life of reinforced concrete (RC) structure
bookkeeping factors responsible for deterioration mechanism.
<em>SOCO</em>, <em>24</em>(3), 2109–2123. (<a
href="https://doi.org/10.1007/s00500-019-04042-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Degradation of RC structures due to corrosion induced mechanism in the reinforcing steel is a serious durability problem worldwide. It occurs essentially when the reinforcement within the concrete is subjected to marine or aggressive environment. The aim of the present work is to predict the reliable service life of the RC structures by taking into consideration of various prominent models of corrosion and comparing the output with the predicted output of ANN model. Parametric studies have been conducted on four different models to study the effect of various parameters such as corrosion rate, cover thickness, bar diameter, and perimeter of bar which actively participates in the time dependent degradation of RC structures. The outcomes of the parametric inspection of the four chosen degradation models are shown in the present study. The acceptability of the prediction models in forecasting the service life of RC structures are shown through circumstantial illustrative analysis and the best suited model sorted out. However, with the application of soft computing such as ANN, a prediction has been made to determine the service life of RC structures, and the predicted outputs validated with the intended outputs thereby yielding good outcomes for envisaging service life of RC structure.},
  archive      = {J_SOCO},
  author       = {Dey, Abhijeet and Miyani, Ghanashyam and Sil, Arjun},
  doi          = {10.1007/s00500-019-04042-y},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {2109-2123},
  shortjournal = {Soft Comput.},
  title        = {Application of artificial neural network (ANN) for estimating reliable service life of reinforced concrete (RC) structure bookkeeping factors responsible for deterioration mechanism},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Data sharing using proxy re-encryption based on DNA
computing. <em>SOCO</em>, <em>24</em>(3), 2101–2108. (<a
href="https://doi.org/10.1007/s00500-019-04041-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud data sharing allows users to access data stored on the web object. Security and protecting cloud data sharing form different attacks is recently considered one of the most challenges. In this paper, we are proposing a framework for cloud data sharing protection against unauthorized access. The proposed framework is based on DNA-proxy re-encryption. Firstly, three keys are generated for the owner, proxy and the user who need to access the data. Then, the owner stores his data encrypted on the cloud using his key. If the user wants to access this data then he can access it via the proxy after re-encrypting using the second generated key for the proxy. Finally, the user can decrypt the re-encrypted data with the third generated key. The framework was implemented using various plaintext files and real DNA sequences. The experimental results show that the framework has an outstanding performance in terms of execution time.},
  archive      = {J_SOCO},
  author       = {Elhadad, Ahmed},
  doi          = {10.1007/s00500-019-04041-z},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {2101-2108},
  shortjournal = {Soft Comput.},
  title        = {Data sharing using proxy re-encryption based on DNA computing},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Normative fish swarm algorithm (NFSA) for optimization.
<em>SOCO</em>, <em>24</em>(3), 2083–2099. (<a
href="https://doi.org/10.1007/s00500-019-04040-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a swarm-based optimization algorithm, normative fish swarm algorithm (NFSA) is proposed as an effective global and local search technique to obtain effective global optima at superior convergence speed. Artificial fish swarm algorithm is a recent swarm-based algorithm that imitates the behavior of fish swarm in the real environment. Many improvements and modifications have been proposed regularly on fish swarm algorithm to improve the performance of optimization, but to date, existing fish swarm algorithms have not yet obtained a global optimum at extremely superior convergence rates. Hence, there still remains a huge potential for the development of fish swarm algorithm. NFSA hybridizes the characteristics of PSOEM-FSA with the normative knowledge as the complementary guidelines for more accurate and precise global optimum approaching. NFSA further improves the adaptive parameters in term of visual and step to balance the contradiction between the exploration and exploitation processes. Random initialization of the initial population is introduced to spread out the solution candidates of artificial fishes over the solution space. For the purpose of experiments, ten benchmark functions have been used in the evaluation process. The proposed algorithm is then compared with other related algorithms published in the literature. The results proved that the proposed NFSA achieved superior results in terms of convergence rate and best optimal solution on a majority of the tested benchmark functions in comparison with other comparative algorithms.},
  archive      = {J_SOCO},
  author       = {Tan, Weng-Hooi and Mohamad-Saleh, Junita},
  doi          = {10.1007/s00500-019-04040-0},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {2083-2099},
  shortjournal = {Soft Comput.},
  title        = {Normative fish swarm algorithm (NFSA) for optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Aggregating expert advice strategy for online portfolio
selection with side information. <em>SOCO</em>, <em>24</em>(3),
2067–2081. (<a
href="https://doi.org/10.1007/s00500-019-04039-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online portfolio selection is an important fundamental problem in computational finance, which has been further developed in recent years. As the financial market changes rapidly, investors need to dynamically adjust asset positions according to various financial market information. However, existing online portfolio strategies are always designed without considering this information, which limits their practicability to some extent. To overcome this limitation, this paper exploits the available side information and presents a novel online portfolio strategy named “WAACS”. Specifically, all the constant rebalanced portfolio strategies are considered as experts and the weak aggregating algorithm is applied to aggregate all the expert advice according to their previous cumulative returns under the same side information state as the current period. Furthermore, WAACS is theoretically proved to be a universal portfolio, i.e., its growth rate is asymptotically the same as that of the best state constant rebalanced portfolio, which is a benchmark strategy considering side information. Numerical experiments show that WAACS achieves significant performance and demonstrate that considering side information improves the performance of the proposed strategy.},
  archive      = {J_SOCO},
  author       = {Yang, Xingyu and He, Jin’an and Xian, Jiayi and Lin, Hong and Zhang, Yong},
  doi          = {10.1007/s00500-019-04039-7},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {2067-2081},
  shortjournal = {Soft Comput.},
  title        = {Aggregating expert advice strategy for online portfolio selection with side information},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Structural risk minimization of rough set-based classifier.
<em>SOCO</em>, <em>24</em>(3), 2049–2066. (<a
href="https://doi.org/10.1007/s00500-019-04038-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classification ability in unseen objects, namely generalization ability, remains a long-standing challenge in rough set-based classifier. Current research mainly focuses on introducing thresholds to tolerate some errors in seen objects. The reason for introducing thresholds and the selection of threshold still lack sufficient theoretical support. The structural risk minimization (SRM) inductive principle is one of the most effective theories to control the generalization ability, which suggests a trade-off between errors in seen objects and complexity. Therefore, this paper introduces the SRM principle into rough set-based classifier and proposes SRM algorithm of rough set-based classifier called SRM-R algorithm. SRM-R algorithm uses the number of rules to characterize the actual complexity of rough set-based classifier and obtains the optimal trade-off between errors in seen objects and complexity through genetic multi-objective optimization. The tenfold cross-validation experiment in 12 UCI datasets shows SRM-R algorithm can significantly improve the generalization ability compared with conventional threshold algorithm. Besides, this paper uses other two possible complexity metrics including the number of attributes and attribute space to construct corresponding SRM algorithms, respectively, and compared their classification accuracy with that of SRM-R algorithm. Comparison result shows SRM-R algorithm obtains optimal classification accuracy. This indicates that the number of rules characterizes the complexity more effectively than the number of attributes and attribute space. Further experiments show that SRM-R algorithm obtains fewer rules and larger support coefficient, which means it extracts stronger rules. This explains why it obtains better generalization ability to some extent.},
  archive      = {J_SOCO},
  author       = {Liu, Jinfu and Bai, Mingliang and Jiang, Na and Yu, Daren},
  doi          = {10.1007/s00500-019-04038-8},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {2049-2066},
  shortjournal = {Soft Comput.},
  title        = {Structural risk minimization of rough set-based classifier},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Intelligent sales volume forecasting using google search
engine data. <em>SOCO</em>, <em>24</em>(3), 2033–2047. (<a
href="https://doi.org/10.1007/s00500-019-04036-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Business forecasting is a critical organizational capability for both strategic and tactical business planning. Improving the quality of forecasts is thus an important organization goal. In this paper, the intelligent sales volume forecasting models are constructed using grey analysis, deep learning (DNN), and least-square support vector regression (LSSVR) optimized through particle swarm optimization or genetic algorithm. First, features (predictors) from economic variables are extracted through grey analysis. The selected features together with Google Index, an exogenous variable used widely by researchers, are then used as the inputs to the DNN and LSSVR to build the models. The experimental results indicate that the grey DNN model, an emerging and pioneering artificial intelligence technology, can accurately predict sales volumes based on non-parametric statistical tests. DNN also outperformed the competing models when using Google Index.},
  archive      = {J_SOCO},
  author       = {Yuan, Fong-Ching and Lee, Chao-Hui},
  doi          = {10.1007/s00500-019-04036-w},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {2033-2047},
  shortjournal = {Soft Comput.},
  title        = {Intelligent sales volume forecasting using google search engine data},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel hybrid multi-objective bacterial colony chemotaxis
algorithm. <em>SOCO</em>, <em>24</em>(3), 2013–2032. (<a
href="https://doi.org/10.1007/s00500-019-04034-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, a novel hybrid multi-objective bacterial colony chemotaxis (HMOBCC) algorithm is proposed to solve multi-objective optimization problems. A mechanism of particle swarm optimization is introduced to multi-objective bacterial colony chemotaxis (MOBCC) algorithm to improve the performance of MOBCC algorithm. Also, three other techniques, including dynamic reverse learning operator, external archive multiplying operator and adaptive diversity maintenance operator, are further applied to improve the diversity and convergence of the algorithm. The proposed algorithm is validated using 12 benchmark problems, and three performance measures are implemented for 5 benchmark problems to compare its performance with existing popular algorithms such as MOBCC, multi-objective bacterial colony chemotaxis based on grid algorithm, non-dominated sorting genetic algorithm (NSGA-II) and multi-objective evolutionary algorithm based on decomposition. The results show that the proposed HMOBCC is very effective against existing algorithms. The graphical abstract of this study.},
  archive      = {J_SOCO},
  author       = {Lu, Zhigang and Geng, Lijun and Huo, Guanghao and Zhao, Hao and Yao, Weitao and Li, Guoqiang and Guo, Xiaoqiang and Zhang, Jiangfeng},
  doi          = {10.1007/s00500-019-04034-y},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {2013-2032},
  shortjournal = {Soft Comput.},
  title        = {A novel hybrid multi-objective bacterial colony chemotaxis algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep packet: A novel approach for encrypted traffic
classification using deep learning. <em>SOCO</em>, <em>24</em>(3),
1999–2012. (<a
href="https://doi.org/10.1007/s00500-019-04030-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network traffic classification has become more important with the rapid growth of Internet and online applications. Numerous studies have been done on this topic which have led to many different approaches. Most of these approaches use predefined features extracted by an expert in order to classify network traffic. In contrast, in this study, we propose a deep learning-based approach which integrates both feature extraction and classification phases into one system. Our proposed scheme, called “Deep Packet,” can handle both traffic characterization in which the network traffic is categorized into major classes (e.g., FTP and P2P) and application identification in which identifying end-user applications (e.g., BitTorrent and Skype) is desired. Contrary to most of the current methods, Deep Packet can identify encrypted traffic and also distinguishes between VPN and non-VPN network traffic. The Deep Packet framework employs two deep neural network structures, namely stacked autoencoder (SAE) and convolution neural network (CNN) in order to classify network traffic. Our experiments show that the best result is achieved when Deep Packet uses CNN as its classification model where it achieves recall of 0.98 in application identification task and 0.94 in traffic categorization task. To the best of our knowledge, Deep Packet outperforms all of the proposed classification methods on UNB ISCX VPN-nonVPN dataset.},
  archive      = {J_SOCO},
  author       = {Lotfollahi, Mohammad and Jafari Siavoshani, Mahdi and Shirali Hossein Zade, Ramin and Saberian, Mohammdsadegh},
  doi          = {10.1007/s00500-019-04030-2},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {1999-2012},
  shortjournal = {Soft Comput.},
  title        = {Deep packet: A novel approach for encrypted traffic classification using deep learning},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Group decision making based on power heronian aggregation
operators under neutrosophic cubic environment. <em>SOCO</em>,
<em>24</em>(3), 1971–1997. (<a
href="https://doi.org/10.1007/s00500-019-04025-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neutrosophic cubic sets can deal with the complex information by combining the neutrosophic sets and cubic sets, the power average (PA) can weaken some effects of awkward data from biased decision makers, and Heronian mean (HM) can deal with the interrelationship between the aggregated attributes or arguments. In this article, in order to consider the advantages of the PA and HM, we combined and extended them to process neutrosophic cubic information. Firstly, we defined a distance measure for neutrosophic cubic numbers, then we presented the neutrosophic cubic power Heronian aggregation operator and neutrosophic cubic power weighted Heronian aggregation operator, and some characters and special cases of these new aggregation operators were investigated. Furthermore, we gave a new approach for multi-attribute group decision making based on new proposed operators. Finally, two examples were given to explain the validity and advantages of the developed approach by comparing with the existing method.},
  archive      = {J_SOCO},
  author       = {Liu, Peide and Khan, Qaisar and Mahmood, Tahir},
  doi          = {10.1007/s00500-019-04025-z},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {1971-1997},
  shortjournal = {Soft Comput.},
  title        = {Group decision making based on power heronian aggregation operators under neutrosophic cubic environment},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stabilization of a class of nonlinear control systems via a
neural network scheme with convergence analysis. <em>SOCO</em>,
<em>24</em>(3), 1957–1970. (<a
href="https://doi.org/10.1007/s00500-019-04024-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the stability of a class of nonlinear control systems is analyzed. We first construct an optimal control problem by inserting a suitable performance index; this problem is referred to as an infinite horizon problem. By a suitable change of variable, the infinite horizon problem is reduced to a finite horizon problem. We then present a feedback controller designing approach for the obtained finite horizon control problem. This approach involves a neural network scheme for solving the nonlinear Hamilton Jacobi Bellman equation. By using the neural network method, an analytic approximate solution for value function and a suboptimal feedback control law are achieved. A learning algorithm based on a dynamic optimization scheme with stability and convergence properties is also provided. Some illustrative examples are employed to demonstrate the accuracy and efficiency of the proposed plan. As a real-life application in engineering, the stabilization of a micro-electromechanical system is studied.},
  archive      = {J_SOCO},
  author       = {Nazemi, Alireza and Mortezaee, Marziyeh},
  doi          = {10.1007/s00500-019-04024-0},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {1957-1970},
  shortjournal = {Soft Comput.},
  title        = {Stabilization of a class of nonlinear control systems via a neural network scheme with convergence analysis},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Integer cat swarm optimization algorithm for multiobjective
integer problems. <em>SOCO</em>, <em>24</em>(3), 1927–1955. (<a
href="https://doi.org/10.1007/s00500-019-04023-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the literature, several variants of cat swarm optimization (CSO) algorithm are reported. However, CSO for integer multiobjective optimization problems (MOPs) has not yet been investigated. Owing to the frequent occurrence of integer MOPs and their importance in practical design problems, in this work, we investigate a new CSO approach for solving purely integer MOPs. This new approach named as multiobjective integer cat swarm optimization (MO-ICSO) algorithm incorporates the modified version of the CSO algorithm for MOPs. This approach is comprised of the concepts of rounding the floating points to the nearest integer numbers and the probabilistic updating (PU) technique. It uses the idea of Pareto dominance for finding the non-dominated solutions and an external archive for storing these solutions. We demonstrate the power of this new approach via its quantitative analysis and sensitivity test of its several parameters using different performance metrics performed over multiobjective multidimensional knapsack problem and several standard test functions. The simulation results argue that the proposed MO-ICSO approach can be a better candidate for solving the integer MOPs.},
  archive      = {J_SOCO},
  author       = {Ali Murtza, Shahid and Ahmad, Ayaz and Shafique, Jawad},
  doi          = {10.1007/s00500-019-04023-1},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {1927-1955},
  shortjournal = {Soft Comput.},
  title        = {Integer cat swarm optimization algorithm for multiobjective integer problems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hybrid model for prediction of heart disease. <em>SOCO</em>,
<em>24</em>(3), 1903–1925. (<a
href="https://doi.org/10.1007/s00500-019-04022-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heart disease is a leading cause of death in the world. In order to drop its rate, effective and timely diagnosis of the disease is very essential. Numerous automated decision support systems have been developed for this purpose. In the present research, a predictive model consisting of two-level optimization is introduced, to save lives and cost via effective diagnosis of the disease. Level-1 optimization of the model first identifies parallelly an optimal proportion (Popt) for training and test sets for each dataset on parallel machine. Next, the best training set (Tbest) for Popt is again searched parallelly. On the other hand, level-2 optimization refines the rule set (R) generated by the Perfect Rule Induction by Sequential Method (PRISM) learner on Tbest employing parallel genetic algorithm. The experimental results obtained by the model over the heart disease datasets (collected from https://archive.ics.uci.edu/ml) are compared and analysed with its base learner and four state-of-the-art learners, namely C4.5 (decision tree-based classifier), Naïve Bayes, neural network and support vector machine. The empirical outcomes (based on the top performance metrics—prediction accuracy, precision, recall, area under curve values, true positive and false positive rates) positively demonstrate that the new model is proficient in undertaking heart disease treatment. Importantly, the prediction accuracy of the presented hybrid model exceeds around 6\% than that of the sequential GA-based hybrid model over almost all the chosen datasets. After all, the proposed system may work as an e-doctor to predict heart attack and assist clinicians to take precautionary steps.},
  archive      = {J_SOCO},
  author       = {Sarkar, Bikash Kanti},
  doi          = {10.1007/s00500-019-04022-2},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {1903-1925},
  shortjournal = {Soft Comput.},
  title        = {Hybrid model for prediction of heart disease},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Solving the set-union knapsack problem by a novel hybrid
jaya algorithm. <em>SOCO</em>, <em>24</em>(3), 1883–1902. (<a
href="https://doi.org/10.1007/s00500-019-04021-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The set-union knapsack problem (SUKP) is a variation of the 0–1 knapsack problem (KP) in which each item is a set of elements, each item has a nonnegative value, and each element has a nonnegative weight. The weight of one item is given by the total weight of the elements in the union of the items’ sets. The SUKP accommodates a number of real-life applications and is more complicated and computationally difficult than the 0–1 KP. In this paper, we propose a novel hybrid Jaya algorithm with double coding (DHJaya) to solve the SUKP. In the DHJaya, double coding is used to represent the individual, which includes the solutions for solving the SUKP by adopting a mapping function. The Jaya algorithm and differential evolution algorithm are combined to improve the exploration ability. To enhance the exploitation ability, the Cauchy mutation is performed on some individuals. Meanwhile, an improved repairing and optimization algorithm (MS-GROA) is proposed to repair the infeasible solutions and optimize the feasible solutions. We test the DHJaya using three sets of SUKP instances to demonstrate its efficiency, and the obtained results are compared with those in the previous study. Extensive experiments show a remarkable performance of the proposed approach.},
  archive      = {J_SOCO},
  author       = {Wu, Congcong and He, Yichao},
  doi          = {10.1007/s00500-019-04021-3},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {1883-1902},
  shortjournal = {Soft Comput.},
  title        = {Solving the set-union knapsack problem by a novel hybrid jaya algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A decentralized multi-authority ciphertext-policy
attribute-based encryption with mediated obfuscation. <em>SOCO</em>,
<em>24</em>(3), 1869–1882. (<a
href="https://doi.org/10.1007/s00500-019-04018-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To ensure security and obtain fine-grained data access control policies in many management domains, multi-authority attribute-based encryption (MA-ABE) schemes were presented and have been applied in cloud storage system. There exist certain scenes where the application domains managed by different attribute authorities ($$ AAs $$) often change, and hence domain managements require more autonomous and independent. However, most of existing schemes do not support flexible managements. In order to support dynamic managements, we propose a new decentralized ciphertext-policy MA-ABE scheme with mediated obfuscation (MA-DCP-ABE-WMO) where each of $$ AAs $$ works independently without any interaction with other $$ AAs $$. When issuing a secret key to a user, each of $$ AAs $$ uses his secret to compute a share of the system master secret. Data are encrypted under the public keys of attribute management domains. To resist collusion attack, a common pseudorandom function $$ PRF( \cdot ) $$ is shared among $$ AAs $$ and is used to randomize each user’s global identifier $$ Gid $$. The randomized $$ Gid $$ is adopted to unify all target messages which need to be reconstructed from different management domains. We first introduce the mediated obfuscation (MO) model into MA-ABE scheme to provide online service and the interaction works among data owner, data user and the mediator. In the MO model, we define a special functional encryption scheme where the function program can be coded into an element of the multiplicative cyclic group. We obfuscate the function by randomly selecting a blinding factor to conduct exponent arithmetic with the base of the function. A special input of the function is constructed to cancel the blinding factor when calling the obfuscated function. It makes other participants know nothing about the inner function program but can evaluate the function program. Furthermore, the MA-DCP-ABE-WMO scheme is proved to be secure. Compared with related schemes, our scheme is suitable to dynamic domain managements. When the management domains are added or removed, the workload to update original ciphertexts and private keys is dramatically reduced.},
  archive      = {J_SOCO},
  author       = {Li, Jiguo and Hu, Shengzhou and Zhang, Yichen and Han, Jinguang},
  doi          = {10.1007/s00500-019-04018-y},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {1869-1882},
  shortjournal = {Soft Comput.},
  title        = {A decentralized multi-authority ciphertext-policy attribute-based encryption with mediated obfuscation},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Classification of gait patterns in patients with unilateral
anterior cruciate ligament deficiency based on phase space
reconstruction, euclidean distance and neural networks. <em>SOCO</em>,
<em>24</em>(3), 1851–1868. (<a
href="https://doi.org/10.1007/s00500-019-04017-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The anterior cruciate ligament (ACL) is one of the most important structures of the knee joint which plays a significant role in controlling knee joint stability. Patients with unilateral ACL deficiency often show alterations of their gait patterns in the deficient side in comparison with the unaffected contralateral side. Gait analysis is widely used to detect biomechanical changes in the lower limbs, aiming at diagnosing ACL injury, establishing physical therapy treatments or surgery, monitoring the progression of ACL deficiency over time. This paper proposes new combined methods to classify gait patterns between ACL deficient (ACL-D) knee and contralateral ACL-intact (ACL-I) knee in patients with unilateral ACL deficiency by using phase space reconstruction (PSR), Euclidean distance (ED) and neural networks. First knee, hip and ankle kinematic parameters are extracted and phase space has been reconstructed. The properties associated with the gait system dynamics are preserved in the reconstructed phase space. For the purpose of classification of ACL-D and ACL-I knee gait patterns, three-dimensional (3D) PSR together with EDs has been used. These measured parameters show significant difference in gait dynamics between the two groups and have been utilized to form the feature set. Neural networks are then used as the classifier to distinguish between ACL-D and ACL-I knee gait patterns based on the difference of gait dynamics between the two groups. Finally, experiments are carried out on forty-three patients to assess the effectiveness of the proposed method. By using the leave-one-out cross-validation style under normal and fast walking speed conditions, the correct classification rates for discriminating between ACL-D and ACL-I knees are reported to be $$95.4\%$$ and $$93.3\%$$, respectively. Compared with other state-of-the-art methods, the results demonstrate superior performance and support the validity of the proposed method.},
  archive      = {J_SOCO},
  author       = {Zeng, Wei and Ismail, Shiek Abdullah and Pappas, Evangelos},
  doi          = {10.1007/s00500-019-04017-z},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {1851-1868},
  shortjournal = {Soft Comput.},
  title        = {Classification of gait patterns in patients with unilateral anterior cruciate ligament deficiency based on phase space reconstruction, euclidean distance and neural networks},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). N-ary cartesian composition of automata. <em>SOCO</em>,
<em>24</em>(3), 1837–1849. (<a
href="https://doi.org/10.1007/s00500-019-04015-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In our paper, we construct Cartesian composition of automata in a way rather different from the classical approach. In our case, the resulting structure is not an automaton but a quasi-multiautomaton, i.e., a structure whose input alphabet is a semihypergroup instead of a set or a free monoid. In our reasoning, we make use of earlier results on complete (semi)hypergroups and show that this approach not only simplifies our construction but also yields some natural applications.},
  archive      = {J_SOCO},
  author       = {Novák, Michal and Křehlík, Štěpán and Staněk, David},
  doi          = {10.1007/s00500-019-04015-1},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {1837-1849},
  shortjournal = {Soft Comput.},
  title        = {N-ary cartesian composition of automata},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fast curvelet transform through genetic algorithm for
multimodal medical image fusion. <em>SOCO</em>, <em>24</em>(3),
1815–1836. (<a
href="https://doi.org/10.1007/s00500-019-04011-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, medical imaging modalities produce different types of medical images to help doctors to diagnose illnesses or injuries. Each modality of images has its specific intensity. Many researchers in medical imaging have attempted to combine redundancy and related information from multiple types of medical images to produce fused medical images that can provide additional concentration and image diagnosis inspired by the information for the medical examination. We propose a new method and method of fusion for multimodal medical images based on the curvelet transform and the genetic algorithm (GA). The application of GA in our method can solve the suspicions and diffuse existing in the input image and can further optimize the characteristics of image fusion. The proposed method has been tested in many sets of medical images and is also compared to recent medical image fusion techniques. The results of our quantitative evaluation and visual analysis indicate that our proposed method produces the best advantage of medical fusion images over other methods, by maintaining perfect data information and color compliance at the base image.},
  archive      = {J_SOCO},
  author       = {Arif, Muhammad and Wang, Guojun},
  doi          = {10.1007/s00500-019-04011-5},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {1815-1836},
  shortjournal = {Soft Comput.},
  title        = {Fast curvelet transform through genetic algorithm for multimodal medical image fusion},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Valuation of stock loan under uncertain stock model with
floating interest rate. <em>SOCO</em>, <em>24</em>(3), 1803–1814. (<a
href="https://doi.org/10.1007/s00500-019-04007-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stock loan is a special loan with stocks as collateral, which offers the borrower the right to redeem the stocks at any time prior to the loan maturity by repaying the bank the principal and the loan interest. In this paper, we investigate the valuation of stock loan under an uncertain stock model with floating interest rate. The pricing formulas of standard stock loan and capped stock loan for the stock model are derived by using the method of uncertain calculus. Subsequently, some numerical algorithms are designed to calculate the prices of stock loans based on the pricing formulas. Finally, some numerical experiments are presented to study the relationship between stock loan price and some parameters.},
  archive      = {J_SOCO},
  author       = {Wang, Weiwei and Chen, Ping},
  doi          = {10.1007/s00500-019-04007-1},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {1803-1814},
  shortjournal = {Soft Comput.},
  title        = {Valuation of stock loan under uncertain stock model with floating interest rate},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Jump detection in financial time series using machine
learning algorithms. <em>SOCO</em>, <em>24</em>(3), 1789–1801. (<a
href="https://doi.org/10.1007/s00500-019-04006-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we develop a new Hybrid method based on machine learning algorithms for jump detection in financial time series. Jump is an important behavior in financial time series, since it implies a change in volatility. Ones can buy the volatility instrument if ones expect the volatility will bloom up in the future. A jump detection model attempts to detect short-term market instability, since it could be jumping up or down, instead of a directional prediction. The directional prediction can be considered as a momentum or trend following, which is not the focus of this paper. A jump detection model is commonly applied in a systematic fast-moving strategy, which reallocates the assets automatically. Also, a systematic opening position protection strategy can be driven by a jump detection model. For example, for a tail risk protection strategy, a pair of long call and put option order could be placed in the same time, in order to protect the open position given a huge change in volatility. One of the key differentiations of the proposed model with the classical methods of time-series anomaly detection is that, jump threshold parameters are not required to be predefined in our proposed model. Also the model is a combination of a Long short-term memory (LSTM) neural network model and a machine learning pattern recognition model. The LSTM model is applied for time series prediction, which predicts the next data point. The historical prediction errors sequence can be used as the information source or input of the jump detection model/module. The machine learning pattern recognition model is applied for jump detection. The combined model attempts to determine whether the current data point is a jump or not. LSTM neural network is a type of Recurrent Neural Networks (RNNs). LSTM records not only the recent market, but also the historical status. A stacked RNN is trained on a dataset which is mixed with normal and anomalous data. We compare the performance of the proposed Hybrid jump detection model and different pattern classification algorithms, such as k-nearest neighbors algorithm identifier, Hampel identifier, and Lee Mykland test. The model is trained and tested using real financial market data, including 11 global stock market in both developed and emerging markets in US, China, Hong Kong, Taiwan, Japan, UK, German, and Israel. The experiment result shows that the proposed Hybrid jump detection model is effective to detect jumps in terms of accuracy, comparing to the other classical jump detection methods.},
  archive      = {J_SOCO},
  author       = {Au Yeung, Jay F. K. and Wei, Zi-kai and Chan, Kit Yan and Lau, Henry Y. K. and Yiu, Ka-Fai Cedric},
  doi          = {10.1007/s00500-019-04006-2},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {1789-1801},
  shortjournal = {Soft Comput.},
  title        = {Jump detection in financial time series using machine learning algorithms},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Products and services valuation through unsolicited
information from social media. <em>SOCO</em>, <em>24</em>(3), 1775–1788.
(<a href="https://doi.org/10.1007/s00500-019-04005-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Technological advances and the Internet have changed the way consumers approach the market for assets and services. Increasingly, consumers use the opinions of others to make their decisions. Web sites have assessment indexes (ORIs, ORS), where consumers value products/services using discrete-value scales, like stars or likes. But these ways of assessing are being questioned for several reasons such as the answers’ reliability, and the opinions representativeness and aggregation. Lack of reliability is since opinions are requested directly, which makes possible the paradox of the strategic aspect of decisions. Representativeness and aggregation problems are owing to an important loss of decisions information when using a single value, instead of using the interval that includes all feelings/opinions, as well as preferences cardinality in the aggregation that somehow reinforce those assessments. The aim of this work is to propose an index for products/services evaluation over the Internet. This index, called Quorum Valuation Opinion Reputation Index, takes unsolicited information from consumers, and through a semantic analysis and a majority aggregation process, builds a valuation interval. In addition, an opinion interval reliability index is proposed. The index has been tested with real data in the tourism field.},
  archive      = {J_SOCO},
  author       = {Peláez, J. I. and Martínez, E. A. and Vargas, L. G.},
  doi          = {10.1007/s00500-019-04005-3},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {1775-1788},
  shortjournal = {Soft Comput.},
  title        = {Products and services valuation through unsolicited information from social media},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Supervised kohonen network with heterogeneous value
difference metric for both numeric and categorical inputs.
<em>SOCO</em>, <em>24</em>(3), 1763–1774. (<a
href="https://doi.org/10.1007/s00500-019-04001-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multi-attribute information appears in real world, which also includes numeric and categorical attributes. However, the previous classification algorithms for both numeric and categorical data exist in some limitations on categorical data. In this paper, a supervised Kohonen network with heterogeneous value difference metric is proposed for both numeric and categorical inputs. It employs the framework of supervised Kohonen networks, adopts heterogeneous value difference metric to measure dissimilarity between numeric and categorical data, uses the frequency of each categorical item in the Voronoi set to update the reference vector of categorical attribute on the competitive layer, and updates different competitive learning rules for numeric and categorical data. The effectiveness of the proposed algorithm is verified by UCI Machine Learning Data Repository. The classification accuracy is compared with BP, k-NN, naive Bayes network, C4.5 and SVM; the dissimilarity metric is analyzed. The proposed classification algorithm is applied to the operating mode classification for wind turbines; the effectiveness is illustrated in condition monitoring for pitch system of wind turbines.},
  archive      = {J_SOCO},
  author       = {Zhang, Yuxian and Gendeel, Mohammed Altayeb Awad and Peng, Huideng and Qian, Xiaoyi and Xu, Hongqing},
  doi          = {10.1007/s00500-019-04001-7},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {1763-1774},
  shortjournal = {Soft Comput.},
  title        = {Supervised kohonen network with heterogeneous value difference metric for both numeric and categorical inputs},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Clustering-based heterogeneous optimized-HEED protocols for
WSNs. <em>SOCO</em>, <em>24</em>(3), 1737–1761. (<a
href="https://doi.org/10.1007/s00500-019-04000-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering-based networks play a vital role in efficient utilization of energy consumption of each sensor node (SN) in wireless sensor networks (WSNs). Furthermore, firstly, prolonged network’s lifetime is observed as the key factor to analyze the protocol’s efficiency. However, in critical applications, i.e., military surveillance, environmental monitoring and structural health monitoring, stability region is also an important aspect for consideration. This provides reliability of data from each SN in the network. On the other hand, once a SN dies at any region, we are not able to sense that region which leaves the region vulnerable from detection of events. With this reason, it is highly important for an energy efficient protocol to provide good stability region with prolonged network lifetime. Secondly, a protocol should be intelligent enough to handle homogeneous as well as heterogeneous nodes efficiently in the network (i.e., homogeneous and heterogeneous WSNs) because once the network executes, a homogeneous WSN is also transformed in heterogeneous WSN. This is because of different radio communication features, occurrence of random events or morphological attributes of the network field. optimized-HEED protocols are one of the most recent clustering-based algorithms which improved the various shortcomings of classical protocol, i.e., HEED and provided far efficient results in terms of energy consumption, load balancing and network lifetime. However, these demonstrated their efficiency for homogeneous WSN only. In this paper, we extend the optimized-HEED protocols for heterogeneous WSNs model on the basis of varying levels of node heterogeneity (in terms of energy), i.e., 1-level, 2-level, 3-level and multi-level, and propose these as heterogeneous optimized-HEED (Hetero-OHEED) protocols. Simulation results confirm that by increasing the level of node’s heterogeneity, stability region of each Hetero-OHEED protocol enhances extremely with prolonged network lifetime. These provide a rich solution in designing of efficient protocols for those applications, where stability region and network lifetime require equal importance.},
  archive      = {J_SOCO},
  author       = {Gupta, Prateek and Sharma, Ajay K.},
  doi          = {10.1007/s00500-019-04000-8},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {1737-1761},
  shortjournal = {Soft Comput.},
  title        = {Clustering-based heterogeneous optimized-HEED protocols for WSNs},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A modeling error-based adaptive fuzzy observer approach with
input saturation analysis for robust control of affine and non-affine
systems. <em>SOCO</em>, <em>24</em>(3), 1717–1735. (<a
href="https://doi.org/10.1007/s00500-019-03999-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a robust control approach is applied for both MIMO/SISO affine/non-affine nonlinear systems based on a modeling error-based adaptive fuzzy observer controller, in the presence of input saturation. In the proposed scheme, non-affine nonlinear systems can be transformed to affine systems and unknown higher-order term of expansion (HOTE) that appears due to the use of this method can be estimated by an adaptive fuzzy technique. Using the modeling error between the system states observer and a serial–parallel estimator model, a modeling error-based adaptive fuzzy observer estimator is proposed that uses the modeling error as the input of fuzzy system to approximate and adaptively compensate the unknown HOTE and also the external disturbance. The proposed scheme is able to hold control performance in the presence of input saturation. An analysis of the controlled system is presented to verify the stability of the system under control. The stability of the closed-loop system is provided based on the strictly positive real condition and Lyapunov theory. The proposed approach is effectual and robust. The simulation results demonstrate the usefulness of the proposed method for both MIMO and SISO systems.},
  archive      = {J_SOCO},
  author       = {Ghavidel, Hesam Fallah},
  doi          = {10.1007/s00500-019-03999-0},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {1717-1735},
  shortjournal = {Soft Comput.},
  title        = {A modeling error-based adaptive fuzzy observer approach with input saturation analysis for robust control of affine and non-affine systems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Integrating social annotations into topic models for
personalized document retrieval. <em>SOCO</em>, <em>24</em>(3),
1707–1716. (<a
href="https://doi.org/10.1007/s00500-019-03998-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social annotations are valuable resources generated by users on the Web, which encode abundant information on user preferences for certain documents. Social annotation-based information retrieval has been studied in recent years for personalizing search results and fulfilling user information needs. However, since social annotations are complicated and associated with users, documents and tags simultaneously, it remains a great challenge to fully capture the potentially useful information for improving retrieval performance. To meet the challenge, we propose a novel method to integrate social annotations into topic models for personalized document retrieval. Our method first reconstructs candidate documents for a given query using social tags of documents to capture user preferences. The reconstructed documents are tailored to user preferences for achieving better performance. We then generalize the latent Dirichlet allocation-based topic models by considering the relationship among users, social tags and documents from social annotations. The modified topic model optimizes the distribution of latent topics of documents for different users to meet user information needs. Experimental results show that our method can significantly outperform the state-of-the-art baseline models for improving the performance of personalized retrieval.},
  archive      = {J_SOCO},
  author       = {Xu, Bo and Lin, Hongfei and Lin, Yuan and Guan, Yizhou},
  doi          = {10.1007/s00500-019-03998-1},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {1707-1716},
  shortjournal = {Soft Comput.},
  title        = {Integrating social annotations into topic models for personalized document retrieval},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel fuzzy mechanism for risk assessment in software
projects. <em>SOCO</em>, <em>24</em>(3), 1683–1705. (<a
href="https://doi.org/10.1007/s00500-019-03997-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Risk management is a vital factor for ensuring better quality software development processes. Moreover, risks are the events that could adversely affect the organization activities or the development of projects. Effective prioritization of software project risks play a significant role in determining whether the project will be successful in terms of performance characteristics or not. In this work, we develop a new hybrid fuzzy-based machine learning mechanism for performing risk assessment in software projects. This newly developed hybridized risk assessment scheme can be used to determine and rank the significant software project risks that support the decision making during the software project lifecycle. For better assessment of the software project risks, we have incorporated fuzzy decision making trial and evaluation laboratory, adaptive neuro-fuzzy inference system-based multi-criteria decision making (ANFIS MCDM) and intuitionistic fuzzy-based TODIM (IF-TODIM) approaches. More significantly, for the newly introduced ANFIS MCDM approach, the parameters of ANFIS are adjusted using a traditional crow search algorithm (CSA) which applies only a reasonable as well as small changes in variables. The main activity of CSA in ANFIS is to find the best parameter to achieve most accurate software risk estimate. Experimental validation was conducted on NASA 93 dataset having 93 software project values. The result of this method exhibits a vivid picture that provides software risk factors that are key determinant for achievement of the project performance. Experimental outcomes reveal that our proposed integrated fuzzy approaches can exhibit better and accurate performance in the assessment of software project risks compared to other existing approaches.},
  archive      = {J_SOCO},
  author       = {Suresh, K. and Dillibabu, R.},
  doi          = {10.1007/s00500-019-03997-2},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {1683-1705},
  shortjournal = {Soft Comput.},
  title        = {A novel fuzzy mechanism for risk assessment in software projects},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Analysis of fuzzy supply chain performance based on
different buyback contract configurations. <em>SOCO</em>,
<em>24</em>(3), 1673–1682. (<a
href="https://doi.org/10.1007/s00500-019-03996-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, a two-echelon supply chain is analyzed where the supplier sells the products to retailer, who in turn sells the product to end customers. In such an arrangement, the supplier and the retailer aim to increase their profits individually which causes double marginalization. Several studies have been proposed by researches to solve the problem of “double marginalization” and its consequences to supply chain performance. Therefore, contractual agreements as coordination mechanisms were developed to improve the supply chain performance. In the literature, many studies have been conducted on these coordination mechanisms under probabilistic demand. However, in the absence of the historical data it is not possible to establish the probability distribution. In such cases, the fuzzy set theory which is another illustration of uncertainty can be used to model the supply chain. In this study, different configurations of buyback contracts on supply chain performance under fuzzy environment are analyzed. Initially, closed-form solution to buyback contract model with fuzzy demand is proposed by using credibility theory. After that, the closed form of this model with fuzzy buyback rate parameter is obtained. And then the effects of the different configurations of the buyback contract model are analyzed by changing the buyback rate and buyback price. Finally, numerical examples are presented to demonstrate the solving processes of the models and the different effects of buyback rate and buyback price on parameters of buyback contract and the fuzzy expected profit value of all members in supply chain.},
  archive      = {J_SOCO},
  author       = {Canbulut, Gülçin and Torun, Hülya},
  doi          = {10.1007/s00500-019-03996-3},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {1673-1682},
  shortjournal = {Soft Comput.},
  title        = {Analysis of fuzzy supply chain performance based on different buyback contract configurations},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An autoencoder-based spectral clustering algorithm.
<em>SOCO</em>, <em>24</em>(3), 1661–1671. (<a
href="https://doi.org/10.1007/s00500-019-03994-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spectral clustering algorithm suffers from high computational complexity due to the eigen decomposition of Laplacian matrix and large similarity matrix for large-scale datasets. Some researches explore the possibility of deep learning in spectral clustering and propose to replace the eigen decomposition with autoencoder. K-means clustering is generally used to obtain clustering results on the embedding representation, which can improve efficiency but further increase memory consumption. An efficient spectral algorithm based on stacked autoencoder is proposed to solve this issue. In this paper, we select the representative data points as landmarks and use the similarity of landmarks with all data points as the input of autoencoder instead of similarity matrix of the whole datasets. To further refine clustering result, we combine learning the embedding representation and performing clustering. Clustering loss is used to update the parameters of autoencoder and cluster centers simultaneously. The reconstruction loss is also included to prevent the distortion of embedding space and preserve the local structure of data. Experiments on several large-scale datasets validate the effectiveness of the proposed method.},
  archive      = {J_SOCO},
  author       = {Li, Xinning and Zhao, Xiaoxiao and Chu, Derun and Zhou, Zhiping},
  doi          = {10.1007/s00500-019-03994-5},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {1661-1671},
  shortjournal = {Soft Comput.},
  title        = {An autoencoder-based spectral clustering algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Correlation coefficients for t-spherical fuzzy sets and
their applications in clustering and multi-attribute decision making.
<em>SOCO</em>, <em>24</em>(3), 1647–1659. (<a
href="https://doi.org/10.1007/s00500-019-03993-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The framework of T-spherical fuzzy set is a generalization of fuzzy set, intuitionistic fuzzy set and picture fuzzy set having a great potential of dealing with uncertain events with no limitation. A T-spherical fuzzy framework can deal with phenomena of more than yes or no type; for example, consider the scenario of voting where one’s voting interest is not limited to “in favor’’ or “against’’ rather there could be some sort of abstinence or refusal degree also. The objective of this paper is to develop some correlation coefficients for T-spherical fuzzy sets due to the non-applicability of correlations of intuitionistic fuzzy sets and picture fuzzy sets in some certain circumstances. The fitness of new correlation coefficients has been discussed, and their generalization is studied with the help of some results. Clustering and multi-attribute decision-making algorithms have been proposed in the environment of T-spherical fuzzy sets. To demonstrate the viability of proposed algorithms and correlation coefficients, two real-life problems including a clustering problem and a multi-attribute decision-making problem have been solved. A comparative study of the newly presented and pre-existing literature is established showing the superiority of proposed work over the existing theory. Some advantages of new correlation coefficients and drawbacks of the pre-existing work are demonstrated with the help of numerical examples.},
  archive      = {J_SOCO},
  author       = {Ullah, Kifayat and Garg, Harish and Mahmood, Tahir and Jan, Naeem and Ali, Zeeshan},
  doi          = {10.1007/s00500-019-03993-6},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {1647-1659},
  shortjournal = {Soft Comput.},
  title        = {Correlation coefficients for T-spherical fuzzy sets and their applications in clustering and multi-attribute decision making},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cuckoo search algorithm-based brightness preserving
histogram scheme for low-contrast image enhancement. <em>SOCO</em>,
<em>24</em>(3), 1619–1645. (<a
href="https://doi.org/10.1007/s00500-019-03992-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel optimized brightness preserving histogram equalization approach to preserve the mean brightness and to improve the contrast of low-contrast image using cuckoo search algorithm. Traditional histogram equalization scheme induces extreme enhancement and brightness change ensuing abnormal appearance. The proposed method utilizes plateau limits to modify histogram of the image. In this method, histogram is divided into two sub-histograms on which histogram statistics are exploited to obtain the plateau limits. The sub-histograms are equalized and modified based on the calculated plateau limits obtained by cuckoo search optimization technique. To demonstrate the effectiveness of proposed method a comparison of the proposed method with different histogram processing techniques is presented. Proposed method outperforms other state-of-art methods in terms of the objective as well as subjective quality evaluation.},
  archive      = {J_SOCO},
  author       = {Bhandari, Ashish Kumar and Maurya, Shubham},
  doi          = {10.1007/s00500-019-03992-7},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {1619-1645},
  shortjournal = {Soft Comput.},
  title        = {Cuckoo search algorithm-based brightness preserving histogram scheme for low-contrast image enhancement},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Semi-supervised orthogonal discriminant analysis with
relative distance: Integration with a MOO approach. <em>SOCO</em>,
<em>24</em>(3), 1599–1618. (<a
href="https://doi.org/10.1007/s00500-019-03990-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In discriminant analysis, trace ratio is an important criterion for minimizing the between-class similarity and maximizing the within-class similarity, simultaneously. In brief, we address the trace ratio problem associated with many semi-supervised discriminant analysis algorithms as they use the normal Euclidean distances between training data samples. Based on this problem, we propose a new semi-supervised orthogonal discriminant analysis technique with relative distance constraints called SSODARD. Different from the existing semi-supervised dimensionality reduction algorithms, our algorithm is more consistent in propagating the label information from the labeled data to the unlabeled data because of the use of relative distance function instead of normal Euclidean distance function. For finding this appropriate relative distance function, we use pairwise constraints generated from labeled data and satisfy them using Bregman projection. Since the projection is not orthogonal, we require an appropriate subset of constraints. In order to select such a subset of constraints, we further develop a framework called MO-SSODARD, which uses evolutionary algorithm while optimizing various validity indices simultaneously. The experimental results on various datasets show that our proposed approaches are superior than the state-of-the-art discriminant algorithms with respect to various validity indices.},
  archive      = {J_SOCO},
  author       = {Sanodiya, Rakesh Kumar and Saha, Sriparna and Mathew, Jimson},
  doi          = {10.1007/s00500-019-03990-9},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {1599-1618},
  shortjournal = {Soft Comput.},
  title        = {Semi-supervised orthogonal discriminant analysis with relative distance: Integration with a MOO approach},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Pythagorean uncertain linguistic hesitant fuzzy weighted
averaging operator and its application in financial group decision
making. <em>SOCO</em>, <em>24</em>(3), 1585–1597. (<a
href="https://doi.org/10.1007/s00500-019-03989-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With respect to multiple attribute decision-making problems, in which attribute values take in the form of Pythagorean uncertain linguistic hesitant fuzzy information, a new decision-making method based on the Pythagorean uncertain linguistic hesitant fuzzy weighted averaging (PULHFWA) operator is developed. In this paper, we proposed some operational laws based on Pythagorean uncertain linguistic hesitant fuzzy numbers (PULHFNs) and verified some properties. We also developed some aggregation operators to use the decision information represented by PULHFNs, including the PULHFWA operator, Pythagorean uncertain linguistic hesitant fuzzy ordered weighted averaging operator and Pythagorean uncertain linguistic hesitant fuzzy hybrid averaging operator. We develop a decision-making method based on the proposed operators under the Pythagorean uncertain linguistic hesitant fuzzy environment and illustrated with a numerical example and study the applicability of the new approach on a financial decision-making problem concerning the selection of financial strategies. Finally, a comparison analysis between the proposed and the existing approaches has been performed to illustrate the applicability and feasibility of the developed decision-making method.},
  archive      = {J_SOCO},
  author       = {Shakeel, M. and Shahzad, M. and Abdullah, S.},
  doi          = {10.1007/s00500-019-03989-2},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {1585-1597},
  shortjournal = {Soft Comput.},
  title        = {Pythagorean uncertain linguistic hesitant fuzzy weighted averaging operator and its application in financial group decision making},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Feature selection strategy based on hybrid crow search
optimization algorithm integrated with chaos theory and fuzzy c-means
algorithm for medical diagnosis problems. <em>SOCO</em>, <em>24</em>(3),
1565–1584. (<a
href="https://doi.org/10.1007/s00500-019-03988-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Powerful knowledge acquisition tools and techniques have the ability to increase both the quality and the quantity of knowledge-based systems for real-world problems. In this paper, we designed a hybrid crow search optimization algorithm integrated with chaos theory and fuzzy c-means algorithm denoted as CFCSA for feature selection problems of medical diagnosis. In the proposed CFCSA framework, the crow search algorithm adopts the global optimization technique to avoid the sensitivity of local optimization. The fuzzy c-means (FCM) objective function is used as a cost function for the chaotic crow search optimization algorithm. The proposed algorithm CFCSA is benchmarked against the binary crow search algorithm (BCSA), chaotic ant lion optimization algorithm (CALO), binary ant lion optimization algorithm (BALO) and bat algorithm relevant methods. The proposed CFCSA algorithm vs. BCSA, CALO, BALO and bat algorithm is tested on diabetes, heart, Radiopaedia CT liver, breast cancer, lung cancer, cardiotocography, ILPD, liver disorders, hepatitis and arrhythmia. Experimental results show the proposed method CFCSA is better against comparative models in feature selection on the medical diagnosis data sets.},
  archive      = {J_SOCO},
  author       = {Anter, Ahmed M. and Ali, Mumtaz},
  doi          = {10.1007/s00500-019-03988-3},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {1565-1584},
  shortjournal = {Soft Comput.},
  title        = {Feature selection strategy based on hybrid crow search optimization algorithm integrated with chaos theory and fuzzy c-means algorithm for medical diagnosis problems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fuzzy-based approach to assess and prioritize privacy risks.
<em>SOCO</em>, <em>24</em>(3), 1553–1563. (<a
href="https://doi.org/10.1007/s00500-019-03986-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The new general data protection regulation requires organizations to conduct a data protection impact assessment (DPIA) when the processing of personal information may result in high risk to individual rights and freedoms. DPIA allows organizations to identify, assess and prioritize the risks related to the processing of personal information and select suitable mitigations to reduce the severity of the risks. The existing DPIA methodologies measure the severity of privacy risks according to analysts’ opinions about the likelihood and the impact factors of the threats. The assessment is therefore subjective to the expertise of the analysts. To reduce subjectivity, we propose a set of well-defined criteria that analysts can use to measure the likelihood and the impact of a privacy risk. Then, we adopt the fuzzy multi-criteria decision-making approach to systematically measure the severity of privacy risks while modeling the imprecision and vagueness inherent in linguistic assessment. Our approach is illustrated for a realistic scenario with respect to LINDDUN threat categories.},
  archive      = {J_SOCO},
  author       = {Hart, Stephen and Ferrara, Anna Lisa and Paci, Federica},
  doi          = {10.1007/s00500-019-03986-5},
  journal      = {Soft Computing},
  number       = {3},
  pages        = {1553-1563},
  shortjournal = {Soft Comput.},
  title        = {Fuzzy-based approach to assess and prioritize privacy risks},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Application of a new accelerated algorithm to regression
problems. <em>SOCO</em>, <em>24</em>(2), 1539–1552. (<a
href="https://doi.org/10.1007/s00500-019-03984-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many iterative algorithms like Picard, Mann, Ishikawa are very useful to solve fixed point problems of nonlinear operators in real Hilbert spaces. The recent trend is to enhance their convergence rate abruptly by using inertial terms. The purpose of this paper is to investigate a new inertial iterative algorithm for finding the fixed points of nonexpansive operators in the framework of Hilbert spaces. We study the weak convergence of the proposed algorithm under mild assumptions. We apply our algorithm to design a new accelerated proximal gradient method. This new proximal gradient technique is applied to regression problems. Numerical experiments have been conducted for regression problems with several publicly available high-dimensional datasets and compare the proposed algorithm with already existing algorithms on the basis of their performance for accuracy and objective function values. Results show that the performance of our proposed algorithm overreaches the other algorithms, while keeping the iteration parameters unchanged.},
  archive      = {J_SOCO},
  author       = {Dixit, Avinash and Sahu, D. R. and Singh, Amit Kumar and Som, T.},
  doi          = {10.1007/s00500-019-03984-7},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {1539-1552},
  shortjournal = {Soft Comput.},
  title        = {Application of a new accelerated algorithm to regression problems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new cipher system using semi-natural composition in indian
raga. <em>SOCO</em>, <em>24</em>(2), 1529–1537. (<a
href="https://doi.org/10.1007/s00500-019-03983-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cryptographic algorithms are the basic of care-free transactions over the Internet today. Confidential information of a government or private agency or department is secured through the use of Cryptography. From doing secure communication to transferring information of national importance, Cryptographic algorithms play the sole role in hiding the confidentiality. Musical attributes such as notes of which the music is composed are not constant and vary from composition to composition. Same tune played by different composers shows a variation in the sequence of notes used along with other attributes of a musical composition such as duration of each note and the frequency at which each note is played. Such a variation can be employed for the purpose of encrypting the message. In this paper, we have incorporated the use of Hindustani (North Indian) musical notes to encrypt messages. We have used a semi-natural composition process to generate note sequences of Indian music which can then be used as a tool for message hiding. This at first place ensures that the message is hidden from the intruder and second it gives a new random sequence of notes every time same message is sent. So the very purpose of a Cryptographic algorithm is served. The encrypted message in the form of musical notes is then sent to the intended recipient in the form of a musical composition which helps in defying the intruder of sensing any confidential information that is being sent over the communication channel.},
  archive      = {J_SOCO},
  author       = {Pranav, Prashant and Chakraborty, Soubhik and Dutta, Sandip},
  doi          = {10.1007/s00500-019-03983-8},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {1529-1537},
  shortjournal = {Soft Comput.},
  title        = {A new cipher system using semi-natural composition in indian raga},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Linguistic summarization of fuzzy social and economic
networks: An application on the international trade network.
<em>SOCO</em>, <em>24</em>(2), 1511–1527. (<a
href="https://doi.org/10.1007/s00500-019-03982-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although plenty of techniques such as link prediction, clustering, and position analysis have been proposed to analyze social and economic networks and patterns of social and economic relationships in various fields, few studies have addressed the transformation of social and economic network data into the knowledge in the form of linguistic summaries. In this study, we propose, for the first time in the literature, iteration, reciprocal and branching-based linguistic summary forms taking into account both the attributes (features) of social and economic actors and the relations between them. We then develop methods for evaluating the degree of truth of the suggested linguistic summary forms by leveraging generalized quantifiers, specifically semi-fuzzy and polyadic quantifiers. The advantages and applicability of the proposed linguistic summary forms are illustrated on the international trade network.},
  archive      = {J_SOCO},
  author       = {Genç, Serkan and Akay, Diyar and Boran, Fatih Emre and Yager, Ronald R.},
  doi          = {10.1007/s00500-019-03982-9},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {1511-1527},
  shortjournal = {Soft Comput.},
  title        = {Linguistic summarization of fuzzy social and economic networks: An application on the international trade network},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Role of honesty and confined interpersonal influence in
modelling predilections. <em>SOCO</em>, <em>24</em>(2), 1497–1509. (<a
href="https://doi.org/10.1007/s00500-019-03981-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classical models of decision-making do not incorporate for the role of influence and honesty that affects the process. This paper develops on the theory of influence in social network analysis. We study the role of influence and honesty of individual experts on collective outcomes. It is assumed that experts have the tendency to improve their initial predilection for an alternative, over the rest, if they interact with one another. It is suggested that this revised predilection may not be proposed with complete honesty by the expert. Degree of honesty is computed from the preference relation provided by the experts. This measure is dependent on average fuzziness in the relation and its disparity from an additive reciprocal relation. Moreover, an algorithm is introduced to cater for incompleteness in the adjacency matrix of interpersonal influences. This is done by analysing the information on how the expert has influenced others and how others have influenced the expert.},
  archive      = {J_SOCO},
  author       = {Khalid, Asma and Beg, Ismat},
  doi          = {10.1007/s00500-019-03981-w},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {1497-1509},
  shortjournal = {Soft Comput.},
  title        = {Role of honesty and confined interpersonal influence in modelling predilections},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modeling reverse thinking for machine learning.
<em>SOCO</em>, <em>24</em>(2), 1483–1496. (<a
href="https://doi.org/10.1007/s00500-019-03980-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human inertial thinking schemes can be formed through learning, which are then applied to quickly solve similar problems later. However, when problems are significantly different, inertial thinking generally presents the solutions that are definitely imperfect. In such cases, people will apply creative thinking, such as reverse thinking, to solve problems. Similarly, machine learning methods also form inertial thinking schemes through learning the knowledge from a large amount of data. However, when the testing samples are vastly different, the formed inertial thinking schemes will inevitably generate errors. This kind of inertial thinking is called illusion inertial thinking. Because all machine learning methods do not consider the illusion inertial thinking, in this paper we propose a new method that uses the reverse thinking to correct the illusion inertial thinking, which increases the generalization ability of machine learning methods. Experimental results on benchmark data sets validated the proposed method.},
  archive      = {J_SOCO},
  author       = {Li, Huihui and Wen, Guihua},
  doi          = {10.1007/s00500-019-03980-x},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {1483-1496},
  shortjournal = {Soft Comput.},
  title        = {Modeling reverse thinking for machine learning},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Performance comparison using firefly and PSO algorithms on
congestion management of deregulated power market involving renewable
energy sources. <em>SOCO</em>, <em>24</em>(2), 1473–1482. (<a
href="https://doi.org/10.1007/s00500-019-03979-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The power industry across the globe is subjected to a sweeping change in its business as well as in an operating model where the monopoly utilities are being liberalized and opened up for competition with private players. As an outcome of this, the transmission corridors evacuating the power of inexpensive generators would be burdened if all such transactions are admitted. One of the most proficient techniques for congestion management is rescheduling the generators. This research paper suggests a framework to regulate the power flows of the transmission lines within the stipulated limit in a deregulated electricity market environment through rescheduling with and without renewable energy sources (RES). The problem of rescheduling is framed with the intention of lessening the congestion cost. Unlike the traditional method, the best location for the placement of RES is established utilizing a novel weighted locational marginal price (LMP)-based method. The firefly algorithm (FA) and particle swarm optimization (PSO) algorithm are employed in order to get optimized results. The realistic cases are considered, and the results obtained with and without RES using FA and PSO are compared to prove the research study. The efficacy of the method is explored with IEEE 30-bus system.},
  archive      = {J_SOCO},
  author       = {Farzana, D. Fathema and Mahadevan, K.},
  doi          = {10.1007/s00500-019-03979-4},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {1473-1482},
  shortjournal = {Soft Comput.},
  title        = {Performance comparison using firefly and PSO algorithms on congestion management of deregulated power market involving renewable energy sources},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Structural representation-based off-line tamil handwritten
character recognition. <em>SOCO</em>, <em>24</em>(2), 1447–1472. (<a
href="https://doi.org/10.1007/s00500-019-03978-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tamil handwritten character recognition system enormously depends on its character features. This paper deals with the feature extraction and the three ways of feature predictions that are experimented in order to grasp features from various Tamil characters possessing variations in style and shape. Shape, shape ordering and location-based instances are the features predicted from the characters. The key features of this paper are the strip tree-based hierarchical formation which deals with the shape features of the characters, the implementation of the Z-ordering algorithm for addressing the structure ordering and finally the representation of PM-Quad tree that deals with extracting locations of the character features. A hierarchical classification algorithm based on support vector machine is used for predicting the character from its character features using divide-and-conquer procedure. Proof of this work shows that this work can address more characters and its varied shapes.},
  archive      = {J_SOCO},
  author       = {Raj, M. Antony Robert and Abirami, S.},
  doi          = {10.1007/s00500-019-03978-5},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {1447-1472},
  shortjournal = {Soft Comput.},
  title        = {Structural representation-based off-line tamil handwritten character recognition},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-person and multi-criteria decision making with the
induced probabilistic ordered weighted average distance. <em>SOCO</em>,
<em>24</em>(2), 1435–1446. (<a
href="https://doi.org/10.1007/s00500-019-03977-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new approach for selecting suppliers of products or services, specifically with respect to complex decisions that require evaluating different business characteristics to ensure their suitability and to meet the conditions defined in the recruitment process. To address this type of problem, this study presents the multi-person multi-criteria induced ordered weighted average distance (MP-MC-IOWAD) operator, which is an extension of the OWA operators that includes the notion of distances to multiple criteria and expert valuations. Thus, this work introduces new distance measures that can aggregate the information with probabilistic information and consider the attitudinal character of the decision maker. Further extensions are developed using probabilities to form the induced probabilistic ordered weighted average distance (IPOWAD) operator. An example in the management of insurance policies is presented, where the selection of insurance companies is very complex and requires the consideration of subjective criteria by experts in decision making.},
  archive      = {J_SOCO},
  author       = {Casanovas, Montserrat and Torres-Martínez, Agustín and Merigó, José M.},
  doi          = {10.1007/s00500-019-03977-6},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {1435-1446},
  shortjournal = {Soft Comput.},
  title        = {Multi-person and multi-criteria decision making with the induced probabilistic ordered weighted average distance},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Ensemble classification from deep predictions with test data
augmentation. <em>SOCO</em>, <em>24</em>(2), 1423–1433. (<a
href="https://doi.org/10.1007/s00500-019-03976-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data augmentation has become a standard step to improve the predictive power and robustness of convolutional neural networks by means of the synthetic generation of new samples depicting different deformations. This step has been traditionally considered to improve the network at the training stage. In this work, however, we study the use of data augmentation at classification time. That is, the test sample is augmented, following the same procedure considered for training, and the decision is taken with an ensemble prediction over all these samples. We present comprehensive experimentation with several datasets and ensemble decisions, considering a rather generic data augmentation procedure. Our results show that performing this step is able to boost the original classification, even when the room for improvement is limited.},
  archive      = {J_SOCO},
  author       = {Calvo-Zaragoza, Jorge and Rico-Juan, Juan R. and Gallego, Antonio-Javier},
  doi          = {10.1007/s00500-019-03976-7},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {1423-1433},
  shortjournal = {Soft Comput.},
  title        = {Ensemble classification from deep predictions with test data augmentation},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Equilibrium strategy for human resource management with
limited effort: In-house versus outsourcing. <em>SOCO</em>,
<em>24</em>(2), 1399–1422. (<a
href="https://doi.org/10.1007/s00500-019-03974-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When outsourcing human resource activities to a vendor, a firm with limited effort may want to save energy to focus on core competencies. However, the firm could also lose control over these activities by outsourcing, especially in a situation with unobservable action, and this could in turn increase cost. In this paper, we consider a firm with limited effort performing core and non-core human resource activities and aiming to choose an appropriate human resource management strategy, in-house or outsourcing within a framework of agency theory. We show that only when the effort ceiling is low enough, will the firm completely commit to its core activities. Surprisingly, under outsourcing strategy with double moral hazard, we find that both of the vendor and the firm distort their efforts. Moreover, the outsourcing strategy is optimal if the effort ceiling is low enough or if the cost of the non-core activities is high and the positive interaction between the two activities is low. Otherwise, the firm prefers the in-house strategy, especially in the case with a high effort ceiling and unobservable action. In addition, we also find that a high revenue generation capacity for the core activities may increase the motivation of the firm for outsourcing.},
  archive      = {J_SOCO},
  author       = {Xu, Man and Tang, Wansheng and Zhao, Ruiqing},
  doi          = {10.1007/s00500-019-03974-9},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {1399-1422},
  shortjournal = {Soft Comput.},
  title        = {Equilibrium strategy for human resource management with limited effort: In-house versus outsourcing},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Novel model to integrate word embeddings and syntactic trees
for automatic caption generation from images. <em>SOCO</em>,
<em>24</em>(2), 1377–1397. (<a
href="https://doi.org/10.1007/s00500-019-03973-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic caption generation from images is an interesting and mainstream direction in the field of machine learning. This method enables us to build a powerful computer model that can interpret the implicit semantic information of images. However, the current state of research faces significant challenges such as those related to extracting robust image features, suppressing noisy words, and improving a caption’s coherence. For the first problem, a novel computer vision system is presented to create a new image feature called MK–KDES-1 (MK–KDES represents Multiple Kernel–Kernel Descriptors) after extracting three KDES features and fusing them by MKL (Multiple Kernel Learning) model. The MK–KDES-1 feature captures both textural characteristics and shape characteristics of images, which contribute to improving the BLEU_1 (BLEU represents Bilingual Evaluation Understudy) scores of captions. For the second problem, an effective newly designed two-layer TR (Tag Refinement) strategy is integrated into our NLG (Natural Language Generation) algorithm. Words that are most relevant semantically to images are summarized to generate N-gram phrases. Noisy words are suppressed using the innovative TR strategy. For the last problem, on the one hand, a pop WE (Word Embeddings) model and a novel metric called PDI (Positive Distance Information) are introduced together to generate N-gram phrases. The phrases are evaluated by the AWSC (Accumulated Word Semantic Correlation) metric. On the other hand, the phrases are fused to generate captions by the ST (Syntactic Trees). Experimental results demonstrate that informative captions with high BLEU_3 scores can be obtained to describe images.},
  archive      = {J_SOCO},
  author       = {Zhang, Hongbin and Qiu, Diedie and Wu, Renzhong and Ji, Donghong and Li, Guangli and Niu, Zhenyu and Li, Tao},
  doi          = {10.1007/s00500-019-03973-w},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {1377-1397},
  shortjournal = {Soft Comput.},
  title        = {Novel model to integrate word embeddings and syntactic trees for automatic caption generation from images},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hierarchical granular hotspots detection. <em>SOCO</em>,
<em>24</em>(2), 1357–1376. (<a
href="https://doi.org/10.1007/s00500-019-03971-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a hierarchical model based on the extended fuzzy C-means (EFCM) clustering algorithm to develop a granular view of hotspots on a geographic map. The objective is to establish an overview of the spatial distribution of a phenomenon when the relevant data are partitioned into different datasets. The EFCM algorithm is applied to each dataset to detect local hotspots, represented as circles, on the map. The local hotspots constitute information granules at lower level of abstraction in the model. A weighted EFCM algorithm is then applied to a dataset formed by the centers of all the local hotspots to extract circular prototypes, defined as global hotspots, which constitute information granules at the higher level, and hence, they deliver a global overview of the spatial distribution of the phenomenon on the map. Two indices related to the essential criteria of the principle of justifiable granularity are used. The results demonstrate that the most justifiable overview is obtained by using the radius of the local hotspot as weight. Comparisons with a hierarchical model based on FCM algorithm show that our algorithm gives a better granular view of the phenomenon with respect to the latter.},
  archive      = {J_SOCO},
  author       = {Di Martino, Ferdinando and Pedrycz, Witold and Sessa, Salvatore},
  doi          = {10.1007/s00500-019-03971-y},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {1357-1376},
  shortjournal = {Soft Comput.},
  title        = {Hierarchical granular hotspots detection},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Scheduling parallel machine problem under general effects of
deterioration and learning with past-sequence-dependent setup time:
Heuristic and meta-heuristic approaches. <em>SOCO</em>, <em>24</em>(2),
1335–1355. (<a
href="https://doi.org/10.1007/s00500-019-03970-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates an identical parallel machine scheduling problem with past-sequence-dependent setup times and general effects of deteriorating and learning. The actual job processing time on each machine is defined by a two-element function of the normal processing times of the preprocessed jobs and its scheduled position on the same machine. Moreover, the job setup time on each machine is a function of the actual processing times of the preprocessed jobs on the same machine. A novel mixed-integer programming model is developed to satisfy the goal of minimizing total completion time. Due to the NP-hard characteristic and intractability of the problem, three efficient methodologies including a heuristic algorithm (HA), a genetic algorithm (GA) with an enhanced exploration ability and an ant colony optimization (ACO) combined with a new stochastic elitism strategy are designed to find optimal/near-optimal solutions within an appropriate period of time. The effectiveness and efficiency of the presented model and the proposed algorithms are verified by computational experiments. The computational results indicate that the suggested algorithms are effective and executable approaches to generate solutions as good as optimal solution in the small-sized problems. Also, the ACO statistically outperformed the HA and GA in the medium- and large-sized problems.},
  archive      = {J_SOCO},
  author       = {Salehi Mir, Mir Saber and Rezaeian, Javad and Mohamadian, Hossein},
  doi          = {10.1007/s00500-019-03970-z},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {1335-1355},
  shortjournal = {Soft Comput.},
  title        = {Scheduling parallel machine problem under general effects of deterioration and learning with past-sequence-dependent setup time: Heuristic and meta-heuristic approaches},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Neural collision avoidance system for biomimetic autonomous
underwater vehicle. <em>SOCO</em>, <em>24</em>(2), 1315–1333. (<a
href="https://doi.org/10.1007/s00500-019-03969-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous underwater vehicles (AUVs) are underwater robots which are able to perform certain tasks without the help of a human operator. The key skill of each AUV is the capability to avoid collisions. To this end, appropriate devices and software are necessary with the potential to detect obstacles and to take proper decisions from the point of view of both the task and safety of the vehicle. The paper presents a neural collision avoidance system (NCAS) designed for the biomimetic autonomous underwater vehicle (BAUV). The NCAS is a component of the path following and collision avoidance system (PFCAS), which as the name implies is responsible for safely leading the vehicle along a desired path with collision avoidance. The task of NCAS is to make decisions regarding vehicle maneuvers in the horizontal plane, but only in the close proximity of the obstacles. It is implemented as an evolutionary artificial neural network designed by means of a neuro-evolutionary technique called assembler encoding with evolvable operations (AEEO). The paper outlines operation and construction of the BAUV as well as the PFCAS, the role of the NCAS in the entire system, and briefly presents AEEO as well as reporting on the experiments performed in simulation.},
  archive      = {J_SOCO},
  author       = {Praczyk, Tomasz},
  doi          = {10.1007/s00500-019-03969-6},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {1315-1333},
  shortjournal = {Soft Comput.},
  title        = {Neural collision avoidance system for biomimetic autonomous underwater vehicle},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). EPL models with fuzzy imperfect production system including
carbon emission: A fuzzy differential equation approach. <em>SOCO</em>,
<em>24</em>(2), 1293–1313. (<a
href="https://doi.org/10.1007/s00500-019-03967-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper outlines the production policies for maximum profit of a firm producing imperfect economic lot size with time-dependent fuzzy defective rate under the respective country’s carbon emission rules. Generally in economic production lot-size models, defective production starts after the passage of some time from production commencement. So the starting time of producing defective units is normally uncertain and imprecise. Thus, produced defective units are fuzzy, partially reworked instantly and sold as fresh units. As a result, the inventory level at any time becomes fuzzy and the relation between the production, demand and inventory level becomes a fuzzy differential equation (FDE). Nowadays, different governments have made environmental regulations following the United Nations Framework Convention on Climate Change to reduce carbon emission. Some governments use cape and trade policy on emission. Due to this, firms are in fix how to optimize the production. If the firms produce more, the profit increases along with more emission and corresponding tax. Here, models are formulated as profit maximization problems using FDE, and the corresponding inventory and environmental costs are calculated using fuzzy Riemann integration. An $$\alpha $$-cut of average profits is obtained and the reduced multi-objective crisp problems are solved using intuitionistic fuzzy optimization technique. The models are illustrated numerically and results are presented graphically. Considering different carbon regulations, an algorithm for a firm management is presented to achieve the maximum profit. Real-life production problems for the firms in Annex I and developing countries are solved.},
  archive      = {J_SOCO},
  author       = {De, Manoranjan and Das, Barun and Maiti, Manoranjan},
  doi          = {10.1007/s00500-019-03967-8},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {1293-1313},
  shortjournal = {Soft Comput.},
  title        = {EPL models with fuzzy imperfect production system including carbon emission: A fuzzy differential equation approach},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A high accurate vehicle speed estimation method.
<em>SOCO</em>, <em>24</em>(2), 1283–1291. (<a
href="https://doi.org/10.1007/s00500-019-03965-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a novel approach for accurate vehicle speed estimation from video sequences. Common methods usually track sets of distinguishing features; however, feature extraction is a difficult task in dynamic environments. Herein, we propose a novel analysis method without feature extraction. Initially, a frame difference method is applied to a region of interest, from which projection histograms are obtained and a group of key bins are selected to represent the vehicle motion. Then, all the possible speeds are tested one by one, and the extreme value of the testing function is selected for the corresponding speed. The proposed system was tested on three data sets containing 2054 vehicles, where the ground truth of speed is obtained by a radar speed detector. The experiment results show that the proposed system has an average error of 0.3 km/h, with 99.4\% of the estimation speed within the error of range (− 2 km/h, 2 km/h). The system turns out to be robust, accurate and real time for practical use.},
  archive      = {J_SOCO},
  author       = {Lu, Shengnan and Wang, Yuping and Song, Huansheng},
  doi          = {10.1007/s00500-019-03965-w},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {1283-1291},
  shortjournal = {Soft Comput.},
  title        = {A high accurate vehicle speed estimation method},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improving the one-position inheritance artificial bee colony
algorithm using heuristic search mechanisms. <em>SOCO</em>,
<em>24</em>(2), 1271–1281. (<a
href="https://doi.org/10.1007/s00500-019-03964-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The artificial bee colony algorithm with one-position inheritance (OPIABC) has shown good performance for large-scale problems. But, the improvement in its performance for some other type test problem is not obvious, since the onlookers in this algorithm use the foraging strategy that randomly selects a neighbor to produce a new candidate. Moreover, the scout foraging behavior in this algorithm is completely random, which would sometimes make it consume more search efforts to discover some promising area and hamper its convergent speed especially for large-scale optimization. To further improve its performance, a running information-guided onlooker foraging strategy and a heuristic scout search mechanism are designed and combined with it. The improved OPIABC algorithm has been tested on a set of test functions with dimensions D = 30, 100 and 1000. Experimental results show that after using the heuristic search mechanisms, the performance of the OPIABC algorithm is significantly improved for most test problems.},
  archive      = {J_SOCO},
  author       = {Ning, Jiaxu and Zhang, Changsheng and Zhang, Bin and Wang, Peng},
  doi          = {10.1007/s00500-019-03964-x},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {1271-1281},
  shortjournal = {Soft Comput.},
  title        = {Improving the one-position inheritance artificial bee colony algorithm using heuristic search mechanisms},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Monte carlo method for the real and complex fuzzy system of
linear algebraic equations. <em>SOCO</em>, <em>24</em>(2), 1255–1270.
(<a href="https://doi.org/10.1007/s00500-019-03960-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we apply the Monte Carlo method to solve the real and complex fuzzy system of linear algebraic equations via new techniques. At first, we determine the specified and simpler computing condition for convergence of the Monte Carlo method using Hadamard product related to select the transition probability matrix. Then, we employ the new strategy based on the exclusive characteristic of the Monte Carlo method to find the solution of the real and complex fuzzy system of linear algebraic equations. Finally, some numerical examples are proposed to demonstrate the validity and efficiency of the discussed theoretical concepts.},
  archive      = {J_SOCO},
  author       = {Fathi-Vajargah, Behrouz and Hassanzadeh, Zeinab},
  doi          = {10.1007/s00500-019-03960-1},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {1255-1270},
  shortjournal = {Soft Comput.},
  title        = {Monte carlo method for the real and complex fuzzy system of linear algebraic equations},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An intelligent credit card fraud detection approach based on
semantic fusion of two classifiers. <em>SOCO</em>, <em>24</em>(2),
1243–1253. (<a
href="https://doi.org/10.1007/s00500-019-03958-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increased usage of credit cards for online and regular purchases in E-banking communication systems is vulnerable to credit card fraud. Data imbalance also poses a huge challenge in the fraud detection process. The efficiency of the current fraud detection system (FDS) is in question only because they detect the fraudulent activity after the suspicious transaction is done. This paper proposes an intelligent two-level credit card fraud detection model from highly imbalanced datasets, relying on the semantic fusion of k-means and artificial bee colony algorithm (ABC) to enhance the classification accuracy and speed up detection convergence. ABC as a second classification level performs a kind of neighborhood search combined with the global search to handle the inability the k-means classifier to discover the real cluster if the same data is inputted in a different order it may produce different cluster. Besides, the k-means classifier may be surrounded by the local optimum as it is sensitive to the initial condition. The advised system filters the dataset’ features using a built-in rule engine to analyze whether the transaction is genuine or fraudulent based on many customer behavior (profile) parameters such geographical locations, usage frequency, and book balance. Experimental results indicate that the proposed model can enhance the classification accuracy against the risk coming from suspicious transactions, and gives higher accuracy compared to traditional methods.},
  archive      = {J_SOCO},
  author       = {Darwish, Saad M.},
  doi          = {10.1007/s00500-019-03958-9},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {1243-1253},
  shortjournal = {Soft Comput.},
  title        = {An intelligent credit card fraud detection approach based on semantic fusion of two classifiers},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). SVM hyper-parameters optimization using quantized multi-PSO
in dynamic environment. <em>SOCO</em>, <em>24</em>(2), 1225–1241. (<a
href="https://doi.org/10.1007/s00500-019-03957-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Support vector machine (SVM) is considered as one of the most powerful classifiers. They are parameterized models build upon the support vectors extracted during the training phase. One of the crucial tasks in the modeling of SVM is to select optimal values for its hyper-parameters, because the effectiveness and efficiency of SVM depend upon these parameters. This task of selecting optimal values for the SVM hyper-parameters is often called as the SVM model selection problem. Till now a lot of methods have been proposed to deal with this SVM model selection problem, but most of these methods consider the model selection problem in static environment only, where the knowledge about a problem does not change over time. In this paper we have proposed a framework to deal with SVM model selection problem in dynamic environment. In dynamic environment, knowledge about a problem changes over time due to which static optimum values for yper-parameters may degrade the performance of the classifier. For this there should be one efficient mechanism which can re-evaluate the optimal values of hyper-parameters when the knowledge about a problem changes. Our proposed framework uses multi-swarm-based optimization with exclusion and anti-convergence theory to select the optimal values for the SVM hyper-parameters in dynamic environment. The experiments performed using the proposed framework have shown better results in comparison with other techniques like traditional gird search, first grid search, PSO, chained PSO and dynamic model selection in terms of effectiveness and efficiency.},
  archive      = {J_SOCO},
  author       = {Kalita, Dhruba Jyoti and Singh, Shailendra},
  doi          = {10.1007/s00500-019-03957-w},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {1225-1241},
  shortjournal = {Soft Comput.},
  title        = {SVM hyper-parameters optimization using quantized multi-PSO in dynamic environment},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On shadowed hypergraphs. <em>SOCO</em>, <em>24</em>(2),
1213–1224. (<a
href="https://doi.org/10.1007/s00500-019-03955-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy hypergraphs are useful tools for representing granular structures when describing the relations between objects and set of hyperedges, at minute detail, in a specific granularity. Their merit over classical hypergraphs lies in their ability to model uncertainty that may arise with objects and/or granules incident to each other. Many previous studies on fuzzy hypergraphs seek to exploit their strong descriptive potential to analyze n-ary relations in several contexts. However, due to the very detailed numeric membership grades of their objects, fuzzy hypergraphs are sensitive to noise, which may be overwhelming in their general interpretation. To address this issue, a principle of least commitment to certain membership grades is sort by embracing a framework of shadowed sets. The specific concern of this paper is to study a noise-tolerable framework, viz. shadowed hypergraph. Our goal is to capture and quantify noisy objects in clearly marked out zones. We discuss some characteristic properties of shadowed hypergraph and describe an algorithm for transforming a given fuzzy hypergraph into its resulting shadowed hypergraph. Finally, some illustrative examples are provided to demonstrate the essence of shadowed hypergraphs.},
  archive      = {J_SOCO},
  author       = {William-West, Tamunokuro Opubo},
  doi          = {10.1007/s00500-019-03955-y},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {1213-1224},
  shortjournal = {Soft Comput.},
  title        = {On shadowed hypergraphs},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A core firework updating information guided dynamic
fireworks algorithm for global optimization. <em>SOCO</em>,
<em>24</em>(2), 1185–1211. (<a
href="https://doi.org/10.1007/s00500-019-03953-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a new variant of swarm intelligence algorithm, fireworks algorithm (FWA) exhibits promising performance on a wide set of optimization problems, for which the fireworks algorithm has been concentrated on and investigated by researchers recently. This paper aims to improve the performance of the FWA by exploiting updating information of the core firework to guide the algorithm’s searching process. Based on this mentality, this paper ameliorated the explosion strategy of core firework of dynamic fireworks algorithm (dynFWA). The proposed algorithm, named dynPgFWA in this paper, improved FWA from two aspects: amplifying the explosion amplitude on the direction on which core firework is updated, and making more sparks which are generated by core firework distributed on this direction to enhance the algorithm’s searching ability on updating direction. A numerical experiment on CEC2015 and CEC2017 test suite was implemented to verify the performance of the proposed algorithm. Results of the experiment indicated that dynPgFWA outperformed the compared evolutionary algorithms in the quality of solutions.},
  archive      = {J_SOCO},
  author       = {Zhao, Haitong and Zhang, Changsheng and Ning, Jiaxu},
  doi          = {10.1007/s00500-019-03953-0},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {1185-1211},
  shortjournal = {Soft Comput.},
  title        = {A core firework updating information guided dynamic fireworks algorithm for global optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). ALO-optimized artificial neural network-controlled dynamic
voltage restorer for compensation of voltage issues in distribution
system. <em>SOCO</em>, <em>24</em>(2), 1171–1184. (<a
href="https://doi.org/10.1007/s00500-019-03952-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The major concern in power distribution system is the power quality concerns specifically voltage sag/swell and harmonics. To compensate for such voltage disturbances, an effective device called dynamic voltage restorer (DVR) is utilized in the electric power distribution system. Accordingly, in this paper, the DVR is designed to shield the sensitive load from source-side voltage disturbances under nonlinear load conditions. Further, in the proposed work, an ant lion optimizer-optimized artificial neural network (ALO-ANN) is used to control DVR, thus compensating the balanced and the unbalanced voltage sag/swell and distortions in the load-side voltage. Simulation results using MATLAB/Simulink software are analysed to confirm the efficiency of the suggested ALO-ANN regulator scheme of DVR system at critical loads by comparing with the existing PSO (particle swarm optimization)-centred control scheme.},
  archive      = {J_SOCO},
  author       = {Ansal, V.},
  doi          = {10.1007/s00500-019-03952-1},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {1171-1184},
  shortjournal = {Soft Comput.},
  title        = {ALO-optimized artificial neural network-controlled dynamic voltage restorer for compensation of voltage issues in distribution system},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A genetic algorithm with local search for solving
single-source single-sink nonlinear non-convex minimum cost flow
problems. <em>SOCO</em>, <em>24</em>(2), 1153–1169. (<a
href="https://doi.org/10.1007/s00500-019-03951-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network models are widely used for solving difficult real-world problems. The minimum cost flow problem (MCFP) is one of the fundamental network optimisation problems with many practical applications. The difficulty of MCFP depends heavily on the shape of its cost function. A common approach to tackle MCFPs is to relax the non-convex, mixed-integer, nonlinear programme (MINLP) by introducing linearity or convexity to its cost function as an approximation to the original problem. However, this sort of simplification is often unable to sufficiently capture the characteristics of the original problem. How to handle MCFPs with non-convex and nonlinear cost functions is one of the most challenging issues. Considering that mathematical approaches (or solvers) are often sensitive to the shape of the cost function of non-convex MINLPs, this paper proposes a hybrid genetic algorithm with local search (namely GALS) for solving single-source single-sink nonlinear non-convex MCFPs. Our experimental results demonstrate that GALS offers highly competitive performances as compared to those of the mathematical solvers and a standard genetic algorithm.},
  archive      = {J_SOCO},
  author       = {Ghasemishabankareh, Behrooz and Ozlen, Melih and Li, Xiaodong and Deb, Kalyanmoy},
  doi          = {10.1007/s00500-019-03951-2},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {1153-1169},
  shortjournal = {Soft Comput.},
  title        = {A genetic algorithm with local search for solving single-source single-sink nonlinear non-convex minimum cost flow problems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel meta-heuristic optimization method based on golden
ratio in nature. <em>SOCO</em>, <em>24</em>(2), 1117–1151. (<a
href="https://doi.org/10.1007/s00500-019-03949-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel parameter-free meta-heuristic optimization algorithm known as the golden ratio optimization method (GROM) is proposed. The proposed algorithm is inspired by the golden ratio of plant and animal growth which is formulated by the well-known mathematician Fibonacci. He introduced a series of numbers in which a number (except the first two numbers) is equal to the sum of the two previous numbers. In this series, the ratio of two consecutive numbers is almost the same for all the numbers and is known as golden ratio. This ratio can be extensively found in nature such as snail lacquer part and foliage growth of trees. The proposed approach employed this golden ratio to update the solutions in an optimization algorithm. In the proposed method, the solutions are updated in two different phases to achieve the global best answer. There is no need for any parameter tuning, and the implementation of the proposed method is very simple. In order to evaluate the proposed method, 29 well-known benchmark test functions and also 5 classical engineering optimization problems including 4 mechanical engineering problems and 1 electrical engineering problem are employed. Using several test functions, the performance of the proposed method in solving different problems including discrete, continuous, high dimension, and high constraints problems is testified. The results of the proposed method are compared with those of 11 well-regarded state-of-the-art optimization algorithms. The comparisons are made from different aspects such as the final obtained answer, the speed and behavior of convergence, and CPU time consumption. Superiority of the purposed method from different points of views can be concluded by means of comparisons.},
  archive      = {J_SOCO},
  author       = {Nematollahi, Amin Foroughi and Rahiminejad, Abolfazl and Vahidi, Behrooz},
  doi          = {10.1007/s00500-019-03949-w},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {1117-1151},
  shortjournal = {Soft Comput.},
  title        = {A novel meta-heuristic optimization method based on golden ratio in nature},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Improved grey wolf optimization based on the two-stage
search of hybrid CMA-ES. <em>SOCO</em>, <em>24</em>(2), 1097–1115. (<a
href="https://doi.org/10.1007/s00500-019-03948-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hybrid algorithms with different features are an important trend in algorithm improvement. In this paper, an improved grey wolf optimization based on the two-stage search of hybrid covariance matrix adaptation-evolution strategy (CMA-ES) is proposed to overcome the shortcomings of the original grey wolf optimization that easily falls into the local minima when solving complex optimization problems. First, the improved algorithm divides the whole search process into two stages. In the first stage, the improved algorithm makes full use of the global search ability of grey wolf optimization on a large scale and thoroughly explores the location of the optimal solution. In the second stage, due to CMA-ES having a strong local search capability, the three CMA-ES instances use the α wolf, β wolf and δ wolf as the starting points. In addition, these instances have different step size for parallel local exploitations. Second, in order to make full use of the global search ability of the grey wolf algorithm, the Beta distribution is used to generate as much of an initial population as possible in the non-edge region of the solution space. Third, the new algorithm improves the hunting formula of the grey wolf algorithm, which increases the diversity of the population through the interference of other individuals and reduces the use of the head wolf’s guidance to the population. Finally, the new algorithm is quantitatively evaluated by fifteen standard benchmark functions, five test functions of CEC 2014 suite and two engineering design cases. The results show that the improved algorithm significantly improves the convergence, robustness and efficiency for solving complex optimization problems compared with other six well-known optimization algorithms.},
  archive      = {J_SOCO},
  author       = {Zhao, Yun-tao and Li, Wei-gang and Liu, Ao},
  doi          = {10.1007/s00500-019-03948-x},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {1097-1115},
  shortjournal = {Soft Comput.},
  title        = {Improved grey wolf optimization based on the two-stage search of hybrid CMA-ES},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Neural network algorithm based on legendre improved extreme
learning machine for solving elliptic partial differential equations.
<em>SOCO</em>, <em>24</em>(2), 1083–1096. (<a
href="https://doi.org/10.1007/s00500-019-03944-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To provide a new numerical algorithm for solving elliptic partial differential equations (PDEs), the Legendre neural network (LNN) and improved extreme learning machine (IELM) algorithm are introduced to propose a Legendre improved extreme learning machine (L-IELM) method, which is applied to solving elliptic PDEs in this paper. The product of two Legendre polynomials is chosen as basis functions of hidden neurons. Single hidden layer LNN is used to construct approximate solutions and its derivatives of differential equations. IELM algorithm is used for network weights training, and the algorithm steps of the proposed L-IELM method are summarized. Finally, in order to evaluate the present algorithm, various test examples are selected and solved by the proposed approach to validate the calculation accuracy. Comparative study with the earlier methods in literature is described to verify the superiority of the presented L-IELM method. Experiment results show that the proposed L-IELM algorithm can perform well in terms of accuracy and execution time, which in addition provides a new algorithm for solving elliptic PDEs.},
  archive      = {J_SOCO},
  author       = {Yang, Yunlei and Hou, Muzhou and Sun, Hongli and Zhang, Tianle and Weng, Futian and Luo, Jianshu},
  doi          = {10.1007/s00500-019-03944-1},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {1083-1096},
  shortjournal = {Soft Comput.},
  title        = {Neural network algorithm based on legendre improved extreme learning machine for solving elliptic partial differential equations},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel extension to VIKOR method under intuitionistic fuzzy
context for solving personnel selection problem. <em>SOCO</em>,
<em>24</em>(2), 1063–1081. (<a
href="https://doi.org/10.1007/s00500-019-03943-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personnel selection is a challenging problem for any organization. The success of a project is determined by the human resources that handle the project. To make better personnel selections, researchers have adopted multi-criteria decision-making (MCDM) approaches. Among these, fuzzy-based MCDM methods are most frequently used, as they handle vagueness and imprecision better. Intuitionistic fuzzy set (IFS) is a popular MCDM context which provides degree of membership and non-membership for preference elicitation. In this work, we propose a novel decision-making framework that consists of two stages. In the first stage, a new extension to the popular VIKOR method is presented under IFS context. The positive and negative ideal solutions are determined, and VIKOR parameters are calculated using transformation procedure. The proposed method combines the strength of both interval-valued fuzzy set and IFS that is more effective in handling vagueness with a simple formulation setup. In the second stage, a personnel selection problem is used to validate the proposed framework. Finally, the superiority and weakness of the proposed framework are discussed by comparison with other methods.},
  archive      = {J_SOCO},
  author       = {Krishankumar, R. and Premaladha, J. and Ravichandran, K. S. and Sekar, K. R. and Manikandan, R. and Gao, X. Z.},
  doi          = {10.1007/s00500-019-03943-2},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {1063-1081},
  shortjournal = {Soft Comput.},
  title        = {A novel extension to VIKOR method under intuitionistic fuzzy context for solving personnel selection problem},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A variable-level automated defect identification model based
on machine learning. <em>SOCO</em>, <em>24</em>(2), 1045–1061. (<a
href="https://doi.org/10.1007/s00500-019-03942-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Static analysis tools, automatically detecting potential source code defects at an early phase during the software development process, are diffusely applied in safety-critical software fields. However, alarms reported by the tools need to be inspected manually by developers, which is inevitable and costly, whereas a large proportion of them are found to be false positives. Aiming at automatically classifying the reported alarms into true defects and false positives, we propose a defect identification model based on machine learning. We design a set of novel features at variable level, called variable characteristics, for building the classification model, which is more fine-grained than the existing traditional features. We select 13 base classifiers and two ensemble learning methods for model building based on our proposed approach, and the reported alarms classified as unactionable (false positives) are pruned for the purpose of mitigating the effort of manual inspection. In this paper, we firstly evaluate the approach on four open-source C projects, and the classification results show that the proposed model achieves high performance and reliability in practice. Then, we conduct a baseline experiment to evaluate the effectiveness of our proposed model in contrast to traditional features, indicating that features at variable level improve the performance significantly in defect identification. Additionally, we use machine learning techniques to rank the variable characteristics in order to identify the contribution of each feature to our proposed model.},
  archive      = {J_SOCO},
  author       = {Zhang, Yuwei and Xing, Ying and Gong, Yunzhan and Jin, Dahai and Li, Honghui and Liu, Feng},
  doi          = {10.1007/s00500-019-03942-3},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {1045-1061},
  shortjournal = {Soft Comput.},
  title        = {A variable-level automated defect identification model based on machine learning},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep learning for effective android malware detection using
API call graph embeddings. <em>SOCO</em>, <em>24</em>(2), 1027–1043. (<a
href="https://doi.org/10.1007/s00500-019-03940-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High penetration of Android applications along with their malicious variants requires efficient and effective malware detection methods to build mobile platform security. API call sequence derived from API call graph structure can be used to model application behavior accurately. Behaviors are extracted by following the API call graph, its branching, and order of calls. But identification of similarities in graphs and graph matching algorithms for classification is slow, complicated to be adopted to a new domain, and their results may be inaccurate. In this study, the authors use the API call graph as a graph representation of all possible execution paths that a malware can track during its runtime. The embedding of API call graphs transformed into a low dimension numeric vector feature set is introduced to the deep neural network. Then, similarity detection for each binary function is trained and tested effectively. This study is also focused on maximizing the performance of the network by evaluating different embedding algorithms and tuning various network configuration parameters to assure the best combination of the hyper-parameters and to reach at the highest statistical metric value. Experimental results show that the presented malware classification is reached at 98.86\% level in accuracy, 98.65\% in F-measure, 98.47\% in recall and 98.84\% in precision, respectively.},
  archive      = {J_SOCO},
  author       = {Pektaş, Abdurrahman and Acarman, Tankut},
  doi          = {10.1007/s00500-019-03940-5},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {1027-1043},
  shortjournal = {Soft Comput.},
  title        = {Deep learning for effective android malware detection using API call graph embeddings},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An efficient and robust grey wolf optimizer algorithm for
large-scale numerical optimization. <em>SOCO</em>, <em>24</em>(2),
997–1026. (<a href="https://doi.org/10.1007/s00500-019-03939-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Meta-heuristic algorithms are widely viewed as feasible techniques to solve continuous large-scale numerical optimization problems. Grey wolf optimizer (GWO) is a relatively new stochastic algorithm with only a few parameters to adjust that can be easily used for global optimization. This paper presents an efficient and robust GWO (ERGWO) variant to solve large-scale numerical optimization problems. Inspired by particle swarm optimization, a nonlinearly adjustment strategy for parameter control is designed to balance exploration and exploitation. Additionally, a modified position-updating equation is presented to improve convergence speed. The performance of ERGWO is verified on 18 benchmark large-scale numerical optimization problems with dimensions ranging from 30 to 10,000, 30 benchmarks from CEC 2014, 30 functions in CEC 2017, respectively. Numerical experiments are performed to compare ERGWO to the basic GWO algorithm, other GWO variants, and other well-known meta-heuristic search techniques. Simulations demonstrate that the proposed ERGWO algorithm can find high quality solutions with low computational cost and very fast convergence.},
  archive      = {J_SOCO},
  author       = {Long, Wen and Cai, Shaohong and Jiao, Jianjun and Tang, Mingzhu},
  doi          = {10.1007/s00500-019-03939-y},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {997-1026},
  shortjournal = {Soft Comput.},
  title        = {An efficient and robust grey wolf optimizer algorithm for large-scale numerical optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-objective redundancy hardening with optimal task
mapping for independent tasks on multi-cores. <em>SOCO</em>,
<em>24</em>(2), 981–995. (<a
href="https://doi.org/10.1007/s00500-019-03937-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rate of transient faults has increased significantly as the technology scales up. The tolerance of transient faults has become an important issue in the system design. Dual modular redundancy (DMR) and triple modular redundancy (TMR) are two commonly used techniques that can achieve fault detection and masking through executing redundant tasks. As DMR and TMR have different time and cost overheads, we must carefully determine which one should be used for each task (i.e., task hardening) to achieve the optimal system design. Furthermore, for multi-core systems, the system-level design includes the allocation of cores for the tasks (i.e., task mapping) as well. This paper aims at task hardening and mapping simultaneously for independent tasks on multi-cores with heterogeneous performances, in order to minimize the maximum completion time of all tasks (i.e., makespan). We demonstrate that once task hardening is given, task mapping of independent tasks can be achieved by employing min–max-weight perfect matching with a polynomial time complexity. Besides, as there is a trade-off between cost and time performance, we propose a multi-objective memetic algorithm (MOMA)-based task hardening method to obtain a set of solutions with different numbers of cores (i.e., costs), so the designer can choose different solutions according to different requirements. The key idea of the MOMA is to incorporate problem-specific knowledge into the global search of evolutionary algorithms. Our experimental studies have demonstrated the effectiveness of the proposed method and have shown that by combining the results of MOMA and MOEA we can provide a designer with a highly accurate set of solutions within a reasonable amount of time.},
  archive      = {J_SOCO},
  author       = {Yuan, Bo and Li, Bin and Chen, Huanhuan and Zeng, Zhigang and Yao, Xin},
  doi          = {10.1007/s00500-019-03937-0},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {981-995},
  shortjournal = {Soft Comput.},
  title        = {Multi-objective redundancy hardening with optimal task mapping for independent tasks on multi-cores},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). KNN search-based trajectory cloaking against the cell-ID
tracking in cellular network. <em>SOCO</em>, <em>24</em>(2), 965–980.
(<a href="https://doi.org/10.1007/s00500-019-03935-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widely used smartphone with powerful positioning capability makes it easy for a user to find his precise physical location. However, this may reveal a user’s geo-location information, making the real-time tracking of the user possible. For example, on the basis of a sequence of numbers (i.e., Cell-IDs) received in the Cell-ID positioning, an entity can gain access to a person’s movement routes without his consent. We argue that if the trajectory of a person is traced, then all his visits may be exposed. Therefore, trajectory cloaking against the mobile positioning is urgently necessary. In this paper, we propose a dummy base station replacement (DBSR) algorithm. It mainly uses the idea of dummy trajectory anonymity and is achieved by replacing the true Cell-ID provided by the network with a fake but nearby Cell-ID. We also implement our DBSR algorithm on an Android-based smartphone to evaluate its performance. Experimental results show that the DBSR algorithm can efficiently tackle the privacy breach caused by the single-base-station positioning in cellular network.},
  archive      = {J_SOCO},
  author       = {Cui, Yuanbo and Gao, Fei and Zhang, Hua and Li, Wenmin and Jin, Zhengping},
  doi          = {10.1007/s00500-019-03935-2},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {965-980},
  shortjournal = {Soft Comput.},
  title        = {KNN search-based trajectory cloaking against the cell-ID tracking in cellular network},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A page replacement algorithm based on a fuzzy approach to
improve cache memory performance. <em>SOCO</em>, <em>24</em>(2),
955–963. (<a href="https://doi.org/10.1007/s00500-019-04624-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The memory management in the operating system includes a part called the page replacement algorithms. Replacement algorithms in environments that require high-performance computing are considered as an important issue. For example, these algorithms are very important in cache management in microprocessors, web caching, replication strategies in distributed information systems and so on. Due to the important role of replacement algorithms in overcoming the problem of performance caused by the difference in processor speeds and memory, many algorithms were proposed. Most of them are the developed schemes of the least frequently used (LFU) and least recently used (LRU). Although most proposed designs can solve the LRU and LFU defects, they are implemented in a difficult way. The most important advantage of LRU and LFU is their simple implementation. This research proposes a page replacement algorithm that is simple to implement. The algorithm, which uses three parameters to cluster cache pages, is called the fuzzy page replacement algorithm. Whenever a miss occurs, it selects a page of the cluster with the lowest priority which has the smallest Euclidean distance with its center and then exits the cache. The most significant advantage of the algorithm is using the FCM (fuzzy c-means) algorithm to cluster pages, resulting in better replacement and hence higher memory performance.},
  archive      = {J_SOCO},
  author       = {Akbari Bengar, Davood and Ebrahimnejad, Ali and Motameni, Homayun and Golsorkhtabaramiri, Mehdi},
  doi          = {10.1007/s00500-019-04624-w},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {955-963},
  shortjournal = {Soft Comput.},
  title        = {A page replacement algorithm based on a fuzzy approach to improve cache memory performance},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the initial value problem for fuzzy differential
equations of non-integer order <span
class="math display"><em>α</em> ∈ (1, 2)</span>. <em>SOCO</em>,
<em>24</em>(2), 935–954. (<a
href="https://doi.org/10.1007/s00500-019-04619-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of this paper is to present some basic theories of an initial value problem of fuzzy fractional differential equations involving the Caputo-fuzzy-type concept of fractional derivative in the case of the order $$\alpha \in (1,2).$$ The existence and uniqueness results of the solution for the given problem are presented. Finally, some examples are given to illustrate our main results.},
  archive      = {J_SOCO},
  author       = {Hoa, Ngo Van},
  doi          = {10.1007/s00500-019-04619-7},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {935-954},
  shortjournal = {Soft Comput.},
  title        = {On the initial value problem for fuzzy differential equations of non-integer order $$\alpha \in (1,2)$$},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Solving fuzzy regression equation and its approximation for
random fuzzy variable and their application. <em>SOCO</em>,
<em>24</em>(2), 919–933. (<a
href="https://doi.org/10.1007/s00500-019-04612-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the problem of linear regression is studied for random fuzzy quantity U which has some statistical linear relationship with another random real variable T. First, we turn the problem of fuzzy number linear regression model into the problem of usual real linear regression models, introduce the conception of r-linear regression equation of random fuzzy number, and give two results on what conditions we can determine the fuzzy number coefficients of the random fuzzy quantity linear regression equation by using these real number coefficients of r-linear regression equations. Then, we give specific method and steps to determine the fuzzy number coefficients of the random fuzzy number linear regression equation from a set of statistic of random fuzzy quantity U and random real variable T. And then, for convenience of application, we propose conception of $$\alpha $$-approximation fuzzy number regression equations of random fuzzy number U with respect to random real variable T through further discussion to the fuzzy coefficients of the random fuzzy number linear regression equation and obtain the specific expressions of membership functions of the fuzzy coefficients of the $$\alpha $$-approximation fuzzy number regression equations. At last, we give the specific method of solving the $$\alpha $$-approximation fuzzy number regression equation and use a specific example to show the application and rationality of the proposed method.},
  archive      = {J_SOCO},
  author       = {Wang, Tengfi and Shi, Peng and Wang, Guixiang},
  doi          = {10.1007/s00500-019-04612-0},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {919-933},
  shortjournal = {Soft Comput.},
  title        = {Solving fuzzy regression equation and its approximation for random fuzzy variable and their application},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Learning with policy prediction in continuous state-action
multi-agent decision processes. <em>SOCO</em>, <em>24</em>(2), 901–918.
(<a href="https://doi.org/10.1007/s00500-019-04600-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by recent attention to multi-agent reinforcement learning (MARL), the effort to provide efficient methods in this field is increasing. But, there are many issues which make this field challenging. Decision making of an agent depends on the other agents’ behavior while sharing information is not always possible. On the other hand, predicting other agents’ policies while they are also learning is a difficult task. Also, some agents in a multi-agent environment may not behave rationally. In such cases, achieving Nash equilibrium, as a target in a system with ideal behavior, is not possible and the best policy is the best response to the other agents’ policies. In addition, many real-world multi-agent problems have a continuous nature in their state and action spaces. This induces complexity in MARL scenarios. In order to overcome these challenges, we propose a new multi-agent learning method based on fuzzy least-square policy iteration. The proposed method consists of two parts: an Inner Model as one other agent policy approximation method and a multi-agent method to learn a near-optimal policy based on the others agents’ policies. Both of the proposed algorithms are applicable to problems with continuous state and action spaces. These methods can be used independently or in combination with each other. They are defined to perfectly suit each other so that the outputs of Inner Model are entirely consistent with the nature of inputs of the multi-agent method. In problems with no possibility of explicit communication, combinations of the proposed methods are recommended. In addition, theoretical analysis proves the near optimality of the policies learned by these methods. We evaluate the learning methods in problems with continuous state-action spaces: the well-known predator–prey problem and the unit commitment problem in the smart power grid. The results are satisfactory and show acceptable performance of our methods.},
  archive      = {J_SOCO},
  author       = {Ghorbani, Farzaneh and Afsharchi, Mohsen and Derhami, Vali},
  doi          = {10.1007/s00500-019-04600-4},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {901-918},
  shortjournal = {Soft Comput.},
  title        = {Learning with policy prediction in continuous state-action multi-agent decision processes},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). A note on the algebraicity of l-fuzzy subalgebras in
universal algebra. <em>SOCO</em>, <em>24</em>(2), 895–899. (<a
href="https://doi.org/10.1007/s00500-019-04594-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a universal algebra $${\mathcal {A}}:=(A;~F^A)$$ of type $${\mathcal {F}}$$, it is well known that the lattice $${\mathbb {S}}ub({\mathcal {A}})$$ of subuniverses of $${\mathcal {A}}$$ is algebraic and its compact elements are exactly finitely generated subuniverses of $${\mathcal {A}}$$. In this paper, under a distributive algebraic lattice $${\mathcal {L}}:=(L;~\wedge ,~\vee ;~0,~1)$$, we characterize the compact elements of the lattice $${\mathbb {F}}s({\mathcal {A}},L)$$ of L-fuzzy subalgebras of $${\mathcal {A}}$$, which is an extension of $${\mathbb {S}}ub({\mathcal {A}})$$ and show that the latter is algebraic.},
  archive      = {J_SOCO},
  author       = {Foka, S. V. Tchoffo and Tonga, Marcel},
  doi          = {10.1007/s00500-019-04594-z},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {895-899},
  shortjournal = {Soft Comput.},
  title        = {A note on the algebraicity of L-fuzzy subalgebras in universal algebra},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Set operations of fuzzy sets using gradual elements.
<em>SOCO</em>, <em>24</em>(2), 879–893. (<a
href="https://doi.org/10.1007/s00500-019-04578-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The conventional set operations of fuzzy sets are based on the membership functions using the $$\max $$ and $$\min $$ functions. In this paper, we shall consider the set operations of fuzzy sets based on the concepts of gradual sets and gradual elements. When the fuzzy sets can be formulated as consisting of gradual elements like the usual set consisting of usual elements, the intersection and union of fuzzy sets can be defined as the same way as the intersection and union of usual sets. In this case, the set operations of fuzzy sets will be similar to the set operations of crisp sets.},
  archive      = {J_SOCO},
  author       = {Wu, Hsien-Chung},
  doi          = {10.1007/s00500-019-04578-z},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {879-893},
  shortjournal = {Soft Comput.},
  title        = {Set operations of fuzzy sets using gradual elements},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Generalized form solutions of cooperative game with fuzzy
coalition structure. <em>SOCO</em>, <em>24</em>(2), 861–877. (<a
href="https://doi.org/10.1007/s00500-019-04552-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A fuzzy coalition structure is a partition of player set under a certain participation level. In this study, a kind of cooperative games with fuzzy coalition structure (i.e., generalized fuzzy game) is proposed, which can be seen as an extension of game in Owen’s coalition structure. The generalized fuzzy game is defined by partition function, which could be used to express several cooperative games with fuzzy coalition structure (i.e., fuzzy coalition structure games). For the fuzzy coalition structure, the generalized cooperative game could denote the coalition interaction under different participation ratios for players. The properties of generalized fuzzy game have been proven, such as inheritance, supperadditivity and convexity. In order to get unified solution for the generalized fuzzy game, fuzzy Owen value is also extended based on the consistent formula of generalized fuzzy game. It is proved that the fuzzy Owen value is a unique value for the generalized fuzzy game based on symmetric within fuzzy coalition, symmetric across fuzzy coalitions, fuzzy null player, linearity and efficiency. Finally, the fuzzy Owen value is represented by crisp one in order to simplify fuzzy solution computation.},
  archive      = {J_SOCO},
  author       = {Yu, Xiaohui and Du, Zhiping and Zhang, Qiang and Zou, Zhengxing and Zhou, Zhen and Pang, Jinhui},
  doi          = {10.1007/s00500-019-04552-9},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {861-877},
  shortjournal = {Soft Comput.},
  title        = {Generalized form solutions of cooperative game with fuzzy coalition structure},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Spectral resolutions and observables in n-perfect
MV-algebras. <em>SOCO</em>, <em>24</em>(2), 843–860. (<a
href="https://doi.org/10.1007/s00500-019-04543-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We define an observable as a kind of a $$\sigma $$-homomorphism from the Borel $$\sigma $$-algebra of the real line into a $$\mathrm{Rad}$$-Dedekind $$\sigma $$-complete n-perfect MV-algebra with principal radical preserving disjoint unions. We show that there is a one-to-one correspondence between spectral resolutions (defined now with four properties and not with three ones). This correspondence allows us to define a partial order on the set of observables, called the Olson order, as well as a sum of observables which converts the set of observables into a commutative lattice-ordered semigroup with respect to the Olson order and with the sum of observables.},
  archive      = {J_SOCO},
  author       = {Dvurečenskij, Anatolij and Lachman, Dominik},
  doi          = {10.1007/s00500-019-04543-w},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {843-860},
  shortjournal = {Soft Comput.},
  title        = {Spectral resolutions and observables in n-perfect MV-algebras},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A data-driven risk measurement model of software developer
turnover. <em>SOCO</em>, <em>24</em>(2), 825–842. (<a
href="https://doi.org/10.1007/s00500-019-04540-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the software development life cycle, the turnover of software developers is one of the critical risks that may lead to severe problems (such as postponement and failure of projects), which is often ignored by many professionals. To address this problem, we focus on the uncertainty of turnover risk of software developer (TRSD) and its loss incurred to projects. To tackle this problem, we propose a method to quantify the uncertain risks related to developer turnover, including resignation and replacement. Additionally, to calculate the extent of loss caused by TRSD, we employed machine learning, natural language processing, and data mining techniques to identify software development activities and establish the importance of developers by mining and analyzing the commit event logs. Moreover, based on the information entropy theory, we established a risk measurement model of TRSD that can be used to measure the risk level of each developer and the holistic risk of ongoing software projects. Finally, we validated the feasibility and efficacy through a case study.},
  archive      = {J_SOCO},
  author       = {Ma, Zifei and Li, Ruiyin and Li, Tong and Zhu, Rui and Jiang, Rong and Yang, Juan and Tang, Mingjing and Zheng, Ming},
  doi          = {10.1007/s00500-019-04540-z},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {825-842},
  shortjournal = {Soft Comput.},
  title        = {A data-driven risk measurement model of software developer turnover},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Algebraic semantics of the <span
class="math display">$$\left{ \rightarrow ,\square
\right}$$</span>-fragment of propositional lax logic. <em>SOCO</em>,
<em>24</em>(2), 813–823. (<a
href="https://doi.org/10.1007/s00500-019-04536-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we will study a particular subvariety of Hilbert algebras with a modal operator $$\square $$, called Lax Hilbert algebras. These algebras are the algebraic semantic of the $$\left{ \square ,\rightarrow \right} $$-fragment of a particular intuitionistic modal logic, called Propositional Lax Logic ($$\mathcal {PLL}$$), which has applications to the formal verification of computer hardware. These algebras turn to be a generalization of the variety of Heyting algebras with a modal operator studied, under different names, by Macnab (Algebra Univ 12:5–29, 1981), Goldblatt (Math Logic Q 27(31–35):495–529, 1981; J Logic Comput 21(6):1035–1063, 2010) and by Bezhanishvili and Ghilardi (Ann Pure Appl Logic 147:84–100, 2007). We shall prove that the set of fixpoints of a Lax Hilbert algebra $$\left\langle A,\square \right\rangle $$ is a Hilbert algebra such that its dual space is homeomorphic to the subspace of reflexive elements of the dual space of A. We will define the notion of subframe of a Hilbert space $$\left\langle X,{\mathcal {K}}\right\rangle $$, and we will prove that there is a 1–1 correspondence between subframes of $$\left\langle X,{\mathcal {K}}\right\rangle $$ and binary relations $$Q\subseteq X\times X$$ such that $$\left\langle X,{\mathcal {K}},Q\right\rangle $$ is a Lax Hilbert space. In addition, we will define the notion of subframe variety and we will prove that any variety of Hilbert algebras is a subframe variety.},
  archive      = {J_SOCO},
  author       = {Celani, Sergio A. and Montangie, Daniela},
  doi          = {10.1007/s00500-019-04536-9},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {813-823},
  shortjournal = {Soft Comput.},
  title        = {Algebraic semantics of the $$\left{ \rightarrow ,\square \right} $$-fragment of propositional lax logic},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Filters and ideals in the generalization of pseudo-BL
algebras. <em>SOCO</em>, <em>24</em>(2), 795–812. (<a
href="https://doi.org/10.1007/s00500-019-04528-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce the notion of quasi-pseudo-BL algebras as the generalization of pseudo-BL algebras and quasi-pseudo-MV algebras. First, we investigate the properties of quasi-pseudo-BL algebras and show the subdirect product composition of any quasi-pseudo-BL algebra. Especially, some properties of good quasi-pseudo-BL algebras are presented. Second, we discuss the filters of quasi-pseudo-BL algebras and prove that there exists a bijective correspondence between normal filters and filter congruences on a quasi-pseudo-BL algebra. The properties of some special filters are also discussed. Finally, we study the ideals of quasi-pseudo-BL algebras and investigate some connections between ideals and filters of a quasi-pseudo-BL algebra.},
  archive      = {J_SOCO},
  author       = {Chen, Wenjuan and Wang, Hongkai},
  doi          = {10.1007/s00500-019-04528-9},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {795-812},
  shortjournal = {Soft Comput.},
  title        = {Filters and ideals in the generalization of pseudo-BL algebras},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A blind and robust color images watermarking method based on
block transform and secured by modified 3-dimensional hénon map.
<em>SOCO</em>, <em>24</em>(2), 771–794. (<a
href="https://doi.org/10.1007/s00500-019-04524-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a blind and robust color image watermarking method based on a new three-dimensional Hénon chaotic map and uses integer wavelet transform, discrete wavelet transform and contourlet transform in embedding and extracting processes. In the presented approach, color images are divided into $$4\times 4$$ main nonoverlapping parts, and one of the transforms is applied to these parts. Then the low–low sub-band of transform is selected. The suggested map is used to find $$2\times 2$$ blocks in the embedding process. The bits of watermark are embedded in the parts of images to increase the robustness of the proposed watermarking scheme. To improve the quality of the final watermark, the suggested technique uses a correction process in the extracting process. In this paper, the bifurcation diagram, Lyapunov exponent, cobweb plot and trajectory diagram are used to show the chaotic behavior of the proposed map. Based on DIEHARD, ENT and NIST test suites, the suggested map can be used as a pseudo-random number generator. The simulation results show that the proposed watermarking algorithm is robust against most image processing attacks like salt &amp; pepper, cropping, low-pass filter, wiener filter, blurring, etc. The comparison results between the suggested watermarking scheme, and some similar methods show that the presented technique has good performance, imperceptibility, acceptable robustness and outperforms most related methods.},
  archive      = {J_SOCO},
  author       = {Yousefi Valandar, Milad and Jafari Barani, Milad and Ayubi, Peyman},
  doi          = {10.1007/s00500-019-04524-z},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {771-794},
  shortjournal = {Soft Comput.},
  title        = {A blind and robust color images watermarking method based on block transform and secured by modified 3-dimensional hénon map},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Survey on soft computing. <em>SOCO</em>, <em>24</em>(2),
761–770. (<a href="https://doi.org/10.1007/s00500-019-04508-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft computing triggers a revolutionary change in the field of computer science and technology. How did soft computing evolve? What is soft computing application situation? Which fields are soft computing widely used? Which fields does soft computing still need popularizing? All of these problems resort to the survey on the development of soft computing.},
  archive      = {J_SOCO},
  author       = {Liang, Yun and He, Tian-ping},
  doi          = {10.1007/s00500-019-04508-z},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {761-770},
  shortjournal = {Soft Comput.},
  title        = {Survey on soft computing},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Choquet integrals of weighted generalized and group
generalized intuitionistic fuzzy soft sets. <em>SOCO</em>,
<em>24</em>(2), 745–760. (<a
href="https://doi.org/10.1007/s00500-019-04472-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For many real multi-criteria decision-making (MCDM) problems under intuitionistic fuzzy environment, most criteria have interactive characteristics so that it is not suitable for us to aggregate them by traditional aggregation operators based on additive measures. To approximate the human subjective decision-making process, this paper puts forward the new aggregation operators of generalized intuitionistic fuzzy soft set (GIFSS) and group generalized intuitionistic fuzzy soft sets (G-GIFSS) through the Chqouet integral. These new operators not only demonstrate the interaction phenomena among elements, experts (or moderators) or the ordered positions of them, but also consider their importance or the order positions of them. Furthermore, the new operators are not necessary to assume additivity and independence among decision-making criteria. It should be noted that the existing aggregation operators of GIFSS and G-GIFSS are special cases of the new Choquet integral operators. Two Choquet integral operator-based approaches are developed to solve the MCDM under the intuitionistic fuzzy soft set environment. Finally, a practical example of MCDM is given to validate the effectiveness of the proposal.},
  archive      = {J_SOCO},
  author       = {Li, Sheng and Peng, Xiao-qi and Li, Yu-xiao},
  doi          = {10.1007/s00500-019-04472-8},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {745-760},
  shortjournal = {Soft Comput.},
  title        = {Choquet integrals of weighted generalized and group generalized intuitionistic fuzzy soft sets},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust convex clustering. <em>SOCO</em>, <em>24</em>(2),
731–744. (<a href="https://doi.org/10.1007/s00500-019-04471-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objective-based clustering is a class of important clustering analysis techniques; however, these methods are easily beset by local minima due to the non-convexity of their objective functions involved, as a result, impacting final clustering performance. Recently, a convex clustering method (CC) has been on the spot light and enjoys the global optimality and independence on the initialization. However, one of its downsides is non-robustness to data contaminated with outliers, leading to a deviation of the clustering results. In order to improve its robustness, in this paper, an outlier-aware robust convex clustering algorithm, called as RCC, is proposed. Specifically, RCC extends the CC by modeling the contaminated data as the sum of the clean data and the sparse outliers and then adding a Lasso-type regularization term to the objective of the CC to reflect the sparsity of outliers. In this way, RCC can both resist the outliers to great extent and still maintain the advantages of CC, including the convexity of the objective. Further we develop a block coordinate descent approach with the convergence guarantee and find that RCC can usually converge just in a few iterations. Finally, the effectiveness and robustness of RCC are empirically corroborated by numerical experiments on both synthetic and real datasets.},
  archive      = {J_SOCO},
  author       = {Quan, Zhenzhen and Chen, Songcan},
  doi          = {10.1007/s00500-019-04471-9},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {731-744},
  shortjournal = {Soft Comput.},
  title        = {Robust convex clustering},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Left residuated lattices induced by lattices with a unary
operation. <em>SOCO</em>, <em>24</em>(2), 723–729. (<a
href="https://doi.org/10.1007/s00500-019-04461-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a previous paper, the authors defined two binary term operations in orthomodular lattices such that an orthomodular lattice can be organized by means of them into a left residuated lattice. It is a natural question if these operations serve in this way also for more general lattices than the orthomodular ones. In our present paper, we involve two conditions formulated as simple identities in two variables under which this is really the case. Hence, we obtain a variety of lattices with a unary operation which contains exactly those lattices with a unary operation which can be converted into a left residuated lattice by use of the above mentioned operations. It turns out that every lattice in this variety is in fact a bounded one and the unary operation is a complementation. Finally, we use a similar technique by using simpler terms and identities motivated by Boolean algebras.},
  archive      = {J_SOCO},
  author       = {Chajda, Ivan and Länger, Helmut},
  doi          = {10.1007/s00500-019-04461-x},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {723-729},
  shortjournal = {Soft Comput.},
  title        = {Left residuated lattices induced by lattices with a unary operation},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cost optimization of rectangular RC footing using GA and
UPSO. <em>SOCO</em>, <em>24</em>(2), 709–721. (<a
href="https://doi.org/10.1007/s00500-019-04437-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper presents an estimation of the optimum cost of an isolated foundation following the safety and serviceability guidelines of Indian Standard (IS) 456:2000. Two adaptable optimization algorithms are developed for the first time to optimize the cost of any type of isolated footing design. Two optimization methods, i.e., constrained binary-coded genetic algorithm, with static penalty function approach and unified particle swarm optimization are developed in MATLAB compliant for optimal design of any isolated foundations. The objective function formulated is based on the total cost of footing. This includes the cost of concrete, the cost of steel and cost of formwork. The design variables which influence the total cost of footing are plan area and depth of footing and area of flexural reinforcement at moment critical sections. The footing design algorithm is developed according to the biaxial-isolated rectangular footing as per IS codes. The constraints, e.g., dimension of footing, restriction on bending, shear stresses and displacements, are considered in the footing design algorithm which acted as a subroutine to the developed optimization programs. Four different numerical examples have been solved to evaluate the versatility of the developed method. A comparison study has been done to observe the efficacy of both the optimization methods.},
  archive      = {J_SOCO},
  author       = {Chaudhuri, Payel and Maity, Damodar},
  doi          = {10.1007/s00500-019-04437-x},
  journal      = {Soft Computing},
  number       = {2},
  pages        = {709-721},
  shortjournal = {Soft Comput.},
  title        = {Cost optimization of rectangular RC footing using GA and UPSO},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Application of the TOPSİS method to improve software
efficiency and to optimize its management. <em>SOCO</em>,
<em>24</em>(1), 697–708. (<a
href="https://doi.org/10.1007/s00500-019-04549-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Technique for Order of Prevention by Similarity to Ideal Solution (TOPSİS) method is used for decision-making to improve software efficiency and to optimize its management by using methodological approaches. TOPSIS method is a multi-criteria decision-making analysis method. TOPSIS identifies the best alternative variant based on compromise solution. The basic concept of the TOPSIS method is that the chosen alternate variant has to be at the shortest Euclidean distance from the positive ideal solution and at the farthest Euclidean distance from the negative ideal solution. Criteria and alternatives for software are identified. Two or three of software features from other studies are used. Based on international experience, practically, only few characteristics of software efficiency have been used in the articles so far, but not all eight characteristics. Eight attributes of software efficiency are used, which distinguish this study from others. The values of the worst and best alternatives are found in multi-criterion decision-making by using the estimations of four expert programmers. The software currently run in three systems was used in experiments. The skills of the experts are also taken into account for finding the values. The results of the experiments are estimated to be good.},
  archive      = {J_SOCO},
  author       = {Mahmudova, Shafagat},
  doi          = {10.1007/s00500-019-04549-4},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {697-708},
  shortjournal = {Soft Comput.},
  title        = {Application of the TOPSİS method to improve software efficiency and to optimize its management},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modified fuzzy TOPSIS + TFNs ranking model for candidate
selection using the qualifying criteria. <em>SOCO</em>, <em>24</em>(1),
681–695. (<a href="https://doi.org/10.1007/s00500-019-04521-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, globalization process significantly impacts not only technological, economical, but also social, political and cultural fields. Ongoing social, economic and political processes demonstrate their impacts, and countries are governed by different regimes and government forms. From this standpoint, there is a need for qualified, competent staff for operation of the regimes and governments. In the article researches, which criteria or factors must be taken into account for selection of competent candidates that are suitable for relevant positions during the election process in contrast to traditional voting. Criteria for candidates’ selection include adoption of democratic principles, age, education, government agency experience, professional competence, global culture and value acknowledgement, influence in voting area, leadership skills, activity in social media, etc. In the article implemented multi-criteria evaluation approach for candidate selection. Candidates are ranked based on criteria selected using modified fuzzy TOPSIS and triangular fuzzy numbers ranking methods and different aggregation operators. Candidates are ranked by applying both methods in a numeral experiment, and obtained results are compared. Proposed fuzzy multi-criteria decision-making model allows determining a compromise solution in candidate selection.},
  archive      = {J_SOCO},
  author       = {Alguliyev, Rasim and Aliguliyev, Ramiz and Yusifov, Farhad},
  doi          = {10.1007/s00500-019-04521-2},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {681-695},
  shortjournal = {Soft Comput.},
  title        = {Modified fuzzy TOPSIS + TFNs ranking model for candidate selection using the qualifying criteria},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new method for prediction of air pollution based on
intelligent computation. <em>SOCO</em>, <em>24</em>(1), 661–680. (<a
href="https://doi.org/10.1007/s00500-019-04495-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection and treatment of increasing air pollution due to technological developments represent some of the most important challenges facing the world today. Indeed, there has been a significant increase in levels of environmental pollution in recent years. The aim of the work presented herein is to design an intelligent predictor for the concentrations of air pollutants over the next 2 days based on deep learning techniques using a recurrent neural network (RNN). The best structure for its operation is then determined using a particle swarm optimization (PSO) algorithm. The new predictor based on intelligent computation relying on unsupervised learning, i.e., long short-term memory (LSTM) and optimization (i.e., PSO), is called the smart air quality prediction model (SAQPM). The main goal is to predict six the concentrations of six types of air pollution, viz. PM2.5 particulate matter, PM10, particulate matter, nitrogen dioxide (NO2), carbon monoxide (CO), ozone (O3), and sulfur dioxide (SO2). SAQPM consists of four stages. The first stage involves data collection from multiple stations (35 in this case). The second stage involves preprocessing of the data, including (a) separation of each station with an independent focus, (b) handle missing values, and (c) normalization of the dataset to the range of (0, 1) using the MinMaxScalar method. The third stage relates to building the predictor based on the LSTM method by identifying the best structure and parameter values (weight, bias, number of hidden layers, number of nodes in each hidden layer, and activation function) for the network using the functional PSO algorithm to achieve a goal. Thereafter, the dataset is split into training and testing parts based on the ten cross-validation principle. The training dataset is then used to build the predictor. In the fourth stage, evaluation results for each station are obtained by reading the concentration of each pollutant each hour for at most 30 days then taking the average of the symmetric mean absolute percentage error (SMAPE) for 25 days only.},
  archive      = {J_SOCO},
  author       = {Al-Janabi, Samaher and Mohammad, Mustafa and Al-Sultan, Ali},
  doi          = {10.1007/s00500-019-04495-1},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {661-680},
  shortjournal = {Soft Comput.},
  title        = {A new method for prediction of air pollution based on intelligent computation},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fuzzy applications of best–worst method in manufacturing
environment. <em>SOCO</em>, <em>24</em>(1), 647–659. (<a
href="https://doi.org/10.1007/s00500-019-04491-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-strength steel alloys, titanium, ceramics, composites are in the group of materials that are hard to machine. Conventional manufacturing techniques are not sufficient to machine these materials. For this reason, these materials are generally machined with non-conventional manufacturing methods. In this study, a fuzzy application of Best–Worst method and a novel hybrid decision-making model (Best–Worst decision-making approach with fuzzy TOPSIS) are proposed to solve different non-traditional machining method selection problems which were taken from the literature. Using these models, the Best–Worst method shortens the steps of solutions in the fuzzy environment compared to the AHP/ANP-based fuzzy solutions in the literature. The proposed models produce successful results.},
  archive      = {J_SOCO},
  author       = {Sofuoğlu, Mehmet Alper},
  doi          = {10.1007/s00500-019-04491-5},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {647-659},
  shortjournal = {Soft Comput.},
  title        = {Fuzzy applications of Best–Worst method in manufacturing environment},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A modified shuffled frog leaping algorithm for scientific
workflow scheduling using clustering techniques. <em>SOCO</em>,
<em>24</em>(1), 637–646. (<a
href="https://doi.org/10.1007/s00500-019-04484-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The scientific workflows in the field of science like biology and astronomy are essential in facilitating and automating the scientific data of high volumes and their processing especially in a computing structure that is large. Owing to the large need for resources, a public heterogeneous cloud tends to play a major role in the completion of tasks. The traditional researches falling into the scheduling workflows in cloud applications were focusing on the problems that have a quality of service that is not sufficient for the competitive environment that exists today. There are scientific workflows that consist of several granular tasks which are intensive in terms of data. For a computational granularity that is efficient, the task clustering has a major role to play in reducing the length of the schedule and the utilization of resources. The workflow scheduling is a prominent issue in cloud computing, and this makes an attempt to map workflow tasks to VMs on the basis of various functional needs. The very popular approaches to this are either the static or the dynamic scheduling algorithms that have been based on various heuristics like the Opportunistic Load Balancing (OLB). But, in the case of workflow scheduling, this becomes a non-deterministic polynomial-hard optimization and is a challenge to achieve within an optimal schedule. The proposed work is a vertical node partition that makes use the vertical node partition that make use of a heuristic and novel shuffled frog leaping algorithm (SFLA) technique of clustering for optimal scheduling of scientific workflow. The results of the technique have shown that the SFLA proposed along with the method of clustering has achieved better performance (in terms of makespan and utilization of resources) compared to the SFLA and the OLB without clustering.},
  archive      = {J_SOCO},
  author       = {Karpagam, M. and Geetha, K. and Rajan, C.},
  doi          = {10.1007/s00500-019-04484-4},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {637-646},
  shortjournal = {Soft Comput.},
  title        = {A modified shuffled frog leaping algorithm for scientific workflow scheduling using clustering techniques},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improvement in hadoop performance using integrated feature
extraction and machine learning algorithms. <em>SOCO</em>,
<em>24</em>(1), 627–636. (<a
href="https://doi.org/10.1007/s00500-019-04453-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Big Data has been a term used in datasets which are complex and large in such a way there are some traditional technologies of data processing which are not adequate. Big Data can revolutionize most aspects in society such as collection or management of data from Big Data which is challenging and also very complex. The Hadoop has been designed for processing a large amount of unstructured and complex data. It has provided with a large amount of storage for data along with the ability to be able to tackle unlimited and concurrent tasks or jobs. The selection of features is an extremely powerful technique in the reduction of dimensionality and is also the most important step in machine learning applications. In recent decades, data is getting larger in a progressive manner in terms of instances and numbers making it very hard to deal with the problem of feature selection. In order to cope with such an epoch of Big Data, there are some more new techniques that are required to address the problem in a more efficient manner. At the same time, the suitability of the algorithms currently used may not be applicable especially when the size of data is above hundreds of gigabytes. For the purpose of this work, the correlation-based feature selection along with mutual information-based methods of feature selection was used for improving the performance. The AdaBoost and the support vector machine based classifiers have been used for improving their accuracy. The results of the experiment prove that the method proposed was able to achieve better performance compared to that of the other methods.},
  archive      = {J_SOCO},
  author       = {Sarumathiy, C. K. and Geetha, K. and Rajan, C.},
  doi          = {10.1007/s00500-019-04453-x},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {627-636},
  shortjournal = {Soft Comput.},
  title        = {Improvement in hadoop performance using integrated feature extraction and machine learning algorithms},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Graph coloring: A novel heuristic based on trailing
path—properties, perspective and applications in structured networks.
<em>SOCO</em>, <em>24</em>(1), 603–625. (<a
href="https://doi.org/10.1007/s00500-019-04278-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph coloring is a manifestation of graph partitioning, wherein a graph is partitioned based on the adjacency of its elements. The fact that there is no general efficient solution to this problem that may work unequivocally for all graphs opens up the realistic scope for combinatorial optimization algorithms to be invoked. The algorithmic complexity of graph coloring is non-deterministic in polynomial time and hard. To the best of our knowledge, there is no algorithm as yet that procures an exact solution of the chromatic number comprehensively for any and all graphs within the polynomial (P) time domain. Here, we present a novel heuristic, namely the ‘trailing path’, which returns an approximate solution of the chromatic number within P time, and with a better accuracy than most existing algorithms. The ‘trailing path’ algorithm is effectively a subtle combination of the search patterns of two existing heuristics (DSATUR and largest first) and operates along a trailing path of consecutively connected nodes (and thereby effectively maps to the problem of finding spanning tree(s) of the graph) during the entire course of coloring, where essentially lies both the novelty and the apt of the current approach. The study also suggests that the judicious implementation of randomness is one of the keys toward rendering an improved accuracy in such combinatorial optimization algorithms. Apart from the algorithmic attributes, essential properties of graph partitioning in random and different structured networks have also been surveyed, followed by a comparative study. The study reveals the remarkable stability and absorptive property of chromatic number across a wide array of graphs. Finally, a case study is presented to demonstrate the potential use of graph coloring in protein design—yet another hard problem in structural and evolutionary biology.},
  archive      = {J_SOCO},
  author       = {Bandyopadhyay, Abhirup and Dhar, Amit kumar and Basu, Sankar},
  doi          = {10.1007/s00500-019-04278-8},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {603-625},
  shortjournal = {Soft Comput.},
  title        = {Graph coloring: A novel heuristic based on trailing path—properties, perspective and applications in structured networks},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Zombie politics: Evolutionary algorithms to counteract the
spread of negative opinions. <em>SOCO</em>, <em>24</em>(1), 591–601. (<a
href="https://doi.org/10.1007/s00500-019-04251-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is about simulating the spread of opinions in a society and about finding ways to counteract that spread. To abstract away from potentially emotionally laden opinions, we instead simulate the spread of a zombie outbreak in a society. The virus causing this outbreak is different from traditional approaches: It not only causes a binary outcome (healthy vs. infected) but rather a continuous outcome. To counteract the outbreak, a discrete number of infection-level-specific treatments are available. This corresponds to acts of mild persuasion or the threats of legal action in the opinion spreading use case. This paper offers a genetic and a cultural algorithm that find the optimal mixture of treatments during the run of the simulation. They are assessed in a number of different scenarios. It is shown that albeit far from being perfect, the cultural algorithm delivers superior performance at lower computational expense.},
  archive      = {J_SOCO},
  author       = {Hochreiter, Ronald and Waldhauser, Christoph},
  doi          = {10.1007/s00500-019-04251-5},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {591-601},
  shortjournal = {Soft Comput.},
  title        = {Zombie politics: Evolutionary algorithms to counteract the spread of negative opinions},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modeling of EHD inkjet printing performance using soft
computing-based approaches. <em>SOCO</em>, <em>24</em>(1), 571–589. (<a
href="https://doi.org/10.1007/s00500-019-04202-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nature-inspired heuristic and/or metaheuristic algorithms have been used for solving complex real-world problems in recent years. Electrohydrodynamic (EHD) inkjet printing is a microadditive manufacturing process in which high-resolution jets of polarizable functional materials were deposited on the defined spot of a substrate at the appointed time. The quality of the printed features is derived by the complex physics of the system. Parameter modeling of this process was carried out by using regression analysis, a feed-forward neural network trained with backpropagation (BPNN) and a neural network trained with a genetic algorithm (GA-NN) separately. This study emphasizes the droplet diameter prediction of an EHD inkjet printing system and explores the applicability of the soft computing-based methods for this new emerging technology. Soft computing-based approaches have been developed for the first time in this area to model the EHD inkjet process. Five hundred data were produced through the conventional regression analysis to train the neural network-based models. Output droplet diameter was predicted for different combinations of input parameters such as standoff height (SH), applied voltage (AV) and ink flow rate (FR) using the above three approaches, and their performances were analyzed through some randomly created real experimental test cases. All three models gave good prediction accuracy with less than 10\% error in the prediction of the droplet diameter. Furthermore, it had been observed that the performance of GA-NN surpasses both the regression- and BPNN-based approaches in most of the test cases. It achieved quite satisfactory average absolute percentage deviation value of 2.51\% between the target and predicted output using GA-NN model, which also showed an improvement over the regression or BPNN model.},
  archive      = {J_SOCO},
  author       = {Ball, Amit Kumar and Das, Raju and Roy, Shibendu Shekhar and Kisku, Dakshina Ranjan and Murmu, Naresh Chandra},
  doi          = {10.1007/s00500-019-04202-0},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {571-589},
  shortjournal = {Soft Comput.},
  title        = {Modeling of EHD inkjet printing performance using soft computing-based approaches},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A nifty collaborative analysis to predicting a novel tool
(DRFLLS) for missing values estimation. <em>SOCO</em>, <em>24</em>(1),
555–569. (<a href="https://doi.org/10.1007/s00500-019-03972-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the important trends in an intelligent data analysis will be the growing importance of data processing. But this point faces problems similar to those of data mining (i.e., high-dimensional data, missing value imputation and data integration); one of the challenges in estimation missing value methods is how to select the optimal number of nearest neighbors of those values. This paper, attempting to search the capability of building a novel tool to estimate missing values of various datasets called developed random forest and local least squares (DRFLLS). By developing random forest algorithm, seven categories of similarity measures were defined. These categories are person similarity coefficient, simple similarity, and fuzzy similarity (M1, M2, M3, M4 and M5). They are sufficient to estimate the optimal number of neighborhoods of missing values in this application. Hereafter, local least squares (LLS) has been used to estimate the missing values. Imputation accuracy can be measured in different ways: Pearson correlation (PC) and NRMSE. Then, the optimal number of neighborhoods is associated with the highest value of PC and a smaller value of NRMSE. The experimental results were carried out on six datasets obtained from different disciplines, and DRFLLS proves the dataset which has a small rate of missing values gave the best estimation to the number of nearest neighbors by DRFPC and in the second degree by DRFFSM1 when r = 4, while if the dataset has high rate of missing values, then it gave the best estimation to number of nearest neighbors by DRFFSM5 and in the second degree by DRFFSM3. After that, the missing value was estimated by LLS, and the results accuracy was measured by NRMSE and Pearson correlation. The smallest value of NRMSE for a given dataset is corresponding to DRF correlation function which is a better function for a given dataset. The highest value of PC for a given dataset is corresponding to DRF correlation function which is a better function for a given dataset.},
  archive      = {J_SOCO},
  author       = {Al-Janabi, Samaher and Alkaim, Ayad F.},
  doi          = {10.1007/s00500-019-03972-x},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {555-569},
  shortjournal = {Soft Comput.},
  title        = {A nifty collaborative analysis to predicting a novel tool (DRFLLS) for missing values estimation},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A multiple pheromone ant colony optimization scheme for
energy-efficient wireless sensor networks. <em>SOCO</em>,
<em>24</em>(1), 543–553. (<a
href="https://doi.org/10.1007/s00500-019-03933-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ant colony optimization (ACO) is a well-applied technique to solve the real-time problem of discovering the energy-efficient routes to transmit the sensing information to the base station (BS). Traditionally, ACO incorporated wireless sensor networks used only one pheromone, i.e., minimum distance between the sensor nodes to discover the optimum route to the BS. The authors illustrated a multiple pheromone-based ACO technique known as multiple pheromone ant colony optimization (MPACO), for instance, distance between sensing nodes, their residual energy and number of neighbor nodes to ascertain an efficient route. MPACO enables the sensing nodes to transmit the sensing data to BS over optimal routes with economical energy consumption to achieve a prolonged network life span. The comprehensive evaluation reveals that MPACO proffers 20\% more network lifetime than the current existing ACO technique, i.e., improved ACO. Moreover, MPACO shows a significant improvement of 300\% in network life span than another existing fuzzy-based strategy, i.e., multi-objective fuzzy clustering algorithm.},
  archive      = {J_SOCO},
  author       = {Arora, Vishal Kumar and Sharma, Vishal and Sachdeva, Monika},
  doi          = {10.1007/s00500-019-03933-4},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {543-553},
  shortjournal = {Soft Comput.},
  title        = {A multiple pheromone ant colony optimization scheme for energy-efficient wireless sensor networks},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Distance measures on intuitionistic fuzzy sets based on
intuitionistic fuzzy dissimilarity functions. <em>SOCO</em>,
<em>24</em>(1), 523–541. (<a
href="https://doi.org/10.1007/s00500-019-03932-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the significant topics in intuitionistic fuzzy set (IFS) is the measure of the distance between IFSs. Although distance measures on IFSs have been widely studied in previous studies, there are few studies about the generation of them. In this paper, a quaternary function called intuitionistic fuzzy dissimilarity function is proposed to construct distance measures on IFSs. Two methods for building intuitionistic fuzzy dissimilarity functions are presented. The first one is obtained by combining dissimilarity functions and fuzzy equivalencies. The second one is obtained based on constructing new intuitionistic fuzzy dissimilarity functions through other existing ones. We also examine and compare some properties of intuitionistic fuzzy dissimilarity functions, through which we obtain some properties of distance measures on IFSs. Some examples of pattern recognition are applied to illustrate the effectiveness of the proposed distance measures on IFSs.},
  archive      = {J_SOCO},
  author       = {He, Xingxing and Li, Yingfang and Qin, Keyun and Meng, Dan},
  doi          = {10.1007/s00500-019-03932-5},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {523-541},
  shortjournal = {Soft Comput.},
  title        = {Distance measures on intuitionistic fuzzy sets based on intuitionistic fuzzy dissimilarity functions},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Perception based performance analysis of higher education
institutions: A soft computing approach. <em>SOCO</em>, <em>24</em>(1),
513–521. (<a href="https://doi.org/10.1007/s00500-019-03931-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the tertiary education institutions, rankings have started gaining ample attention all over the world. This has created a profound impact on the indian higher education system. As a result of that, in 2015, the government of India announced National institutional ranking framework (NIRF) to rank the indian institutions. NIRF is based on multiple parameters which are evaluated by standardised survey. In this work, a mathematical model, which can handle such multiple parameters to rank higher education institutions (HEIs), has been proposed. In this model, six criteria, named as, student intake, faculty strength, expenditure of the institution, research paper published per faculty, placements and perception, are considered. Since the criterion perception is a qualitative criterion and can not be modelled by classical mathematics, fuzzy rule based inference system is proposed to determine its precise value. Then DEA-Entropy-TOPSIS approach has been employed to rank HEIs. To emphasize the applicability of the proposed method, a numerical illustration is provided. It is asserted that this proposed mathematical model is a unique HEIs ranking approach involving human perception.},
  archive      = {J_SOCO},
  author       = {Srinivasan, R. and Jain, Vidyottama and Dharmaraja, S.},
  doi          = {10.1007/s00500-019-03931-6},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {513-521},
  shortjournal = {Soft Comput.},
  title        = {Perception based performance analysis of higher education institutions: A soft computing approach},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Partial divergence measure of uncertain random variables and
its application. <em>SOCO</em>, <em>24</em>(1), 501–512. (<a
href="https://doi.org/10.1007/s00500-019-03929-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-entropy (divergence measure) of two uncertain random variables characterizes the difference of two chance distributions. Sometimes, we occur with a complex system as a mixture of uncertain variables and controllable random variables; in order to characterize the difference in these situations, this paper introduces the concept of partial divergence measure of two uncertain random variables and investigates several properties of this concept. Furthermore, some formulas are derived to calculate the partial divergence measure. And how to use these formulas, several examples are provided. Finally, as an application of partial divergence measure, the concept is used to portfolio selection with uncertain random returns as a mixture of new markets and controllable historical markets.},
  archive      = {J_SOCO},
  author       = {Ahmadzade, Hamed and Gao, Rong and Naderi, Habib and Farahikia, Mehran},
  doi          = {10.1007/s00500-019-03929-0},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {501-512},
  shortjournal = {Soft Comput.},
  title        = {Partial divergence measure of uncertain random variables and its application},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Some solving methods for a fuzzy multi-point boundary value
problem. <em>SOCO</em>, <em>24</em>(1), 483–499. (<a
href="https://doi.org/10.1007/s00500-019-03926-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider a fuzzy multi-point boundary value problem-FMBVP [or a multi-point boundary value problem (MBVP) for fuzzy second-order differential equations (FSDEs) under generalized Hukuhara differentiability]. We present solving methods for a FMBVP in the space of fuzzy numbers $$E^{1}$$, such that we have shown the ability to and methods to find solution of the MBVP for FSDEs in the form of $$(FH^{gi}-FH^{gj})$$-solutions. In addition, we provide with a new idea to develop the real Green’s function method and give two examples being simple illustration of this FMBVP.},
  archive      = {J_SOCO},
  author       = {Phu, Nguyen Dinh and Hung, Nguyen Nhut},
  doi          = {10.1007/s00500-019-03926-3},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {483-499},
  shortjournal = {Soft Comput.},
  title        = {Some solving methods for a fuzzy multi-point boundary value problem},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020c). An improved scatter search algorithm for the corridor
allocation problem considering corridor width. <em>SOCO</em>,
<em>24</em>(1), 461–481. (<a
href="https://doi.org/10.1007/s00500-019-03925-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the existing literature on the corridor allocation problem (CAP), the corridor width is not taken into consideration. But in the actual production, the corridor width plays a very important role in logistics transportation inside factories. To study the effect of the corridor width in a CAP problem, the corridor width is considered by a mixed-integer programming model proposed in this paper. Subsequently, an improved scatter search (ISS) algorithm is proposed to handle the CAP. Several improvement mechanisms have been applied to the ISS according to the special characteristics of the problem, such as the adoption of a simulated annealing operation, a dynamic reference set update method, and an improved subset generation method. The proposed ISS is evaluated on test instances of various sizes ranging from 9 to 49 facilities. Computational results demonstrate the validity of the ISS. Specifically, for small-sized instances, the acquired best solutions by the ISS are identical to the optimal solutions obtained by the exact solution given by GUROBI, while for moderate and large-sized instances, the objective values by the ISS are better than those solved by the method in GUROBI. Furthermore, the proposed algorithm shows better performance in solution quality and stability by comparing to the simulated annealing algorithm and the scatter search algorithm.},
  archive      = {J_SOCO},
  author       = {Zhang, Zeqiang and Mao, Lili and Guan, Chao and Zhu, Lixia and Wang, Yi},
  doi          = {10.1007/s00500-019-03925-4},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {461-481},
  shortjournal = {Soft Comput.},
  title        = {An improved scatter search algorithm for the corridor allocation problem considering corridor width},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An improved watermarking algorithm for color image using
schur decomposition. <em>SOCO</em>, <em>24</em>(1), 445–460. (<a
href="https://doi.org/10.1007/s00500-019-03924-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to protect the color image copyright protection of the multimedia big data, it is necessary to design a color image watermarking algorithm. To achieve this purpose, an improved color image watermarking algorithm based on Schur decomposition is proposed in this paper. First, the watermark information is, respectively, embedded into the upper triangular matrix and the unitary matrix of Schur decomposition by two different methods, and two temporary watermarked image blocks are obtained. Then, the proposed improved method is used to select the final watermarked image block from these temporary watermarked image blocks. The highlight of the proposed method is that the final watermarked block has less visual distortion. Meanwhile, the embedded flag is created and uploaded to the cloud service provider with the watermarked image. When extracting watermark, the original host image or the watermark image is not needed. Experimental results show that the proposed watermarking algorithm has better performance; in particular, the watermark invisibility has been obviously improved than other methods considered in this paper.},
  archive      = {J_SOCO},
  author       = {Su, Qingtang and Zhang, Xiaofeng and Wang, Gang},
  doi          = {10.1007/s00500-019-03924-5},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {445-460},
  shortjournal = {Soft Comput.},
  title        = {An improved watermarking algorithm for color image using schur decomposition},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An intuitionistic fuzzy projection-based approach and
application to software quality evaluation. <em>SOCO</em>,
<em>24</em>(1), 429–443. (<a
href="https://doi.org/10.1007/s00500-019-03923-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Projection is a very important measure in decision science. However, this research finds that the existing projection measures are not always reasonable in intuitionistic fuzzy settings. To solve this problem, this work provides a new normalized projection measure. And this work establishes a new group decision-making model based on new normalized projection measure and TOPSIS (technique for order preference by similarity to ideal solution) technique. This paper also introduces a practical application to the software quality evaluation. An experimental analysis shows the practicability, feasibility and validity of method introduced in this paper. In a word, this article contributes to knowledge domain a new decision-making technique and tool.},
  archive      = {J_SOCO},
  author       = {Yue, Chuan},
  doi          = {10.1007/s00500-019-03923-6},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {429-443},
  shortjournal = {Soft Comput.},
  title        = {An intuitionistic fuzzy projection-based approach and application to software quality evaluation},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient compression of volumetric medical images using
legendre moments and differential evolution. <em>SOCO</em>,
<em>24</em>(1), 409–427. (<a
href="https://doi.org/10.1007/s00500-019-03922-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Volumetric medical images are widely used in diagnosing and detecting health problems of patients. Large datasets of volumetric medical images required huge storage space and high network capabilities to transmit these medical images from one location to another especially in the applications of telemedicine and teleradiology. In addition, the quality of medical images plays an important role in successful diagnoses. Therefore, an efficient compression algorithm must achieve significant reduction in the size of these volumetric medical images by using high compression ratio and preserve the quality of these images for successful diagnosis. In this paper, a novel optimized compression algorithm for volumetric medical images is proposed. In this algorithm, the volumetric medical images are divided into two-dimensional (2D) slices where each slice is divided into a group of 8 × 8 nonoverlapped blocks. The Legendre moments are computed for each block where the differential evolution optimization algorithm is utilized to select the optimum moments according to minimization of the cost function. Volumetric medical images from different medical imaging modalities are used in testing and evaluating the proposed compression algorithm. The performance of the proposed algorithm is compared with the existing volumetric medical images compression algorithms where the comparison clearly shows that the proposed algorithm outperforms the existing compression algorithms in terms of mean square error, peak signal-to-noise ratio, normalized correlation coefficient, and structural similarity index.},
  archive      = {J_SOCO},
  author       = {Hosny, Khalid M. and Khalid, Asmaa M. and Mohamed, Ehab R.},
  doi          = {10.1007/s00500-019-03922-7},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {409-427},
  shortjournal = {Soft Comput.},
  title        = {Efficient compression of volumetric medical images using legendre moments and differential evolution},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020c). Utilization of trapezoidal intuitionistic fuzzy numbers and
extended fuzzy preference relation for multi-criteria group
decision-making based on individual differentiation of decision-makers.
<em>SOCO</em>, <em>24</em>(1), 397–407. (<a
href="https://doi.org/10.1007/s00500-019-03921-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In 2015, Li and Chen proposed a multi-criteria group decision-making (MCGDM) method, as similar as technique for order preference by similarity to ideal solution (TOPSIS), with trapezoidal intuitionistic fuzzy information to derive preference values (i.e., alternative ratings) based on individual differentiation of decision-makers. The individual differentiation consideration of decision-makers was useful because alternative ratings and criteria weights in group were generally derived by mean computation in the past. Additionally, MCGDM with trapezoidal intuitionistic fuzzy information is regarded to be the extension of multi-criteria decision-making (MCDM) with group decision-making under fuzzy environment. Practically, fuzzy extension of MCDM is commonly complicated based on the characteristics of fuzzy numbers, especially for intuitionistic fuzzy numbers that may be the most complex one for all kinds of fuzzy numbers. Obviously, Li and Chen’s contribution was extending MCGDM based on individual differentiation of decision-makers under trapezoidal intuitionistic fuzzy environment. Unfortunately, Li and Chen’s method merely expressed the importance difference of decision-makers for yielding preference values, but they derived criteria weights by mean computation. Therefore, the computations of preference values and criteria weights are inconsistent on considering the importance of decision-makers. Besides, their fuzzy extension was complicated and hard for MCGDM with trapezoidal intuitionistic fuzzy information. To resolve the importance inconsistent of yielding ratings and weights as well as fuzzy operation complicated ties, we utilize trapezoidal intuitionistic fuzzy numbers and extended fuzzy preference relation for MCGDM based on individual differentiation of decision-makers in this paper. By utilization of extended fuzzy preference relation, both alternative ratings and criteria weights of MCGDM under intuitionistic fuzzy environment are yielded based on individual differentiation of decision-makers, and decision-making problems are easily and reasonably solved. Furthermore, we also use the simplified version of the MCGDM with trapezoidal intuitionistic fuzzy numbers to evaluate alternatives in the illustrating example of Li and Chen, and compare their evaluating result with the result of proposed method based on individual differentiation of decision-makers.},
  archive      = {J_SOCO},
  author       = {Wang, Yu-Jie},
  doi          = {10.1007/s00500-019-03921-8},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {397-407},
  shortjournal = {Soft Comput.},
  title        = {Utilization of trapezoidal intuitionistic fuzzy numbers and extended fuzzy preference relation for multi-criteria group decision-making based on individual differentiation of decision-makers},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A topological method for reduction in digital information
uncertainty. <em>SOCO</em>, <em>24</em>(1), 385–396. (<a
href="https://doi.org/10.1007/s00500-019-03920-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An attribute reduct, an important concept of rough set theory, is a subset that is sufficient and individually necessary for preserving a particular property of the given information system. In this study, we present a proposed method to calculate the accuracy of data by using the concepts of pre-open and semi-open. We also compared the results of accuracies in the proposed method with the accuracies in Yao and Pawlak methods. Our study revealed that the new model calculating the degree of accuracy was better than the previous models. Additionally, we provided a new insight into the application of the attribute reduction and we used MATLAB programming to obtain the result.},
  archive      = {J_SOCO},
  author       = {Elsafty, M. A. and Alkhathami, A. M.},
  doi          = {10.1007/s00500-019-03920-9},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {385-396},
  shortjournal = {Soft Comput.},
  title        = {A topological method for reduction in digital information uncertainty},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal replacement policy with minimal repair and
preventive maintenance of an aircraft structure subjected to corrosion.
<em>SOCO</em>, <em>24</em>(1), 375–384. (<a
href="https://doi.org/10.1007/s00500-019-03919-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study focuses on a replacement policy using preventive maintenance and periodic inspections with minimal repairs for a deteriorating aircraft structure suffering from corrosion damage. The type of structure component operates normally when its cumulative corroded depth that does not exceed the maintenance allowance threshold and satisfies the reliability requirement. We assume that the number of minimal repairs and preventive maintenance time are both stochastic variables with a independent geometric distribution, and the lifetime has a Weibull distribution. An optimal replacement model is formulated to minimize the expected cost rate with two constraints: corrosion threshold and reliability level. The optimal time interval $$T^{*}$$ between the two successive periodic inspections with minimal repairs and the number of preventive maintenance $$N^{*}$$ can be obtained by an improved iteration algorithm using the golden section method and quadratic interpolation method based on stochastic simulation. Finally, a numerical example using parameters sensitivity analysis is illustrated to verify the proposed model and algorithm.},
  archive      = {J_SOCO},
  author       = {Zhang, Chunxiao and Li, Qiang and Liu, Yankuan},
  doi          = {10.1007/s00500-019-03919-2},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {375-384},
  shortjournal = {Soft Comput.},
  title        = {Optimal replacement policy with minimal repair and preventive maintenance of an aircraft structure subjected to corrosion},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Logarithmic means of sequences of fuzzy numbers and a
tauberian theorem. <em>SOCO</em>, <em>24</em>(1), 367–374. (<a
href="https://doi.org/10.1007/s00500-019-03915-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A sequence $$(x_n)$$ of fuzzy numbers is said to be summable to a fuzzy number L by the logarithmic mean method $$(\ell ,2)$$ if $$\begin{aligned} \lim _{n\rightarrow \infty }\frac{1}{\ell _n^{(2)}}\sum _{k=1}^{n}\frac{x_k}{k\ell _k}=L \end{aligned}$$where $$\begin{aligned} \ell _n^{(2)}=\sum _{k=1}^{n}\frac{1}{k\ell _k}\sim \log (\log n). \end{aligned}$$We prove that the ordinary convergence of $$(x_n)$$ implies its $$(\ell ,2)$$ summability. The converse implication is not necessarily true. Namely, the $$(\ell ,2)$$ summability of $$(x_n)$$ may not imply the convergence of $$(x_n)$$. However, under certain additional conditions the converse may hold. Such conditions are called Tauberian conditions, and the resulting theorem is said to be a Tauberian theorem. In this paper, we provide necessary and sufficient Tauberian conditions to transform $$(\ell ,2)$$ summable sequences of fuzzy numbers into convergent sequences of fuzzy numbers with preserving the limit.},
  archive      = {J_SOCO},
  author       = {Sezer, Sefa Anıl},
  doi          = {10.1007/s00500-019-03915-6},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {367-374},
  shortjournal = {Soft Comput.},
  title        = {Logarithmic means of sequences of fuzzy numbers and a tauberian theorem},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Scheduling multi-component maintenance with a greedy
heuristic local search algorithm. <em>SOCO</em>, <em>24</em>(1),
351–366. (<a href="https://doi.org/10.1007/s00500-019-03914-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As many large-scale systems age, and due to budgetary and performance efficiency concerns, there is a need to improve the decision-making process for system sustainment, including maintenance, repair, and overhaul (MRO) operations and the acquisition of MRO parts. To help address the link between sustainment policies and acquisition, this work develops a greedy heuristic-based local search algorithm (GHLSA) to provide a system maintenance schedule for multi-component systems, coordinating recommended component maintenance times to reduce system downtime costs, thereby enabling effective acquisition. The proposed iterative algorithm aims to minimize the sum of downtime, earliness and tardiness costs of scheduling, which contains three phases: (1) the construction phase, which uses a heuristic to construct an initial partial solution, (2) an improvement phase, which aims to improve the partial solution generated in the construction phase, and finally, (3) a local search phase, which performs a local search technique to the partial solution found in the improvement phase. The proposed algorithm makes a trade-off between exploration and exploitation of solutions. The experimental results for small (10 jobs) and large size (50 jobs) problems indicate that GHLSA outperforms both genetic algorithm and simulated annealing approaches in terms of solution quality and is similar in terms of efficiency.},
  archive      = {J_SOCO},
  author       = {Hosseini, Seyedmohsen and Kalam, Sifat and Barker, Kash and Ramirez-Marquez, Jose E.},
  doi          = {10.1007/s00500-019-03914-7},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {351-366},
  shortjournal = {Soft Comput.},
  title        = {Scheduling multi-component maintenance with a greedy heuristic local search algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal feature selection in industrial foam injection
processes using hybrid binary particle swarm optimization and
gravitational search algorithm in the mahalanobis–taguchi system.
<em>SOCO</em>, <em>24</em>(1), 341–349. (<a
href="https://doi.org/10.1007/s00500-019-03911-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection of variables that contribute to the variation of a system is one of the most important considerations in the industrial manufacturing processes. This work presents the combination of Mahalanobis–Taguchi system and a hybrid binary metaheuristic based on particle swarm optimization and gravitational search algorithm (BPSOGSA) to perform an optimal feature selection in order to detect the relevant variables in a real process of foam injection in automotive industry. The proposed method is compared with other feature selection approach based in binary PSO algorithm. The experimental results revealed that BPSOGSA is faster and successfully converge selecting a smallest subset of features than BPSO. Moreover, the feature selection effect is validated through other widely used machine learning algorithms which improve their accuracy performance when they are trained with the subset of detected variables by the proposed system.},
  archive      = {J_SOCO},
  author       = {Reséndiz-Flores, Edgar O. and Navarro-Acosta, Jesús Alejandro and Hernández-Martínez, Agustín},
  doi          = {10.1007/s00500-019-03911-w},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {341-349},
  shortjournal = {Soft Comput.},
  title        = {Optimal feature selection in industrial foam injection processes using hybrid binary particle swarm optimization and gravitational search algorithm in the Mahalanobis–Taguchi system},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Spatial-domain steganalytic feature selection based on
three-way interaction information and KS test. <em>SOCO</em>,
<em>24</em>(1), 333–340. (<a
href="https://doi.org/10.1007/s00500-019-03910-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To select informative features from steganalytic features, a spatial-domain steganalytic feature selection method based on three-way interaction information and Kolmogorov–Smirnov (KS) test is proposed. Three-way interaction information is employed to rank all the features, and KS test is exploited to remove redundant features. Feature selection process of the proposed method is presented as follows: It calculates mutual information between features and the class label and selects the feature with the maximum value. Then, it loops to calculate three-way interaction information among each candidate feature, the previously selected feature and the class label and select the candidate feature with the maximum value. Following that, it calculates KS test between features and compares an obtained parameter with the predefined significance level for eliminating redundant features. To validate the performance of the proposed method, several typical feature ranking methods based on information measure and spatial-domain steganalytic feature selection methods are adopted for performance comparisons. Experimental results demonstrate that the proposed method can achieve better feature selection performance.},
  archive      = {J_SOCO},
  author       = {Gu, Xiangyuan and Guo, Jichang and Wei, Huiwen and He, Yanhong},
  doi          = {10.1007/s00500-019-03910-x},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {333-340},
  shortjournal = {Soft Comput.},
  title        = {Spatial-domain steganalytic feature selection based on three-way interaction information and KS test},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Incremental mechanism of attribute reduction based on
discernible relations for dynamically increasing attribute.
<em>SOCO</em>, <em>24</em>(1), 321–332. (<a
href="https://doi.org/10.1007/s00500-019-04511-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rough set is a data evaluation methodology to take care of uncertainty in data. Attribute reduction with rough set goals to achieve a compact and informative attribute set for a given data sets, and incremental mechanism is reasonable selection for attribute reduction in dynamic data sets. This paper focuses on introducing incremental mechanism to develop effective incremental algorithm during the arrival of new attributes in terms of approach of discerning samples. The traditional definition of discernibility matrix is improved first to address fewer samples to be discerned. Based on this improvement, discernible relation is developed for every attribute and utilized to characterize attribute reduction. For dynamic data sets with the dynamically increasing of attributes, an incremental mechanism is introduced to judge and ignore unnecessary new arriving attributes. For necessary new arriving attributes, the original reduct is updated in terms of updating of discernible relations instead of information granular or information entropy. The efficiency and effectiveness of developed incremental algorithm based on this mechanism is demonstrated through experimental comparisons in this paper in terms of running time.},
  archive      = {J_SOCO},
  author       = {Chen, Degang and Dong, Lianjie and Mi, Jusheng},
  doi          = {10.1007/s00500-019-04511-4},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {321-332},
  shortjournal = {Soft Comput.},
  title        = {Incremental mechanism of attribute reduction based on discernible relations for dynamically increasing attribute},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Quantile fuzzy regression based on fuzzy outputs and fuzzy
parameters. <em>SOCO</em>, <em>24</em>(1), 311–320. (<a
href="https://doi.org/10.1007/s00500-019-04424-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new approach is investigated to the problem of quantile regression modeling based on the fuzzy response variable and the fuzzy parameters. In this approach, we first introduce a loss function between fuzzy numbers which it can present some quantiles of fuzzy data. Then, we fit a quantile regression model between the available data based on proposed loss function. To evaluate the goodness of fit of the optimal quantile fuzzy regression models, we introduce two indices. Inside, we study the application of the proposed approach in modeling some soil characteristics, based on a real data set.},
  archive      = {J_SOCO},
  author       = {Arefi, Mohsen},
  doi          = {10.1007/s00500-019-04424-2},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {311-320},
  shortjournal = {Soft Comput.},
  title        = {Quantile fuzzy regression based on fuzzy outputs and fuzzy parameters},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Computational properties of pentadiagonal and
anti-pentadiagonal block band matrices with perturbed corners.
<em>SOCO</em>, <em>24</em>(1), 301–309. (<a
href="https://doi.org/10.1007/s00500-019-04415-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we derive an orthogonal block diagonalization and a number of formulas for pentadiagonal block band symmetric Toeplitz matrices and anti-pentadiagonal block band persymmetric Hankel matrices, both with perturbed corners. Namely, our formulas include block diagonalization, inverse, eigenvalues of these matrices. Our approach uses a suitable modification technique for pentadiagonal block band symmetric Toeplitz matrices and anti-pentadiagonal block band persymmetric Hankel matrices. Some numerical experiments are also presented to demonstrate the performance and effectiveness of the proposed theorems.},
  archive      = {J_SOCO},
  author       = {Shams Solary, Maryam},
  doi          = {10.1007/s00500-019-04415-3},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {301-309},
  shortjournal = {Soft Comput.},
  title        = {Computational properties of pentadiagonal and anti-pentadiagonal block band matrices with perturbed corners},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A space–time trade-off for computing the visibility polygon
in the multi-pass model. <em>SOCO</em>, <em>24</em>(1), 293–299. (<a
href="https://doi.org/10.1007/s00500-019-04382-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of computing the visibility polygon of a simple polygon $${\mathcal {P}}$$ from a viewpoint inside it, when $${\mathcal {P}}$$ resides in a read-only memory without random accessibility. This model of stored data is called the multi-pass model in the literature. We present an algorithm to compute the visibility polygon in this model in $$O(nr/t + nt)$$ time, where n is the size of input data, r is the number of reflex vertices of input data, and t is the number of additional variables which we use to compute the visibility polygon where $$2&lt;t&lt;r$$.},
  archive      = {J_SOCO},
  author       = {Asgaripour, Mohammad and Mohades, Ali},
  doi          = {10.1007/s00500-019-04382-9},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {293-299},
  shortjournal = {Soft Comput.},
  title        = {A space–time trade-off for computing the visibility polygon in the multi-pass model},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Anonymous certificateless multi-receiver encryption scheme
for smart community management systems. <em>SOCO</em>, <em>24</em>(1),
281–292. (<a href="https://doi.org/10.1007/s00500-019-04375-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In community management services, it is a common requirement for management centers to send the same encrypted message to some units and individuals in the community, while avoiding the leakage of personal information of the user. In order to achieve this goal safely and efficiently, the multi-receiver encryption is a good option. In the setting, a sender generates the ciphertext for a designed group of receivers. Any receiver in the group can obtain the plaintext by decrypting the ciphertext using his own private key, and the true identity of the receiver is kept secret to anyone including other receivers. Recently, several certificateless multi-receiver encryption (CLMRE) schemes have been introduced, and all of them are proved to be secure in the random oracles model (ROM). ROM is a simulation of the hash function and can not replace the real hash function computation. In this paper, a new CLMRE scheme is constructed and it is proved to be secure based on decision bilinear Diffie–Hellman problem in the standard model (SM). It achieves the anonymity of the receivers and is suitable for smart community management systems.},
  archive      = {J_SOCO},
  author       = {Deng, Lunzhi},
  doi          = {10.1007/s00500-019-04375-8},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {281-292},
  shortjournal = {Soft Comput.},
  title        = {Anonymous certificateless multi-receiver encryption scheme for smart community management systems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Indefinite LQ optimal control for discrete-time uncertain
systems. <em>SOCO</em>, <em>24</em>(1), 267–279. (<a
href="https://doi.org/10.1007/s00500-019-04350-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with a linear quadratic (LQ) optimal control for discrete-time uncertain systems, with indefinite state and control weighting matrices in the cost function. Firstly, a recurrence equation of general optimal control problem for discrete-time uncertain systems is obtained by applying Bellman’s principle of optimality. Then, the optimal state feedback control is obtained based on the recurrence equation. Moreover, a sufficient condition of well-posedness for the LQ problem is proposed and a general expression for the optimal control set is given. Furthermore, a numerical example is presented by using the obtained results. Finally, as an application of the indefinite LQ optimal control, an optimal production inventory problem of uncertain environment is solved.},
  archive      = {J_SOCO},
  author       = {Chen, Yuefen and Zhu, Yuanguo},
  doi          = {10.1007/s00500-019-04350-3},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {267-279},
  shortjournal = {Soft Comput.},
  title        = {Indefinite LQ optimal control for discrete-time uncertain systems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A short note on divisible residuated semilattices.
<em>SOCO</em>, <em>24</em>(1), 259–266. (<a
href="https://doi.org/10.1007/s00500-019-04348-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this note we prove that divisible residuated semilattices have some specific algebraic properties. We show that: (1) for normal and divisible residuated semilattices representability is equivalent to the existence of a join term, (2) any integral divisible residuated semilattice is distributive, and (3) a finite divisible residuated semilattice is integral and commutative.},
  archive      = {J_SOCO},
  author       = {Aglianò, Paolo},
  doi          = {10.1007/s00500-019-04348-x},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {259-266},
  shortjournal = {Soft Comput.},
  title        = {A short note on divisible residuated semilattices},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). N-normal residuated lattices. <em>SOCO</em>, <em>24</em>(1),
247–258. (<a href="https://doi.org/10.1007/s00500-019-04346-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The notion of n-normal residuated lattice, as a subclass of residuated lattices in which every prime filter contains at most n minimal prime filters, is introduced and investigated. Before that, the notion of $$\omega $$-filter is introduced and it is observed that the set of $$\omega $$-filters in a residuated lattice forms a distributive lattice on its own, which includes the set of coannulets as a sublattice. The class of n-normal residuated lattices is characterized in terms of their prime filters, minimal prime filters, coannulets and $$\omega $$-filters. It is shown that a residuated lattice is normal if and only if its reticulation is conormal. Finally, the existence of the greatest $$\omega $$-filters contained in a given filter of a normal residuated lattice is obtained.},
  archive      = {J_SOCO},
  author       = {Rasouli, Saeed and Kondo, Michiro},
  doi          = {10.1007/s00500-019-04346-z},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {247-258},
  shortjournal = {Soft Comput.},
  title        = {N-normal residuated lattices},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Classification of non-local rings with genus two
zero-divisor graphs. <em>SOCO</em>, <em>24</em>(1), 237–245. (<a
href="https://doi.org/10.1007/s00500-019-04345-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The zero-divisor graph of a commutative ring R is a simple graph whose vertices are the nonzero zero divisors of R and two distinct vertices are adjacent if their product is zero. In this article, we determine precisely all non-local commutative rings whose zero-divisor graphs have genus two.},
  archive      = {J_SOCO},
  author       = {Asir, T. and Mano, K.},
  doi          = {10.1007/s00500-019-04345-0},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {237-245},
  shortjournal = {Soft Comput.},
  title        = {Classification of non-local rings with genus two zero-divisor graphs},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Monadic boolean algebras with an automorphism and their
relation to <span
class="math display"><strong>D</strong><strong>f</strong><sub><strong>2</strong></sub></span>-algebras.
<em>SOCO</em>, <em>24</em>(1), 227–236. (<a
href="https://doi.org/10.1007/s00500-019-04317-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we initiate an investigation of the class $${\mathcal {B}}_{T_km}$$ of monadic Boolean algebras endowed with a monadic automorphism of period k. These algebras constitute a generalization of monadic symmetric Boolean algebras. We determine the congruences on these algebras and we characterize the subdirectly irreducible algebras. This last result allows us to prove that $${\mathcal {B}}_{T_km}$$ is a discriminator variety and as a consequence, the principal congruences are characterized. Finally, we explore, in the finite case, the relationship between this class and the class $${\mathbf{Df}}_{\mathbf{2}}$$ of diagonal-free two-dimensional cylindric algebras.},
  archive      = {J_SOCO},
  author       = {Figallo, Aldo V. and Gomes, Claudia M.},
  doi          = {10.1007/s00500-019-04317-4},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {227-236},
  shortjournal = {Soft Comput.},
  title        = {Monadic boolean algebras with an automorphism and their relation to $${\mathbf{Df}}_{\mathbf{2}}$$-algebras},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A review of optimization swarm intelligence-inspired
algorithms with type-2 fuzzy logic parameter adaptation. <em>SOCO</em>,
<em>24</em>(1), 215–226. (<a
href="https://doi.org/10.1007/s00500-019-04290-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a survey about the algorithms based on swarm intelligence with parameter adaptation using some techniques to achieve the best results is presented. In this case, we analyzed the most popular algorithms such as ant colony optimization, particle swarm optimization, bee colony optimization, bat algorithm, firefly algorithm and cuckoo search. These algorithms are referenced in the paper because they have demonstrated to be superior with respect to the other optimization methods based on swarms with parameter adaptation using type-2 fuzzy logic in some applications, and also the algorithms are inspired on swarm intelligence.},
  archive      = {J_SOCO},
  author       = {Valdez, Fevrier},
  doi          = {10.1007/s00500-019-04290-y},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {215-226},
  shortjournal = {Soft Comput.},
  title        = {A review of optimization swarm intelligence-inspired algorithms with type-2 fuzzy logic parameter adaptation},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimization of fuzzy controller design using a differential
evolution algorithm with dynamic parameter adaptation based on type-1
and interval type-2 fuzzy systems. <em>SOCO</em>, <em>24</em>(1),
193–214. (<a href="https://doi.org/10.1007/s00500-019-04156-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes the use of the Differential Evolution algorithm with fuzzy logic for parameter adaptation in the optimal design of fuzzy controllers for nonlinear plants. The Differential Evolution algorithm is enhanced using Type-1 and Interval Type-2 fuzzy systems for achieving dynamic adaptation of the mutation parameter. In this paper, four control optimization problems in which the Differential Evolution algorithm optimizes the membership functions of the fuzzy controllers are presented. First, the experiments were performed with the original algorithm, second the experiments were performed with the Fuzzy Differential Evolution (in this case the mutation parameter is dynamic), and last, experiments were performed applying noise to the control plant by using Fuzzy Differential Evolution.},
  archive      = {J_SOCO},
  author       = {Ochoa, Patricia and Castillo, Oscar and Soria, José},
  doi          = {10.1007/s00500-019-04156-3},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {193-214},
  shortjournal = {Soft Comput.},
  title        = {Optimization of fuzzy controller design using a differential evolution algorithm with dynamic parameter adaptation based on type-1 and interval type-2 fuzzy systems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dynamic parameter adaptation in the harmony search algorithm
for the optimization of interval type-2 fuzzy logic controllers.
<em>SOCO</em>, <em>24</em>(1), 179–192. (<a
href="https://doi.org/10.1007/s00500-019-04124-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At the present time there are several types of metaheuristics which have been used to solve various types of problems in the real world. These metaheuristics contain parameters that are usually fixed throughout the iterations. However, various techniques exist to adjust the parameters of an algorithm such as probabilistic, fuzzy logic, among others. This work describes the methodology and equations for building Triangular and Gaussian interval type-2 membership functions, and this methodology was applied to the optimization of a benchmark control problem with an interval type-2 fuzzy logic controller. To validate in the best way the effect of uncertainty we perform experiments using noise (Pulse generator) and without noise. Also, a statistical z-test is presented to verify the effectiveness of the proposed method. The main contribution of this article is the proposed use of the theory of interval type-2 fuzzy logic to the dynamic adjustment of parameters for the harmony search algorithm and then its application to the optimal design of interval type-2 fuzzy logic controller.},
  archive      = {J_SOCO},
  author       = {Valdez, Fevrier and Peraza, Cinthia},
  doi          = {10.1007/s00500-019-04124-x},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {179-192},
  shortjournal = {Soft Comput.},
  title        = {Dynamic parameter adaptation in the harmony search algorithm for the optimization of interval type-2 fuzzy logic controllers},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-objective optimization of cost-effective and
customer-centric closed-loop supply chain management model in
t-environment. <em>SOCO</em>, <em>24</em>(1), 155–178. (<a
href="https://doi.org/10.1007/s00500-019-04289-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents one real-life-based cost-effective and customer-centric closed-loop supply chain management model. The review of the existing literature identifies the classical performance indicators to any supply chain management model as the aggregate revenue, the customer satisfaction and the environmental concern. However, this review fails to find a single optimization-based supply chain management model that considers these three indicators, simultaneously. In this article, the proposed model maximizes the customer-satisfaction index and the aggregate revenue both under the environmental considerations via the reverse chain, whereas many existing studies took the reverse chain and the associated subsidies into account; this is the first mathematical model that optimizes the customer-satisfaction index, at the same time. This article employs the T-set that represents the inherent impreciseness to objective functions to the proposed model. The corresponding optimal values are superior than stipulated goals to both the objective functions in T-environment. The managerial insights extracted from sensitivity analysis of parameters suggest the managers to stabilize the environmental concern and the customer satisfaction, while ensuring the cost-effectiveness in real-life-based T-environment. Also, this analysis finds that the subsidy assists any supply chain to sustain, only if it is offered without any break and within the optimally determined bounds.},
  archive      = {J_SOCO},
  author       = {Garai, Arindam and Roy, Tapan K.},
  doi          = {10.1007/s00500-019-04289-5},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {155-178},
  shortjournal = {Soft Comput.},
  title        = {Multi-objective optimization of cost-effective and customer-centric closed-loop supply chain management model in T-environment},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A ranking method based on interval type-2 fuzzy sets for
multiple attribute group decision making. <em>SOCO</em>, <em>24</em>(1),
131–154. (<a href="https://doi.org/10.1007/s00500-019-04285-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ranking of fuzzy numbers has become an important research direction for decision-making problems due to its role to find the best objects under uncertainty. In this paper, we propose a new approach to perform multiple attribute group decision-making (MAGDM) problems using the ranking of interval type-2 fuzzy sets. Initially, a new ranking method for interval type-2 fuzzy numbers based on centroid and rank index has been proposed. Next, we present a comparative study to analyze the ranking values of the proposed method with the existing approaches, where we explore the necessity of the proposed ranking method. After that, a new MAGDM approach has been developed using the proposed ranking procedure to solve uncertain MAGDM problems. Finally, the applicability of the proposed approach has been illustrated using two numerical examples and a case study related to car-sharing problems. The proposed study exhibits a useful way to solve fuzzy MAGDM problems with much efficient manner since it applies interval type-2 fuzzy sets compared to type-1 fuzzy sets to signify the evaluating values and weights of the attributes.},
  archive      = {J_SOCO},
  author       = {De, Avijit and Kundu, Pradip and Das, Sujit and Kar, Samarjit},
  doi          = {10.1007/s00500-019-04285-9},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {131-154},
  shortjournal = {Soft Comput.},
  title        = {A ranking method based on interval type-2 fuzzy sets for multiple attribute group decision making},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel parameter estimation in dynamic model via fuzzy
swarm intelligence and chaos theory for faults in wastewater treatment
plant. <em>SOCO</em>, <em>24</em>(1), 111–129. (<a
href="https://doi.org/10.1007/s00500-019-04225-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Faults during a wastewater treatment for plant (WWTP) are critical issue for social and biological. Poorly treated wastewater may achieve dangerous effect for human as well as nature. This paper proposed a novel model based on a binary version of whale optimization algorithm (WOA), chaos theory and fuzzy logic, namely (CF-BWOA). CF-BWOA is applied in the application of WWTP to find out the more relevant attributes from the whole dataset, reducing cost and validation of decision rules, and helping to identify a non-well-structured domain. CF-BWOA attempts to reduce the whole feature set without loss of significant information to the classification process. Fast fuzzy c-means is used as a cost function to measure the fuzzification and uncertainty of data. Ten different chaos sequence maps are used to estimate and tune WOA parameters. Experiments are applied on a complex real-time dataset with various uncertainty features and missing values. The overall result indicates that the CWOA with the Sine chaos map shows the better performance, lower error, higher convergence speed and shorter execution time. In addition, the proposed model is capable of detecting sensor process faults in WWTP with high accuracy and can guide the operators of these systems to control decisions.},
  archive      = {J_SOCO},
  author       = {Anter, Ahmed M. and Gupta, Deepak and Castillo, Oscar},
  doi          = {10.1007/s00500-019-04225-7},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {111-129},
  shortjournal = {Soft Comput.},
  title        = {A novel parameter estimation in dynamic model via fuzzy swarm intelligence and chaos theory for faults in wastewater treatment plant},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improved grey wolf optimization-based feature subset
selection with fuzzy neural classifier for financial crisis prediction.
<em>SOCO</em>, <em>24</em>(1), 101–110. (<a
href="https://doi.org/10.1007/s00500-019-04323-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In present days, prediction of financial crisis of a company is a hot research area. The use of data mining and machine learning algorithms assists to resolve the financial crisis prediction (FCP) problem. Since financial data contain more demographical and unwanted information, it might decrease the classification performance significantly. So, feature selection (FS) process is applied to choose useful data and remove the irrelevant repetitive data. This paper introduces a novel predictive framework for FCP model by the incorporation of improved grey wolf optimization (IGWO) and fuzzy neural classifier (FNC). An IGWO algorithm is derived by the integration of GWO algorithm and tumbling effect. The presented IGWO-based FS method is employed to discover the optimal features from the financial data. For classification purposes, FNC is employed. The proposed method is experimented on two benchmark data sets, namely Australian Credit and German data set under several of performance metrics. The experimental values verified the superior nature of the proposed FCP model over the compared methods.},
  archive      = {J_SOCO},
  author       = {Sankhwar, Shweta and Gupta, Deepak and Ramya, K. C. and Sheeba Rani, S. and Shankar, K. and Lakshmanaprabu, S. K.},
  doi          = {10.1007/s00500-019-04323-6},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {101-110},
  shortjournal = {Soft Comput.},
  title        = {Improved grey wolf optimization-based feature subset selection with fuzzy neural classifier for financial crisis prediction},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Toward a development of general type-2 fuzzy classifiers
applied in diagnosis problems through embedded type-1 fuzzy classifiers.
<em>SOCO</em>, <em>24</em>(1), 83–99. (<a
href="https://doi.org/10.1007/s00500-019-04157-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, with the emergence of computer-aided systems, diagnosis problems are one of the most important application areas of artificial intelligence. The present paper is focused on a specific kind of computer-aided diagnosis system based on General Type-2 Fuzzy Logic. The main goal is the generation of General Type-2 Fuzzy Classifiers that can handle the data uncertainty. The concept of embedded Type-1 Fuzzy membership functions has been proposed to be used in the design of General Type-2 Fuzzy Classifiers. A methodology for generating the embedded Type-1 fuzzy membership functions is introduced, and the subsequent approach for developing the Footprint of Uncertainty of the General Type-2 Fuzzy Classifier is presented. On the other hand, the proposed approach performance is evaluated by the experimentation with different diagnosis benchmark problems. In addition, a statistical comparison with respect to another existing approach of General Type-2 Fuzzy classifiers is presented.},
  archive      = {J_SOCO},
  author       = {Ontiveros-Robles, Emanuel and Melin, Patricia},
  doi          = {10.1007/s00500-019-04157-2},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {83-99},
  shortjournal = {Soft Comput.},
  title        = {Toward a development of general type-2 fuzzy classifiers applied in diagnosis problems through embedded type-1 fuzzy classifiers},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An optimal redistribution plan considering aftermath
disruption in disaster management. <em>SOCO</em>, <em>24</em>(1), 65–82.
(<a href="https://doi.org/10.1007/s00500-019-04287-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unpredictable occurrence of any disaster emerges immeasurable demand in an affected society. Importance of immediate response in the aftermath of disaster is a crucial part of humanitarian logistic. Resource redistribution among the affected areas makes the optimal allocation in this chaotic situation. The research work has introduced a transportation plan considering the redistribution of resources from those areas which has already acquired relief and restored the normal condition to those areas still not being recovered from the effect of calamities. This research plan is developed to minimize the total cost of the relief operation as well as optimal allocation of the resources. The optimal allocation amidst the disruption of some resource storing points in the aftermath attack of disaster is also one of the key factors of the research. This research work has a great impact for decision-maker to derive an appropriate decision-making in such an anarchic situation of critical humanitarian supply chain. Due to the complexity of disaster, the model is considered in mixed uncertain environment. A numerical study is also performed to show the smooth functioning of the mathematical model assuming the uncertainty by trapezoidal neutrosophic number. Also, trapezoidal fuzzy number is implemented for uncertain parameters of the mathematical model and hereby compared with trapezoidal neutrosophic number.},
  archive      = {J_SOCO},
  author       = {Sarma, Deepshikha and Das, Amrit and Bera, Uttam Kumar},
  doi          = {10.1007/s00500-019-04287-7},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {65-82},
  shortjournal = {Soft Comput.},
  title        = {An optimal redistribution plan considering aftermath disruption in disaster management},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Intuitionistic fuzzy adaptive sliding mode control of
nonlinear systems. <em>SOCO</em>, <em>24</em>(1), 53–64. (<a
href="https://doi.org/10.1007/s00500-019-04286-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, Takagi–Sugeno intuitionistic fuzzy adaptive sliding mode control system (TS-IFASMC) is designed for nonlinear systems. We propose an intuitionistic fuzzy method to determine the parameters of the adaptive sliding mode control method which is used to control nonlinear systems. Intuitionistic fuzzy systems are considered as a skilled tool to model uncertainty in systems so they can transfer expert knowledge to control schemes better than the other classical methods, and real-world problems can be handled more effectively with this control method. In the proposed system, control parameters are defined by the intuitionistic fuzzy membership, non-membership, hesitation degrees and an integral sliding mode surface for a robust control performance. The novelty of this study is the use of Takagi–Sugeno type intuitionistic fuzzy system in adaptive sliding mode control method and comparison of performance of this new system with other classical methods. Thus, adaptive sliding mode controller based on the Takagi–Sugeno intuitionistic fuzzy system is obtained to provide robust control performance. Finally, the results support the effectiveness of the presented control scheme.},
  archive      = {J_SOCO},
  author       = {Kutlu, Fatih and Atan, Özkan and Silahtar, Onur},
  doi          = {10.1007/s00500-019-04286-8},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {53-64},
  shortjournal = {Soft Comput.},
  title        = {Intuitionistic fuzzy adaptive sliding mode control of nonlinear systems},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Qualitative model optimization of almond (terminalia
catappa) oil using soxhlet extraction in type-2 fuzzy environment.
<em>SOCO</em>, <em>24</em>(1), 41–51. (<a
href="https://doi.org/10.1007/s00500-019-04158-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An investigation into solid–liquid-based soxhlet extraction and drying pretreatment was conducted for the oil extraction from almond seed powder. The best possible combination of extraction parameters was obtained with interval type-2 fuzzy logic. Four major parameters: extraction time, temperature, moisture content and solvent-to-sample ratio were taken as input variables, and oil recovery and stability index were taken as output variables to optimize the extraction process based on their selected linguistic nature. Using these four input and two output parameters, eight Mamdani fuzzy inference systems were formed depending on the different membership functions of the variables. Finally, a statistical analysis has been performed using type-2 fuzzy data set to improve the control of process parameters that can be easily determined in type-2 fuzzy environment to get high yield as well as prominent quality.},
  archive      = {J_SOCO},
  author       = {Mukherjee, Anupam and Roy, Kunal and Jana, Dipak K. and Hossain, Sheikh A.},
  doi          = {10.1007/s00500-019-04158-1},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {41-51},
  shortjournal = {Soft Comput.},
  title        = {Qualitative model optimization of almond (Terminalia catappa) oil using soxhlet extraction in type-2 fuzzy environment},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dynamic adaptation of the PID’s gains via interval type-1
non-singleton type-2 fuzzy logic systems whose parameters are adapted
using the backpropagation learning algorithm. <em>SOCO</em>,
<em>24</em>(1), 17–40. (<a
href="https://doi.org/10.1007/s00500-019-04360-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a new design to dynamically adapt the proportional, the integral and the derivative (PID) controller’s gains using three interval type-1 non-singleton type-2 fuzzy logic systems (IT2 NSFLS-1), one fuzzy system for each gain of the PID, being the first main contribution of this proposal. This assembly is named as hybrid IT2 NSFLS-1 PID. Each IT2 NSFLS-1 system requires two non-singleton input values each period of discrete time $$ \left( \varvec{k} \right) $$, (1) the error $$ \varvec{e}\left( \varvec{k} \right) $$ and its standard deviation $$ \varvec{\sigma e}\left( \varvec{k} \right) $$, and (2) the change of error $$ \Delta \varvec{e}\left( \varvec{k} \right) $$ and its standard deviation $$ \varvec{\sigma}\Delta \varvec{e}\left( \varvec{k} \right) $$, to calculate the corresponding adjustment $$ \Delta \varvec{KP}\left( \varvec{k} \right) $$, $$ \Delta \varvec{KI}\left( \varvec{k} \right) $$, and $$ \Delta \varvec{KD}\left( \varvec{k} \right) $$ for the PID controller’s gains $$ \varvec{K}_{\varvec{p}} \left( \varvec{k} \right) $$, $$ \varvec{K}_{\varvec{i}} \left( \varvec{k} \right) $$, and $$ \varvec{K}_{\varvec{d}} \left( \varvec{k} \right) $$. The second main contribution of this proposal is that the parameters of each IT2 NSFLS-1 system are tuned each period of discrete time $$ \left( \varvec{k} \right) $$ by the non-singleton backpropagation (BP) algorithm using the plant output error and its standard deviation, which are processed as non-singleton values together with its non-singleton partial derivatives with respect to each IT2 fuzzy system parameter. Then these updated gains are used by the PID controller to calculate the best control signal for the plant under control. The uncertainty and the mean value of the measurement are used to calculate the non-singleton error which is processed as (a) input and (b) as gradient vector by each of the three IT2 NSFLS-1 systems. Simulation results show that the proposed hybrid assembly presents the better performance than the next five benchmarking control systems (a) the classic Zeigler–Nichols PID controller, and (b) four hybrid assemblies using PID controller and fuzzy systems with fixed fuzzy rule bases (T1 SFLS, T1 NSFLS, IT2 SFLS, IT2 NSFLS-1). The proposed assembly produces the better performance in a shortest period of time and it maintains a stable behavior on the output of the second-order plant model subject to variations and noise.},
  archive      = {J_SOCO},
  author       = {Méndez, Gerardo M. and Montes Dorantes, P. Noradino and Alcorta, M. Aracelia},
  doi          = {10.1007/s00500-019-04360-1},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {17-40},
  shortjournal = {Soft Comput.},
  title        = {Dynamic adaptation of the PID’s gains via interval type-1 non-singleton type-2 fuzzy logic systems whose parameters are adapted using the backpropagation learning algorithm},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Senti-NSetPSO: Large-sized document-level sentiment analysis
using neutrosophic set and particle swarm optimization. <em>SOCO</em>,
<em>24</em>(1), 3–15. (<a
href="https://doi.org/10.1007/s00500-019-04209-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last decade, opinion mining has been explored by using various machine learning methods. In the literature, document-level sentiment analysis has been majorly dealt with short-sized text only. For large-sized text, document-level sentiment analysis has never been dealt. In this paper, a hybrid framework named as “Senti-NSetPSO” is proposed to analyse large-sized text. Senti-NSetPSO comprises of two classifiers: binary and ternary based on hybridization of particle swarm optimization (PSO) with Neutrosophic Set. This method is suitable to classify large-sized text having more than 25 kb of size. Swarm size generated from large text can give a suitable measurement for implementation of PSO convergence. The proposed approach is trained and tested for large-sized text collected from Blitzer, aclIMDb, Polarity and Subjective Dataset. The proposed method establishes a co-relation between sentiment analysis and Neutrosophic Set. On Blitzer, aclIMDb and Polarity dataset, the model acquires satisfactory accuracy by ternary classifier. The accuracy of ternary classifier of the proposed framework shows significant improvement than review paper classifier present in the literature.},
  archive      = {J_SOCO},
  author       = {Jain, Amita and Pal Nandi, Basanti and Gupta, Charu and Tayal, Devendra Kumar},
  doi          = {10.1007/s00500-019-04209-7},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {3-15},
  shortjournal = {Soft Comput.},
  title        = {Senti-NSetPSO: Large-sized document-level sentiment analysis using neutrosophic set and particle swarm optimization},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Special issue on “extensions to type-1 fuzzy logic: Theory,
algorithms and applications.” <em>SOCO</em>, <em>24</em>(1), 1–2. (<a
href="https://doi.org/10.1007/s00500-019-04566-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SOCO},
  author       = {Castillo, Oscar and Jana, Dipak Kumar},
  doi          = {10.1007/s00500-019-04566-3},
  journal      = {Soft Computing},
  number       = {1},
  pages        = {1-2},
  shortjournal = {Soft Comput.},
  title        = {Special issue on “Extensions to type-1 fuzzy logic: Theory, algorithms and applications”},
  volume       = {24},
  year         = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
