<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AIL_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ail---19">AIL - 19</h2>
<ul>
<li><details>
<summary>
(2020). Encoded summarization: Summarizing documents into continuous
vector space for legal case retrieval. <em>AIL</em>, <em>28</em>(4),
441–467. (<a href="https://doi.org/10.1007/s10506-020-09262-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present our method for tackling a legal case retrieval task by introducing our method of encoding documents by summarizing them into continuous vector space via our phrase scoring framework utilizing deep neural networks. On the other hand, we explore the benefits from combining lexical features and latent features generated with neural networks. Our experiments show that lexical features and latent features generated with neural networks complement each other to improve the retrieval system performance. Furthermore, our experimental results suggest the importance of case summarization in different aspects: using provided summaries and performing encoded summarization. Our approach achieved F1 of 65.6% and 57.6% on the experimental datasets of legal case retrieval tasks.},
  archive      = {J_AIL},
  author       = {Tran, Vu and Le Nguyen, Minh and Tojo, Satoshi and Satoh, Ken},
  doi          = {10.1007/s10506-020-09262-4},
  journal      = {Artificial Intelligence and Law},
  month        = {12},
  number       = {4},
  pages        = {441-467},
  shortjournal = {Artif. Intell. Law},
  title        = {Encoded summarization: Summarizing documents into continuous vector space for legal case retrieval},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Explainable AI under contract and tort law: Legal incentives
and technical challenges. <em>AIL</em>, <em>28</em>(4), 415–439. (<a
href="https://doi.org/10.1007/s10506-020-09260-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper shows that the law, in subtle ways, may set hitherto unrecognized incentives for the adoption of explainable machine learning applications. In doing so, we make two novel contributions. First, on the legal side, we show that to avoid liability, professional actors, such as doctors and managers, may soon be legally compelled to use explainable ML models. We argue that the importance of explainability reaches far beyond data protection law, and crucially influences questions of contractual and tort liability for the use of ML models. To this effect, we conduct two legal case studies, in medical and corporate merger applications of ML. As a second contribution, we discuss the (legally required) trade-off between accuracy and explainability and demonstrate the effect in a technical case study in the context of spam classification.},
  archive      = {J_AIL},
  author       = {Hacker, Philipp and Krestel, Ralf and Grundmann, Stefan and Naumann, Felix},
  doi          = {10.1007/s10506-020-09260-6},
  journal      = {Artificial Intelligence and Law},
  month        = {12},
  number       = {4},
  pages        = {415-439},
  shortjournal = {Artif. Intell. Law},
  title        = {Explainable AI under contract and tort law: Legal incentives and technical challenges},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Legal and ethical implications of applications based on
agreement technologies: The case of auction-based road intersections.
<em>AIL</em>, <em>28</em>(4), 385–414. (<a
href="https://doi.org/10.1007/s10506-019-09259-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Agreement technologies refer to a novel paradigm for the construction of distributed intelligent systems, where autonomous software agents negotiate to reach agreements on behalf of their human users. Smart Cities are a key application domain for agreement technologies. While several proofs of concept and prototypes exist, such systems are still far from ready for being deployed in the real-world. In this paper we focus on a novel method for managing elements of smart road infrastructures of the future, namely the case of auction-based road intersections. We show that, even though the key technological elements for such methods are already available, there are multiple non-technical issues that need to be tackled before they can be applied in practice. For this purpose, we analyse legal and ethical implications of auction-based road intersections in the context of international regulations and from the standpoint of the Spanish legislation. From this exercise, we extract a set of required modifications, of both technical and legal nature, which need to be addressed so as to pave the way for the potential real-world deployment of such systems in a future that may not be too far away.},
  archive      = {J_AIL},
  author       = {Santos, José-Antonio and Fernández, Alberto and Moreno-Rebato, Mar and Billhardt, Holger and Rodríguez-García, José-A. and Ossowski, Sascha},
  doi          = {10.1007/s10506-019-09259-8},
  journal      = {Artificial Intelligence and Law},
  month        = {12},
  number       = {4},
  pages        = {385-414},
  shortjournal = {Artif. Intell. Law},
  title        = {Legal and ethical implications of applications based on agreement technologies: The case of auction-based road intersections},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Is hybrid formal theory of arguments, stories and criminal
evidence well suited for negative causation? <em>AIL</em>,
<em>28</em>(3), 361–384. (<a
href="https://doi.org/10.1007/s10506-019-09258-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, I have two primary goals. First, I show that the causal-based story approach in A hybrid formal theory of arguments, stories and criminal evidence (or Hybrid Theory, for short) is ill suited to negative (or absence) causation. In the literature, the causal-based approach requires that hypothetical stories be causally linked to the explanandum. Many take these links to denote physical or psychological causation, or temporal precedence. However, understanding causality in those terms, as I will show, cannot capture cases of negative causation, which are of interest to the Law. In keeping with this, I also discuss some of the difficulties Hybrid Theory invites by remaining silent on the nature of the causal links. In my second aim, I sketch a way for Hybrid Theory to overcome this problem. By replacing the original, underlying causal structure with contrastive causation in the law, Hybrid Theory can represent reasoning in which the evidence that is appealed to is causally linked via negative causation to the explananda.},
  archive      = {J_AIL},
  author       = {Barclay, Charles A.},
  doi          = {10.1007/s10506-019-09258-9},
  journal      = {Artificial Intelligence and Law},
  month        = {9},
  number       = {3},
  pages        = {361-384},
  shortjournal = {Artif. Intell. Law},
  title        = {Is hybrid formal theory of arguments, stories and criminal evidence well suited for negative causation?},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Appellate court modifications extraction for portuguese.
<em>AIL</em>, <em>28</em>(3), 327–360. (<a
href="https://doi.org/10.1007/s10506-019-09256-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Appellate Court Modifications Extraction consists of, given an Appellate Court decision, identifying the proposed modifications by the upper Court of the lower Court judge’s decision. In this work, we propose a system to extract Appellate Court Modifications for Portuguese. Information extraction for legal texts has been previously addressed using different techniques and for several languages. Our proposal differs from previous work in two ways: (1)  our corpus is composed of Brazilian Appellate Court decisions, in which we look for a set of modifications provided by the Court; and (2) to automatically extract the modifications, we use a traditional Machine Learning approach and a Deep Learning approach, both as alternative solutions and as a combined solution. We tackle the Appellate Court Modifications Extraction task, experimenting with a wide variety of methods. In order to train and evaluate the system, we have built the KauaneJunior corpus, using public data disclosed by the Appellate State Court of Rio de Janeiro jurisprudence database. Our best method, which is a Bidirectional Long Short-Term Memory network combined with Conditional Random Fields, obtained an $$F_{\beta = 1}$$ score of 94.79%.},
  archive      = {J_AIL},
  author       = {Fernandes, William Paulo Ducca and Silva, Luiz José Schirmer and Frajhof, Isabella Zalcberg and de Almeida, Guilherme da Franca Couto Fernandes and Konder, Carlos Nelson and Nasser, Rafael Barbosa and de Carvalho, Gustavo Robichez and Barbosa, Simone Diniz Junqueira and Lopes, Hélio Côrtes Vieira},
  doi          = {10.1007/s10506-019-09256-x},
  journal      = {Artificial Intelligence and Law},
  month        = {9},
  number       = {3},
  pages        = {327-360},
  shortjournal = {Artif. Intell. Law},
  title        = {Appellate court modifications extraction for portuguese},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). In memoriam douglas n. Walton: The influence of doug walton
on AI and law. <em>AIL</em>, <em>28</em>(3), 281–326. (<a
href="https://doi.org/10.1007/s10506-020-09272-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Doug Walton, who died in January 2020, was a prolific author whose work in informal logic and argumentation had a profound influence on Artificial Intelligence, including Artificial Intelligence and Law. He was also very interested in interdisciplinary work, and a frequent and generous collaborator. In this paper seven leading researchers in AI and Law, all past programme chairs of the International Conference on AI and Law who have worked with him, describe his influence on their work.},
  archive      = {J_AIL},
  author       = {Atkinson, Katie and Bench-Capon, Trevor and Bex, Floris and Gordon, Thomas F. and Prakken, Henry and Sartor, Giovanni and Verheij, Bart},
  doi          = {10.1007/s10506-020-09272-2},
  journal      = {Artificial Intelligence and Law},
  month        = {9},
  number       = {3},
  pages        = {281-326},
  shortjournal = {Artif. Intell. Law},
  title        = {In memoriam douglas n. walton: The influence of doug walton on AI and law},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). ICAIL doctoral consortium, montreal 2019. <em>AIL</em>,
<em>28</em>(2), 267–280. (<a
href="https://doi.org/10.1007/s10506-020-09267-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This is a report on the Doctoral Consortium co-located with the 17th International Conference on Artificial Intelligence and Law in Montreal.},
  archive      = {J_AIL},
  author       = {Araszkiewicz, Michał and Amantea, Ilaria Angela and Chakravarty, Saurabh and van Doesburg, Robert and Dymitruk, Maria and Garin, Marie and Gilpin, Leilani and Odekerken, Daphne and Salehi, Seyedeh Sajedeh},
  doi          = {10.1007/s10506-020-09267-z},
  journal      = {Artificial Intelligence and Law},
  month        = {6},
  number       = {2},
  pages        = {267-280},
  shortjournal = {Artif. Intell. Law},
  title        = {ICAIL doctoral consortium, montreal 2019},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Using machine learning to predict decisions of the european
court of human rights. <em>AIL</em>, <em>28</em>(2), 237–266. (<a
href="https://doi.org/10.1007/s10506-019-09255-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When courts started publishing judgements, big data analysis (i.e. large-scale statistical analysis of case law and machine learning) within the legal domain became possible. By taking data from the European Court of Human Rights as an example, we investigate how natural language processing tools can be used to analyse texts of the court proceedings in order to automatically predict (future) judicial decisions. With an average accuracy of 75% in predicting the violation of 9 articles of the European Convention on Human Rights our (relatively simple) approach highlights the potential of machine learning approaches in the legal domain. We show, however, that predicting decisions for future cases based on the cases from the past negatively impacts performance (average accuracy range from 58 to 68%). Furthermore, we demonstrate that we can achieve a relatively high classification performance (average accuracy of 65%) when predicting outcomes based only on the surnames of the judges that try the case.},
  archive      = {J_AIL},
  author       = {Medvedeva, Masha and Vols, Michel and Wieling, Martijn},
  doi          = {10.1007/s10506-019-09255-y},
  journal      = {Artificial Intelligence and Law},
  month        = {6},
  number       = {2},
  pages        = {237-266},
  shortjournal = {Artif. Intell. Law},
  title        = {Using machine learning to predict decisions of the european court of human rights},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Taking stock of legal ontologies: A feature-based
comparative analysis. <em>AIL</em>, <em>28</em>(2), 207–235. (<a
href="https://doi.org/10.1007/s10506-019-09252-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ontologies represent the standard way to model the knowledge about specific domains. This holds also for the legal domain where several ontologies have been put forward to model specific kinds of legal knowledge. Both for standard users and for law scholars, it is often difficult to have an overall view on the existing alternatives, their main features and their interlinking with the other ontologies. To answer this need, in this paper, we address an analysis of the state-of-the-art in legal ontologies and we characterise them along with some distinctive features. This paper aims to guide generic users and law experts in selecting the legal ontology that better fits their needs and in understanding its specificity so that proper extensions to the selected model could be investigated.},
  archive      = {J_AIL},
  author       = {Leone, Valentina and Di Caro, Luigi and Villata, Serena},
  doi          = {10.1007/s10506-019-09252-1},
  journal      = {Artificial Intelligence and Law},
  month        = {6},
  number       = {2},
  pages        = {207-235},
  shortjournal = {Artif. Intell. Law},
  title        = {Taking stock of legal ontologies: A feature-based comparative analysis},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Artificial intelligence as law. <em>AIL</em>,
<em>28</em>(2), 181–206. (<a
href="https://doi.org/10.1007/s10506-020-09266-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information technology is so ubiquitous and AI’s progress so inspiring that also legal professionals experience its benefits and have high expectations. At the same time, the powers of AI have been rising so strongly that it is no longer obvious that AI applications (whether in the law or elsewhere) help promoting a good society; in fact they are sometimes harmful. Hence many argue that safeguards are needed for AI to be trustworthy, social, responsible, humane, ethical. In short: AI should be good for us. But how to establish proper safeguards for AI? One strong answer readily available is: consider the problems and solutions studied in AI &amp; Law. AI &amp; Law has worked on the design of social, explainable, responsible AI aligned with human values for decades already, AI &amp; Law addresses the hardest problems across the breadth of AI (in reasoning, knowledge, learning and language), and AI &amp; Law inspires new solutions (argumentation, schemes and norms, rules and cases, interpretation). It is argued that the study of AI as Law supports the development of an AI that is good for us, making AI &amp; Law more relevant than ever.},
  archive      = {J_AIL},
  author       = {Verheij, Bart},
  doi          = {10.1007/s10506-020-09266-0},
  journal      = {Artificial Intelligence and Law},
  month        = {6},
  number       = {2},
  pages        = {181-206},
  shortjournal = {Artif. Intell. Law},
  title        = {Artificial intelligence as law},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Interactive virtue and vice in systems of arguments: A
logocratic analysis. <em>AIL</em>, <em>28</em>(1), 151–179. (<a
href="https://doi.org/10.1007/s10506-019-09257-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Logocratic Method, and the Logocratic theory that underwrites it, provide a philosophical explanation of three purposes or goals that arguers have for their arguments: to make arguments that are internally strong (the premises follow from the conclusions, to a greater or lesser degree—greatest degree in valid deductive arguments), or that are dialectically strong (win in some forum of argument competition, as for example in litigation contests of plaintiffs or prosecutors on the one hand, and defendants, on the other), or that are rhetorically strong (effective at persuading a targeted audience). This article presents the basic terms and methods of Logocratic analysis and then uses a case study to illustrate the Logocratic explanation of arguments. Highlights of this explanation are: the use of a (non-moral) virtue (and vice) framework to explicate the three strengths and weaknesses of arguments that are of greatest interest to arguers in many contexts (including but not limited to the context of legal argument), the Logocratic explication of the structure of abduction generally and of legal abduction specifically, the concept of a system of arguments, and the concept of the dynamic interactive virtue (and vice) of arguments—a property of systems of arguments in which the system of arguments as a whole (for example, the set of several arguments typically offered by a plaintiff or by a defendant) is as virtuous (or vicious) as are the component arguments that comprise the system. This is especially important since, according to Logocratic theory (and as illustrated in detail in this paper), some arguments, such as abduction and analogical argument, are themselves comprised of different logical forms (for example, abduction always plays a role within analogical argument, and either deduction or defeasible modus ponens, always plays a role within legal abduction).},
  archive      = {J_AIL},
  author       = {Brewer, Scott},
  doi          = {10.1007/s10506-019-09257-w},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {151-179},
  shortjournal = {Artif. Intell. Law},
  title        = {Interactive virtue and vice in systems of arguments: A logocratic analysis},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A system of communication rules for justifying and
explaining beliefs about facts in civil trials. <em>AIL</em>,
<em>28</em>(1), 135–150. (<a
href="https://doi.org/10.1007/s10506-019-09247-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the problems of justifying and explaining beliefs about facts in the context of civil trials. The first section contains some remarks about the nature of adjudicative fact-finding and highlights the communicative features of deciding about facts in judicial context. In Sect. 2, some difficulties and the incompleteness presented by Bayesian and coherentist frameworks, which are taken as methods suitable to solve the above-mentioned problems, are pointed out. In the third section, the purely epistemic approach to the justification and the explanation of beliefs about facts is abandoned and focus is given to the dialectical nature of civil procedure, where the parties and, particularly, the judge have to make their reasoning clear enough to allow a fruitful and efficient debate about facts. For this purpose, a communication/argumentation system is put forward, consisting of fourteen intertwined rules of discourse. The system embodies the fundamental epistemic principle according to which belief is updated given new evidence, is tailored for abductive inferences and is structured on fundamental concepts of civil procedural law. The fourth section presents an empirical application of the system to a real case.},
  archive      = {J_AIL},
  author       = {Marques Martins, João},
  doi          = {10.1007/s10506-019-09247-y},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {135-150},
  shortjournal = {Artif. Intell. Law},
  title        = {A system of communication rules for justifying and explaining beliefs about facts in civil trials},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Proof beyond a context-relevant doubt. A structural analysis
of the standard of proof in criminal adjudication. <em>AIL</em>,
<em>28</em>(1), 111–133. (<a
href="https://doi.org/10.1007/s10506-019-09248-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present article proceeds from the mainstream view that the conceptual framework underpinning adversarial systems of criminal adjudication, i.e. a mixture of common-sense philosophy and probabilistic analysis, is unsustainable. In order to provide fact-finders with an operable structure of justification, we need to turn to epistemology once again. The article proceeds in three parts. First, I examine the structural features of justification and how various theories have attempted to overcome Agrippa’s trilemma. Second, I put Inferential Contextualism to the test and show that a defeasible structure of justification allocating epistemic rights and duties to all participants of an inquiry manages to dissolve the problem of scepticism. Third, I show that our epistemic practice already embodies a contextualist mechanism. Our problem was not that our Standard of Proof is inoperable but that it was not adequately conceptualized. Contextualism provides the framework to articulate the abovementioned practice and to treat ‘reasonable doubts’ as a mechanism which we can now describe in detail. The seemingly insurmountable problem with our efforts to define the concept “reasonable doubts” was the fact that we have been conflating the surface features of this mechanism and its internal structure, i.e. the rules for its use.},
  archive      = {J_AIL},
  author       = {Kotsoglou, Kyriakos N.},
  doi          = {10.1007/s10506-019-09248-x},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {111-133},
  shortjournal = {Artif. Intell. Law},
  title        = {Proof beyond a context-relevant doubt. a structural analysis of the standard of proof in criminal adjudication},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Assessment criteria or standards of proof? An effort in
clarification. <em>AIL</em>, <em>28</em>(1), 91–109. (<a
href="https://doi.org/10.1007/s10506-018-9233-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper provides a conceptual distinction between evidence assessment criteria and standards of proof. Evidence must be assessed in order to check whether it satisfies a relevant standard of proof, and the assessment is operated with some criterion; so both criteria and standards are necessary for fact-finding. In addition to this conceptual point, the article addresses three main questions: (1) Why do some scholars and decision-makers take assessment criteria as standards of proof and vice versa? (2) Why do systems differ as to criteria and standards? (3) How can a system work if it neglects one of these things? The answers to the first and second question come from the historical and procedural differences between the systems. The answer to the third focuses on the functional connection between criteria and standards.},
  archive      = {J_AIL},
  author       = {Tuzet, Giovanni},
  doi          = {10.1007/s10506-018-9233-1},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {91-109},
  shortjournal = {Artif. Intell. Law},
  title        = {Assessment criteria or standards of proof? an effort in clarification},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Arguing about causes in law: A semi-formal framework for
causal arguments. <em>AIL</em>, <em>28</em>(1), 69–89. (<a
href="https://doi.org/10.1007/s10506-019-09246-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Disputes over causes play a central role in legal argumentation and liability attribution. Legal approaches to causation often struggle to capture cause-in-fact in complex situations, e.g. overdetermination, preemption, omission. In this paper, we first assess three current theories of causation (but-for, NESS, ‘actual causation’) to illustrate their strengths and weaknesses in capturing cause-in-fact. Secondly, we introduce a semi-formal framework for modelling causal arguments through strict and defeasible rules. Thirdly, the framework is applied to the Althen vaccine injury case. And lastly, we discuss the need for new criteria based on a common causal argumentation framework and propose ideas on how to integrate the current theories of causation to assess the strength of causal arguments, while also acknowledging the tension between evidence-based and policy-based causal analysis in law.},
  archive      = {J_AIL},
  author       = {Liepiņa, Rūta and Sartor, Giovanni and Wyner, Adam},
  doi          = {10.1007/s10506-019-09246-z},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {69-89},
  shortjournal = {Artif. Intell. Law},
  title        = {Arguing about causes in law: A semi-formal framework for causal arguments},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Group-to-individual (G2i) inferences: Challenges in modeling
how the u.s. Court system uses brain data. <em>AIL</em>, <em>28</em>(1),
51–68. (<a href="https://doi.org/10.1007/s10506-018-9234-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regardless of formalization used, one on-going challenge for AI systems that model legal proceedings is accounting for contextual issues, particularly where judicial decisions are made in criminal cases. The law assumes a rational approach to rule application in deciding a defendant’s guilt; however, judges and juries can behave irrationally. What should a model prize: efficiency, accuracy, or fairness? Exactly whether and how to incorporate the psychology of courtroom interactions into formal models or expert systems has only just begun to be examined in a serious fashion. Here, I outline data from the United States which suggest that trying to incorporate psychological biases into formal models of legal decision-making will be challenging. I focus on the use of neuroscience data in criminal trials, homing in on so-called group-to-individual (G2i) inferences. I argue that data which should be the most effective at swaying judicial decisions are in fact those most likely not to make a difference in the disposition of the case. I conclude that judges often assign culpability by ignoring what our best science regarding how human decision-making occurs.},
  archive      = {J_AIL},
  author       = {Hardcastle, Valerie Gray},
  doi          = {10.1007/s10506-018-9234-0},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {51-68},
  shortjournal = {Artif. Intell. Law},
  title        = {Group-to-individual (G2i) inferences: Challenges in modeling how the U.S. court system uses brain data},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new use case for argumentation support tools: Supporting
discussions of bayesian analyses of complex criminal cases.
<em>AIL</em>, <em>28</em>(1), 27–49. (<a
href="https://doi.org/10.1007/s10506-018-9235-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper a new use case for legal argumentation support tools is considered: supporting discussions about analyses of complex criminal cases with the help of Bayesian probability theory. By way of a case study, two actual discussions between experts in court cases are analysed on their argumentation structure. In this study the usefulness of several recognised argument schemes is confirmed, a new argument scheme for arguments from statistics are proposed, and an analysis is given of debates between experts about the validity of their arguments. From a practical point of view the case study yields insights into the design of support software for discussions about Bayesian analyses of complex criminal cases.},
  archive      = {J_AIL},
  author       = {Prakken, Henry},
  doi          = {10.1007/s10506-018-9235-z},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {27-49},
  shortjournal = {Artif. Intell. Law},
  title        = {A new use case for argumentation support tools: Supporting discussions of bayesian analyses of complex criminal cases},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Normative decision analysis in forensic science.
<em>AIL</em>, <em>28</em>(1), 7–25. (<a
href="https://doi.org/10.1007/s10506-018-9232-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the normative analysis—in the sense of the classic decision-theoretic formulation—of decision problems that arise in connection with forensic expert reporting. We distinguish this analytical account from other common types of decision analyses, such as descriptive approaches. While decision theory is, since several decades, an extensively discussed topic in legal literature, its use in forensic science is more recent, and with an emphasis on goals such as the analysis of the logical structure of forensic expert conclusions regarding, for example, propositions of common source of evidential and known materials. Typical examples are so-called identification (or, individualization) decisions, especially categorical conclusions according to which fingermarks (or stains of biological nature, handwriting, etc.) come from a particular a person of interest. We will present and compare ways of stating forensic identification decisions in decision-theoretic terms and explain their underlying rationale. In particular, we will emphasize the importance of viewing this analysis as normative in the sense of providing a reflective rather than a prescriptive reference point against which people in charge of forensic identification decisions may compare their otherwise (possibly) intuitive and informal reasoning, before acting. Normative decision analysis in forensic science thus provides a vector through which current practice can be articulated, scrutinized and rethought.},
  archive      = {J_AIL},
  author       = {Biedermann, A. and Bozza, S. and Taroni, F.},
  doi          = {10.1007/s10506-018-9232-2},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {7-25},
  shortjournal = {Artif. Intell. Law},
  title        = {Normative decision analysis in forensic science},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evidence &amp; decision making in the law: Theoretical,
computational and empirical approaches. <em>AIL</em>, <em>28</em>(1),
1–5. (<a href="https://doi.org/10.1007/s10506-019-09253-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AIL},
  author       = {Di Bello, Marcello and Verheij, Bart},
  doi          = {10.1007/s10506-019-09253-0},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {1-5},
  shortjournal = {Artif. Intell. Law},
  title        = {Evidence &amp; decision making in the law: Theoretical, computational and empirical approaches},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
