<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>CC_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="cc---87">CC - 87</h2>
<ul>
<li><details>
<summary>
(2020). A novel approach for detecting anomalous energy consumption
based on micro-moments and deep neural networks. <em>CC</em>,
<em>12</em>(6), 1381–1401. (<a
href="https://doi.org/10.1007/s12559-020-09764-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, analyzing, detecting, and visualizing abnormal power consumption behavior of householders are among the principal challenges in identifying ways to reduce power consumption. This paper introduces a new solution to detect energy consumption anomalies based on extracting micro-moment features using a rule-based model. The latter is used to draw out load characteristics using daily intent-driven moments of user consumption actions. Besides micro-moment features extraction, we also experiment with a deep neural network architecture for efficient abnormality detection and classification. In the following, a novel anomaly visualization technique is introduced that is based on a scatter representation of the micro-moment classes, and hence providing consumers an easy solution to understand their abnormal behavior. Moreover, in order to validate the proposed system, a new energy consumption dataset at appliance level is also designed through a measurement campaign carried out at Qatar University Energy Lab, namely, Qatar University dataset. Experimental results on simulated and real datasets collected at two regions, which have extremely different climate conditions, confirm that the proposed deep micro-moment architecture outperforms other machine learning algorithms and can effectively detect anomalous patterns. For example, 99.58% accuracy and 97.85% F1 score have been achieved under Qatar University dataset. These promising results establish the efficacy of the proposed deep micro-moment solution for detecting abnormal energy consumption, promoting energy efficiency behaviors, and reducing wasted energy.},
  archive      = {J_CC},
  author       = {Himeur, Yassine and Alsalemi, Abdullah and Bensaali, Faycal and Amira, Abbes},
  doi          = {10.1007/s12559-020-09764-y},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1381-1401},
  shortjournal = {Cogn. Comput.},
  title        = {A novel approach for detecting anomalous energy consumption based on micro-moments and deep neural networks},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Neural network–based event-triggered adaptive control
algorithms for uncertain nonlinear systems with actuator failures.
<em>CC</em>, <em>12</em>(6), 1370–1380. (<a
href="https://doi.org/10.1007/s12559-020-09767-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The adaptive control for strict-feedback nonlinear systems has drawn a lot of attention in various communities. Since neural network is a useful universal-approximator to approximate unknown plant model, the neural network–based adaptive control for nonlinear systems has attracted substantial interest over decades. Furthermore, to reduce the controller updating and save the control resource, the event-triggered mechanism has been widely applied. In this paper, the RBF neural network is applied to construct the state and composite disturbance observers and the back-stepping and Lyapunov-like method are applied to design the event-triggered adaptive controller. The theoretical framework of adaptive fault-tolerant control issue for strict-feedback nonlinear system that suffer from both unknown mismatched disturbance and actuator failures is formulated. This paper comes up with a novel event-triggered control strategy to guarantee that the tracking issue is resolved with better desired performance. In this study, a unified theoretical mechanism is developed to tackle the case where some factors consisting of unknown state variables, unknown mismatched disturbance, and actuator failures as well as event-triggered effects are merged together. We expect to extend the proposed method for the self-triggered case.},
  archive      = {J_CC},
  author       = {Tan, Lihua and Li, Chuandong and Huang, Junjian},
  doi          = {10.1007/s12559-020-09767-9},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1370-1380},
  shortjournal = {Cogn. Comput.},
  title        = {Neural Network–Based event-triggered adaptive control algorithms for uncertain nonlinear systems with actuator failures},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Understanding violin players’ skill level based on motion
capture: A data-driven perspective. <em>CC</em>, <em>12</em>(6),
1356–1369. (<a
href="https://doi.org/10.1007/s12559-020-09768-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning to play and perform a music instrument is a complex cognitive task, requiring high conscious control and coordination of an impressive number of cognitive and sensorimotor skills. For professional violinists, there exists a physical connection with the instrument allowing the player to continuously manage the sound through sophisticated bowing techniques and fine hand movements. Hence, it is not surprising that great importance in violin training is given to right hand techniques, responsible for most of the sound produced. In this paper, our aim is to understand which motion features can be used to efficiently and effectively distinguish a professional performance from that of a student without exploiting sound-based features. We collected and made freely available a dataset consisting of motion capture recordings of different violinists with different skills performing different exercises covering different pedagogical and technical aspects. We then engineered peculiar features and trained a data-driven classifier to distinguish among two different levels of violinist experience, namely beginners and experts. In accordance with the hierarchy present in the dataset, we study two different scenarios: extrapolation with respect to different exercises and violinists. Furthermore, we study which features are the most predictive ones of the quality of a violinist to corroborate the significance of the results. The results, both in terms of accuracy and insight on the cognitive problem, support the proposal and support the use of the proposed technique as a support tool for students to monitor and enhance their home study and practice.},
  archive      = {J_CC},
  author       = {D’Amato, Vincenzo and Volta, Erica and Oneto, Luca and Volpe, Gualtiero and Camurri, Antonio and Anguita, Davide},
  doi          = {10.1007/s12559-020-09768-8},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1356-1369},
  shortjournal = {Cogn. Comput.},
  title        = {Understanding violin players’ skill level based on motion capture: A data-driven perspective},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A neutrosophic VIKOR method-based decision-making with an
improved distance measure and score function: Case study of selection
for renewable energy alternatives. <em>CC</em>, <em>12</em>(6),
1338–1355. (<a
href="https://doi.org/10.1007/s12559-020-09765-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, a new score and distance function which provides more accurate results than the studies in the literature and considers the decision maker’s cognition has been proposed. In order to show the effects of the new score function coefficients on neutrosophic numbers, a new representation named “4D Plot” has been proposed. VIKOR (Vlse Kriterijumska Optimizacija Kompromisno Resenje which means multicriteria optimization and compromise solution in Serbian) method, which is based on the creation of a conciliatory solution within the framework of alternatives and evaluation criteria, provides highly effective results in multiple criteria decision-making problems. Neutrosophic numbers play an active role in facilitating the decision-making process in many studies. In this context, extension of the classical VIKOR method is introduced in detail in this study. The framework of the extended neutrosophic VIKOR method has been established. The proposed method has been applied to the renewable energy alternative selection problem in Turkey and compared with different methods and different scenarios. It has been shown that the proposed method gives more effective and accurate results. Furthermore, the sensitivity and accuracy of the study are enhanced by a sensitivity analysis. We have extended the classical VIKOR method for SVN numbers with a newly generalized score function and a distance measure. As a novel and newly presentation named “The 4D Plot” has been developed and applied in this paper to SVN numbers for presenting the effect of the new score function. The renewable energy alternative selection was made in Turkey with the proposed method by the opinions of the experts and the ranking of the alternatives was obtained. A sensitivity analysis has been made to show the accuracy and validity of the study. With the proposed distance measure and score function, it is shown that more accurate results can be found in multiple criteria decision-making problems. The model will provide solutions for many soft computing problems such as engineering and economy by finding more effective and accurate results in the neutrosophic number space according to the preference of decision makers. As a future work, the presented functions and framework can be adapted to different MCDM problems.},
  archive      = {J_CC},
  author       = {Eroğlu, Hasan and Şahin, Ridvan},
  doi          = {10.1007/s12559-020-09765-x},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1338-1355},
  shortjournal = {Cogn. Comput.},
  title        = {A neutrosophic VIKOR method-based decision-making with an improved distance measure and score function: Case study of selection for renewable energy alternatives},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Linguistic interval-valued pythagorean fuzzy sets and their
application to multiple attribute group decision-making process.
<em>CC</em>, <em>12</em>(6), 1313–1337. (<a
href="https://doi.org/10.1007/s12559-020-09750-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper’s aims are to present a novel concept of linguistic interval-valued Pythagorean fuzzy set (LIVPFS) or called a linguistic interval-valued intuitionistic type-2 fuzzy set, which is a robust and trustworthy tool, and to accomplish the imprecise information while solving the decision-making problems. The presented LIVPFS is a generalization of the linguistic Pythagorean fuzzy set, by characterizing the membership and non-membership degrees as the interval-valued linguistic terms to represent the uncertain information. To explore the study, we firstly define some basic operational rules, score and accuracy functions, and the ordering relations of LIVPFS with a brief study of the desirable properties. Based on the stated operational laws, we proposed several weighted averages and geometric aggregating operators to aggregate the linguistic interval-valued Pythagorean fuzzy information. The fundamental inequalities between the proposed operators and their properties are discussed in detail. Finally, a multiple attribute group decision-making (MAGDM) algorithm is promoted to solve the group decision-making problems with uncertain information using linguistic features and the proposed operators. The fundamental inequalities between the proposed operators and their properties are discussed in detail. Also, the illustration of the stated algorithm is given through several numerical examples and compared their performance with the results of the existing algorithms. Based on the stated MAGDM algorithm and the suitable operators, the decision-makers’ can be selected their best alternatives with their own attitude character towards optimism or pessimism choice. The presented LIVPFS is an extension of the several existing sets and is more generalized to utilize the uncertain and imprecise information with a wider range of information. Based on the presented aggregation operators, a decision-maker can select the desired one as per their choices to access the finest alternatives.},
  archive      = {J_CC},
  author       = {Garg, Harish},
  doi          = {10.1007/s12559-020-09750-4},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1313-1337},
  shortjournal = {Cogn. Comput.},
  title        = {Linguistic interval-valued pythagorean fuzzy sets and their application to multiple attribute group decision-making process},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A context-based disambiguation model for sentiment concepts
using a bag-of-concepts approach. <em>CC</em>, <em>12</em>(6),
1299–1312. (<a
href="https://doi.org/10.1007/s12559-020-09729-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread dissemination of user-generated content on different web sites, social networks, and online consumer systems such as Amazon, the quantity of opinionated information available on the Internet has been increased. Sentiment analysis of user-generated content is one of the main cognitive computing branches; hence, it has attracted the attention of many scholars in recent years. One of the main tasks of the sentiment analysis is to detect polarity within a text. The existing polarity detection methods mainly focus on keywords and their naïve frequency counts; however, they less regard the meanings and implicit dimensions of the natural concepts. Although background knowledge plays a critical role in determining the polarity of concepts, it has been disregarded in polarity detection methods. This study presents a context-based model to solve ambiguous polarity concepts using commonsense knowledge. First, a model is presented to generate a source of ambiguous sentiment concepts based on SenticNet by computing the probability distribution. Then, the model uses a bag-of-concepts approach to remove ambiguities and semantic augmentation with the ConceptNet handling to overcome lost knowledge. ConceptNet is a large-scale semantic network with a large number of commonsense concepts. In this paper, the point mutual information (PMI) measure is used to select the contextual concepts having strong relationships with ambiguous concepts. The polarity of the ambiguous concepts is precisely detected using positive/negative contextual concepts and the relationship of the concepts in the semantic knowledge base. The text representation scheme is semantically enriched using Numberbatch, which is a word embedding model based on the concepts from the ConceptNet semantic network. In this regard, the cosine similarity metric is used to measure similarity and select a concept from the ConceptNet network for semantic augmentation. Pre-trained concepts vectors facilitate the more effective computation of semantic similarity among the concerned concepts. The proposed model is evaluated by applying a corpus of product reviews, called Semeval. The experimental results revealed an accuracy rate of 82.07%, representing the effectiveness of the proposed model.},
  archive      = {J_CC},
  author       = {Rajabi, Zeinab and Valavi, Mohammad Reza and Hourali, Maryam},
  doi          = {10.1007/s12559-020-09729-1},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1299-1312},
  shortjournal = {Cogn. Comput.},
  title        = {A context-based disambiguation model for sentiment concepts using a bag-of-concepts approach},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multiple attribute decision making based on power muirhead
mean operators under 2-tuple linguistic pythagorean fuzzy environment.
<em>CC</em>, <em>12</em>(6), 1276–1298. (<a
href="https://doi.org/10.1007/s12559-020-09756-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the uncertainty and complexity of socioeconomic environments and cognitive diversity of decision makers, the cognitive information over alternatives provided by decision makers is usually uncertain and fuzzy. Two-tuple linguistic Pythagorean fuzzy sets (2TLPFSs) provide useful tools to depict the uncertain and fuzzy cognitions of the decision makers over attributes. To effectively handle such common cases, in this paper, some power Muirhead mean (PMM) operator and power dual MM (PDMM) operator operators under 2TLPFS environment are proposed and investigated the methods for multiple attribute decision making(MADM) problems based on the PMM and PDMM operators with 2-tuple linguistic Pythagorean fuzzy numbers (2TLPFNs) are investigated. Firstly, some new PMM and PDMM operators to aggregate 2-tuple linguistic Pythagorean fuzzy cognitive information is developed, such as 2-tuple linguistic Pythagorean fuzzy MM (2TLPFPMM) operator, 2-tuple linguistic Pythagorean fuzzy weighted PMM (2TLPFWPMM) operator, 2-tuple linguistic Pythagorean fuzzy PDMM (2TLPFPDMM) operator, and 2-tuple linguistic Pythagorean fuzzy weighted PDMM (2TLPFNWPDMM) operator, which consider the interrelationship of 2TLPFNs, and can generate more accurate results than the existing aggregation operators. After that, the developed aggregation operator are applied to MADM with 2TLPFNs and two MADM methods are designed, which can be applied to different decision making situations. Based on the proposed operators and built models, two methods are developed to solve the MADM problems with 2TLPFNs and the validity and advantages of the proposed method are analyzed by comparison with some existing approaches. The method proposed in this paper can effectively handle the MADM problems in which the attribute information is expressed by 2TLPFNs, the attributes’ weights are completely known, and the attributes are interactive. Finally, an example for green supplier selection is used to show the proposed methods.},
  archive      = {J_CC},
  author       = {Deng, Xiumei and Wang, Jie and Wei, Guiwu},
  doi          = {10.1007/s12559-020-09756-y},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1276-1298},
  shortjournal = {Cogn. Comput.},
  title        = {Multiple attribute decision making based on power muirhead mean operators under 2-tuple linguistic pythagorean fuzzy environment},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Collective neurodynamic optimization for image segmentation
by binary model with constraints. <em>CC</em>, <em>12</em>(6),
1265–1275. (<a
href="https://doi.org/10.1007/s12559-020-09762-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Threshold method is an important image segmentation method, which has been widely used in image segmentation. For this method, it is very important to choose a good threshold. The traditional threshold segmentation algorithm is implemented by exhaustive method, which makes the solution efficiency very low. This paper presents a collective neurodynamic optimization algorithm to solve the problem of binary optimization in the image segmentation. The problem of image segmentation based on threshold is transformed into binary optimization with constraints. Then, a collective neurodynamic optimization algorithm is introduced which combined with feedback neural network and particle swarm optimization (PSO) algorithm. And the linear programming relaxation constraint method is used to relax binary constraints. It is proved by numerical simulation that the feedback neural network algorithm can converge to the exact local optimal solution of the model and the PSO algorithm can get a better local optimal solution. Finally, several sets of comparative experiments are presented. The feasibility of our proposed method is verified; the experimental results demonstrate the effectiveness of our approach in image segmentation. In this study, a collective neurodynamic optimization was proposed for the image segmentation problem. In the future, we expect that multiple centralized neurodynamic models and intelligent algorithms can be used to solve the problem and improve the convergence speed of the solved model.},
  archive      = {J_CC},
  author       = {He, Shengzhan and Huang, Junjian and He, Xing},
  doi          = {10.1007/s12559-020-09762-0},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1265-1275},
  shortjournal = {Cogn. Comput.},
  title        = {Collective neurodynamic optimization for image segmentation by binary model with constraints},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Parameter transfer deep neural network for single-modal
b-mode ultrasound-based computer-aided diagnosis. <em>CC</em>,
<em>12</em>(6), 1252–1264. (<a
href="https://doi.org/10.1007/s12559-020-09761-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Elastography ultrasound (EUS) imaging has shown its effectiveness for diagnosis of tumors by providing additional information about tissue stiffness to the conventional B-mode ultrasound (BUS). However, due to the lack of EUS devices and experienced sonologists, EUS is not widely used, especially in rural areas. It is still a challenging task to improve the performance of the single-modal BUS-based computer-aided diagnosis (CAD) for tumors. In this work, we propose a novel transfer learning (TL)–based deep neural network (DNN) algorithm, named CW-PM-DNN, for the BUS-based CAD by transferring diagnosis knowledge from EUS during model training. CW-PM-DNN integrates both the feature-level and classifier-level knowledge transfer into a unified framework. In the feature-level TL, a bichannel DNN is learned by the cross-weight-based multimodal DL (MDL-CW) algorithm to transfer informative features from EUS to BUS. In the classifier-level TL, a projective model (PM)–based classifier is then embedded to the pretrained bichannel DNN to implement the parameter transfer in the classifier model at the second stage. The back-propagation procedure is then applied to optimize the whole CW-PM-DNN to further improve its performance. Experimental results on two bimodal ultrasound tumor datasets demonstrate that the proposed CW-PM-DNN achieves the best classification accuracy, sensitivity, and specificity of 89.02 ± 1.54%, 88.37 ± 4.72%, and 89.63 ± 4.06%, respectively, for the breast ultrasound dataset, and the corresponding values of 80.57 ± 3.41%, 76.67 ± 3.85%, and 83.94 ± 3.95%, respectively, for the prostate ultrasound dataset. The proposed two-stage TL-based CW-PM-DNN algorithm outperforms all the compared algorithms. It is also proved that the performance of the BUS-based CAD can be significantly improved by transferring the knowledge of EUS. It suggests that CW-PM-DNN has the potential for more applications in the field of medical image–based CAD.},
  archive      = {J_CC},
  author       = {Fei, Xiaoyan and Shen, Lu and Ying, Shihui and Cai, Yehua and Zhang, Qi and Kong, Wentao and Zhou, Weijun and Shi, Jun},
  doi          = {10.1007/s12559-020-09761-1},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1252-1264},
  shortjournal = {Cogn. Comput.},
  title        = {Parameter transfer deep neural network for single-modal B-mode ultrasound-based computer-aided diagnosis},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Anomaly detection in activities of daily living with linear
drift. <em>CC</em>, <em>12</em>(6), 1233–1251. (<a
href="https://doi.org/10.1007/s12559-020-09740-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomalyq detection in Activities of Daily Living (ADL) plays an important role in e-health applications. An abrupt change in the ADL performed by a subject might indicate that she/he needs some help. Another important issue related with e-health applications is the case where the change in ADL undergoes a linear drift, which occurs in cognitive decline, Alzheimer’s disease or dementia. This work presents a novel method for detecting a linear drift in ADL modelled as circular normal distributions. The method is based on techniques commonly used in Statistical Process Control and, through the selection of a convenient threshold, is able to detect and estimate the change point in time when a linear drift started. Public datasets have been used to assess whether ADL can be modelled by a mixture of circular normal distributions. Exhaustive experimentation was performed on simulated data to assess the validity of the change detection algorithm, the results showing that the difference between the real change point and the estimated change point was $4.90_{+3.17}^{-1.98}$ days on average. ADL can be modelled using a mixture of circular normal distributions. A new method to detect anomalies following a linear drift is presented. Exhaustive experiments showed that this method is able to estimate the change point in time for processes following a linear drift.},
  archive      = {J_CC},
  author       = {Belmonte-Fernández, Óscar and Caballer-Miedes, Antonio and Chinellato, Eris and Montoliu, Raúl and Sansano-Sansano, Emilio and García-Vidal, Rubén},
  doi          = {10.1007/s12559-020-09740-6},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1233-1251},
  shortjournal = {Cogn. Comput.},
  title        = {Anomaly detection in activities of daily living with linear drift},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Feature selection of network data VIA ℓ2,p regularization.
<em>CC</em>, <em>12</em>(6), 1217–1232. (<a
href="https://doi.org/10.1007/s12559-020-09763-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is the process of selecting a subset of relevant features from the original feature set, and it plays an important role in handling high-dimensional data. In recent years, sparse learning-based feature selection approaches have been widely studied, and different regularizers have been proposed. Among these regularizers, it has been found that ℓ2,p (0 &lt; p &lt; 1) has a good modeling effect on feature selection due to its excellent performance in inducing sparsity. In this paper, we propose the ℓ2,p norm–based feature selection to deal with network data in an unsupervised scenario, and design an iterative algorithm using the framework of the alternating direction method of multipliers. In order to deal with the nonsmooth and non-Lipschitz continuous subproblem caused by ℓ2,p, we design a nonmonotone smoothing trust region algorithm and present its global convergence analysis. The extensive numerical experiments on real-world network datasets validate the effectiveness of the proposed model and algorithm.},
  archive      = {J_CC},
  author       = {Zhou, Ruizhi and Niu, Lingfeng},
  doi          = {10.1007/s12559-020-09763-z},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1217-1232},
  shortjournal = {Cogn. Comput.},
  title        = {Feature selection of network data VIA ℓ2,p regularization},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Iris segmentation using feature channel optimization for
noisy environments. <em>CC</em>, <em>12</em>(6), 1205–1216. (<a
href="https://doi.org/10.1007/s12559-020-09759-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, iris recognition has been widely used in various fields. As the first step of iris recognition, segmentation accuracy is of great significance to the final recognition. However, iris images exhibit a variety of noise in the real world, which leads to lower segmentation accuracy than the ideal case. To address this problem, this paper proposes an iris segmentation method using feature channel optimization for noisy images. The method for non-ideal environments with noise is more suitable for practical applications. We add dense blocks and dilated convolutional layers to the encoder so that the information gradient flow obtained by different layers can be reused, and the receptive field can be expanded. In the decoder, based on Jensen-Shannon (JS) divergence, we first recalculate the weight of the feature channels obtained from each layer, which enhances the useful information and suppresses the interference information in the noisy environments to boost the segmentation accuracy. The proposed architecture is validated in the CASIA v4.0 interval (CASIA) and IIT Delhi v1.0 datasets (IITD). For CASIA, the mean error rate is 0.78%, and the F-measure value is 98.21%. For IITD, the mean error rate is 0.97%, and the F-measure value is 97.87%. Experimental results show that the proposed method outperforms other state-of-art methods under noisy environments, such as Gaussian blur, Gaussian noise, and salt and pepper noise.},
  archive      = {J_CC},
  author       = {Hao, Kangli and Feng, Guorui and Ren, Yanli and Zhang, Xinpeng},
  doi          = {10.1007/s12559-020-09759-9},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1205-1216},
  shortjournal = {Cogn. Comput.},
  title        = {Iris segmentation using feature channel optimization for noisy environments},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Developed optimization algorithms based on natural taxis
behavior of bacteria. <em>CC</em>, <em>12</em>(6), 1187–1204. (<a
href="https://doi.org/10.1007/s12559-020-09760-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bio-inspired optimization algorithms are capable of resolving a wide variety of challenges in science and technology, including cognitive science. The principles used by the smallest living organisms in the world could be adopted in the decision-based algorithms for artificial intelligence purposes. Bacterial biological functions and behaviors have been the most effective strategies, which have evolved in these single-cell organisms. The bacteria live based on cognitive and social sensing in nature. Using cognitive processing in bacterial populations enables them to perceive the dynamic surrounding ecosystem and explore their environment. Recently, the behavioral pattern of bacterial foraging has been recruited for resolving optimization issues. This paper reviews 22 developed optimization algorithms based on the bacterial life cycle of motile bacteria. The solicitation of these algorithms applies to a wide range of topics, including cognitive analysis, engineering, medicine, and industry. Following a comparison between different algorithms, we summarize the application of the algorithms in these areas. Eventually, some points are suggested for developing and employing the algorithms in future practical applications of cognitive technology.},
  archive      = {J_CC},
  author       = {Sajedi, Hedieh and Mohammadipanah, Fatemeh},
  doi          = {10.1007/s12559-020-09760-2},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1187-1204},
  shortjournal = {Cogn. Comput.},
  title        = {Developed optimization algorithms based on natural taxis behavior of bacteria},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Exploring personalised autonomous vehicles to influence user
trust. <em>CC</em>, <em>12</em>(6), 1170–1186. (<a
href="https://doi.org/10.1007/s12559-020-09757-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trust is a major determinant of acceptance of an autonomous vehicle (AV), and a lack of appropriate trust could prevent drivers and society in general from taking advantage of such technology. This paper makes a new attempt to explore the effects of personalised AVs as a novel approach to the cognitive underpinnings of drivers’ trust in AVs. The personalised AV system is able to identify the driving behaviours of users and thus adapt the driving style of the AV accordingly. A prototype of a personalised AV was designed and evaluated in a lab-based experimental study of 36 human drivers, which investigated the impact of the personalised AV on user trust when compared with manual human driving and non-personalised AVs. The findings show that a personalised AV appears to be significantly more reliable through accepting and understanding each driver’s behaviour, which could thereby increase a user’s willingness to trust the system. Furthermore, a personalised AV brings a sense of familiarity by making the system more recognisable and easier for users to estimate the quality of the automated system. Personalisation parameters were also explored and discussed to support the design of AV systems to be more socially acceptable and trustworthy.},
  archive      = {J_CC},
  author       = {Sun, Xu and Li, Jingpeng and Tang, Pinyan and Zhou, Siyuan and Peng, Xiangjun and Li, Hao Nan and Wang, Qingfeng},
  doi          = {10.1007/s12559-020-09757-x},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1170-1186},
  shortjournal = {Cogn. Comput.},
  title        = {Exploring personalised autonomous vehicles to influence user trust},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Characterizing the time-varying brain networks of
audiovisual integration across frequency bands. <em>CC</em>,
<em>12</em>(6), 1154–1169. (<a
href="https://doi.org/10.1007/s12559-020-09783-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multisensory integration involves multiple cortical regions and occurs at multiple stages with attentional modulation. The structure of network formed by the interactive cortical regions reflects the state of working on a current task and changes continuously with the task processing. In addition, the neural oscillatory responses in various frequency bands are associated with different cognitive functions. Thus, studying topological characteristics of time-varying networks across multiple frequency bands helps to elucidate the mechanism of multisensory integration. Here, we designed an event-related experiment using auditory, visual, and audiovisual stimuli to record electroencephalographic data in both attended and unattended conditions and constructed delta-, theta-, alpha-, and beta-band networks at eight time points post-stimulus. We used graph theory to calculate global properties, nodal out-degree, and their correlation with behavioral performance. The increasing clustering coefficient and global efficiency and decreasing characteristic path length indicated that the brain had optimized the configuration across multiple frequency bands over time to efficiently process audiovisual integration. The differences in global properties and hub distributions showed that each frequency band–specificity system in the brain had a different topological structure, indicating that the networks on each frequency band contributed to various cognitive functions and involved in different stages of audiovisual integration. Our results suggest that differences in cognitive function are, at least partly, due to the different network structures across frequency bands and that the frequency band–specificity systems with different distribution are involved in various stages of audiovisual integration and attention modulation.},
  archive      = {J_CC},
  author       = {Xi, Yang and Li, Qi and Zhang, Mengchao and Liu, Lin and Wu, Jinglong},
  doi          = {10.1007/s12559-020-09783-9},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1154-1169},
  shortjournal = {Cogn. Comput.},
  title        = {Characterizing the time-varying brain networks of audiovisual integration across frequency bands},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Graph convolutional network based on manifold similarity
learning. <em>CC</em>, <em>12</em>(6), 1144–1153. (<a
href="https://doi.org/10.1007/s12559-020-09788-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the area of large-scale graph data representation and semi-supervised learning, deep graph-based convolutional neural networks have been widely applied. However, typical graph convolutional network (GCN) aggregates information of neighbor nodes based on binary neighborhood similarity (adjacency matrix). It treats all neighbor nodes of one node equally, which does not suppress the influence of dissimilar neighbor nodes. In this paper, we investigate GCN based on similarity matrix instead of adjacency matrix of graph nodes. Gaussian heat kernel similarity in Euclidean space is first adopted, which is named EGCN. Then biologically inspired manifold similarity is trained in reproducing kernel Hilbert space (RKHS), based on which a manifold GCN (named MGCN) is proposed for graph data representation and semi-supervised learning with four different kernel types. The proposed method is evaluated with extensive experiments on four benchmark document citation network datasets. The objective function of manifold similarity learning converges very quickly on different datasets using various kernel functions. Compared with state-of-the-art methods, our method is very competitive in terms of graph node recognition accuracy. In particular, the recognition rates of MGCN (Gaussian kernel) and MGCN (Polynomial Kernel) outperform that of typical GCN about 3.8% on Cora dataset, 3.5% on Citeseer dataset, 1.3% on Pubmed dataset and 4% on Cora_ML dataset, respectively. Although the proposed MGCN is relatively simple and easy to implement, it can discover local manifold structure by manifold similarity learning and suppress the influence of dissimilar neighbor nodes, which shows the effectiveness of the proposed MGCN.},
  archive      = {J_CC},
  author       = {Chen, Si-Bao and Tian, Xiu-Zhi and Ding, Chris H. Q. and Luo, Bin and Liu, Yi and Huang, Hao and Li, Qiang},
  doi          = {10.1007/s12559-020-09788-4},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1144-1153},
  shortjournal = {Cogn. Comput.},
  title        = {Graph convolutional network based on manifold similarity learning},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mixture kernel density estimation and remedied correlation
matrix on the EEG-based copula model for the assessment of visual
discomfort. <em>CC</em>, <em>12</em>(6), 1130–1143. (<a
href="https://doi.org/10.1007/s12559-020-09780-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since electroencephalogram (EEG) signals can directly provide information on changes in brain activity due to behaviour changes, how to assess visual discomfort through EEG signals attracts researchers’ attention. However, previous assessments based on time-domain EEG features lack sufficient consideration of the dependence among EEG signals, which may affect the discrimination to visual discomfort. Although the copula model can explore the dependence among variables, the EEG-based copula models still have the following deficiencies: (1) the methods ignoring the fine-grained information hidden in EEG signals could make the estimated marginal density function improper, and (2) the approaches neglecting the pseudo-correlation among data may inappropriately estimate the correlation matrix parameter of the copula density function. The mixture kernel density estimation (MKDE) and remedied correlation matrix (RCM) on the EEG-based copula model are proposed to mitigate the mentioned shortcomings. The simulation experiments show that MKDE can not only better estimate the marginal density function but also explore fine-grained information. The RCM can be closer to the real correlation matrix parameter. With the favourable quality of the proposed EEG-based model, it is used to extract time-domain EEG features to assess visual discomfort further. To our best knowledge, the extracted features present better discrimination to visual discomfort compared with the features extracted by the state-of-the-art method.},
  archive      = {J_CC},
  author       = {Zheng, Yawen and Zhao, Xiaojie and Yao, Li},
  doi          = {10.1007/s12559-020-09780-y},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1130-1143},
  shortjournal = {Cogn. Comput.},
  title        = {Mixture kernel density estimation and remedied correlation matrix on the EEG-based copula model for the assessment of visual discomfort},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A structural topic modeling-based bibliometric study of
sentiment analysis literature. <em>CC</em>, <em>12</em>(6), 1097–1129.
(<a href="https://doi.org/10.1007/s12559-020-09745-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis is an increasingly evolving field of research in computer science. With the considerable number of studies on innovative sentiment analysis available, it is worth the effort to present a review to understand the research on sentiment analysis comprehensively. This study aimed to investigate issues involved in sentiment analysis; for instance, (1) What types of research topics had been covered in sentiment analysis research? (2) How did the research topics evolve with time? (3) What were the topic distributions for major contributors? (4) How did major contributors collaborate in sentiment analysis research? Based on articles retrieved from the Web of Science, this study presented a bibliometric review of sentiment analysis with the basis of a structural topic modeling method to obtain an extensive overview of the research field. We also utilized methods such as regression analysis, geographic visualization, social network analysis, and the Mann–Kendal trend test. Sentiment analysis research had, overall, received a growing interest in academia. In addition, institutions and authors within the same countries/regions were liable to collaborate closely. Highly discussed topics were sentiment lexicons and knowledge bases, aspect-based sentiment analysis, and social network analysis. Several current and potential future directions, such as deep learning for natural language processing, web services, recommender systems and personalization, and education and social issues, were revealed. The findings provided a thorough understanding of the trends and topics regarding sentiment analysis, which could help in efficiently monitoring future research works and projects. Through this study, we proposed a framework for conducting a comprehensive bibliometric analysis.},
  archive      = {J_CC},
  author       = {Chen, Xieling and Xie, Haoran},
  doi          = {10.1007/s12559-020-09745-1},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1097-1129},
  shortjournal = {Cogn. Comput.},
  title        = {A structural topic modeling-based bibliometric study of sentiment analysis literature},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Weakly supervised learning in neural encoding for the
position of the moving finger of a macaque. <em>CC</em>, <em>12</em>(5),
1083–1096. (<a
href="https://doi.org/10.1007/s12559-020-09742-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of neural decoding is essential for the realization of a neural interface. In this study, the position of the moving finger of a macaque was directly decoded through the neuron spike signals in the motor cortex, instead of relying on the synergy of the related muscle tissues around the body, also known as neural decoding. Currently, supervised learning is the most commonly employed method for this purpose. However, based on existing technologies, unsupervised learning with regression causes excessive errors. To solve this problem, weakly supervised learning (WSL) was used to correct the predicted position of the moving finger of a macaque in unsupervised training. Then, the corrected finger position was further used to train and accurately fit the weight parameters. We then utilized public data to evaluate the decoding performance of the Kalman filter (KF) and the expectation maximization (EM) algorithms in the WSL model. Unlike in previous methods, in WSL, the only available information is that the finger has moved to four areas in the plane, instead of the actual track value. When compared to the supervised models, the WSL decoding performance only differs by approximately 0.4%. This result improves by 41.3% relative to unsupervised models in the two-dimensional plane. The investigated approach overcomes the instability and inaccuracy of unsupervised learning. What’s more, the method in the paper also verified that the unsupervised encoding and decoding technology of neuronal signals is related to the range of external activities, rather than having a priori specific location.},
  archive      = {J_CC},
  author       = {Feng, Jingyi and Wu, Haifeng and Zeng, Yu and Wang, Yuhong},
  doi          = {10.1007/s12559-020-09742-4},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1083-1096},
  shortjournal = {Cogn. Comput.},
  title        = {Weakly supervised learning in neural encoding for the position of the moving finger of a macaque},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A revised picture fuzzy linguistic aggregation operator and
its application to group decision-making. <em>CC</em>, <em>12</em>(5),
1070–1082. (<a
href="https://doi.org/10.1007/s12559-020-09728-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complexity of decision environments poses challenges for individuals engaged in decision-making proceedings. Picture fuzzy linguistic sets (PFLSs) are an effective tool for depicting the inherent subjective nature of human cognition. Aiming for the promotion of a general theory on PFLSs, we conduct a critical research to identify some limitations of a recent publication in Cognitive Computation [2018, 10(2), 242–259]. This published article is a meaningful and interesting study that initiates the PFLS as well as introduces the corresponding operations and the Archimedean picture fuzzy linguistic weighted arithmetic averaging operator. Unfortunately, we have carefully analyzed these operations and found that they may not be appropriate to all situations within picture fuzzy linguistic environment, which would result in the violation of human cognition. To eliminate this limitation, we explore and suggest novel operational laws and an aggregation operator for PFLSs from a modified version, so as to support further study on picture fuzzy linguistic group decision-making. Furthermore, a comparative and illustrative example is presented to validate the advantages of our modified operations. Towardly , the research outcome will be of significant benefit to promoting the development of picture fuzzy linguistic decision-making theory. Accordingly, our contribution to improving the current research on PFLSs makes their application in solving realistic problems feasible and practical.},
  archive      = {J_CC},
  author       = {Zhang, Xue-yang and Wang, Jing and Wang, Jian-qiang and Hu, Jun-hua},
  doi          = {10.1007/s12559-020-09728-2},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1070-1082},
  shortjournal = {Cogn. Comput.},
  title        = {A revised picture fuzzy linguistic aggregation operator and its application to group decision-making},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Automatic arabic text summarization using analogical
proportions. <em>CC</em>, <em>12</em>(5), 1043–1069. (<a
href="https://doi.org/10.1007/s12559-020-09748-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic text summarization is the process of generating or extracting a brief representation of an input text. There are several algorithms for extractive summarization in the literature tested by using English and other languages datasets; however, only few extractive Arabic summarizers exist due to the lack of large collection in Arabic language. This paper proposes and assesses new extractive single-document summarization approaches based on analogical proportions which are statements of the form “a is to b as c is to d”. The goal is to study the capability of analogical proportions to represent the relationship between documents and their corresponding summaries. For this purpose, we suggest two algorithms to quantify the relevance/irrelevance of an extracted keyword from the input text, to build its summary. In the first algorithm, the analogical proportion representing this relationship is limited to check the existence/non-existence of the keyword in any document or summary in a binary way without considering keyword frequency in the text, whereas the analogical proportion of the second algorithm considers this frequency. We have assessed and compared these two algorithms with some language-independent summarizers (LexRank, TextRank, Luhn and LSA (Latent Semantic Analysis)) using our large corpus ANT (Arabic News Texts) and a small test collection EASC (Essex Arabic Summaries Corpus) by computing ROUGE (Recall-Oriented Understudy for Gisting Evaluation) and BLEU (BiLingual Evaluation Understudy) metrics. The best-achieved results are ROUGE-1 = 0.96 and BLEU-1 = 0.65 corresponding to educational documents from EASC collection which outperform the best LexRank algorithm. The proposed algorithms are also compared with three other Arabic extractive summarizers, using EASC collection, and show better results in terms of ROUGE-1 = 0.75 and BLEU-1 = 0.47 for the first algorithm, and ROUGE-1 = 0.74 and BLEU-1 = 0.49 for the second one. Experimental results show the interest of analogical proportions for text summarization. In particular, analogical summarizers significantly outperform three among four language-independent summarizers in the case of BLEU-1 for ANT collection and they are not significantly outperformed by any other summarizer in the case of EASC collection.},
  archive      = {J_CC},
  author       = {Elayeb, Bilel and Chouigui, Amina and Bounhas, Myriam and Khiroun, Oussama Ben},
  doi          = {10.1007/s12559-020-09748-y},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1043-1069},
  shortjournal = {Cogn. Comput.},
  title        = {Automatic arabic text summarization using analogical proportions},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel functional link network stacking ensemble with
fractal features for multichannel fall detection. <em>CC</em>,
<em>12</em>(5), 1024–1042. (<a
href="https://doi.org/10.1007/s12559-020-09749-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Falls are a major health concern and result in high morbidity and mortality rates in older adults with high costs to health services. Automatic fall classification and detection systems can provide early detection of falls and timely medical aid. This paper proposes a novel Random Vector Functional Link (RVFL) stacking ensemble classifier with fractal features for classification of falls. The fractal Hurst exponent is used as a representative of fractal dimensionality for capturing irregularity of accelerometer signals for falls and other activities of daily life. The generalised Hurst exponents along with wavelet transform coefficients are leveraged as input feature space for a novel stacking ensemble of RVFLs composed with an RVFL neural network meta-learner. Novel fast selection criteria are presented for base classifiers founded on the proposed diversity indicator, obtained from the overall performance values during the training phase. The proposed features and the stacking ensemble provide the highest classification accuracy of 95.71% compared with other machine learning techniques, such as Random Forest (RF), Artificial Neural Network (ANN) and Support Vector Machine. The proposed ensemble classifier is 2.3× faster than a single Decision Tree and achieves the highest speedup in training time of 317.7× and 198.56× compared with a highly optimised ANN and RF ensemble, respectively. The significant improvements in training times of the order of 100× and high accuracy demonstrate that the proposed RVFL ensemble is a prime candidate for real-time, embedded wearable device–based fall detection systems.},
  archive      = {J_CC},
  author       = {Tahir, Ahsen and Morison, Gordon and Skelton, Dawn A. and Gibson, Ryan M.},
  doi          = {10.1007/s12559-020-09749-x},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1024-1042},
  shortjournal = {Cogn. Comput.},
  title        = {A novel functional link network stacking ensemble with fractal features for multichannel fall detection},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Social group optimization–assisted kapur’s entropy and
morphological segmentation for automated detection of COVID-19 infection
from computed tomography images. <em>CC</em>, <em>12</em>(5), 1011–1023.
(<a href="https://doi.org/10.1007/s12559-020-09751-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The coronavirus disease (COVID-19) caused by a novel coronavirus, SARS-CoV-2, has been declared a global pandemic. Due to its infection rate and severity, it has emerged as one of the major global threats of the current generation. To support the current combat against the disease, this research aims to propose a machine learning–based pipeline to detect COVID-19 infection using lung computed tomography scan images (CTI). This implemented pipeline consists of a number of sub-procedures ranging from segmenting the COVID-19 infection to classifying the segmented regions. The initial part of the pipeline implements the segmentation of the COVID-19–affected CTI using social group optimization–based Kapur’s entropy thresholding, followed by k-means clustering and morphology-based segmentation. The next part of the pipeline implements feature extraction, selection, and fusion to classify the infection. Principle component analysis–based serial fusion technique is used in fusing the features and the fused feature vector is then employed to train, test, and validate four different classifiers namely Random Forest, K-Nearest Neighbors (KNN), Support Vector Machine with Radial Basis Function, and Decision Tree. Experimental results using benchmark datasets show a high accuracy (&gt; 91%) for the morphology-based segmentation task; for the classification task, the KNN offers the highest accuracy among the compared classifiers (&gt; 87%). However, this should be noted that this method still awaits clinical validation, and therefore should not be used to clinically diagnose ongoing COVID-19 infection.},
  archive      = {J_CC},
  author       = {Dey, Nilanjan and Rajinikanth, V. and Fong, Simon James and Kaiser, M. Shamim and Mahmud, Mufti},
  doi          = {10.1007/s12559-020-09751-3},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1011-1023},
  shortjournal = {Cogn. Comput.},
  title        = {Social group Optimization–Assisted kapur’s entropy and morphological segmentation for automated detection of COVID-19 infection from computed tomography images},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Particle swarm optimization based swarm intelligence for
active learning improvement: Application on medical data classification.
<em>CC</em>, <em>12</em>(5), 991–1010. (<a
href="https://doi.org/10.1007/s12559-020-09739-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised learning targets the common situation where labeled data are scarce but unlabeled data are abundant. It uses unlabeled data to help supervised learning tasks. In practice, it may make sense to utilize active learning in conjunction with semi-supervised learning. That is, we might allow the learning algorithm to pick a set of unlabeled instances to be labeled by a domain expert, which will then be used as the labeled data set. However, existing approaches are computationally expensive and require searching through an entire unlabeled dataset, which may contain redundant instances that provide no instructive information to the classifier and can decrease the performance. To address this optimization problem, a hybrid system that combines active learning (AL) and particle swarm optimization (PSO) algorithms is proposed to reduce the cost of labeling while building a more efficient classifier. The novelty of this work resides in the integration of a bio-inspired optimization algorithm in the machine learning strategy. Furthermore, a novel uncertainty measure was integrated into the particle swarm optimization algorithm as an objective function to select from massive amounts of medical instances those that are deemed most informative. To evaluate the effectiveness of the proposed approach, eighteen (18) benchmark datasets were used and compared against three best-known classifiers with different learning paradigms: AL–NB an active learning algorithm using Naïve Base classifier and Margin Sampling strategy, SVM (Support Vector Machine), ELM (Extreme Learning Machine) with supervised learning, and TSVM (Transductive Support Vector Machine) with the semi-supervised learning. Experiments showed that the proposed approach is effective in reducing the efforts required by experts for medical data annotation to produce an accurate classifier. The active learning approach has been utilized to optimize the expensive task of labeling. Based on a novel uncertainty measure, the nature-inspired algorithm PSO attempts to select from massive amounts of unlabeled medical instances those considered informative, at the same time improving the classifier performance. The experiments carried out confirm that the proposed strategy significantly enhances the performance of the AL algorithm compared with the commonly used uncertainty strategies. It achieves a performance similar to that of fully supervised and semi-supervised algorithms while requiring much less labeling. As a future extension of this work, it would be interesting to integrate other evolutionary optimization algorithms and compare them with our approach. In addition, it is beneficial to test the impact of using other variants of PSO algorithm in our approach. Also, it is aimed to test more classification algorithms in the experimentation process.},
  archive      = {J_CC},
  author       = {Zemmal, Nawel and Azizi, Nabiha and Sellami, Mokhtar and Cheriguene, Soraya and Ziani, Amel and AlDwairi, Monther and Dendani, Nadjette},
  doi          = {10.1007/s12559-020-09739-z},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {991-1010},
  shortjournal = {Cogn. Comput.},
  title        = {Particle swarm optimization based swarm intelligence for active learning improvement: Application on medical data classification},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Densely connected deep extreme learning machine algorithm.
<em>CC</em>, <em>12</em>(5), 979–990. (<a
href="https://doi.org/10.1007/s12559-020-09752-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a single hidden layer feed-forward neural network, the extreme learning machine (ELM) has been extensively studied for its short training time and good generalization ability. Recently, with the deep learning algorithm becoming a research hotspot, some deep extreme learning machine algorithms such as multi-layer extreme learning machine (ML-ELM) and hierarchical extreme learning machine (H-ELM) have also been proposed. However, the deep ELM algorithm also has many shortcomings: (1) when the number of model layers is shallow, the random feature mapping makes the sample features cannot be fully learned and utilized; (2) when the number of model layers is deep, the validity of the sample features will decrease after continuous abstraction and generalization. In order to solve the above problems, this paper proposes a densely connected deep ELM algorithm: dense-HELM (D-HELM). Benchmark data sets of different sizes have been employed for the property of the D-HELM algorithm. Compared with the H-ELM algorithm on the benchmark dataset, the average test accuracy is increased by 5.34% and the average training time is decreased by 21.15%. On the NORB dataset, the proposed D-HELM algorithm still maintains the best classification results and the fastest training speed. The D-HELM algorithm can make full use of the features of hidden layer learning by using the densely connected network structure and effectively reduce the number of parameters. Compared with the H-ELM algorithm, the D-HELM algorithm significantly improves the recognition accuracy and accelerates the training speed of the algorithm.},
  archive      = {J_CC},
  author       = {Jiang, X. W. and Yan, T. H. and Zhu, J. J. and He, B. and Li, W. H. and Du, H. P. and Sun, S. S.},
  doi          = {10.1007/s12559-020-09752-2},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {979-990},
  shortjournal = {Cogn. Comput.},
  title        = {Densely connected deep extreme learning machine algorithm},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cognitive traffic anomaly prediction from GPS trajectories
using visible outlier indexes and meshed spatiotemporal neighborhoods.
<em>CC</em>, <em>12</em>(5), 967–978. (<a
href="https://doi.org/10.1007/s12559-020-09735-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advancement of cognitive computing for traffic status understanding, powered by machine learning and data analytics, enables prediction of traffic anomalies from continuously generated big GPS trajectory data. Existing methods generally use traffic indicators such as traffic flows and speeds to detect anomalies, but they may over-identify anomalies while missing the critical ones. For example, they use historical anomalies to train the prediction model, but past anomalies may not be a perfect indication of future anomalies since anomalies are often rare. In this paper, we propose a novel cognitive approach, a Visible Outlier Indexes and Meshed Spatiotemporal Neighborhoods (VOI-MSN) method, to predict traffic anomalies from GPS trajectories. In the VOI-MSN method, two cognitive techniques are provided. The first is VOI, which measures the abnormal scores using overall samples and can be intuitively understood by humans. The second is MSN, which learns the dynamic impact range (i.e., spatiotemporal neighborhood) from historical trajectory data and provides a complete and exact analysis of the local traffic situation. It emulates human cognitive processing to adaptively judge the impact range by experience. The effectiveness of the proposed method is demonstrated using a massive trajectory dataset with 2.5 billion location records for 27,266 taxis, and it achieves higher precision and recall in predicting traffic anomalies than the counterpart methods. The VOI-MSN method achieves high accuracy and recall for predicting traffic anomalies. It outperforms traffic indicator–based (speed and traffic flow) methods, the fixed-size spatial neighborhood method and the causal network method.},
  archive      = {J_CC},
  author       = {Huang, Guang-Li and Deng, Ke and He, Jing},
  doi          = {10.1007/s12559-020-09735-3},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {967-978},
  shortjournal = {Cogn. Comput.},
  title        = {Cognitive traffic anomaly prediction from GPS trajectories using visible outlier indexes and meshed spatiotemporal neighborhoods},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Why should we add early exits to neural networks?
<em>CC</em>, <em>12</em>(5), 954–966. (<a
href="https://doi.org/10.1007/s12559-020-09734-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks are generally designed as a stack of differentiable layers, in which a prediction is obtained only after running the full stack. Recently, some contributions have proposed techniques to endow the networks with early exits, allowing to obtain predictions at intermediate points of the stack. These multi-output networks have a number of advantages, including (i) significant reductions of the inference time, (ii) reduced tendency to overfitting and vanishing gradients, and (iii) capability of being distributed over multi-tier computation platforms. In addition, they connect to the wider themes of biological plausibility and layered cognitive reasoning. In this paper, we provide a comprehensive introduction to this family of neural networks, by describing in a unified fashion the way these architectures can be designed, trained, and actually deployed in time-constrained scenarios. We also describe in-depth their application scenarios in 5G and Fog computing environments, as long as some of the open research questions connected to them.},
  archive      = {J_CC},
  author       = {Scardapane, Simone and Scarpiniti, Michele and Baccarelli, Enzo and Uncini, Aurelio},
  doi          = {10.1007/s12559-020-09734-4},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {954-966},
  shortjournal = {Cogn. Comput.},
  title        = {Why should we add early exits to neural networks?},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Handwriting biometrics: Applications and future trends in
e-security and e-health. <em>CC</em>, <em>12</em>(5), 940–953. (<a
href="https://doi.org/10.1007/s12559-020-09755-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online handwritten analysis presents many applications in e-security, signature biometrics being the most popular but not the only one. Handwriting analysis also has an important set of applications in e-health. Both kinds of applications (e-security and e-health) have some unsolved questions and relations among them that should be addressed in the next years. We summarize the state of the art and applications based on handwriting signals. Later on, we focus on the main achievements and challenges that should be addressed by the scientific community, providing a guide for future research. Among all the points discussed in this article, we remark the importance of considering security, health, and metadata from a joint perspective. This is especially critical due to the risks inherent when using these behavioral signals.},
  archive      = {J_CC},
  author       = {Faundez-Zanuy, Marcos and Fierrez, Julian and Ferrer, Miguel A. and Diaz, Moises and Tolosana, Ruben and Plamondon, Réjean},
  doi          = {10.1007/s12559-020-09755-z},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {940-953},
  shortjournal = {Cogn. Comput.},
  title        = {Handwriting biometrics: Applications and future trends in e-security and e-health},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Comprehensive taxonomies of nature- and bio-inspired
optimization: Inspiration versus algorithmic behavior, critical analysis
recommendations. <em>CC</em>, <em>12</em>(5), 897–939. (<a
href="https://doi.org/10.1007/s12559-020-09730-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent algorithmic family simulates different biological processes observed in Nature in order to efficiently address complex optimization problems. In the last years the number of bio-inspired optimization approaches in literature has grown considerably, reaching unprecedented levels that dark the future prospects of this field of research. This paper addresses this problem by proposing two comprehensive, principle-based taxonomies that allow researchers to organize existing and future algorithmic developments into well-defined categories, considering two different criteria: the source of inspiration and the behavior of each algorithm. Using these taxonomies we review more than three hundred publications dealing with nature-inspired and bio-inspired algorithms, and proposals falling within each of these categories are examined, leading to a critical summary of design trends and similarities between them, and the identification of the most similar classical algorithm for each reviewed paper. From our analysis we conclude that a poor relationship is often found between the natural inspiration of an algorithm and its behavior. Furthermore, similarities in terms of behavior between different algorithms are greater than what is claimed in their public disclosure: specifically, we show that more than one-third of the reviewed bio-inspired solvers are versions of classical algorithms. Grounded on the conclusions of our critical analysis, we give several recommendations and points of improvement for better methodological practices in this active and growing research field.},
  archive      = {J_CC},
  author       = {Molina, Daniel and Poyatos, Javier and Ser, Javier Del and García, Salvador and Hussain, Amir and Herrera, Francisco},
  doi          = {10.1007/s12559-020-09730-8},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {897-939},
  shortjournal = {Cogn. Comput.},
  title        = {Comprehensive taxonomies of nature- and bio-inspired optimization: Inspiration versus algorithmic behavior, critical analysis recommendations},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Commentary on “on intuitionistic fuzzy copula aggregation
operators in multiple-attribute decision making.” <em>CC</em>,
<em>12</em>(4), 891–895. (<a
href="https://doi.org/10.1007/s12559-020-09746-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CC},
  author       = {Kaur, Arshdeep and Kumar, Amit},
  doi          = {10.1007/s12559-020-09746-0},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {891-895},
  shortjournal = {Cogn. Comput.},
  title        = {Commentary on “On intuitionistic fuzzy copula aggregation operators in multiple-attribute decision making”},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An effective semi-fragile watermarking method for image
authentication based on lifting wavelet transform and feed-forward
neural network. <em>CC</em>, <em>12</em>(4), 863–890. (<a
href="https://doi.org/10.1007/s12559-019-09700-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital watermarking is a significant issue in the field of information security and avoiding the misuse of images in the world of Internet and communication. This paper proposes a novel watermarking method for tamper detection and recovery using semi-fragile data hiding, based on lifting wavelet transform (LWT) and feed-forward neural network (FNN). In this work, first, the host image is decomposed up to one level using LWT, and the discrete cosine transform (DCT) is applied to each 2×2 blocks of diagonal details. Next, a random binary sequence is embedded in each block as the watermark by correlating DC coefficients. In the authentication stage, first, the geometry is analyzed by using speeded up robust features (SURF) algorithm and extract watermark bits by using FNN. Afterward, logical exclusive or operation between original and extracted watermark is applied to detect tampered region. Eventually, in the recovery stage, tampered regions are recovered using the inverse halftoning technique. The performance and efficiency of the method and its robustness against various geometric, non-geometric, and hybrid attacks are reported. From the experimental results, it can be seen that the proposed method is superior in terms of robustness and quality of the watermarked and recovered images, respectively, compared to the state-of-the-art methods. Besides, imperceptibility has been improved by using different correlation steps as the gain factor for flat (smooth) and texture (rough) blocks. Based on the advantages exhibited, the proposed method outperforms the related works, in terms of superiority, efficiency, and effectiveness for tamper detection and recovery-based applications.},
  archive      = {J_CC},
  author       = {Bolourian Haghighi, Behrouz and Taherinia, Amir Hossein and Monsefi, Reza},
  doi          = {10.1007/s12559-019-09700-9},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {863-890},
  shortjournal = {Cogn. Comput.},
  title        = {An effective semi-fragile watermarking method for image authentication based on lifting wavelet transform and feed-forward neural network},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Extracting time expressions and named entities with
constituent-based tagging schemes. <em>CC</em>, <em>12</em>(4), 844–862.
(<a href="https://doi.org/10.1007/s12559-020-09714-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time expressions and named entities play important roles in data mining, information retrieval, and natural language processing. However, the conventional position-based tagging schemes (e.g., the BIO and BILOU schemes) that previous research used to model time expressions and named entities suffer from the problem of inconsistent tag assignment. To overcome the problem of inconsistent tag assignment, we designed a new type of tagging schemes to model time expressions and named entities based on their constituents. Specifically, to model time expressions, we defined a constituent-based tagging scheme termed TOMN scheme with four tags, namely T, O, M, and N, indicating the defined constituents of time expressions, namely time token, modifier, numeral, and the words outside time expressions. To model named entities, we defined a constituent-based tagging scheme termed UGTO scheme with four tags, namely U, G, T, and O, indicating the defined constituents of named entities, namely uncommon word, general modifier, trigger word, and the words outside named entities. In modeling, our TOMN and UGTO schemes model time expressions and named entities under conditional random fields with minimal features according to an in-depth analysis for the characteristics of time expressions and named entities. Experiments on diverse datasets demonstrate that our proposed methods perform equally with or more effectively than representative state-of-the-art methods on both time expression extraction and named entity extraction.},
  archive      = {J_CC},
  author       = {Zhong, Xiaoshi and Cambria, Erik and Hussain, Amir},
  doi          = {10.1007/s12559-020-09714-8},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {844-862},
  shortjournal = {Cogn. Comput.},
  title        = {Extracting time expressions and named entities with constituent-based tagging schemes},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cognitive template-clustering improved LineMod for efficient
multi-object pose estimation. <em>CC</em>, <em>12</em>(4), 834–843. (<a
href="https://doi.org/10.1007/s12559-020-09717-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various types of theoretical algorithms have been proposed for 6D pose estimation, e.g., the point pair method, template matching method, Hough forest method, and deep learning method. However, they are still far from the performance of our natural biological systems, which can undertake 6D pose estimation of multi-objects efficiently, especially with severe occlusion. With the inspiration of the Müller-Lyer illusion in the biological visual system, in this paper, we propose a cognitive template-clustering improved LineMod (CT-LineMod) model. The model uses a 7D cognitive feature vector to replace standard 3D spatial points in the clustering procedure of Patch-LineMod, in which the cognitive distance of different 3D spatial points will be further influenced by the additional 4D information related with direction and magnitude of features in the Müller-Lyer illusion. The 7D vector will be dimensionally reduced into the 3D vector by the gradient-descent method, and then further clustered by K-means to aggregately match templates and automatically eliminate superfluous clusters, which makes the template matching possible on both holistic and part-based scales. The model has been verified on the standard Doumanoglou dataset and demonstrates a state-of-the-art performance, which shows the accuracy and efficiency of the proposed model on cognitive feature distance measurement and template selection on multiple pose estimation under severe occlusion. The powerful feature representation in the biological visual system also includes characteristics of the Müller-Lyer illusion, which, to some extent, will provide guidance towards a biologically plausible algorithm for efficient 6D pose estimation under severe occlusion.},
  archive      = {J_CC},
  author       = {Zhang, Tielin and Yang, Yang and Zeng, Yi and Zhao, Yuxuan},
  doi          = {10.1007/s12559-020-09717-5},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {834-843},
  shortjournal = {Cogn. Comput.},
  title        = {Cognitive template-clustering improved LineMod for efficient multi-object pose estimation},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). TeKET: A tree-based unsupervised keyphrase extraction
technique. <em>CC</em>, <em>12</em>(4), 811–833. (<a
href="https://doi.org/10.1007/s12559-019-09706-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic keyphrase extraction techniques aim to extract quality keyphrases for higher level summarization of a document. Majority of the existing techniques are mainly domain-specific, which require application domain knowledge and employ higher order statistical methods, and computationally expensive and require large train data, which is rare for many applications. Overcoming these issues, this paper proposes a new unsupervised keyphrase extraction technique. The proposed unsupervised keyphrase extraction technique, named TeKET or Tree-based Keyphrase Extraction Technique, is a domain-independent technique that employs limited statistical knowledge and requires no train data. This technique also introduces a new variant of a binary tree, called KeyPhrase Extraction (KePhEx) tree, to extract final keyphrases from candidate keyphrases. In addition, a measure, called Cohesiveness Index or CI, is derived which denotes a given node’s degree of cohesiveness with respect to the root. The CI is used in flexibly extracting final keyphrases from the KePhEx tree and is co-utilized in the ranking process. The effectiveness of the proposed technique and its domain and language independence are experimentally evaluated using available benchmark corpora, namely SemEval-2010 (a scientific articles dataset), Theses100 (a thesis dataset), and a German Research Article dataset, respectively. The acquired results are compared with other relevant unsupervised techniques belonging to both statistical and graph-based techniques. The obtained results demonstrate the improved performance of the proposed technique over other compared techniques in terms of precision, recall, and F1 scores.},
  archive      = {J_CC},
  author       = {Rabby, Gollam and Azad, Saiful and Mahmud, Mufti and Zamli, Kamal Z. and Rahman, Mohammed Mostafizur},
  doi          = {10.1007/s12559-019-09706-3},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {811-833},
  shortjournal = {Cogn. Comput.},
  title        = {TeKET: A tree-based unsupervised keyphrase extraction technique},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cognitive system framework for brain-training exercise based
on human-robot interaction. <em>CC</em>, <em>12</em>(4), 793–810. (<a
href="https://doi.org/10.1007/s12559-019-09696-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Every 3 seconds, someone develops dementia worldwide. Brain-training exercises, preferably involving also physical activity, have shown their potential to monitor and improve the brain function of people affected by Alzheimer disease (AD) or mild cognitive impairment (MCI). This paper presents a cognitive robotic system designed to assist mild dementia patients during brain-training sessions of sorting tokens, an exercise inspired by the Syndrom KurzTest neuropsychological test (SKT). The system is able to perceive, learn and adapt to the user’s behaviour and is composed of two main modules. The adaptive module based on representing the human-robot interaction as a planning problem, that can adapt to the user performance offering different encouragement and recommendation actions using both verbal and gesture communication in order to minimize the time spent to solve the exercise. As safety is a very important issue, the cognitive system is enriched with a safety module that monitors the possibility of physical contact and reacts accordingly. The cognitive system is presented as well as its embodiment in a real robot. Simulated experiments are performed to (i) evaluate the adaptability of the system to different patient use-cases and (ii) validate the coherence of the proposed safety module. A real experiment in the lab, with able users, is used as preliminary evaluation to validate the overall approach. Results in laboratory conditions show that the two presented modules effectively provide additional and essential functionalities to the system, although further work is necessary to guarantee robustness and timely response of the robot before testing it with patients.},
  archive      = {J_CC},
  author       = {Andriella, Antonio and Torras, Carme and Alenyà, Guillem},
  doi          = {10.1007/s12559-019-09696-2},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {793-810},
  shortjournal = {Cogn. Comput.},
  title        = {Cognitive system framework for brain-training exercise based on human-robot interaction},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A review of shorthand systems: From brachygraphy to
microtext and beyond. <em>CC</em>, <em>12</em>(4), 778–792. (<a
href="https://doi.org/10.1007/s12559-020-09723-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human civilizations have performed the art of writing across continents and over different time periods. In order to speed up the writing process, the art of shorthand (brachygraphy) came into existence. Today, the performance of writing does not make an exception in social media platforms. Brachygraphy started to re-emerge in the early 2000s in the form of microtext in order to facilitate faster typing without compromising semantic clarity. This paper focuses on microtext approaches predominantly found in social media and explains the relevance of microtext normalization for natural language processing tasks in English. The review introduces brachygraphy and how it has evolved into microtext in today’s social media–dominant society. The study provides a comprehensive classification of microtext normalization based on different approaches. We propose to classify microtext based on different normalization techniques, i.e. syntax-based (syntactic), probability-based (probabilistic) and phonetic-based approaches and review application areas, strategies and challenges of microtext normalization. The review shows that there is a compelling similarity between brachygraphy and microtext even though they started centuries apart. This paper represents the first attempt to connect brachygraphy to current texting language and to show its impact in social media. This paper classifies microtext normalization according to different approaches and discusses how, in the future, microtext will likely comprise both words and images together. This will expand the horizon of human creative power. We conclude the review with some considerations on future directions.},
  archive      = {J_CC},
  author       = {Satapathy, Ranjan and Cambria, Erik and Nanetti, Andrea and Hussain, Amir},
  doi          = {10.1007/s12559-020-09723-7},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {778-792},
  shortjournal = {Cogn. Comput.},
  title        = {A review of shorthand systems: From brachygraphy to microtext and beyond},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Autism AI: A new autism screening system based on artificial
intelligence. <em>CC</em>, <em>12</em>(4), 766–777. (<a
href="https://doi.org/10.1007/s12559-020-09743-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autistic spectrum disorder (ASD) is a neurodevelopment condition normally linked with substantial healthcare costs and time-consuming assessments where early detection of ASD traits can help limit the development of the condition. The existing conventional ASD screening methods contain a large number of items and are based on domain expert rules which may be criticized of being lengthy and subjective. More importantly, these methods use basic scoring functions to pinpoint to autistic traits rather intelligently learning patterns from cases and controls which can be more accurate and efficient. One promising solution to deal with the above issues and speed up ASD assessment referrals is to develop intelligent artificial intelligence screening methods that not only provide accurate pre-diagnostic classifications but also improve the efficiency and accessibility of the screening process. This paper proposes a new autism screening system that replaces the conventional scoring functions in classic screening methods with deep learning algorithms. The system is composed of a mobile application that provides the user interface capturing questionnaire data; an intelligent ASD detection web service that interfaces with a Convolutional Neural Network (CNN) trained with historical ASD cases; and a database that enables the CNN to learn new knowledge from future users of the system. The CNN classification method was evaluated against a large autism dataset consisting of adult, adolescent, child, and toddler cases and controls. The results obtained from the CNN were compared with other intelligent algorithms in which superior performance was achieved by the CNN. Particularly, the proposed CNN-based ASD classification system revealed higher accuracy, sensitivity, and specificity when compared with conventional screening methods. This indeed will be of high benefit for busy medical clinics and diagnosticians and could possibly be a new direction to change the way ASD diagnosis process is conducted in the future.},
  archive      = {J_CC},
  author       = {Shahamiri, Seyed Reza and Thabtah, Fadi},
  doi          = {10.1007/s12559-020-09743-3},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {766-777},
  shortjournal = {Cogn. Comput.},
  title        = {Autism AI: A new autism screening system based on artificial intelligence},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel natural language processing (NLP)–based machine
translation model for english to pakistan sign language translation.
<em>CC</em>, <em>12</em>(4), 748–765. (<a
href="https://doi.org/10.1007/s12559-020-09731-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The deaf community in the world uses a gesture-based language, generally known as sign language. Every country has a different sign language; for instance, USA has American Sign Language (ASL) and UK has British Sign Language (BSL). The deaf community in Pakistan uses Pakistan Sign Language (PSL), which like other natural languages, has a vocabulary, sentence structure, and word order. Majority of the hearing community is not aware of PSL due to which there exists a huge communication gap between the two groups. Similarly, deaf persons are unable to read text written in English and Urdu. Hence, the provision of an effective translation model can support the cognitive capability of the deaf community to interpret natural language materials available on the Internet and in other useful resources. This research involves exploiting natural language processing (NLP) techniques to support the deaf community by proposing a novel machine translation model that translates English sentences into equivalent Pakistan Sign Language (PSL). Though a large number of machine translation systems have been successfully implemented for natural to natural language translations, natural to sign language machine translation is a relatively new area of research. State-of-the-art works in natural to sign language translation are mostly domain specific and suffer from low accuracy scores. Major reasons are specialised language structures for sign languages, and lack of annotated corpora to facilitate development of more generalisable machine translation systems. To this end, a grammar-based machine translation model is proposed to translate sentences written in English language into equivalent PSL sentences. To the best of our knowledge, this is a first effort to translate any natural language to PSL using core NLP techniques. The proposed approach involves a structured process to investigate the linguistic structure of PSL and formulate the grammatical structure of PSL sentences. These rules are then formalised into a context-free grammar, which, in turn, can be efficiently implemented as a parsing module for translation and validation of target PSL sentences. The whole concept is implemented as a software system, comprising the NLP pipeline and an external service to render the avatar-based video of translated words, in order to compensate the cognitive hearing deficit of deaf people. The accuracy of the proposed translation model has been evaluated manually and automatically. Quantitative results reveal a very promising Bilingual Evaluation Understudy (BLEU) score of 0.78. Subjective evaluations demonstrate that the system can compensate for the cognitive hearing deficit of end users through the system output expressed as a readily interpretable avatar. Comparative analysis shows that our proposed system works well for simple sentences but struggles to translate compound and compound complex sentences correctly, which warrants future ongoing research.},
  archive      = {J_CC},
  author       = {Khan, Nabeel Sabir and Abid, Adnan and Abid, Kamran},
  doi          = {10.1007/s12559-020-09731-7},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {748-765},
  shortjournal = {Cogn. Comput.},
  title        = {A novel natural language processing (NLP)–Based machine translation model for english to pakistan sign language translation},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An adaptive fuzzy predictive controller with hysteresis
compensation for piezoelectric actuators. <em>CC</em>, <em>12</em>(4),
736–747. (<a href="https://doi.org/10.1007/s12559-020-09722-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Piezoelectric actuators (PEAs) are the pivotal components of many nanopositioning systems because of their superiorities in bandwidth, mechanical force, and precision. Unfortunately, the intrinsic nonlinear property, hysteresis, makes it difficult to achieve the precise control of PEAs. Considering this drawback, diversified feedback control approaches have been studied in the literature. Inspired by the idea that the involvement of feedforward terms can upgrade the tracking performance, our previous conference paper proposed a novel feedforward–feedback control approach (model predictive control with hysteresis compensation). Following the previous work, an adaptive fuzzy predictive controller with hysteresis compensation is further studied in this paper. The major improvement of the proposed method is the employment of adaptive fuzzy model, by which the dynamic model of PEAs is able to adjust in real time, resulting in a better control performance. To validate the effectiveness of the proposed method, extensive experiments are conducted on a Physik Instrumente P-753.1CD piezoelectric nanopositioning stage. Comparisons with several existing control approaches are carried out, and the root mean square tracking error of the proposed method is reduced to 30% of that under the previously proposed neural network model–based predictive control, when tracking 100 Hz sinusoidal reference.},
  archive      = {J_CC},
  author       = {Wang, Ang and Cheng, Long and Yang, Chenguang and Hou, Zeng-Guang},
  doi          = {10.1007/s12559-020-09722-8},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {736-747},
  shortjournal = {Cogn. Comput.},
  title        = {An adaptive fuzzy predictive controller with hysteresis compensation for piezoelectric actuators},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Shaping emotions in negotiation: A nash bargaining solution.
<em>CC</em>, <em>12</em>(4), 720–735. (<a
href="https://doi.org/10.1007/s12559-020-09713-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling emotions in negotiations is an open challenge that attracted an increasing amount of attention from researchers. Bargainers look for achieving an agreement with the opposing parties and, at the same time, try to reach their own goals. This process consists of both bargaining and (game theory) problem solving. Game theory models seek to enlighten the rational negotiations between players, but these models lack the evidence of how emotional motives may influence individuals’ behavior. This paper suggests a model for shaping emotions in negotiation using Nash’s bargaining approach. We focus on the case where negotiation between players has motives of cooperating, considering eight emotions: anger, fear, joy, sadness, surprise, disgust, guilt, and disappointment. For representing the solution of the problem, we employ a homogeneous Markov game. The simplicity of the model relies on the fact that the emotions are represented by the states of the Markov chain. The relationship between the emotions is represented by a transition matrix that determines the probability of changing between the emotions (states) at any time. Because any emotion can be reached at any time with certain probability, the bargaining Markov game is ergodic. We represent naturally the emotional process of bargaining using a proximal method, which involves the bargaining Nash product for computing the equilibrium of the game. We show the convergence of the method to the emotional equilibrium point. The solution of the Nash bargaining game consists of cooperative emotional strategies, which are transformed in emotional probability distributions. Such emotional probability distributions are measured using an asymmetric distance function that determines the “emotional distance” between players in negotiations. Emotions are measured using an asymmetric distance function because they are different between players. We present a new approach for shaping emotions in negotiations employing Nash’s bargaining model. An application example shows the influence of expressing emotions in the relationship process, and those emotions are strategically selected to gain a benefit in negotiations. We show that the magnitude and direction of emotional distance matter and that feelings have an asymmetric effect on the negotiation process.},
  archive      = {J_CC},
  author       = {Clempner, Julio B.},
  doi          = {10.1007/s12559-020-09713-9},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {720-735},
  shortjournal = {Cogn. Comput.},
  title        = {Shaping emotions in negotiation: A nash bargaining solution},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Editor’s note: Cognitive computation and COVID-19.
<em>CC</em>, <em>12</em>(4), 719. (<a
href="https://doi.org/10.1007/s12559-020-09726-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CC},
  doi          = {10.1007/s12559-020-09726-4},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {719},
  shortjournal = {Cogn. Comput.},
  title        = {Editor’s note: Cognitive computation and COVID-19},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel group decision-making method based on linguistic
neutrosophic maclaurin symmetric mean (revision IV). <em>CC</em>,
<em>12</em>(3), 699–717. (<a
href="https://doi.org/10.1007/s12559-019-09709-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Linguistic neutrosophic number (LNN) is a specific form of neutrosophic number whose elements are expressed by linguistic terms. Maclaurin symmetric mean (MSM) operator is one of the basic collection operators in the modern knowledge fusion theory. Its most important feature is to consider the interrelationships among multiple input arguments. Multiple attribute group decision-making (MAGDM) with linguistic neutrosophic information is considered. First, we present some basic concepts, then we combine the MSM operator with linguistic neutrosophic environment and develop a sequence of linguistic neutrosophic MSM operators which are the linguistic neutrosophic Maclaurin symmetric mean (LNMSM) operator, the weighted linguistic neutrosophic Maclaurin symmetric mean (WLNMSM) operator, linguistic neutrosophic dual Maclaurin symmetric mean (LNDMSM) operator, and the weighted linguistic neutrosophic dual Maclaurin symmetric mean (WLNDMSM) operator. We look into some features of them such as monotonicity, boundedness, and idempotency and then discuss some special situations of these operators. A new idea based on the WLNMSM operator is proposed to solve an MAGDM problem where evaluation information is composed of LNNs. It is worth mentioning that the weight information of the decision-makers (DMs) and the attributes are completely unknown. In conclusion, a comparison analysis is performed with the existing methods. The developed method is based on both the WLNMSM operator which considers the interrelationships among any number of input arguments and LNNs which is a combination of the neutrosophic numbers, linguistic variables. At the same time, it also has the advantages of mentioned components. So, it enables preventing the loss or distortion of the original decision information in the decision-making process.},
  archive      = {J_CC},
  author       = {Şahin, Rıdvan and Küçük, Gökçe Dilek},
  doi          = {10.1007/s12559-019-09709-0},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {699-717},
  shortjournal = {Cogn. Comput.},
  title        = {A novel group decision-making method based on linguistic neutrosophic maclaurin symmetric mean (Revision IV)},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Generalized geometric aggregation operators based on t-norm
operations for complex intuitionistic fuzzy sets and their application
to decision-making. <em>CC</em>, <em>12</em>(3), 679–698. (<a
href="https://doi.org/10.1007/s12559-019-09678-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex intuitionistic fuzzy set (CIFS) is a special intuitionistic fuzzy set where the membership and non-membership degrees are expressed by a complex-valued membership degree and can more easily describe the vagueness and uncertainty in the real world. Archimedean t-conorm and t-norm (ATT), as an important class of the t-norm (TN) and t-conorm (TC), have greater flexibility in the information fusion process. In this paper, we extend the ATT to CIFSs and present some generalized geometric aggregation operators, which can be used to handle the multiple criteria decision-making (MCDM) problems. For it, we firstly define some new operational laws of the CIFSs based on ATT, then some weighted geometric aggregation operators based on proposed operations are proposed. Further, some desirable properties and special cases of them are studied. Finally, a decision-making approach is developed for the MCDM problem with complex intuitionistic fuzzy information. A practical example is given to show the availability and advantages of the proposed method by comparison with some existing methods. The proposed aggregation operators are more generalized than the existing ones to utilize the uncertain and imprecise information. Several existing operators are considered as special cases of the proposed one. Finally, the proposed method will offer various choices to the decision-maker to access the finest alternatives.},
  archive      = {J_CC},
  author       = {Garg, Harish and Rani, Dimple},
  doi          = {10.1007/s12559-019-09678-4},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {679-698},
  shortjournal = {Cogn. Comput.},
  title        = {Generalized geometric aggregation operators based on T-norm operations for complex intuitionistic fuzzy sets and their application to decision-making},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A cognitively inspired knowledge-based decision-making
methodology employing intuitionistic fuzzy sets. <em>CC</em>,
<em>12</em>(3), 667–678. (<a
href="https://doi.org/10.1007/s12559-019-09702-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The differentiation procedure of intuitionistic fuzzy sets (IFSs) is very important in multiple criteria decision-making (MCDM). The aim here is to introduce a fruitful class of knowledge measures related to the information provided in terms of IFSs. We present a class of knowledge measures of IFSs that are based on the two notions: the fuzziness and the intuitionism of an IFS. An experimental problem is employed to illustrate the weight determination method based on the proposed knowledge measures.},
  archive      = {J_CC},
  author       = {Farhadinia, Bahram},
  doi          = {10.1007/s12559-019-09702-7},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {667-678},
  shortjournal = {Cogn. Comput.},
  title        = {A cognitively inspired knowledge-based decision-making methodology employing intuitionistic fuzzy sets},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A broad learning system with ensemble and classification
methods for multi-step-ahead wind speed prediction. <em>CC</em>,
<em>12</em>(3), 654–666. (<a
href="https://doi.org/10.1007/s12559-019-09698-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short-term wind speed prediction plays a significant role in the management of large-scale wind power plants. However, wind speed prediction is extremely complex and difficult due to the volatility and non-linearity of wind. For this purpose, a broad learning system (BLS) with ensemble and classification named BLS-EC is proposed to predict multi-step-ahead wind speed. The proposed method is based on a new neural network termed the BLS, which could work out the complex non-linear relation by learning model while ensuring the computational efficiency. To overcome the randomness and instability of a single BLS, this paper proposes the BLS ensemble method to improve the generalization and stability of the network. In order to improve the accuracy of prediction, a method called classification-guided regression is proposed to distinguish different variation patterns of initial predicted wind speed. According to the classification result, different pattern sequences are re-predicted to obtain the final prediction result. Applying this thinking and method into research of three real-time wind speed datasets which were taken from Sotavento Galicia SA (SG), Alberta (ALB), and Newfoundland (NFL), the validity and practical value of this method can be demonstrated. Results obtained clearly show that BLS is better than existing methods ARIMA and RBF. Moreover, the BLS-EC method improved generalization performance and the predicting precision of a single BLS. In this study, the BLS-EC was proposed and successfully applied to wind speed prediction.},
  archive      = {J_CC},
  author       = {Zhu, Lingzi and Lian, Cheng and Zeng, Zhigang and Su, Yixin},
  doi          = {10.1007/s12559-019-09698-0},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {654-666},
  shortjournal = {Cogn. Comput.},
  title        = {A broad learning system with ensemble and classification methods for multi-step-ahead wind speed prediction},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Knowledge fusion via joint tensor and matrix factorization.
<em>CC</em>, <em>12</em>(3), 642–653. (<a
href="https://doi.org/10.1007/s12559-019-09686-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the task of knowledge fusion, an important aspect of cognitive intelligence, with the goal of combining part-of knowledge drawn from different sources. For this, entities and relations are cast into matrix-based representations. Unlike previous work on relation prediction, we consider the challenging setting of graphs with large amounts of completely separate connected components and no overlap between the training and test set entities. In order to address these challenges, we propose a novel cognitively inspired factorization method that jointly factorizes a subject–predicate–object tensor via RESCAL and a similarity matrix via matrix factorization. Our experimental results show that our method significantly outperforms several strong baseline models, including RESCAL and several TransE-style models. The proposed joint factorization of a subject–predicate–object tensor while applying matrix factorization to a similarity matrix obtains substantially higher average accuracy rates than previous approaches. This shows that it can successfully address the challenge of knowledge fusion of disconnected data.},
  archive      = {J_CC},
  author       = {Hao, Zengguang and Wang, Yafang and Liu, Zining and de Melo, Gerard and Xu, Zenglin},
  doi          = {10.1007/s12559-019-09686-4},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {642-653},
  shortjournal = {Cogn. Comput.},
  title        = {Knowledge fusion via joint tensor and matrix factorization},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). D-WASPAS: Addressing social cognition in uncertain
decision-making with an application to a sustainable project portfolio
problem. <em>CC</em>, <em>12</em>(3), 619–641. (<a
href="https://doi.org/10.1007/s12559-019-09679-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision-making is an interdisciplinary area that has roots in mathematics, economics, and social science. Multiple-criteria group decision-making (MCGDM) is one of the most applicable areas of decision-making. Social cognition is involved in group decision-making. Therefore, it is necessary to address how decision makers (DMs) process and apply judgments and information during the process. In recent years, many approaches have been applied to MCGDM. As an important aspect of this process, uncertainty has led to the application of fuzzy sets. However, utilizing various decision-making approaches can result in different results and confusion among DMs. Moreover, using classic fuzzy sets and expressing degrees of belonging by crisp values has proven to be inadequate for uncertain decision-making environments. This paper presents a novel MCGDM approach, double-weighted aggregated sum product assessment (D-WASPAS), under interval-valued Pythagorean fuzzy (IVPF) uncertainty. The proposed approach applies knowledge measures to address the objective weights of criteria. Then, subjective and objective weights of criteria are aggregated to create a more appropriate weight. This approach considers three decision-making methods. In the first, an IVPF-ARAS (additive ratio assessment) method is extended to rank the alternatives. In the second, an IVPF-EDAS (evaluation based on distance from average solution) method is developed to rank the alternatives. In the third, a novel IVPF-COADAP (complex adequate appraisal) method is utilized for a third ranking. To aggregate the results, two steps are carried out using the WASPAS method. First, the results of the ranking approaches are aggregated. This process starts with computing the objective weights of the ranking approaches and aggregating the outcome with the subjective weights of the approaches. Then, the WASPAS method is applied to aggregate the obtained rankings and obtain a set of rankings for each DM. The second aggregation is utilized to aggregate the results for the DMs and reach a final set of rankings. Similarly, the subjective and objective weights of the DMs are applied in the WASPAS to aggregate the results. It should be noted that since the WASPAS method is utilized twice to aggregate the results, this approach is called D-WASPAS. A case study of the application of the proposed method shows that it is applicable to many multiple-criteria analysis and decision-making processes. Moreover, the results are more reliable because various decision-making methods are taken into consideration, and it is a last-aggregation process. Double-weighted aggregated sum product assessment offers a novel decision-making framework that is applicable in real-world decision-making situations. The proposed method is based on interval-valued Pythagorean fuzzy sets (IVPFSs), which would be especially applicable to uncertain situations. Also, it would enhance calculations of the process by offering more flexibility in dealing with uncertainty. Consequently, introducing this new decision-making framework and applying extended fuzzy sets would make the proposed method more widely applicable. The last-aggregation nature of this method avoids loss of cognitive information and assigning weights to the DMs, and the different ranking methods address the social cognition that leads to the judgments expressed and the final decisions.},
  archive      = {J_CC},
  author       = {Mohagheghi, Vahid and Mousavi, S. Meysam},
  doi          = {10.1007/s12559-019-09679-3},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {619-641},
  shortjournal = {Cogn. Comput.},
  title        = {D-WASPAS: Addressing social cognition in uncertain decision-making with an application to a sustainable project portfolio problem},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel approach for EEG electrode selection in automated
emotion recognition based on lagged poincare’s indices and sLORETA.
<em>CC</em>, <em>12</em>(3), 602–618. (<a
href="https://doi.org/10.1007/s12559-019-09699-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of this paper was to develop a novel method to track emotional processing in different brain regions using electroencephalogram (EEG) analysis. In addition, the role of EEG electrode selection and feature reduction in emotion recognition was investigated. To this end, the multi-channel EEG signals of 32 subjects available in DEAP dataset were studied. The best EEG electrode positions were selected based on lagged Poincare’s measures of EEG recordings and a source localization method (sLORETA). Three feature reduction algorithms, including random subset feature selection (RSFS), sequential floating forward selection (SFFS), and sequential forward selection (SFS) in combination with support vector machine (SVM), were evaluated to classify high/low valence and high/low arousal. The results showed that RSFS outperformed the other feature selection approaches. In addition, the positive impact of the EEG electrode selection on the classification performances has been confirmed. The most active EEG electrodes were FP1, C3, Cp1, P3, and Pz. Adopting RSFS and selected EEG electrodes, the mean subject-independent accuracies of 73.89 and 74.62% and subject-dependent accuracies of 98.97 and 98.94% were obtained for valence and arousal dimensions, respectively.},
  archive      = {J_CC},
  author       = {Goshvarpour, Ateke and Goshvarpour, Atefeh},
  doi          = {10.1007/s12559-019-09699-z},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {602-618},
  shortjournal = {Cogn. Comput.},
  title        = {A novel approach for EEG electrode selection in automated emotion recognition based on lagged poincare’s indices and sLORETA},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel real-time, lightweight chaotic-encryption scheme for
next-generation audio-visual hearing aids. <em>CC</em>, <em>12</em>(3),
589–601. (<a href="https://doi.org/10.1007/s12559-019-09653-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Next-generation audio-visual (AV) hearing aids stand as a major enabler to realize more intelligible audio. However, high data rate, low latency, low computational complexity, and privacy are some of the major bottlenecks to the successful deployment of such advanced hearing aids. To address these challenges, we propose an integration of 5G Cloud-Radio Access Network (C-RAN), Internet of Things (IoT), and strong privacy algorithms to fully benefit from the possibilities these technologies have to offer. Existing audio-only hearing aids are known to perform poorly in noisy situations where overwhelming noise is present. Current devices make the signal more audible but remain deficient in restoring intelligibility. Thus, there is a need for hearing aids that can selectively amplify the attended talker or filter out acoustic clutter. The proposed 5G IoT-enabled AV hearing-aid framework transmits the encrypted compressed AV information and receives encrypted enhanced reconstructed speech in real time to address cybersecurity attacks such as location privacy and eavesdropping. For security implementation, a real-time lightweight AV encryption is proposed, based on a piece-wise linear chaotic map (PWLSM), Chebyshev map, and a secure hash and S-Box algorithm. For speech enhancement, the received secure AV (including lip-reading) information in the cloud is used to filter noisy audio using both deep learning and analytical acoustic modelling. To offload the computational complexity and real-time optimization issues, the framework runs deep learning and big data optimization processes in the background, on the cloud. The effectiveness and security of the proposed 5G-IoT-enabled AV hearing-aid framework are extensively evaluated using widely known security metrics. Our newly reported, deep learning-driven lip-reading approach for speech enhancement is evaluated under four different dynamic real-world scenarios (cafe, street, public transport, pedestrian area) using benchmark Grid and ChiME3 corpora. Comparative critical analysis in terms of both speech enhancement and AV encryption demonstrates the potential of the envisioned technology to deliver high-quality speech reconstruction and secure mobile AV hearing aid communication. We believe our proposed 5G IoT enabled AV hearing aid framework is an effective and feasible solution and represents a step change in the development of next-generation multimodal digital hearing aids. The ongoing and future work includes more extensive evaluation and comparison with benchmark lightweight encryption algorithms and hardware prototype implementation.},
  archive      = {J_CC},
  author       = {Adeel, Ahsan and Ahmad, Jawad and Larijani, Hadi and Hussain, Amir},
  doi          = {10.1007/s12559-019-09653-z},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {589-601},
  shortjournal = {Cogn. Comput.},
  title        = {A novel real-time, lightweight chaotic-encryption scheme for next-generation audio-visual hearing aids},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Merging similar neurons for deep networks compression.
<em>CC</em>, <em>12</em>(3), 577–588. (<a
href="https://doi.org/10.1007/s12559-019-09703-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have achieved outstanding progress in many fields, such as computer vision, speech recognition and natural language processing. However, large deep neural networks often need huge storage space and long training time, making them difficult to apply to resource restricted devices. In this paper, we propose a method for compressing the structure of deep neural networks. Specifically, we apply clustering analysis to find similar neurons in each layer of the original network, and merge them and the corresponding connections. After the compression of the network, the number of parameters in the deep neural network is significantly reduced, and the required storage space and computational time is greatly reduced as well. We test our method on deep belief network (DBN) and two convolutional neural networks. The experimental results demonstrate that our proposed method can greatly reduce the number of parameters of the deep networks, while keeping their classification accuracy. Especially, on the CIFAR-10 dataset, we have compressed VGGNet with compression ratio 92.96%, and the final model after fine-tuning obtains even higher accuracy than the original model.},
  archive      = {J_CC},
  author       = {Zhong, Guoqiang and Liu, Wenxue and Yao, Hui and Li, Tao and Sun, Jinxuan and Liu, Xiang},
  doi          = {10.1007/s12559-019-09703-6},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {577-588},
  shortjournal = {Cogn. Comput.},
  title        = {Merging similar neurons for deep networks compression},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Quantum aspects of high dimensional conceptual space: A
model for achieving consciousness. <em>CC</em>, <em>12</em>(3), 563–576.
(<a href="https://doi.org/10.1007/s12559-020-09712-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cognitive frameworks best represent cognitive information and knowledge. Several classical probability theory (CPT)-based cognitive frameworks were proposed in the literature. Recently, CPT has failed in explaining certain cognitive processes while quantum theories were successful in explaining the same. In this work, we integrate two cognitive frameworks namely conceptual spaces and 3-way formal concept analysis (3WFCA) to propose a high dimensional conceptual space (HDCS). Our new insights into the analysis of this proposal reveal its quantum characteristics. Among different cognitive processes that can be modelled, our interest is on phenomenal consciousness. Accordingly, we have proposed a formal method to achieve consciousness. We have also proposed an algorithm for the conceptual scaling of a cognitive scenario. HDCS represents a cognitive state using quality dimensions, attributes and their relations. Subsequently, the proposed model makes novel use of agent-environment interaction paradigm for guiding the interaction of HDCS with conceptually scaled cognitive scenario. Cognitive-state representation in HDCS is analogous to quantum state representation in a N-qubit system. Cognitive states are learnt through the parallel accumulation of evidences against all the attributes of multiple dimensions. The interaction between the HDCS and the scenario facilitates the identification and removal of uncertainties. The identified uncertainty coupled with its resolution time resembles Heisenberg-like uncertainty. The analogous of quantum two-slit self-interference would be comparison of evidence accumulation in HDCS with the preceding version of itself. Consequently, this research reveals that modelling consciousness requires a high dimensional space rather than set theoretic structures and support from quantum theories.},
  archive      = {J_CC},
  author       = {Ishwarya, M. S. and Kumar, Ch. Aswani},
  doi          = {10.1007/s12559-020-09712-w},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {563-576},
  shortjournal = {Cogn. Comput.},
  title        = {Quantum aspects of high dimensional conceptual space: A model for achieving consciousness},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An improved deep polynomial network algorithm for
transcranial sonography–based diagnosis of parkinson’s disease.
<em>CC</em>, <em>12</em>(3), 553–562. (<a
href="https://doi.org/10.1007/s12559-019-09691-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transcranial sonography (TCS) is a valid neuroimaging tool for the diagnosis of Parkinson’s disease (PD). The TCS-based computer-aided diagnosis (CAD) has attracted increasing attention in recent years, in which feature representation and pattern classification are two critical issues. Deep polynomial network (DPN) is a newly proposed deep learning algorithm that has shown its advantage in learning effective feature representation for samples with a small size. In this work, an improved DPN algorithm with enhanced performance on both feature representation and classification is proposed. First, the empirical kernel mapping (EKM) algorithm is embedded into DPN (EKM-DPN) to improve its feature representation. Second, the network pruning strategy is utilized in the EKM-DPN (named P-EKM-DPN). It not only produces robust feature representation, but also addresses the overfitting issues for the subsequent classifiers to some extent. Lastly, the generalization ability is further enhanced by applying the Dropout approach to P-EKM-DPN (D-P-EKM-DPN). The proposed D-P-EKM-DPN algorithm has been evaluated on a TCS dataset with 153 samples. The experimental results indicate that D-P-EKM-DPN outperforms all the compared algorithms and achieves the best classification accuracy, sensitivity, and specificity of 86.95 ± 3.15%, 85.77 ± 7.87%, and 87.16 ± 6.50%, respectively. The proposed D-P-EKN-DPN algorithm has a great potential in TCS-based CAD for PD due to its excellent performance.},
  archive      = {J_CC},
  author       = {Shen, Lu and Shi, Jun and Dong, Yun and Ying, Shihui and Peng, Yaxin and Chen, Lu and Zhang, Qi and An, Hedi and Zhang, Yingchun},
  doi          = {10.1007/s12559-019-09691-7},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {553-562},
  shortjournal = {Cogn. Comput.},
  title        = {An improved deep polynomial network algorithm for transcranial Sonography–Based diagnosis of parkinson’s disease},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A template-based sequential algorithm for online clustering
of spikes in extracellular recordings. <em>CC</em>, <em>12</em>(3),
542–552. (<a href="https://doi.org/10.1007/s12559-020-09711-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to discriminate different spikes in an extracellular recording, a multitude of successful spike sorting algorithms has been proposed up to now. However, new implantable neuroprosthetics containing a spike sorting block necessitate the use of a real-time and a preferably unsupervised method. The aim of this article is to propose a new unsupervised spike sorting algorithm which could work in real-time. As opposed to most traditional frameworks that consist of separate noise cancelation and feature extraction steps, here a sequential algorithm is proposed which makes use of noise statistics and uses data samples as features. For each detected spike, the difference between the detected spike and all the previously detected spike templates are calculated. If the output is a signal similar to noise, this indicates that the new spike is fired from a previously observed neuron. Two varieties of the general method are illustrated and a set of clustering indices which determine an optimal clustering is used to set the parameters. Clustering indices surpassed 0.90 (out of 1) for synthetic data with modest noise level. Experiments with our recorded signals showed satisfactory results in clustering and template identification. Spike sorting is an active field. A deficiency in conventional spike sorting algorithms is that most of them are either supervised or offline. Here, we present an online unsupervised algorithm which could be developed as a solution for current neuroprosthetics. Since the present method clustered real spikes data appropriately without a need for training data, the methodology could be adapted to be used in implantable devices.},
  archive      = {J_CC},
  author       = {Yeganegi, Hamed and Salami, Parvaneh and Daliri, Mohammad Reza},
  doi          = {10.1007/s12559-020-09711-x},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {542-552},
  shortjournal = {Cogn. Comput.},
  title        = {A template-based sequential algorithm for online clustering of spikes in extracellular recordings},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Indoor topological localization based on a novel deep
learning technique. <em>CC</em>, <em>12</em>(3), 528–541. (<a
href="https://doi.org/10.1007/s12559-019-09693-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Millions of people in the world suffer from vision impairment or vision loss. Traditionally, they rely on guide sticks or dogs to move around and avoid potential obstacles. However, both guide sticks and dogs are passive. They are unable to provide conceptual knowledge or semantic contents of an environment. To address this issue, this paper presents a vision-based cognitive system to support the independence of visually impaired people. More specifically, a 3D indoor semantic map is firstly constructed with a hand-held RGB-D sensor. The constructed map is then deployed for indoor topological localization. Convolutional neural networks are used for both semantic information extraction and location inference. Semantic information is used to further verify localization results and eliminate errors. The topological localization performance can be effectively improved despite significant appearance changes within an environment. Experiments have been conducted to demonstrate that the proposed method can increase both localization accuracy and recall rates. The proposed system can be potentially deployed by visually impaired people to move around safely and have independent life.},
  archive      = {J_CC},
  author       = {Liu, Qiang and Li, Ruihao and Hu, Huosheng and Gu, Dongbing},
  doi          = {10.1007/s12559-019-09693-5},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {528-541},
  shortjournal = {Cogn. Comput.},
  title        = {Indoor topological localization based on a novel deep learning technique},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Functional brain network classification for alzheimer’s
disease detection with deep features and extreme learning machine.
<em>CC</em>, <em>12</em>(3), 513–527. (<a
href="https://doi.org/10.1007/s12559-019-09688-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The human brain can be inherently modeled as a brain network, where nodes denote billions of neurons and edges denote massive connections between neurons. Analysis on functional brain networks provides powerful abilities to discover potential mechanisms of human brain, and to aid brain disease detection, such as AD (Alzheimer’s disease). Effective discrimination of patients of AD and MCI (mild cognitive impairment) from NC (normal control) is important for the early diagnosis of AD. Therefore, this paper explores the problem of brain network classification for AD detection. Two deep learning methods of functional brain network classification are designed. The convolutional learning method learns the deep regional-connectivity features, while the recurrent learning method learns the deep adjacent positional features. The ELM (extreme learning machine)-boosted structure is also implemented to further improve the learning ability. Extensive experiments are conducted to evaluate and compare the AUC (area under curve), accuracy, recall, and training time of the proposed methods on a real-world dataset. Results indicate that (1) the proposed methods which learn deep features directly from brain networks outperform shallow learning methods and (2) models with the ELM-boosted structure achieve a higher performance. This paper explores the brain networks learning with deep features and ELM. The results demonstrate that the proposed methods provide a satisfactory learning ability in the application of AD detection.},
  archive      = {J_CC},
  author       = {Bi, Xin and Zhao, Xiangguo and Huang, Hong and Chen, Deyang and Ma, Yuliang},
  doi          = {10.1007/s12559-019-09688-2},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {513-527},
  shortjournal = {Cogn. Comput.},
  title        = {Functional brain network classification for alzheimer’s disease detection with deep features and extreme learning machine},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modeling marked temporal point process using multi-relation
structure RNN. <em>CC</em>, <em>12</em>(3), 499–512. (<a
href="https://doi.org/10.1007/s12559-019-09690-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event sequences with marker and timing information are available in a wide range of domains, from machine log in automatic train supervision systems to information cascades in social networks. Given the historical event sequences, predicting what event will happen next and when it will happen can benefit many useful applications, such as maintenance service schedule for mass rapid transit trains and product advertising in social networks. Temporal point process (TPP) is one effective solution to solve the next event prediction problem due to its capability of capturing the temporal dependence among events. The recent recurrent temporal point process (RTPP) methods exploited recurrent neural network (RNN) to get rid of the parametric form assumption in the density functions of TPP. However, most existing RTPP methods focus only on the temporal dependence among events. In this work, we design a novel multi-relation structure RNN model with a hierarchical attention mechanism to capture not only the conventional temporal dependencies but also the explicit multi-relation topology dependencies. We then propose an RTPP algorithm whose density function conditioned on the event sequence embedding learned from our RNN model for cognitively predict the next event marker and time. The experiments show that our proposed MRS-RMTPP outperforms the state-of-the-art baselines in terms of both event marker prediction and event time prediction on three real-world datasets. The capability of capturing both ontology relation structure and temporal structure in the event sequences is of great importance for the next event marker and time prediction.},
  archive      = {J_CC},
  author       = {Cai, Hongyun and Nguyen, Thanh Tung and Li, Yan and Zheng, Vincent W. and Chen, Binbin and Cong, Gao and Li, Xiaoli},
  doi          = {10.1007/s12559-019-09690-8},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {499-512},
  shortjournal = {Cogn. Comput.},
  title        = {Modeling marked temporal point process using multi-relation structure RNN},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Perceptions or actions? Grounding how agents interact within
a software architecture for cognitive robotics. <em>CC</em>,
<em>12</em>(2), 479–497. (<a
href="https://doi.org/10.1007/s12559-019-09685-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the aims of cognitive robotics is to endow robots with the ability to plan solutions for complex goals and then to enact those plans. Additionally, robots should react properly upon encountering unexpected changes in their environment that are not part of their planned course of actions. This requires a close coupling between deliberative and reactive control flows. From the perspective of robotics, this coupling generally entails a tightly integrated perceptuomotor system, which is then loosely connected to some specific form of deliberative system such as a planner. From the high-level perspective of automated planning, the emphasis is on a highly functional system that, taken to its extreme, calls perceptual and motor modules as services when required. This paper proposes to join the perceptual and acting perspectives via a unique representation where the responses of all software modules in the architecture are generalized using the same set of tokens. The proposed representation integrates symbolic and metric information. The proposed approach has been successfully tested in CLARC, a robot that performs Comprehensive Geriatric Assessments of elderly patients. The robot was favourably appraised in a survey conducted to assess its behaviour. For instance, using a 5-point Likert scale from 1 (strongly disagree) to 5 (strongly agree), patients reported an average of 4.86 when asked if they felt confident during the interaction with the robot. This paper proposes a mechanism for bringing the perceptual and acting perspectives closer within a distributed robotics architecture. The idea is built on top of the blackboard model and scene graphs. The modules in our proposal communicate using a short-term memory, writing the perceptual information they need to share with other agents and accessing the information they need for determining the next goals to address.},
  archive      = {J_CC},
  author       = {Marfil, R. and Romero-Garces, A. and Bandera, J. P. and Manso, L. J. and Calderita, L. V. and Bustos, P. and Bandera, A. and Garcia-Polo, J. and Fernandez, F. and Voilmy, D.},
  doi          = {10.1007/s12559-019-09685-5},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {479-497},
  shortjournal = {Cogn. Comput.},
  title        = {Perceptions or actions? grounding how agents interact within a software architecture for cognitive robotics},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Doctor recommendation based on an intuitionistic normal
cloud model considering patient preferences. <em>CC</em>,
<em>12</em>(2), 460–478. (<a
href="https://doi.org/10.1007/s12559-018-9616-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chinese medical websites help patients search for satisfactory doctors via the Internet regardless of time and location. Existing website systems recommend the same doctors for all patients using a global ranking but disregard patient preferences and online reviews. Additionally, these models do not consider the effects of interdependencies among criteria when making recommendations. We propose a systematic decision support model to improve such recommendations using intuitionistic fuzzy sets (IFSs) with the Bonferroni mean (BM) to address interdependencies. Our system accommodates patient preferences using multiple intuitionistic normal clouds (INCs). A case study using production data from haodf.com , the largest such website, shows that our model improves the diversity and coverage of doctor recommendations while considering patient preferences when compared to the existing haodf.com approach. This pattern continued with testing using data from several other Chinese healthcare sites. Our proposal is thus both applicable and readily implemented to improve the recommendations of these websites.},
  archive      = {J_CC},
  author       = {Yang, Yan and Hu, Junhua and Liu, Yongmei and Chen, Xiaohong},
  doi          = {10.1007/s12559-018-9616-3},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {460-478},
  shortjournal = {Cogn. Comput.},
  title        = {Doctor recommendation based on an intuitionistic normal cloud model considering patient preferences},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Creating, interpreting and rating harmonic colour palettes
using a cognitively inspired model. <em>CC</em>, <em>12</em>(2),
442–459. (<a href="https://doi.org/10.1007/s12559-018-9589-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a cognitively inspired qualitative theory, $QCharm$, which defines five operators for colour combination based on the qualitative colour descriptor (QCD) and applies these operators to recommend palettes of harmonic colours. Machine learning techniques have been applied to learn the QCD colour coordinates in Kobayashi’s colour space, in order to assign the resulting $QCharm$ harmonic-colour palettes to cognitive keywords representing a feeling or a lifestyle. Furthermore, a regression model has been implemented to learn users’ preferences based on the COLOURlovers dataset. The resulting model is used as an additional criterion for recommendation. The resulting cognitive system can recommend (i) colour palettes using keywords on feelings/lifestyle, and (ii) colour palettes using the learnt user’s preference model. As an example of the practical applicability of the model, a web application, the $QCharm$ tool, has been implemented to provide recommendations to users in an interactive way. The $QCharm$ tool can also extract colour palettes from digital images and assign a cognitive adjective to describe colour combinations, to serve as a starting point for the design process.},
  archive      = {J_CC},
  author       = {Museros, Lledó and Sanz, Ismael and Falomir, Zoe and Gonzalez-Abril, Luis},
  doi          = {10.1007/s12559-018-9589-2},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {442-459},
  shortjournal = {Cogn. Comput.},
  title        = {Creating, interpreting and rating harmonic colour palettes using a cognitively inspired model},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A cognitively inspired clustering approach for
critique-based recommenders. <em>CC</em>, <em>12</em>(2), 428–441. (<a
href="https://doi.org/10.1007/s12559-018-9586-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of recommender systems is to support humans in the purchasing decision-making process. Decision-making is a human activity based on cognitive information. In the field of recommender systems, critiquing has been widely applied as an effective approach for obtaining users’ feedback on recommended products. In the last decade, there have been a large number of proposals in the field of critique-based recommenders. These proposals mainly differ in two aspects: in the source of data and in how it is mined to provide the user with recommendations. To date, no approach has mined data using an adaptive clustering algorithm to increase the recommender’s performance. In this paper, we describe how we added a clustering process to a critique-based recommender, thereby adapting the recommendation process and how we defined a cognitive user preference model based on the preferences (i.e., defined by critiques) received by the user. We have developed several proposals based on clustering, whose acronyms are MCP, CUM, CUM-I, and HGR-CUM-I. We compare our proposals with two well-known state-of-the-art approaches: incremental critiquing (IC) and history-guided recommendation (HGR). The results of our experiments showed that using clustering in a critique-based recommender leads to an improvement in their recommendation efficiency, since all the proposals outperform the baseline IC algorithm. Moreover, the performance of the best proposal, HGR-CUM-I, is significantly superior to both the IC and HGR algorithms. Our results indicate that introducing clustering into the critique-based recommender is an appealing option since it enhances overall efficiency, especially with a large data set.},
  archive      = {J_CC},
  author       = {Contreras, David and Salamó, Maria},
  doi          = {10.1007/s12559-018-9586-5},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {428-441},
  shortjournal = {Cogn. Comput.},
  title        = {A cognitively inspired clustering approach for critique-based recommenders},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bridging cognitive models and recommender systems.
<em>CC</em>, <em>12</em>(2), 426–427. (<a
href="https://doi.org/10.1007/s12559-020-09719-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CC},
  author       = {Angulo, Cecilio and Falomir, Ing. Zoe and Anguita, Davide and Agell, Núria and Cambria, Erik},
  doi          = {10.1007/s12559-020-09719-3},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {426-427},
  shortjournal = {Cogn. Comput.},
  title        = {Bridging cognitive models and recommender systems},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). AEKOC+: Kernel ridge regression-based auto-encoder for
one-class classification using privileged information. <em>CC</em>,
<em>12</em>(2), 412–425. (<a
href="https://doi.org/10.1007/s12559-019-09705-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, non-iterative learning approaches for kernel have received quite an attention by researchers and kernel ridge regression (KRR) approach is one of them. Recently, KRR-based Auto-Encoder is developed for the one-class classification (OCC) task and named as AEKOC. OCC is generally used for outlier or novelty detection. The brain can detect outlier just by learning from only normal samples. Similarly, OCC also uses only normal samples to train the model, and trained model can be used for outlier detection. In this paper, AEKOC is enabled to utilize privileged information, which is generally ignored by AEKOC or any traditional machine learning technique but usually present in human learning. For this purpose, we have combined learning using privileged information (LUPI) framework with AEKOC, and proposed a classifier, which is referred to as AEKOC+. Privileged information is only available during training but not during testing. Therefore, AEKOC is unable to utilize this information for building the model. However, AEKOC+ can efficiently handle the privileged information due to the inclusion of the LUPI framework with AEKOC. Experiments have been conducted on MNIST dataset and on various other datasets from UCI machine learning repository, which demonstrates the superiority of AEKOC+ over AEKOC. Our formulation shows that AEKOC does not utilize the privileged features in learning; however, formulation of AEKOC+ helps it in learning from the privileged features differently from other available features and improved generalization performance of AEKOC. Moreover, AEKOC+ also outperformed two LUPI framework–based one-class classifiers (i.e., OCSVM+ and SSVDD+).},
  archive      = {J_CC},
  author       = {Gautam, Chandan and Tiwari, Aruna and Tanveer, M.},
  doi          = {10.1007/s12559-019-09705-4},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {412-425},
  shortjournal = {Cogn. Comput.},
  title        = {AEKOC+: Kernel ridge regression-based auto-encoder for one-class classification using privileged information},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Detecting gas turbine combustor anomalies using
semi-supervised anomaly detection with deep representation learning.
<em>CC</em>, <em>12</em>(2), 398–411. (<a
href="https://doi.org/10.1007/s12559-019-09710-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL), regarded as a breakthrough machine learning technique, has proven to be effective for a variety of real-world applications. However, DL has not been actively applied to condition monitoring of industrial assets, such as gas turbine combustors. We propose a deep semi-supervised anomaly detection (deepSSAD) that has two key components: (1) using DL to learn representations or features from multivariate, time-series sensor measurements; and (2) using one-class classification to model normality in the learned feature space, thus performing anomaly detection. Both steps use normal data only; thus our anomaly detection falls into the semi-supervised anomaly detection category, which is advantageous for industrial asset condition monitoring where abnormal or faulty data is rare. Using the data collected from a real-world gas turbine combustion system, we demonstrate that our proposed approach achieved a good detection performance (AUC) of 0.9706 ± 0.0029. Furthermore, we compare the detection performance of the proposed approach against that of other different designs, including different features (i.e., the deep learned, handcrafted and PCA features) and different detection models (i.e., one-class ELM, one-class SVM, isolation forest, and Gaussian mixture model). The proposed approach significantly outperforms others. The proposed combustor anomaly detection approach is effective in detecting combustor anomalies or faults.},
  archive      = {J_CC},
  author       = {Yan, Weizhong},
  doi          = {10.1007/s12559-019-09710-7},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {398-411},
  shortjournal = {Cogn. Comput.},
  title        = {Detecting gas turbine combustor anomalies using semi-supervised anomaly detection with deep representation learning},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). How deep should be the depth of convolutional neural
networks: A backyard dog case study. <em>CC</em>, <em>12</em>(2),
388–397. (<a href="https://doi.org/10.1007/s12559-019-09667-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The work concerns the problem of reducing a pre-trained deep neuronal network to a smaller network, with just few layers, whilst retaining the network’s functionality on a given task. In this particular case study, we are focusing on the networks developed for the purposes of face recognition. The proposed approach is motivated by the observation that the aim to deliver the highest accuracy possible in the broadest range of operational conditions, which many deep neural networks models strive to achieve, may not necessarily be always needed, desired or even achievable due to the lack of data or technical constraints. In relation to the face recognition problem, we formulated an example of such a use case, the ‘backyard dog’ problem. The ‘backyard dog’, implemented by a lean network, should correctly identify members from a limited group of individuals, a ‘family’, and should distinguish between them. At the same time, the network must produce an alarm to an image of an individual who is not in a member of the family, i.e. a ‘stranger’. To produce such a lean network, we propose a network shallowing algorithm. The algorithm takes an existing deep learning model on its input and outputs a shallowed version of the model. The algorithm is non-iterative and is based on the advanced supervised principal component analysis. Performance of the algorithm is assessed in exhaustive numerical experiments. Our experiments revealed that in the above use case, the ‘backyard dog’ problem, the method is capable of drastically reducing the depth of deep learning neural networks, albeit at the cost of mild performance deterioration. In this work, we proposed a simple non-iterative method for shallowing down pre-trained deep convolutional networks. The method is generic in the sense that it applies to a broad class of feed-forward networks, and is based on the advanced supervise principal component analysis. The method enables generation of families of smaller-size shallower specialized networks tuned for specific operational conditions and tasks from a single larger and more universal legacy network.},
  archive      = {J_CC},
  author       = {Gorban, Alexander N. and Mirkes, Evgeny M. and Tyukin, Ivan Y.},
  doi          = {10.1007/s12559-019-09667-7},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {388-397},
  shortjournal = {Cogn. Comput.},
  title        = {How deep should be the depth of convolutional neural networks: A backyard dog case study},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel algorithm for online inexact string matching and its
FPGA implementation. <em>CC</em>, <em>12</em>(2), 369–387. (<a
href="https://doi.org/10.1007/s12559-019-09646-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Among the basic cognitive skills of the biological brain in humans and other mammals, a fundamental one is the ability to recognize inexact patterns in a sequence of objects or events. Accelerating inexact string matching procedures is of utmost importance when dealing with practical applications where huge amounts of data must be processed in real time, as usual in bioinformatics or cybersecurity. Inexact matching procedures can yield multiple shadow hits, which must be filtered, according to some criterion, to obtain a concise and meaningful list of occurrences. The filtering procedures are often computationally demanding and are performed offline in a post-processing phase. This paper introduces a novel algorithm for online approximate string matching (OASM) able to filter shadow hits on the fly, according to general purpose priority rules that greedily assign priorities to overlapping hits. A field-programmable gate array (FPGA) hardware implementation of OASM is proposed and compared with a serial software version. Even when implemented on entry-level FPGAs, the proposed procedure can reach a high degree of parallelism and superior performance in time compared to the software implementation, while keeping low the usage of logic elements. This makes the developed architecture very competitive in terms of both performance and cost of the overall computing system.},
  archive      = {J_CC},
  author       = {Cinti, Alessandro and Bianchi, Filippo Maria and Martino, Alessio and Rizzi, Antonello},
  doi          = {10.1007/s12559-019-09646-y},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {369-387},
  shortjournal = {Cogn. Comput.},
  title        = {A novel algorithm for online inexact string matching and its FPGA implementation},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Energy consumption forecasting for the nonferrous metallurgy
industry using hybrid support vector regression with an adaptive state
transition algorithm. <em>CC</em>, <em>12</em>(2), 357–368. (<a
href="https://doi.org/10.1007/s12559-019-09644-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The nonferrous metallurgy industry is a major energy consumer in China, and accurate energy consumption forecasting for the nonferrous metallurgy industry can help government policymakers with energy planning. For this purpose, a hybrid support vector regression (HSVR) with an adaptive state transition algorithm (ASTA) named ASTA-HSVR is proposed to forecast energy consumption in the nonferrous metallurgy industry. The proposed support vector regression (SVR) model consists of a linear weighting of 𝜖-SVR and ν-SVR. The ASTA was developed to optimize the parameters of the HSVR. Two cases of energy consumption from the nonferrous metallurgy industry in China are used to demonstrate the performance of the proposed method. The results indicate that the ASTA-HSVR method is superior to other methods. In this study, a hybrid support vector regression with an adaptive state transition algorithm (ASTA-HSVR) was developed and successfully applied to energy consumption forecasting for the nonferrous metallurgy industry. However, it should be noted that the outliers were not considered in this study. In the future, we expect to extend the ASTA-HSVR method to include energy consumption forecasting problems with outliers.},
  archive      = {J_CC},
  author       = {Huang, Zhaoke and Yang, Chunhua and Zhou, Xiaojun and Yang, Shengxiang},
  doi          = {10.1007/s12559-019-09644-0},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {357-368},
  shortjournal = {Cogn. Comput.},
  title        = {Energy consumption forecasting for the nonferrous metallurgy industry using hybrid support vector regression with an adaptive state transition algorithm},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Interpreting recurrent neural networks behaviour via
excitable network attractors. <em>CC</em>, <em>12</em>(2), 330–356. (<a
href="https://doi.org/10.1007/s12559-019-09634-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning provides fundamental tools both for scientific research and for the development of technologies with significant impact on society. It provides methods that facilitate the discovery of regularities in data and that give predictions without explicit knowledge of the rules governing a system. However, a price is paid for exploiting such flexibility: machine learning methods are typically black boxes where it is difficult to fully understand what the machine is doing or how it is operating. This poses constraints on the applicability and explainability of such methods. Our research aims to open the black box of recurrent neural networks, an important family of neural networks used for processing sequential data. We propose a novel methodology that provides a mechanistic interpretation of behaviour when solving a computational task. Our methodology uses mathematical constructs called excitable network attractors, which are invariant sets in phase space composed of stable attractors and excitable connections between them. As the behaviour of recurrent neural networks depends both on training and on inputs to the system, we introduce an algorithm to extract network attractors directly from the trajectory of a neural network while solving tasks. Simulations conducted on a controlled benchmark task confirm the relevance of these attractors for interpreting the behaviour of recurrent neural networks, at least for tasks that involve learning a finite number of stable states and transitions between them.},
  archive      = {J_CC},
  author       = {Ceni, Andrea and Ashwin, Peter and Livi, Lorenzo},
  doi          = {10.1007/s12559-019-09634-2},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {330-356},
  shortjournal = {Cogn. Comput.},
  title        = {Interpreting recurrent neural networks behaviour via excitable network attractors},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Non-iterative learning approaches and their applications.
<em>CC</em>, <em>12</em>(2), 327–329. (<a
href="https://doi.org/10.1007/s12559-020-09720-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CC},
  author       = {Bianchi, Filippo Maria and Suganthan, Ponnuthurai Nagaratnam},
  doi          = {10.1007/s12559-020-09720-w},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {327-329},
  shortjournal = {Cogn. Comput.},
  title        = {Non-iterative learning approaches and their applications},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new risk-based fuzzy cognitive model and its application
to decision-making. <em>CC</em>, <em>12</em>(1), 309–326. (<a
href="https://doi.org/10.1007/s12559-019-09701-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cognitive information in real-world decision-making problems is usually associated with all sorts of ambiguities and uncertainties. Fuzzy sets have been proposed as a general workaround for such information representation. Notwithstanding, there are cases in which the fuzzy sets and fuzzy numbers have some degree of uncertainty when available data either come from unreliable sources or refer to events in the future. These situations result in some unreliability of the obtained fuzzy information. For the modeling of the possible future-event effects on the fuzzy information credibility, the present research presents a novel risk-based fuzzy cognitive methodology by investigating all possible cases to risk modeling of fuzzy sets and the governing mathematical equations. The new fuzzy cognitive model is used to develop a multi-criteria decision-making method based on a fuzzy TOPSIS method so-called RFC-TOPSIS, and the proposed approach was tested on a case study of failure modes and effects analysis problem. Based on the results, robust outcomes were obtained when the proposed methodology was used, highlighting the flexibility and the efficiency of the proposed methodology. The present concept can be used to deal with any problems, where membership function is associated with some risks and errors due to risk factors.},
  archive      = {J_CC},
  author       = {Seiti, Hamidreza and Hafezalkotob, Ashkan},
  doi          = {10.1007/s12559-019-09701-8},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {309-326},
  shortjournal = {Cogn. Comput.},
  title        = {A new risk-based fuzzy cognitive model and its application to decision-making},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Rising star evaluation based on extreme learning machine in
geo-social networks. <em>CC</em>, <em>12</em>(1), 296–308. (<a
href="https://doi.org/10.1007/s12559-019-09680-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In social networks, rising stars are junior individuals who may be not so charming at first but turn out to be outstanding over time. Recently, rising star evaluation has become a popular research topic in the field of social analysis, which is helpful for decision support, cognitive computation, and other practical problems. In this paper, we study the problem of rising star evaluation in geo-social networks. Specifically, given a topic keyword Q and a time point t, we aim at evaluating the latent influence of users to find rising stars, which refer to experts who have few activities and little impact currently on the underlying geo-social network but may become influential experts in the future. To efficiently evaluate future stars, we propose a novel processing framework based on extreme learning machine (ELM) called FS-ELM. FS-ELM consists of three key components. The first component constructs features by incorporating social topology and user behavior patterns. The second component extracts supervised information by discovering topic experts of Q at time (t + Δt); that is, excluding those detected at time t, topic experts obtained at time (t + Δt) can be regarded as rising stars at time t. The third component is ELM-based future star classification that leverages ELM as a departure point to evaluate whether a user is a rising star. Our experimental studies conducted on real-world datasets show that (1) FS-ELM can effectively discover rising stars with a query topic at time t and outperform other traditional methods and (2) user social characteristics have an important impact on the rising star evaluation. This paper studies a novel problem, namely, rising star evaluation in geo-social networks. We propose an advanced processing framework based on ELM by exploiting social topology characteristics and user behavior patterns. The experimental results encouragingly demonstrate the efficiency and effectiveness of the proposed approach.},
  archive      = {J_CC},
  author       = {Ma, Yuliang and Yuan, Ye and Wang, Guoren and Bi, Xin and Wang, Zhongqing and Wang, Yishu},
  doi          = {10.1007/s12559-019-09680-w},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {296-308},
  shortjournal = {Cogn. Comput.},
  title        = {Rising star evaluation based on extreme learning machine in geo-social networks},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Triangular fuzzy neutrosophic preference relations and their
application in enterprise resource planning software selection.
<em>CC</em>, <em>12</em>(1), 261–295. (<a
href="https://doi.org/10.1007/s12559-019-09640-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enterprise resource planning (ERP) system selection is one of the most important topics in an ERP implementation program that ensures the success of the system. Because of the inherent complexity of ERP systems, it is difficult and time consuming for the organization to select the suitable ERP software. This paper employs triangular fuzzy neutrosophic preference relations (TFNPRs) to express the recognitions of decision-makers (DMs) for the choice of ERP software. Preference relation is a powerful tool to express complex decision problems, and the triangular fuzzy neutrosophic number (TFNN) is a good choice to represent the recognitions of the DMs; this paper combines preference relation with TFNN to define the concept of triangular fuzzy neutrosophic preference relations (TFNPRs). To rank the evaluated ERP systems logically, a multiplicative consistency concept for TFNPRs is defined. Then, several multiplicative consistency-based 0–1 mixed programming models are established for estimating missing values in incomplete TFNPRs and for deriving multiplicatively consistent TFNPRs from inconsistent ones, respectively. For group decision-making (GDM), a Manhattan distance measure-based consensus index is defined to measure the agreement degrees of the DMs’ opinions. A multiplicative consistency and consensus-based algorithm to GDM with TFNPRs is provided that can cope with incomplete and inconsistent TFNPRs. Meanwhile, an illustrative example about the selection of ERP software is offered to show the utilization of the new method, and comparison analysis is performed with several previous methods about ERP software selection. The new method adopts TFNPRs that can express the fuzzy truth-membership degree, the fuzzy indeterminacy-membership degree and the fuzzy falsity-membership degree of the recognitions of the DMs. It extends the application of preference relations and endows the DMs with more flexibility to denote their recognitions. Furthermore, the new method is based on the multiplicative consistency and consensus analysis that ensures the rational and representative ranking of the considered objects.},
  archive      = {J_CC},
  author       = {Meng, Fanyong and Wang, Na and Xu, Yanwei},
  doi          = {10.1007/s12559-019-09640-4},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {261-295},
  shortjournal = {Cogn. Comput.},
  title        = {Triangular fuzzy neutrosophic preference relations and their application in enterprise resource planning software selection},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A collaborative-filtering-based data collection strategy for
friedreich’s ataxia. <em>CC</em>, <em>12</em>(1), 249–260. (<a
href="https://doi.org/10.1007/s12559-019-09674-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Friedreich’s ataxia (FRDA) is an inherited neurodegenerative disorder with the prevalence of 2–4 in every 100,000 Caucasian population. Since 2010, the European Friedreich’s Ataxia Consortium for Translational Studies (EFACTS) has endeavored to define and characterize FRDA by recruiting over 940 FRDA patients to provide baseline data in 19 study sites distributed in 9 European countries. It is challenging to collect primary data at EFACTS’ study sites because of physical/psychological difficulties in recruiting new patients and collecting follow-up assessment data. To overcome such challenges, in this paper, we propose a novel data collection strategy for the FRDA baseline data by using the collaborative filtering (CF) approaches. This strategy is motivated by the popularity of the nowadays “Recommendation System” whose central idea is based on the fact that similar patients have similar symptoms on each test item. By doing so, instead of having no data at all, the FRDA researchers would be provided with certain predicted baseline data on patients who cannot attend the assessments for physical/psychological reasons, thereby helping with the data analysis from the researchers’ perspective. It is shown that the CF approaches are capable of predicting baseline data based on the similarity in test items of the patients, where the prediction accuracy is evaluated based on three rating scales selected from the EFACTS database. Experimental results demonstrate the validity and efficiency of the proposed strategy.},
  archive      = {J_CC},
  author       = {Yue, Wenbin and Wang, Zidong and Tian, Bo and Payne, Annette and Liu, Xiaohui},
  doi          = {10.1007/s12559-019-09674-8},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {249-260},
  shortjournal = {Cogn. Comput.},
  title        = {A collaborative-filtering-based data collection strategy for friedreich’s ataxia},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal feature selection for learning-based algorithms for
sentiment classification. <em>CC</em>, <em>12</em>(1), 238–248. (<a
href="https://doi.org/10.1007/s12559-019-09669-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment classification is an important branch of cognitive computation—thus the further studies of properties of sentiment analysis is important. Sentiment classification on text data has been an active topic for the last two decades and learning-based methods are very popular and widely used in various applications. For learning-based methods, a lot of enhanced technical strategies have been used to improve the performance of the methods. Feature selection is one of these strategies and it has been studied by many researchers. However, an existing unsolved difficult problem is the choice of a suitable number of features for obtaining the best sentiment classification performance of the learning-based methods. Therefore, we investigate the relationship between the number of features selected and the sentiment classification performance of the learning-based methods. A new method for the selection of a suitable number of features is proposed in which the Chi Square feature selection algorithm is employed and the features are selected using a preset score threshold. It is discovered that there is a relationship between the logarithm of the number of features selected and the sentiment classification performance of the learning-based method, and it is also found that this relationship is independent of the learning-based method involved. The new findings in this research indicate that it is always possible for researchers to select the appropriate number of features for learning-based methods to obtain the best sentiment classification performance. This can guide researchers to select the proper features for optimizing the performance of learning-based algorithms. (A preliminary version of this paper received a Best Paper Award at the International Conference on Extreme Learning Machines 2018.)},
  archive      = {J_CC},
  author       = {Wang, Zhaoxia and Lin, Zhiping},
  doi          = {10.1007/s12559-019-09669-5},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {238-248},
  shortjournal = {Cogn. Comput.},
  title        = {Optimal feature selection for learning-based algorithms for sentiment classification},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A multiscale hierarchical threshold-based completed local
entropy binary pattern for texture classification. <em>CC</em>,
<em>12</em>(1), 224–237. (<a
href="https://doi.org/10.1007/s12559-019-09673-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the year, visual texture analysis has come to be recognized as one of the most important methods in the area of medical image analysis and understanding, face description and detection, and so on. The goal of texture descriptors is to capture the general characteristic of textures such as dependency as well as invariance properties. Among all the texture descriptors, the binary pattern family of algorithms achieves a great trade of representation efficiency and complexity. This work introduces an efficient discriminative texture descriptor for visual texture classification. Its main contribution is twofold: a multiscale thresholding framework based on hierarchical adaptive local partition to binary encoding and an efficient completed local entropy binary pattern (CLEBP) descriptor. The basic completed local entropy binary pattern is extended by multiscale thresholding framework with hierarchical thresholding to capture not only microstructure local patterns but also macrostructure texture information. Such extension improves the quality and discriminative factor of texture classification. Extensive experiments on three widely used benchmark texture databases (Outex, UIUC, and KTH-TIPS) proof the efficiency of the proposed visual texture descriptor and hierarchical thresholding strategy. Compared with some classical local binary pattern variants and many state-of-the-art methods, the proposed descriptor achieves competitive and superior texture classification performance. The results prove that the proposed method is a powerful and effective texture descriptor for visual texture classification.},
  archive      = {J_CC},
  author       = {Xu, Xiaochun and Li, Yibing and Wu, Q. M. Jonathan},
  doi          = {10.1007/s12559-019-09673-9},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {224-237},
  shortjournal = {Cogn. Comput.},
  title        = {A multiscale hierarchical threshold-based completed local entropy binary pattern for texture classification},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Computational imaging method with a learned plug-and-play
prior for electrical capacitance tomography. <em>CC</em>,
<em>12</em>(1), 206–223. (<a
href="https://doi.org/10.1007/s12559-019-09682-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electrical capacitance tomography (ECT) is a potent image-based measurement technology for monitoring industrial processes, but low-quality images generally limit its application scope and measurement reliability. To increase the precision of reconstruction, in this study, a data-driven plug-and-play prior abstracted by a deep convolutional neural network (DCNN) and the sparseness prior of imaging objects, in form of regularizers, are jointly leveraged to generate a potent imaging model, in which the L1 norm of the mismatch error acts as a data fidelity term (DFT) to weaken the sensitivity of estimation result to noisy input data. The DCNN is embedded into the split Bregman (SB) technique to generate a powerful computing scheme for solving the built imaging model and the fast iterative shrinkage-thresholding algorithm (FISTA) is applied to solve the sub-problems efficiently. Extensive numerical results verify that the proposed imaging technique has competitive reconstruction ability and better robustness in comparison with the state-of-the-art methods. This study demonstrates the validity and efficacy of the proposed algorithm in reducing reconstruction error. Most importantly, the research outcomes verify that the data-driven plug-and-play prior and the sparseness prior can be jointly embedded into the imaging model, leading to a remarkable decline in reconstruction error.},
  archive      = {J_CC},
  author       = {Lei, J. and Liu, Q. B. and Wang, X. Y.},
  doi          = {10.1007/s12559-019-09682-8},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {206-223},
  shortjournal = {Cogn. Comput.},
  title        = {Computational imaging method with a learned plug-and-play prior for electrical capacitance tomography},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Extracting new dispatching rules for multi-objective dynamic
flexible job shop scheduling with limited buffer spaces. <em>CC</em>,
<em>12</em>(1), 195–205. (<a
href="https://doi.org/10.1007/s12559-018-9595-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dispatching rules are among the most widely applied and practical methods for solving dynamic flexible job shop scheduling problems in manufacturing systems. Hence, the design of applicable and effective rules is always an important subject in the scheduling literature. The aim of this study is to propose a practical approach for extracting efficient rules for a more general type of dynamic job shop scheduling problem in which jobs arrive at the shop at different times and machine breakdowns occur stochastically. Limited-buffer conditions are also considered, increasing the problem complexity. Benchmarks are selected from the literature, with some modifications. Gene expression programming combined with a simulation model is used for the design of scheduling policies. The extracted rules are compared with several classic dispatching rules from the literature based on a multi-objective function. The new rules are found to be superior to the classic ones. They are robust and can be used for similar complex scheduling problems. The results prove the efficiency of gene expression programming as a nature-inspired method for dispatching rule extraction.},
  archive      = {J_CC},
  author       = {Teymourifar, Aydin and Ozturk, Gurkan and Ozturk, Zehra Kamisli and Bahadir, Ozan},
  doi          = {10.1007/s12559-018-9595-4},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {195-205},
  shortjournal = {Cogn. Comput.},
  title        = {Extracting new dispatching rules for multi-objective dynamic flexible job shop scheduling with limited buffer spaces},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). EPF: A general framework for supporting continuous top-k
queries over streaming data. <em>CC</em>, <em>12</em>(1), 176–194. (<a
href="https://doi.org/10.1007/s12559-019-09661-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continuous top-k query over sliding window is a fundamental problem in the domain of streaming data management, which monitors the query window and retrieves k objects with the highest scores when the window slides. The key of supporting this query is maintaining a subset of objects in the window, and try to retrieve answers from them when the window slides. The state-of-the-art approach called SAP utilizes the partition technique to support top-k searches. Its key idea is using, as few as possible, high-quality candidates to support the query via finding a proper partition. However, it has to waste relatively high computation cost in evaluating whether the partition is proper and re-scanning the widow. In this paper, we propose an ELM-based framework named EPF, which improves SAP via learning the nature of streaming data. If we learn that the distribution of streaming data is predictable, we could construct a suitable prediction model for a more efficient partition of the window. Furthermore, we propose a novel algorithm to reduce the re-scanning cost. We conduct a thorough experimental study of this technique on real and synthetic datasets and show the significant performance improvement when applying the technique in existing algorithms.},
  archive      = {J_CC},
  author       = {Jiang, Hong and Zhu, Rui and Wang, Bin},
  doi          = {10.1007/s12559-019-09661-z},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {176-194},
  shortjournal = {Cogn. Comput.},
  title        = {EPF: A general framework for supporting continuous top-k queries over streaming data},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient hybrid nature-inspired binary optimizers for
feature selection. <em>CC</em>, <em>12</em>(1), 150–175. (<a
href="https://doi.org/10.1007/s12559-019-09668-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The process of dimensionality reduction is a crucial solution to deal with the dimensionality problem that may be faced when dealing with the majority of machine learning techniques. This paper proposes an enhanced hybrid metaheuristic approach using grey wolf optimizer (GWO) and whale optimization algorithm (WOA) to develop a wrapper-based feature selection method. The main objective of the proposed technique is to alleviate the drawbacks of both algorithms, including immature convergence and stagnation to local optima (LO). The hybridization is done with improvements in the mechanisms of both algorithms. To confirm the stability of the proposed approach, 18 well-known datasets are employed from the UCI repository. Furthermore, the classification accuracy, number of selected features, fitness values, and run time matrices are collected and compared with a set of well-known feature selection approaches in the literature. The results show the superiority of the proposed approach compared with both GWO and WOA. The results also show that the proposed hybrid technique outperforms other state-of-the-art approaches, significantly.},
  archive      = {J_CC},
  author       = {Mafarja, Majdi and Qasem, Asma and Heidari, Ali Asghar and Aljarah, Ibrahim and Faris, Hossam and Mirjalili, Seyedali},
  doi          = {10.1007/s12559-019-09668-6},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {150-175},
  shortjournal = {Cogn. Comput.},
  title        = {Efficient hybrid nature-inspired binary optimizers for feature selection},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A cognitively inspired system architecture for the mengshi
cognitive vehicle. <em>CC</em>, <em>12</em>(1), 140–149. (<a
href="https://doi.org/10.1007/s12559-019-09692-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces the functional system architecture of the Mengshi intelligent vehicle, winner of the 2018 World Intelligent Driving Challenge (WIDC). Different from traditional smart vehicles, a cognitive module is introduced in the system architecture to realise the transition from perception to decision-making. This is shown to enhance the practical utility of the smart vehicle, enabling safe and robust driving in different scenes. The collaborative work of hardware and software systems is achieved through multi-sensor fusion and artificial intelligence (AI) technologies, including novel use of deep machine learning and context-aware scene analysis to select optimal driving strategies. Experimental results using both robustness tests and road tests confirm that the Mengshi intelligent vehicle is reliable and robust in challenging environments. This paper describes the major components of this cognitively inspired architecture and discusses the results of the 2018 WIDC.},
  archive      = {J_CC},
  author       = {Zhang, Xinyu and Zhou, Mo and Liu, Huaping and Hussain, Amir},
  doi          = {10.1007/s12559-019-09692-6},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {140-149},
  shortjournal = {Cogn. Comput.},
  title        = {A cognitively inspired system architecture for the mengshi cognitive vehicle},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An air combat decision learning system based on a brain-like
cognitive mechanism. <em>CC</em>, <em>12</em>(1), 128–139. (<a
href="https://doi.org/10.1007/s12559-019-09683-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The unmanned aerial vehicle (UAV) has emerged unexpectedly as a new force in the recent local wars. To occupy the high ground of military technology in the future, research on autonomous air combat using UAVs is extremely important. In this paper, we propose an intelligent air combat learning system inspired by the cognitive mechanism of the human brain. The air combat capability was divided into two parts: declarative and procedural memory. Imitating the updating and storage mechanism of human knowledge, a long- and short-term hierarchical asynchronous learning principle was designed. We adopted the basic idea of using the error signal to drive learning according to neurophysiological research. Drawing lessons from the working memory mechanism, the error signal for driving the short-term learning was created in the absence of labelled data, using only the interactive information. Then, we proved that the learning mechanism could ensure that system performance advances steadily and gradually. The experiments illustrated that the learning system designed in this paper can achieve some inferior confrontation ability through self-learning without human prior knowledge. Action strategies formed by learning are analogous to the classical tactical manoeuvres of human fighter pilots. We compared our work with related works and found that our method could improve its performance continuously and finally defeat its opponent.},
  archive      = {J_CC},
  author       = {Zhou, Kai and Wei, Ruixuan and Xu, Zhuofan and Zhang, Qirui and Lu, Hongxuan and Zhang, Guofeng},
  doi          = {10.1007/s12559-019-09683-7},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {128-139},
  shortjournal = {Cogn. Comput.},
  title        = {An air combat decision learning system based on a brain-like cognitive mechanism},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Saliency subtraction inspired automated event detection in
underwater environments. <em>CC</em>, <em>12</em>(1), 115–127. (<a
href="https://doi.org/10.1007/s12559-019-09671-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned underwater exploration in unconstrained environments is a challenging problem. Analysis of the large volumes of images/videos captured by underwater stations/vehicles manually is a major bottleneck for further research. Existing computer vision methods either do not target unconstrained underwater environments or they only aim to detect static or moving entities. In this paper, we present a novel method for analyzing underwater videos and detecting events. Entry/exit of an object in scene is treated as an event independent of the other objects present therein. The method is applied on underwater videos with no prior knowledge, thus aiding in automated underwater exploration. The method is inspired by the fact that saliency of objects in the scene is invariant of the surrounding environment. The proposed method is composed of three main steps: Local Patch Saliency, Adaptive Saliency Subtraction, and event generation for analyzing underwater imagery from the videos. The method is aimed at detecting overlapping events containing man-made as well as natural objects including those containing multiple objects in the unconstrained underwater conditions. The performance of the method is evaluated on publicly available videos obtained from Ocean Networks Canada and Fish4Knowledge datasets. Ground truth for Ocean Networks Canada videos is not available; hence, a method for generating the same for varied sources is also presented. The algorithm achieves a precision of 98% for event detection with 20% misclassification rate. The results show the robustness of the method that performs even in complex and varying underwater conditions.},
  archive      = {J_CC},
  author       = {Kumar, Nitin and Sardana, H. K. and Shome, S. N. and Mittal, Neerja},
  doi          = {10.1007/s12559-019-09671-x},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {115-127},
  shortjournal = {Cogn. Comput.},
  title        = {Saliency subtraction inspired automated event detection in underwater environments},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An integrated method with PROMETHEE and conflict analysis
for qualitative and quantitative decision-making: Case study of site
selection for wind power plants. <em>CC</em>, <em>12</em>(1), 100–114.
(<a href="https://doi.org/10.1007/s12559-019-09675-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple-criteria decision-making is common in our daily life. The probabilistic linguistic term set is an effective tool to represent both simple and cognitive complex linguistic expressions given by individuals and groups completely. In this paper, the PROMETHEE (Preference Ranking Organization METHod for Enrichment Evaluations) is enhanced by integrating with a conflict analysis to solve general multiple-criteria decision-making problems with both quantitative and qualitative criteria. Firstly, to capture the inherent uncertainty of evaluations, interval numbers are used to expresses the values of quantitative criteria while probability linguistic term sets are used to scale the qualitative criteria. Then, a preference function for both quantitative and qualitative criteria is proposed. In addition, a conflict analysis is presented and added to the PROMETHEE, which can derive the preference, indifference, and incomparability (PIR) relations of alternatives. A reference point is given to select the thresholds for the PIR relations. Finally, the improved PROMETHEE is highlighted by a case study concerning site selection of the wind power plant.},
  archive      = {J_CC},
  author       = {Wu, Xingli and Zhang, Cheng and Jiang, Lisheng and Liao, Huchang},
  doi          = {10.1007/s12559-019-09675-7},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {100-114},
  shortjournal = {Cogn. Comput.},
  title        = {An integrated method with PROMETHEE and conflict analysis for qualitative and quantitative decision-making: Case study of site selection for wind power plants},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Using the instance-based learning paradigm to model
energy-relevant occupant behaviors in buildings. <em>CC</em>,
<em>12</em>(1), 71–99. (<a
href="https://doi.org/10.1007/s12559-019-09672-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human interactive behavior is accountable for most of the variance between the observed and predicted energy consumption of buildings, and is accordingly acknowledged as a major field of research into limiting building-related energy consumption. A thorough understanding of occupant behavior is critical to facilitate a more reliable prediction of energy consumption and identifying means by which pro-environmental behaviors can be promoted. Insights and models from psychology and sociology appear to be best suited to improving such understanding, and this article contributes to this end by developing and testing a cognitive model that serves as the core of a numerical human-building interaction model. The proposed implementation builds on instance-based learning, a well-established cognitive modeling paradigm, is integrated into a thermodynamic building model, and complemented by perception models for the approximation of the thermal and olfactory perception of the environment. The model successfully learns to interact plausibly with a set of elements of a model room—a heating system, a window, and the actor’s clothing—in order to establish predefined room conditions. Accumulation of context-specific instances in the declarative memory, which are retrieved and blended in a decision situation, provide the model with the flexibility to adapt its actions to very different climatic contexts, represented by the locations Stuttgart, Madrid, Stockholm, and Melbourne. Moreover, the model manages to find appropriate compromises if need satisfaction requires contradictory actions, such as in situations where satisfaction of the olfactory need requires opening the window and satisfaction of the thermal need requires keeping it closed. Despite its obvious complexity, the model must be considered to be a basic model, which restricts the immediate comparability of its results to human behavior data. However, the successfully applied plausibility checks clearly indicate the value of the cognitive approach to modeling human-building interaction.},
  archive      = {J_CC},
  author       = {von Grabe, Jörn},
  doi          = {10.1007/s12559-019-09672-w},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {71-99},
  shortjournal = {Cogn. Comput.},
  title        = {Using the instance-based learning paradigm to model energy-relevant occupant behaviors in buildings},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A multiple attribute group decision-making method based on
the partitioned bonferroni mean of linguistic intuitionistic fuzzy
numbers. <em>CC</em>, <em>12</em>(1), 49–70. (<a
href="https://doi.org/10.1007/s12559-019-09676-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a more effective linguistic information representation model, the linguistic intuitionistic fuzzy number (LIFN), made up of the linguistic membership degree (LMD) and the linguistic non-membership degree (LNMD), plays an important role in describing uncertain-decision information in cognitive activity. The partitioned Bonferroni mean (PBM) operator is constructed based on real conditions, considering that some factors considered by decision-makers are interrelated and some are independent. The PBM operator can aggregate evaluation information under various attributes, which are divided into several independent groups; the factors interact with each other within the same group, but the factors are independent of each other when located in different groups. The classical PBM operators and their extensions can handle many decision-making problems but are unable to handle decision-making problems under a linguistic intuitionistic environment. To take full advantage of the PBM operator and LIFNs, this paper combines the PBM operator with LIFNs to propose several PBM operators for aggregating LIFNs. First, the relative theories about LIFNs are reviewed in brief. Then, linguistic intuitionistic fuzzy partitioned BM aggregation operators and partitioned geometric BM aggregation operators are discussed, including the linguistic intuitionistic fuzzy partitioned Bonferroni mean (LIFPBM) operator, the linguistic intuitionistic fuzzy weighted partitioned Bonferroni mean (LIFWPBM) operator, the linguistic intuitionistic fuzzy partitioned geometric Bonferroni mean (LIFPGBM) operator, and the linguistic intuitionistic fuzzy weighted partitioned geometric Bonferroni mean (LIFWPGBM) operator. Moreover, a novel method constructed on the developed operators is presented to address multiple attribute group decision-making (MAGDM) problems with the LIFNs. The feasibility of the proposed method is given by a numeric example, and the comparative analysis of our proposed method and other methods shows some advantages of these new methods. The developed method is constructed based on LIFNs and the PBM operator, and it is more practical and general than other existing methods and easily describes qualitative information that stems from a decision maker’s cognition. In addition, it can more effectively handle the complex relationship among multiple attributes in MAGDM problems.},
  archive      = {J_CC},
  author       = {Liu, Peide and Liu, Junlin},
  doi          = {10.1007/s12559-019-09676-6},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {49-70},
  shortjournal = {Cogn. Comput.},
  title        = {A multiple attribute group decision-making method based on the partitioned bonferroni mean of linguistic intuitionistic fuzzy numbers},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Overview of hesitant linguistic preference relations for
representing cognitive complex information: Where we stand and what is
next. <em>CC</em>, <em>12</em>(1), 25–48. (<a
href="https://doi.org/10.1007/s12559-019-09681-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hesitant fuzzy linguistic preference relations (HFLPRs) can be used to represent cognitive complex information in a situation in which people hesitate among several possible linguistic terms for the preference degrees of pairwise comparisons over alternatives. HFLPRs have attracted growing attention owing to their efficiency in dealing with increasingly cognitive complex decision-making problems. Due to the emergence of various studies on HFLPRs, it is necessary to make a comprehensive overview of the theory of HFLPRs and their applications. In this paper, we first review different types of linguistic representation models, including the hesitant fuzzy linguistic term set, hesitant 2-tuple fuzzy linguistic term set, probabilistic linguistic term set, and double-hierarchy hesitant fuzzy linguistic term set. The reasons for proposing these models are discussed in detail. Then, the hesitant linguistic preference relation models associated with the aforementioned linguistic representation models are addressed one by one. An overview is then provided in terms of their consistency properties, inconsistency-repairing processes, priority vector derivation methods, consensus measures, applications, and future directions. Basically, we try to answer to two questions: where we stand and what is next? The preference relations and consistency properties are discussed in detail. The inconsistency-repairing processes for those preference relations that are not acceptably consistent are summarized. Methods to derive the priorities from the HFLPRs and their extensions are further reviewed. The consensus measures and consensus-reaching processes for group decision making with HFLPRs and their extensions are discussed. The applications of HFLPRs and their extensions in different areas are highlighted. The future research directions regarding HFLPRs are given from different perspectives. This paper provides a comprehensive overview of the development and research status of HFLPRs for representing cognitive complex information. It can help researchers to identify the frontier of cognitive complex preference relation theory in the realm of decision analysis. Since the research on HFLPRs is still at its initial stage, this review has guiding significance for the later stage of study on this topic. Furthermore, this paper can engage further research or extend the research interests of scholars.},
  archive      = {J_CC},
  author       = {Liao, Huchang and Tang, Ming and Qin, Rui and Mi, Xiaomei and Altalhi, Abdulrahman and Alshomrani, Saleh and Herrera, Francisco},
  doi          = {10.1007/s12559-019-09681-9},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {25-48},
  shortjournal = {Cogn. Comput.},
  title        = {Overview of hesitant linguistic preference relations for representing cognitive complex information: Where we stand and what is next},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Use of neural signals to evaluate the quality of generative
adversarial network performance in facial image generation. <em>CC</em>,
<em>12</em>(1), 13–24. (<a
href="https://doi.org/10.1007/s12559-019-09670-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is a growing interest in using generative adversarial networks (GANs) to produce image content that is indistinguishable from real images as judged by a typical person. A number of GAN variants for this purpose have been proposed; however, evaluating GAN performance is inherently difficult because current methods for measuring the quality of their output are not always consistent with what a human perceives. We propose a novel approach that combines a brain-computer interface (BCI) with GANs to generate a measure we call Neuroscore, which closely mirrors the behavioral ground truth measured from participants tasked with discerning real from synthetic images. This technique we call a neuro-AI interface, as it provides an interface between a human’s neural systems and an AI process. In this paper, we first compare the three most widely used metrics in the literature for evaluating GANs in terms of visual quality and compare their outputs with human judgments. Secondly, we propose and demonstrate a novel approach using neural signals and rapid serial visual presentation (RSVP) that directly measures a human perceptual response to facial production quality, independent of a behavioral response measurement. The correlation between our proposed Neuroscore and human perceptual judgments has Pearson correlation statistics: r(48) = − 0.767, p = 2.089e − 10. We also present the bootstrap result for the correlation i.e., p ≤ 0.0001. Results show that our Neuroscore is more consistent with human judgment compared with the conventional metrics we evaluated. We conclude that neural signals have potential applications for high-quality, rapid evaluation of GANs in the context of visual image synthesis.},
  archive      = {J_CC},
  author       = {Wang, Zhengwei and Healy, Graham and Smeaton, Alan F. and Ward, Tomás E.},
  doi          = {10.1007/s12559-019-09670-y},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {13-24},
  shortjournal = {Cogn. Comput.},
  title        = {Use of neural signals to evaluate the quality of generative adversarial network performance in facial image generation},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Automatic design of deep networks with neural blocks.
<em>CC</em>, <em>12</em>(1), 1–12. (<a
href="https://doi.org/10.1007/s12559-019-09677-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep neural networks (DNNs) have achieved great successes in many areas, such as cognitive computation, pattern recognition, and computer vision. Although many hand-crafted deep networks have been proposed in the literature, designing a well-behaved neural network for a specific application requires high-level expertise yet. Hence, the automatic architecture design of DNNs has become a challenging and important problem. In this paper, we propose a new reinforcement learning method, whose action policy is to select neural blocks and construct deep networks. We define the action search space with three types of neural blocks, i.e., dense block, residual block, and inception-like block. Additionally, we have also designed several variants for the residual and inception-like blocks. The optimal network is automatically learned by a Q-learning agent, which is iteratively trained to generate well-performed deep networks. To evaluate the proposed method, we have conducted experiments on three datasets, MNIST, SVHN, and CIFAR-10, for image classification applications. Compared with existing hand-crafted and auto-generated neural networks, our auto-designed neural network delivers promising results. Moreover, the proposed reinforcement learning algorithm for deep networks design only runs on one GPU, demonstrating much higher efficiency than most of the previous deep network search approaches.},
  archive      = {J_CC},
  author       = {Zhong, Guoqiang and Jiao, Wencong and Gao, Wei and Huang, Kaizhu},
  doi          = {10.1007/s12559-019-09677-5},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {1-12},
  shortjournal = {Cogn. Comput.},
  title        = {Automatic design of deep networks with neural blocks},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
