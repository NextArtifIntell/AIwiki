<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>JMIV_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="jmiv---76">JMIV - 76</h2>
<ul>
<li><details>
<summary>
(2020). Temporal huber regularization for DCE-MRI. <em>JMIV</em>,
<em>62</em>(9), 1334–1346. (<a
href="https://doi.org/10.1007/s10851-020-00985-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) is used to study microvascular structure and tissue perfusion. In DCE-MRI, a bolus of gadolinium-based contrast agent is injected into the blood stream and spatiotemporal changes induced by the contrast agent flow are estimated from a time series of MRI data. Sufficient time resolution can often only be obtained by using an imaging protocol which produces undersampled data for each image in the time series. This has lead to the popularity of compressed sensing-based image reconstruction approaches, where all the images in the time series are reconstructed simultaneously, and temporal coupling between the images is introduced into the problem by a sparsity promoting regularization functional. We propose the use of Huber penalty for temporal regularization in DCE-MRI, and compare it to total variation, total generalized variation and smoothness-based temporal regularization models. We also study the effect of spatial regularization to the reconstruction and compare the reconstruction accuracy with different temporal resolutions due to varying undersampling. The approaches are tested using simulated and experimental radial golden angle DCE-MRI data from a rat brain specimen. The results indicate that Huber regularization produces similar reconstruction accuracy with the total variation-based models, but the computation times are significantly faster.},
  archive      = {J_JMIV},
  author       = {Hanhela, Matti and Kettunen, Mikko and Gröhn, Olli and Vauhkonen, Marko and Kolehmainen, Ville},
  doi          = {10.1007/s10851-020-00985-2},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {11},
  number       = {9},
  pages        = {1334-1346},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Temporal huber regularization for DCE-MRI},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Equivalence between digital well-composedness and
well-composedness in the sense of alexandrov on n-d cubical grids.
<em>JMIV</em>, <em>62</em>(9), 1285–1333. (<a
href="https://doi.org/10.1007/s10851-020-00988-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Among the different flavors of well-composednesses on cubical grids, two of them, called, respectively, digital well-composedness (DWCness) and well-composedness in the sense of Alexandrov (AWCness), are known to be equivalent in 2D and in 3D. The former means that a cubical set does not contain critical configurations, while the latter means that the boundary of a cubical set is made of a disjoint union of discrete surfaces. In this paper, we prove that this equivalence holds in n-D, which is of interest because today images are not only 2D or 3D but also 4D and beyond. The main benefit of this proof is that the topological properties available for AWC sets, mainly their separation properties, are also true for DWC sets, and the properties of DWC sets are also true for AWC sets: an Euler number locally computable, equivalent connectivities from a local or global point of view. This result is also true for gray-level images thanks to cross section topology, which means that the sets of shapes of DWC gray-level images make a tree like the ones of AWC gray-level images.},
  archive      = {J_JMIV},
  author       = {Boutry, Nicolas and Najman, Laurent and Géraud, Thierry},
  doi          = {10.1007/s10851-020-00988-z},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {11},
  number       = {9},
  pages        = {1285-1333},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Equivalence between digital well-composedness and well-composedness in the sense of alexandrov on n-D cubical grids},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Topological properties of the first non-local digitally
well-composed interpolation on n-d cubical grids. <em>JMIV</em>,
<em>62</em>(9), 1256–1284. (<a
href="https://doi.org/10.1007/s10851-020-00989-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In discrete topology, we like digitally well-composed (shortly DWC) interpolations because they remove pinches in cubical images. Usual well-composed interpolations are local and sometimes self-dual (they treat in a same way dark and bright components in the image). In our case, we are particularly interested in n-D self-dual DWC interpolations to obtain a purely self-dual tree of shapes. However, it has been proved that we cannot have an n-D interpolation which is at the same time local, self-dual and well-composed. By removing the locality constraint, we have obtained an n-D interpolation with many properties in practice: it is self-dual, DWC, and in-between (this last property means that it preserves the contours). Since we did not publish the proofs of these results before, we propose to provide in a first time the proofs of the two last properties here (DWCness and in-betweeness) and a sketch of the proof of self-duality (the complete proof of self-duality requires more material and will come later). Some theoretical and practical results are given.},
  archive      = {J_JMIV},
  author       = {Boutry, Nicolas and Najman, Laurent and Géraud, Thierry},
  doi          = {10.1007/s10851-020-00989-y},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {11},
  number       = {9},
  pages        = {1256-1284},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Topological properties of the first non-local digitally well-composed interpolation on n-D cubical grids},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Non-blind and blind deconvolution under poisson noise using
fractional-order total variation. <em>JMIV</em>, <em>62</em>(9),
1238–1255. (<a
href="https://doi.org/10.1007/s10851-020-00987-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a wide range of applications such as astronomy, biology, and medical imaging, acquired data are usually corrupted by Poisson noise and blurring artifacts. Poisson noise often occurs when photon counting is involved in such imaging modalities as X-ray, positron emission tomography, and fluorescence microscopy. Meanwhile, blurring is also inevitable due to the physical mechanism of an imaging system, which can be modeled as a convolution of the image with a point spread function. In this paper, we consider both non-blind and blind image deblurring models that deal with Poisson noise. In the pursuit of high-order smoothness of a restored image, we propose a fractional-order total variation regularization to remove the blur and Poisson noise simultaneously. We develop two efficient algorithms based on the alternating direction method of multipliers, while an expectation-maximization algorithm is adopted only in the blind case. A variety of numerical experiments have demonstrated that the proposed algorithms can efficiently reconstruct piecewise smooth images degraded by Poisson noise and various types of blurring, including Gaussian and motion blurs. Specifically for blind image deblurring, we obtain significant improvements over the state of the art.},
  archive      = {J_JMIV},
  author       = {Chowdhury, Mujibur Rahman and Qin, Jing and Lou, Yifei},
  doi          = {10.1007/s10851-020-00987-0},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {11},
  number       = {9},
  pages        = {1238-1255},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Non-blind and blind deconvolution under poisson noise using fractional-order total variation},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An additive approximation to multiplicative noise.
<em>JMIV</em>, <em>62</em>(9), 1227–1237. (<a
href="https://doi.org/10.1007/s10851-020-00984-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiplicative noise models are often used instead of additive noise models in cases in which the noise variance depends on the state. Furthermore, when Poisson distributions with relatively small counts are approximated with normal distributions, multiplicative noise approximations are straightforward to implement. There are a number of limitations in the existing approaches to deal with multiplicative errors, such as positivity of the multiplicative noise term. The focus in this paper is on large dimensional (inverse) problems for which sampling-type approaches have too high computational complexity. In this paper, we propose an alternative approach utilising the Bayesian framework to carry out approximative marginalisation over the multiplicative error by embedding the statistics in an additive error term. The Bayesian framework allows the statistics of the resulting additive error term to be found based on the statistics of the other unknowns. As an example, we consider a deconvolution problem on random fields with different statistics of the multiplicative noise. Furthermore, the approach allows for correlated multiplicative noise. We show that the proposed approach provides feasible error estimates in the sense that the posterior models support the actual image.},
  archive      = {J_JMIV},
  author       = {Nicholson, R. and Kaipio, J. P.},
  doi          = {10.1007/s10851-020-00984-3},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {11},
  number       = {9},
  pages        = {1227-1237},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {An additive approximation to multiplicative noise},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Geometric interpretation of the multi-solution phenomenon in
the P3P problem. <em>JMIV</em>, <em>62</em>(9), 1214–1226. (<a
href="https://doi.org/10.1007/s10851-020-00982-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is well known that the P3P problem could have 1, 2, 3 and at most 4 positive solutions under different configurations among its three control points and the position of the optical center. Since in any real applications, the knowledge on the exact number of possible solutions is a prerequisite for selecting the right one among all the possible solutions, and the study on the phenomenon of multiple solutions in the P3P problem has been an active topic since its very inception. In this work, we provide some new geometric interpretations on the multi-solution phenomenon in the P3P problem, and our main results include: (1) the necessary and sufficient condition for the P3P problem to have a pair of side-sharing solutions is the two optical centers of the solutions both lie on one of the three vertical planes to the base plane of control points; (2) the necessary and sufficient condition for the P3P problem to have a pair of point-sharing solutions is the two optical centers of the solutions both lie on one of the three so-called skewed danger cylinders;(3) if the P3P problem has other solutions in addition to a pair of side-sharing (point-sharing) solutions, these remaining solutions must be a point-sharing (side-sharing ) pair. In a sense, the side-sharing pair and the point-sharing pair are companion pairs; (4) there indeed exist such P3P problems that have four completely distinct solutions, i.e., the solutions sharing neither a side nor a point, closing a long guessing issue in the literature. In sum, our results provide some new insights into the nature of the multi-solution phenomenon in the P3P problem, and in addition to their academic value, they could also be used as some theoretical guidance for practitioners in real applications to avoid occurrence of multiple solutions by properly arranging the control points.},
  archive      = {J_JMIV},
  author       = {Wang, Bo and Hu, Hao and Zhang, Caixia},
  doi          = {10.1007/s10851-020-00982-5},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {11},
  number       = {9},
  pages        = {1214-1226},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Geometric interpretation of the multi-solution phenomenon in the P3P problem},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Power spectral clustering. <em>JMIV</em>, <em>62</em>(9),
1195–1213. (<a
href="https://doi.org/10.1007/s10851-020-00980-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spectral clustering is one of the most important image processing tools, especially for image segmentation. This specializes at taking local information such as edge weights and globalizing them. Due to its unsupervised nature, it is widely applicable. However, traditional spectral clustering is $${\mathcal {O}}(n^{3/2})$$ . This poses a challenge, especially given the recent trend of large datasets. In this article, we propose an algorithm by using ideas from $$\varGamma $$ -convergence, which is an amalgamation of maximum spanning tree clustering and spectral clustering. This algorithm scales as $${\mathcal {O}}(n \log (n))$$ under certain conditions, while producing solutions which are similar to that of spectral clustering. Several toy examples are used to illustrate the similarities and differences. To validate the proposed algorithm, a recent state-of-the-art technique for segmentation—multiscale combinatorial grouping is used, where the normalized cut is replaced with the proposed algorithm and results are analyzed.},
  archive      = {J_JMIV},
  author       = {Challa, Aditya and Danda, Sravan and Sagar, B. S. Daya and Najman, Laurent},
  doi          = {10.1007/s10851-020-00980-7},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {11},
  number       = {9},
  pages        = {1195-1213},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Power spectral clustering},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Variational models for color image correction inspired by
visual perception and neuroscience. <em>JMIV</em>, <em>62</em>(9),
1173–1194. (<a
href="https://doi.org/10.1007/s10851-020-00978-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reproducing the perception of a real-world scene on a display device is a very challenging task which requires the understanding of the camera processing pipeline, the display process, and the way the human visual system processes the light it captures. Mathematical models based on psychophysical and physiological laws on color vision, named Retinex, provide efficient tools to handle degradations produced during the camera processing pipeline like the reduction of the contrast. In particular, Batard and Bertalmío (in J Math Imaging Vis 60(6):849–881, 2018) described some psychophysical laws on brightness perception as covariant derivatives, included them into a variational model, and observed that the quality of the color image correction is correlated with the accuracy of the vision model it includes. Based on this observation, we postulate that this model can be improved by including more accurate data on vision with a special attention on visual neuroscience here. Then, inspired by the presence of neurons responding to different visual attributes in the area V1 of the visual cortex as orientation, color or movement, to name a few, and horizontal connections modeling the interactions between those neurons, we construct two variational models to process both local (edges, textures) and global (contrast) features. This is an improvement with respect to the model of Batard and Bertalmío as the latter cannot process local and global features independently and simultaneously. Finally, we conduct experiments on color images which corroborate the improvement provided by the new models.},
  archive      = {J_JMIV},
  author       = {Batard, Thomas and Hertrich, Johannes and Steidl, Gabriele},
  doi          = {10.1007/s10851-020-00978-1},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {11},
  number       = {9},
  pages        = {1173-1194},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Variational models for color image correction inspired by visual perception and neuroscience},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Background subtraction using adaptive singular value
decomposition. <em>JMIV</em>, <em>62</em>(8), 1159–1172. (<a
href="https://doi.org/10.1007/s10851-020-00967-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An important task when processing sensor data is to distinguish relevant from irrelevant data. This paper describes a method for an iterative singular value decomposition that maintains a model of the background via singular vectors spanning a subspace of the image space, thus providing a way to determine the amount of new information contained in an incoming frame. We update the singular vectors spanning the background space in a computationally efficient manner and provide the ability to perform blockwise updates, leading to a fast and robust adaptive SVD computation. The effects of those two properties and the success of the overall method to perform a state-of-the-art background subtraction are shown in both qualitative and quantitative evaluations.},
  archive      = {J_JMIV},
  author       = {Reitberger, Günther and Sauer, Tomas},
  doi          = {10.1007/s10851-020-00967-4},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {10},
  number       = {8},
  pages        = {1159-1172},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Background subtraction using adaptive singular value decomposition},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hexagonality as a new shape-based descriptor of object.
<em>JMIV</em>, <em>62</em>(8), 1136–1158. (<a
href="https://doi.org/10.1007/s10851-020-00966-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we define a new shape-based measure which evaluates how much a given shape is hexagonal. Such an introduced measure ranges through the interval (0, 1] and reaches the maximal possible value 1 if and only if the shape considered is a hexagon. The new measure is also invariant with respect to rotation, translation and scaling transformations. A number of experiments, performed on both synthetic and real image data, are shown in order to confirm theoretical observations and illustrate the behavior of the new measure. The new hexagonality measure also provides several useful side results whose theoretical properties are discussed and experimentally evaluated. As side results, we obtain a new method that computes the shape orientation as the direction which optimizes the new hexagonality measure and a new shape elongation measure which computes the elongation of a given shape as the ratio of the lengths of the longer and shorter semi-axis of the appropriate associated hexagon. Several experiments relating to three well-known image datasets, such as MPEG-7 CE-1, Swedish Leaf, and Galaxy Zoo datasets, are also provided to illustrate effectiveness and benefits of the new introduced shape measures.},
  archive      = {J_JMIV},
  author       = {Ilić, Vladimir and Ralević, Nebojša M.},
  doi          = {10.1007/s10851-020-00966-5},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {10},
  number       = {8},
  pages        = {1136-1158},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Hexagonality as a new shape-based descriptor of object},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A measure of q-convexity for shape analysis. <em>JMIV</em>,
<em>62</em>(8), 1121–1135. (<a
href="https://doi.org/10.1007/s10851-020-00962-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study three basic novel measures of convexity for shape analysis. The convexity considered here is the so-called Q-convexity, that is, convexity by quadrants. The measures are based on the geometrical properties of Q-convex shapes and have the following features: (1) their values range from 0 to 1; (2) their values equal 1 if and only if the binary image is Q-convex; and (3) they are invariant by translation, reflection, and rotation by 90 degrees. We design a new algorithm for the computation of the measures whose time complexity is linear in the size of the binary image representation. We investigate the properties of our measures by solving object ranking problems and give an illustrative example of how these convexity descriptors can be utilized in classification problems.},
  archive      = {J_JMIV},
  author       = {Balázs, Péter and Brunetti, Sara},
  doi          = {10.1007/s10851-020-00962-9},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {10},
  number       = {8},
  pages        = {1121-1135},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {A measure of Q-convexity for shape analysis},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the generalized essential matrix correction: An efficient
solution to the problem and its applications. <em>JMIV</em>,
<em>62</em>(8), 1107–1120. (<a
href="https://doi.org/10.1007/s10851-020-00961-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the problem of finding the closest generalized essential matrix from a given $$6\times 6$$ matrix, with respect to the Frobenius norm. To the best of our knowledge, this nonlinear constrained optimization problem has not been addressed in the literature yet. Although it can be solved directly, it involves a large number of constraints, and any optimization method to solve it would require much computational effort. We start by deriving a couple of unconstrained formulations of the problem. After that, we convert the original problem into a new one, involving only orthogonal constraints, and propose an efficient algorithm of steepest descent type to find its solution. To test the algorithms, we evaluate the methods with synthetic data and conclude that the proposed steepest descent-type approach is much faster than the direct application of general optimization techniques to the original formulation with 33 constraints and to the unconstrained ones. To further motivate the relevance of our method, we apply it in two pose problems (relative and absolute) using synthetic and real data.},
  archive      = {J_JMIV},
  author       = {Miraldo, Pedro and Cardoso, João R.},
  doi          = {10.1007/s10851-020-00961-w},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {10},
  number       = {8},
  pages        = {1107-1120},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {On the generalized essential matrix correction: An efficient solution to the problem and its applications},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Shape analysis of surfaces using general elastic metrics.
<em>JMIV</em>, <em>62</em>(8), 1087–1106. (<a
href="https://doi.org/10.1007/s10851-020-00959-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we introduce a family of elastic metrics on the space of parametrized surfaces in 3D space using a corresponding family of metrics on the space of vector-valued one-forms. We provide a numerical framework for the computation of geodesics with respect to these metrics. The family of metrics is invariant under rigid motions and reparametrizations; hence, it induces a metric on the “shape space” of surfaces. This new class of metrics generalizes a previously studied family of elastic metrics and includes in particular the Square Root Normal Field (SRNF) metric, which has been proven successful in various applications. We demonstrate our framework by showing several examples of geodesics and compare our results with earlier results obtained from the SRNF framework.},
  archive      = {J_JMIV},
  author       = {Su, Zhe and Bauer, Martin and Preston, Stephen C. and Laga, Hamid and Klassen, Eric},
  doi          = {10.1007/s10851-020-00959-4},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {10},
  number       = {8},
  pages        = {1087-1106},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Shape analysis of surfaces using general elastic metrics},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient relative pose estimation for cameras and
generalized cameras in case of known relative rotation angle.
<em>JMIV</em>, <em>62</em>(8), 1076–1086. (<a
href="https://doi.org/10.1007/s10851-020-00958-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose two minimal solvers to the problem of relative pose estimation for a camera with known relative rotation angle. In practice, such angle can be derived from the readings of a 3D gyroscope. Different from other relative pose formulations fusing a camera and a gyroscope, the use of relative rotation angle does not require extrinsic calibration between the two sensors. The first proposed solver is formulated for a calibrated regular camera and requires four-point correspondences from two views. The second solver extends the problem to a generalized camera and requires five-point correspondences. We represent the rotation part of the motion in terms of unit quaternions in order to construct polynomial equations encoding the epipolar constraints. The Gröbner basis technique is then used to efficiently derive the polynomial solutions. Our first solver for regular cameras significantly improves the existing state-of-the-art solution. The second solver for generalized cameras is novel. The presented minimal solvers can be used in a hypothesize-and-test architecture such as RANSAC for reliable pose estimation. Experiments on synthetic and real datasets confirm that our algorithms are numerically stable, fast, and robust.},
  archive      = {J_JMIV},
  author       = {Martyushev, Evgeniy and Li, Bo},
  doi          = {10.1007/s10851-020-00958-5},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {10},
  number       = {8},
  pages        = {1076-1086},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Efficient relative pose estimation for cameras and generalized cameras in case of known relative rotation angle},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). 2D geometric moment invariants from the point of view of the
classical invariant theory. <em>JMIV</em>, <em>62</em>(8), 1062–1075.
(<a href="https://doi.org/10.1007/s10851-020-00954-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this paper is to clear up the question of the connection between the geometric moment invariants and the invariant theory, considering a problem of describing the 2D geometric moment invariants as a problem of the classical invariant theory. We give a precise statement of the problem of computation of the 2D geometric invariant moments, introducing the notions of the algebras of simultaneous 2D geometric moment invariants, and prove that they are isomorphic to the algebras of joint $$\hbox {SO}(2)$$ -invariants of several binary forms. Also, to simplify the calculating of the invariants, we proceed from an action of Lie group $$\hbox {SO}(2)$$ to an action of its Lie algebra $${{\mathfrak {so}}}_2$$ . Though the 2D geometric moments are not as effective as the orthogonal ones are, the author hopes that the results will be useful to the researchers in the fields of image analysis and pattern recognition.},
  archive      = {J_JMIV},
  author       = {Bedratyuk, Leonid},
  doi          = {10.1007/s10851-020-00954-9},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {10},
  number       = {8},
  pages        = {1062-1075},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {2D geometric moment invariants from the point of view of the classical invariant theory},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Single image blind deblurring based on salient
edge-structures and elastic-net regularization. <em>JMIV</em>,
<em>62</em>(8), 1049–1061. (<a
href="https://doi.org/10.1007/s10851-020-00949-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In single image blind deblurring, the blur kernel and latent image are estimated from a single observed blurry image. The associated mathematical problem is ill-posed, and an acceptable solution is difficult to obtain without additional priors or heuristics. Inspired by the nonlocal self-similarity in image denoising problem, we introduce elastic-net regularization as a rank prior to improve the estimation of the intermediate image. Furthermore, it is well known that salient edge-structures can provide reliable information for kernel estimation. Therefore, we propose a new blind image deblurring method by combining the salient edge-structures and the elastic-net regularization. The salient edge-structures are selected from the intermediate image and used to guide the estimation of the blur kernel. Then, we employ the elastic-net regularization and edge-structures to further estimate intermediate latent image, by retaining the dominant edge and removing slight texture, for a better kernel estimation. Finally, quantitative and qualitative evaluations are conducted by comparing the results with those obtained by state-of-the-art methods. We conclude that the proposed method performs favorably when considering both synthetic and real blurry images.},
  archive      = {J_JMIV},
  author       = {Yu, XiaoYuan and Xie, Wei},
  doi          = {10.1007/s10851-020-00949-6},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {10},
  number       = {8},
  pages        = {1049-1061},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Single image blind deblurring based on salient edge-structures and elastic-net regularization},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Correcting the side effects of ADC filtering in MR image
reconstruction. <em>JMIV</em>, <em>62</em>(6), 1034–1047. (<a
href="https://doi.org/10.1007/s10851-019-00940-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work investigates the role of the filters implemented on analog-to-digital converters for the reconstruction of magnetic resonance images. We analyze the effects of these filters both from a theoretical and an experimental point of view and demonstrate how it may lead to severe degradation of the reconstructed images when the distance between consecutive samples is larger than Shannon’s limit. Based on these findings, we propose a mathematical model and a numerical algorithm that allow to mitigate such filtering effects both for linear and nonlinear reconstructions. Experiments on simulated and real data on a 7 Tesla scanner show that the proposed ideas allow to significantly improve the overall image quality. These findings are particularly relevant for high resolution imaging and for recent sampling schemes saturating the maximum gradient amplitude. They also open new challenges in sampling theory.},
  archive      = {J_JMIV},
  author       = {Lazarus, Carole and März, Maximilian and Weiss, Pierre},
  doi          = {10.1007/s10851-019-00940-w},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {7},
  number       = {6},
  pages        = {1034-1047},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Correcting the side effects of ADC filtering in MR image reconstruction},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A nonlocal laplacian-based model for bituminous surfacing
crack recovery and its MPI implementation. <em>JMIV</em>,
<em>62</em>(6), 1007–1033. (<a
href="https://doi.org/10.1007/s10851-020-00968-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is devoted to the challenging problem of fine structure detection with applications to bituminous surfacing crack recovery. Drogoul (SIAM J Imag Sci 7(4):2700–2731, 2014) shows that such structures can be suitably modeled by a sequence of smooth functions whose Hessian matrices blow up in the perpendicular direction to the crack, while their gradient is null. This observation serves as the basis of the introduced model that also handles the natural dense and highly oscillatory texture exhibited by the images: We propose weighting $$\left| \frac{\partial ^2u}{\partial x_1^2}\right| ^2+\left| \frac{\partial ^2u}{\partial x_2^2}\right| ^2$$ , u denoting the reconstructed image, by a variable that annihilates great expansion of this quantity, making then a connection with the elliptic approximation of the Blake–Zisserman functional. Extending then the ideas developed in the case of first-order nonlocal regularization to higher-order derivatives, we derive and analyze a nonlocal version of the model, and provide several theoretical results among which there are a $$\varGamma $$ -convergence result as well as a detailed algorithmic approach and an MPI implementation based on a natural domain decomposition approach.},
  archive      = {J_JMIV},
  author       = {Debroux, Noémie and Le Guyader, Carole and Vese, Luminita A.},
  doi          = {10.1007/s10851-020-00968-3},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {7},
  number       = {6},
  pages        = {1007-1033},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {A nonlocal laplacian-based model for bituminous surfacing crack recovery and its MPI implementation},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Unsupervised assignment flow: Label learning on feature
manifolds by spatially regularized geometric assignment. <em>JMIV</em>,
<em>62</em>(6), 982–1006. (<a
href="https://doi.org/10.1007/s10851-019-00935-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces the unsupervised assignment flow that couples the assignment flow for supervised image labeling (Åström et al. in J Math Imaging Vis 58(2):211–238, 2017) with Riemannian gradient flows for label evolution on feature manifolds. The latter component of the approach encompasses extensions of state-of-the-art clustering approaches to manifold-valued data. Coupling label evolution with the spatially regularized assignment flow induces a sparsifying effect that enables to learn compact label dictionaries in an unsupervised manner. Our approach alleviates the requirement for supervised labeling to have proper labels at hand, because an initial set of labels can evolve and adapt to better values while being assigned to given data. The separation between feature and assignment manifolds enables the flexible application which is demonstrated for three scenarios with manifold-valued features. Experiments demonstrate a beneficial effect in both directions: adaptivity of labels improves image labeling, and steering label evolution by spatially regularized assignments leads to proper labels, because the assignment flow for supervised labeling is exactly used without any approximation for label learning.},
  archive      = {J_JMIV},
  author       = {Zern, Artjom and Zisler, Matthias and Petra, Stefania and Schnörr, Christoph},
  doi          = {10.1007/s10851-019-00935-7},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {7},
  number       = {6},
  pages        = {982-1006},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Unsupervised assignment flow: Label learning on feature manifolds by spatially regularized geometric assignment},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multilayer joint segmentation using MRF and graph cuts.
<em>JMIV</em>, <em>62</em>(6), 961–981. (<a
href="https://doi.org/10.1007/s10851-019-00938-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of jointly segmenting objects, according to a set of labels (of cardinality L), from a set of images (of cardinality K) to produce K individual segmentations plus one joint segmentation, can be cast as a Markov random field model. Coupling terms in the considered energy function enforce the consistency between the individual segmentations and the joint segmentation. However, neither optimality on the minimizer (at least for particular cases), nor the sensitivity of the parameters, nor the robustness of this approach against standard ones has been clearly discussed before. This paper focuses on the case where $$L&gt;1$$ , $$K&gt;1$$ and the segmentation problem is handled using graph cuts. Noticeably, some properties of the considered energy function are demonstrated, such as global optimality when $$L=2$$ and $$K&gt;1$$ , the link with majority voting and the link with naive Bayes segmentation. Experiments on synthetic and real images depict superior segmentation performance and better robustness against noisy observations.},
  archive      = {J_JMIV},
  author       = {Lermé, Nicolas and Le Hégarat-Mascle, Sylvie and Malgouyres, François and Lachaize, Marie},
  doi          = {10.1007/s10851-019-00938-4},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {7},
  number       = {6},
  pages        = {961-981},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Multilayer joint segmentation using MRF and graph cuts},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stable backward diffusion models that minimise convex
energies. <em>JMIV</em>, <em>62</em>(6), 941–960. (<a
href="https://doi.org/10.1007/s10851-020-00976-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The inverse problem of backward diffusion is known to be ill-posed and highly unstable. Backward diffusion processes appear naturally in image enhancement and deblurring applications. It is therefore greatly desirable to establish a backward diffusion model which implements a smart stabilisation approach that can be used in combination with an easy-to-handle numerical scheme. So far, existing stabilisation strategies in the literature require sophisticated numerics to solve the underlying initial value problem. We derive a class of space-discrete one-dimensional backward diffusion as gradient descent of energies where we gain stability by imposing range constraints. Interestingly, these energies are even convex. Furthermore, we establish a comprehensive theory for the time-continuous evolution and we show that stability carries over to a simple explicit time discretisation of our model. Finally, we confirm the stability and usefulness of our technique in experiments in which we enhance the contrast of digital greyscale and colour images.},
  archive      = {J_JMIV},
  author       = {Bergerhoff, Leif and Cárdenas, Marcelo and Weickert, Joachim and Welk, Martin},
  doi          = {10.1007/s10851-020-00976-3},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {7},
  number       = {6},
  pages        = {941-960},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Stable backward diffusion models that minimise convex energies},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A proximal interior point algorithm with applications to
image processing. <em>JMIV</em>, <em>62</em>(6), 919–940. (<a
href="https://doi.org/10.1007/s10851-019-00916-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we introduce a new proximal interior point algorithm (PIPA). This algorithm is able to handle convex optimization problems involving various constraints where the objective function is the sum of a Lipschitz differentiable term and a possibly nonsmooth one. Each iteration of PIPA involves the minimization of a merit function evaluated for decaying values of a logarithmic barrier parameter. This inner minimization is performed thanks to a finite number of subiterations of a variable metric forward-backward method employing a line search strategy. The convergence of this latter step as well as the convergence the global method itself is analyzed. The numerical efficiency of the proposed approach is demonstrated in two image processing applications.},
  archive      = {J_JMIV},
  author       = {Chouzenoux, Emilie and Corbineau, Marie-Caroline and Pesquet, Jean-Christophe},
  doi          = {10.1007/s10851-019-00916-w},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {7},
  number       = {6},
  pages        = {919-940},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {A proximal interior point algorithm with applications to image processing},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Tensor factorization with total variation and tikhonov
regularization for low-rank tensor completion in imaging data.
<em>JMIV</em>, <em>62</em>(6), 900–918. (<a
href="https://doi.org/10.1007/s10851-019-00933-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main aim of this paper is to study tensor factorization for low-rank tensor completion in imaging data. Due to the underlying redundancy of real-world imaging data, the low-tubal-rank tensor factorization (the tensor–tensor product of two factor tensors) can be used to approximate such tensor very well. Motivated by the spatial/temporal smoothness of factor tensors in real-world imaging data, we propose to incorporate a hybrid regularization combining total variation and Tikhonov regularization into low-tubal-rank tensor factorization model for low-rank tensor completion problem. We also develop an efficient proximal alternating minimization (PAM) algorithm to tackle the corresponding minimization problem and establish a global convergence of the PAM algorithm. Numerical results on color images, color videos, and multispectral images are reported to illustrate the superiority of the proposed method over competing methods.},
  archive      = {J_JMIV},
  author       = {Lin, Xue-Lei and Ng, Michael K. and Zhao, Xi-Le},
  doi          = {10.1007/s10851-019-00933-9},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {7},
  number       = {6},
  pages        = {900-918},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Tensor factorization with total variation and tikhonov regularization for low-rank tensor completion in imaging data},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Crouzeix–raviart approximation of the total variation on
simplicial meshes. <em>JMIV</em>, <em>62</em>(6), 872–899. (<a
href="https://doi.org/10.1007/s10851-019-00939-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an adaptive implementation of a Crouzeix–Raviart-based discretization of the total variation, which has the property of approximating from below the total variation, with metrication errors only depending on the local curvature, rather than on the orientation as is usual for other approaches.},
  archive      = {J_JMIV},
  author       = {Chambolle, Antonin and Pock, Thomas},
  doi          = {10.1007/s10851-019-00939-3},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {7},
  number       = {6},
  pages        = {872-899},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Crouzeix–Raviart approximation of the total variation on simplicial meshes},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Testing that a local optimum of the likelihood is globally
optimum using reparameterized embeddings. <em>JMIV</em>, <em>62</em>(6),
858–871. (<a href="https://doi.org/10.1007/s10851-020-00979-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many mathematical imaging problems are posed as non-convex optimization problems. When numerically tractable global optimization procedures are not available, one is often interested in testing ex post facto whether or not a locally convergent algorithm has found the globally optimal solution. When the problem is formulated in terms of maximizing the likelihood function under a statistical model for the measurements, one can construct a statistical test that a local maximum is in fact the global maximum. A one-sided test is proposed for the case that the statistical model is a member of the generalized location family of probability distributions, a condition often satisfied in imaging and other inverse problems. We propose a general method for improving the accuracy of the test by reparameterizing the likelihood function to embed its domain into a higher-dimensional parameter space. We show that the proposed global maximum testing method results in improved accuracy and reduced computation for a physically motivated joint-inverse problem arising in camera-blur estimation.},
  archive      = {J_JMIV},
  author       = {LeBlanc, Joel W. and Thelen, Brian J. and Hero, Alfred O.},
  doi          = {10.1007/s10851-020-00979-0},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {7},
  number       = {6},
  pages        = {858-871},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Testing that a local optimum of the likelihood is globally optimum using reparameterized embeddings},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bregman itoh–abe methods for sparse optimisation.
<em>JMIV</em>, <em>62</em>(6), 842–857. (<a
href="https://doi.org/10.1007/s10851-020-00944-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose optimisation methods for variational regularisation problems based on discretising the inverse scale space flow with discrete gradient methods. Inverse scale space flow generalises gradient flows by incorporating a generalised Bregman distance as the underlying metric. Its discrete-time counterparts, Bregman iterations and linearised Bregman iterations are popular regularisation schemes for inverse problems that incorporate a priori information without loss of contrast. Discrete gradient methods are tools from geometric numerical integration for preserving energy dissipation of dissipative differential systems. The resultant Bregman discrete gradient methods are unconditionally dissipative and achieve rapid convergence rates by exploiting structures of the problem such as sparsity. Building on previous work on discrete gradients for non-smooth, non-convex optimisation, we prove convergence guarantees for these methods in a Clarke subdifferential framework. Numerical results for convex and non-convex examples are presented.},
  archive      = {J_JMIV},
  author       = {Benning, Martin and Riis, Erlend Skaldehaug and Schönlieb, Carola-Bibiane},
  doi          = {10.1007/s10851-020-00944-x},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {7},
  number       = {6},
  pages        = {842-857},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Bregman Itoh–Abe methods for sparse optimisation},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Non-convex total variation regularization for convex
denoising of signals. <em>JMIV</em>, <em>62</em>(6), 825–841. (<a
href="https://doi.org/10.1007/s10851-019-00937-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Total variation (TV) signal denoising is a popular nonlinear filtering method to estimate piecewise constant signals corrupted by additive white Gaussian noise. Following a ‘convex non-convex’ strategy, recent papers have introduced non-convex regularizers for signal denoising that preserve the convexity of the cost function to be minimized. In this paper, we propose a non-convex TV regularizer, defined using concepts from convex analysis, that unifies, generalizes, and improves upon these regularizers. In particular, we use the generalized Moreau envelope which, unlike the usual Moreau envelope, incorporates a matrix parameter. We describe a novel approach to set the matrix parameter which is essential for realizing the improvement we demonstrate. Additionally, we describe a new set of algorithms for non-convex TV denoising that elucidate the relationship among them and which build upon fast exact algorithms for classical TV denoising.},
  archive      = {J_JMIV},
  author       = {Selesnick, Ivan and Lanza, Alessandro and Morigi, Serena and Sgallari, Fiorella},
  doi          = {10.1007/s10851-019-00937-5},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {7},
  number       = {6},
  pages        = {825-841},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Non-convex total variation regularization for convex denoising of signals},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). New insights on the optimality conditions of the <span
class="math display"><em>ℓ</em><sub>2</sub> − <em>ℓ</em><sub>0</sub></span>
minimization problem. <em>JMIV</em>, <em>62</em>(6), 808–824. (<a
href="https://doi.org/10.1007/s10851-019-00917-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is devoted to the analysis of necessary (not sufficient) optimality conditions for the $$\ell _0$$ -regularized least-squares minimization problem. Such conditions are the roots of the plethora of algorithms that have been designed to cope with this NP-hard problem. Indeed, as global optimality is, in general, intractable, these algorithms only ensure the convergence to suboptimal points that verify some necessary optimality conditions. The degree of restrictiveness of these conditions is thus directly related to the performance of the algorithms. Within this context, our first goal is to provide a comprehensive review of commonly used necessary optimality conditions as well as known relationships between them. Then, we complete this hierarchy of conditions by proving new inclusion properties between the sets of candidate solutions associated with them. Moreover, we go one step further by providing a quantitative analysis of these sets. Finally, we report the results of a numerical experiment dedicated to the comparison of several algorithms with different optimality guaranties. In particular, this illustrates the fact that the performance of an algorithm is related to the restrictiveness of the optimality condition verified by the point it converges to.},
  archive      = {J_JMIV},
  author       = {Soubies, Emmanuel and Blanc-Féraud, Laure and Aubert, Gilles},
  doi          = {10.1007/s10851-019-00917-9},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {7},
  number       = {6},
  pages        = {808-824},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {New insights on the optimality conditions of the $$\ell _2-\ell _0$$ minimization problem},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A two-stage method for spectral–spatial classification of
hyperspectral images. <em>JMIV</em>, <em>62</em>(6), 790–807. (<a
href="https://doi.org/10.1007/s10851-019-00925-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel two-stage method for the classification of hyperspectral images. Pixel-wise classifiers, such as the classical support vector machine (SVM), consider spectral information only. As spatial information is not utilized, the classification results are not optimal and the classified image may appear noisy. Many existing methods, such as morphological profiles, superpixel segmentation, and composite kernels, exploit the spatial information. In this paper, we propose a two-stage approach inspired by image denoising and segmentation to incorporate the spatial information. In the first stage, SVMs are used to estimate the class probability for each pixel. In the second stage, a convex variant of the Mumford–Shah model is applied to each probability map to denoise and segment the image into different classes. Our proposed method effectively utilizes both spectral and spatial information of the data sets and is fast as only convex minimization is needed in addition to the SVMs. Experimental results on three widely utilized real hyperspectral data sets indicate that our method is very competitive in accuracy, timing, and the number of parameters when compared with current state-of-the-art methods, especially when the inter-class spectra are similar or the percentage of training pixels is reasonably high.},
  archive      = {J_JMIV},
  author       = {Chan, Raymond H. and Kan, Kelvin K. and Nikolova, Mila and Plemmons, Robert J.},
  doi          = {10.1007/s10851-019-00925-9},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {7},
  number       = {6},
  pages        = {790-807},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {A two-stage method for spectral–spatial classification of hyperspectral images},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A characterization of proximity operators. <em>JMIV</em>,
<em>62</em>(6), 773–789. (<a
href="https://doi.org/10.1007/s10851-020-00951-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We characterize proximity operators, that is to say functions that map a vector to a solution of a penalized least-squares optimization problem. Proximity operators of convex penalties have been widely studied and fully characterized by Moreau. They are also widely used in practice with nonconvex penalties such as the $$\ell ^0$$ pseudo-norm, yet the extension of Moreau’s characterization to this setting seemed to be a missing element of the literature. We characterize proximity operators of (convex or nonconvex) penalties as functions that are the subdifferential of some convex potential. This is proved as a consequence of a more general characterization of the so-called Bregman proximity operators of possibly nonconvex penalties in terms of certain convex potentials. As a side effect of our analysis, we obtain a test to verify whether a given function is the proximity operator of some penalty, or not. Many well-known shrinkage operators are indeed confirmed to be proximity operators. However, we prove that windowed Group-LASSO and persistent empirical Wiener shrinkage—two forms of a so-called social sparsity shrinkage—are generally not the proximity operator of any penalty; the exception is when they are simply weighted versions of group-sparse shrinkage with non-overlapping groups.},
  archive      = {J_JMIV},
  author       = {Gribonval, Rémi and Nikolova, Mila},
  doi          = {10.1007/s10851-020-00951-y},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {7},
  number       = {6},
  pages        = {773-789},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {A characterization of proximity operators},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Guest editorial: Special issue in memory of mila nikolova.
<em>JMIV</em>, <em>62</em>(6), 771–772. (<a
href="https://doi.org/10.1007/s10851-020-00981-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JMIV},
  author       = {Chan, Raymond H. and Cohen, Albert and Fadili, Jalal and Hero, Alfred and Steidl, Gabriele},
  doi          = {10.1007/s10851-020-00981-6},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {7},
  number       = {6},
  pages        = {771-772},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Guest editorial: Special issue in memory of mila nikolova},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stochastic distance transform: Theory, algorithms and
applications. <em>JMIV</em>, <em>62</em>(5), 751–769. (<a
href="https://doi.org/10.1007/s10851-020-00964-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distance transforms (DTs) are standard tools in image analysis, with applications in image registration and segmentation. The DT is based on extremal (minimal) distance values and is therefore highly sensitive to noise. We present a stochastic distance transform (SDT) based on discrete random sets, in which a model of element-wise probability is utilized and the SDT is computed as the first moment of the distance distribution to the random set. We present two methods for computing the SDT and analyze them w.r.t. accuracy and complexity. Further, we propose a method, utilizing kernel density estimation, for estimating probability functions and associated random sets to use with the SDT. We evaluate the accuracy of the SDT and the proposed framework on images of thin line structures and disks corrupted by salt and pepper noise and observe excellent performance. We also insert the SDT into a segmentation framework and apply it to overlapping objects, where it provides substantially improved performance over previous methods. Finally, we evaluate the SDT and observe very good performance, on simulated images from localization microscopy, a state-of-the-art super-resolution microscopy technique which yields highly spatially localized but noisy point-clouds.},
  archive      = {J_JMIV},
  author       = {Öfverstedt, Johan and Lindblad, Joakim and Sladoje, Nataša},
  doi          = {10.1007/s10851-020-00964-7},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {6},
  number       = {5},
  pages        = {751-769},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Stochastic distance transform: Theory, algorithms and applications},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Two polynomial time graph labeling algorithms optimizing
max-norm-based objective functions. <em>JMIV</em>, <em>62</em>(5),
737–750. (<a href="https://doi.org/10.1007/s10851-020-00963-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many problems in applied computer science can be expressed in a graph setting and solved by finding an appropriate vertex labeling of the associated graph. It is also common to identify the term “appropriate labeling” with a labeling that optimizes some application-motivated objective function. The goal of this work is to present two algorithms that, for the objective functions in a general format motivated by image processing tasks, find such optimal labelings. Specifically, we consider a problem of finding an optimal binary labeling for the objective function defined as the max-norm over a set of local costs of a form that naturally appears in image processing. It is well known that for a limited subclass of such problems, globally optimal solutions can be found via watershed cuts, that is, by the cuts associated with the optimal spanning forests of a graph. Here, we propose two new algorithms for optimizing a broader class of such problems. The first algorithm, that works for all considered objective functions, returns a globally optimal labeling in quadratic time with respect to the size of the graph (i.e., the number of its vertices and edges) or, for an image associated graph, the size of the image. The second algorithm is more efficient, with quasi-linear time complexity, and returns a globally optimal labeling provided that the objective function satisfies certain given conditions. These conditions are analogous to the submodularity conditions encountered in max-flow/min-cut optimization, where the objective function is defined as sum of all local costs. We will also consider a refinement of the max-norm measure, defined in terms of the lexicographical order, and examine the algorithms that could find minimal labelings with respect to this refined measure.},
  archive      = {J_JMIV},
  author       = {Malmberg, Filip and Ciesielski, Krzysztof Chris},
  doi          = {10.1007/s10851-020-00963-8},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {6},
  number       = {5},
  pages        = {737-750},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Two polynomial time graph labeling algorithms optimizing max-norm-based objective functions},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An optimized framework for plane-probing algorithms.
<em>JMIV</em>, <em>62</em>(5), 718–736. (<a
href="https://doi.org/10.1007/s10851-020-00965-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A plane-probing algorithm computes the normal vector of a digital plane from a starting point and a predicate “Is a point $${x}$$ in the digital plane?”. This predicate is used to probe the digital plane as locally as possible and decide on the fly the next points to consider. However, several existing plane-probing algorithms return the correct normal vector only for some specific starting points and an approximation otherwise, e.g., the H- and R-algorithm proposed in Lachaud et al. (J Math Imaging Vis 59(1):23–39, 2017). In this paper, we present a general framework for these plane-probing algorithms that provides a way of retrieving the correct normal vector from any starting point, while keeping their main features. There are $$O(\omega \log \omega )$$ calls to the predicate in the worst-case scenario, where $$\omega $$ is the thickness of the underlying digital plane, but far fewer calls are experimentally observed on average. In the context of digital surface analysis, the resulting algorithm is expected to be of great interest for normal estimation and shape reconstruction.},
  archive      = {J_JMIV},
  author       = {Lachaud, Jacques-Olivier and Meyron, Jocelyn and Roussillon, Tristan},
  doi          = {10.1007/s10851-020-00965-6},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {6},
  number       = {5},
  pages        = {718-736},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {An optimized framework for plane-probing algorithms},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Filtration simplification for persistent homology via edge
contraction. <em>JMIV</em>, <em>62</em>(5), 704–717. (<a
href="https://doi.org/10.1007/s10851-020-00956-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Persistent homology is a popular data analysis technique that is used to capture the changing homology of an indexed sequence of simplicial complexes. These changes are summarized in persistence diagrams. A natural problem is to contract edges in complexes in the initial sequence to obtain a sequence of simplified complexes while controlling the perturbation between the original and simplified persistence diagrams. This paper is an extended version of Dey and Slechta (in: Discrete geometry for computer imagery, Springer, New York, 2019), where we developed two contraction operators for the case where the initial sequence is a filtration. In addition to the content in the original version, this paper presents proofs relevant to the filtration case and develops contraction operators for towers and multiparameter filtrations.},
  archive      = {J_JMIV},
  author       = {Dey, Tamal K. and Slechta, Ryan},
  doi          = {10.1007/s10851-020-00956-7},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {6},
  number       = {5},
  pages        = {704-717},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Filtration simplification for persistent homology via edge contraction},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficiently testing digital convexity and recognizing
digital convex polygons. <em>JMIV</em>, <em>62</em>(5), 693–703. (<a
href="https://doi.org/10.1007/s10851-020-00957-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A set $$S \subset \mathbb {Z}^2$$ of integer points is digital convex if $${{\,\mathrm{conv}\,}}(S) \cap \mathbb {Z}^2 = S$$ , where $${{\,\mathrm{conv}\,}}(S)$$ denotes the convex hull of S. In this paper, we consider the following two problems. The first one is to test whether a given set S of n lattice points is digital convex. If the answer to the first problem is positive, then the second problem is to find a polygon $$P\subset \mathbb {Z}^2$$ with minimum number of edges and whose intersection with the lattice $$P\cap \mathbb {Z}^2$$ is exactly S. We provide linear-time algorithms for these two problems. The algorithm is based on the well-known quickhull algorithm. The time to solve both problems is $$O(n + h \log r) = O(n + n^{1/3} \log r)$$ , where $$h = \min (|{{\,\mathrm{conv}\,}}(S)|, n^{1/3})$$ and r is the diameter of S.},
  archive      = {J_JMIV},
  author       = {Crombez, Loïc and Fonseca, Guilherme D. da and Gerard, Yan},
  doi          = {10.1007/s10851-020-00957-6},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {6},
  number       = {5},
  pages        = {693-703},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Efficiently testing digital convexity and recognizing digital convex polygons},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Local turn-boundedness: A curvature control for continuous
curves with application to digitization. <em>JMIV</em>, <em>62</em>(5),
673–692. (<a href="https://doi.org/10.1007/s10851-020-00952-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article focuses on the classical problem of the control of information loss during the digitization step. The properties proposed in the literature rely on smoothness hypotheses that are not satisfied by the curves including angular points. The notion of turn introduced by Milnor in the article On the Total Curvature of Knots generalizes the notion of integral curvature to continuous curves. Thanks to the turn, we are able to define the local turn-boundedness. This promising property of curves does not require smoothness hypotheses and shares several properties with the par(r)-regularity, in particular well-composed digitizations. Besides, the local turn-boundedness enables to constrain spatially the continuous curve as a function of its digitization.},
  archive      = {J_JMIV},
  author       = {Le Quentrec, Étienne and Mazo, Loïc and Baudrier, Étienne and Tajine, Mohamed},
  doi          = {10.1007/s10851-020-00952-x},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {6},
  number       = {5},
  pages        = {673-692},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Local turn-boundedness: A curvature control for continuous curves with application to digitization},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimum cuts in graphs by general fuzzy connectedness with
local band constraints. <em>JMIV</em>, <em>62</em>(5), 659–672. (<a
href="https://doi.org/10.1007/s10851-020-00953-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of this work is to describe an efficient algorithm for finding a binary segmentation of an image such that the indicated object satisfies a novel high-level prior, called local band, LB, constraint; the returned segmentation is optimal, with respect to an appropriate graph-cut measure, among all segmentations satisfying the given LB constraint. The new algorithm has two stages: expanding the number of edges of a standard edge-weighted graph of an image; applying to this new weighted graph an algorithm known as an oriented image foresting transform, OIFT. In our theoretical investigation, we prove that OIFT algorithm belongs to a class of general fuzzy connectedness algorithms and so has several good theoretical properties, like robustness for seed placement. The extension of the graph constructed in the first stage ensures, as we prove, that the resulted object indeed satisfies the given LB constraint. We also notice that this graph construction is flexible enough to allow combining it with other high-level constraints. Finally, we experimentally demonstrate that the LB constraint gives competitive results as compared to geodesic star convexity, boundary band, and hedgehog shape prior, all implemented within OIFT framework and applied to various scenarios involving natural and medical images.},
  archive      = {J_JMIV},
  author       = {de Moraes Braz, Caio and Miranda, Paulo A. V. and Ciesielski, Krzysztof Chris and Cappabianco, Fábio A. M.},
  doi          = {10.1007/s10851-020-00953-w},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {6},
  number       = {5},
  pages        = {659-672},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Optimum cuts in graphs by general fuzzy connectedness with local band constraints},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Characterization of graph-based hierarchical watersheds:
Theory and algorithms. <em>JMIV</em>, <em>62</em>(5), 627–658. (<a
href="https://doi.org/10.1007/s10851-019-00936-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Watershed is a well-established clustering and segmentation method. In this article, we aim to achieve a better theoretical understanding of the hierarchical version of the watershed operator. More precisely, we propose a characterization of hierarchical watersheds in the framework of edge-weighted graphs. The proposed characterization leads to an efficient algorithm to recognize hierarchical watersheds.},
  archive      = {J_JMIV},
  author       = {Santana Maia, Deise and Cousty, Jean and Najman, Laurent and Perret, Benjamin},
  doi          = {10.1007/s10851-019-00936-6},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {6},
  number       = {5},
  pages        = {627-658},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Characterization of graph-based hierarchical watersheds: Theory and algorithms},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Guest editorial: Special issue on discrete geometry for
computer imagery. <em>JMIV</em>, <em>62</em>(5), 625–626. (<a
href="https://doi.org/10.1007/s10851-020-00971-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JMIV},
  author       = {Couprie, Michel and Cousty, Jean and Kenmochi, Yukiko and Coeurjolly, David},
  doi          = {10.1007/s10851-020-00971-8},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {6},
  number       = {5},
  pages        = {625-626},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Guest editorial: Special issue on discrete geometry for computer imagery},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). New set of non-separable orthogonal invariant moments for
image recognition. <em>JMIV</em>, <em>62</em>(4), 606–624. (<a
href="https://doi.org/10.1007/s10851-020-00948-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is known that the rotation, scaling and translation invariant property of image moments has a high significance in image recognition. For this reason, the seven invariant moments presented by Hu are widely used in the field of image analysis. These moments are of finite order; therefore, they do not comprise a complete set of image descriptors. For this reason, we introduce in this paper another series of invariant moments of infinite order, which are based on normalized central moments. The non-orthogonal property of these moments causes the redundancy of information. To overcome this problem, we propose a new construction technique of non-separable orthogonal polynomials in two variables based on a recurrence formula and we present a new set of orthogonal moments, which are invariant to translation, scaling and rotation. The presented approaches are tested in several well-known computer vision datasets including moment’s invariability, image retrieval and classification of objects, this latter based on fuzzy K-means clustering algorithm. The performance of these invariant moments for classification and image retrieval is compared with some recent invariant moments such as invariants of multi-channel orthogonal radial-substituted Chebyshev moments, invariants of quaternion radial-substituted Chebyshev moments, invariants of rotational moments in Radon space and Legendre–Fourier moments in Radon space. The experimental results made using four databases of images, namely Columbia Object Image Library (COIL-20) database, MPEG7-CE shape database, COIL-100 database and ORL database, show that our orthogonal invariant moments have done better than the other descriptors tested.},
  archive      = {J_JMIV},
  author       = {Hjouji, Amal and EL-Mekkaoui, Jaouad and Jourhmane, Mostafa and Bouikhalene, Belaid},
  doi          = {10.1007/s10851-020-00948-7},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {5},
  number       = {4},
  pages        = {606-624},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {New set of non-separable orthogonal invariant moments for image recognition},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Screen-light decomposition framework for point-of-gaze
estimation using a single uncalibrated camera and multiple light
sources. <em>JMIV</em>, <em>62</em>(4), 585–605. (<a
href="https://doi.org/10.1007/s10851-020-00947-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of a single uncalibrated camera is desirable for eye tracking to reduce the overall complexity and cost of the system. Quite often, at least one external light source is used to enhance image quality and generate a corneal reflection used as a reference point to estimate the point-of-gaze (PoG). Though the use of more than one light source has shown to enhance accuracy and robustness to head motion, it is unlikely that all corneal reflections appear in the eye images during natural eye movements. In this paper, we introduce the Screen-Light Decomposition (SLD) framework as a generalized model for PoG estimation using a single uncalibrated camera and a variable number of light sources. SLD synthesizes existing uncalibrated video-based eye trackers and can be used as a modeling tool to compare and design eye trackers. We have used the framework to design a novel eye-tracking technique, called SAGE, for single normalized space adaptive gaze estimation, that can gracefully degrade the gaze tracker performance when one or more corneal reflections are not detected, even during the calibration procedure. Results from an user experiment are presented to demonstrate its improved performance over other designs.},
  archive      = {J_JMIV},
  author       = {Morimoto, Carlos H. and Coutinho, Flávio L. and Hansen, Dan W.},
  doi          = {10.1007/s10851-020-00947-8},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {5},
  number       = {4},
  pages        = {585-605},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Screen-light decomposition framework for point-of-gaze estimation using a single uncalibrated camera and multiple light sources},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Generalized visual information analysis via tensorial
algebra. <em>JMIV</em>, <em>62</em>(4), 560–584. (<a
href="https://doi.org/10.1007/s10851-020-00946-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-order data are modeled using matrices whose entries are numerical arrays of a fixed size. These arrays, called t-scalars, form a commutative ring under the convolution product. Matrices with elements in the ring of t-scalars are referred to as t-matrices. The t-matrices can be scaled, added and multiplied in the usual way. There are t-matrix generalizations of positive matrices, orthogonal matrices and Hermitian symmetric matrices. With the t-matrix model, it is possible to generalize many well-known matrix algorithms. In particular, the t-matrices are used to generalize the singular value decomposition (SVD), high-order SVD (HOSVD), principal component analysis (PCA), two-dimensional PCA (2DPCA) and Grassmannian component analysis (GCA). The generalized t-matrix algorithms, namely TSVD, THOSVD, TPCA, T2DPCA and TGCA, are applied to low-rank approximation, reconstruction and supervised classification of images. Experiments show that the t-matrix algorithms compare favorably with standard matrix algorithms.},
  archive      = {J_JMIV},
  author       = {Liao, Liang and Maybank, Stephen John},
  doi          = {10.1007/s10851-020-00946-9},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {5},
  number       = {4},
  pages        = {560-584},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Generalized visual information analysis via tensorial algebra},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Geodesic analysis in kendall’s shape space with
epidemiological applications. <em>JMIV</em>, <em>62</em>(4), 549–559.
(<a href="https://doi.org/10.1007/s10851-020-00945-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analytically determine Jacobi fields and parallel transports and compute geodesic regression in Kendall’s shape space. Using the derived expressions, we can fully leverage the geometry via Riemannian optimization and thereby reduce the computational expense by several orders of magnitude over common, nonlinear constrained approaches. The methodology is demonstrated by performing a longitudinal statistical analysis of epidemiological shape data. As an example application, we have chosen 3D shapes of knee bones, reconstructed from image data of the Osteoarthritis Initiative. Comparing subject groups with incident and developing osteoarthritis versus normal controls, we find clear differences in the temporal development of femur shapes. This paves the way for early prediction of incident knee osteoarthritis, using geometry data alone.},
  archive      = {J_JMIV},
  author       = {Nava-Yazdani, Esfandiar and Hege, Hans-Christian and Sullivan, T. J. and von Tycowicz, Christoph},
  doi          = {10.1007/s10851-020-00945-w},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {5},
  number       = {4},
  pages        = {549-559},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Geodesic analysis in kendall’s shape space with epidemiological applications},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Nonlocal elastica model for sparse reconstruction.
<em>JMIV</em>, <em>62</em>(4), 532–548. (<a
href="https://doi.org/10.1007/s10851-019-00943-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In view of the exceptional ability of curvature in connecting missing edges and structures, we propose novel sparse reconstruction models via the Euler’s elastica energy. In particular, we firstly extend the Euler’s elastica regularity into the nonlocal formulation to fully take the advantages of the pattern redundancy and structural similarity in image data. Due to its non-convexity, non-smoothness and nonlinearity, we regard both local and nonlocal elastica functional as the weighted total variation for a good trade-off between the runtime complexity and performance. The splitting techniques and alternating direction method of multipliers (ADMM) are used to achieve efficient algorithms, the convergence of which is also discussed under certain assumptions. The weighting function occurred in our model can be well estimated according to the local approach. Numerical experiments demonstrate that our nonlocal elastica model achieves the state-of-the-art reconstruction results for different sampling patterns and sampling ratios, especially when the sampling rate is extremely low.},
  archive      = {J_JMIV},
  author       = {Yan, Mengyuan and Duan, Yuping},
  doi          = {10.1007/s10851-019-00943-7},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {5},
  number       = {4},
  pages        = {532-548},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Nonlocal elastica model for sparse reconstruction},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Denoising color images based on local orientation estimation
and CNN classifier. <em>JMIV</em>, <em>62</em>(4), 505–531. (<a
href="https://doi.org/10.1007/s10851-019-00942-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A structure-adaptive vector filter for removal of impulse noise from color images is presented. The proposed method is based on local orientation estimation. A color image is represented in quaternion form, and then, quaternion Fourier transform is used to compute the orientation of the pattern in a local neighborhood. Since the computation in quaternion frequency domain is extremely time-consuming, we prove a theorem that the integral of the product of frequency variables and the magnitude of quaternion frequency signals can be computed directly in spatial domain, which results that the color orientation detection problem can be solved in spatial domain. Based on the local orientation and orientation strength, the size, shape, and orientation of the support window of vector median filter (VMF) are adaptively determined, leading to an effective structure-adaptive VMF. Unlike the classical VMF restricting the output to the existing color samples, this paper computes the output of VMF over the entire 3D data space, which boosts the filtering performance effectively. To further improve denoising effect, a deep convolutional neural network is employed to detect impulse noise in color images and integrated into the proposed denoising framework. The experimental results exhibit the effectiveness of the proposed denoiser by showing significant performance improvements both in noise suppression and in detail preservation, compared to other color image denoising methods.},
  archive      = {J_JMIV},
  author       = {Jin, Lianghai and Song, Enmin and Zhang, Wenhua},
  doi          = {10.1007/s10851-019-00942-8},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {5},
  number       = {4},
  pages        = {505-531},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Denoising color images based on local orientation estimation and CNN classifier},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A projection-based method for shape measurement.
<em>JMIV</em>, <em>62</em>(4), 489–504. (<a
href="https://doi.org/10.1007/s10851-019-00932-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work addresses two main contributions for shape measurement: First, a new circularity measure for planar shapes is introduced based on their geometrical properties in the projection space of Radon transform. Second, a general-purpose evaluation criterion, power of discrimination, for assessing the efficiency of a shape measure is proposed. The new measure ranges over the interval [0, 1] and produces the value 1 if and only if the measured shape is a perfect circle. The proposed measure is invariant with respect to translation, rotation and scaling transformations. Moreover, it is also robust against border distortion of shapes. It is theoretically well founded and can be extended to other problems of shape measurement. Our approach can deal with complex shapes composed of connected components that cannot be handled by classical contour-based methods. Several experiments show its good behavior and demonstrate the efficiency and applicability of our proposed measure. Finally, we also consider our proposed evaluation criterion for assessing different circularity measures.},
  archive      = {J_JMIV},
  author       = {Nguyen, Thanh Phuong and Nguyen, Xuan Son and Borgi, Mohamed Anouar and Nguyen, M. K.},
  doi          = {10.1007/s10851-019-00932-w},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {5},
  number       = {4},
  pages        = {489-504},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {A projection-based method for shape measurement},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Networks for nonlinear diffusion problems in imaging.
<em>JMIV</em>, <em>62</em>(3), 471–487. (<a
href="https://doi.org/10.1007/s10851-019-00901-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A multitude of imaging and vision tasks have seen recently a major transformation by deep learning methods and in particular by the application of convolutional neural networks. These methods achieve impressive results, even for applications where it is not apparent that convolutions are suited to capture the underlying physics. In this work, we develop a network architecture based on nonlinear diffusion processes, named DiffNet. By design, we obtain a nonlinear network architecture that is well suited for diffusion-related problems in imaging. Furthermore, the performed updates are explicit, by which we obtain better interpretability and generalisability compared to classical convolutional neural network architectures. The performance of DiffNet is tested on the inverse problem of nonlinear diffusion with the Perona–Malik filter on the STL-10 image dataset. We obtain competitive results to the established U-Net architecture, with a fraction of parameters and necessary training data.},
  archive      = {J_JMIV},
  author       = {Arridge, S. and Hauptmann, A.},
  doi          = {10.1007/s10851-019-00901-3},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {4},
  number       = {3},
  pages        = {471-487},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Networks for nonlinear diffusion problems in imaging},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Regularization by architecture: A deep prior approach for
inverse problems. <em>JMIV</em>, <em>62</em>(3), 456–470. (<a
href="https://doi.org/10.1007/s10851-019-00923-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present paper studies so-called deep image prior (DIP) techniques in the context of ill-posed inverse problems. DIP networks have been recently introduced for applications in image processing; also first experimental results for applying DIP to inverse problems have been reported. This paper aims at discussing different interpretations of DIP and to obtain analytic results for specific network designs and linear operators. The main contribution is to introduce the idea of viewing these approaches as the optimization of Tikhonov functionals rather than optimizing networks. Besides theoretical results, we present numerical verifications.},
  archive      = {J_JMIV},
  author       = {Dittmer, Sören and Kluth, Tobias and Maass, Peter and Otero Baguer, Daniel},
  doi          = {10.1007/s10851-019-00923-x},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {4},
  number       = {3},
  pages        = {456-470},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Regularization by architecture: A deep prior approach for inverse problems},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Big in japan: Regularizing networks for solving inverse
problems. <em>JMIV</em>, <em>62</em>(3), 445–455. (<a
href="https://doi.org/10.1007/s10851-019-00911-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning and (deep) neural networks are emerging tools to address inverse problems and image reconstruction tasks. Despite outstanding performance, the mathematical analysis for solving inverse problems by neural networks is mostly missing. In this paper, we introduce and rigorously analyze families of deep regularizing neural networks (RegNets) of the form $$\mathbf {B}_\alpha + \mathbf {N}_{\theta (\alpha )} \mathbf {B}_\alpha $$, where $$\mathbf {B}_\alpha $$ is a classical regularization and the network $$\mathbf {N}_{\theta (\alpha )} \mathbf {B}_\alpha $$ is trained to recover the missing part $${\text {Id}}_X - \mathbf {B}_\alpha $$ not found by the classical regularization. We show that these regularizing networks yield a convergent regularization method for solving inverse problems. Additionally, we derive convergence rates (quantitative error estimates) assuming a sufficient decay of the associated distance function. We demonstrate that our results recover existing convergence and convergence rates results for filter-based regularization methods as well as the recently introduced null space network as special cases. Numerical results are presented for a tomographic sparse data problem, which clearly demonstrate that the proposed RegNets improve classical regularization as well as the null space network.},
  archive      = {J_JMIV},
  author       = {Schwab, Johannes and Antholzer, Stephan and Haltmeier, Markus},
  doi          = {10.1007/s10851-019-00911-1},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {4},
  number       = {3},
  pages        = {445-455},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Big in japan: Regularizing networks for solving inverse problems},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A convex variational model for learning convolutional image
atoms from incomplete data. <em>JMIV</em>, <em>62</em>(3), 417–444. (<a
href="https://doi.org/10.1007/s10851-019-00919-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A variational model for learning convolutional image atoms from corrupted and/or incomplete data is introduced and analyzed both in function space and numerically. Building on lifting and relaxation strategies, the proposed approach is convex and allows for simultaneous image reconstruction and atom learning in a general, inverse problems context. Further, motivated by an improved numerical performance, also a semi-convex variant is included in the analysis and the experiments of the paper. For both settings, fundamental analytical properties allowing in particular to ensure well-posedness and stability results for inverse problems are proven in a continuous setting. Exploiting convexity, globally optimal solutions are further computed numerically for applications with incomplete, noisy and blurry data and numerical results are shown.},
  archive      = {J_JMIV},
  author       = {Chambolle, A. and Holler, M. and Pock, T.},
  doi          = {10.1007/s10851-019-00919-7},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {4},
  number       = {3},
  pages        = {417-444},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {A convex variational model for learning convolutional image atoms from incomplete data},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Variational networks: An optimal control approach to early
stopping variational methods for image restoration. <em>JMIV</em>,
<em>62</em>(3), 396–416. (<a
href="https://doi.org/10.1007/s10851-019-00926-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate a well-known phenomenon of variational approaches in image processing, where typically the best image quality is achieved when the gradient flow process is stopped before converging to a stationary point. This paradox originates from a tradeoff between optimization and modeling errors of the underlying variational model and holds true even if deep learning methods are used to learn highly expressive regularizers from data. In this paper, we take advantage of this paradox and introduce an optimal stopping time into the gradient flow process, which in turn is learned from data by means of an optimal control approach. After a time discretization, we obtain variational networks, which can be interpreted as a particular type of recurrent neural networks. The learned variational networks achieve competitive results for image denoising and image deblurring on a standard benchmark data set. One of the key theoretical results is the development of first- and second-order conditions to verify optimal stopping time. A nonlinear spectral analysis of the gradient of the learned regularizer gives enlightening insights into the different regularization properties.},
  archive      = {J_JMIV},
  author       = {Effland, Alexander and Kobler, Erich and Kunisch, Karl and Pock, Thomas},
  doi          = {10.1007/s10851-019-00926-8},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {4},
  number       = {3},
  pages        = {396-416},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Variational networks: An optimal control approach to early stopping variational methods for image restoration},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Correction to: On orthogonal projections for dimension
reduction and applications in augmented target loss functions for
learning problems. <em>JMIV</em>, <em>62</em>(3), 395. (<a
href="https://doi.org/10.1007/s10851-019-00927-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The article was originally published by the journal with an incorrect title.},
  archive      = {J_JMIV},
  author       = {Breger, A. and Orlando, J. I. and Harar, P. and Dörfler, M. and Klimscha, S. and Grechenig, C. and Gerendas, B. S. and Schmidt-Erfurth, U. and Ehler, M.},
  doi          = {10.1007/s10851-019-00927-7},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {4},
  number       = {3},
  pages        = {395},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Correction to: On orthogonal projections for dimension reduction and applications in augmented target loss functions for learning problems},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). On orthogonal projections for dimension reduction and
applications in augmented target loss functions for learning problems.
<em>JMIV</em>, <em>62</em>(3), 376–394. (<a
href="https://doi.org/10.1007/s10851-019-00902-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of orthogonal projections on high-dimensional input and target data in learning frameworks is studied. First, we investigate the relations between two standard objectives in dimension reduction, preservation of variance and of pairwise relative distances. Investigations of their asymptotic correlation as well as numerical experiments show that a projection does usually not satisfy both objectives at once. In a standard classification problem, we determine projections on the input data that balance the objectives and compare subsequent results. Next, we extend our application of orthogonal projections to deep learning tasks and introduce a general framework of augmented target loss functions. These loss functions integrate additional information via transformations and projections of the target data. In two supervised learning problems, clinical image segmentation and music information classification, the application of our proposed augmented target loss functions increases the accuracy.},
  archive      = {J_JMIV},
  author       = {Breger, A. and Orlando, J. I. and Harar, P. and Dörfler, M. and Klimscha, S. and Grechenig, C. and Gerendas, B. S. and Schmidt-Erfurth, U. and Ehler, M.},
  doi          = {10.1007/s10851-019-00902-2},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {4},
  number       = {3},
  pages        = {376-394},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {On orthogonal projections for dimension reduction and applications in augmented target loss functions for learning problems},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Residual networks as flows of diffeomorphisms.
<em>JMIV</em>, <em>62</em>(3), 365–375. (<a
href="https://doi.org/10.1007/s10851-019-00890-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the understanding and characterization of residual networks (ResNet), which are among the state-of-the-art deep learning architectures for a variety of supervised learning problems. We focus on the mapping component of ResNets, which map the embedding space toward a new unknown space where the prediction or classification can be stated according to linear criteria. We show that this mapping component can be regarded as the numerical implementation of continuous flows of diffeomorphisms governed by ordinary differential equations. In particular, ResNets with shared weights are fully characterized as numerical approximation of exponential diffeomorphic operators. We stress both theoretically and numerically the relevance of the enforcement of diffeomorphic properties and the importance of numerical issues to make consistent the continuous formulation and the discretized ResNet implementation. We further discuss the resulting theoretical and computational insights into ResNet architectures.},
  archive      = {J_JMIV},
  author       = {Rousseau, François and Drumetz, Lucas and Fablet, Ronan},
  doi          = {10.1007/s10851-019-00890-3},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {4},
  number       = {3},
  pages        = {365-375},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Residual networks as flows of diffeomorphisms},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep neural networks motivated by partial differential
equations. <em>JMIV</em>, <em>62</em>(3), 352–364. (<a
href="https://doi.org/10.1007/s10851-019-00903-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial differential equations (PDEs) are indispensable for modeling many physical phenomena and also commonly used for solving image processing tasks. In the latter area, PDE-based approaches interpret image data as discretizations of multivariate functions and the output of image processing algorithms as solutions to certain PDEs. Posing image processing problems in the infinite-dimensional setting provides powerful tools for their analysis and solution. For the last few decades, the reinterpretation of classical image processing problems through the PDE lens has been creating multiple celebrated approaches that benefit a vast area of tasks including image segmentation, denoising, registration, and reconstruction. In this paper, we establish a new PDE interpretation of a class of deep convolutional neural networks (CNN) that are commonly used to learn from speech, image, and video data. Our interpretation includes convolution residual neural networks (ResNet), which are among the most promising approaches for tasks such as image classification having improved the state-of-the-art performance in prestigious benchmark challenges. Despite their recent successes, deep ResNets still face some critical challenges associated with their design, immense computational costs and memory requirements, and lack of understanding of their reasoning. Guided by well-established PDE theory, we derive three new ResNet architectures that fall into two new classes: parabolic and hyperbolic CNNs. We demonstrate how PDE theory can provide new insights and algorithms for deep learning and demonstrate the competitiveness of three new CNN architectures using numerical experiments.},
  archive      = {J_JMIV},
  author       = {Ruthotto, Lars and Haber, Eldad},
  doi          = {10.1007/s10851-019-00903-1},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {4},
  number       = {3},
  pages        = {352-364},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Deep neural networks motivated by partial differential equations},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Forward stability of ResNet and its variants. <em>JMIV</em>,
<em>62</em>(3), 328–351. (<a
href="https://doi.org/10.1007/s10851-019-00922-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The residual neural network (ResNet) is a popular deep network architecture which has the ability to obtain high-accuracy results on several image processing problems. In order to analyze the behavior and structure of ResNet, recent work has been on establishing connections between ResNets and continuous-time optimal control problems. In this work, we show that the post-activation ResNet is related to an optimal control problem with differential inclusions and provide continuous-time stability results for the differential inclusion associated with ResNet. Motivated by the stability conditions, we show that alterations of either the architecture or the optimization problem can generate variants of ResNet which improves the theoretical stability bounds. In addition, we establish stability bounds for the full (discrete) network associated with two variants of ResNet, in particular, bounds on the growth of the features and a measure of the sensitivity of the features with respect to perturbations. These results also help to show the relationship between the depth, regularization, and stability of the feature space. Computational experiments on the proposed variants show that the accuracy of ResNet is preserved and that the accuracy seems to be monotone with respect to the depth and various corruptions.},
  archive      = {J_JMIV},
  author       = {Zhang, Linan and Schaeffer, Hayden},
  doi          = {10.1007/s10851-019-00922-y},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {4},
  number       = {3},
  pages        = {328-351},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Forward stability of ResNet and its variants},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adversarial noise attacks of deep learning architectures:
Stability analysis via sparse-modeled signals. <em>JMIV</em>,
<em>62</em>(3), 313–327. (<a
href="https://doi.org/10.1007/s10851-019-00913-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite their impressive performance, deep convolutional neural networks (CNN) have been shown to be sensitive to small adversarial perturbations. These nuisances, which one can barely notice, are powerful enough to fool sophisticated and well performing classifiers, leading to ridiculous misclassification results. In this paper, we analyze the stability of state-of-the-art deep learning classification machines to adversarial perturbations, where we assume that the signals belong to the (possibly multilayer) sparse representation model. We start with convolutional sparsity and then proceed to its multilayered version, which is tightly connected to CNN. Our analysis links between the stability of the classification to noise and the underlying structure of the signal, quantified by the sparsity of its representation under a fixed dictionary. In addition, we offer similar stability theorems for two practical pursuit algorithms, which are posed as two different deep learning architectures—the layered thresholding and the layered basis pursuit. Our analysis establishes the better robustness of the later to adversarial attacks. We corroborate these theoretical results by numerical experiments on three datasets: MNIST, CIFAR-10 and CIFAR-100.},
  archive      = {J_JMIV},
  author       = {Romano, Yaniv and Aberdam, Aviad and Sulam, Jeremias and Elad, Michael},
  doi          = {10.1007/s10851-019-00913-z},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {4},
  number       = {3},
  pages        = {313-327},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Adversarial noise attacks of deep learning architectures: Stability analysis via sparse-modeled signals},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Processing simple geometric attributes with autoencoders.
<em>JMIV</em>, <em>62</em>(3), 293–312. (<a
href="https://doi.org/10.1007/s10851-019-00924-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image synthesis is a core problem in modern deep learning, and many recent architectures such as autoencoders and generative adversarial networks produce spectacular results on highly complex data, such as images of faces or landscapes. While these results open up a wide range of new, advanced synthesis applications, there is also a severe lack of theoretical understanding of how these networks work. This results in a wide range of practical problems, such as difficulties in training, the tendency to sample images with little or no variability and generalization problems. In this paper, we propose to analyze the ability of the simplest generative network, the autoencoder, to encode and decode two simple geometric attributes: size and position. We believe that, in order to understand more complicated tasks, it is necessary to first understand how these networks process simple attributes. For the first property, we analyze the case of images of centered disks with variable radii. We explain how the autoencoder projects these images to and from a latent space of smallest possible dimension, a scalar. In particular, we describe both the encoding process and a closed-form solution to the decoding training problem in a network without biases and shows that during training, the network indeed finds this solution. We then investigate the best regularization approaches which yield networks that generalize well. For the second property, position, we look at the encoding and decoding of Dirac delta functions, also known as “one-hot” vectors. We describe a handcrafted filter that achieves encoding perfectly and show that the network naturally finds this filter during training. We also show experimentally that the decoding can be achieved if the dataset is sampled in an appropriate manner. We hope that the insights given here will provide better understanding of the precise mechanisms used by generative networks and will ultimately contribute to producing more robust and generalizable networks.},
  archive      = {J_JMIV},
  author       = {Newson, Alasdair and Almansa, Andrés and Gousseau, Yann and Ladjal, Saïd},
  doi          = {10.1007/s10851-019-00924-w},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {4},
  number       = {3},
  pages        = {293-312},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Processing simple geometric attributes with autoencoders},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The global optimization geometry of shallow linear neural
networks. <em>JMIV</em>, <em>62</em>(3), 279–292. (<a
href="https://doi.org/10.1007/s10851-019-00889-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We examine the squared error loss landscape of shallow linear neural networks. We show—with significantly milder assumptions than previous works—that the corresponding optimization problems have benign geometric properties: There are no spurious local minima, and the Hessian at every saddle point has at least one negative eigenvalue. This means that at every saddle point there is a directional negative curvature which algorithms can utilize to further decrease the objective value. These geometric properties imply that many local search algorithms (such as the gradient descent which is widely utilized for training neural networks) can provably solve the training problem with global convergence.},
  archive      = {J_JMIV},
  author       = {Zhu, Zhihui and Soudry, Daniel and Eldar, Yonina C. and Wakin, Michael B.},
  doi          = {10.1007/s10851-019-00889-w},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {4},
  number       = {3},
  pages        = {279-292},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {The global optimization geometry of shallow linear neural networks},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Special issue on the mathematical foundations of deep
learning in imaging science. <em>JMIV</em>, <em>62</em>(3), 277–278. (<a
href="https://doi.org/10.1007/s10851-020-00955-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JMIV},
  author       = {Bruna, Joan and Haber, Eldad and Kutyniok, Gitta and Pock, Thomas and Vidal, René},
  doi          = {10.1007/s10851-020-00955-8},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {4},
  number       = {3},
  pages        = {277-278},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Special issue on the mathematical foundations of deep learning in imaging science},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Appreciation to journal of mathematics imaging and vision
reviewers. <em>JMIV</em>, <em>62</em>(3), 273–276. (<a
href="https://doi.org/10.1007/s10851-020-00950-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JMIV},
  doi          = {10.1007/s10851-020-00950-z},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {4},
  number       = {3},
  pages        = {273-276},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Appreciation to journal of mathematics imaging and vision reviewers},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Path-based analysis for structure-preserving image
filtering. <em>JMIV</em>, <em>62</em>(2), 253–271. (<a
href="https://doi.org/10.1007/s10851-019-00941-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structure-preserving image filtering is an image smoothing technique that aims to preserve prominent structures while removing unwanted details in natural images. However, relevant studies mainly focus on small variances/fluctuations suppression and are vulnerable to separate pixels connected by some low-contrast edges or cluster pixels which exhibit strong differences between neighbors in highly textured region. Inspired by the fact that the human visual system significantly outperforms manually designed operators in extracting meaningful structures from natural scenes, we present an efficient structure-preserving filtering method which integrates similarity, proximity and continuation principles of human perception to accomplish high-contrast details (textures/noises) smoothing. Additionally, a Liebig’s law of minimum-based distance transform is presented to seamlessly incorporate the three properties for the description of the filter kernel. Experiments demonstrate that our distance transform keeps a clustering-like manner of separating different image pixels and grouping similar ones with the awareness of structure. When integrating this affinity measure into the bilateral-filter-like framework, our method can efficiently remove high-contrast textures/noises while preserving major structures.},
  archive      = {J_JMIV},
  author       = {Xu, Lijuan and Wang, Fan and Dempere-Marco, Laura and Wang, Qi and Yang, Yan and Hu, Xiaopeng},
  doi          = {10.1007/s10851-019-00941-9},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {2},
  number       = {2},
  pages        = {253-271},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Path-based analysis for structure-preserving image filtering},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimizing excitation coil currents for advanced
magnetorelaxometry imaging. <em>JMIV</em>, <em>62</em>(2), 238–252. (<a
href="https://doi.org/10.1007/s10851-019-00934-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetorelaxometry imaging is a highly sensitive technique enabling noninvasive, quantitative detection of magnetic nanoparticles. Electromagnetic coils are sequentially energized, aligning the nanoparticles’ magnetic moments. Relaxation signals are recorded after turning off the coils. The forward model describing this measurement process is reformulated into a severely ill-posed inverse problem that is solved for estimating the particle distribution. Typically, many activation sequences employing different magnetic fields are required to obtain reasonable imaging quality. We seek to improve the imaging quality and accelerate the imaging process using fewer activation sequences by optimizing the applied magnetic fields. Minimizing the Frobenius condition number of the system matrix, we stabilize the inverse problem solution toward model uncertainties and measurement noise. Furthermore, our sensitivity-weighted reconstruction algorithms improve imaging quality in lowly sensitive areas. The optimization approach is employed to real measurement data and yields improved reconstructions with fewer activation sequences compared to non-optimized measurements.},
  archive      = {J_JMIV},
  author       = {Schier, Peter and Liebl, Maik and Steinhoff, Uwe and Handler, Michael and Wiekhorst, Frank and Baumgarten, Daniel},
  doi          = {10.1007/s10851-019-00934-8},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {2},
  number       = {2},
  pages        = {238-252},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Optimizing excitation coil currents for advanced magnetorelaxometry imaging},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Learning stable nonlinear cross-diffusion models for image
restoration. <em>JMIV</em>, <em>62</em>(2), 223–237. (<a
href="https://doi.org/10.1007/s10851-019-00931-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we focus on learning optimized partial differential equation (PDE) models for image filtering. In our approach, the gray-scale images are represented by a vector field of two real-valued functions and the image restoration problem is modeled by an evolutionary process such that the restored image at any time satisfies an initial-boundary value problem of cross-diffusion with reaction type. The coupled evolution of the two components of the image is determined by a nondiagonal matrix that depends on those components. A critical question when designing a good performing filter lies in the selection of the optimal coefficients and influence functions which define the cross-diffusion matrix. We propose to take a PDE based on a nonlinear cross-diffusion process and turn it into a learnable architecture in order to optimize the parameters of the model. In particular, we use a back-propagation technique in order to minimize a cost function related to the quality of the denoising process, while we ensure stability during the learning procedure. Consequently, we obtain improved image restoration models with solid mathematical foundations. The learning framework and resulting models are presented along with related numerical experiments and image comparisons. Making use of synthetic data, the numerical results show the advantages of the proposed methodology by achieving significant improvements.},
  archive      = {J_JMIV},
  author       = {Barbeiro, Sílvia and Lobo, Diogo},
  doi          = {10.1007/s10851-019-00931-x},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {2},
  number       = {2},
  pages        = {223-237},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Learning stable nonlinear cross-diffusion models for image restoration},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Squeezing the DCT to fight camouflage. <em>JMIV</em>,
<em>62</em>(2), 206–222. (<a
href="https://doi.org/10.1007/s10851-019-00930-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel descriptor based on the two-dimensional discrete cosine transform (2D DCT) to fight camouflage. The 2D DCT gained popularity in image and video analysis owing to its wide use in signal compression. The 2D DCT is a well-established example to evaluate new techniques in sparse representation and is widely used for block and texture description, mainly due to its simplicity and its ability to condense information in a few coefficients. A common approach, for different applications, is to select a subset of these coefficients, which is fixed for every analyzed signal. In this paper, we question this approach and propose a novel method to select a signal-dependent subset of relevant coefficients, which is the basis for the proposed R-DCT and sR-DCT descriptors. As we propose to describe each pixel with a different set of coefficients, each associated to a particular basis function, in order to compare any two so-obtained descriptors a distance function is required: we propose a novel metric to cope with this situation. The presented experiments over the change detection dataset show that the proposed descriptors notably reduce the likelihood of camouflage respect to other popular descriptors: 92% respect to the pixel luminance, 82% respect to the RGB values, and 65% respect to the best performing LBP configuration.},
  archive      = {J_JMIV},
  author       = {Escudero-Viñolo, Marcos and Bescos, Jesus},
  doi          = {10.1007/s10851-019-00930-y},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {2},
  number       = {2},
  pages        = {206-222},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Squeezing the DCT to fight camouflage},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sparse reconstruction of log-conductivity in current density
impedance tomography. <em>JMIV</em>, <em>62</em>(2), 189–205. (<a
href="https://doi.org/10.1007/s10851-019-00929-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new nonlinear optimization approach is proposed for the sparse reconstruction of log-conductivities in current density impedance imaging. This framework comprises of minimizing an objective functional involving a least squares fit of the interior electric field data corresponding to two boundary voltage measurements, where the conductivity and the electric potential are related through an elliptic PDE arising in electrical impedance tomography. Further, the objective functional consists of a $$L^1$$ regularization term that promotes sparsity patterns in the conductivity and a Perona–Malik anisotropic diffusion term that enhances the edges to facilitate high contrast and resolution. This framework is motivated by a similar recent approach to solve an inverse problem in acousto-electric tomography. Several numerical experiments and comparison with an existing method demonstrate the effectiveness of the proposed method for superior image reconstructions of a wide variety of log-conductivity patterns.},
  archive      = {J_JMIV},
  author       = {Gupta, Madhu and Mishra, Rohit Kumar and Roy, Souvik},
  doi          = {10.1007/s10851-019-00929-5},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {2},
  number       = {2},
  pages        = {189-205},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Sparse reconstruction of log-conductivity in current density impedance tomography},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Homography estimation from ellipse correspondences based on
the common self-polar triangle. <em>JMIV</em>, <em>62</em>(2), 169–188.
(<a href="https://doi.org/10.1007/s10851-019-00928-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents new implementation algorithms for estimating the homography from ellipse correspondences based on the common self-polar triangle. Firstly, we propose an analytical solution with a fourfold ambiguity to homography based on converting two ellipse correspondences to three common pole correspondences. Secondly, after exploring the position information of the common poles, we propose the analytical algorithms for estimating the homography from only two ellipse correspondences. We also propose an analytical linear algorithm for estimating the homography by using the common pole correspondences with the known projective scale factors when given three or more ellipse correspondences. Unlike the previous methods, our algorithms are very easy to implement and furthermore may usually provide a unique solution (at most two solutions). Experimental results in synthetic data and real images show the accuracy advantage and the usefulness of our proposed algorithms.},
  archive      = {J_JMIV},
  author       = {Guo, Yang},
  doi          = {10.1007/s10851-019-00928-6},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {2},
  number       = {2},
  pages        = {169-188},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Homography estimation from ellipse correspondences based on the common self-polar triangle},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A unified view on patch aggregation. <em>JMIV</em>,
<em>62</em>(2), 149–168. (<a
href="https://doi.org/10.1007/s10851-019-00921-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Patch-based methods are widely used in various topics of image processing, such as image restoration or image editing and synthesis. Patches capture local image geometry and structure and are much easier to model than whole images: in practice, patches are small enough to be represented by simple multivariate priors. An important question arising in all patch-based methods is the one of patch aggregation. For instance, in image restoration, restored patches are usually not compatible, in the sense that two overlapping restored patches do not necessarily yield the same values to their common pixels. A standard way to overcome this difficulty is to see the values provided by different patches at a given pixel as independent estimators of a true unknown value and to aggregate these estimators. This aggregation step usually boils down to a simple average, with uniform weights or with weights depending on the trust we have on these different estimators. In this paper, we propose a probabilistic framework aiming at a better understanding of this crucial and often neglected step. The key idea is to see the aggregation of two patches as a fusion between their models rather than a fusion of estimators. The proposed fusion operation is pretty intuitive and generalizes previous aggregation methods. It also yields a novel interpretation of the Expected Patch Log Likelihood (EPLL) proposed in Zoran and Weiss (in: 2011 IEEE international conference on computer vision (ICCV), 2011).},
  archive      = {J_JMIV},
  author       = {Saint-Dizier, Alexandre and Delon, Julie and Bouveyron, Charles},
  doi          = {10.1007/s10851-019-00921-z},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {2},
  number       = {2},
  pages        = {149-168},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {A unified view on patch aggregation},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Provably scale-covariant continuous hierarchical networks
based on scale-normalized differential expressions coupled in cascade.
<em>JMIV</em>, <em>62</em>(1), 120–148. (<a
href="https://doi.org/10.1007/s10851-019-00915-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a theory for constructing hierarchical networks in such a way that the networks are guaranteed to be provably scale covariant. We first present a general sufficiency argument for obtaining scale covariance, which holds for a wide class of networks defined from linear and nonlinear differential expressions expressed in terms of scale-normalized scale-space derivatives. Then, we present a more detailed development of one example of such a network constructed from a combination of mathematically derived models of receptive fields and biologically inspired computations. Based on a functional model of complex cells in terms of an oriented quasi quadrature combination of first- and second-order directional Gaussian derivatives, we couple such primitive computations in cascade over combinatorial expansions over image orientations. Scale-space properties of the computational primitives are analysed, and we give explicit proofs of how the resulting representation allows for scale and rotation covariance. A prototype application to texture analysis is developed, and it is demonstrated that a simplified mean-reduced representation of the resulting QuasiQuadNet leads to promising experimental results on three texture datasets.},
  archive      = {J_JMIV},
  author       = {Lindeberg, Tony},
  doi          = {10.1007/s10851-019-00915-x},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {1},
  number       = {1},
  pages        = {120-148},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Provably scale-covariant continuous hierarchical networks based on scale-normalized differential expressions coupled in cascade},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel euler’s elastica-based segmentation approach for
noisy images using the progressive hedging algorithm. <em>JMIV</em>,
<em>62</em>(1), 98–119. (<a
href="https://doi.org/10.1007/s10851-019-00920-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Euler’s elastica-based unsupervised segmentation models have strong capability of completing the missing boundaries for existing objects in a clean image, but they are not working well for noisy images. This paper aims to establish a Euler’s elastica-based approach that can properly deal with the random noises to improve the segmentation performance for noisy images. The corresponding formulation of stochastic optimization is solved via the progressive hedging algorithm (PHA), and the description of each individual scenario is obtained by the alternating direction method of multipliers. Technically, all the sub-problems derived from the framework of PHA can be solved by using the curvature-weighted approach and the convex relaxation method. Then, an alternating optimization strategy is applied by using some powerful accelerating techniques including the fast Fourier transform and generalized soft threshold formulas. Extensive experiments have been conducted on both synthetic and real images, which displayed significant gains of the proposed segmentation models and demonstrated the advantages of the developed algorithms.},
  archive      = {J_JMIV},
  author       = {Tan, Lu and Li, Ling and Liu, Wanquan and Sun, Jie and Zhang, Min},
  doi          = {10.1007/s10851-019-00920-0},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {1},
  number       = {1},
  pages        = {98-119},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {A novel euler’s elastica-based segmentation approach for noisy images using the progressive hedging algorithm},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). New type of gegenbauer–hermite monogenic polynomials and
associated clifford wavelets. <em>JMIV</em>, <em>62</em>(1), 73–97. (<a
href="https://doi.org/10.1007/s10851-019-00914-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, 3D images processing constitutes a challenging topic in many scientific fields such as medicine, computational physics, informatics. Therefore, the construction of suitable functional bases that allow computational aspects to be easily done is a necessity. Wavelets and Clifford algebras are ones of the most import mathematical tools for achieving such necessities. In the present work, new classes of wavelet functions are presented in the framework of Clifford analysis. Firstly, some classes of new monogenic polynomials are provided based on two-parameter weight functions. Such classes englobe the well-known Gegenbauer and Hermite ones. The discovered polynomial sets are next applied to introduce new wavelet functions. Reconstruction formula and Fourier–Plancherel rules have been proved. Computational concrete examples are developed by means of some illustrative examples with graphical representations of the Clifford mother wavelets in some cases. These discovered wavelets have been applied by the next for modeling some biomedical signals such as EEG, ECG and proteins.},
  archive      = {J_JMIV},
  author       = {Arfaoui, Sabrine and Ben Mabrouk, Anouar and Cattani, Carlo},
  doi          = {10.1007/s10851-019-00914-y},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {1},
  number       = {1},
  pages        = {73-97},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {New type of Gegenbauer–Hermite monogenic polynomials and associated clifford wavelets},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). 3D shape recovery by aggregating 3D wavelet transform-based
image focus volumes through 3D weighted least squares. <em>JMIV</em>,
<em>62</em>(1), 54–72. (<a
href="https://doi.org/10.1007/s10851-019-00918-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a shape from focus method based on high-frequency components from 3D discrete wavelet transform. First, an input image sequence is decomposed into approximation and detail components up to certain levels. Then, for each level, an image focus volume is obtained from the energy of detail components. These image focus volumes contain varying sized structural information about the shape of the object. From this set of image focus volumes, a single image focus volume is obtained through cross-scale aggregation of image focus volumes by applying 3D weighted least squares. The weights for the smoothness term for each pixel have been computed from the cross-scale prior. Incorporating this cross-scale prior enables the multi-scale interaction for image focus volume aggregation. Finally, the depth map is recovered from the resultant image focus volume using the best focused pixels along the optical axis. The proposed method is evaluated using image sequences of synthetic and real objects. The experimental results demonstrate the effectiveness of the proposed method.},
  archive      = {J_JMIV},
  author       = {Ali, Usman and Mahmood, Muhammad Tariq},
  doi          = {10.1007/s10851-019-00918-8},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {1},
  number       = {1},
  pages        = {54-72},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {3D shape recovery by aggregating 3D wavelet transform-based image focus volumes through 3D weighted least squares},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fractal dimension estimation for color texture images.
<em>JMIV</em>, <em>62</em>(1), 37–53. (<a
href="https://doi.org/10.1007/s10851-019-00912-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an important feature of image texture, fractal dimension is widely used to index, segment or classify texture images. Previously, many methods have been proposed to estimate fractal dimension. However, most of them are for binary and gray-scale images. Only a few of them are for color images. In this paper, by extending the differential box-counting approach to five-dimensional Euclidean hyper-space, we present a new robust and simple algorithm to estimate fractal dimension for color texture images. By the differential box-counting method, a real empty box not covering any pixel even with ideal resolution is also counted as a box having pixels, resulting in errors of computations. This problem is eliminated by our method based on fractal Brownian surface model. Our experiments demonstrate that our algorithm is able to capture the complexity of color natures, and outperforms other methods in terms of color texture complexity ranking and discrimination, robustness and computational complexity.},
  archive      = {J_JMIV},
  author       = {Li, Yurong},
  doi          = {10.1007/s10851-019-00912-0},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {1},
  number       = {1},
  pages        = {37-53},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Fractal dimension estimation for color texture images},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Accelerated variational PDEs for efficient solution of
regularized inversion problems. <em>JMIV</em>, <em>62</em>(1), 10–36.
(<a href="https://doi.org/10.1007/s10851-019-00910-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We further develop a new framework, called PDE acceleration, by applying it to calculus of variation problems defined for general functions on $$\mathbb {R}^n$$, obtaining efficient numerical algorithms to solve the resulting class of optimization problems based on simple discretizations of their corresponding accelerated PDEs. While the resulting family of PDEs and numerical schemes are quite general, we give special attention to their application for regularized inversion problems, with particular illustrative examples on some popular image processing applications. The method is a generalization of momentum, or accelerated, gradient descent to the PDE setting. For elliptic problems, the descent equations are a nonlinear damped wave equation, instead of a diffusion equation, and the acceleration is realized as an improvement in the CFL condition from $$\varDelta t\sim \varDelta x^{2}$$ (for diffusion) to $$\varDelta t\sim \varDelta x$$ (for wave equations). We work out several explicit as well as a semi-implicit numerical scheme, together with their necessary stability constraints, and include recursive update formulations which allow minimal-effort adaptation of existing gradient descent PDE codes into the accelerated PDE framework. We explore these schemes more carefully for a broad class of regularized inversion applications, with special attention to quadratic, Beltrami, and total variation regularization, where the accelerated PDE takes the form of a nonlinear wave equation. Experimental examples demonstrate the application of these schemes for image denoising, deblurring, and inpainting, including comparisons against primal–dual, split Bregman, and ADMM algorithms.},
  archive      = {J_JMIV},
  author       = {Benyamin, Minas and Calder, Jeff and Sundaramoorthi, Ganesh and Yezzi, Anthony},
  doi          = {10.1007/s10851-019-00910-2},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {1},
  number       = {1},
  pages        = {10-36},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Accelerated variational PDEs for efficient solution of regularized inversion problems},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Tomographic reconstruction of the beltrami fields.
<em>JMIV</em>, <em>62</em>(1), 1–9. (<a
href="https://doi.org/10.1007/s10851-019-00900-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce and study a tomography method and have developed a numerical algorithm for the reconstruction of the linear Beltrami fields $$\nabla \times \mathbf{B}=\varkappa \mathbf{B}$$ in a bounded domain of $$\mathbf{R}^3$$ by using a known ray transform. This method is based on the expansion of a vector field over the special basis of vector functions. The results of computer simulation are given.},
  archive      = {J_JMIV},
  author       = {Balandin, A. L.},
  doi          = {10.1007/s10851-019-00900-4},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {1},
  number       = {1},
  pages        = {1-9},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Tomographic reconstruction of the beltrami fields},
  volume       = {62},
  year         = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
