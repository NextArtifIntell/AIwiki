<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AR_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ar---88">AR - 88</h2>
<ul>
<li><details>
<summary>
(2020). Tightly-coupled ultra-wideband-aided monocular visual SLAM
with degenerate anchor configurations. <em>AR</em>, <em>44</em>(8),
1519–1534. (<a
href="https://doi.org/10.1007/s10514-020-09944-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an enhanced tightly-coupled sensor fusion scheme using a monocular camera and ultra-wideband (UWB) ranging sensors for the task of simultaneous localization and mapping. By leveraging UWB data, the method can achieve metric-scale, drift-reduced odometry and a map consisting of visual landmarks and UWB anchors without knowing the anchor positions. Firstly, the UWB configuration accommodates any degenerate cases with an insufficient number of anchors for 3D triangulation ( $$N\le 3$$ and no height data). Secondly, a practical model for UWB measurement is used, ensuring more accurate estimates for all the states. Thirdly, selected prior range measurements including the anchor-world origin and anchor–anchor ranges are utilized to alleviate the requirement of good initial guesses for anchor position. Lastly, a monitoring scheme is introduced to appropriately fix the scale factor to maintain a smooth trajectory as well as the UWB anchor position to fuse camera and UWB measurement in the bundle adjustment. Extensive experiments are carried out to showcase the effectiveness of the proposed system.},
  archive      = {J_AR},
  author       = {Nguyen, Thien Hoang and Nguyen, Thien-Minh and Xie, Lihua},
  doi          = {10.1007/s10514-020-09944-7},
  journal      = {Autonomous Robots},
  month        = {11},
  number       = {8},
  pages        = {1519-1534},
  shortjournal = {Auton. Robot.},
  title        = {Tightly-coupled ultra-wideband-aided monocular visual SLAM with degenerate anchor configurations},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An approach to object-level stiffness regulation of hand-arm
systems subject to under-actuation constraints. <em>AR</em>,
<em>44</em>(8), 1505–1517. (<a
href="https://doi.org/10.1007/s10514-020-09942-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When using a tool with a robotic hand-arm system, the stiffness at the grasped object plays a key role in the interaction with the environment, allowing the successful execution of the task. However, the rapidly increasing use of under-actuated hands in robotic systems due to their robustness and simplicity of control, pose limitations to the achievable object-level stiffness. Indeed, due to the serial coupling of the hand and the arm, the resulting object-level stiffness is determined by the most compliant of both elements. To address this problem, we propose a novel controller that takes into account the limited achievable geometry of the object stiffness ellipsoid given by a hand with under-actuation constraints, and exploits the contribution of the robotic arm in reshaping the final stiffness towards the desired profile. The under-actuation is illustrated by a coordinated stiffening of the hand fingers. The proposed method is experimentally validated by a hand-arm system performing a peg-in-hole task.},
  archive      = {J_AR},
  author       = {Ruiz Garate, Virginia and Ajoudani, Arash},
  doi          = {10.1007/s10514-020-09942-9},
  journal      = {Autonomous Robots},
  month        = {11},
  number       = {8},
  pages        = {1505-1517},
  shortjournal = {Auton. Robot.},
  title        = {An approach to object-level stiffness regulation of hand-arm systems subject to under-actuation constraints},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). RGB-d camera calibration and trajectory estimation for
indoor mapping. <em>AR</em>, <em>44</em>(8), 1485–1503. (<a
href="https://doi.org/10.1007/s10514-020-09941-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a system for estimating the trajectory of a moving RGB-D camera with applications to building maps of large indoor environments. Unlike the current most researches, we propose a ‘feature model’ based RGB-D visual odometry system for a computationally-constrained mobile platform, where the ‘feature model’ is persistent and dynamically updated from new observations using a Kalman filter. In this paper, we firstly propose a mixture of Gaussians model for the depth random noise estimation, which is used to describe the spatial uncertainty of the feature point cloud. Besides, we also introduce a general depth calibration method to remove systematic errors in the depth readings of the RGB-D camera. We provide comprehensive theoretical and experimental analysis to demonstrate that our model based iterative-closest-point (ICP) algorithm can achieve much higher localization accuracy compared to the conventional ICP. The visual odometry runs at frequencies of 30 Hz or higher, on VGA images, in a single thread on a desktop CPU with no GPU acceleration required. Finally, we examine the problem of place recognition from RGB-D images, in order to form a pose-graph SLAM approach to refining the trajectory and closing loops. We evaluate the effectiveness of the system on using publicly available datasets with ground-truth data. The entire system is available for free and open-source online.},
  archive      = {J_AR},
  author       = {Yang, Liang and Dryanovski, Ivan and Valenti, Roberto G. and Wolberg, George and Xiao, Jizhong},
  doi          = {10.1007/s10514-020-09941-w},
  journal      = {Autonomous Robots},
  month        = {11},
  number       = {8},
  pages        = {1485-1503},
  shortjournal = {Auton. Robot.},
  title        = {RGB-D camera calibration and trajectory estimation for indoor mapping},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Angular momentum-based control of an underactuated orthotic
system for crouch-to-stand motion. <em>AR</em>, <em>44</em>(8),
1469–1484. (<a
href="https://doi.org/10.1007/s10514-020-09938-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an angular momentum-based controller for crouch-to-stand motion of a powered pediatric lower-limb orthosis. The control law is developed using an underactuated triple pendulum model representing the legs of an orthosis-dummy system where the hip and knee joints are actuated but the ankle joint is unpowered. The control law is conceived to drive the angular momentum of the system to zero, thereby bringing the system to a statically balanced upright configuration. The parameters of the dynamic model of the orthosis-dummy system are experimentally identified and used to synthesize the momentum-based controller. Control parameters are selected using closed-loop pole placement of the linearized system via numerical optimization to ensure local closed-loop stability with adequate damping and satisfactory response time without too large controller gains. The controller is applied in simulation to determine the region of viable initial conditions resulting in no knee hyperextension or loss of balance, as determined from a zero-moment point analysis. The controller is then implemented in experiment showing feasibility of the control strategy in practice. Results are compared against a similarly-synthesized linear-quadratic regulator.},
  archive      = {J_AR},
  author       = {Laubscher, Curt A. and Farris, Ryan J. and Sawicki, Jerzy T.},
  doi          = {10.1007/s10514-020-09938-5},
  journal      = {Autonomous Robots},
  month        = {11},
  number       = {8},
  pages        = {1469-1484},
  shortjournal = {Auton. Robot.},
  title        = {Angular momentum-based control of an underactuated orthotic system for crouch-to-stand motion},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Scalable time-constrained planning of multi-robot systems.
<em>AR</em>, <em>44</em>(8), 1451–1467. (<a
href="https://doi.org/10.1007/s10514-020-09937-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a scalable procedure for time-constrained planning of a class of uncertain nonlinear multi-robot systems. In particular, we consider N robotic agents operating in a workspace which contains regions of interest (RoI), in which atomic propositions for each robot are assigned. The main goal is to design decentralized and robust control laws so that each robot meets an individual high-level specification given as a metric interval temporal logic (MITL), while using only local information based on a limited sensing radius. Furthermore, the robots need to fulfill certain desired transient constraints such as collision avoidance between them. The controllers, which guarantee the transition between regions, consist of two terms: a nominal control input, which is computed online and is the solution of a decentralized finite-horizon optimal control problem (DFHOCP); and an additive state feedback law which is computed offline and guarantees that the real trajectories of the system will belong to a hyper-tube centered along the nominal trajectory. The controllers serve as actions for the individual weighted transition system (WTS) of each robot, and the time duration required for the transition between regions is modeled by a weight. The DFHOCP is solved at every sampling time by each robot and then necessary information is exchanged between neighboring robots. The proposed approach is scalable since it does not require a product computation among the WTS of the robots. The proposed framework is experimentally tested and the results show that the proposed framework is promising for solving real-life robotic as well as industrial applications.},
  archive      = {J_AR},
  author       = {Nikou, Alexandros and Heshmati-alamdari, Shahab and Dimarogonas, Dimos V.},
  doi          = {10.1007/s10514-020-09937-6},
  journal      = {Autonomous Robots},
  month        = {11},
  number       = {8},
  pages        = {1451-1467},
  shortjournal = {Auton. Robot.},
  title        = {Scalable time-constrained planning of multi-robot systems},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Online coverage and inspection planning for 3D modeling.
<em>AR</em>, <em>44</em>(8), 1431–1450. (<a
href="https://doi.org/10.1007/s10514-020-09936-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we address an exploration problem when constructing complete 3D models in an unknown environment using a Micro-Aerial Vehicle. Most previous exploration methods were based on the Next-Best-View (NBV) approaches, which iteratively determine the most informative view, that exposes the greatest unknown area from the current partial model. However, these approaches sometimes miss minor unreconstructed regions like holes or sparse surfaces (while these can be important features). Furthermore, because the NBV methods iterate the next-best path from a current partial view, they sometimes produce unnecessarily long trajectories by revisiting known regions. To address these problems, we propose a novel exploration algorithm that integrates coverage and inspection strategies. The suggested algorithm first computes a global plan to cover unexplored regions to complete the target model sequentially. It then plans local inspection paths that comprehensively scans local frontiers. This approach reduces the total exploration time and improves the completeness of the reconstructed models. We evaluate the proposed algorithm in comparison with other state-of-the-art approaches through simulated and real-world experiments. The results show that our algorithm outperforms the other approaches and in particular improves the completeness of surface coverage.},
  archive      = {J_AR},
  author       = {Song, Soohwan and Kim, Daekyum and Jo, Sungho},
  doi          = {10.1007/s10514-020-09936-7},
  journal      = {Autonomous Robots},
  month        = {11},
  number       = {8},
  pages        = {1431-1450},
  shortjournal = {Auton. Robot.},
  title        = {Online coverage and inspection planning for 3D modeling},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A dynamical system approach for detection and reaction to
human guidance in physical human–robot interaction. <em>AR</em>,
<em>44</em>(8), 1411–1429. (<a
href="https://doi.org/10.1007/s10514-020-09934-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A seamless interaction requires two robotic behaviors: the leader role where the robot rejects the external perturbations and focuses on the autonomous execution of the task, and the follower role where the robot ignores the task and complies with human intentional forces. The goal of this work is to provide (1) a unified robotic architecture to produce these two roles, and (2) a human-guidance detection algorithm to switch across the two roles. In the absence of human-guidance, the robot performs its task autonomously and upon detection of such guidances the robot passively follows the human motions. We employ dynamical systems to generate task-specific motion and admittance control to generate reactive motions toward the human-guidance. This structure enables the robot to reject undesirable perturbations, track the motions precisely, react to human-guidance by providing proper compliant behavior, and re-plan the motion reactively. We provide analytical investigation of our method in terms of tracking and compliant behavior. Finally, we evaluate our method experimentally using a 6-DoF manipulator.},
  archive      = {J_AR},
  author       = {Khoramshahi, Mahdi and Billard, Aude},
  doi          = {10.1007/s10514-020-09934-9},
  journal      = {Autonomous Robots},
  month        = {11},
  number       = {8},
  pages        = {1411-1429},
  shortjournal = {Auton. Robot.},
  title        = {A dynamical system approach for detection and reaction to human guidance in physical human–robot interaction},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A method for autonomous robotic manipulation through
exploratory interactions with uncertain environments. <em>AR</em>,
<em>44</em>(8), 1395–1410. (<a
href="https://doi.org/10.1007/s10514-020-09933-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Expanding robot autonomy can deliver functional flexibility and enable fast deployment of robots in challenging and unstructured environments. In this direction, significant advances have been recently made in visual-perception driven autonomy, which is mainly due to the availability of rich sensory data-sets. However, current robots’ physical interaction autonomy levels still remain at a basic level. Towards providing a systematic approach to this problem, this paper presents a new context-aware and adaptive method that allows a robotic platform to interact with unknown environments. In particular, a multi-axes self-tuning impedance controller is introduced to regulate quasi-static parameters of the robot based on previous experience in interacting with similar environments and the real-time sensory data. The proposed method is also capable of differentiating internal and external disruptions, and responding to them accordingly and appropriately. An agricultural experiment with different deformable material is presented to validate robot interaction autonomy improvements, and the capability of the proposed methodology in detecting and responding to unexpected events (e.g., faults).},
  archive      = {J_AR},
  author       = {Balatti, Pietro and Kanoulas, Dimitrios and Tsagarakis, Nikos and Ajoudani, Arash},
  doi          = {10.1007/s10514-020-09933-w},
  journal      = {Autonomous Robots},
  month        = {11},
  number       = {8},
  pages        = {1395-1410},
  shortjournal = {Auton. Robot.},
  title        = {A method for autonomous robotic manipulation through exploratory interactions with uncertain environments},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Structuring of tactile sensory information for category
formation in robotics palpation. <em>AR</em>, <em>44</em>(8), 1377–1393.
(<a href="https://doi.org/10.1007/s10514-020-09931-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a framework to investigate the influence of physical interactions to sensory information, during robotic palpation. We embed a capacitive tactile sensor on a robotic arm to probe a soft phantom and detect and classify hard inclusions within it. A combination of PCA and K-Means clustering is used to: first, reduce the dimensionality of the spatiotemporal data obtained through the probing of each area in the phantom; second categorize the re-encoded data into a given number of categories. Results show that appropriate probing interactions can be useful in compensating for the quality of the data, or lack thereof. Finally, we test the proposed framework on a palpation scenario where a Support Vector Machine classifier is trained to discriminate amongst different types of hard inclusions. We show the proposed framework is capable of predicting the best-performing motion strategy, as well as the relative classification performance of the SVM classifier, solely based on unsupervised cluster analysis methods.},
  archive      = {J_AR},
  author       = {Scimeca, Luca and Maiolino, Perla and Bray, Ed and Iida, Fumiya},
  doi          = {10.1007/s10514-020-09931-y},
  journal      = {Autonomous Robots},
  month        = {11},
  number       = {8},
  pages        = {1377-1393},
  shortjournal = {Auton. Robot.},
  title        = {Structuring of tactile sensory information for category formation in robotics palpation},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal solution of the generalized dubins interval problem:
Finding the shortest curvature-constrained path through a set of
regions. <em>AR</em>, <em>44</em>(7), 1359–1376. (<a
href="https://doi.org/10.1007/s10514-020-09932-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Generalized Dubins Interval Problem (GDIP) stands to determine the minimal length path connecting two disk-shaped regions where the departure and terminal headings of Dubins vehicle are within the specified angle intervals. The GDIP is a generalization of the existing point-to-point planning problem for Dubins vehicle with a single heading angle per particular location that can be solved optimally using closed-form expression. For the GDIP, both the heading angles and locations need to be chosen from continuous sets which makes the problem challenging because of infinite possibilities how to connect the regions by Dubins path. We provide the optimal solution of the introduced GDIP based on detailed problem analysis. Moreover, we propose to employ the GDIP to provide the first tight lower bound for the Dubins Touring Regions Problem which stands to find the shortest curvature-constrained path through a set of regions in the prescribed order.},
  archive      = {J_AR},
  author       = {Váňa, Petr and Faigl, Jan},
  doi          = {10.1007/s10514-020-09932-x},
  journal      = {Autonomous Robots},
  month        = {9},
  number       = {7},
  pages        = {1359-1376},
  shortjournal = {Auton. Robot.},
  title        = {Optimal solution of the generalized dubins interval problem: Finding the shortest curvature-constrained path through a set of regions},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An analysis of RelaxedIK: An optimization-based framework
for generating accurate and feasible robot arm motions. <em>AR</em>,
<em>44</em>(7), 1341–1358. (<a
href="https://doi.org/10.1007/s10514-020-09918-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a real-time motion-synthesis method for robot manipulators, called RelaxedIK, that is able to not only accurately match end-effector pose goals as done by traditional IK solvers, but also create smooth, feasible motions that avoid joint-space discontinuities, self-collisions, and kinematic singularities. To achieve these objectives on-the-fly, we cast the standard IK formulation as a weighted-sum non-linear optimization problem, such that motion goals in addition to end-effector pose matching can be encoded as terms in the sum. We present a normalization procedure such that our method is able to effectively make trade-offs to simultaneously reconcile many, and potentially competing, objectives. Using these trade-offs, our formulation allows features to be relaxed when in conflict with other features deemed more important at a given time. We compare performance against a state-of-the-art IK solver and a real-time motion-planning approach in several geometric and real-world tasks on seven robot platforms ranging from 5-DOF to 8-DOF. We show that our method achieves motions that effectively follow position and orientation end-effector goals without sacrificing motion feasibility, resulting in more successful execution of tasks compared to the baseline approaches. We also empirically evaluate how our solver performs with different optimization solvers, gradient calculation methods, and choice of loss function in the objective function.},
  archive      = {J_AR},
  author       = {Rakita, Daniel and Mutlu, Bilge and Gleicher, Michael},
  doi          = {10.1007/s10514-020-09918-9},
  journal      = {Autonomous Robots},
  month        = {9},
  number       = {7},
  pages        = {1341-1358},
  shortjournal = {Auton. Robot.},
  title        = {An analysis of RelaxedIK: An optimization-based framework for generating accurate and feasible robot arm motions},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Planar max flow maps and determination of lanes with
clearance. <em>AR</em>, <em>44</em>(7), 1323–1339. (<a
href="https://doi.org/10.1007/s10514-020-09917-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One main challenge in multi-agent navigation is to generate trajectories minimizing bottlenecks in environments cluttered with obstacles. In this paper we approach this problem globally by taking into account the maximum flow capacity of a given polygonal environment. Given the difficulty in solving the continuous maximum flow of a planar environment, we present in this paper a GPU-based methodology which leads to practical methods for computing maximum flow maps in arbitrary two-dimensional polygonal domains. Once a flow map representation is obtained, lanes can be extracted and optimized in length while keeping constant the flow capacity achieved by the system of trajectories. This work extends our previous work on max flow maps by presenting a clearance-based flow generation method which takes into account the size of the agents at the flow generation phase. In this way we ensure that the maximum possible number of lanes with the needed clearance is always obtained, a property that was found to not be always obtained with our previous method. As a result we are able to generate trajectories of maximum flow from source to sink edges across a generic set of polygonal obstacles, enabling the deployment of large numbers of agents utilizing the maximum flow capacity of a continuous description of the environment and eliminating bottlenecks.},
  archive      = {J_AR},
  author       = {Farias, Renato and Kallmann, Marcelo},
  doi          = {10.1007/s10514-020-09917-w},
  journal      = {Autonomous Robots},
  month        = {9},
  number       = {7},
  pages        = {1323-1339},
  shortjournal = {Auton. Robot.},
  title        = {Planar max flow maps and determination of lanes with clearance},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Plug-and-play supervisory control using muscle and brain
signals for real-time gesture and error detection. <em>AR</em>,
<em>44</em>(7), 1303–1322. (<a
href="https://doi.org/10.1007/s10514-020-09916-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective human supervision of robots can be key for ensuring correct robot operation in a variety of potentially safety-critical scenarios. This paper takes a step towards fast and reliable human intervention in supervisory control tasks by combining two streams of human biosignals: muscle and brain activity acquired via EMG and EEG, respectively. It presents continuous classification of left and right hand-gestures using muscle signals, time-locked classification of error-related potentials using brain signals (unconsciously produced when observing an error), and a framework that combines these pipelines to detect and correct robot mistakes during multiple-choice tasks. The resulting hybrid system is evaluated in a “plug-and-play” fashion with 7 untrained subjects supervising an autonomous robot performing a target selection task. Offline analysis further explores the EMG classification performance, and investigates methods to select subsets of training data that may facilitate generalizable plug-and-play classifiers.},
  archive      = {J_AR},
  author       = {DelPreto, Joseph and Salazar-Gomez, Andres F. and Gil, Stephanie and Hasani, Ramin and Guenther, Frank H. and Rus, Daniela},
  doi          = {10.1007/s10514-020-09916-x},
  journal      = {Autonomous Robots},
  month        = {9},
  number       = {7},
  pages        = {1303-1322},
  shortjournal = {Auton. Robot.},
  title        = {Plug-and-play supervisory control using muscle and brain signals for real-time gesture and error detection},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). High precision control and deep learning-based corn stand
counting algorithms for agricultural robot. <em>AR</em>, <em>44</em>(7),
1289–1302. (<a
href="https://doi.org/10.1007/s10514-020-09915-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents high precision control and deep learning-based corn stand counting algorithms for a low-cost, ultra-compact 3D printed and autonomous field robot for agricultural operations. Currently, plant traits, such as emergence rate, biomass, vigor, and stand counting, are measured manually. This is highly labor-intensive and prone to errors. The robot, termed TerraSentia, is designed to automate the measurement of plant traits for efficient phenotyping as an alternative to manual measurements. In this paper, we formulate a Nonlinear Moving Horizon Estimator that identifies key terrain parameters using onboard robot sensors and a learning-based Nonlinear Model Predictive Control that ensures high precision path tracking in the presence of unknown wheel-terrain interaction. Moreover, we develop a machine vision algorithm designed to enable an ultra-compact ground robot to count corn stands by driving through the fields autonomously. The algorithm leverages a deep network to detect corn plants in images, and a visual tracking model to re-identify detected objects at different time steps. We collected data from 53 corn plots in various fields for corn plants around 14 days after emergence (stage V3 - V4). The robot predictions have agreed well with the ground truth with $$C_{robot}=1.02 \times C_{human}-0.86$$ and a correlation coefficient $$R=0.96$$ . The mean relative error given by the algorithm is $$-3.78\%$$ , and the standard deviation is $$6.76\%$$ . These results indicate a first and significant step towards autonomous robot-based real-time phenotyping using low-cost, ultra-compact ground robots for corn and potentially other crops.},
  archive      = {J_AR},
  author       = {Zhang, Zhongzhong and Kayacan, Erkan and Thompson, Benjamin and Chowdhary, Girish},
  doi          = {10.1007/s10514-020-09915-y},
  journal      = {Autonomous Robots},
  month        = {9},
  number       = {7},
  pages        = {1289-1302},
  shortjournal = {Auton. Robot.},
  title        = {High precision control and deep learning-based corn stand counting algorithms for agricultural robot},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Guest editorial: Robotics: Science and systems 2018 (RSS
2018). <em>AR</em>, <em>44</em>(7), 1287–1288. (<a
href="https://doi.org/10.1007/s10514-020-09939-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AR},
  author       = {Howard, Thomas and Prorok, Amanda and Kress-Gazit, Hadas},
  doi          = {10.1007/s10514-020-09939-4},
  journal      = {Autonomous Robots},
  month        = {9},
  number       = {7},
  pages        = {1287-1288},
  shortjournal = {Auton. Robot.},
  title        = {Guest editorial: robotics: science and systems 2018 (RSS 2018)},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Wind disturbance rejection for unmanned aerial vehicles
using acceleration feedback enhanced <span
class="math display"><em>H</em><sub>∞</sub></span> method. <em>AR</em>,
<em>44</em>(7), 1271–1285. (<a
href="https://doi.org/10.1007/s10514-020-09935-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most critical issues for unmanned aerial vehicle (UAV) safety and precision flight is wind disturbance. To this end, this paper presents an acceleration feedback (AF) enhanced $$H_\infty $$ method for UAV flight control against wind disturbance and its application on a hex-rotor platform. The dynamics of the UAV system are decoupled into attitude control and position control loops. A hierarchical $$H_\infty $$ controller is then designed for the decoupled system. Finally, an AF-enhanced method is introduced into the decoupled system without altering the original control structure. The stability of the AF-enhanced $$H_\infty $$ method for the UAV system is analyzed and verified using the $$H_\infty $$ theory. Two types of wind disturbances—continuous and gusty winds—are considered and analyzed for guiding the AF-enhanced controller design. The results of an experimental comparison between the $$H_\infty $$ controller and the AF-enhanced $$H_\infty $$ controller against wind disturbances demonstrate the robustness and effectiveness of the proposed method for wind disturbance rejection.},
  archive      = {J_AR},
  author       = {Dai, Bo and He, Yuqing and Zhang, Guangyu and Gu, Feng and Yang, Liying and Xu, Weiliang},
  doi          = {10.1007/s10514-020-09935-8},
  journal      = {Autonomous Robots},
  month        = {9},
  number       = {7},
  pages        = {1271-1285},
  shortjournal = {Auton. Robot.},
  title        = {Wind disturbance rejection for unmanned aerial vehicles using acceleration feedback enhanced $$H_\infty $$ method},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Manipulation planning under changing external forces.
<em>AR</em>, <em>44</em>(7), 1249–1269. (<a
href="https://doi.org/10.1007/s10514-020-09930-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a planner that enables robots to manipulate objects under changing external forces. Particularly, we focus on the scenario where a human applies a sequence of forceful operations, e.g. cutting and drilling, on an object that is held by a robot. The planner produces an efficient manipulation plan by choosing stable grasps on the object, by intelligently deciding when the robot should change its grasp on the object as the external forces change, and by choosing subsequent grasps such that they minimize the number of regrasps required in the long-term. Furthermore, as it switches from one grasp to the other, the planner solves the bimanual regrasping in the air by using an alternating sequence of bimanual and unimanual grasps. We also present a conic formulation to address force uncertainties inherent in human-applied external forces, using which the planner can robustly assess the stability of a grasp configuration without sacrificing planning efficiency. We provide a planner implementation on a dual-arm robot and present a variety of simulated and real human-robot experiments to show the performance of our planner.},
  archive      = {J_AR},
  author       = {Chen, Lipeng and Figueredo, Luis F. C. and Dogar, Mehmet R.},
  doi          = {10.1007/s10514-020-09930-z},
  journal      = {Autonomous Robots},
  month        = {9},
  number       = {7},
  pages        = {1249-1269},
  shortjournal = {Auton. Robot.},
  title        = {Manipulation planning under changing external forces},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A unified kinematics modeling, optimization and control of
universal robots: From serial and parallel manipulators to walking,
rolling and hybrid robots. <em>AR</em>, <em>44</em>(7), 1233–1248. (<a
href="https://doi.org/10.1007/s10514-020-09929-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper develops a unified kinematics modeling, optimization and control that is applicable to a wide range of autonomous and non-autonomous robots. These include hybrid robots that combine two or more modes of operations, such as combination of walking and rolling, or rolling and manipulation, as well as parallel robots in various configurations. The equations of motion are derived in compact forms that embed an optimization criterion. These equations are used to obtain various useful forms of the robot kinematics such as recursive, body and limb-end kinematic forms. Using the modeling, actuation and control equations are derived that ensure traversing a desired path while maintaining balanced operations and tip-over avoidance. Various simulation results are provided for a hybrid rolling-walking robot, which demonstrate the capabilities and effectiveness of the developed methodologies.},
  archive      = {J_AR},
  author       = {Tarokh, Mahmoud},
  doi          = {10.1007/s10514-020-09929-6},
  journal      = {Autonomous Robots},
  month        = {9},
  number       = {7},
  pages        = {1233-1248},
  shortjournal = {Auton. Robot.},
  title        = {A unified kinematics modeling, optimization and control of universal robots: From serial and parallel manipulators to walking, rolling and hybrid robots},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Disturbance observer enhanced variable gain controller for
robot teleoperation with motion capture using wearable armbands.
<em>AR</em>, <em>44</em>(7), 1217–1231. (<a
href="https://doi.org/10.1007/s10514-020-09928-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Disturbance observer (DOB) based controller performs well in estimating and compensating for perturbation when the external or internal unknown disturbance is slowly time varying. However, to some extent, robot manipulators usually work in complex environment with high-frequency disturbance. Thereby, to enhance tracking performance in a teleoperation system, only traditional DOB technique is insufficient. In this paper, for the purpose of constructing a feasible teleoperation scheme, we develop a novel controller that contains a variable gain scheme to deal with fast-time varying perturbation, whose gain is adjusted linearly according to human surface electromyographic signals collected from Myo wearable armband. In addition, for tracking the motion of operator’s arm, we derive five-joint-angle data of a moving human arm through two groups of quaternions generated from the armbands. Besides, the radial basis function neural networks and the disturbance observer-based control (DOBC) approaches are fused together into the proposed controller to compensate the unknown dynamics uncertainties of the slave robot as well as environmental perturbation. Experiments and simulations are conducted to demonstrated the effectiveness of the proposed strategy.},
  archive      = {J_AR},
  author       = {Huang, Darong and Yang, Chenguang and Ju, Zhaojie and Dai, Shi-Lu},
  doi          = {10.1007/s10514-020-09928-7},
  journal      = {Autonomous Robots},
  month        = {9},
  number       = {7},
  pages        = {1217-1231},
  shortjournal = {Auton. Robot.},
  title        = {Disturbance observer enhanced variable gain controller for robot teleoperation with motion capture using wearable armbands},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Geolocalization with aerial image sequence for UAVs.
<em>AR</em>, <em>44</em>(7), 1199–1215. (<a
href="https://doi.org/10.1007/s10514-020-09927-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The estimation of geolocation for aerial images is significant for tasks like map creating, or automatic navigation for unmanned aerial vehicles (UAVs). We propose a novel geolocalization method for the UAVs using only aerial images and reference road map. The corresponding road maps of the aerial images are firstly merged into a whole mosaic image using our newly-designed aerial image mosaicking algorithm, where the relative homography transformations between road images are firstly estimated using keypoints tracking in RGB aerial images, and then further refined with registration between detected roads. The geolocalization of the aerial mosaic image is then taken as the problem of registering observed roads in the aerial images to the reference road map under the homography transformation. The registration problem is solved with our fast search algorithm based on a novel projective-invariant feature, which consists of two road intersections augmented with their tangents. Experiments demonstrate that the proposed method can localize the aerial image sequence over an area larger than 1000 km $$^2$$ within a few seconds.},
  archive      = {J_AR},
  author       = {Li, Yongfei and He, Hao and Yang, Dongfang and Wang, Shicheng and Zhang, Meng},
  doi          = {10.1007/s10514-020-09927-8},
  journal      = {Autonomous Robots},
  month        = {9},
  number       = {7},
  pages        = {1199-1215},
  shortjournal = {Auton. Robot.},
  title        = {Geolocalization with aerial image sequence for UAVs},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-objective drone path planning for search and rescue
with quality-of-service requirements. <em>AR</em>, <em>44</em>(7),
1183–1198. (<a
href="https://doi.org/10.1007/s10514-020-09926-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We incorporate communication into the multi-UAV path planning problem for search and rescue missions to enable dynamic task allocation via information dissemination. Communication is not treated as a constraint but a mission goal. While achieving this goal, our aim is to avoid compromising the area coverage goal and the overall mission time. We define the mission tasks as: search, inform, and monitor at the best possible link quality. Building on our centralized simultaneous inform and connect (SIC) path planning strategy, we propose two adaptive strategies: (1) SIC with QoS (SICQ): optimizes search, inform, and monitor tasks simultaneously and (2) SIC following QoS (SIC+): first optimizes search and inform tasks together and then finds the optimum positions for monitoring. Both strategies utilize information as soon as it becomes available to determine UAV tasks. The strategies can be tuned to prioritize certain tasks in relation to others. We illustrate that more tasks can be performed in the given mission time by efficient incorporation of communication in the path design. We also observe that the quality of the resultant paths improves in terms of connectivity.},
  archive      = {J_AR},
  author       = {Hayat, Samira and Yanmaz, Evşen and Bettstetter, Christian and Brown, Timothy X.},
  doi          = {10.1007/s10514-020-09926-9},
  journal      = {Autonomous Robots},
  month        = {9},
  number       = {7},
  pages        = {1183-1198},
  shortjournal = {Auton. Robot.},
  title        = {Multi-objective drone path planning for search and rescue with quality-of-service requirements},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Iterative residual tuning for system identification and
sim-to-real robot learning. <em>AR</em>, <em>44</em>(7), 1167–1182. (<a
href="https://doi.org/10.1007/s10514-020-09925-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots are increasingly learning complex skills in simulation, increasing the need for realistic simulation environments. Existing techniques for approximating real-world physics with a simulation require extensive observation data and/or thousands of simulation samples. This paper presents iterative residual tuning (IRT), a deep learning system identification technique that modifies a simulator’s parameters to better match reality using minimal real-world observations. IRT learns to estimate the parameter difference between two parameterized models, allowing repeated iterations to converge on the true parameters similarly to gradient descent. In this paper, we develop and analyze IRT in depth, including its similarities and differences with gradient descent. Our IRT implementation, TuneNet, is pre-trained via supervised learning over an auto-generated simulated dataset. We show that TuneNet can perform rapid, efficient system identification even when the true parameter values lie well outside those in the network’s training data, and can also learn real-world parameter values from visual data. We apply TuneNet to a sim-to-real task transfer experiment, allowing a robot to perform a dynamic manipulation task with a new object after a single observation.},
  archive      = {J_AR},
  author       = {Allevato, Adam David and Schaertl Short, Elaine and Pryor, Mitch and Thomaz, Andrea L.},
  doi          = {10.1007/s10514-020-09925-w},
  journal      = {Autonomous Robots},
  month        = {9},
  number       = {7},
  pages        = {1167-1182},
  shortjournal = {Auton. Robot.},
  title        = {Iterative residual tuning for system identification and sim-to-real robot learning},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Nonlinear observability of unicycle multi-robot teams
subject to nonuniform environmental disturbances. <em>AR</em>,
<em>44</em>(7), 1149–1166. (<a
href="https://doi.org/10.1007/s10514-020-09923-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we consider the problem of localizing a team of robots, without access to direct pose measurements, under the influence of nonuniform environmental disturbances and measurement bias. Specifically, we are interested in the conditions under which teams remain range-only localizable when the environmental disturbances vary from robot to robot. We approach this problem through nonlinear observability and graph theory. After analyzing the system’s observability properties, we present theorems that identify the structural conditions under which the system maintains local weak observability. We demonstrate that rigid structures are important not only in defining multi-robot interactions, but also in characterizing the influence of nonuniform disturbances. We also give several example systems to cement intuition on the derived conditions. An observability-based planner is then presented that guides a subset of robots toward trajectories that are highly observable through finite-horizon optimization on robot headings. Simulations are then presented, along with an extended Kalman filter for state estimation, and a comparison to previous methods, to corroborate and demonstrate the results derived.},
  archive      = {J_AR},
  author       = {Heintzman, Larkin and Williams, Ryan K.},
  doi          = {10.1007/s10514-020-09923-y},
  journal      = {Autonomous Robots},
  month        = {9},
  number       = {7},
  pages        = {1149-1166},
  shortjournal = {Auton. Robot.},
  title        = {Nonlinear observability of unicycle multi-robot teams subject to nonuniform environmental disturbances},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Correction to: Orientation constraints for wi-fi SLAM using
signal strength gradients. <em>AR</em>, <em>44</em>(7), 1147. (<a
href="https://doi.org/10.1007/s10514-020-09940-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The original version of this article unfortunately missing the “Acknowledgements” section.},
  archive      = {J_AR},
  author       = {Yen, Hsiao-Chieh and Wang, Chieh-Chih and Chou, Cheng-Fu},
  doi          = {10.1007/s10514-020-09940-x},
  journal      = {Autonomous Robots},
  month        = {9},
  number       = {7},
  pages        = {1147},
  shortjournal = {Auton. Robot.},
  title        = {Correction to: Orientation constraints for wi-fi SLAM using signal strength gradients},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Orientation constraints for wi-fi SLAM using signal
strength gradients. <em>AR</em>, <em>44</em>(7), 1135–1146. (<a
href="https://doi.org/10.1007/s10514-020-09914-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose the signal strength gradient (SSG) orientation constraints for simultaneous localization and mapping (SLAM) using Wi-Fi received signal strength (RSS) measurements. We show that under certain circumstances, the relative orientation between nearby trajectory segments can be recovered from the cosine similarity between their SSGs. We then show how to obtain trajectory segments and self-consistent SSGs by jointly segmenting Wi-Fi measurements and odometry. Because SSG orientation constraints inevitably contain outliers, we also evaluate the effectiveness of robust SLAM backends on the proposed constraints. Experiments show that Wi-Fi SLAM using the proposed method can correctly estimate orientations given topologically incorrect initialization on trajectories with little to no overlapping sections.},
  archive      = {J_AR},
  author       = {Yen, Hsiao-Chieh and Wang, Chieh-Chih and Chou, Cheng-Fu},
  doi          = {10.1007/s10514-020-09914-z},
  journal      = {Autonomous Robots},
  month        = {9},
  number       = {7},
  pages        = {1135-1146},
  shortjournal = {Auton. Robot.},
  title        = {Orientation constraints for wi-fi SLAM using signal strength gradients},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Exploration of the applicability of probabilistic inference
for learning control in underactuated autonomous underwater vehicles.
<em>AR</em>, <em>44</em>(6), 1121–1134. (<a
href="https://doi.org/10.1007/s10514-020-09922-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater vehicles are employed in the exploration of dynamic environments where tuning of a specific controller for each task would be time-consuming and unreliable as the controller depends on calculated mathematical coefficients in idealised conditions. For such a case, learning task from experience can be a useful alternative. This paper explores the capability of probabilistic inference learning to control autonomous underwater vehicles that can be used for different tasks without re-programming the controller. Probabilistic inference learning uses a Gaussian process model of the real vehicle to learn the correct policy with a small number of real field experiments. The use of probabilistic reinforcement learning looks for a simple implementation of controllers without the burden of coefficients calculation, controller tuning or system identification. A series of computational simulations were employed to test the applicability of model-based reinforcement learning in underwater vehicles. Three simulation scenarios were evaluated: waypoint tracking, depth control and 3D path tracking control. The 3D path tracking is done by coupling together a line-of-sight law with probabilistic inference for learning control. As a comparison study LOS-PILCO algorithm can perform better than a robust LOS-PID. The results show that probabilistic model-based reinforcement learning can be a deployable solution to motion control of underactuated AUVs as it can generate capable policies with minimum quantity of episodes.},
  archive      = {J_AR},
  author       = {Ariza Ramirez, Wilmer and Leong, Zhi Quan and Nguyen, Hung Duc and Jayasinghe, Shantha Gamini},
  doi          = {10.1007/s10514-020-09922-z},
  journal      = {Autonomous Robots},
  month        = {7},
  number       = {6},
  pages        = {1121-1134},
  shortjournal = {Auton. Robot.},
  title        = {Exploration of the applicability of probabilistic inference for learning control in underactuated autonomous underwater vehicles},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Spatially-dependent bayesian semantic perception under model
and localization uncertainty. <em>AR</em>, <em>44</em>(6), 1091–1119.
(<a href="https://doi.org/10.1007/s10514-020-09921-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic perception can provide autonomous robots operating under uncertainty with more efficient representation of their environment and better ability for correct loop closures than only geometric features. However, accurate inference of semantics requires measurement models that correctly capture properties of semantic detections such as viewpoint dependence, spatial correlations, and intra- and inter-class variations. Such models should also gracefully handle open-set conditions which may be encountered, keeping track of the resultant model uncertainty. We propose a method for robust visual classification of an object of interest observed from multiple views in the presence of significant localization uncertainty and classifier noise, and possible dataset shift. We use a viewpoint dependent measurement model to capture viewpoint dependence and spatial correlations in classifier scores, showing how to use it in the presence of localization uncertainty. Assuming a Bayesian classifier providing a measure of uncertainty, we show how its outputs can be fused in the context of the above model, allowing robust classification under model uncertainty when novel scenes are encountered. We present statistical evaluation of our method both in synthetic simulation, and in a 3D environment where rendered images are fed into a Deep Neural Network classifier. We compare to baseline methods in scenarios of varying difficulty showing improved robustness of our method to localization uncertainty and dataset shift. Finally, we validate our contribution w.r.t. localization uncertainty on a dataset of real-world images.},
  archive      = {J_AR},
  author       = {Feldman, Yuri and Indelman, Vadim},
  doi          = {10.1007/s10514-020-09921-0},
  journal      = {Autonomous Robots},
  month        = {7},
  number       = {6},
  pages        = {1091-1119},
  shortjournal = {Auton. Robot.},
  title        = {Spatially-dependent bayesian semantic perception under model and localization uncertainty},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Online trajectory planning and control of a MAV payload
system in dynamic environments. <em>AR</em>, <em>44</em>(6), 1065–1089.
(<a href="https://doi.org/10.1007/s10514-020-09919-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Micro Aerial Vehicles (MAVs) can be used for aerial transportation in remote and urban spaces where portability can be exploited to reach previously inaccessible and inhospitable spaces. Current approaches for path planning of MAV swung payload system either compute conservative minimal-swing trajectories or pre-generate agile collision-free trajectories. However, these approaches have failed to address the prospect of online re-planning in uncertain and dynamic environments, which is a prerequisite for real-world deployability. This paper describes an online method for agile and closed-loop local trajectory planning and control that relies on Non-Linear Model Predictive Control and that addresses the mentioned limitations of contemporary approaches. We integrate the controller in a full system framework, and demonstrate the algorithm’s effectiveness in simulation and in experimental studies. Results show the scalability and adaptability of our method to various dynamic setups with repeatable performance over several complex tasks that include flying through a narrow opening and avoiding moving humans.},
  archive      = {J_AR},
  author       = {Potdar, Nikhil D. and de Croon, Guido C. H. E. and Alonso-Mora, Javier},
  doi          = {10.1007/s10514-020-09919-8},
  journal      = {Autonomous Robots},
  month        = {7},
  number       = {6},
  pages        = {1065-1089},
  shortjournal = {Auton. Robot.},
  title        = {Online trajectory planning and control of a MAV payload system in dynamic environments},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A velocity control strategy for collision avoidance of
autonomous agricultural vehicles. <em>AR</em>, <em>44</em>(6),
1047–1063. (<a
href="https://doi.org/10.1007/s10514-020-09924-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collision avoidance ability is very important for autonomous agricultural vehicles, but the influence of different obstacles in agricultural environment is rarely taken into account. In this paper, a velocity control strategy for collision avoidance was proposed to adjust the velocity of autonomous agricultural vehicles according to the movement state and dangerous degree of the obstacles and the distance between the obstacles and the vehicles, thus to improve intelligence and safety of the vehicles. The control strategy involved two steps: collision prediction in dynamic environments with an improved obstacle space–time grid map, and velocity generator for collision avoidance with a cloud model. Simulations were conducted on the obstacle collision prediction and the designed cloud generator for velocity control respectively. Simulation results show that the proposed strategy can effectively predict collision with anti-disturbance ability for threat-free obstacles and rapid and accurate velocity output. And it realizes the real-time operation in dynamic environments with an average time of 0.2 s to predict collision. Additionally, field experiments including five trial schemes were performed to test the proposed velocity control strategy on an agricultural robot, where a haystack, a tractor and walking persons were regarded as static or dynamic obstacles. The results of the field experiments show that the proposed velocity control strategy has strong feasibility and effectiveness.},
  archive      = {J_AR},
  author       = {Xue, Jinlin and Xia, Chengkai and Zou, Jun},
  doi          = {10.1007/s10514-020-09924-x},
  journal      = {Autonomous Robots},
  month        = {7},
  number       = {6},
  pages        = {1047-1063},
  shortjournal = {Auton. Robot.},
  title        = {A velocity control strategy for collision avoidance of autonomous agricultural vehicles},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Observability index optimization of robot calibration based
on multiple identification spaces. <em>AR</em>, <em>44</em>(6),
1029–1046. (<a
href="https://doi.org/10.1007/s10514-020-09920-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A calibration method is proposed for six-DoF serial robot based on multiple identification spaces consisting of two subspaces in which the orientations of joint 3 and poses of end-effector are measured simultaneously using hybrid sensors. The rotational geometric errors with higher sensitivities are identified in the first space while the rest are identified in the second. Compared with single identification space used in traditional methods, the number of geometric errors to be identified is reduced in each subspace. Thus the identification vectors corresponding to the geometric errors belonging to identification models can be better spaced. Simulation results show that the observability indices and identifiability are further improved by using the multiple identification spaces. Experimental results are also obtained from a six-DoF serial robot with laser tracker and IMUs to verify the identification accuracy improvement. Uncertainty analysis of each identification results is also provided.},
  archive      = {J_AR},
  author       = {Jiang, Zhouxiang and Huang, Min and Tang, Xiaoqi and Song, Bao and Guo, Yixuan},
  doi          = {10.1007/s10514-020-09920-1},
  journal      = {Autonomous Robots},
  month        = {7},
  number       = {6},
  pages        = {1029-1046},
  shortjournal = {Auton. Robot.},
  title        = {Observability index optimization of robot calibration based on multiple identification spaces},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Merging of appearance-based place knowledge among multiple
robots. <em>AR</em>, <em>44</em>(6), 1009–1027. (<a
href="https://doi.org/10.1007/s10514-020-09911-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {If robots can merge the appearance-based place knowledge of other robots with their own, they can relate to these places even if they have not previously visited them. We have investigated this problem using robots with compatible visual sensing capabilities and with each robot having its individual long-term place memory. Here, each place refers to a spatial region as defined by a collection of appearances and in the place memory, the knowledge is organized in a tree hierarchy. In the proposed merging approach, the hierarchical organization plays a key role—as it corresponds to a nested sequence of hyperspheres in the appearance space. The merging proceeds by considering the extent of overlap of the respective nested hyperspheres—starting with the largest covering hypersphere. Thus, differing from related work, knowledge is merged in as large chunks as possible while the hierarchical structure is preserved accordingly. As such, the merging scales better as the extent of knowledge to be merged increases. This is demonstrated in an extensive set of multirobot experiments where robots share their knowledge and then use their merged knowledge when visiting these places.},
  archive      = {J_AR},
  author       = {Karaoğuz, Hakan and Bozma, H. Işil},
  doi          = {10.1007/s10514-020-09911-2},
  journal      = {Autonomous Robots},
  month        = {7},
  number       = {6},
  pages        = {1009-1027},
  shortjournal = {Auton. Robot.},
  title        = {Merging of appearance-based place knowledge among multiple robots},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Formation control of unmanned micro aerial vehicles for
straitened environments. <em>AR</em>, <em>44</em>(6), 991–1008. (<a
href="https://doi.org/10.1007/s10514-020-09913-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel approach for control and motion planning of formations of multiple unmanned micro aerial vehicles (multi-rotor helicopters, in the literature also often called unmanned aerial vehicles—UAVs or unmanned aerial system—UAS) in cluttered GPS-denied on straitened environments. The proposed method enables us to autonomously design complex maneuvers of a compact Micro Aerial Vehicles (MAV) team in a virtual-leader-follower scheme. The results of the motion planning approach and the required stability of the formation are achieved by migrating the virtual leader along with the hull surrounding the formation. This enables us to suddenly change the formation motion in all directions, independently from the current orientation of the formation, and therefore to fully exploit the maneuverability of small multi-rotor helicopters. The proposed method was verified and its performance has been statistically evaluated in numerous simulations and experiments with a fleet of MAVs.},
  archive      = {J_AR},
  author       = {Saska, Martin and Hert, Daniel and Baca, Tomas and Kratky, Vit and Nascimento, Tiago},
  doi          = {10.1007/s10514-020-09913-0},
  journal      = {Autonomous Robots},
  month        = {7},
  number       = {6},
  pages        = {991-1008},
  shortjournal = {Auton. Robot.},
  title        = {Formation control of unmanned micro aerial vehicles for straitened environments},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Generative attention learning: A “GenerAL” framework for
high-performance multi-fingered grasping in clutter. <em>AR</em>,
<em>44</em>(6), 971–990. (<a
href="https://doi.org/10.1007/s10514-020-09907-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Attention Learning (GenerAL) is a framework for high-DOF multi-fingered grasping that is not only robust to dense clutter and novel objects but also effective with a variety of different parallel-jaw and multi-fingered robot hands. This framework introduces a novel attention mechanism that substantially improves the grasp success rate in clutter. Its generative nature allows the learning of full-DOF grasps with flexible end-effector positions and orientations, as well as all finger joint angles of the hand. Trained purely in simulation, this framework skillfully closes the sim-to-real gap. To close the visual sim-to-real gap, this framework uses a single depth image as input. To close the dynamics sim-to-real gap, this framework circumvents continuous motor control with a direct mapping from pixel to Cartesian space inferred from the same depth image. Finally, this framework demonstrates inter-robot generality by achieving over $$92\%$$ real-world grasp success rates in cluttered scenes with novel objects using two multi-fingered robotic hand-arm systems with different degrees of freedom.},
  archive      = {J_AR},
  author       = {Wu, Bohan and Akinola, Iretiayo and Gupta, Abhi and Xu, Feng and Varley, Jacob and Watkins-Valls, David and Allen, Peter K.},
  doi          = {10.1007/s10514-020-09907-y},
  journal      = {Autonomous Robots},
  month        = {7},
  number       = {6},
  pages        = {971-990},
  shortjournal = {Auton. Robot.},
  title        = {Generative attention learning: A “GenerAL” framework for high-performance multi-fingered grasping in clutter},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Correction to: GP-SLAM: Laser-based SLAM approach based on
regionalized gaussian process map reconstruction. <em>AR</em>,
<em>44</em>(6), 969. (<a
href="https://doi.org/10.1007/s10514-020-09909-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unfortunately, the acknowledgement text was incorrectly published in the original article.},
  archive      = {J_AR},
  author       = {Li, Bo and Wang, Yingqiang and Zhang, Yu and Zhao, Wenjie and Ruan, Jianyuan and Li, Ping},
  doi          = {10.1007/s10514-020-09909-w},
  journal      = {Autonomous Robots},
  month        = {7},
  number       = {6},
  pages        = {969},
  shortjournal = {Auton. Robot.},
  title        = {Correction to: GP-SLAM: laser-based SLAM approach based on regionalized gaussian process map reconstruction},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). GP-SLAM: Laser-based SLAM approach based on regionalized
gaussian process map reconstruction. <em>AR</em>, <em>44</em>(6),
947–967. (<a href="https://doi.org/10.1007/s10514-020-09906-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing laser-based 2D simultaneous localization and mapping (SLAM) methods exhibit limitations with regard to either efficiency or map representation. An ideal method should estimate the map of the environment and the state of the robot quickly and accurately while providing a compact and dense map representation. In this study, we develop a new laser-based SLAM algorithm by redesigning the two core elements common to all SLAM systems, namely the state estimation and map construction. Utilizing Gaussian process (GP) regression, we propose a new type of map representation based on the regionalized GP map reconstruction algorithm. With this new map representation, both the state estimation method and the map update method can be completed with the use of concise mathematics. For small- or medium-scale scenarios, our method, consisting of only state estimation and map construction, demonstrates outstanding performance relative to traditional occupancy-grid-map-based approaches in both accuracy and especially efficiency. For large-scale scenarios, we extend our approach to a graph-based version.},
  archive      = {J_AR},
  author       = {Li, Bo and Wang, Yingqiang and Zhang, Yu and Zhao, Wenjie and Ruan, Jianyuan and Li, Ping},
  doi          = {10.1007/s10514-020-09906-z},
  journal      = {Autonomous Robots},
  month        = {7},
  number       = {6},
  pages        = {947-967},
  shortjournal = {Auton. Robot.},
  title        = {GP-SLAM: Laser-based SLAM approach based on regionalized gaussian process map reconstruction},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improved and scalable online learning of spatial concepts
and language models with mapping. <em>AR</em>, <em>44</em>(6), 927–946.
(<a href="https://doi.org/10.1007/s10514-020-09905-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel online learning algorithm, called SpCoSLAM 2.0, for spatial concepts and lexical acquisition with high accuracy and scalability. Previously, we proposed SpCoSLAM as an online learning algorithm based on unsupervised Bayesian probabilistic model that integrates multimodal place categorization, lexical acquisition, and SLAM. However, our original algorithm had limited estimation accuracy owing to the influence of the early stages of learning, and increased computational complexity with added training data. Therefore, we introduce techniques such as fixed-lag rejuvenation to reduce the calculation time while maintaining an accuracy higher than that of the original algorithm. The results show that, in terms of estimation accuracy, the proposed algorithm exceeds the original algorithm and is comparable to batch learning. In addition, the calculation time of the proposed algorithm does not depend on the amount of training data and becomes constant for each step of the scalable algorithm. Our approach will contribute to the realization of long-term spatial language interactions between humans and robots.},
  archive      = {J_AR},
  author       = {Taniguchi, Akira and Hagiwara, Yoshinobu and Taniguchi, Tadahiro and Inamura, Tetsunari},
  doi          = {10.1007/s10514-020-09905-0},
  journal      = {Autonomous Robots},
  month        = {7},
  number       = {6},
  pages        = {927-946},
  shortjournal = {Auton. Robot.},
  title        = {Improved and scalable online learning of spatial concepts and language models with mapping},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-agent informed path planning using the probability
hypothesis density. <em>AR</em>, <em>44</em>(6), 913–925. (<a
href="https://doi.org/10.1007/s10514-020-09904-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An Informed Path Planning algorithm for multiple agents is presented. It can be used to efficiently utilize available agents when surveying large areas, when total coverage is unattainable. Internally the algorithm has a Probability Hypothesis Density (PHD) representation, inspired by modern multi-target tracking methods, to represent unseen objects. Using the PHD, the expected number of observed objects is optimized. In a sequential manner, each agent maximizes the number of observed new targets, taking into account the probability of undetected objects due to previous agents’ actions and the probability of detection, which yields a scalable algorithm. Algorithm properties are evaluated in simulations, and shown to outperform a greedy base line method. The algorithm is also evaluated by applying it to a sea ice tracking problem, using two datasets collected in the Arctic, with reasonable results. An implementation is provided under an Open Source license.},
  archive      = {J_AR},
  author       = {Olofsson, Jonatan and Hendeby, Gustaf and Lauknes, Tom Rune and Johansen, Tor Arne},
  doi          = {10.1007/s10514-020-09904-1},
  journal      = {Autonomous Robots},
  month        = {7},
  number       = {6},
  pages        = {913-925},
  shortjournal = {Auton. Robot.},
  title        = {Multi-agent informed path planning using the probability hypothesis density},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An informative path planning framework for UAV-based terrain
monitoring. <em>AR</em>, <em>44</em>(6), 889–911. (<a
href="https://doi.org/10.1007/s10514-020-09903-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicles represent a new frontier in a wide range of monitoring and research applications. To fully leverage their potential, a key challenge is planning missions for efficient data acquisition in complex environments. To address this issue, this article introduces a general informative path planning framework for monitoring scenarios using an aerial robot, focusing on problems in which the value of sensor information is unevenly distributed in a target area and unknown a priori. The approach is capable of learning and focusing on regions of interest via adaptation to map either discrete or continuous variables on the terrain using variable-resolution data received from probabilistic sensors. During a mission, the terrain maps built online are used to plan information-rich trajectories in continuous 3-D space by optimizing initial solutions obtained by a coarse grid search. Extensive simulations show that our approach is more efficient than existing methods. We also demonstrate its real-time application on a photorealistic mapping scenario using a publicly available dataset and a proof of concept for an agricultural monitoring task.},
  archive      = {J_AR},
  author       = {Popović, Marija and Vidal-Calleja, Teresa and Hitz, Gregory and Chung, Jen Jen and Sa, Inkyu and Siegwart, Roland and Nieto, Juan},
  doi          = {10.1007/s10514-020-09903-2},
  journal      = {Autonomous Robots},
  month        = {7},
  number       = {6},
  pages        = {889-911},
  shortjournal = {Auton. Robot.},
  title        = {An informative path planning framework for UAV-based terrain monitoring},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Event- and time-triggered dynamic task assignments for
multiple vehicles. <em>AR</em>, <em>44</em>(5), 877–888. (<a
href="https://doi.org/10.1007/s10514-020-09912-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the dynamic task assignment problem in which multiple dispersed vehicles are employed to visit a set of targets. Some targets’ locations are initially known and the others are dynamically randomly generated during a finite time horizon. The objective is to visit all the target locations while trying to minimize the vehicles’ total travel time. Based on existing algorithms used to deal with static multi-vehicle task assignment, two types of dynamic task assignments, namely event-triggered and time-triggered, are studied to investigate what the appropriate time instants should be to change in real time the assignment of the target locations in response to the newly generated target locations. Furthermore, for both the event- and time-triggered assignments, we propose several algorithms to investigate how to distribute the newly generated target locations to the vehicles. Extensive numerical simulations are carried out which show better performance of the event-triggered task assignment algorithms over the time-triggered algorithms under different arrival rates of the newly generated target locations.},
  archive      = {J_AR},
  author       = {Bai, Xiaoshan and Cao, Ming and Yan, Weisheng},
  doi          = {10.1007/s10514-020-09912-1},
  journal      = {Autonomous Robots},
  month        = {5},
  number       = {5},
  pages        = {877-888},
  shortjournal = {Auton. Robot.},
  title        = {Event- and time-triggered dynamic task assignments for multiple vehicles},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Autonomous ballistic airdrop of objects from a small
fixed-wing unmanned aerial vehicle. <em>AR</em>, <em>44</em>(5),
859–875. (<a href="https://doi.org/10.1007/s10514-020-09902-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous airdrop is a useful basic operation for a fixed-wing unmanned aerial system. Being able to deliver an object to a known target position extends operational range without risking human lives, but is still limited to known delivery locations. If the fixed-wing unmanned aerial vehicle delivering the object could also recognize its target, the system would take one step further in the direction of autonomy. This paper presents a closed-loop autonomous delivery system that uses machine vision to identify a target marked with a distinct colour, calculates the geographical coordinates of the target location and plans a path to a release point, where it delivers the object. Experimental results present a visual target estimator with a mean error distance of 3.4 m and objects delivered with a mean error distance of 5.5 m.},
  archive      = {J_AR},
  author       = {Mathisen, Siri Gulaker and Leira, Frederik Stendahl and Helgesen, Håkon Hagen and Gryte, Kristoffer and Johansen, Tor Arne},
  doi          = {10.1007/s10514-020-09902-3},
  journal      = {Autonomous Robots},
  month        = {5},
  number       = {5},
  pages        = {859-875},
  shortjournal = {Auton. Robot.},
  title        = {Autonomous ballistic airdrop of objects from a small fixed-wing unmanned aerial vehicle},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Approximate bayesian reinforcement learning based on
estimation of plant. <em>AR</em>, <em>44</em>(5), 845–857. (<a
href="https://doi.org/10.1007/s10514-020-09901-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes an approximate parametric model-based Bayesian reinforcement learning approach for robots, based on online Bayesian estimation and online planning for an estimated model. The proposed approach is designed to learn a robotic task with a few real-world samples and to be robust against model uncertainty, within feasible computational resources. The proposed approach employs two-stage modeling, which is composed of (1) a parametric differential equation model with a few parameters based on prior knowledge such as equations of motion, and (2) a parametric model that interpolates a finite number of transition probability models for online estimation and planning. The proposed approach modifies the online Bayesian estimation to be robust against approximation errors of the parametric model to a real plant. The policy planned for the interpolating model is proven to have a form of theoretical robustness. Numerical simulation and hardware experiments of a planar peg-in-hole task demonstrate the effectiveness of the proposed approach.},
  archive      = {J_AR},
  author       = {Senda, Kei and Hishinuma, Toru and Tani, Yurika},
  doi          = {10.1007/s10514-020-09901-4},
  journal      = {Autonomous Robots},
  month        = {5},
  number       = {5},
  pages        = {845-857},
  shortjournal = {Auton. Robot.},
  title        = {Approximate bayesian reinforcement learning based on estimation of plant},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Graph search of a moving ground target by a UAV aided by
ground sensors with local information. <em>AR</em>, <em>44</em>(5),
831–843. (<a href="https://doi.org/10.1007/s10514-019-09900-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optimal control of a UAV searching for a target moving, with known constant speed, on a road network and heading toward one of many goal locations is considered. To aid the UAV, some roads in the network are instrumented with unattended ground sensors (UGSs) that detect the target’s motion and record the time it passes by the UGS. When the UAV flies over an UGS location, this time stamped information, if available, is communicated to it. At time 0, the target enters the road network and selects a path leading to one of the exit nodes. The UAV also arrives at the same entry UGS after some delay and is thus informed about the presence of the target in the network. The UAV has no on-board sensing capability and so, capture entails the UAV and target being colocated at an UGS location. If this happens, the UGS is triggered and this information is instantaneously relayed to the UAV, thereby enabling capture. On the other hand, if the target reaches an exit node without being captured, he is deemed to have escaped. We transform the road network, which is restricted to a directed acyclic graph, into a time tree whose node is a tuple comprising the UGS location and evader arrival time at that location. For a given initial delay, we present a recursive forward search method that computes the minimum capture time UAV pursuit policy, under worst-case target action. The recursion scales poorly in the problem parameters, i.e., number of nodes in the time tree and number of evader paths. We present a novel branch and bound technique and a pre-processing step that is experimentally shown to reduce the computational burden by at least two orders of magnitude. We illustrate the applicability of the proposed pruning methods, which result in no loss in optimality, on a realistic example road network.},
  archive      = {J_AR},
  author       = {Kalyanam, Krishna and Casbeer, David and Pachter, Meir},
  doi          = {10.1007/s10514-019-09900-0},
  journal      = {Autonomous Robots},
  month        = {5},
  number       = {5},
  pages        = {831-843},
  shortjournal = {Auton. Robot.},
  title        = {Graph search of a moving ground target by a UAV aided by ground sensors with local information},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Relative navigation of autonomous GPS-degraded micro air
vehicles. <em>AR</em>, <em>44</em>(5), 811–830. (<a
href="https://doi.org/10.1007/s10514-019-09899-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unlike many current navigation approaches for micro air vehicles, the relative navigation (RN) framework presented in this paper ensures that the filter state remains observable in GPS-denied environments by working with respect to a local reference frame. By subtly restructuring the problem, RN ensures that the filter uncertainty remains bounded, consistent, and normally-distributed, and insulates flight-critical estimation and control processes from large global updates. This paper thoroughly outlines the RN framework and demonstrates its practicality with several long flight tests in unknown GPS-denied and GPS-degraded environments. The relative front end is shown to produce low-drift estimates and smooth, stable control while leveraging off-the-shelf algorithms. The system runs in real time with onboard processing, fuses a variety of vision sensors, and works indoors and outdoors without requiring special tuning for particular sensors or environments. RN is shown to produce globally-consistent, metric, and localized maps by incorporating loop closures and intermittent GPS measurements.},
  archive      = {J_AR},
  author       = {Wheeler, David O. and Koch, Daniel P. and Jackson, James S. and Ellingson, Gary J. and Nyholm, Paul W. and McLain, Timothy W. and Beard, Randal W.},
  doi          = {10.1007/s10514-019-09899-4},
  journal      = {Autonomous Robots},
  month        = {5},
  number       = {5},
  pages        = {811-830},
  shortjournal = {Auton. Robot.},
  title        = {Relative navigation of autonomous GPS-degraded micro air vehicles},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Joint optimization based on direct sparse stereo
visual-inertial odometry. <em>AR</em>, <em>44</em>(5), 791–809. (<a
href="https://doi.org/10.1007/s10514-019-09897-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel fusion of an inertial measurement unit (IMU) and stereo camera method based on direct sparse odometry (DSO) and stereo DSO. It jointly optimizes all model parameters within a sliding window, including the inverse depth of all selected pixels and the internal or external camera parameters of all keyframes. The vision part uses a photometric error function that optimizes 3D geometry and camera pose in a combined energy functional. The proposed algorithm uses image blocks to extract neighboring image features and directly forms measurement residuals in the image intensity space. A fixed-baseline stereo camera solves scale drift. IMU information is accumulated between several frames using manifold pre-integration and is inserted into the optimization as additional constraints between keyframes. The scale and gravity inserted are incorporated into the stereo visual inertial odometry model and are optimized together with other variables such as poses. The experimental results show that the tracking accuracy and robustness of the proposed method are superior to those of the state-of-the-art fused IMU method. In addition, compared with previous semi-dense direct methods, the proposed method displays a higher reconstruction density and scene recovery.},
  archive      = {J_AR},
  author       = {Wen, Shuhuan and Zhao, Yanfang and Zhang, Hong and Lam, Hak Keung and Manfredi, Luigi},
  doi          = {10.1007/s10514-019-09897-6},
  journal      = {Autonomous Robots},
  month        = {5},
  number       = {5},
  pages        = {791-809},
  shortjournal = {Auton. Robot.},
  title        = {Joint optimization based on direct sparse stereo visual-inertial odometry},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptive force and velocity control based on intrinsic
contact sensing during surface exploration of dynamic objects.
<em>AR</em>, <em>44</em>(5), 773–790. (<a
href="https://doi.org/10.1007/s10514-019-09896-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Haptic exploration is a process of using haptic feedback to interact and perceive an unknown object. It is an essential approach to understand the physical and geometrical properties of the object. While numerous research has been carried out for haptic exploration on static objects, haptic exploration on objects with dynamic movements has not been reported. It is due to the significant challenges to achieve robust force and velocity control when the object is nonstationary. In this work, a novel adaptive force and velocity control algorithm based on intrinsic contact sensing (ICS) for haptic surface exploration of dynamic objects is presented. A fuzzy-logic control framework making use of the information obtained from ICS has been developed. To validate the proposed control algorithm, extensive surface exploration experiments have been carried out on objects with different surface properties, geometries, stiffness, and concave or convex patterns. The validation results demonstrate the high accuracy and robustness of the proposed algorithm using different experimental platforms.},
  archive      = {J_AR},
  author       = {Sun, Teng and Liu, Hongbin},
  doi          = {10.1007/s10514-019-09896-7},
  journal      = {Autonomous Robots},
  month        = {5},
  number       = {5},
  pages        = {773-790},
  shortjournal = {Auton. Robot.},
  title        = {Adaptive force and velocity control based on intrinsic contact sensing during surface exploration of dynamic objects},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A highly stable and efficient spherical underwater robot
with hybrid propulsion devices. <em>AR</em>, <em>44</em>(5), 759–771.
(<a href="https://doi.org/10.1007/s10514-019-09895-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater robots have been promoted a significant interest in monitoring the marine environment. In some complex situation, robots sometimes need to keep moving fast, sometimes need to keep low speed and low noise. To address this issue, a novel spherical underwater robot (SUR IV) with hybrid propulsion devices including vectored water-jet and propeller thrusters is proposed in this paper. The diversity of the movement modes is also proposed for the different targets as remote or hover and general or silent. To analyze the hydrodynamic characteristics of the hybrid thruster, the computational fluid dynamics simulation is calculated in ANSYS CFX by using the multi-reference frame method. The simulation results show the interaction between the propeller and water-jet thruster. The thrust experiment to evaluate the performance of the improved hybrid thruster is also conducted. The maximum thrust of the hybrid thruster is increased 2.27 times than before. In addition, a noise comparison experiment is conducted to verify the low noise of the water-jet thruster. Finally, the 3 DoF motions which include the surge, heave and yaw for the SUR IV were carried out in the swimming pool. The improvement of the overall robot is assessed by the experimental results.},
  archive      = {J_AR},
  author       = {Gu, Shuoxin and Guo, Shuxiang and Zheng, Liang},
  doi          = {10.1007/s10514-019-09895-8},
  journal      = {Autonomous Robots},
  month        = {5},
  number       = {5},
  pages        = {759-771},
  shortjournal = {Auton. Robot.},
  title        = {A highly stable and efficient spherical underwater robot with hybrid propulsion devices},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On-line object detection: A robotics challenge. <em>AR</em>,
<em>44</em>(5), 739–757. (<a
href="https://doi.org/10.1007/s10514-019-09894-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection is a fundamental ability for robots interacting within an environment. While stunningly effective, state-of-the-art deep learning methods require huge amounts of labeled images and hours of training which does not favour such scenarios. This work presents a novel pipeline resulting from integrating (Maiettini et al. in 2017 IEEE-RAS 17th international conference on humanoid robotics (Humanoids), 2017) and (Maiettini et al. in 2018 IEEE/RSJ international conference on intelligent robots and systems (IROS), 2018), which naturally trains a robot to detect novel objects in few seconds. Moreover, we report on an extended empirical evaluation of the learning method, justifying that the proposed hybrid architecture is key in leveraging powerful deep representations while maintaining fast training time of large scale Kernel methods. We validate our approach on the Pascal VOC benchmark (Everingham et al. in Int J Comput Vis 88(2): 303–338, 2010), and on a challenging robotic scenario (iCubWorld Transformations (Pasquale et al. in Rob Auton Syst 112:260–281, 2019). We address real world use-cases and show how to tune the method for different speed/accuracy trades-off. Lastly, we discuss limitations and directions for future development.},
  archive      = {J_AR},
  author       = {Maiettini, Elisa and Pasquale, Giulia and Rosasco, Lorenzo and Natale, Lorenzo},
  doi          = {10.1007/s10514-019-09894-9},
  journal      = {Autonomous Robots},
  month        = {5},
  number       = {5},
  pages        = {739-757},
  shortjournal = {Auton. Robot.},
  title        = {On-line object detection: A robotics challenge},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-robot information driven path planning under
communication constraints. <em>AR</em>, <em>44</em>(5), 721–737. (<a
href="https://doi.org/10.1007/s10514-019-09890-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of simultaneous exploration and information collection in an initially unknown environment by multiple autonomous robots when the communication between robots is unreliable and intermittent. We propose a novel algorithm where decisions to select locations for exploration and information collection are guided by a utility function that combines Gaussian Process-based distributions for information entropy and communication signal strength, along with a distributed coordination protocol to avoid path conflicts between robots and repeated exploration and information collection from the same region by different robots. Our proposed algorithm was experimentally validated in simulation and on hardware Clearpath Jackal robots while using a realistic signal loss model from the literature. Our results show that our approach plans it samples such that it receives up to 25 dBm more signal strength throughout navigation compared to approaches that do not consider communications when selecting locations to sample from while accomplishing similar levels of model error.},
  archive      = {J_AR},
  author       = {Woosley, Bradley and Dasgupta, Prithviraj and Rogers, John G. and Twigg, Jeffrey},
  doi          = {10.1007/s10514-019-09890-z},
  journal      = {Autonomous Robots},
  month        = {5},
  number       = {5},
  pages        = {721-737},
  shortjournal = {Auton. Robot.},
  title        = {Multi-robot information driven path planning under communication constraints},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Air-ground cooperative topometric mapping of traversable
ground. <em>AR</em>, <em>44</em>(3), 705–720. (<a
href="https://doi.org/10.1007/s10514-019-09872-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose an approach for cooperative mapping of traversable ground from aerial and ground views in structured outdoor and indoor environments. The presented approach achieves a hybrid map building based on traversable ground skeletonization and graph matching. The obtained map is an augmented ground traversability map, represented as a hybrid topological/metric graph from heterogeneous sources. This approach provides a very suitable representation for ground navigation and planning. To validate this approach, the proposed algorithm is applied between aerial views, provided by a UAV flying over an experimental site, and ground maps from ground robots at different exploration stages, in realistic simulation and real-world environments.},
  archive      = {J_AR},
  author       = {Renaudeau, Brice and Labbani-Igbida, Ouiddad and Mourioux, Gilles},
  doi          = {10.1007/s10514-019-09872-1},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {3},
  pages        = {705-720},
  shortjournal = {Auton. Robot.},
  title        = {Air-ground cooperative topometric mapping of traversable ground},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptive target tracking with a mixed team of static and
mobile guards: Deployment and activation strategies. <em>AR</em>,
<em>44</em>(3), 691–703. (<a
href="https://doi.org/10.1007/s10514-019-09833-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work explores a variation of the art gallery problem in which a team of static and mobile guards track a mobile intruder with unknown maximum speed. We consider the special case when the mobile guards are restricted to move along the diagonals of a polygonal environment. First, we present an algorithm to identify candidate vertices in a polygon at which either static guards can be placed or they can serve as an endpoint of the segment on which mobile guards move. Next, we present a technique to partition the environment based on the triangulation of the environment, and allocate guards to each partition to track the intruder. The allocation strategy leads to a classification of the mobile guards based on their task and coordination requirements. Finally, we present a strategy to activate/deactivate static guards based on the speed of the intruder. Simulation results are presented to validate the efficacy of the proposed techniques.},
  archive      = {J_AR},
  author       = {Laguna, Guillermo J. and Bhattacharya, Sourabh},
  doi          = {10.1007/s10514-019-09833-8},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {3},
  pages        = {691-703},
  shortjournal = {Auton. Robot.},
  title        = {Adaptive target tracking with a mixed team of static and mobile guards: Deployment and activation strategies},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Distributed multi-target search and tracking using the PHD
filter. <em>AR</em>, <em>44</em>(3), 673–689. (<a
href="https://doi.org/10.1007/s10514-019-09840-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a distributed estimation and control algorithm that enables a team of mobile robots to search for and track an unknown number of targets. These targets may be stationary or moving, and the number of targets may vary over time as targets enter and leave the area of interest. The robots are equipped with sensors that have a finite field of view and may experience false negative and false positive detections. The robots use a novel, distributed formulation of the Probability Hypothesis Density (PHD) filter, which accounts for the limitations of the sensors, to estimate the number of targets and the positions of the targets. The robots then use Lloyd’s algorithm, a distributed control algorithm that has been shown to be effective for coverage and search tasks, to drive their motion within the environment. We utilize the output of the PHD filter as the importance weighting function within Lloyd’s algorithm. This causes the robots to be drawn towards areas that are likely to contain targets. We demonstrate the efficacy of our proposed algorithm, including comparisons to a coverage-based controller with a uniform importance weighting function, through an extensive series of simulated experiments. These experiments show teams of 10–100 robots successfully tracking 10–50 targets in both 2D and 3D environments.},
  archive      = {J_AR},
  author       = {Dames, Philip M.},
  doi          = {10.1007/s10514-019-09840-9},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {3},
  pages        = {673-689},
  shortjournal = {Auton. Robot.},
  title        = {Distributed multi-target search and tracking using the PHD filter},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). CARE: Cooperative autonomy for resilience and efficiency of
robot teams for complete coverage of unknown environments under robot
failures. <em>AR</em>, <em>44</em>(3), 647–671. (<a
href="https://doi.org/10.1007/s10514-019-09870-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the problem of Multi-robot Coverage Path Planning for unknown environments in the presence of robot failures. Unexpected robot failures can seriously degrade the performance of a robot team and in extreme cases jeopardize the overall operation. Therefore, this paper presents a distributed algorithm, called Cooperative Autonomy for Resilience and Efficiency, which not only provides resilience to the robot team against failures of individual robots, but also improves the overall efficiency of operation via event-driven replanning. The algorithm uses distributed Discrete Event Supervisors, which trigger games between a set of feasible players in the event of a robot failure or idling, to make collaborative decisions for task reallocations. The game-theoretic structure is built using Potential Games, where the utility of each player is aligned with a shared objective function for all players. The algorithm has been validated in various complex scenarios on a high-fidelity robotic simulator, and the results demonstrate that the team achieves complete coverage under failures, reduced coverage time, and faster target discovery as compared to three alternative methods.},
  archive      = {J_AR},
  author       = {Song, Junnan and Gupta, Shalabh},
  doi          = {10.1007/s10514-019-09870-3},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {3},
  pages        = {647-671},
  shortjournal = {Auton. Robot.},
  title        = {CARE: Cooperative autonomy for resilience and efficiency of robot teams for complete coverage of unknown environments under robot failures},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Distributed coverage in mobile sensor networks without
location information. <em>AR</em>, <em>44</em>(3), 627–645. (<a
href="https://doi.org/10.1007/s10514-019-09859-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the recent advances in robotic technologies, field coverage using mobile sensors is now possible, so that a small set of sensors can be mounted on mobile robots and move to desired areas. Compared to static settings, area coverage is more complicated in a mobile sensor network due to the dynamics arising from the continuous movement of the sensors. This complication is even higher in the more realistic case where little or no prior metric information is available about the sensor field. In this paper, we consider the problem of self-deployment of a set of mobile sensors which have no knowledge of the area, the number of nodes, their location, and even the distances to each other. In this restricted setting, we formulate the problem as a multi-player game in which each sensor tries to maximize its coverage while considering the overlapping sensing areas by its neighbors. We propose a distributed learning algorithm for coordinating the movement of the sensors in the field, and prove its convergence to the equilibria of the formulated game. Simulation results demonstrate that for moderate density deployments, the proposed algorithm competes with the existing location-dependent mobility strategies, while outperforming location-free algorithms.},
  archive      = {J_AR},
  author       = {Varposhti, Marzieh and Hakami, Vesal and Dehghan, Mehdi},
  doi          = {10.1007/s10514-019-09859-y},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {3},
  pages        = {627-645},
  shortjournal = {Auton. Robot.},
  title        = {Distributed coverage in mobile sensor networks without location information},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cooperative queuing policies for effective scheduling of
operator intervention. <em>AR</em>, <em>44</em>(3), 617–626. (<a
href="https://doi.org/10.1007/s10514-019-09877-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider multi-robot applications, where a team of robots can ask for the intervention of a human operator to handle difficult situations. As the number of requests grows, team members will have to wait for the operator attention, hence the operator becomes a bottleneck for the system. Our aim in this context is to make the robots learn cooperative strategies to decrease the idle time of the system by modeling the operator as a shared resource. In particular, we consider a balking queuing model where robots decide whether or not to join the queue and use multi-robot learning to estimate the best cooperative policy. In more detail, we formalize the problem as Decentralized Markov Decision Process and provide a suitable state representation, so to apply an independent learners approach. We evaluate the proposed method in a robotic water monitoring simulation and empirically show that our approach can significantly improve the team performance, while being computationally tractable.},
  archive      = {J_AR},
  author       = {Raeissi, Masoume M. and Farinelli, Alessandro},
  doi          = {10.1007/s10514-019-09877-w},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {3},
  pages        = {617-626},
  shortjournal = {Auton. Robot.},
  title        = {Cooperative queuing policies for effective scheduling of operator intervention},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Humans interacting with multi-robot systems: A natural
affect-based approach. <em>AR</em>, <em>44</em>(3), 601–616. (<a
href="https://doi.org/10.1007/s10514-019-09889-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel human–multi-robot-system interaction approach that enjoys two main features: natural interaction and affect-based adaptation of robots behavior. Specifically, the proposed system enables interaction by means of a wrist-worn device, such as a commercial smartwatch, which allows to track user’s movements and heart activity. Thus, on the one side, the proposed system allows the user to intuitively drive the robots by establishing a natural mapping between wrist movements and robots velocity. On the other side, the system estimates user’s mental fatigue during interaction by means of the analysis of heart rate variability. The proposed interaction system adapts then the behavior of the multi-robot system when the interacting user gets overwhelmed with the interaction and control task, which is then simplified. Experimental validation is provided, to show the effectiveness of the proposed system. First, the natural and affect-based interaction are considered separately. Then, the approach is tested considering a complex realistic scenario, which is simulated in virtual reality in order to get an immersive and realistic interaction experience. The results of the experimental validation clearly show that the proposed affect-based adaptive system leads to relieving the user’s fatigue and mental workload.},
  archive      = {J_AR},
  author       = {Villani, Valeria and Capelli, Beatrice and Secchi, Cristian and Fantuzzi, Cesare and Sabattini, Lorenzo},
  doi          = {10.1007/s10514-019-09889-6},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {3},
  pages        = {601-616},
  shortjournal = {Auton. Robot.},
  title        = {Humans interacting with multi-robot systems: A natural affect-based approach},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Automated synthesis of decentralized controllers for robot
swarms from high-level temporal logic specifications. <em>AR</em>,
<em>44</em>(3), 585–600. (<a
href="https://doi.org/10.1007/s10514-019-09861-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The majority of work in the field of swarm robotics focuses on the bottom-up design of local rules for individual robots that create emergent swarm behaviors. In this paper, we take a top-down approach and consider the following problem: how can we specify a desired collective behavior and automatically synthesize decentralized controllers that can be distributed over robots to achieve the collective objective in a provably correct way? We propose a formal specification language for the high-level description of swarm behaviors on both the swarm and individual levels. We present algorithms for automated synthesis of decentralized controllers and synchronization skeletons that describe how groups of robots must coordinate to satisfy the specification. We demonstrate our proposed approach through an example in simulation.},
  archive      = {J_AR},
  author       = {Moarref, Salar and Kress-Gazit, Hadas},
  doi          = {10.1007/s10514-019-09861-4},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {3},
  pages        = {585-600},
  shortjournal = {Auton. Robot.},
  title        = {Automated synthesis of decentralized controllers for robot swarms from high-level temporal logic specifications},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Auctions for multi-robot task allocation in communication
limited environments. <em>AR</em>, <em>44</em>(3), 547–584. (<a
href="https://doi.org/10.1007/s10514-019-09828-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of multi-robot task allocation using auctions, and study how lossy communication between the auctioneer and bidders affects solution quality. We demonstrate both analytically and experimentally that even though many auction algorithms have similar performance when communication is perfect, different auctions degrade in different ways as communication quality decreases from perfect to nonexistent. Thus, if a multi-robot system is expected to encounter lossy communication, then the auction algorithm that it uses for task allocation must be chosen carefully. We compare six auction algorithms including: standard implementations of the Sequential Auction, Parallel Auction, Combinatorial Auction; a generalization of the Prim Allocation Auction called G-Prim; and two multi-round variants of a Repeated Parallel Auction. Variants of these auctions are also considered in which award information from previous rounds is rebroadcast by the auctioneer during later rounds. We consider a variety of valuation functions used by the bidders, including: the total and maximum distance traveled (for distance based cost functions), the expected profit or cost to a robot (assuming robots’ task values are drawn from a random distribution). Different auctioneer objectives are also evaluated, and include: maximizing profit (max sum), minimizing cost (min sum), and minimizing the maximum distance traveled by any particular robot (min max). In addition to the cost value functions that are used, we are also interested in fleet performance statistics such as the expected robot utilization rate, and the expected number of items won by each robot. Experiments are performed both in simulation and on real AscTec Pelican quad-rotor aircraft. In simulation, each algorithm is considered across communication qualities ranging from perfect to nonexistent. For the case of the distance-based cost functions, the performance of the auctions is compared using two different communication models: (1) a Bernoulli model and (2) the Gilbert–Elliot model. The particular auction that performs the best changes based on the the reliability of the communication between the bidders and the auctioneer. We find that G-Prim and its repeated variant perform relatively well when communication is poor, and that re-sending winner data in later rounds is an easy way improve the performance of multi-round auctions, in general.},
  archive      = {J_AR},
  author       = {Otte, Michael and Kuhlman, Michael J. and Sofge, Donald},
  doi          = {10.1007/s10514-019-09828-5},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {3},
  pages        = {547-584},
  shortjournal = {Auton. Robot.},
  title        = {Auctions for multi-robot task allocation in communication limited environments},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Competition and cooperation in a community of autonomous
agents. <em>AR</em>, <em>44</em>(3), 533–546. (<a
href="https://doi.org/10.1007/s10514-019-09867-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Agents that perform intelligent tasks interacting with humans in a seamless manner are becoming a reality. In contexts in which interactions among agents repeat over time, they might evolve from a cooperative to a competitive attitude, and vice versa, depending on environmental factors and other contextual circumstances. We provide a framework to model transitions between competition and cooperation in a community of agents. Competition is dealt with through the paradigm of adversarial risk analysis, which provides a disagreement solution; implicitly, we minimize the distance to such solution. Cooperation is handled through a concept of maximal separation from the disagreement solution. Mixtures of both problems are used to refer to in-between behaviour. We illustrate the ideas with several simulations in relation with a group of robots. Our motivation is the constitution of communities of robotic agents that interact among them and with one or more users.},
  archive      = {J_AR},
  author       = {Gómez Esteban, Pablo and Liu, Si and Ríos Insua, David and González-Ortega, Jorge},
  doi          = {10.1007/s10514-019-09867-y},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {3},
  pages        = {533-546},
  shortjournal = {Auton. Robot.},
  title        = {Competition and cooperation in a community of autonomous agents},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hybrid planning and distributed iterative repair for
multi-robot missions with communication losses. <em>AR</em>,
<em>44</em>(3), 505–531. (<a
href="https://doi.org/10.1007/s10514-019-09869-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a planning and execution architecture suited for the initial planning, the execution and the on-board repair of a plan for a multi-robot mission. The team as a whole must accomplish its mission while dealing with online events such as robots breaking down, new objectives for the team, late actions and intermittent communications. We have chosen a “plan then repair” approach where an initial plan is computed offline and updated online whenever disruptive events happen. We have defined an hybrid planner that mixes Partial Order Planning (POP) with a Hierarchical Task Network (HTN)-based modelling of actions. This planner, called HiPOP for Hierarchical Partial-Order Planner, computes plans with temporal flexibility (thus easing its execution) and abstract actions (thus easing the repair process). It uses a symbolic representation of the world and has been extended with geometrical reasoning to adapt to multi-robots missions. Plans are executed in a distributed way: each robot is responsible of executing its own actions, and to propagate delays in its local plan, taking benefit from the temporal flexibility of the plan. When an inconsistency or a failure arises, a distributed repair algorithm based on HiPOP is used to repair the plan, by iteratively removing actions in the plan in order to amend the global plan. This repair is done onboard one of the robot of the team, and takes care of partial communication. The whole architecture has been evaluated through several benchmarks, statistical simulations, and field experiments involving 8 robots.},
  archive      = {J_AR},
  author       = {Bechon, Patrick and Lesire, Charles and Barbier, Magali},
  doi          = {10.1007/s10514-019-09869-w},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {3},
  pages        = {505-531},
  shortjournal = {Auton. Robot.},
  title        = {Hybrid planning and distributed iterative repair for multi-robot missions with communication losses},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hierarchical reinforcement learning via dynamic subspace
search for multi-agent planning. <em>AR</em>, <em>44</em>(3), 485–503.
(<a href="https://doi.org/10.1007/s10514-019-09871-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider scenarios where a swarm of unmanned vehicles (UxVs) seek to satisfy a number of diverse, spatially distributed objectives. The UxVs strive to determine an efficient plan to service the objectives while operating in a coordinated fashion. We focus on developing autonomous high-level planning, where low-level controls are leveraged from previous work in distributed motion, target tracking, localization, and communication. We rely on the use of state and action abstractions in a Markov decision processes framework to introduce a hierarchical algorithm, Dynamic Domain Reduction for Multi-Agent Planning, that enables multi-agent planning for large multi-objective environments. Our analysis establishes the correctness of our search procedure within specific subsets of the environments, termed ‘sub-environment’ and characterizes the algorithm performance with respect to the optimal trajectories in single-agent and sequential multi-agent deployment scenarios using tools from submodularity. Simulated results show significant improvement over using a standard Monte Carlo tree search in an environment with large state and action spaces.},
  archive      = {J_AR},
  author       = {Ma, Aaron and Ouimet, Michael and Cortés, Jorge},
  doi          = {10.1007/s10514-019-09871-2},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {3},
  pages        = {485-503},
  shortjournal = {Auton. Robot.},
  title        = {Hierarchical reinforcement learning via dynamic subspace search for multi-agent planning},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Average case constant factor time and distance optimal
multi-robot path planning in well-connected environments. <em>AR</em>,
<em>44</em>(3), 469–483. (<a
href="https://doi.org/10.1007/s10514-019-09858-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fast algorithms for optimal multi-robot path planning are sought after in real-world applications. Known methods, however, generally do not simultaneously guarantee good solution optimality and good (e.g., polynomial) running time. In this work, we develop a first low-polynomial running time algorithm, called SplitAndGroup (SaG), that solves the multi-robot path planning problem on grids and grid-like environments, and produces constant factor makespan optimal solutions on average over all problem instances. That is, SaG is an average case O(1)-approximation algorithm and computes solutions with sub-linear makespan. SaG is capable of handling cases when the density of robots is extremely high - in a graph-theoretic setting, the algorithm supports cases where all vertices of the underlying graph are occupied. SaG attains its desirable properties through a careful combination of a novel divide-and-conquer technique, which we denote as global decoupling, and network flow based methods for routing the robots. Solutions from SaG, in a weaker sense, are also a constant factor approximation on total distance optimality.},
  archive      = {J_AR},
  author       = {Yu, Jingjin},
  doi          = {10.1007/s10514-019-09858-z},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {3},
  pages        = {469-483},
  shortjournal = {Auton. Robot.},
  title        = {Average case constant factor time and distance optimal multi-robot path planning in well-connected environments},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). DRRT*: Scalable and informed asymptotically-optimal
multi-robot motion planning. <em>AR</em>, <em>44</em>(3), 443–467. (<a
href="https://doi.org/10.1007/s10514-019-09832-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many exciting robotic applications require multiple robots with many degrees of freedom, such as manipulators, to coordinate their motion in a shared workspace. Discovering high-quality paths in such scenarios can be achieved, in principle, by exploring the composite space of all robots. Sampling-based planners do so by building a roadmap or a tree data structure in the corresponding configuration space and can achieve asymptotic optimality. The hardness of motion planning, however, renders the explicit construction of such structures in the composite space of multiple robots impractical. This work proposes a scalable solution for such coupled multi-robot problems, which provides desirable path-quality guarantees and is also computationally efficient. In particular, the proposed $$\mathtt{dRRT^*}$$ is an informed, asymptotically-optimal extension of a prior sampling-based multi-robot motion planner, $$\mathtt{dRRT}$$. The prior approach introduced the idea of building roadmaps for each robot and implicitly searching the tensor product of these structures in the composite space. This work identifies the conditions for convergence to optimal paths in multi-robot problems, which the prior method was not achieving. Building on this analysis, $$\mathtt{dRRT}$$ is first properly adapted so as to achieve the theoretical guarantees and then further extended so as to make use of effective heuristics when searching the composite space of all robots. The case where the various robots share some degrees of freedom is also studied. Evaluation in simulation indicates that the new algorithm, $$\mathtt{dRRT^*}$$  converges to high-quality paths quickly and scales to a higher number of robots where various alternatives fail. This work also demonstrates the planner’s capability to solve problems involving multiple real-world robotic arms.},
  archive      = {J_AR},
  author       = {Shome, Rahul and Solovey, Kiril and Dobson, Andrew and Halperin, Dan and Bekris, Kostas E.},
  doi          = {10.1007/s10514-019-09832-9},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {3},
  pages        = {443-467},
  shortjournal = {Auton. Robot.},
  title        = {DRRT*: Scalable and informed asymptotically-optimal multi-robot motion planning},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On-board range-based relative localization for micro air
vehicles in indoor leader–follower flight. <em>AR</em>, <em>44</em>(3),
415–441. (<a href="https://doi.org/10.1007/s10514-019-09843-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a range-based solution for indoor relative localization by micro air vehicles (MAVs), achieving sufficient accuracy for leader–follower flight. Moving forward from previous work, we removed the dependency on a common heading measurement by the MAVs, making the relative localization accuracy independent of magnetometer readings. We found that this restricts the relative maneuvers that guarantee observability, and also that higher accuracy range measurements are required to rectify the missing heading information, yet both disadvantages can be tackled. Our implementation uses ultra wideband, for both range measurements between MAVs and sharing their velocities, accelerations, yaw rates, and height with each other. We showcased our implementation on a total of three Parrot Bebop 2.0 MAVs and performed leader–follower flight in a real-world indoor environment. The follower MAVs were autonomous and used only on-board sensors to track the same trajectory as the leader. They could follow the leader MAV in close proximity for the entire durations of the flights.},
  archive      = {J_AR},
  author       = {van der Helm, Steven and Coppola, Mario and McGuire, Kimberly N. and de Croon, Guido C. H. E.},
  doi          = {10.1007/s10514-019-09843-6},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {3},
  pages        = {415-441},
  shortjournal = {Auton. Robot.},
  title        = {On-board range-based relative localization for micro air vehicles in indoor leader–follower flight},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A robust localization system for multi-robot formations
based on an extension of a gaussian mixture probability hypothesis
density filter. <em>AR</em>, <em>44</em>(3), 395–414. (<a
href="https://doi.org/10.1007/s10514-019-09860-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a strategy for providing reliable state estimates that allow a group of robots to realize a formation even when communication fails and the tracking data alone is insufficient for maintaining a stable formation. Furthermore, the tracking information does not provide the identity of the robot, therefore a simple fusion of tracking and communication data is not possible. We extend a Gaussian mixture probability hypothesis density filter to incorporate, firstly, absolute poses exchanged by the robots, and secondly, the geometry of the desired formation. Our method of combining communicated data, information about the formation and sensory detections is capable of maintaining the state estimates even when long-duration occlusions occur, and improves awareness of the situation when the communication is sporadic or suffers from short-term outage. The proposed method is validated using a high-fidelity simulator in scenarios with a formation of up to five robots. The results show that the proposed tracking strategy allows for sustaining formations in cluttered environments, with high measurement uncertainty and low quality communication.},
  archive      = {J_AR},
  author       = {Wasik, Alicja and Lima, Pedro U. and Martinoli, Alcherio},
  doi          = {10.1007/s10514-019-09860-5},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {3},
  pages        = {395-414},
  shortjournal = {Auton. Robot.},
  title        = {A robust localization system for multi-robot formations based on an extension of a gaussian mixture probability hypothesis density filter},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). SOUL: Data sharing for robot swarms. <em>AR</em>,
<em>44</em>(3), 377–394. (<a
href="https://doi.org/10.1007/s10514-019-09855-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interconnected devices and mobile multi-robot systems are increasingly present in many real-life scenarios. To be effective, these systems need to collect large amounts of data from their environment, and often these data need to be aggregated, shared, and distributed. Many multi-robot systems are designed to share state information and commands, but their communication infrastructure is often too limited for significant data transfers. This paper introduces Swarm-Oriented Upload of Labeled data, a mechanism that allows members of a fully distributed system to share data with their peers. We leverage a BitTorrent-like strategy to share data in smaller chunks, or datagrams, with policies that minimize reconstruction time. We performed extensive simulations to study the properties of the system and to demonstrate its scalability. We report experiments conducted with real robots following two realistic deployment scenarios: searching for objects in a scene, and replacing the full identity of a defective robot.},
  archive      = {J_AR},
  author       = {Varadharajan, Vivek Shankar and St-Onge, David and Adams, Bram and Beltrame, Giovanni},
  doi          = {10.1007/s10514-019-09855-2},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {3},
  pages        = {377-394},
  shortjournal = {Auton. Robot.},
  title        = {SOUL: Data sharing for robot swarms},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Gaussian process decentralized data fusion meets transfer
learning in large-scale distributed cooperative perception. <em>AR</em>,
<em>44</em>(3), 359–376. (<a
href="https://doi.org/10.1007/s10514-018-09826-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents novel Gaussian process decentralized data fusion algorithms exploiting the notion of agent-centric support sets for distributed cooperative perception of large-scale environmental phenomena. To overcome the limitations of scale in existing works, our proposed algorithms allow every mobile sensing agent to utilize a different support set and dynamically switch to another during execution for encapsulating its own data into a local summary that, perhaps surprisingly, can still be assimilated with the other agents’ local summaries (i.e., based on their current support sets) into a globally consistent summary to be used for predicting the phenomenon. To achieve this, we propose a novel transfer learning mechanism for a team of agents capable of sharing and transferring information encapsulated in a summary based on a support set to that utilizing a different support set with some loss that can be theoretically bounded and analyzed. To alleviate the issue of information loss accumulating over multiple instances of transfer learning, we propose a new information sharing mechanism to be incorporated into our algorithms in order to achieve memory-efficient lazy transfer learning. Empirical evaluation on three real-world datasets for up to 128 agents show that our algorithms outperform the state-of-the-art methods.},
  archive      = {J_AR},
  author       = {Ouyang, Ruofei and Low, Bryan Kian Hsiang},
  doi          = {10.1007/s10514-018-09826-z},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {3},
  pages        = {359-376},
  shortjournal = {Auton. Robot.},
  title        = {Gaussian process decentralized data fusion meets transfer learning in large-scale distributed cooperative perception},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cooperative visual-inertial sensor fusion: Fundamental
equations and state determination in closed-form. <em>AR</em>,
<em>44</em>(3), 339–357. (<a
href="https://doi.org/10.1007/s10514-019-09841-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the visual and inertial sensor fusion problem in the cooperative case and provides new theoretical and basic results. Specifically, the case of two agents is investigated. Each agent is equipped with inertial sensors (accelerometer and gyroscope) and with a monocular camera. By using the monocular camera, each agent can observe the other agent. No additional camera observations (e.g., of external point features in the environment) are considered. First, the entire observable state is analytically derived. This state contains the relative position between the two agents (which includes the absolute scale), the relative velocity, the three Euler angles that express the rotation between the two local frames and all the accelerometer and gyroscope biases. Then, the basic equations that describe this system are analytically obtained. The last part of the paper describes the use of these equations to obtain a closed-form solution that provides the observable state in terms of the visual and inertial measurements provided in a short time interval. This last contribution is the extension of the results presented in Kaiser et al. (IEEE Robot Autom Lett 2(1):18–25, 2017), Martinelli (IEEE Trans Robot 28(1):44–60, 2012; Int J Comput Vis 106(2):138–152, 2014) to the cooperative case. The impact of the presence of the bias on the performance of this closed-form solution is also investigated and a simple and effective method to obtain the gyroscope bias is proposed. Extensive simulations clearly show that the proposed method is successful. It is worth noting that it is possible to automatically retrieve the absolute scale and simultaneously calibrate the gyroscopes not only without any prior knowledge (as in Kaiser et al. IEEE Robot Autom Lett 2(1):18–25, 2017), but also without external point features in the environment.},
  archive      = {J_AR},
  author       = {Martinelli, Agostino and Renzaglia, Alessandro and Oliva, Alexander},
  doi          = {10.1007/s10514-019-09841-8},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {3},
  pages        = {339-357},
  shortjournal = {Auton. Robot.},
  title        = {Cooperative visual-inertial sensor fusion: Fundamental equations and state determination in closed-form},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient recursive distributed state estimation of hidden
markov models over unreliable networks. <em>AR</em>, <em>44</em>(3),
321–338. (<a href="https://doi.org/10.1007/s10514-019-09854-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a scenario in which a process of interest, evolving within an environment occupied by several agents, is well-described probablistically via a Markov model. The agents each have local views and observe only some limited partial aspects of the world, but their overall task is to fuse their data to construct an integrated, global portrayal. The problem, however, is that their communications are unreliable: network links may fail, packets can be dropped, and generally the network might be partitioned for protracted periods. The fundamental problem then becomes one of consistency as agents in different parts of the network gain new information from their observations but can only share this with those with whom they are able to communicate. As the communication network changes, different views may be at odds; the challenge is to reconcile these differences. The issue is that correlations must be accounted for, lest some sensor data be double counted, inducing overconfidence or bias. As a means to address these problems, a new recursive consensus filter for distributed state estimation on hidden Markov models is presented. It is shown to be well-suited to multi-agent settings and associated applications since the algorithm is scalable, robust to network failure, capable of handling non-Gaussian transition and observation models, and is, therefore, quite general. Crucially, no global knowledge of the communication network is ever assumed. We have dubbed the algorithm a Hybrid method because two existing pieces are used in concert: the first, iterative conservative fusion is used to reach consensus over potentially correlated priors, while consensus over likelihoods, the second, is handled using weights based on a Metropolis Hastings Markov chain. To attain a detailed understanding of the theoretical upper limit for estimator performance modulo imperfect communication, we introduce an idealized distributed estimator. It is shown that under certain general conditions, the proposed Hybrid method converges exponentially to the ideal distributed estimator, despite the latter being purely conceptual and unrealizable in practice. An extensive evaluation of the Hybrid method, through a series of simulated experiments, shows that its performance surpasses competing algorithms.},
  archive      = {J_AR},
  author       = {Tamjidi, Amirhossein and Oftadeh, Reza and Chakravorty, Suman and Shell, Dylan},
  doi          = {10.1007/s10514-019-09854-3},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {3},
  pages        = {321-338},
  shortjournal = {Auton. Robot.},
  title        = {Efficient recursive distributed state estimation of hidden markov models over unreliable networks},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-robot online sensing strategies for the construction
of communication maps. <em>AR</em>, <em>44</em>(3), 299–319. (<a
href="https://doi.org/10.1007/s10514-019-09862-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper tackles the problem of constructing a communication map of a known environment using multiple robots. A communication map encodes information on whether two robots can communicate when they are at two arbitrary locations and plays a fundamental role for a multi-robot system deployment to reliably and effectively achieve a variety of tasks, such as environmental monitoring and exploration. Previous work on communication map building typically considered only scenarios with a fixed base station and designed offline methods, which did not exploit data collected online by the robots. This paper proposes Gaussian Process-based online methods to efficiently build a communication map with multiple robots. Such robots form a mesh network, where there is no fixed base station. Specifically, we provide two leader-follower online sensing strategies to coordinate and guide the robots while collecting data. Furthermore, we improve the performance and computational efficiency by exploiting prior communication models that can be built from the physical map of the environment. Extensive experimental results in simulation and with a team of TurtleBot 2 platforms validate the approach.},
  archive      = {J_AR},
  author       = {Quattrini Li, Alberto and Penumarthi, Phani Krishna and Banfi, Jacopo and Basilico, Nicola and O’Kane, Jason M. and Rekleitis, Ioannis and Nelakuditi, Srihari and Amigoni, Francesco},
  doi          = {10.1007/s10514-019-09862-3},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {3},
  pages        = {299-319},
  shortjournal = {Auton. Robot.},
  title        = {Multi-robot online sensing strategies for the construction of communication maps},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Guest editorial: Special issue on multi-robot and
multi-agent systems. <em>AR</em>, <em>44</em>(3), 297–298. (<a
href="https://doi.org/10.1007/s10514-020-09908-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AR},
  author       = {Ayanian, Nora and Robuffo Giordano, Paolo and Fitch, Robert and Franchi, Antonio and Sabattini, Lorenzo},
  doi          = {10.1007/s10514-020-09908-x},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {3},
  pages        = {297-298},
  shortjournal = {Auton. Robot.},
  title        = {Guest editorial: Special issue on multi-robot and multi-agent systems},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robustness and efficiency insights from a mechanical
coupling metric for ankle-actuated biped robots. <em>AR</em>,
<em>44</em>(2), 281–295. (<a
href="https://doi.org/10.1007/s10514-019-09893-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents results pertaining to the coupling between the actuated and unactuated degrees of freedom for biped robots. It is focused on revealing the qualitative relationship between a mechanical coupling metric and gait characteristics for an ankle-actuated biped robot. By considering robot models with varying masses, leg lengths and positions of the center of mass of the legs, it validates the universality of prior results based on a single robot model. The development of a method for designing ankle-actuated biped gaits is given in detail, and numerical computation is utilized to find the initial conditions needed to generate the ankle-actuated candidate gait regions. The correlation between the coupling metric and the maximum magnitude of disturbance that can be rejected is significant, regardless of the robot parameters. It indicates that robust gaits tend to have small coupling under zero disturbance so that the “reserve” coupling may be utilized to reject the disturbance. Furthermore, for the same walking speed, gaits with smaller cost of transport under zero disturbances have smaller coupling and therefore should be more robust, which highlights the value of gait optimization for biped walking. The coupling metric for hip actuation is also briefly discussed as a contrast.},
  archive      = {J_AR},
  author       = {Chen, Tan and Schmiedeler, James P. and Goodwine, Bill},
  doi          = {10.1007/s10514-019-09893-w},
  journal      = {Autonomous Robots},
  month        = {1},
  number       = {2},
  pages        = {281-295},
  shortjournal = {Auton. Robot.},
  title        = {Robustness and efficiency insights from a mechanical coupling metric for ankle-actuated biped robots},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Design of a new air pressure perception multi-cavity
pneumatic-driven earthworm-like soft robot. <em>AR</em>, <em>44</em>(2),
267–279. (<a href="https://doi.org/10.1007/s10514-019-09892-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a soft robot which can imitate the crawling locomotion of an earthworm. Locomotion of the robot can be achieved by expanding and contracting the body that is made of flexible material. Earthworm-like soft robot can agilely get through cramped space and has strong ability of self-adaption to an unstructured environment. A link of the earthworm-like robot is combined with three modules, and the robot is combined with multiple links. Experiments on a single module, two-links and three-links show that the soft robot can move and bend on condition of modules extension and contraction in a specified gait. In the process of earthworm-like robot movement, the internal pressure of each cavity is detected and adjusted in real-time to change the moving and bending state of earthworm-like soft robot to realize the ability of self-adaption to unstructured environment. The air pressure perception earthworm-like soft robot shows a great prospect in many complicate environment such as pipeline detection.},
  archive      = {J_AR},
  author       = {Tang, Zhijie and Lu, Jiaqi and Wang, Zhen and Chen, Weiwei and Feng, Hao},
  doi          = {10.1007/s10514-019-09892-x},
  journal      = {Autonomous Robots},
  month        = {1},
  number       = {2},
  pages        = {267-279},
  shortjournal = {Auton. Robot.},
  title        = {Design of a new air pressure perception multi-cavity pneumatic-driven earthworm-like soft robot},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Learning quasi-periodic robot motions from demonstration.
<em>AR</em>, <em>44</em>(2), 251–266. (<a
href="https://doi.org/10.1007/s10514-019-09891-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of Learning from Demonstration is to automatically transfer the skill knowledge from human to robot. Current researches focus on the problem of modeling aperiodic/periodic robot motions and extracting dynamic task parameters from the recorded sensory information. However, it is still not adequate for describing complex behaviors in an unstructured environment, such as searching for an unknown fitting position or painting/polishing an irregular surface. The quasi-periodic and stochastic properties cause a high demand for generalization ability of the modeling techniques. This paper proposes a systematic framework for learning quasi-periodic robot motions, which contains three steps: decomposition, modeling, and synthesization. Firstly FFT transform is performed to identify all the frequencies in the quasi-periodic motion. Then the motion is decomposed into an offset component, a series of harmonic and corresponding envelop components based on the concept of equivalent transformation. The offset component is extracted by Empirical Mode Decomposition, harmonic is separated by notch filter, and envelope component is extracted by Hilbert Transform. These components are either periodic or aperiodic. The aperiodic motions can be modeled by conventional techniques such as Gaussian Mixture Model and recovered by Gaussian Mixture Regression. The periodic motions are modeled in closed-form expressions. Finally, they are synthesized together to regenerate the robot motion. This modeling process captures both the aperiodicity and periodicity of a quasi-periodic motion. Simulation and experiment show that the proposed methods are feasible, effective and can predict robot motions beyond demonstrations. With this generalization ability, it is able to reduce the programming difficulty and demonstration complexity.},
  archive      = {J_AR},
  author       = {Li, Xiao and Cheng, Hongtai and Chen, Heping and Chen, Jiaming},
  doi          = {10.1007/s10514-019-09891-y},
  journal      = {Autonomous Robots},
  month        = {1},
  number       = {2},
  pages        = {251-266},
  shortjournal = {Auton. Robot.},
  title        = {Learning quasi-periodic robot motions from demonstration},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Application of lissajous curves in trajectory planning of
multiple agents. <em>AR</em>, <em>44</em>(2), 233–250. (<a
href="https://doi.org/10.1007/s10514-019-09888-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lissajous curves have been used in various engineering applications such as optics, imaging, antenna scan, machining, as well as mobile robotics. In this article, we propose and analytically justify a Lissajous curve based trajectory planning strategy for aerial multi-agent systems to achieve the following objectives simultaneously: (i) Collision free paths for repeated coverage of a region while maintaining a closed sensor ring around a specified center for all time. (ii) Guaranteed detection of any stationary or moving object enclosed within the ring in finite time without the possibility of undetected escape. This leverages known and some novel properties of Lissajous curves that we establish as a part of this work. This has several potential applications in civil and military missions such as search and surveillance, repeated patrolling, target detection and capture, and the proposed strategy meets all these objectives simultaneously. We validate the proposed strategy through simulations and experiments using differential drive ground robots. We also demonstrate the applicability of this strategy for aerial surveillance through a Software-In-Loop-Simulation for quadrotors.},
  archive      = {J_AR},
  author       = {Borkar, Aseem Vivek and Sinha, Arpita and Vachhani, Leena and Arya, Hemendra},
  doi          = {10.1007/s10514-019-09888-7},
  journal      = {Autonomous Robots},
  month        = {1},
  number       = {2},
  pages        = {233-250},
  shortjournal = {Auton. Robot.},
  title        = {Application of lissajous curves in trajectory planning of multiple agents},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A velocity obstacles approach for autonomous landing and
teleoperated robots. <em>AR</em>, <em>44</em>(2), 217–232. (<a
href="https://doi.org/10.1007/s10514-019-09887-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Velocity obstacles (VO) are one of the most successful methods to compute collision-free trajectory for multi-agent systems. VO provide for each autonomous robot the set of velocities that avoids collisions with other robots (sharing or not the same motion policy) and with moving or static obstacles in the environment. In this paper we will focus on a particular efficient implementation of the VO paradigm available in the literature, called optimal reciprocal collision avoidance. After highlighting and solving a couple of deadlock situations that the current implementation cannot manage, we extend this approach to two challenging applications: (1) the landing of a UAV onto a UGV in crowded environments, and (2) the generation of force feedback for teleoperated vehicles. The theoretical outcomes are validated in simulated scenarios using V-REP as a virtual robot development tool.},
  archive      = {J_AR},
  author       = {Battisti, Thomas and Muradore, Riccardo},
  doi          = {10.1007/s10514-019-09887-8},
  journal      = {Autonomous Robots},
  month        = {1},
  number       = {2},
  pages        = {217-232},
  shortjournal = {Auton. Robot.},
  title        = {A velocity obstacles approach for autonomous landing and teleoperated robots},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Model-referenced pose estimation using monocular vision for
autonomous intervention tasks. <em>AR</em>, <em>44</em>(2), 205–216. (<a
href="https://doi.org/10.1007/s10514-019-09886-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses vision-based underwater navigation techniques to automate underwater intervention tasks with robotic vehicles. A systematic procedure of model-referenced pose estimation is introduced to obtain the relative pose information between the underwater vehicle and the underwater structures whose geometry and shape are known. The vision-based pose estimation combined with inertial navigation enables underwater robots to navigate precisely around underwater structures for challenging underwater intervention tasks such as subsea construction, maintenance, and inspection. To demonstrate the feasibility of the proposed approach, a set of experiments were carried out in a test tank using an autonomous underwater vehicle.},
  archive      = {J_AR},
  author       = {Park, Jisung and Kim, Taeyun and Kim, Jinwhan},
  doi          = {10.1007/s10514-019-09886-9},
  journal      = {Autonomous Robots},
  month        = {1},
  number       = {2},
  pages        = {205-216},
  shortjournal = {Auton. Robot.},
  title        = {Model-referenced pose estimation using monocular vision for autonomous intervention tasks},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Asynchronous microphone arrays calibration and sound source
tracking. <em>AR</em>, <em>44</em>(2), 183–204. (<a
href="https://doi.org/10.1007/s10514-019-09885-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we proposed an optimisation method to solve the problem of sound source localisation and calibration of an asynchronous microphone array. This method is based on the graph-based formulation of the simultaneous localisation and mapping problem. In this formulation, a moving sound source is considered to be observed from a static microphone array. Traditional approaches for sound source localisation rely on the well-known geometrical information of the array and synchronous readings of the audio signals. Recent work relaxed these two requirements by estimating the temporal offset between pair of microphones based on the assumption that the clock timing of each microphone is exactly the same. This assumption requires the sound cards to be identically manufactured, which in practice is not possible to achieve. Hereby an approach is proposed to jointly estimate the array geometrical information, time offset and clock difference/drift rate of each microphone together with the location of a moving sound source. In addition, an observability analysis of the system is performed to investigate the most suitable configuration for sound source localisation. Simulation and experimental results are presented, which prove the effectiveness of the proposed methodology.},
  archive      = {J_AR},
  author       = {Su, Daobilige and Vidal-Calleja, Teresa and Miro, Jaime Valls},
  doi          = {10.1007/s10514-019-09885-w},
  journal      = {Autonomous Robots},
  month        = {1},
  number       = {2},
  pages        = {183-204},
  shortjournal = {Auton. Robot.},
  title        = {Asynchronous microphone arrays calibration and sound source tracking},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Simultaneous planning of sampling and optimization: Study on
lazy evaluation and configuration free space approximation for optimal
motion planning algorithm. <em>AR</em>, <em>44</em>(2), 165–181. (<a
href="https://doi.org/10.1007/s10514-019-09884-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A recent trend in optimal motion planning has broadened the research area toward the hybridization of sampling, optimization, and grid-based approaches. A synergy from such integrations can be expected to bring the overall performance improvement, but seamless integration and generalization is still an open problem. In this paper, we suggest a hybrid motion planning algorithm utilizing both sampling and optimization techniques, while simultaneously approximating a configuration-free space. Unlike conventional optimization-based approaches, the proposed algorithm does not depend on a priori information or resolution-complete factors, e.g., a distance field. Ours instead learns spatial information on the fly by exploiting empirical collisions found during the execution, and decentralizes the information over the constructed graph for an efficient reference. With the help of the learned information, we associate the constructed search graph with the approximate configuration-free space so that our optimization-based local planner exploits the local area to identify the connectivity of free space without depending on the precomputed workspace information. To show the novelty of the proposed algorithm, we apply the proposed idea to asymptotic optimal planners with lazy collision checking; lazy PRM$$^*$$ and Batch Informed Tree$$^*$$, and evaluate them against other state-of-the-arts in both synthetic and practical benchmarks with varying degrees of freedom. We also discuss the performance analysis, properties of different algorithm frameworks of lazy collision checking and our approximation method.},
  archive      = {J_AR},
  author       = {Kim, Donghyuk and Yoon, Sung-Eui},
  doi          = {10.1007/s10514-019-09884-x},
  journal      = {Autonomous Robots},
  month        = {1},
  number       = {2},
  pages        = {165-181},
  shortjournal = {Auton. Robot.},
  title        = {Simultaneous planning of sampling and optimization: Study on lazy evaluation and configuration free space approximation for optimal motion planning algorithm},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Online learning for 3D LiDAR-based human detection:
Experimental analysis of point cloud clustering and classification
methods. <em>AR</em>, <em>44</em>(2), 147–164. (<a
href="https://doi.org/10.1007/s10514-019-09883-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a system for online learning of human classifiers by mobile service robots using 3D LiDAR sensors, and its experimental evaluation in a large indoor public space. The learning framework requires a minimal set of labelled samples (e.g. one or several samples) to initialise a classifier. The classifier is then retrained iteratively during operation of the robot. New training samples are generated automatically using multi-target tracking and a pair of “experts” to estimate false negatives and false positives. Both classification and tracking utilise an efficient real-time clustering algorithm for segmentation of 3D point cloud data. We also introduce a new feature to improve human classification in sparse, long-range point clouds. We provide an extensive evaluation of our the framework using a 3D LiDAR dataset of people moving in a large indoor public space, which is made available to the research community. The experiments demonstrate the influence of the system components and improved classification of humans compared to the state-of-the-art.},
  archive      = {J_AR},
  author       = {Yan, Zhi and Duckett, Tom and Bellotto, Nicola},
  doi          = {10.1007/s10514-019-09883-y},
  journal      = {Autonomous Robots},
  month        = {1},
  number       = {2},
  pages        = {147-164},
  shortjournal = {Auton. Robot.},
  title        = {Online learning for 3D LiDAR-based human detection: Experimental analysis of point cloud clustering and classification methods},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Attention-based active visual search for mobile robots.
<em>AR</em>, <em>44</em>(2), 131–146. (<a
href="https://doi.org/10.1007/s10514-019-09882-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an active visual search model for finding objects in unknown environments. The proposed algorithm guides the robot towards the sought object using the relevant stimuli provided by the visual sensors. Existing search strategies are either purely reactive or use simplified sensor models that do not exploit all the visual information available. In this paper, we propose a new model that actively extracts visual information via visual attention techniques and, in conjunction with a non-myopic decision-making algorithm, leads the robot to search more relevant areas of the environment. The attention module couples both top-down and bottom-up attention models enabling the robot to search regions with higher importance first. The proposed algorithm is evaluated on a mobile robot platform in a 3D simulated environment. The results indicate that the use of visual attention significantly improves search, but the degree of improvement depends on the nature of the task and the complexity of the environment. In our experiments, we found that performance enhancements of up to 42% in structured and 38% in highly unstructured cluttered environments can be achieved using visual attention mechanisms.},
  archive      = {J_AR},
  author       = {Rasouli, Amir and Lanillos, Pablo and Cheng, Gordon and Tsotsos, John K.},
  doi          = {10.1007/s10514-019-09882-z},
  journal      = {Autonomous Robots},
  month        = {1},
  number       = {2},
  pages        = {131-146},
  shortjournal = {Auton. Robot.},
  title        = {Attention-based active visual search for mobile robots},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). DVL-SLAM: Sparse depth enhanced direct visual-LiDAR SLAM.
<em>AR</em>, <em>44</em>(2), 115–130. (<a
href="https://doi.org/10.1007/s10514-019-09881-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a framework for direct visual-LiDAR SLAM that combines the sparse depth measurement of light detection and ranging (LiDAR) with a monocular camera. The exploitation of the depth measurement between two sensor modalities has been reported in the literature but mostly by a keyframe-based approach or by using a dense depth map. When the sparsity becomes severe, the existing methods reveal limitation. The key finding of this paper is that the direct method is more robust under sparse depth with narrow field of view. The direct exploitation of sparse depth is achieved by implementing a joint optimization of each measurement under multiple keyframes. To ensure real-time performance, the keyframes of the sliding window are kept constant through rigorous marginalization. Through cross-validation, loop-closure achieves the robustness even in large-scale mapping. We intensively evaluated the proposed method using our own portable camera-LiDAR sensor system as well as the KITTI dataset. For the evaluation, the performance according to the LiDAR of sparsity was simulated by sampling the laser beam from 64 to 16 and 8. The experiment proves that the presented approach is significantly outperformed in terms of accuracy and robustness under sparse depth measurements.},
  archive      = {J_AR},
  author       = {Shin, Young-Sik and Park, Yeong Sang and Kim, Ayoung},
  doi          = {10.1007/s10514-019-09881-0},
  journal      = {Autonomous Robots},
  month        = {1},
  number       = {2},
  pages        = {115-130},
  shortjournal = {Auton. Robot.},
  title        = {DVL-SLAM: Sparse depth enhanced direct visual-LiDAR SLAM},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). SwarmCom: An infra-red-based mobile ad-hoc network for
severely constrained robots. <em>AR</em>, <em>44</em>(1), 93–114. (<a
href="https://doi.org/10.1007/s10514-019-09873-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Swarm robotics investigates groups of relatively simple robots that use decentralized control to achieve a common goal. While the robots of many swarm systems communicate via optical links, the underlying channels and their impact on swarm performance are poorly understood. This paper models the optical channel of a widely used robotic platform, the e-puck. It proposes SwarmCom, a mobile ad-hoc network for mobile robots. SwarmCom has a detector that, with the help of the channel model, was designed to adapt to the environment and nearby robots. Experiments with groups of up to 30 physical e-pucks show that (i) SwarmCom outperforms the state-of-the-art infra-red communication software—libIrcom—in range (up to 3 times further), bit error rate (between 50 and 63% lower), or throughput (up to 8 times higher) and that (ii) the maximum number of communication channels per robot is relatively low, which limits the load per robot even for high-density swarms. Using channel coding, the bit error rate can be further reduced at the expense of throughput. SwarmCom could have profound implications for swarm robotics, contributing to system understanding and reproducibility, while paving the way for novel applications.},
  archive      = {J_AR},
  author       = {Trenkwalder, Stefan M. and Esnaola, Iñaki and Kaszubowski Lopes, Yuri and Kolling, Andreas and Groß, Roderich},
  doi          = {10.1007/s10514-019-09873-0},
  journal      = {Autonomous Robots},
  month        = {1},
  number       = {1},
  pages        = {93-114},
  shortjournal = {Auton. Robot.},
  title        = {SwarmCom: An infra-red-based mobile ad-hoc network for severely constrained robots},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Live multicast video streaming from drones: An experimental
study. <em>AR</em>, <em>44</em>(1), 75–91. (<a
href="https://doi.org/10.1007/s10514-019-09851-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present and evaluate a multicast framework for point-to-multipoint and multipoint-to-point-to-multipoint video streaming that is applicable if both source and receiver nodes are mobile. Receiver nodes can join a multicast group by selecting a particular video stream and are dynamically elected as designated nodes based on their signal quality to provide feedback about packet reception. We evaluate the proposed application-layer rate-adaptive multicast video streaming over an aerial ad-hoc network that uses IEEE 802.11, a desirable protocol that, however, does not support a reliable multicast mechanism due to its inability to provide feedback from the receivers. Our rate-adaptive approach outperforms legacy multicast in terms of goodput, delay, and packet loss. Moreover, we obtain a gain in video quality (PSNR) of $$30\%$$ for point-to-multipoint and of $$20\%$$ for multipoint-to-point-to-multipoint streaming.},
  archive      = {J_AR},
  author       = {Muzaffar, Raheeb and Yanmaz, Evşen and Raffelsberger, Christian and Bettstetter, Christian and Cavallaro, Andrea},
  doi          = {10.1007/s10514-019-09851-6},
  journal      = {Autonomous Robots},
  month        = {1},
  number       = {1},
  pages        = {75-91},
  shortjournal = {Auton. Robot.},
  title        = {Live multicast video streaming from drones: An experimental study},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Distributed assignment with limited communication for
multi-robot multi-target tracking. <em>AR</em>, <em>44</em>(1), 57–73.
(<a href="https://doi.org/10.1007/s10514-019-09856-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of tracking multiple moving targets using a team of mobile robots. Each robot has a set of motion primitives to choose from in order to collectively maximize the number of targets tracked or the total quality of tracking. Our focus is on scenarios where communication is limited and the robots have limited time to share information with their neighbors. As a result, we seek distributed algorithms that can find solutions in a bounded amount of time. We present two algorithms: (1) a greedy algorithm that is guaranteed to find a 2-approximation to the optimal (centralized) solution but requiring |R| communication rounds in the worst case, where |R| denotes the number of robots, and (2) a local algorithm that finds a $$\mathcal {O}\left( (1+\epsilon )(1+1/h)\right) $$—approximation algorithm in $$\mathcal {O}(h\log 1/\epsilon )$$ communication rounds. Here, h and $$\epsilon $$ are parameters that allow the user to trade-off the solution quality with communication time. In addition to theoretical results, we present empirical evaluation including comparisons with centralized optimal solutions.},
  archive      = {J_AR},
  author       = {Sung, Yoonchang and Budhiraja, Ashish Kumar and Williams, Ryan K. and Tokekar, Pratap},
  doi          = {10.1007/s10514-019-09856-1},
  journal      = {Autonomous Robots},
  month        = {1},
  number       = {1},
  pages        = {57-73},
  shortjournal = {Auton. Robot.},
  title        = {Distributed assignment with limited communication for multi-robot multi-target tracking},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimizing multi-robot communication under bandwidth
constraints. <em>AR</em>, <em>44</em>(1), 43–55. (<a
href="https://doi.org/10.1007/s10514-019-09849-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots working collaboratively can share observations with others to improve team performance, but communication bandwidth is limited. Recognizing this, an agent must decide which observations to communicate to best serve the team. Accurately estimating the value of a single communication is expensive; finding an optimal combination of observations to put in the message is intractable. In this paper, we present OCBC, an algorithm for Optimizing Communication under Bandwidth Constraints. OCBC uses forward simulation to evaluate communications and applies a bandit-based combinatorial optimization algorithm to select what to include in a message. We evaluate OCBC’s performance in a simulated multi-robot navigation task. We show that OCBC achieves better task performance than a state-of-the-art method while communicating up to an order of magnitude less.},
  archive      = {J_AR},
  author       = {Marcotte, Ryan J. and Wang, Xipeng and Mehta, Dhanvin and Olson, Edwin},
  doi          = {10.1007/s10514-019-09849-0},
  journal      = {Autonomous Robots},
  month        = {1},
  number       = {1},
  pages        = {43-55},
  shortjournal = {Auton. Robot.},
  title        = {Optimizing multi-robot communication under bandwidth constraints},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Statistics of the distance traveled until successful
connectivity for unmanned vehicles. <em>AR</em>, <em>44</em>(1), 25–42.
(<a href="https://doi.org/10.1007/s10514-019-09850-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider a scenario where a robot needs to establish connectivity with a remote operator or another robot, as it moves along a path. We are interested in answering the following question: what is the distance traveled by the robot along the path before it finds a connected spot? More specifically, we are interested in characterizing the statistics of the distance traveled along the path before it gets connected, in realistic channel environments experiencing path loss, shadowing and multipath effects. We develop an exact mathematical analysis of these statistics for straight-line paths and also mathematically characterize a more general space of loop-free paths (beyond straight paths) for which the analysis holds, based on the properties of the path such as its curvature. Finally, we confirm our theoretical analysis using extensive numerical results with real channel parameters from downtown San Francisco.},
  archive      = {J_AR},
  author       = {Muralidharan, Arjun and Mostofi, Yasamin},
  doi          = {10.1007/s10514-019-09850-7},
  journal      = {Autonomous Robots},
  month        = {1},
  number       = {1},
  pages        = {25-42},
  shortjournal = {Auton. Robot.},
  title        = {Statistics of the distance traveled until successful connectivity for unmanned vehicles},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Transmission of images by unmanned underwater vehicles.
<em>AR</em>, <em>44</em>(1), 3–24. (<a
href="https://doi.org/10.1007/s10514-019-09866-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an acoustic communications medium, water is characterized by frequency dependent attenuation, short range, very low bandwidth, scattering, and multi-path. It is generally difficult to acoustically communicate even terse messages underwater much less images. For the naval mine counter-measures mission, there is value in transmitting images of mine-like objects, acquired by side-scan sonar on-board unmanned underwater vehicles, to the above-water operator for review. The contribution of this paper is a methodology and implementation, based on vector quantization, to compress and transmit snippets of side-scan sonar images from underway unmanned underwater vehicles to an operator. The work has been validated through controlled indoor tank tests and several at-sea trials. The fidelity of the received images is such that trained operators can recognize targets in the received images as well as they would have in the original images. Future work investigates machine learning to improve the compression basis and psycho-visual studies for the specialized skill of feature recognition in sonar images.},
  archive      = {J_AR},
  author       = {Danckaers, Alice and Seto, Mae L.},
  doi          = {10.1007/s10514-019-09866-z},
  journal      = {Autonomous Robots},
  month        = {1},
  number       = {1},
  pages        = {3-24},
  shortjournal = {Auton. Robot.},
  title        = {Transmission of images by unmanned underwater vehicles},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Guest editorial: Special issue on robot communication
challenges: Real-world problems, systems, and methods. <em>AR</em>,
<em>44</em>(1), 1–2. (<a
href="https://doi.org/10.1007/s10514-019-09898-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AR},
  author       = {Otte, Michael and Sofge, Donald and Fitch, Robert},
  doi          = {10.1007/s10514-019-09898-5},
  journal      = {Autonomous Robots},
  month        = {1},
  number       = {1},
  pages        = {1-2},
  shortjournal = {Auton. Robot.},
  title        = {Guest editorial: special issue on robot communication challenges: real-world problems, systems, and methods},
  volume       = {44},
  year         = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
