<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>NPL_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="npl---283">NPL - 283</h2>
<ul>
<li><details>
<summary>
(2020). Convergence of batch gradient method based on the entropy
error function for feedforward neural networks. <em>NPL</em>,
<em>52</em>(3), 2687–2695. (<a
href="https://doi.org/10.1007/s11063-020-10374-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gradient method is often used for the feedforward neural network training. Most of the studies so far have been focused on the square error function. In this paper, a novel entropy error function is proposed for the feedforward neural network training. The week and strong convergence analysis of the gradient method based on the entropy error function with batch input training patterns is strictly proved. Numerical examples are also given by the end of the paper for verifying the effectiveness and correctness. Compared with the square error function, our method provides both faster learning speed and better generalization for the given test problems.},
  archive      = {J_NPL},
  author       = {Xiong, Yan and Tong, Xin},
  doi          = {10.1007/s11063-020-10374-w},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {2687-2695},
  shortjournal = {Neural Process. Lett.},
  title        = {Convergence of batch gradient method based on the entropy error function for feedforward neural networks},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptive synchronization of complex dynamical networks via
distributed pinning impulsive control. <em>NPL</em>, <em>52</em>(3),
2669–2686. (<a
href="https://doi.org/10.1007/s11063-020-10373-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, exponential synchronization of a class of nonlinearly coupled complex dynamical networks with time-varying delay is investigated. A novel distributed controller combined with pinning impulsive method is designed by selecting the systems with largest norms of errors to be controlled at every impulsive instant. By introducing the adaptive control protocol into the negative feedback controller, suitable control gains are obtained and therefore, the control cost is efficiently saved. Based on the Lyapunov stability theory and some mathematical techniques, some novel leader-following synchronization criteria are derived. Furthermore, with consideration of time-varying impulsive effects, the obtained results are extended to a more complicated situation. Finally, two numerical examples are performed to illustrate the effectiveness of the theoretical analysis.},
  archive      = {J_NPL},
  author       = {Ding, Dong and Tang, Ze and Wang, Yan and Ji, Zhicheng},
  doi          = {10.1007/s11063-020-10373-x},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {2669-2686},
  shortjournal = {Neural Process. Lett.},
  title        = {Adaptive synchronization of complex dynamical networks via distributed pinning impulsive control},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Pedestrian detection based on light-weighted separable
convolution for advanced driver assistance systems. <em>NPL</em>,
<em>52</em>(3), 2655–2668. (<a
href="https://doi.org/10.1007/s11063-020-10367-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growth in the number of vehicles in the world makes it hard to safely share the environment with pedestrians. Pedestrian’s safety is an important task that needs to be granted in the traffic environment. New cars are equipped with advanced driver assistance systems (ADAS) with a variety of applications. Pedestrian detection application is one of the most important applications for an ADAS that needs to be enhanced. In this paper, we propose a pedestrian detection system to be implemented in an ADAS. The proposed system is based on convolutional neural networks thanks to its performance when solving computer vision applications. On the other side, the proposed system ensures real-time processing and high detection performance. The proposed system will be designed by tacking the advantage of building lightweight convolution blocks and model compression techniques to ensure an embedded implementation. Those blocks will guarantee high precision and fast processing speed. To train and evaluate the proposed system, we used the Caltech dataset. The evaluation of the proposed system resulted in 87% of mean average precision and an inference speed of 35 frames per second.},
  archive      = {J_NPL},
  author       = {Ayachi, Riadh and Said, Yahia and Ben Abdelaali, Abdessalem},
  doi          = {10.1007/s11063-020-10367-9},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {2655-2668},
  shortjournal = {Neural Process. Lett.},
  title        = {Pedestrian detection based on light-weighted separable convolution for advanced driver assistance systems},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Output layer multiplication for class imbalance problem in
convolutional neural networks. <em>NPL</em>, <em>52</em>(3), 2637–2653.
(<a href="https://doi.org/10.1007/s11063-020-10366-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) have demonstrated remarkable performance in the field of computer vision. However, they are prone to suffer from the class imbalance problem, in which the number of some classes is significantly higher or lower than that of other classes. Commonly, there are two main strategies to handle the problem, including dataset-level methods via resampling and algorithmic-level methods by modifying the existing learning frameworks. However, most of these methods need extra data resampling or elaborate algorithm design. In this work we provide an effective but extremely simple approach to tackle the imbalance problem in CNNs with cross-entropy loss. Specifically, we multiply a coefficient $$ \alpha &gt; 1 $$ to output of the last layer in a CNN model. With this modification, the final loss function can dynamically adjust the contributions of examples from different classes during the imbalanced training procedure. Because of its simplicity, the proposed method can be easily applied in the off-the-shelf models with little change. To prove the effectiveness on imbalance problem, we design three experiments on classification tasks of increasing complexity. The experimental results show that our approach could improve the convergence rate in the training stage and/or increase accuracy for test.},
  archive      = {J_NPL},
  author       = {Yang, Zhao and Zhu, Yuanxin and Liu, Tie and Zhao, Sai and Wang, Yunyan and Tao, Dapeng},
  doi          = {10.1007/s11063-020-10366-w},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {2637-2653},
  shortjournal = {Neural Process. Lett.},
  title        = {Output layer multiplication for class imbalance problem in convolutional neural networks},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Forecasting monthly tourism demand using enhanced
backpropagation neural network. <em>NPL</em>, <em>52</em>(3), 2607–2636.
(<a href="https://doi.org/10.1007/s11063-020-10363-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accurate forecasting of monthly tourism demand can improve tourism policies and planning. However, the complex nonlinear characteristics of monthly tourism demand complicate forecasting. This study proposes a novel approach named ICPSO-BPNN that combines improved chaotic particle swarm optimization (ICPSO) with backpropagation neural network (BPNN) to forecast monthly tourism demand. ICPSO with chaotic initialization and two search strategies, sigmoid-like inertia weight, and linear acceleration coefficients is utilized to search for the appropriate initial connection weights and thresholds necessary to improve the performance of BPNN. Two comparative real-life examples and one extended example are adopted to verify the superiority of the proposed ICPSO-BPNN. Results show ICPSO-BPNN outperforms that of the basic BPNN, autoregressive integrated moving average model, support vector regression, and other popular existing models.},
  archive      = {J_NPL},
  author       = {Wang, Lin and Wu, Binrong and Zhu, Qing and Zeng, Yu-Rong},
  doi          = {10.1007/s11063-020-10363-z},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {2607-2636},
  shortjournal = {Neural Process. Lett.},
  title        = {Forecasting monthly tourism demand using enhanced backpropagation neural network},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Detecting ordinal subcascades. <em>NPL</em>, <em>52</em>(3),
2583–2605. (<a
href="https://doi.org/10.1007/s11063-020-10362-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ordinal classifier cascades are constrained by a hypothesised order of the semantic class labels of a dataset. This order determines the overall structure of the decision regions in feature space. Assuming the correct order on these class labels will allow a high generalisation performance, while an incorrect one will lead to diminished results. In this way ordinal classifier systems can facilitate explorative data analysis allowing to screen for potential candidate orders of the class labels. Previously, we have shown that screening is possible for total orders of all class labels. However, as datasets might comprise samples of ordinal as well as non-ordinal classes, the assumption of a total ordering might be not appropriate. An analysis of subsets of classes is required to detect such hidden ordinal substructures. In this work, we devise a novel screening procedure for exhaustive evaluations of all order permutations of all subsets of classes by bounding the number of enumerations we have to examine. Experiments with multi-class data from diverse applications revealed ordinal substructures that generate new and support known relations.},
  archive      = {J_NPL},
  author       = {Lausser, Ludwig and Schäfer, Lisa M. and Kühlwein, Silke D. and Kestler, Angelika M. R. and Kestler, Hans A.},
  doi          = {10.1007/s11063-020-10362-0},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {2583-2605},
  shortjournal = {Neural Process. Lett.},
  title        = {Detecting ordinal subcascades},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evolutionary denoising-based machine learning for detecting
knee disorders. <em>NPL</em>, <em>52</em>(3), 2565–2581. (<a
href="https://doi.org/10.1007/s11063-020-10361-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surface electromyography (sEMG) is a non-invasive tool that can aid physiological assessment of knee disorders towards clinical interventions. Machine Learning (ML) is widely used to classify sEMG data to help with early detection of knee disorders; however, the inherent noise and the high non-linearity of sEMG signals make pattern recognition a challenging task. This study aims to partly overcome these challenges with existing ML-based classifiers by denoising sEMG signals further via an innovative two-fold evolutionary approach. A novel Genetic Algorithm-based denoising approach is applied to sEMG data to decrease the search space for pattern-related classification. Thereafter, the proposed denoising technique is coupled with an ML-based classifier to improve the discrimination between physiological and pathophysiological knee functions from sEMG data by optimising its hyperparameters too. Thus, the novel evolutionary approach serves two purposes. Firstly, it further reduces noise in sEMG signals via a new GA-based denoising technique to concurrently maximise mutual information and minimise entropy; secondly, it also enables the optimisation of the classifier’s hyperparameters. The classification performance of the resulting hybrid algorithm was validated using sEMG data on 144 subjects (67 patients with knee disorders, 77 healthy subjects) and was found higher (ACC = 99.57%, 95% CI: 99.47–99.66; AUC = 1, 95% CI: 0.98–1) than that of similar ML algorithms and published studies. The hybrid algorithm achieved the highest classification performance by leveraging an evolutionary approach for effective denoising and hyperparameter optimisation, whilst retaining the lowest computational cost. Thus, the proposed evolutionary denoising ML-based classifier is deemed an accurate and reliable decision support system to aid the detection of knee disorders.},
  archive      = {J_NPL},
  author       = {Parisi, Luca and RaviChandran, Narrendar},
  doi          = {10.1007/s11063-020-10361-1},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {2565-2581},
  shortjournal = {Neural Process. Lett.},
  title        = {Evolutionary denoising-based machine learning for detecting knee disorders},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Exploratory data analysis and foreground detection with the
growing hierarchical neural forest. <em>NPL</em>, <em>52</em>(3),
2537–2563. (<a
href="https://doi.org/10.1007/s11063-020-10360-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new self-organizing artificial neural network called growing hierarchical neural forest (GHNF) is proposed. The GHNF is a hierarchical model based on the growing neural forest, which is a tree-based model that learns a set of trees (forest) instead of a general graph so that the forest can grow in size. This way, the GHNF faces three important limitations regarding the self-organizing map: fixed size, fixed topology, and lack of hierarchical representation for input data. Hence, the GHNF is especially amenable to datasets containing clusters where each cluster has a hierarchical structure since each tree of the GHNF forest can adapt to one of the clusters. Experimental results show the goodness of our proposal in terms of self-organization and clustering capabilities. In particular, it has been applied to text mining of tweets as a typical exploratory data analysis application, where a hierarchical representation of concepts present in tweets has been obtained. Moreover, it has been applied to foreground detection in video sequences, outperforming several methods specialized in foreground detection.},
  archive      = {J_NPL},
  author       = {Palomo, Esteban J. and López-Rubio, Ezequiel and Ortega-Zamorano, Francisco and Benítez-Rochel, Rafaela},
  doi          = {10.1007/s11063-020-10360-2},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {2537-2563},
  shortjournal = {Neural Process. Lett.},
  title        = {Exploratory data analysis and foreground detection with the growing hierarchical neural forest},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust two-dimensional linear discriminant analysis via
information divergence. <em>NPL</em>, <em>52</em>(3), 2513–2535. (<a
href="https://doi.org/10.1007/s11063-020-10359-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the complexities of collected data that may contain outliers and noises, many variants of LDA and 2DLDA have been proposed to address this problem and have shown that the improved methods produce much better performance than classical LDA and 2DLDA. In this paper we propose a novel two-dimensional linear discriminant analysis method via information divergence. The proposed method applies the weighted L21 norm to learn a robust projection matrix in the image space. In the proposed model, we introduce the weights into the within-class scatter and the total scatter simultaneously, and learn the weights by imposing information divergence on the objective functions. To handle the proposed model, we resort to Dinkelbach’s extended algorithm to solve the proposed ratio minimization problem. Considering the characteristics of the subproblems, we exploit an equivalent representation of subproblems which can be solved by alternating optimization techniques where each block of variables has good optimization properties. The proposed model not only overcomes the small-sample-size problem, but also suppresses outliers by an adaptively weighted scheme with the guidance of information divergences. The experiments on several image data sets demonstrate that the classification performance of the proposed method is superior to that of some existing methods in the presence of outliers.},
  archive      = {J_NPL},
  author       = {Zhang, Lei and Liang, Zhizheng},
  doi          = {10.1007/s11063-020-10359-9},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {2513-2535},
  shortjournal = {Neural Process. Lett.},
  title        = {Robust two-dimensional linear discriminant analysis via information divergence},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Two-stage game strategy for multiclass imbalanced data
online prediction. <em>NPL</em>, <em>52</em>(3), 2493–2512. (<a
href="https://doi.org/10.1007/s11063-020-10358-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For multiclass imbalanced data online prediction, how to design a self-adapted model is a challenging problem. To address this issue, a novel dynamic multi-classification algorithm which uses two-stage game strategy has been put forward. Different from typical imbalanced classification methods, the proposed approach provided a self-updating model quantificationally, which can match the changes of arriving sample chunk automatically. In data generation phase, two dynamic ELMs with game theory are utilized for generating the lifelike minority class to equilibrate the distribution of different samples. In model update phase, both the current prediction performance and the cost sensitivity are taken into consideration simultaneously. According to the suffer loss and the shifty imbalance ratio, the proposed method develops the relationship between new weight and individual model, and an aggregate model of game theory is adopted to calculate the combination weight. These strategies help the algorithm reduce fitting error of sequence fragments. Also, alterative hidden-layer output matrix can be calculated according to the current fragment, thus building the steady network architecture in the next chunk. Numerical experiments are conducted on eight multiclass UCI datasets. The results demonstrate that the proposed algorithm not only has better generalization performance, but also improves the predictive ability of ELM method for minority samples.},
  archive      = {J_NPL},
  author       = {Yu, Haiyang and Chen, Chunyi and Yang, Huamin},
  doi          = {10.1007/s11063-020-10358-w},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {2493-2512},
  shortjournal = {Neural Process. Lett.},
  title        = {Two-stage game strategy for multiclass imbalanced data online prediction},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Extracting classification rules from artificial neural
network trained with discretized inputs. <em>NPL</em>, <em>52</em>(3),
2469–2491. (<a
href="https://doi.org/10.1007/s11063-020-10357-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rule extraction from artificial neural networks remains important task in complex diseases such as diabetes and breast cancer where the rules should be accurate and comprehensible. The quality of rules is improved by the improvement of the network classification accuracy which is done by the discretization of input attributes. In this paper, we developed a rule extraction algorithm based on multiobjective genetic algorithms and association rules mining to extract highly accurate and comprehensible classification rules from ANN’s that have been trained using the discretization of the continuous attributes. The data pre-processing provides very good improvement of the ANN accuracy and consequently leads to improve the performance of the classification rules in terms of fidelity and coverage. The results show that our algorithm is very suitable for medical decision making, so an excellent average accuracy of 94.73 has been achieved for the Pima dataset and 99.36 for the breast cancer dataset.},
  archive      = {J_NPL},
  author       = {Yedjour, Dounia},
  doi          = {10.1007/s11063-020-10357-x},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {2469-2491},
  shortjournal = {Neural Process. Lett.},
  title        = {Extracting classification rules from artificial neural network trained with discretized inputs},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Global stabilization of memristive neural networks with
leakage and time-varying delays via quantized sliding-mode controller.
<em>NPL</em>, <em>52</em>(3), 2451–2468. (<a
href="https://doi.org/10.1007/s11063-020-10356-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This pape investigates the global stabilization of memristive neural networks (MNNs) with leakage and time-varying delays via quantized sliding-mode controller. The leakage delay is considered in the MNNs. Sliding mode controller is imported to ensure global stabilization of delayed MNNs. We also introduce two quantization schemes with uniform quantizer and logarithmic quantizer. Our goal is to deal with errors before and after quantization. We give some simulations and comparisons between two quantizers in the end of this paper.},
  archive      = {J_NPL},
  author       = {Cao, Yuting and Sun, Bo and Guo, Zhenyuan and Huang, Tingwen and Yan, Zheng and Wen, Shiping},
  doi          = {10.1007/s11063-020-10356-y},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {2451-2468},
  shortjournal = {Neural Process. Lett.},
  title        = {Global stabilization of memristive neural networks with leakage and time-varying delays via quantized sliding-mode controller},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cost-sensitive dictionary learning for software defect
prediction. <em>NPL</em>, <em>52</em>(3), 2415–2449. (<a
href="https://doi.org/10.1007/s11063-020-10355-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, software defect prediction has been recognized as a cost-sensitive learning problem. To deal with the unequal misclassification losses resulted by different classification errors, some cost-sensitive dictionary learning methods have been proposed recently. Generally speaking, these methods usually define the misclassification costs to measure the unequal losses and then propose to minimize the cost-sensitive reconstruction loss by embedding the cost information into the reconstruction function of dictionary learning. Although promising performance has been achieved, their cost-sensitive reconstruction functions are not well-designed. In addition, no sufficient attentions are paid to the coding coefficients which can also be helpful to reduce the reconstruction loss. To address these issues, this paper proposes a new cost-sensitive reconstruction loss function and introduces an additional cost-sensitive discrimination regularization for the coding coefficients. Both the two terms are jointly optimized in a unified cost-sensitive dictionary learning framework. By doing so, we can achieve the minimum reconstruction loss and thus obtain a more cost-sensitive dictionary for feature encoding of test data. In the experimental part, we have conducted extensive experiments on twenty-five software projects from four benchmark datasets of NASA, AEEEM, ReLink and Jureczko. The results, in comparison with ten state-of-the-art software defect prediction methods, demonstrate the effectiveness of learned cost-sensitive dictionary for software defect prediction.},
  archive      = {J_NPL},
  author       = {Niu, Liang and Wan, Jianwu and Wang, Hongyuan and Zhou, Kaiwei},
  doi          = {10.1007/s11063-020-10355-z},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {2415-2449},
  shortjournal = {Neural Process. Lett.},
  title        = {Cost-sensitive dictionary learning for software defect prediction},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). EW-fisher: A novel loss function for deep learning-based
image co-segmentation. <em>NPL</em>, <em>52</em>(3), 2399–2413. (<a
href="https://doi.org/10.1007/s11063-020-10354-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The loss function is an important factor for the success of machine learning. This paper proposes a new loss function for deep learning-based image co-segmentation. It aims to maximize the inter-class difference between the foreground and the background and at the same time minimize the two intra-class variances. This idea has some similarity to the Fisher criterion in pattern recognition. We further embed an edge weighting strategy into this form of Fisher-like criterion to let the pixels near the foreground edges be paid more attentions in the training process for achieving the finer segmentation. The resultant loss function is called EW-Fisher (Edge-Weighted Fisher). We apply the proposed EW-Fisher loss to image co-segmentation and evaluate it on commonly used datasets. In the experiments, the EW-Fisher stably outperforms the most-widely used cross-entropy loss and Dice loss as well as the recently presented edge agreement loss and Hausdorff distance loss. The comparison results and the ablation studies prove the values of our Fisher-like learning criterion and edge weighting strategy.},
  archive      = {J_NPL},
  author       = {Gong, Xiaopeng and Liu, Xiabi and Duan, Xin and Li, Yushuo},
  doi          = {10.1007/s11063-020-10354-0},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {2399-2413},
  shortjournal = {Neural Process. Lett.},
  title        = {EW-fisher: A novel loss function for deep learning-based image co-segmentation},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A robust least squares support vector machine based on
l∞-norm. <em>NPL</em>, <em>52</em>(3), 2371–2397. (<a
href="https://doi.org/10.1007/s11063-020-10353-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A family of norm-based least squares support vector machines (LSSVMs) is the effective statistical learning tool and has attracted considerable attentions. However, there are two critical problems: (1) LSSVM is ill-conditioned or singular when the sample size is much less than feature number and thus causes over-fitting for small sample size (SSS) problem, while other norm-based LSSVMs own slower training speed and cannot deal with large scale data. (2) Norm-based LSSVMs pay less attention to the edge points that are important for learning the final classifier. To overcome the above drawbacks, by replacing $$ L_{2}\text{-}norm $$ with $$ L_{\infty }\text{-}norm $$ in empirical loss, we construct a robust classifier, named $$ L_{\infty }\text{-}LSSVM $$ in short. After adjustment, $$ L_{\infty }\text{-}LSSVM $$ can detect edge points effectively and enhances the capability of the robustness and the generalization. Also, inspired by the idea of sequential minimal optimization (SMO), we design a novel SMO-typed iterative algorithm. The new algorithm not only guarantees the convergence of optimum solution in theory, but also owns the lower computational time and storage space when data size is large. Finally, extensive numerical experiments validate the above opinions again on four groups of artificial data, Non-i.i.d data: fault detection of railway turnout, four SSS datasets, two types of massive datasets and six benchmark datasets.},
  archive      = {J_NPL},
  author       = {Ke, Ting and Zhang, Lidong and Ge, Xuechun and Lv, Hui and Li, Min},
  doi          = {10.1007/s11063-020-10353-1},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {2371-2397},
  shortjournal = {Neural Process. Lett.},
  title        = {A robust least squares support vector machine based on l∞-norm},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptively converting auxiliary attributes and textual
embedding for video captioning based on BiLSTM. <em>NPL</em>,
<em>52</em>(3), 2353–2369. (<a
href="https://doi.org/10.1007/s11063-020-10352-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatically generating captions for videos faces a huge challenge since it is a cross-modal cross task that involves vision and texts. Most of the existing models generate the captioning words merely based on the video visual content features, ignoring the important underlying semantic information. The relationship between explicit semantics and hidden visual content is not holistically exploited, thus hardly describing fine-grained caption accurately from a global view. To better extract and integrate the semantic information, we propose a novel encoder-decoder framework of bi-directional long short-term memory with attention model and conversion gate (BiLSTM-CG), which transfers auxiliary attributes and then generates detailed captioning. Specifically, we extract semantic attributes from sliced frames in a multiple-instance learning (MIL) manner. MIL algorithms attempt to learn a classification function that can predict the labels of bags and/or instances in the visual content. In the encoding stage, we adopt 2D and 3D convolutional neural networks to encode video clips, and then feed the concatenate features into a BiLSTM. In decoding stage, we design a CG to adaptively fuse semantic attributes into hidden features at word level, and a CG can convert auxiliary attributes and textual embedding for video captioning. Furthermore, the CG has an ability to automatically decide the optimal time stamp to capture the explicit semantic or rely on the hidden states of the language model to generate the next word. Extensive experiments conducted on the MSR-VTT and MSVD video captioning datasets demonstrate the effectiveness of our method compared with state-of-the-art approaches.},
  archive      = {J_NPL},
  author       = {Chen, Shuqin and Zhong, Xian and Li, Lin and Liu, Wenxuan and Gu, Cheng and Zhong, Luo},
  doi          = {10.1007/s11063-020-10352-2},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {2353-2369},
  shortjournal = {Neural Process. Lett.},
  title        = {Adaptively converting auxiliary attributes and textual embedding for video captioning based on BiLSTM},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Specialization in hierarchical learning systems.
<em>NPL</em>, <em>52</em>(3), 2319–2352. (<a
href="https://doi.org/10.1007/s11063-020-10351-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Joining multiple decision-makers together is a powerful way to obtain more sophisticated decision-making systems, but requires to address the questions of division of labor and specialization. We investigate in how far information constraints in hierarchies of experts not only provide a principled method for regularization but also to enforce specialization. In particular, we devise an information-theoretically motivated on-line learning rule that allows partitioning of the problem space into multiple sub-problems that can be solved by the individual experts. We demonstrate two different ways to apply our method: (i) partitioning problems based on individual data samples and (ii) based on sets of data samples representing tasks. Approach (i) equips the system with the ability to solve complex decision-making problems by finding an optimal combination of local expert decision-makers. Approach (ii) leads to decision-makers specialized in solving families of tasks, which equips the system with the ability to solve meta-learning problems. We show the broad applicability of our approach on a range of problems including classification, regression, density estimation, and reinforcement learning problems, both in the standard machine learning setup and in a meta-learning setting.},
  archive      = {J_NPL},
  author       = {Hihn, Heinke and Braun, Daniel A.},
  doi          = {10.1007/s11063-020-10351-3},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {2319-2352},
  shortjournal = {Neural Process. Lett.},
  title        = {Specialization in hierarchical learning systems},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Solar radiation estimation in mediterranean climate by
weather variables using a novel bayesian model averaging and machine
learning methods. <em>NPL</em>, <em>52</em>(3), 2297–2318. (<a
href="https://doi.org/10.1007/s11063-020-10350-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present study investigated the potential of new ensemble method, Bayesian model averaging (BMA), in modeling monthly solar radiation based on climatic data. Data records covered monthly maximum temperature (Tmax), minimum temperature (Tmin), sunshine hours (Hs), wind speed (Ws), relative humidity (RH), and solar radiation values obtained from two weather stations of Turkey. The BMA estimates were compared with the artificial neural networks (ANN), extreme learning machines (ELM), radial basis function (RBF), and their hybrid versions with wavelet transform technique (wavelet-ANN or WANN, wavelet-ELM or WELM, and wavelet-RBF or WRBF). Three evaluation criteria e.g., root mean square error (RMSE), Nash–Sutcliffe efficiency, and determination coefficient (R2), were applied to measure the accuracy of the employed methods. The results indicated the superior accuracy of the BMA4 models over six machine learning models for estimating monthly solar radiation; improvements in accuracy of ANN4, ELM4, RBF4, WANN4, WELM4, and WRBF4 models comprising Tmax, Tmin, Hs, Ws and RH input variables were about 56–41%, 44–31%, 57–46%, 35–26%, 27–16%, and 43–28% in terms of RMSE reduction in both stations. While the hybrid models (i.e., WANN4, WELM4, and WRBF4) increased the accuracy of the single models about 31–21%, 23–18%, and 26–25% for ANN4, ELM4, and RBF4, respectively.},
  archive      = {J_NPL},
  author       = {Kisi, Ozgur and Alizamir, Meysam and Trajkovic, Slavisa and Shiri, Jalal and Kim, Sungwon},
  doi          = {10.1007/s11063-020-10350-4},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {2297-2318},
  shortjournal = {Neural Process. Lett.},
  title        = {Solar radiation estimation in mediterranean climate by weather variables using a novel bayesian model averaging and machine learning methods},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Complementary boundary estimation network for temporal
action proposal generation. <em>NPL</em>, <em>52</em>(3), 2275–2295. (<a
href="https://doi.org/10.1007/s11063-020-10349-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal Action Detection is an important yet challenging task, in which temporal action proposal generation plays an important part. Since the temporal boundaries of action instances in videos are often ambiguous, it’s difficult to locate them precisely. Boundary Sensitive Network (BSN) (Lin et al. in ECCV, 2018) is a state-of-the-art corner-based method that can generate high-quality proposals with high recall rate. It contains a temporal evaluation network and a proposal evaluation network to generate and evaluate proposals separately, which can find the temporal boundaries of action instances directly to produce proposals with flexible temporal intervals and evaluate the quality of proposals. But BSN still has some issues: (1) Due to the small reception field of temporal evaluation network, it often generates many false temporal boundaries. (2) Evaluating the quality of proposals is a difficult task and not well solved in the paper. To address these issues, we propose Complementary Boundary Estimation Network (CBEN), an improved approach to temporal action proposal generation based on the framework of BSN. Specifically, we improve BSN in two aspects: Firstly, considering the temporal evaluation network of BSN can only capture local information and tends to have high response at background segments, we combine it with a new network with larger reception field to better identify false temporal action boundaries. Secondly, to evaluate the quality of temporal action proposals more accurately, we propose a class-based proposal evaluation network and combine it with a tIoU-based proposal evaluation network to filter out low-quality proposals. Extensive experiments on THUMOS14 and ActivityNet-1.3 datasets indicate that CBEN can achieve better performance than current mainstream methods on temporal action proposal generation. We further combine CBEN with an off-the-shelf action classifier, and show consistent performance improvements on THUMOS14 dataset.},
  archive      = {J_NPL},
  author       = {Wang, Jinding and Hu, Haifeng},
  doi          = {10.1007/s11063-020-10349-x},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {2275-2295},
  shortjournal = {Neural Process. Lett.},
  title        = {Complementary boundary estimation network for temporal action proposal generation},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Finite time anti-synchronization of quaternion-valued neural
networks with asynchronous time-varying delays. <em>NPL</em>,
<em>52</em>(3), 2253–2274. (<a
href="https://doi.org/10.1007/s11063-020-10348-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the finite time anti-synchronization (A-SYN) of master-slave coupled quaternion-valued neural networks, where the time-varying delays can be asynchronous and unbounded. Without adopting the general decomposition method, the quaternion-valued state is considered as a whole, which greatly reduces the hassle of further analysis and calculations. The designed controller is delay-free, and the terms with time delay do not need to be bounded globally. Several sufficient conditions for ensuring the finite time A-SYN are obtained under 1-norm and 2-norm respectively. The A-SYN error will be proved to evolve from the initial value to 1 in finite time, and evolve from 1 to 0 also in finite time, hence the finite time A-SYN is proved, which is called two-phases-method. Moreover, adaptive rules for control strengths are also designed to realize the finite time A-SYN. Lastly, a numerical example is presented to demonstrate the correctness and effectiveness of our obtained results.},
  archive      = {J_NPL},
  author       = {Li, Zihan and Liu, Xiwei},
  doi          = {10.1007/s11063-020-10348-y},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {2253-2274},
  shortjournal = {Neural Process. Lett.},
  title        = {Finite time anti-synchronization of quaternion-valued neural networks with asynchronous time-varying delays},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Locate the bounding box of neural networks with intervals.
<em>NPL</em>, <em>52</em>(3), 2241–2251. (<a
href="https://doi.org/10.1007/s11063-020-10347-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel hybrid method is proposed for neural network training. The method consists of two phases: in the first phase the bounds for the neural network parameters are estimated using a genetic algorithm that uses intervals as chromosomes. In the second phase a genetic algorithm is used to train the neural network inside the bounding box located by the first phase. The proposed method is tested on a series of well-known datasets from the relevant literature and the results are reported.},
  archive      = {J_NPL},
  author       = {Anastasopoulos, Nikolaos and Tsoulos, Ioannis G. and Karvounis, Evangelos and Tzallas, Alexandros},
  doi          = {10.1007/s11063-020-10347-z},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {2241-2251},
  shortjournal = {Neural Process. Lett.},
  title        = {Locate the bounding box of neural networks with intervals},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improved sparsity of support vector machine with robustness
towards label noise based on rescaled <span
class="math display"><em>α</em></span> -hinge loss with non-smooth
regularizer. <em>NPL</em>, <em>52</em>(3), 2211–2239. (<a
href="https://doi.org/10.1007/s11063-020-10346-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As support vector machines (SVM) are used extensively in machine learning applications, it becomes essential to obtain a sparse model that is also robust to noise in the data set. Although many researchers have presented different approaches to get a robust SVM, the work on robust SVM based on rescaled hinge loss function (RSVM-RHHQ) has attracted a great deal of attention. The method of using correntropy with hinge loss function has added a noticeable amount of robustness to the model. However, the sparsity of the model can be further improved. In this work, we focus on enhancing the sparsity of RSVM-RHHQ. As this work is the improved version of the RSVM-RHHQ, we follow the same track (of adding noise in the data) of RSVM-RHHQ with altogether a new problem formulation. We apply correntropy to the $$\alpha $$ -hinge loss function, which results in a better loss function than the rescaled hinge loss function. We use a non-smooth regularizer with a non-convex and non-smooth loss function. We solve this non-smooth and non-convex problem using the primal–dual proximal method. We find that this combination not only adds sparsity to the model, but it is also better than the existing robust SVM methods in terms of robustness towards label noise. We also provide the convergence proof of the proposed approach. In addition, the time complexity of the optimization technique is included. We perform experiments over various publicly available real-world data sets to compare the proposed method with the existing robust SVM methods. For experimentation purposes, we use small data sets, large data sets, and also data sets with significant class imbalance. Experimental results show that the proposed approach outperforms existing methods in sparseness, accuracy, and robustness. We also provide the sensitivity analysis of the regularization parameter for the label noise in the data set.},
  archive      = {J_NPL},
  author       = {Singla, Manisha and Ghosh, Debdas and Shukla, K. K.},
  doi          = {10.1007/s11063-020-10346-0},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {2211-2239},
  shortjournal = {Neural Process. Lett.},
  title        = {Improved sparsity of support vector machine with robustness towards label noise based on rescaled $$\alpha $$ -hinge loss with non-smooth regularizer},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new robust fuzzy clustering approach: DBKIFCM.
<em>NPL</em>, <em>52</em>(3), 2189–2210. (<a
href="https://doi.org/10.1007/s11063-020-10345-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A clustering algorithm—Distance Based Gaussian Kernelized Intuitionistic Fuzzy C Means (DBKIFCM) is proposed. This algorithm is based on Gaussian kernel, outlier identification, and intuitionist fuzzy sets. It is intended to resolve the issue of presence of outliers, problem of sensitivity to initialization (STI) and is motivated by good performance of Radial Based Kernelized Intuitionistic Fuzzy C Means (KIFCM-RBF). Experiments are performed on standard 2D data sets such as Diamond (D12 and D15), and Dunn and real-world high dimension data sets such as Fisheriris, Wisconsin breast cancer, and Wine. DBKIFCM outcomes are studied in relation to Fuzzy C Means (FCM), Intuitionistic Fuzzy C Means (IFCM), KIFCM-RBF, Density Oriented Fuzzy C Means (DOFCM). It is observed that proposed approach significantly outperforms the earlier proposed algorithms with respect to outlier identification, effect of noise, issue of STI, and clustering error.},
  archive      = {J_NPL},
  author       = {Gosain, Anjana and Dahiya, Sonika},
  doi          = {10.1007/s11063-020-10345-1},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {2189-2210},
  shortjournal = {Neural Process. Lett.},
  title        = {A new robust fuzzy clustering approach: DBKIFCM},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Region stability and stabilization of recurrent neural
network with parameter disturbances. <em>NPL</em>, <em>52</em>(3),
2175–2188. (<a
href="https://doi.org/10.1007/s11063-020-10344-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper mainly focuses on global region stability and stabilization analysis for recurrent neural networks with certain or uncertain parameter disturbances. Firstly, it presents global region stability results for recurrent neural networks with certain parameter disturbances by state partition and mathematical analysis methods. Next, it designs one adaptive controller to stabilize network states to the desired region for recurrent neural networks with uncertain parameter disturbances. At last, it gives two numerical examples for verifying obtained results.},
  archive      = {J_NPL},
  author       = {Bao, Gang and Peng, Yue and Zhou, Xue and Gong, Shunqi},
  doi          = {10.1007/s11063-020-10344-2},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {2175-2188},
  shortjournal = {Neural Process. Lett.},
  title        = {Region stability and stabilization of recurrent neural network with parameter disturbances},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptive decision threshold-based extreme learning machine
for classifying imbalanced multi-label data. <em>NPL</em>,
<em>52</em>(3), 2151–2173. (<a
href="https://doi.org/10.1007/s11063-020-10343-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label learning is a popular area of machine learning research as it is widely applicable to many real-world scenarios. In comparison with traditional binary and multi-classification tasks, the multi-label data are more easily impacted or destroyed by an imbalanced data distribution. This paper describes an adaptive decision threshold-based extreme learning machine algorithm (ADT-ELM) that addresses the imbalanced multi-label data classification problem. Specifically, the macro and micro F-measure metrics are adopted as the optimization functions for ADT-ELM, and the particle swarm optimization algorithm is employed to determine the optimal decision threshold combination. We use the optimized thresholds to make decision for future multi-label instances. Twelve baseline multi-label data sets are used in a series of experiments o verify the effectiveness and superiority of the proposed algorithm. The experimental results indicate that the proposed ADT-ELM algorithm is significantly superior to many state-of-the-art multi-label imbalance learning algorithms, and it generally requires less training time than more sophisticated algorithms.},
  archive      = {J_NPL},
  author       = {Gao, Shang and Dong, Wenlu and Cheng, Ke and Yang, Xibei and Zheng, Shang and Yu, Hualong},
  doi          = {10.1007/s11063-020-10343-3},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {2151-2173},
  shortjournal = {Neural Process. Lett.},
  title        = {Adaptive decision threshold-based extreme learning machine for classifying imbalanced multi-label data},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Low-rank discriminative adaptive graph preserving subspace
learning. <em>NPL</em>, <em>52</em>(3), 2127–2149. (<a
href="https://doi.org/10.1007/s11063-020-10340-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The global and local geometric structures of data play a key role in subspace learning. Although many manifold-based subspace learning methods have been proposed for preserving the local geometric structure of data, they usually use a predefined neighbor graph to characterize it. However, the predefined neighbor graph might be not optimal since it keeps fixed during the subsequent subspace learning process. Moreover, most manifold-based subspace learning methods ignore the global structure of data. To address these issues, we propose a low-rank discriminative adaptive graph preserving (LRDAGP) subspace learning method for image feature extraction and recognition by integrating the low-rank representation , adaptive manifold learning, and supervised regularizer into a unified framework. To capture the optimal local geometric structure of data for subspace learning, LRDAGP adopts an adaptive manifold learning strategy that the neighbor graph is adaptively updated during the subspace learning process. To capture the optimal global structure of data for subspace learning, LRDAGP also seeks the low-rank representations of data in a low-dimensional subspace during the subspace learning process. Moreover, for improving the discrimination ability of the learned subspace, a supervised regularizer is designed and incorporated into the LRDAGP model. Experimental results on several image datasets show that LRDAGP is effective for image feature extraction and recognition.},
  archive      = {J_NPL},
  author       = {Du, Haishun and Wang, Yuxi and Zhang, Fan and Zhou, Yi},
  doi          = {10.1007/s11063-020-10340-6},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {2127-2149},
  shortjournal = {Neural Process. Lett.},
  title        = {Low-rank discriminative adaptive graph preserving subspace learning},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust biometrics from motion wearable sensors using a
d-vector approach. <em>NPL</em>, <em>52</em>(3), 2109–2125. (<a
href="https://doi.org/10.1007/s11063-020-10339-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a d-vector approach for extracting robust biometrics from inertial signals recorded with wearable sensors. The d-vector approach generates identity representations using a deep learning architecture composed of Convolutional Neural Networks. This architecture includes two convolutional layers for learning features from the inertial signal spectrum. These layers were pretrained using data from 154 subjects. After that, additional fully connected layers were attached to perform user identification and verification, considering 36 new subjects. This paper compares the proposed d-vector approach with previous proposed algorithms using in-the-wild recordings in different scenarios. The results demonstrated the robustness of the proposed d-vector approach for in-the-wild conditions: 97.69% and 94.16% accuracies (for user identification) and 99.89% and 99.67% Areas Under the Curve (for user verification) were obtained using one (walking) or several activities (walking, jogging and stairs) respectively. These results were also verified in laboratory conditions improving the performance reported in previous works. All the analyses were carried out using public datasets recorded at the Wireless Sensor Data Mining laboratory.},
  archive      = {J_NPL},
  author       = {Gil-Martín, Manuel and San-Segundo, Rubén and de Córdoba, Ricardo and Pardo, José Manuel},
  doi          = {10.1007/s11063-020-10339-z},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {2109-2125},
  shortjournal = {Neural Process. Lett.},
  title        = {Robust biometrics from motion wearable sensors using a D-vector approach},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An LMI based state estimation for fractional-order
memristive neural networks with leakage and time delays. <em>NPL</em>,
<em>52</em>(3), 2089–2108. (<a
href="https://doi.org/10.1007/s11063-020-10338-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the state estimation problem for a class of fractional-order memristive neural networks (FOMNNs) with leakage and time delay. The main objective of this study is to construct an efficient estimator such that the state of the corresponding estimation error is globally stable. Distinct to the previous studies, the state estimation problem of FOMNNs is investigated through fractional-order Lyapunov direct method. The sufficient conditions that ensure the global stability of the error system has been derived as a set of solvable linear matrix inequalities. In order to validate the effectiveness of the proposed theoretical results, two numerical examples have been illustrated.},
  archive      = {J_NPL},
  author       = {Nagamani, G. and Shafiya, M. and Soundararajan, G.},
  doi          = {10.1007/s11063-020-10338-0},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {2089-2108},
  shortjournal = {Neural Process. Lett.},
  title        = {An LMI based state estimation for fractional-order memristive neural networks with leakage and time delays},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Asynchronous <span
class="math display"><em>l</em><sub>2</sub></span> – <span
class="math display"><em>l</em><sub>∞</sub></span> filtering for
discrete-time fuzzy markov jump neural networks with unreliable
communication links. <em>NPL</em>, <em>52</em>(3), 2069–2088. (<a
href="https://doi.org/10.1007/s11063-020-10337-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the problem of $$l_{2}$$ – $$l_{\infty }$$ asynchronous filtering for a class of discrete-time fuzzy neural networks subject to Markov jump parameters and unreliable communication links. Due to the fact that neural networks possess the nonlinear dynamic characteristic, it is difficult to deal with such a nonlinear characteristic directly, so the Takagi–Sugeno fuzzy model is introduced to approximate the system. Directed against the unreliable communication links, the data packet loss depicted by a stochastic variable with Bernoulli distribution and the signal quantization phenomenon occurring in communication channels are taken into consideration simultaneously. The attention of this paper is mainly centered on devising an asynchronous $$l_{2}$$ – $$l_{\infty }$$ filter for ensuring the $$l_{2}$$ – $$l_{\infty }$$ performance of the studied system under asynchronous conditions. Some sufficient conditions for the existence of the asynchronous $$l_{2}$$ – $$l_{\infty }$$ filter are presented. Finally, a numerical example is given to carry out the simulation experiment, which can verify the effectiveness of the obtained results.},
  archive      = {J_NPL},
  author       = {Zhang, Yigang and Xia, Jianwei and Huang, Xia and Wang, Jing and Shen, Hao},
  doi          = {10.1007/s11063-020-10337-1},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {2069-2088},
  shortjournal = {Neural Process. Lett.},
  title        = {Asynchronous $$l_{2}$$ – $$l_{\infty }$$ filtering for discrete-time fuzzy markov jump neural networks with unreliable communication links},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Ensemble pruning of ELM via migratory binary glowworm swarm
optimization and margin distance minimization. <em>NPL</em>,
<em>52</em>(3), 2043–2067. (<a
href="https://doi.org/10.1007/s11063-020-10336-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensemble pruning aims at attaining an ensemble composed of less size of leaners for improving classification ability. Extreme Learning Machine (ELM) is employed as a base learner in this work, in light of its salient features, an initial pool is constructed using ELM. An ensemble composed of ELMs with better performance and diversity can make it perform the best, but the average accuracy of the whole ELMs must be decreased as the increase of diversity among them. Hence there exists a balance between the diversity and the precision of ELMs. Existing works find it via diversity measures or heuristic algorithms, which cannot find the exact tradeoff. To solve the issue, ensemble pruning of ELM via migratory binary glowworm swarm optimization and margin distance minimization (EPEMBM) is proposed utilizing the integration of the proposed migratory binary glowworm swarm optimization (MBGSO) and margin distance minimization (MDM). First, the created ELMs in a pool can be pre-pruned by MDM, and it can markedly downsize the ELMs in the pool, and significantly alleviates its computation overhead. Second, the retaining ELMs are further pruned utilizing MBGSO, and the final ensemble is attained with a high efficiency. Experimental results on 21 UCI classification tasks indicate that EPEMBM outperforms techniques, and that its effectiveness and efficiency. It is a very useful tool for solving the selection problem of ELMs.},
  archive      = {J_NPL},
  author       = {Zhu, Xuhui and Ni, Zhiwei and Ni, Liping and Jin, Feifei and Cheng, Meiying and Wu, Zhangjun},
  doi          = {10.1007/s11063-020-10336-2},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {2043-2067},
  shortjournal = {Neural Process. Lett.},
  title        = {Ensemble pruning of ELM via migratory binary glowworm swarm optimization and margin distance minimization},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stochastic one-step training for feedforward artificial
neural networks. <em>NPL</em>, <em>52</em>(3), 2021–2041. (<a
href="https://doi.org/10.1007/s11063-020-10335-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the use and application of a fast method (non-iterative and instantaneous) for Feedforward Neural Networks training in which the weights of the hidden layer are assigned randomly, and the weights of the output layer are trained through a linear regression adjustment. The method solves two of the problems that are present in traditional training: training time and optimal structure. While traditional iterative training methods require long periods to train a single structure, the proposed method allows training a structure in a single step (not iterative). In this way, by scanning the number of neurons in the hidden layer, many structures are trained in a short time, and it is possible to obtain an optimal topology. A quality control criterion of the predictions is proposed based on the coefficient of determination that guarantees short times and an optimal number of hidden neurons to characterize a specific problem. The feasibility of the proposed method is tested by comparing its performance against building functions of the artificial neural networks toolbox in Matlab®, resulting superior in both approximation quality and training time. A rigorous study and analysis are performed for the regression of simulated data on two different surfaces with a specific noise and different topologies of the neural network. The resulting process time is at least 150 times shorter for proposed training than with the iterative training that Matlab uses, thus obtaining well-founded learning rules. A novel way of an amputated matrix is proposed that breaks the paradigm of the way multiple-output systems are trained and improves the quality of predictions with no detriment to training times.},
  archive      = {J_NPL},
  author       = {Cano-Rocha, Hector and Gonzalez-Garcia, Raul},
  doi          = {10.1007/s11063-020-10335-3},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {2021-2041},
  shortjournal = {Neural Process. Lett.},
  title        = {Stochastic one-step training for feedforward artificial neural networks},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An application of generalized fuzzy hyperbolic model for
solving fractional optimal control problems with caputo–fabrizio
derivative. <em>NPL</em>, <em>52</em>(3), 1997–2020. (<a
href="https://doi.org/10.1007/s11063-020-10334-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we present a new approach for solving a class of fractional optimal control problems based on generalized fuzzy hyperbolic model. The fractional derivatives are described in the Caputo–Fabrizio sense. In order to solve this problem, the necessary optimality conditions associated to the fractional optimal control problem is first derived. The solution of these conditions is then approximated by fuzzy solution based on generalized fuzzy hyperbolic model. A learning algorithm is used to achieve the adjustable parameters of the obtained fuzzy solution. In order to confirm the efficiency and accuracy of the proposed approach, some illustrative examples are implemented.},
  archive      = {J_NPL},
  author       = {Mortezaee, Marzieh and Ghovatmand, Mehdi and Nazemi, Alireza},
  doi          = {10.1007/s11063-020-10334-4},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {1997-2020},
  shortjournal = {Neural Process. Lett.},
  title        = {An application of generalized fuzzy hyperbolic model for solving fractional optimal control problems with Caputo–Fabrizio derivative},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep plot-aware generalized matrix factorization for
collaborative filtering. <em>NPL</em>, <em>52</em>(3), 1983–1995. (<a
href="https://doi.org/10.1007/s11063-020-10333-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fusing auxiliary information into ratings has shown promising performance for many recommendation tasks, such as age, sex, vocation of users or actors, director, genre, reviews of movies. However, all above auxiliary information is still sparse and not informative. For movie recommendations, besides the above information, there exists richer information in plot texts, exerting huge impacts on improving the recommendation accuracy. In this paper, we explore effective fusion of movie ratings and plot texts, we propose a deep plot-aware generalized matrix factorization for collaborative filtering model, which effectively combines both ratings and plot texts to implement a generalized collaborative filtering. To verify our proposal, we conduct extensive experiments on two popular datasets, and the results perform better than other state-of-the-art approaches in common recommendation tasks.},
  archive      = {J_NPL},
  author       = {Sun, Xiaoxin and Zhang, Haobo and Wang, Meiqi and Yu, Mengying and Yin, Minghao and Zhang, Bangzuo},
  doi          = {10.1007/s11063-020-10333-5},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {1983-1995},
  shortjournal = {Neural Process. Lett.},
  title        = {Deep plot-aware generalized matrix factorization for collaborative filtering},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bipartite synchronization analysis of fractional order
coupled neural networks with hybrid control. <em>NPL</em>,
<em>52</em>(3), 1969–1981. (<a
href="https://doi.org/10.1007/s11063-020-10332-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The bipartite synchronization problem for fractional order antagonistic coupled neural networks (FACNNs) is investigated in this paper. Using the properties of gamma function and special matrix, some criteria for bipartite Mittag–Leffler (M–L) synchronization and bipartite finite time synchronization of FACNNs have been obtained. To achieve bipartite finite time pinning synchronization, hybrid control strategy is designed. That is, finite time control combined with pinning control, pinning partial nodes, which can access the information of the leader. The upper bound of synchronization setting time is obtained.},
  archive      = {J_NPL},
  author       = {Zhang, Lingzhong and Yang, Yongqing},
  doi          = {10.1007/s11063-020-10332-6},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {1969-1981},
  shortjournal = {Neural Process. Lett.},
  title        = {Bipartite synchronization analysis of fractional order coupled neural networks with hybrid control},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Content-aware summarization of broadcast sports videos: An
audio–visual feature extraction approach. <em>NPL</em>, <em>52</em>(3),
1945–1968. (<a
href="https://doi.org/10.1007/s11063-020-10200-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A large number of videos available on the internet belong to the category of sports. Generally, a sports video has a long duration and consists of only a few exciting moments. Sports enthusiasts keep themselves updated on the current happenings, in less time, by means of a summarized version of the sports video known as highlights. For the past few years, sports video summarization is regaining attention among the research community. Automatic generation of highlights form a sports video is a challenging task as different sports games have different rules and situations. In this paper, we propose a method for automatically generating highlights from broadcast sports videos. The proposed method generates highlights by extracting audio and visual features from a sports video. Our method automatically learns the scorebox template from a broadcast sports video using SIFT features, and then locates and extracts the template from a video stream. The extracted template is further analyzed to find out all the possible text regions. Afterward, the information is extracted from all the text regions by means of deep neural network. Based on user preferences, the most relevant information is extracted and converted to a keyframe representation which helps to generate highlights. Extensive experiments were performed to evaluate the effectiveness of the proposed method. Results of the experiments reveal the effectiveness and superiority of the proposed method.},
  archive      = {J_NPL},
  author       = {Khan, Abdullah Aman and Shao, Jie and Ali, Waqar and Tumrani, Saifullah},
  doi          = {10.1007/s11063-020-10200-3},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {1945-1968},
  shortjournal = {Neural Process. Lett.},
  title        = {Content-aware summarization of broadcast sports videos: An Audio–Visual feature extraction approach},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Parameter-free extreme learning machine for imbalanced
classification. <em>NPL</em>, <em>52</em>(3), 1927–1944. (<a
href="https://doi.org/10.1007/s11063-020-10282-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imbalanced data distribution is a common problem in classification situations, that is the number of samples in different categories varies greatly, thus increasing the classification difficulty. Although many methods have been used for the imbalanced data classification, there are still problems with low classification accuracy in minority class and adding additional parameter settings. In order to increase minority classification accuracy in imbalanced problem, this paper proposes a parameter-free weighting learning mechanism based on extreme learning machine and sample loss values to balance the number of samples in each training step. The proposed method mainly includes two aspects: the sample weight learning process based on the sample losses; the sample selection process and weight update process according to the constraint function and iterations. Experimental results on twelve datasets from the KEEL repository show that the proposed method could achieve more balanced and accurate results than other compared methods in this work.},
  archive      = {J_NPL},
  author       = {Li, Li and Zhao, Kaiyi and Sun, Ruizhi and Gan, Jiangzhang and Yuan, Gang and Liu, Tong},
  doi          = {10.1007/s11063-020-10282-z},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {1927-1944},
  shortjournal = {Neural Process. Lett.},
  title        = {Parameter-free extreme learning machine for imbalanced classification},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An efficient algorithm combining spectral clustering with
feature selection. <em>NPL</em>, <em>52</em>(3), 1913–1925. (<a
href="https://doi.org/10.1007/s11063-020-10297-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional clustering algorithms have some limitations, which are sensitive to noise and mostly applicable to convex data sets. To solve these problems, the paper proposes a novel algorithm combining spectral clustering with feature selection. Specifically, the loss item is marked with a root that can reduce the deviation value then improve the robustness of the model. And in the algorithm optimization, there is one parameter is represented by other known parameters, which can reduce the time of parameter adjustment. Then, the regular term $${{\ell }_{2,p}}\text {-norm}$$ is applied to reduce the influence of noise and redundant features and prevent the model from overfitting. Finally, Laplace matrix is constructed by kNN algorithm which is used to learn subspace and to preserve the local structure among samples, and the data after dimension reduction is used to spectral clustering. Experimental analysis on 10 benchmark datasets show that the proposed algorithm is more outperformed than the algorithms of the state-of-the-art.},
  archive      = {J_NPL},
  author       = {Luo, Qimin and Wen, Guoqiu and Zhang, Leyuan and Zhan, Mengmeng},
  doi          = {10.1007/s11063-020-10297-6},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {1913-1925},
  shortjournal = {Neural Process. Lett.},
  title        = {An efficient algorithm combining spectral clustering with feature selection},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A style-specific music composition neural network.
<em>NPL</em>, <em>52</em>(3), 1893–1912. (<a
href="https://doi.org/10.1007/s11063-020-10241-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic music composition could dramatically decrease music production costs, lower the threshold for the non-professionals to compose as well as improve the efficiency of music creation. In this paper, we proposed an intelligent music composition neutral network to automatically generate a specific style of music. The advantage of our model is the innovative structure: we obtained the music sequence through an actor’s long short term memory, then fixed the probability of sequence by a reward-based procedure which serves as feedback to improve the performance of music composition. The music theoretical rule is introduced to constrain the style of generated music. We also utilized a subjective validation in experiment to guarantee the superiority of our model compared with state-of-the-art works.},
  archive      = {J_NPL},
  author       = {Jin, Cong and Tie, Yun and Bai, Yong and Lv, Xin and Liu, Shouxun},
  doi          = {10.1007/s11063-020-10241-8},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {1893-1912},
  shortjournal = {Neural Process. Lett.},
  title        = {A style-specific music composition neural network},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Convolutional sparse coded dynamic brain functional
connectivity. <em>NPL</em>, <em>52</em>(3), 1881–1892. (<a
href="https://doi.org/10.1007/s11063-020-10295-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Functional brain network has been widely studied in many previous work for brain disorder diagnosis and brain network analysis. However, most previous work focus on static dynamic brain network research. Lots of recent work reveals that the brain shows dynamic activity even in resting state. Such dynamic brain functional connectivity reveals discriminative patterns for identifying many brain disorders. Current sliding window based dynamic brain connectivity framework are not easy to be applied to real clinical applications due to many issues: First, how to set up the optimal sliding window size and how to determine the threshold for the brain connectivity patterns. Secondly, how to represent the high dimensional dynamic brain connectivity pattern in a low dimensional representations for diagnosis purpose. Last, how to deal with the different length dynamic brain network patterns especially when the raw data are of different length. In order to address all those above issues, we proposed a new framework, which employs multiple scale sliding windows and automatically learns a sparse and low ran dynamic brain functional connectivity patterns from raw fMRI data. Furthermore, we are able to measure different length dynamic brain functional connectivity patterns in an equal space by learning a sparse coded convolutional filters. We have evaluated our method with state of the art dynamic brain network methods and the results demonstrated the strong potential of our methods for brain disorder diagnosis in real clinical applications.},
  archive      = {J_NPL},
  author       = {Yan, Jin and Zhu, Yingying},
  doi          = {10.1007/s11063-020-10295-8},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {1881-1892},
  shortjournal = {Neural Process. Lett.},
  title        = {Convolutional sparse coded dynamic brain functional connectivity},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Intra- and inter-modal multilinear pooling with multitask
learning for video grounding. <em>NPL</em>, <em>52</em>(3), 1863–1879.
(<a href="https://doi.org/10.1007/s11063-020-10205-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video grounding aims to temporally localize an action in an untrimmed video referred to by a query in natural language, which plays an important role in fine-grained video understanding. Given temporal proposals of limited granularity, the task is challenging that it requires fusing multi-modal features from questions and videos effectively, and localizing the referred action accurately. For multimodal feature fusion, we present an Intra- and Inter-modal Multilinear pooling (IIM) model to effectively combine the multi-modal features with considering both the intra- and inter-modal feature interactions. Compared to existing multimodal fusion models, IIM can capture high-order interactions and is more capable for modeling temporal information of videos. For action localization, we propose a simple yet effective multi-task learning framework to simultaneously predict the action label, alignment score and refined location in an end-to-end manner. Experimental results on real-world TaCoS and Charades-STA datasets demonstrate the superiority of the proposed approach over existing state-of-the-art methods.},
  archive      = {J_NPL},
  author       = {Yu, Zhou and Song, Yijun and Yu, Jun and Wang, Meng and Huang, Qingming},
  doi          = {10.1007/s11063-020-10205-y},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {1863-1879},
  shortjournal = {Neural Process. Lett.},
  title        = {Intra- and inter-modal multilinear pooling with multitask learning for video grounding},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Joint robust multi-view spectral clustering. <em>NPL</em>,
<em>52</em>(3), 1843–1862. (<a
href="https://doi.org/10.1007/s11063-020-10257-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current multi-view clustering algorithms use multistage strategies to conduct clustering, or require cluster number or similarity matrix prior, or suffer influence of irrelevant features and outliers. In this paper, we propose a Joint Robust Multi-view (JRM) spectral clustering algorithm that considers information from all views of the multi-view dataset to conduct clustering and solves the issues, such as initialization, cluster number determination, similarity measure, feature selection, and outlier reduction around clustering, in a unified way. The optimal performance could be reached when all views are considered and the separated stages are combined in a unified way. Experiments have been performed on six real-world benchmark datasets and our proposed JRM algorithm outperforms the comparison clustering algorithms in terms of two evaluation metrics for clustering algorithms including accuracy and purity.},
  archive      = {J_NPL},
  author       = {Liu, Tong and Martin, Gaven and Zhu, YongXin and Peng, Lin and Li, Li},
  doi          = {10.1007/s11063-020-10257-0},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {1843-1862},
  shortjournal = {Neural Process. Lett.},
  title        = {Joint robust multi-view spectral clustering},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Using locality preserving projections to improve the
performance of kernel clustering. <em>NPL</em>, <em>52</em>(3),
1827–1842. (<a
href="https://doi.org/10.1007/s11063-020-10252-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many clustering methods may have poor performance when the data structure is complex (i.e., the data has an aspheric shape or non-linear relationship). Inspired by this view, we proposed a clustering model which combines kernel function and Locality Preserving Projections (LPP) together. Specifically, we map original data into the high-dimensional feature space according to the idea of kernel function. Secondly, it is feasible to explore the local structure of data in clustering tasks. LPP is used to preserve the original local structure information of data to improve the validity of the clustering model. Finally, some outliers are often included in real data, so we embedded sparse regularization items in the model to adjust feature weights and remove outliers. In addition, we design a simple iterative optimization method to solve the final objective function and show the convergence of the optimization method in the experimental part. The experimental analysis of ten public data sets showed that our proposed method has better efficiency and performance in clustering tasks than existing clustering methods.},
  archive      = {J_NPL},
  author       = {Zhan, Mengmeng and Lu, Guangquan and Wen, Guoqiu and Zhang, Leyuan and Wu, Lin},
  doi          = {10.1007/s11063-020-10252-5},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {1827-1842},
  shortjournal = {Neural Process. Lett.},
  title        = {Using locality preserving projections to improve the performance of kernel clustering},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Local structure preservation for nonlinear clustering.
<em>NPL</em>, <em>52</em>(3), 1811–1826. (<a
href="https://doi.org/10.1007/s11063-020-10251-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a new nonlinear clustering method to preserve local structure of the features. Specifically, our method applies the gaussian kernel function to achieve high dimensional projection so as to make the original data linearly separable. Our method establishes the similarity matrix of data features in low-dimensional space to conduct local structure learning, as a result, it can avoid the divergence of sample sets and retain the original nearest neighbor structural relations. Furthermore, our method uses the sparse learning to remove the redundant features to make the model more robust in the process of learning. Experimental results on eight benchmark datasets show that our proposed method was superior to the state-of-the-art clustering methods in terms of clustering performance.},
  archive      = {J_NPL},
  author       = {Chen, Linjun and Lu, Guangquan and Li, Yangding and Li, Jiaye and Tan, Malong},
  doi          = {10.1007/s11063-020-10251-6},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {1811-1826},
  shortjournal = {Neural Process. Lett.},
  title        = {Local structure preservation for nonlinear clustering},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sparse low-rank and graph structure learning for supervised
feature selection. <em>NPL</em>, <em>52</em>(3), 1793–1809. (<a
href="https://doi.org/10.1007/s11063-020-10250-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spectral feature selection (SFS) is superior to conventional feature selection methods in many aspects, by extra importing a graph matrix to preserve the subspace structure of data. However, the graph matrix of classical SFS that is generally constructed by original data easily outputs a suboptimal performance of feature selection because of the redundancy. To address this, this paper proposes a novel feature selection method via coupling the graph matrix learning and feature data learning into a unified framework, where both steps can be iteratively update until achieving the stable solution. We also apply a low-rank constraint to obtain the intrinsic structure of data to improve the robustness of learning model. Besides, an optimization algorithm is proposed to solve the proposed problem and to have fast convergence. Compared to classical and state-of-the-art feature selection methods, the proposed method achieved the competitive results on twelve real data sets.},
  archive      = {J_NPL},
  author       = {Wen, Guoqiu and Zhu, Yonghua and Zhan, Mengmeng and Tan, Malong},
  doi          = {10.1007/s11063-020-10250-7},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {1793-1809},
  shortjournal = {Neural Process. Lett.},
  title        = {Sparse low-rank and graph structure learning for supervised feature selection},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Flexible discrete multi-view hashing with collective latent
feature learning. <em>NPL</em>, <em>52</em>(3), 1765–1791. (<a
href="https://doi.org/10.1007/s11063-020-10221-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view hashing has gained considerable research attention in efficient multimedia studies due to its promising performance on heterogeneous data from various sources. However, its application in discriminative hash codes learning remains challenging as it fails to efficiently capture preferable components from multiple representations. In this work, we propose a novel discriminative multi-view hashing framework, dubbed flexible discrete multi-view hashing, in conjunction with collective latent feature learning by combining multiple views of data and consistent hash codes learning by fusing visual features and flexible semantics. Specifically, an adaptive multi-view analysis dictionary learning model is developed to skillfully combine diverse representations into an established common latent feature space where the complementary properties of different views are well explored based on an automatic multi-view weighting strategy. Moreover, we introduce a collaborative learning scheme to jointly encode the visual and semantic embeddings into an aligned consistent Hamming space, which can effectively mitigate the visual-semantic gap. Particularly, we employ the correntropy induced regularization to improve the robustness of the formulated flexible semantics. An efficient learning algorithm is proposed to solve the optimization problem. Extensive experiments show the state-of-art performance of the proposed method on several benchmark datasets.},
  archive      = {J_NPL},
  author       = {Liu, Luyao and Zhang, Zheng and Huang, Zi},
  doi          = {10.1007/s11063-020-10221-y},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {1765-1791},
  shortjournal = {Neural Process. Lett.},
  title        = {Flexible discrete multi-view hashing with collective latent feature learning},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Joint feature selection with dynamic spectral clustering.
<em>NPL</em>, <em>52</em>(3), 1745–1763. (<a
href="https://doi.org/10.1007/s11063-020-10216-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current clustering algorithms solved a few of the issues around clustering such as similarity measure learning, or the cluster number estimation. For instance, some clustering algorithms can learn the data similarity matrix, but to do so they need to know the cluster number beforehand. On the other hand, some clustering algorithms estimate the cluster number, but to do so they need the similarity matrix as an input. Real-world data often contains redundant features and outliers, which many algorithms are susceptive to. None of the current clustering algorithms are able to learn the data similarity measure and the cluster number simultaneously, and at the same time reduce the influence of outliers and redundant features. Here we propose a joint feature selection with dynamic spectral clustering (FSDS) algorithm that not only learns the cluster number k and data similarity measure simultaneously, but also employs the $$ {\text{L}}_{2,1} $$ -norm to reduce the influence of outliers and redundant features. The optimal performance could be reached when all the separated stages are combined in a unified way. Experimental results on eight real-world benchmark datasets show that our FSDS clustering algorithm outperformed the comparison clustering algorithms in terms of two evaluation metrics for clustering algorithms including ACC and Purity.},
  archive      = {J_NPL},
  author       = {Liu, Tong and Martin, Gaven},
  doi          = {10.1007/s11063-020-10216-9},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {1745-1763},
  shortjournal = {Neural Process. Lett.},
  title        = {Joint feature selection with dynamic spectral clustering},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Extreme learning machine for supervised classification with
self-paced learning. <em>NPL</em>, <em>52</em>(3), 1723–1744. (<a
href="https://doi.org/10.1007/s11063-020-10286-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The extreme learning machine (ELM), a typical machine learning algorithm based on feedforward neural network, has been widely used in classification, clustering, regression and feature learning. However, the traditional ELM learns all samples at once, and sample weights of traditional methods are defined before the learning process and they will not change during the learning process. So, its performance is vulnerable to noisy data and outliers, finding a way to solve this problem is meaningful. In this work, we propose a model of self-paced ELM named SP-ELM for binary classification and multi-classification originated from the self-paced learning paradigm. Concretely, the algorithm takes the importance of samples into account according to the loss of predicted value and real value, and it establishes the model from the simple samples to complex samples. By setting certain restrictions, the influence of complex data on the model is reduced. Four different self-paced regularization terms are adopted in the paper to select the instances. Experimental results demonstrate the effectiveness and of the proposed method by comparing it with other improved ELMs.},
  archive      = {J_NPL},
  author       = {Li, Li and Zhao, Kaiyi and Li, Sicong and Sun, Ruizhi and Cai, Saihua},
  doi          = {10.1007/s11063-020-10286-9},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {1723-1744},
  shortjournal = {Neural Process. Lett.},
  title        = {Extreme learning machine for supervised classification with self-paced learning},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Feature-based learning in drug prescription system for
medical clinics. <em>NPL</em>, <em>52</em>(3), 1703–1721. (<a
href="https://doi.org/10.1007/s11063-020-10296-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rapid increases in data volume and variety pose a challenge to safe drug prescription for health professionals like doctors and dentists. This is addressed by our study, which presents innovative approaches in mining data from drug corpus and extracting feature vectors to combine this knowledge with individual patient medical profiles. Within our three-tiered framework—the prediction layer, the knowledge layer and the presentation layer—we describe multiple approaches in computing similarity ratios from the feature vectors, illustrated with an example of applying the framework in a typical medical clinic. Experimental evaluation shows that the word embedding model performs better than the adverse network model, with a F score of 0.75. The F score is a common metrics used for evaluating the performance of classification algorithms. Similarity to a drug the patient is allergic to or is taking are important considerations for the suitability of a drug for prescription. Hence, such an approach, when integrated within the clinical work-flow, will reduce prescription errors thereby increasing patient health outcomes.},
  archive      = {J_NPL},
  author       = {Goh, Wee Pheng and Tao, Xiaohui and Zhang, Ji and Yong, Jianming},
  doi          = {10.1007/s11063-020-10296-7},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {3},
  pages        = {1703-1721},
  shortjournal = {Neural Process. Lett.},
  title        = {Feature-based learning in drug prescription system for medical clinics},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Spiking neural networks: Background, recent development and
the NeuCube architecture. <em>NPL</em>, <em>52</em>(2), 1675–1701. (<a
href="https://doi.org/10.1007/s11063-020-10322-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper reviews recent developments in the still-off-the-mainstream information and data processing area of spiking neural networks (SNN)—the third generation of artificial neural networks. We provide background information about the functioning of biological neurons, discussing the most important and commonly used mathematical neural models. Most relevant information processing techniques, learning algorithms, and applications of spiking neurons are described and discussed, focusing on feasibility and biological plausibility of the methods. Specifically, we describe in detail the functioning and organization of the latest version of a 3D spatio-temporal SNN-based data machine framework called NeuCube, as well as it’s SNN-related submodules. All described submodules are accompanied with formal algorithmic formulations. The architecture is highly relevant for the analysis and interpretation of various types of spatio-temporal brain data (STBD), like EEG, NIRS, fMRI, but we highlight some of the recent both STBD- and non-STBD-based applications. Finally, we summarise and discuss some open research problems that can be addressed in the future. These include, but are not limited to: application in the area of EEG-based BCI through transfer learning; application in the area of affective computing through the extension of the NeuCube framework which would allow for a biologically plausible SNN-based integration of central and peripheral nervous system measures. Matlab implementation of the NeuCube’s SNN-related module is available for research and teaching purposes.},
  archive      = {J_NPL},
  author       = {Tan, Clarence and Šarlija, Marko and Kasabov, Nikola},
  doi          = {10.1007/s11063-020-10322-8},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {2},
  pages        = {1675-1701},
  shortjournal = {Neural Process. Lett.},
  title        = {Spiking neural networks: Background, recent development and the NeuCube architecture},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Label embedding for multi-label classification via
dependence maximization. <em>NPL</em>, <em>52</em>(2), 1651–1674. (<a
href="https://doi.org/10.1007/s11063-020-10331-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label classification has aroused extensive attention in various fields. With the emergence of high-dimensional label space, academia has devoted to performing label embedding in recent years. Whereas current embedding approaches do not take feature space correlation sufficiently into consideration or require an encoding function while learning embedded space. Besides, few of them can be spread to track the missing labels. In this paper, we propose a Label Embedding method via Dependence Maximization (LEDM), which obtains the latent space on which the label and feature information can be embedded simultaneously. To end this, the low-rank factorization model on the label matrix is applied to exploit label correlations instead of the encoding process. The dependence between feature space and label space is increased by the Hilbert–Schmidt independence criterion to facilitate the predictability. The proposed LEDM can be easily extended the missing labels in learning embedded space at the same time. Comprehensive experimental results on data sets validate the effectiveness of our approach over the state-of-art methods on both complete-label and missing-label cases.},
  archive      = {J_NPL},
  author       = {Li, Yachong and Yang, Youlong},
  doi          = {10.1007/s11063-020-10331-7},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {2},
  pages        = {1651-1674},
  shortjournal = {Neural Process. Lett.},
  title        = {Label embedding for multi-label classification via dependence maximization},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Pathological lung segmentation based on random forest
combined with deep model and multi-scale superpixels. <em>NPL</em>,
<em>52</em>(2), 1631–1649. (<a
href="https://doi.org/10.1007/s11063-020-10330-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate segmentation of lungs in pathological thoracic computed tomography (CT) scans plays an important role in pulmonary disease diagnosis. However, it is still a challenging task due to the variability of pathological lung appearances and shapes. In this paper, we proposed a novel segmentation algorithm based on random forest (RF), deep convolutional network, and multi-scale superpixels for segmenting pathological lungs from thoracic CT images accurately. A pathological thoracic CT image is first segmented based on multi-scale superpixels, and deep features, texture, and intensity features extracted from superpixels are taken as inputs of a group of RF classifiers. With the fusion of classification results of RFs by a fractional-order gray correlation approach, we capture an initial segmentation of pathological lungs. We finally utilize a divide-and-conquer strategy to deal with segmentation refinement combining contour correction of left lungs and region repairing of right lungs. Our algorithm is tested on a group of thoracic CT images affected with interstitial lung diseases. Experiments show that our algorithm can achieve a high segmentation accuracy with an average DSC of 96.45% and PPV of 95.07%. Compared with several existing lung segmentation methods, our algorithm exhibits a robust performance on pathological lung segmentation. Our algorithm can be employed reliably for lung field segmentation of pathologic thoracic CT images with a high accuracy, which is helpful to assist radiologists to detect the presence of pulmonary diseases and quantify its shape and size in regular clinical practices.},
  archive      = {J_NPL},
  author       = {Liu, Caixia and Zhao, Ruibin and Xie, Wangli and Pang, Mingyong},
  doi          = {10.1007/s11063-020-10330-8},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {2},
  pages        = {1631-1649},
  shortjournal = {Neural Process. Lett.},
  title        = {Pathological lung segmentation based on random forest combined with deep model and multi-scale superpixels},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). A dynamic programming framework for large-scale online
clustering on graphs. <em>NPL</em>, <em>52</em>(2), 1613–1629. (<a
href="https://doi.org/10.1007/s11063-020-10329-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a fundamental technique for data analysis, graph clustering grouping graph data into clusters has attracted great attentions in recent years. In this paper, we present DPOCG, a dynamic programming framework for large-scale online clustering on graphs, which improves the scalability of a wide range of graph clustering algorithms. Specifically, DPOCG first identifies the nodes whose states are unchanged compared with the states at the previous time on a large-scale graph, then constructs these unchanged nodes as supernodes, which greatly reduces the size of the graph at the current time, and collapses nodes whose degrees are less than a predefined threshold. Based on our density-based graph clustering algorithm (DGCM), DPOCG partitions the reduced graph into clusters. In addition, we theoretically analyze DPOCG in terms of supernode generation, clustering on reduced graph, and computational complexity. We evaluate DPOCG on a synthetic dataset and seven real-world datasets, respectively, and the experimental results show that DPOCG consumes less running time and improves the efficiency of clustering.},
  archive      = {J_NPL},
  author       = {Li, Yantao and Zhao, Xiang and Qu, Zehui},
  doi          = {10.1007/s11063-020-10329-1},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {2},
  pages        = {1613-1629},
  shortjournal = {Neural Process. Lett.},
  title        = {A dynamic programming framework for large-scale online clustering on graphs},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Unsupervised optical flow estimation based on improved
feature pyramid. <em>NPL</em>, <em>52</em>(2), 1601–1612. (<a
href="https://doi.org/10.1007/s11063-020-10328-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning methods for optical flow estimation usually increase the receptive field of convolution through reducing image resolution, which results in loss of spatial detail information during feature extraction. In this paper, we introduce dilated convolution into feature pyramid network, which can extract multi-scale features containing more motion details and can further improve the accuracy of optical flow estimation. The unsupervised loss function is based on forward–backward consistency check and robust census transform that has a good constraint performance in the case of illumination changes, which can train an unsupervised learning optical flow model with higher accuracy. Our network is trained on FlyingChairs and KITTI raw datasets with an unsupervised manner and tested on MPI-Sintel, KITTI 2012 and KITTI 2015 benchmarks. The experimental results show the advantages of our method in unsupervised learning approaches.},
  archive      = {J_NPL},
  author       = {Yang, Bo and Xie, Huan and Li, Hongbin and Li, Nuohan and Liu, Anchang and Ren, Zhigang and Ye, Kuan and Zhu, Rong and Xiang, Xuezhi},
  doi          = {10.1007/s11063-020-10328-2},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {2},
  pages        = {1601-1612},
  shortjournal = {Neural Process. Lett.},
  title        = {Unsupervised optical flow estimation based on improved feature pyramid},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Logic negation with spiking neural p systems. <em>NPL</em>,
<em>52</em>(2), 1583–1599. (<a
href="https://doi.org/10.1007/s11063-020-10324-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, the success of neural networks as reasoning systems is doubtless. Nonetheless, one of the drawbacks of such reasoning systems is that they work as black-boxes and the acquired knowledge is not human readable. In this paper, we present a new step in order to close the gap between connectionist and logic based reasoning systems. We show that two of the most used inference rules for obtaining negative information in rule based reasoning systems, the so-called Closed World Assumption and Negation as Finite Failure can be characterized by means of spiking neural P systems, a formal model of the third generation of neural networks born in the framework of membrane computing.},
  archive      = {J_NPL},
  author       = {Rodríguez-Chavarría, Daniel and Gutiérrez-Naranjo, Miguel A. and Borrego-Díaz, Joaquín},
  doi          = {10.1007/s11063-020-10324-6},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {2},
  pages        = {1583-1599},
  shortjournal = {Neural Process. Lett.},
  title        = {Logic negation with spiking neural p systems},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Semi-supervised weighted ternary decision structure for
multi-category classification. <em>NPL</em>, <em>52</em>(2), 1555–1582.
(<a href="https://doi.org/10.1007/s11063-020-10323-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised learning has attracted researchers due to its advantages over supervised learning. In this paper, an extremely fast multi-category classification algorithm, termed as weighted ternary decision structure (WTDS) is proposed. WTDS is a generic algorithm that can extend any binary classifier into multi-category framework. This work also proposes a novel semi-supervised binary classifier termed as Weighted Laplacian least-squares twin support vector machine which is further extended using WTDS. The novel semi-supervised classifier obtains the solution by formulating a pair of Unconstrained Minimization Problems which are solved as systems of linear equation. WTDS takes advantage of the strengths of the classifier and efficiently constructs the multi-category classifier model in the form of a decision structure. WTDS outperforms other state-of-the-art multi-category approaches in terms of classification accuracy and time complexity. To confirm the feasibility and efficacy of proposed algorithm, experiments are conducted on benchmark UCI datasets.},
  archive      = {J_NPL},
  author       = {Saigal, Pooja and Rastogi, Reshma and Chandra, Suresh},
  doi          = {10.1007/s11063-020-10323-7},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {2},
  pages        = {1555-1582},
  shortjournal = {Neural Process. Lett.},
  title        = {Semi-supervised weighted ternary decision structure for multi-category classification},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel solution of using deep learning for white blood
cells classification: Enhanced loss function with regularization and
weighted loss (ELFRWL). <em>NPL</em>, <em>52</em>(2), 1517–1553. (<a
href="https://doi.org/10.1007/s11063-020-10321-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has been successfully applied in classification of white blood cells (WBCs), however, accuracy and processing time are found to be less than optimal hindering it from getting its full potential. This is due to imbalanced dataset, intra-class compactness, inter-class separability and overfitting problems. The main research idea is to enhance the classification and prediction accuracy of blood images while lowering processing time through the use of deep convolutional neural network (DCNN) architecture by using the modified loss function. The proposed system consists of a deep neural convolution network (DCNN) that will improve the classification accuracy by using modified loss function along with regularization. Firstly, images are pre-processed and fed through DCNN that contains different layers with different activation function for the feature extraction and classification. Along with modified loss function with regularization, weight function aids in the classification of WBCs by considering weights of samples belonging to each class for compensating the error arising due to imbalanced dataset. The processing time will be counted by each image to check the time enhancement. The classification accuracy and processing time are achieved using the dataset-master. Our proposed solution obtains better classification performance in the given dataset comparing with other previous methods. The proposed system enhanced the classification accuracy of 98.92% from 96.1% and a decrease in processing time from 0.354 to 0.216 s. Less time will be required by our proposed solution for achieving the model convergence with 9 epochs against the current convergence time of 13.5 epochs on average, epoch is the formation white blood cells (WBCs) and the development of granular cells. The proposed solution modified loss function to solve the adverse effect caused due to imbalance dataset by considering weight and use regularization technique for overfitting problem.},
  archive      = {J_NPL},
  author       = {Basnet, Jaya and Alsadoon, Abeer and Prasad, P. W. C. and Aloussi, Sarmad Al and Alsadoon, Omar Hisham},
  doi          = {10.1007/s11063-020-10321-9},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {2},
  pages        = {1517-1553},
  shortjournal = {Neural Process. Lett.},
  title        = {A novel solution of using deep learning for white blood cells classification: Enhanced loss function with regularization and weighted loss (ELFRWL)},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A review of dynamic maps for 3D human motion recognition
using ConvNets and its improvement. <em>NPL</em>, <em>52</em>(2),
1501–1515. (<a
href="https://doi.org/10.1007/s11063-020-10320-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGB-D based action recognition is attracting more and more attention in both the research and industrial communities. However, due to the lack of training data, pre-training based methods are popular in this field. This paper presents a review of the concept of dynamic maps for RGB-D based human motion recognition using pretrained models in image domain. The dynamic maps recursively encode the spatial, temporal and structural information contained in the video sequence into dynamic motion images simultaneously. They enable the usage of Convolutional Neural Network and its pretained models on ImageNet for 3D human motion recognition. This simple, compact and effective representation achieves state-of-the-art results on various gesture/action/activities recognition datasets. Based on the review of previous methods using this concept upon different modalities (depth, skeleton or RGB-D data), a novel encoding scheme is developed and presented in this paper. The improved method generates effective flow-guided dynamic maps, and they could select the high motion window and distinguish the order among the frames with small motion. The improved flow-guided dynamic maps achieve state-of-the-art results on the large Chalearn LAP IsoGD and NTU RGB+D datasets.},
  archive      = {J_NPL},
  author       = {Gao, Zhimin and Wang, Pichao and Wang, Huogen and Xu, Mingliang and Li, Wanqing},
  doi          = {10.1007/s11063-020-10320-w},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {2},
  pages        = {1501-1515},
  shortjournal = {Neural Process. Lett.},
  title        = {A review of dynamic maps for 3D human motion recognition using ConvNets and its improvement},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Time series prediction method based on variant LSTM
recurrent neural network. <em>NPL</em>, <em>52</em>(2), 1485–1500. (<a
href="https://doi.org/10.1007/s11063-020-10319-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series prediction problems are a difficult type of predictive modeling problem. In this paper, we propose a time series prediction method based on a variant long short-term memory (LSTM) recurrent neural network. In the proposed method, we firstly improve the memory module of the LSTM recurrent neural network by merging its forget gate and input gate into one update gate, and using Sigmoid layer to control information update. Using improved LSTM recurrent neural network, we develop a time series prediction model. In the proposed model, the parameter migration method is used model update to ensure the model has good predictive ability after predicting multi-step sequences. Experimental results show, compared with several typical time series prediction models, the proposed method have better performance for long-sequence data prediction.},
  archive      = {J_NPL},
  author       = {Hu, Jiaojiao and Wang, Xiaofeng and Zhang, Ying and Zhang, Depeng and Zhang, Meng and Xue, Jianru},
  doi          = {10.1007/s11063-020-10319-3},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {2},
  pages        = {1485-1500},
  shortjournal = {Neural Process. Lett.},
  title        = {Time series prediction method based on variant LSTM recurrent neural network},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Flight delay prediction using deep convolutional neural
network based on fusion of meteorological data. <em>NPL</em>,
<em>52</em>(2), 1461–1484. (<a
href="https://doi.org/10.1007/s11063-020-10318-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, the civil aviation industry has a high precision demand of flight delay prediction. To make full use of the characteristics of flight data and meteorological data, two flight delay prediction models using deep convolution neural network based on fusion of meteorological data are proposed in this paper. One is DCNN (Dual-channel Convolutional Neural Network), which refers to the ResNet network structure. The other is SE-DenseNet (Squeeze and Excitation-Densely Connected Convolutional Network), combining the advantages of DenseNet and SENet. Firstly, flight data and meteorological data are fused in the model. Then, both DCNN and SE-DenseNet models are used to extract feature automatically based on the fused flight data set. Finally, the softmax classifier is adopted to predict the flight delay level. For proposed DCNN model, both straight channel and convolution channel are designed to guarantee the lossless transmission of the feature matrix and enhance the patency of the deep network. For proposed SE-DenseNet model, a SE module is added after the convolution layer of each DenseNet block, which can not only enhance the transmission of deep information but also achieve feature recalibration in the feature extraction process. The research results indicate that after considering characteristics of meteorological information, the accuracy of the model can be improved 1% compared with only considering the flight information. The two deep convolutional neural networks proposed in this paper, DCNN and SE-DenseNet, can both effectively improve the prediction accuracies, reaching to 92.1% and 93.19%, respectively.},
  archive      = {J_NPL},
  author       = {Qu, Jingyi and Zhao, Ting and Ye, Meng and Li, Jiayi and Liu, Chao},
  doi          = {10.1007/s11063-020-10318-4},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {2},
  pages        = {1461-1484},
  shortjournal = {Neural Process. Lett.},
  title        = {Flight delay prediction using deep convolutional neural network based on fusion of meteorological data},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Content-based bipartite user-image correlation for image
recommendation. <em>NPL</em>, <em>52</em>(2), 1445–1459. (<a
href="https://doi.org/10.1007/s11063-020-10317-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The popularity of online social curation networks takes benefits from its convenience to retrieve, collect, sort and share multimedia contents among users. With increasing content and user intent gap, effective recommendation becomes highly desirable for its further development. In this paper, we propose a content-based bipartite graph for image recommendation in social curation networks. Bipartite graph employs given sparse user-image interactions to infer user-image correlation for recommendation. Beside given user-image interactions, the user interacted visual content also reveals valuable user preferences. Visual content is embedded into the bipartite graph to extend the correlation density and the recommendation scope simultaneously. Furthermore, the content similarity is employed for recommendation reranking to improve the visual quality of recommended images. Experimental results demonstrate that the proposed method enhances the recommendation ability of the bipartite graph effectively.},
  archive      = {J_NPL},
  author       = {Jian, Meng and Jia, Ting and Wu, Lifang and Zhang, Lei and Wang, Dong},
  doi          = {10.1007/s11063-020-10317-5},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {2},
  pages        = {1445-1459},
  shortjournal = {Neural Process. Lett.},
  title        = {Content-based bipartite user-image correlation for image recommendation},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Partial pinning control for the synchronization of
fractional-order directed complex networks. <em>NPL</em>,
<em>52</em>(2), 1427–1444. (<a
href="https://doi.org/10.1007/s11063-020-10315-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper mainly studies the synchronization problem of fractional-order directed complex networks through partial pinning control. Unlike other papers, the network studied in this paper is neither strongly connected nor contains directed spanning trees. By utilizing the directed acyclic graph condensation and Layering theory, the network is decomposed into several strong connected components and then divided into layers. It proved that all or part of nodes in the network can achieve synchronization with the pinner’s trajectory, only when the root strong connected components in the upstream of these nodes are pinned and satisfy some sufficient conditions. In addition, according to the ControlRank algorithm, an optimized strategy is designed to solve the problem of the optimal selection of the pinning nodes to ensure the specific nodes of the network can achieve synchronization eventually. Meanwhile the amount of control energy cost will also be given in this paper. Finally, two simulation examples are given to verify the reliability and feasibility of the optimized algorithm.},
  archive      = {J_NPL},
  author       = {Liu, Fengyi and Yang, Yongqing and Hu, Aihua and Li, Li},
  doi          = {10.1007/s11063-020-10315-7},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {2},
  pages        = {1427-1444},
  shortjournal = {Neural Process. Lett.},
  title        = {Partial pinning control for the synchronization of fractional-order directed complex networks},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). SNRNet: A deep learning-based network for banknote serial
number recognition. <em>NPL</em>, <em>52</em>(2), 1415–1426. (<a
href="https://doi.org/10.1007/s11063-020-10313-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The banknote serial number recognition (SNR) plays an important role in the banking business and attracts much attention recently. However, most of the existing SNR methods take character segmentation and character classification as two separate steps, so that the accuracy of SNR heavily relies on the character segmentation, which is a challenging problem due to complicated background and uneven illumination. In this paper, the SNR is cast into a sequence prediction problem, which integrates such two steps into a unified network, and we propose a deep learning-based serial number recognition network, which can be trained end-to-end to avoid the preliminary character-segmentation with three steps as follow. First, the improved convolutional neural networks are employed to extract the feature sequence of the input image. Second, the feature sequence is used as an input to the bidirectional recurrent neural networks (BRNNs), where the character segmentation is not required. Finally, the label recognition is implemented using the connectionist temporal classification to decode the BRNNs’ output. The experimental results demonstrate that the proposed method outperforms the state-of-the-art methods in both accuracy and efficiency: it achieves character and serial number recognition of the renminbi (RMB) with accuracies 99.96% and 99.56%, respectively.},
  archive      = {J_NPL},
  author       = {Lin, Zhijie and He, Zhaoshui and Wang, Peitao and Tan, Beihai and Lu, Jun and Bai, Yulei},
  doi          = {10.1007/s11063-020-10313-9},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {2},
  pages        = {1415-1426},
  shortjournal = {Neural Process. Lett.},
  title        = {SNRNet: A deep learning-based network for banknote serial number recognition},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hyper autoencoders. <em>NPL</em>, <em>52</em>(2), 1395–1413.
(<a href="https://doi.org/10.1007/s11063-020-10310-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce the hyper autoencoder architecture where a secondary, hypernetwork is used to generate the weights of the encoder and decoder layers of the primary, actual autoencoder. The hyper autoencoder uses a one-layer linear hypernetwork to predict all weights of an autoencoder by taking only one embedding vector as input. The hypernetwork is smaller and as such acts as a regularizer. Just like the vanilla autoencoder, the hyper autoencoder can be used for unsupervised or semi-supervised learning. In this study, we also present a semi-supervised model using a combination of convolutional neural networks and autoencoders with the hypernetwork. Our experiments on five image datasets, namely, MNIST, Fashion MNIST, LFW, STL-10 and CelebA, show that the hyper autoencoder performs well on both unsupervised and semi-supervised learning problems.},
  archive      = {J_NPL},
  author       = {Soydaner, Derya},
  doi          = {10.1007/s11063-020-10310-y},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {2},
  pages        = {1395-1413},
  shortjournal = {Neural Process. Lett.},
  title        = {Hyper autoencoders},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Exponential synchronization of complex-valued neural
networks via average impulsive interval strategy. <em>NPL</em>,
<em>52</em>(2), 1377–1394. (<a
href="https://doi.org/10.1007/s11063-020-10309-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the issue of the exponential synchronization for complex-valued neural networks with both discrete and distributed delays is investigated by applying impulsive control protocol. Based on the Lyapunov–Krasovskii function, average impulsive interval as well as the comparison principle, some simple verifiable sufficient criteria are established to guarantee the exponential synchronization between the master and the slave systems. Meanwhile, through the serious analysis of the networks systems, the exponential convergence rate can be specified. Additionally, a numerical example is finally given to illustrate the effectiveness of the proposed theoretical results.},
  archive      = {J_NPL},
  author       = {Liu, Mei and Li, Zhanfeng and Jiang, Haijun and Hu, Cheng and Yu, Zhiyong},
  doi          = {10.1007/s11063-020-10309-5},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {2},
  pages        = {1377-1394},
  shortjournal = {Neural Process. Lett.},
  title        = {Exponential synchronization of complex-valued neural networks via average impulsive interval strategy},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Finite/fixed-time bipartite synchronization of coupled
delayed neural networks under a unified discontinuous controller.
<em>NPL</em>, <em>52</em>(2), 1359–1376. (<a
href="https://doi.org/10.1007/s11063-020-10308-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the finite-time and fixed-time bipartite synchronization (FFTBS) of coupled delayed neural networks (CDNNs) under signed graphs. For the structurally balanced or unbalanced network topology, both the goals of FFTBS of CDNNs are achieved simultaneously by a unified discontinuous controller. Some sufficient criterion are obtained to ensure the FFTBS under the new designed protocols, and the corresponding settling times are estimated as well. Finally, two simulations are established to verify the validity and effectiveness of the designs.},
  archive      = {J_NPL},
  author       = {Wu, Haocong and Wang, Xia and Liu, Xiaoyang and Cao, Jinde},
  doi          = {10.1007/s11063-020-10308-6},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {2},
  pages        = {1359-1376},
  shortjournal = {Neural Process. Lett.},
  title        = {Finite/Fixed-time bipartite synchronization of coupled delayed neural networks under a unified discontinuous controller},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Feature selection method based on differential correlation
information entropy. <em>NPL</em>, <em>52</em>(2), 1339–1358. (<a
href="https://doi.org/10.1007/s11063-020-10307-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is one of the major aspects of pattern classification systems. In previous studies, Ding and Peng recognized the importance of feature selection and proposed a minimum redundancy feature selection method to minimize redundant features for sequential selection in microarray gene expression data. However, since the minimum redundancy feature selection method is used mainly to measure the dependency between random variables of mutual information, the results cannot be optimal without consideration of global feature selection. Therefore, based on the framework of minimum redundancy-maximum correlation, this paper introduces entropy to measure global feature selection and proposes a new feature subset evaluation method, differential correlation information entropy. In our function, different bivariate correlation metrics are selected. Then, the feature selection is completed through sequence forward search. Two different classification models are used on eleven standard data sets of the UCI machine learning knowledge base to compare various comparison algorithms, such as mRMR, reliefF and feature selection method with joint maximal information entropy, with our method. The experimental results show that feature selection based on our proposed method is obviously superior to that of other models.},
  archive      = {J_NPL},
  author       = {Wang, Xiujuan and Yan, Yixuan and Ma, Xiaoyue},
  doi          = {10.1007/s11063-020-10307-7},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {2},
  pages        = {1339-1358},
  shortjournal = {Neural Process. Lett.},
  title        = {Feature selection method based on differential correlation information entropy},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust subspace clustering via latent smooth representation
clustering. <em>NPL</em>, <em>52</em>(2), 1317–1337. (<a
href="https://doi.org/10.1007/s11063-020-10306-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subspace clustering aims to group high-dimensional data samples into several subspaces which they were generated. Among the existing subspace clustering methods, spectral clustering-based algorithms have attracted considerable attentions because of their predominant performances shown in many subspace clustering applications. In this paper, we proposed to apply smooth representation clustering (SMR) to the reconstruction coefficient vectors which were obtained by sparse subspace clustering (SSC). Because the reconstruction coefficient vectors could be regarded as a kind of good representations of original data samples, the proposed method could be considered as a SMR performed in a latent subspace found by SSC and hoped to achieve better performances. For solving the proposed latent smooth representation algorithm (LSMR), we presented an optimization method and also discussed the relationships between LSMR with some related algorithms. Finally, experiments conducted on several famous databases demonstrate that the proposed algorithm dominates the related algorithms.},
  archive      = {J_NPL},
  author       = {Xiao, Xiaobo and Wei, Lai},
  doi          = {10.1007/s11063-020-10306-8},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {2},
  pages        = {1317-1337},
  shortjournal = {Neural Process. Lett.},
  title        = {Robust subspace clustering via latent smooth representation clustering},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new fixed-time stability criterion and its application to
synchronization control of memristor-based fuzzy inertial neural
networks with proportional delay. <em>NPL</em>, <em>52</em>(2),
1291–1315. (<a
href="https://doi.org/10.1007/s11063-020-10305-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new criterion related to fixed-time stability is derived by strict mathematical techniques such as definite integral and inequality techniques. Compared with the existing theorems, the estimate of upper bound for settling time is smaller, which is not only proved theoretically but also shown by numerical simulations. And the new criterion gets improved after introducing a new lemma. Then on the basis of the new criterion and the improved theorem, the fixed-time synchronization (FTS) of a memristor-based fuzzy inertial neural network (MFINN) with proportional delay is investigated via adopting a delay-dependent feedback controller, and several sufficient conditions are given for the FTS of the MFINN. At last, numerical simulations are raised to substaintiate the correctness of our theoretical results.},
  archive      = {J_NPL},
  author       = {Zhang, Yadan and Jiang, Minghui and Fang, Xue},
  doi          = {10.1007/s11063-020-10305-9},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {2},
  pages        = {1291-1315},
  shortjournal = {Neural Process. Lett.},
  title        = {A new fixed-time stability criterion and its application to synchronization control of memristor-based fuzzy inertial neural networks with proportional delay},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fixed-time synchronization of complex-valued memristor-based
neural networks with impulsive effects. <em>NPL</em>, <em>52</em>(2),
1263–1290. (<a
href="https://doi.org/10.1007/s11063-020-10304-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the fixed-time synchronization of complex-valued memristor-based neural networks with impulsive effects is investigated. We first separate these complex-valued networks into real and imaginary parts, and design the appropriate controllers. Then apply the set-valued map and the differential inclusion theorem to handle the discontinuity problems at the right-hand side of the drive-response systems. By constructing the comparison systems together with the Lyapunov function, we get the fixed-time synchronization conditions. Moreover, the estimate of the settling time is also explicitly obtained. Finally, two examples and their numerical simulations are presented to show the effectiveness of the obtained theoretical results.},
  archive      = {J_NPL},
  author       = {Zhang, Yanlin and Deng, Shengfu},
  doi          = {10.1007/s11063-020-10304-w},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {2},
  pages        = {1263-1290},
  shortjournal = {Neural Process. Lett.},
  title        = {Fixed-time synchronization of complex-valued memristor-based neural networks with impulsive effects},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Conditional generative adversarial networks with multi-scale
discriminators for prostate MRI segmentation. <em>NPL</em>,
<em>52</em>(2), 1251–1261. (<a
href="https://doi.org/10.1007/s11063-020-10303-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prostate MR image segmentation is a necessary preprocessing stage for computer-assisted diagnostic algorithms. Convolutional neural network, as a research focus in recent years, has been proven to be powerful in computer vision field. Recently, the most effective prostate MRI segmentation technology mainly relies on full convolutional network which has been widely used in semantic segmentation task. However, it’s independent and identically distributed assumption neglect the structural regularity present in MR images and miss information between pixels. In this paper, we propose an MRI-conditional generative adversarial networks for prostate segmentation. Our adversarial training make it context aware and the use of adversarial loss functions learn high-level structural information. The network consist of a generator and a discriminator. The generator consists of a contraction channel and an expansion channel like U-Net. The method we proposed uses a multi-scale discriminator which consist of two discriminators with the same structure but different input sizes. The objective function has two parts: one is the adversarial loss, the other is feature matching loss which stabilizes the training and get better convergence. The experiment show that our network can accurately segment the prostate MRI and outperforms most existing methods.},
  archive      = {J_NPL},
  author       = {He, Jun and Li, Xinke and Liu, Ninghui and Zhan, Shu},
  doi          = {10.1007/s11063-020-10303-x},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {2},
  pages        = {1251-1261},
  shortjournal = {Neural Process. Lett.},
  title        = {Conditional generative adversarial networks with multi-scale discriminators for prostate MRI segmentation},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Synchronization of stochastic complex dynamical networks
with mixed time-varying coupling delays. <em>NPL</em>, <em>52</em>(2),
1233–1250. (<a
href="https://doi.org/10.1007/s11063-020-10301-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Synchronization of complex networks with mixed time-varying coupling delays and stochastic perturbation. We constructed a novel Lyapunov functional with triple integral terms. By applying Jensen’s inequality and Lyapunov stability theory stability conditions are derived to check the asymptotical stability of the concerned system. By employing the stochastic evaluation and Kronecker product delay-dependent synchronization criteria of stochastic complex dynamical networks are derived. By using the derived conditions control gain matrix is obtained. Finally, numerical results are presented to demonstrate the effectiveness and usefulness of the proposed results.},
  archive      = {J_NPL},
  author       = {Ali, M. Syed and Usha, M. and Alsaedi, Ahmed and Ahmad, Bashir},
  doi          = {10.1007/s11063-020-10301-z},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {2},
  pages        = {1233-1250},
  shortjournal = {Neural Process. Lett.},
  title        = {Synchronization of stochastic complex dynamical networks with mixed time-varying coupling delays},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel combined model for short-term electric load
forecasting based on whale optimization algorithm. <em>NPL</em>,
<em>52</em>(2), 1207–1232. (<a
href="https://doi.org/10.1007/s11063-020-10300-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stable electric load forecasting plays a significant role in power system operation and grid management. Improving the accuracy of electric load forecasting is not only a hot topic for energy managers and researchers of the power system, but also a fair challenging and difficult task due to its complex nonlinearity characteristics. This paper proposes a new combination model, which uses the least squares support vector machine, extreme learning machine, and generalized regression neural network to predict the electric load in New South Wales, Australia. In addition, the model employs a heuristic algorithm–whale optimization algorithm to optimize the weight coefficient. To verify the usability and generalization ability of the model, this paper also applies the proposed combined model to electricity price forecasting and compares it with the benchmark method. The experimental results demonstrate that the combined model not only can get accurate results for short-term electric load forecasting, but also achieves fine accuracy for the same period of electricity price forecasting.},
  archive      = {J_NPL},
  author       = {Shang, Zhihao and He, Zhaoshuang and Song, Yanru and Yang, Yi and Li, Lian and Chen, Yanhua},
  doi          = {10.1007/s11063-020-10300-0},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {2},
  pages        = {1207-1232},
  shortjournal = {Neural Process. Lett.},
  title        = {A novel combined model for short-term electric load forecasting based on whale optimization algorithm},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improved stabilization results for markovian switching CVNNs
with partly unknown transition rates. <em>NPL</em>, <em>52</em>(2),
1189–1205. (<a
href="https://doi.org/10.1007/s11063-020-10299-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, stochastic stability and stabilization problems are investigated for the Markovian switching complex-valued neural networks with mixed delays, where the transition rates (TRs) of the Markov chain are partly unknown, which might reflect more the realistic dynamical behaviors of the neural networks. On the basis of the Lyapunov stability theory and the stochastic analysis method as well as the properties of the TR matrix, several mode-dependent criteria are derived to guarantee the considered complex-valued network to be globally asymptotically stable in mean-square sense. Then, by proposing an appropriate mode-dependent controller, stabilization conditions in terms of matrix inequalities are derived to guarantee the closed-loop system to be stochastically mean-square stable. Finally, two simulation examples are presented to illustrate the effectiveness of the proposed theoretical results.},
  archive      = {J_NPL},
  author       = {Li, Qiang and Liang, Jinling},
  doi          = {10.1007/s11063-020-10299-4},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {2},
  pages        = {1189-1205},
  shortjournal = {Neural Process. Lett.},
  title        = {Improved stabilization results for markovian switching CVNNs with partly unknown transition rates},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bifurcation mechanisation of a fractional-order neural
network with unequal delays. <em>NPL</em>, <em>52</em>(2), 1171–1187.
(<a href="https://doi.org/10.1007/s11063-020-10293-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The theme of bifurcation for a class of fractional-order neural networks (FONNs) with unique delay has been incalculably elucidated. It exhibits that multiple delays are capable of increasing the complicacy of realistic FONNs, but this has been insufficiently probed into. This paper attempts to conduct a research on the stability and bifurcation for a FONN with two unequal delays. By intercalating one delay and taking remnant delay as a bifurcation parameter, the incongruent critical values of diverse delays-induced bifurcations are exactly gained. Eventually, confirmation experiments are offered to endorse the procured theory.},
  archive      = {J_NPL},
  author       = {Huang, Chengdai and Cao, Jinde},
  doi          = {10.1007/s11063-020-10293-w},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {2},
  pages        = {1171-1187},
  shortjournal = {Neural Process. Lett.},
  title        = {Bifurcation mechanisation of a fractional-order neural network with unequal delays},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Super-resolution based automatic diagnosis of retinal
disease detection for clinical applications. <em>NPL</em>,
<em>52</em>(2), 1155–1170. (<a
href="https://doi.org/10.1007/s11063-020-10292-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In medical image processing, the automatic analysis of pathology localization and the anatomical segmentation steps are more important. The Fundus images of Low resolution (LR) are not applicable to detect the retinal disease. The main aim of this paper is to enhance the resolution of the low-resolution retinal images obtained from the cheap imaging devices within less computational time and high accuracy. So, we proposed the fundus image with Super-Resolution and its performance via the Diagnostically Significant Area (DSA). This approach focuses only on the region of Interest (ROI) instead of concentrating on the entire image leading to less computational time by reducing the time complexity. Therefore, the Eigen MR inter-band feature, Energy MR intra-band feature, Shannon entropy and Sensitive Contrast Interest (SCI) are used to capture the clinical data from the selected region. Therefore, the DSA is determined by using Levenshtein based KNN classifier. Because of better classification outcomes, the Bicubic method is employed in the selected region to reduce the loss of reconstruction error. Experimentally, the implementation works are carried out in the platform of MATLAB with DRIVE and STARE database images are chosen. The super-resolution image performances are compared with different start of art techniques such as PSM, GR-SR, LLE, and SpC-SR. Finally, higher efficiency with low computational super-resolution fundus images is collected.},
  archive      = {J_NPL},
  author       = {Anoop, V. and Bipin, P. R.},
  doi          = {10.1007/s11063-020-10292-x},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {2},
  pages        = {1155-1170},
  shortjournal = {Neural Process. Lett.},
  title        = {Super-resolution based automatic diagnosis of retinal disease detection for clinical applications},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An analysis of activation function saturation in particle
swarm optimization trained neural networks. <em>NPL</em>,
<em>52</em>(2), 1123–1153. (<a
href="https://doi.org/10.1007/s11063-020-10290-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The activation functions used in an artificial neural network define how nodes of the network respond to input, directly influence the shape of the error surface and play a role in the difficulty of the neural network training problem. Choice of activation functions is a significant question which must be addressed when applying a neural network to a problem. One issue which must be considered when selecting an activation function is known as activation function saturation. Saturation occurs when a bounded activation function primarily outputs values close to its boundary. Excessive saturation damages the network’s ability to encode information and may prevent successful training. Common functions such as the logistic and hyperbolic tangent functions have been shown to exhibit saturation when the neural network is trained using particle swarm optimization. This study proposes a new measure of activation function saturation, evaluates the saturation behavior of eight common activation functions, and evaluates six measures of controlling activation function saturation in particle swarm optimization based neural network training. Activation functions that result in low levels of saturation are identified. For each activation function recommendations are made regarding which saturation control mechanism is most effective at reducing saturation.},
  archive      = {J_NPL},
  author       = {Dennis, Cody and Engelbrecht, Andries P. and Ombuki-Berman, Beatrice M.},
  doi          = {10.1007/s11063-020-10290-z},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {2},
  pages        = {1123-1153},
  shortjournal = {Neural Process. Lett.},
  title        = {An analysis of activation function saturation in particle swarm optimization trained neural networks},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Radical and stroke-enhanced chinese word embeddings based on
neural networks. <em>NPL</em>, <em>52</em>(2), 1109–1121. (<a
href="https://doi.org/10.1007/s11063-020-10289-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The internal structural information of words has proven to be very effective for learning Chinese word embeddings. However, most previous attempts made a single form extraction of internal feature to learn representations, ignoring the comprehensive combination of such information. And they focused only on explicit feature of internal structures, even though these structures still have the implicit semantics of words. In this paper, we propose Radical and Stroke-enhanced Word Embeddings (RSWE), a novel method based on neural networks for learning Chinese word embeddings with joint guidance from semantic and morphological internal information. RSWE enables an embedding model to learn simultaneously from (1) implicit semantic information that is exploited from the radicals, and (2) stroke n-grams information that can be explicitly obtained from Chinese words. In the learning process, RSWE uses stroke n-grams to capture the local structural feature of words, and integrates the implicit information exploited from radicals to enhance the semantic of embeddings. Through this combination procedure, semantics of Chinese words are effectively transferred into the learned embeddings. We evaluate the effectiveness of RSWE on word similarity computation, word analogy reasoning, performance over dimensions, performance over learning corpus size, and named entity recognition tasks, the experimental results show that our model outperforms existing state-of-the-art approaches.},
  archive      = {J_NPL},
  author       = {Wang, Shirui and Zhou, Wenan and Zhou, Qiang},
  doi          = {10.1007/s11063-020-10289-6},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {2},
  pages        = {1109-1121},
  shortjournal = {Neural Process. Lett.},
  title        = {Radical and stroke-enhanced chinese word embeddings based on neural networks},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Approximately optimal control of discrete-time nonlinear
switched systems using globalized dual heuristic programming.
<em>NPL</em>, <em>52</em>(2), 1089–1108. (<a
href="https://doi.org/10.1007/s11063-020-10278-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on the idea of data-driven control, a novel iterative adaptive dynamic programming (ADP) algorithm based on the globalized dual heuristic programming (GDHP) technique is used to solve the optimal control problem of discrete-time nonlinear switched systems. In order to solve the Hamilton–Jacobi–Bellman (HJB) equation of switched systems, the iterative ADP method is proposed and the strict convergence analysis is also provided. Three neural networks are constructed to implement the iterative ADP algorithm, where a novel model network is designed to identify the system dynamics, a critic network is used to approximate the cost function and its partial derivatives, and an action network is provided to obtain the approximate optimal control law. Two simulation examples are described to illustrate the effectiveness of the proposed method by comparing with the heuristic dynamic programming (HDP) and dual heuristic programming (DHP) methods.},
  archive      = {J_NPL},
  author       = {Mu, Chaoxu and Liao, Kaiju and Ren, Ling and Gao, Zhongke},
  doi          = {10.1007/s11063-020-10278-9},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {2},
  pages        = {1089-1108},
  shortjournal = {Neural Process. Lett.},
  title        = {Approximately optimal control of discrete-time nonlinear switched systems using globalized dual heuristic programming},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). <span class="math display"><em>H</em><sub>∞</sub></span>
state estimation of static neural networks with mixed delay.
<em>NPL</em>, <em>52</em>(2), 1069–1087. (<a
href="https://doi.org/10.1007/s11063-019-10171-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on studying the $$H_{\infty }$$ state estimation of static neural networks with mixed delay in which leakage time-varying delay and distributed delay are taken into account, simultaneously. By constructing several suitable Lyapunov–Krasovskii functionals and linear matrix inequality technique, the delay-independent and delay-dependent criteria are established in order that the error system is globally asymptotically stable with $$H_{\infty }$$ performance, respectively. In addition, with the skills to construct Lyapunov–Krasovskii functionals, we obtain the results in which we constitutionally drop the differentiability requirement of transmission delays. Some numerical examples are given to show the effectiveness and advantages of the obtained results.},
  archive      = {J_NPL},
  author       = {Wu, Shuchen and Han, Xiuping and Li, Xiaodi},
  doi          = {10.1007/s11063-019-10171-0},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {2},
  pages        = {1069-1087},
  shortjournal = {Neural Process. Lett.},
  title        = {$$H_{\infty }$$ state estimation of static neural networks with mixed delay},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hierarchical deep neural network for image captioning.
<em>NPL</em>, <em>52</em>(2), 1057–1067. (<a
href="https://doi.org/10.1007/s11063-019-09997-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatically describing image content with natural language is a fundamental challenge for computer vision community. General methods used visual information to generate sentences directly. However, only depending on the visual information is not enough to generate the fine-grained descriptions for given images. In this paper, we exploit the fusion of visual information and high-level semantic information for image captioning. We propose a hierarchical deep neural network, which consists of the bottom layer and the top layer. The former extracts the visual and high-level semantic information from image and detected regions, respectively, while the latter integrates both of them with adaptive attention mechanism for the caption generation. The experimental results achieve the competing performances against the state-of-the-art methods on MSCOCO dataset.},
  archive      = {J_NPL},
  author       = {Su, Yuting and Li, Yuqian and Xu, Ning and Liu, An-An},
  doi          = {10.1007/s11063-019-09997-5},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {2},
  pages        = {1057-1067},
  shortjournal = {Neural Process. Lett.},
  title        = {Hierarchical deep neural network for image captioning},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). 3D model retrieval using bipartite graph matching based on
attention. <em>NPL</em>, <em>52</em>(2), 1043–1055. (<a
href="https://doi.org/10.1007/s11063-019-10155-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose an attention-based bipartite graph 3D model retrieval algorithm, where many-to-many matching method, the weighted bipartite graph matching, is employed for comparison between two 3D models. Considering the panoramic views can donate the spatial and structural information, in this work, we use panoramic views to represent each 3D model. Attention mechanism is used to generate the weight of all views of each model. And then, we construct a weighted bipartite graph with the views of those models and the weight of each view. According to the bipartite graph, the matching result is used to measure the similarity between two 3D models. We experiment our method on ModelNet, NTU and ETH datasets, and the experimental results and comparison with other methods show the effectiveness of our method.},
  archive      = {J_NPL},
  author       = {Sun, Shanlin and Li, Yun and Xie, Yunfeng and Tan, Zhicheng and Yao, Xing and Zhang, Rongyao},
  doi          = {10.1007/s11063-019-10155-0},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {2},
  pages        = {1043-1055},
  shortjournal = {Neural Process. Lett.},
  title        = {3D model retrieval using bipartite graph matching based on attention},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Pairwise generalization network for cross-domain image
recognition. <em>NPL</em>, <em>52</em>(2), 1023–1041. (<a
href="https://doi.org/10.1007/s11063-019-10041-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, convolutional neural networks have received increasing attention from the computer vision and machine learning communities. Due to the differences in the distribution, tone and brightness of the training domain and test domain, researchers begin to focus on cross-domain image recognition. In this paper, we propose a Pairwise Generalization Network (PGN) for addressing the problem of cross-domain image recognition where Instance Normalization and Batch Normalization are added to enhance their abilities in the original domain and to expand to the new domain. Meanwhile, the Siamese architecture is utilized in the PGN to learn an embedding subspace that is discriminative, and map positive sample pairs aligned and negative sample pairs separated, which can work well even with only few labeled target data samples. We also add residual architecture and MMD loss for the PGN model to further improve its performance. Extensive experiments on two different public benchmarks show that our PGN solution significantly outperforms the state-of-the-art methods.},
  archive      = {J_NPL},
  author       = {Liu, Y. B. and Han, T. T. and Gao, Z.},
  doi          = {10.1007/s11063-019-10041-9},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {2},
  pages        = {1023-1041},
  shortjournal = {Neural Process. Lett.},
  title        = {Pairwise generalization network for cross-domain image recognition},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Construction of retinal vessel segmentation models based on
convolutional neural network. <em>NPL</em>, <em>52</em>(2), 1005–1022.
(<a href="https://doi.org/10.1007/s11063-019-10011-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Segmentation of retinal vessels in fundus images plays a very important role in diagnosing relevant diseases. In this paper, we have constructed automated segmentation models for the retinal vessel segmentation task based on convolutional neural networks. Since some typical deep convolutional neural networks need to be fed by high-resolution patches, small retinal patches should be interpolated to the specific resolution. The interpolated patches sometimes would introduce additional noises. Thus, we modify some typical deep architectures by inserting a set of convolutional layers. In this way, our models have the ability to adapt to different resolutions. Overall, five models are analyzed and compared in our studies including LeNet, M-AlexNet (modified AlexNet), M-ZF-Net (Modified ZF-Net), M-VGG (Modified VGG) and Deformable-ConvNet. Deformable-ConvNet captures the vascular structure and is used to do the retinal vessel segmentation task for the first time. We train the models from scratch and compare their ability to discriminate vessels/non-vessel pixels on two retinal fundus image datasets, DRIVE and STARE. Results are analyzed and compared in our studies. We obtain the highest accuracy of 0.9628/0.9690, lowest loss of 0.1045/0.0968, and highest AUC of 0.9764/0.9844 on DRIVE/STARE respectively. We also compare the CNN models with other segmentation methods. The results demonstrate the high effectiveness of the CNN-based approaches.},
  archive      = {J_NPL},
  author       = {Jin, Qiangguo and Chen, Qi and Meng, Zhaopeng and Wang, Bing and Su, Ran},
  doi          = {10.1007/s11063-019-10011-1},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {2},
  pages        = {1005-1022},
  shortjournal = {Neural Process. Lett.},
  title        = {Construction of retinal vessel segmentation models based on convolutional neural network},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hierarchical temporal fusion of multi-grained attention
features for video question answering. <em>NPL</em>, <em>52</em>(2),
993–1003. (<a href="https://doi.org/10.1007/s11063-019-10003-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work aims to address the problem of video question answering (VideoQA) with a novel model and a new open-ended VideoQA dataset. VideoQA is a challenging field in visual information retrieval, which aims to generate the answer according to the video content and question. Ultimately, VideoQA is a video understanding task. Efficiently combining the multi-grained representations is the key factor in understanding a video. The existing works mostly focus on overall frame-level visual understanding to tackle the problem, which neglects finer-grained and temporal information inside the video, or just combines the multi-grained representations simply by concatenation or addition. Thus, we propose the multi-granularity temporal attention network that enables to search for the specific frames in a video that are holistically and locally related to the answer. We first learn the mutual attention representations of multi-grained visual content and question. Then the mutually attended features are combined hierarchically using a double layer LSTM to generate the answer. Furthermore, we illustrate several different multi-grained fusion configurations to prove the advancement of this hierarchical architecture. The effectiveness of our model is demonstrated on the large-scale video question answering dataset based on ActivityNet dataset.},
  archive      = {J_NPL},
  author       = {Xiao, Shaoning and Li, Yimeng and Ye, Yunan and Chen, Long and Pu, Shiliang and Zhao, Zhou and Shao, Jian and Xiao, Jun},
  doi          = {10.1007/s11063-019-10003-1},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {2},
  pages        = {993-1003},
  shortjournal = {Neural Process. Lett.},
  title        = {Hierarchical temporal fusion of multi-grained attention features for video question answering},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A multi-modality sensor system for unmanned surface vehicle.
<em>NPL</em>, <em>52</em>(2), 977–992. (<a
href="https://doi.org/10.1007/s11063-019-09998-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The onboard multi-modality sensors significantly expand perception ability of Unmanned Surface Vehicle (USV). This paper aims to fully utilize various onboard sensors and enhance USV’s object detection performance. We solve several unique challenges for application of USV multi-modality sensor system in the complex maritime environment. By utilizing deep learning networks, we achieved accurate object detection on water surface. We firstly propose a multi-modality sensor calibration method. The network fuses RGB images with multiple point clouds from various sensors. The well-calibrated image and point cloud are input to our deep object detection network, and conduct 3D detection through proposal generation network and object detection network. Meanwhile, we made a series of improvements to the system framework, which accelerate the detection procedures. We collected two datasets from the real-world offshore field and the simulation scenes respectively. The experiments on both datasets showed valid calibration results. On this basis, our object detection network achieves better accuracy than other methods. The performance of the proposed multi-modality sensor system meets the application requirement of our prototype USV platform.},
  archive      = {J_NPL},
  author       = {Liu, Hao and Nie, Jie and Liu, Yingjian and Wu, Yingying and Wang, Hanxing and Qu, Fangchao and Liu, Wei and Li, Yangyang},
  doi          = {10.1007/s11063-019-09998-4},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {2},
  pages        = {977-992},
  shortjournal = {Neural Process. Lett.},
  title        = {A multi-modality sensor system for unmanned surface vehicle},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Unsupervised learning approach for abnormal event detection
in surveillance video by hybrid autoencoder. <em>NPL</em>,
<em>52</em>(2), 961–975. (<a
href="https://doi.org/10.1007/s11063-019-10113-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abnormal detection plays an important role in video surveillance. LSTM encoder–decoder is used to learn representation of video sequences and applied for detecting abnormal event in complex environment. The learned representation of LSTM encoder–decoder is learned from encoder, and it is crucial for decoder. However, LSTM encoder–decoder generally fails to account for the global context of the learned representation with a fixed dimension representation. In this paper, we explore a hybrid autoencoder architecture, which not only extracts better spatio-temporal context, but also improves the extrapolate capability of the corresponding decoder by the shortcut connection. The experiment shows that the hybrid model performs better than the state-of-the-art anomaly detection methods in both qualitative and quantitative ways on benchmark datasets.},
  archive      = {J_NPL},
  author       = {Zhou, Fuqiang and Wang, Lin and Li, Zuoxin and Zuo, Wangxia and Tan, Haishu},
  doi          = {10.1007/s11063-019-10113-w},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {2},
  pages        = {961-975},
  shortjournal = {Neural Process. Lett.},
  title        = {Unsupervised learning approach for abnormal event detection in surveillance video by hybrid autoencoder},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An abstract painting generation method based on deep
generative model. <em>NPL</em>, <em>52</em>(2), 949–960. (<a
href="https://doi.org/10.1007/s11063-019-10063-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer technology provides new conditions and possibilities for art creation and research, and also expands the forms of artistic expression. Computer-created art has thus become one of the important forms of art. In this paper, we proposed a novel method of generating abstract paintings. We used the public painting dataset WikiArt and designed a K-Means algorithm that automatically finds the optimal K value to perform color segmentation on these images, and divide the picture into different color blocks. We proposed the concept of the collection of color block (CoCB), which records all color block information of the segmented image and serves as an intermediate vector for the generation of abstract painting. We extracted the CoCB as an empirical sample and used a learning model based on deep learning to automatically generate brand-new CoCBs. We then converted the CoCBs into an abstract painting, so that the generated abstract painting also followed certain aesthetic rules. Experiments showed that the resulting abstract painting have great visual impact, and some of them have been installed as decorations in public and private spaces, as well as art institutions. Also, some artists and designers have used the results in their work.},
  archive      = {J_NPL},
  author       = {Li, Mao and Lv, Jiancheng and Wang, Jian and Sang, Yongsheng},
  doi          = {10.1007/s11063-019-10063-3},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {2},
  pages        = {949-960},
  shortjournal = {Neural Process. Lett.},
  title        = {An abstract painting generation method based on deep generative model},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Refocused attention: Long short-term rewards guided video
captioning. <em>NPL</em>, <em>52</em>(2), 935–948. (<a
href="https://doi.org/10.1007/s11063-019-10030-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The adaptive cooperation of visual model and language model is essential for video captioning. However, due to the lack of proper guidance for each time step in end-to-end training, the over-dependence of language model often results in the invalidation of attention-based visual model, which is called ‘Attention Defocus’ problem in this paper. Based on an important observation that the recognition precision of entity word can reflect the effectiveness of the visual model, we propose a novel strategy called refocused attention to optimize the training and cooperating of visual model and language model, using ingenious guidance at appropriate time step. The strategy consists of a short-term-reward guided local entity recognition and a long-term-reward guided global relation understanding, neither requires any external training data. Moreover, a framework with hierarchical visual representations and hierarchical attention is established to fully exploit the potential strength of the proposed learning strategy. Extensive experiments demonstrate that the ingenious guidance strategy together with the optimized structure outperform state-of-the-art video captioning methods with relative improvements 7.7% in BLEU-4 and 5.0% in CIDEr-D on MSVD dataset, even without multi-modal features.},
  archive      = {J_NPL},
  author       = {Dong, Jiarong and Gao, Ke and Chen, Xiaokai and Cao, Juan},
  doi          = {10.1007/s11063-019-10030-y},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {2},
  pages        = {935-948},
  shortjournal = {Neural Process. Lett.},
  title        = {Refocused attention: Long short-term rewards guided video captioning},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Graph-theoretic approach to finite-time synchronization for
fuzzy cohen–grossberg neural networks with mixed delays and
discontinuous activations. <em>NPL</em>, <em>52</em>(1), 905–933. (<a
href="https://doi.org/10.1007/s11063-020-10237-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates finite-time synchronization for fuzzy Cohen–Grossberg neural networks (FCGNNs) with mixed delays and discontinuous activations via state-feedback control. The features of FCGNNs, discrete time delays, distributed delays and discontinuous activations are taken into account which makes our networks more general and practical in comparison with the most existing Cohen–Grossberg neural networks. Two switching state-feedback controllers designed for the implement of finite-time synchronization can be used to effectively overcome the limitations of the traditional continuous linear feedback controllers. Different from previous work, graph theory and Lyapunov method are used to study finite-time synchronization of FCGNNs for the first time in this paper, then some sufficient criteria are obtained to guarantee the finite-time synchronization of FCGNNs. In particular, it is worth noting that the settling time for finite-time synchronization is closely related to the topological structure of FCNNs. Finally, two numerical examples are given to verify the feasibility and effectiveness of the theoretical results.},
  archive      = {J_NPL},
  author       = {Xu, Dongsheng and Xu, Chengqiang and Liu, Ming},
  doi          = {10.1007/s11063-020-10237-4},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {905-933},
  shortjournal = {Neural Process. Lett.},
  title        = {Graph-theoretic approach to finite-time synchronization for fuzzy Cohen–Grossberg neural networks with mixed delays and discontinuous activations},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Consistent discriminant correlation analysis. <em>NPL</em>,
<em>52</em>(1), 891–904. (<a
href="https://doi.org/10.1007/s11063-020-10285-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view dimensionality reduction is an importan subject in multi-view learning. Canonical correlation analysis and its various improved forms can effectively solve this problem. But most of these algorithms do not fully consider the discriminant information and view consistency information contained in the data itself simultaneously. To solve this problem, a new multi-view dimensionality reduction algorithm, consistent discriminant correlation analysis, is proposed in this paper. The algorithm integrates the class information and the consistency information between views into the dimension reduction process. By maximizing the within-class correlations and the consistency between views, and minimizing the between-class correlations simultaneously, it extracts the low-dimensional features that are more efficient to classification. Furthermore, a kernel consistent discriminant correlation analysis is proposed. The experimental results on several data sets demonstrate the effectiveness of the proposed methods.},
  archive      = {J_NPL},
  author       = {Zhang, Enhao and Chen, Xiaohong and Wang, Liping},
  doi          = {10.1007/s11063-020-10285-w},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {891-904},
  shortjournal = {Neural Process. Lett.},
  title        = {Consistent discriminant correlation analysis},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Semi-supervised learning algorithm based on linear lie group
for imbalanced multi-class classification. <em>NPL</em>, <em>52</em>(1),
869–889. (<a href="https://doi.org/10.1007/s11063-020-10287-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practical application, the data are imbalanced, it is difficult to find the balanced, rather skewed data is the common occurrence. This poses a severe challenge to the classification algorithm. At present, imbalanced data classification methods are mainly for binary classes designed, and it is difficult to extend them to multiple classes. In this study, we introduced Lie group machine learning and proposed a semi-supervised learning algorithm based on the linear Lie group. First, the sample set is represented by a matrix, the isomorphism(or homomorphism)-GL(n) linear Lie group of the corresponding learning system is found, and the labeled data are used to represent the object to be learned by linear Lie group. Then, according to the algebraic structure of the linear Lie group, it is marked by the group method. We performed experiments on 18 benchmark multi-class imbalanced datasets to demonstrate the performance of our proposed method and measured the performance of multi-class imbalanced data using four state-of-the-art learning algorithms (mean of accuracy, mean of f-measure, and mean of area under the curve). The experimental results demonstrate that the proposed method is effective and improves the performance.},
  archive      = {J_NPL},
  author       = {Xu, Chengjun and Zhu, Guobin},
  doi          = {10.1007/s11063-020-10287-8},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {869-889},
  shortjournal = {Neural Process. Lett.},
  title        = {Semi-supervised learning algorithm based on linear lie group for imbalanced multi-class classification},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-geometric sparse subspace clustering. <em>NPL</em>,
<em>52</em>(1), 849–867. (<a
href="https://doi.org/10.1007/s11063-020-10274-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the Riemannian manifold has received special attention in unsupervised clustering since the real-world visual data usually resides on a special manifold where Euclidean geometry fails to capture. Although many clustering algorithms have been proposed, most of them use only a single geometric model to describe the data. In this paper, a multi-geometric subspace clustering model is proposed, and the subspace representation is learned together by constructing a shared affinity matrix of multi-order data. Experimental results on several different types of datasets show that the clustering performance of our proposed algorithm is better than most of subspaces algorithms.},
  archive      = {J_NPL},
  author       = {Hu, Wen-Bo and Wu, Xiao-Jun},
  doi          = {10.1007/s11063-020-10274-z},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {849-867},
  shortjournal = {Neural Process. Lett.},
  title        = {Multi-geometric sparse subspace clustering},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). SAOSA: Stable adaptive optimization for stacked
auto-encoders. <em>NPL</em>, <em>52</em>(1), 823–848. (<a
href="https://doi.org/10.1007/s11063-020-10277-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stacked auto-encoders are considered deep learning algorithms automatically extracting meaningful unsupervised features from the input data using a hierarcfhical learning process. The parameters are learnt layer-by-layer in each auto-encoder (AE). As optimization is one of the main components of the neural networks and auto-encoders, the learning rate is one of the crucial hyper-parameters of neural networks and AE. This issue on a large scale and especially sparse data sets is more important. In this paper, we adapt the learning rate for special AE corresponding to various components of AE networks in each stochastic gradient calculation and analyze the theoretical convergence of back-propagation learning for the proposed method. We also promote our methodology for online adaptive optimizations suitable for deep learning. We obtain promising results compared to constant learning rates on the (1) MNIST digit, (2) blogs-Gender-100 text, (3) smartphone based recognition of human activities and postural transitions time series, and (4) EEG brainwave feeling emotions time series classification tasks using a single machine.},
  archive      = {J_NPL},
  author       = {Moradi Vartouni, Ali and Teshnehlab, Mohammad and Sedighian Kashi, Saeed},
  doi          = {10.1007/s11063-020-10277-w},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {823-848},
  shortjournal = {Neural Process. Lett.},
  title        = {SAOSA: Stable adaptive optimization for stacked auto-encoders},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multilayer convolutional neural network to filter low
quality content from quora. <em>NPL</em>, <em>52</em>(1), 805–821. (<a
href="https://doi.org/10.1007/s11063-020-10284-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Question answering (QA) websites now play a crucial role in meeting Internet users’ information needs. Quora is a growing QA platform where users get quick answers to their questions from their peers. Nonetheless, it is noted that a significant number of questions remained unanswered for a long time. Questions that have long been unable to receive any answer, opinion-based, need a debate to get the answers, or a valid answer does not exist, fall under Insincere question group. It is therefore important to weed out Insincere questions in order to maintain the integrity of the site. Quora have a huge number of such questions that can not be filtered manually. To overcome this problem, this paper proposes a multi-layer convolutional neural network model that helps to minimize Insincere questions from the website. Two embeddings were created from Quora dataset: (i) using Skipgram, and (ii) using Continuous Bag of Word model. The created embeddings and a pre-trained GloVe embedding vector were used for system development. The proposed model needs only the question text to predict the question is Insincere question or not and hence free from manual feature engineering. The experimental results indicated that the proposed multilayer CNN model outperforming over the earlier works by achieving the F1-score of 0.98 for the best case.},
  archive      = {J_NPL},
  author       = {Roy, Pradeep Kumar},
  doi          = {10.1007/s11063-020-10284-x},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {805-821},
  shortjournal = {Neural Process. Lett.},
  title        = {Multilayer convolutional neural network to filter low quality content from quora},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Intra-layer synchronization in duplex networks with
time-varying delays and stochastic perturbations under impulsive
control. <em>NPL</em>, <em>52</em>(1), 785–804. (<a
href="https://doi.org/10.1007/s11063-020-10281-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper concerns the intra-layer synchronization in duplex networks with stochastic perturbations under impulsive control. In this paper, we proposed a dynamical system on a duplex network with impulsive control, where delay of interactions within each layer, delay of interactions between layers, and environmental noises are included. Different from Tang et al. (Sci China Technol Sci 61(12):1907–1914, 2018), we used different topology structures for the two layers of the duplex network. Different from the model of Shen and Tang (Chin Phys B 27(10):100503, 2018), delays in the node interactions within or between the layers are allowed. Besides, the environmental noises are included. Moreover, due to the superior efficiency of impulsive control, we use it to control the synchronization of the duplex network even if the dynamical system exhibits chaos phenomena. Finally, we obtain some interesting simulation results by applying our theoretic results to the Chua–Chua chaotic system to show the effectiveness of our control schemes.},
  archive      = {J_NPL},
  author       = {Zhuang, Jinsen and Zhou, Yan and Xia, Yonghui},
  doi          = {10.1007/s11063-020-10281-0},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {785-804},
  shortjournal = {Neural Process. Lett.},
  title        = {Intra-layer synchronization in duplex networks with time-varying delays and stochastic perturbations under impulsive control},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An improved crow search algorithm for test data generation
using search-based mutation testing. <em>NPL</em>, <em>52</em>(1),
767–784. (<a href="https://doi.org/10.1007/s11063-020-10288-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automation of test data generation is of prime importance in software testing because of the high cost and time incurred in manual testing. This paper proposes an Improved Crow Search Algorithm (ICSA) to automate the generation of test suites using the concept of mutation testing by simulating the intelligent behaviour of crows and Cauchy distribution. The Crow Search Algorithm suffers from the problem of search solutions getting trapped into the local search. The ICSA attempts to enhance the exploration capabilities of the metaheuristic algorithm by utilizing the concept of Cauchy random number. The concept of Mutation Sensitivity Testing has been used for defining the fitness function for the search based approach. The fitness function used, aids in finding optimal test suite which can achieve high detection score for the Program Under Test. The empirical evaluation of the proposed approach with other popular meta-heuristics, prove the effectiveness of ICSA for test suite generation using the concepts of mutation testing.},
  archive      = {J_NPL},
  author       = {Jatana, Nishtha and Suri, Bharti},
  doi          = {10.1007/s11063-020-10288-7},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {767-784},
  shortjournal = {Neural Process. Lett.},
  title        = {An improved crow search algorithm for test data generation using search-based mutation testing},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new supervised clustering framework using multi
discriminative parts and expectation–maximization approach for a
fine-grained animal breed classification (SC-MPEM). <em>NPL</em>,
<em>52</em>(1), 727–766. (<a
href="https://doi.org/10.1007/s11063-020-10246-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained image classification is active research in the field of computer vision. Specifically, animal breed classification is an arduous task due to the challenges in camera traps images like occlusion, camouflage, poor illumination, pose variation, etc. In this paper, we propose a fine-grained animal breed classification model using supervised clustering based on Multi Part-Convolutional Neural Network (MP-CNN) and Expectation–Maximization (EM) clustering. The proposed model follows a straightforward pipeline that combines the deep feature extraction using the CNN pre-trained on ImageNet and classifies unsupervised data using EM clustering. Further, we also propose a multi discriminative part selection and detection for the precise classification of animal breeds without using bounding box and annotations on both training and testing phases. The model is tested on several benchmark datasets for animals, including the largest camera trap Snapshot Serengeti dataset and has achieved a cumulative accuracy of 98.4%. The results from the proposed model strengthen the belief that supervised training of deep CNN on a large and versatile dataset, extracts better features than most of the traditional approaches, even for the unsupervised tasks.},
  archive      = {J_NPL},
  author       = {Sundaram, Divya Meena and Loganathan, Agilandeeswari},
  doi          = {10.1007/s11063-020-10246-3},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {727-766},
  shortjournal = {Neural Process. Lett.},
  title        = {A new supervised clustering framework using multi discriminative parts and Expectation–Maximization approach for a fine-grained animal breed classification (SC-MPEM)},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Li-function activated zhang neural network for online
solution of time-varying linear matrix inequality. <em>NPL</em>,
<em>52</em>(1), 713–726. (<a
href="https://doi.org/10.1007/s11063-020-10291-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the previous work, a typical recurrent neural network termed Zhang neural network (ZNN) has been developed for various time-varying problems solving. Based on the previous work, by exploiting a special activation function (i.e., Li activation function), the resultant ZNN model is presented and investigated in this paper for online solution of time-varying linear matrix inequality (TVLMI). For such a Li-function activated ZNN (LFAZNN) model, theoretical results are provided to show its excellent computational performance on solving the TVLMI. That is, the presented LFAZNN model has the property of finite-time convergence. Comparative simulation results with two illustrative examples further substantiate the efficacy of the presented LFAZNN model for TVLMI solving.},
  archive      = {J_NPL},
  author       = {Guo, Dongsheng and Lin, Xinjie},
  doi          = {10.1007/s11063-020-10291-y},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {713-726},
  shortjournal = {Neural Process. Lett.},
  title        = {Li-function activated zhang neural network for online solution of time-varying linear matrix inequality},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). GrasNet: A simple grassmannian network for image set
classification. <em>NPL</em>, <em>52</em>(1), 693–711. (<a
href="https://doi.org/10.1007/s11063-020-10276-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representing image sets on the Grassmann manifold has been widely used in visual classification tasks, and the existing Grassmannian learning methods have shown powerful ability in feature representation. In order to develop the ideology of conventional deep learning to the Grassmann manifold, we devise a simple Grassmann manifold feature learning network (GrasNet) in this paper, which provides a new way for image set classification. For the proposed GrasNet, we design a fully mapping layer to transform the input Grassmannian data into more appropriate representations. In view of the consistency of the data space, orthonormal maintaining layer is exploited to normalize the input matrices to form a valid Grassmann manifold. To perform Grassmannian computing on the resulting Grassmann manifold-valued features, we also introduce a projection mapping layer. For the sake of further reducing the dimensionality and redundancy of the learned geometric features, we devise a projection pooling layer. The log-map layer is finally adopted to embed the resulting data manifold into a tangent space via Riemannian matrix logarithm map, such that the Euclidean computations apply. To learn the multistage connection weights for the proposed GrasNet, we utilize the Principal Component Analysis (PCA) algorithm rather than the complex Riemannian matrix backpropagation optimizer, which makes it be built and trained extremely easy and efficient. We evaluate our model on three different visual classification tasks: face recognition, object categorization and cell identification, respectively. Extensive classification results verify its feasibility and effectiveness.},
  archive      = {J_NPL},
  author       = {Wang, Rui and Wu, Xiao-Jun},
  doi          = {10.1007/s11063-020-10276-x},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {693-711},
  shortjournal = {Neural Process. Lett.},
  title        = {GrasNet: A simple grassmannian network for image set classification},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel technique for segmentation of high resolution remote
sensing images based on neural networks. <em>NPL</em>, <em>52</em>(1),
679–692. (<a href="https://doi.org/10.1007/s11063-020-10280-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote sensing images have become one of the most important imaging resources recently. Thus, it is important to develop high-performance techniques to process and manipulate these images. On the other hand, image processing techniques are enhanced spatially based on neural networks. Deep learning is one of the most important techniques in use for computer vision tasks and has been deployed successfully to solve many tasks. But when dealing with remote sensing images, the deep learning method faces two main problems: the underfitting problem, because of the small amount of learning data and the unbalanced receptive field problem, because of the structural stereotype of the remote sensing images. In this paper, we propose to use a complex-valued neural network to segment high-resolution remote sensing images. The proposed network can deal with the problems of remote sensing images by using an ensemble of Complex-Valued Auto-Encoder. Based on an adaptive clustering technique, this network can be used to solve the multi-label segmentation problem of remote sensing images. The proposed method achieves state-of-the-art performance when evaluated on the ISPRS 2D dataset.},
  archive      = {J_NPL},
  author       = {Barr, Mohammad},
  doi          = {10.1007/s11063-020-10280-1},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {679-692},
  shortjournal = {Neural Process. Lett.},
  title        = {A novel technique for segmentation of high resolution remote sensing images based on neural networks},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Wireless sensor network based smart grid supported by a
cognitively driven load management decision making. <em>NPL</em>,
<em>52</em>(1), 663–678. (<a
href="https://doi.org/10.1007/s11063-020-10270-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Smart Grid (SG) provides the bi-directional flow of data to overcome problems like shortage of electricity, electricity billing, managing fault, home automation so on. For the transfer of data, the integration of Cognitive Radio (CR) in sensor networks makes efficient communication possible in real-time monitoring. SG uses different technologies like WiFi, cellular network, ZigBee, optical cables depending upon the area of application. For effective communication, CR is used to allocate the unutilized spectrum from the Primary User to the Secondary User by sensing. This paper proposes a technique called Fuzzy Long Sort Term Memory based Crow Search Optimization Algorithm (FLSTM–CSOA) to allocate the best available spectrum with minimum delay. By comparing our proposed method with the existing technique, the simulation result shows that the FLSTM–CSOA has better performance in terms of BER (10−1), throughput (200 kbps), and latency (10 ms).},
  archive      = {J_NPL},
  author       = {Sultana, Arifa and Bardalai, Aroop and Sarma, Kandarpa Kumar},
  doi          = {10.1007/s11063-020-10270-3},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {663-678},
  shortjournal = {Neural Process. Lett.},
  title        = {Wireless sensor network based smart grid supported by a cognitively driven load management decision making},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Anti-synchronization of a class of fuzzy memristive
competitive neural networks with different time scales. <em>NPL</em>,
<em>52</em>(1), 647–661. (<a
href="https://doi.org/10.1007/s11063-020-10269-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate a class of fuzzy memristive competitive neural networks with different time scales. Based on Lyapunov functional and differential inclusions, two proper controllers are designed to achieve the anti-synchronization of systems. Some novel results have been obtained for anti-synchronization. Finally, an example is given to illustrate the effectiveness of our main results.},
  archive      = {J_NPL},
  author       = {Ren, Shanshan and Zhao, Yong and Xia, Yonghui},
  doi          = {10.1007/s11063-020-10269-w},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {647-661},
  shortjournal = {Neural Process. Lett.},
  title        = {Anti-synchronization of a class of fuzzy memristive competitive neural networks with different time scales},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). PSSA: Polar coordinate salp swarm algorithm for curve design
problems. <em>NPL</em>, <em>52</em>(1), 615–645. (<a
href="https://doi.org/10.1007/s11063-020-10271-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a modified optimization algorithm called polar coordinate salp swarm algorithm (PSSA). The main inspiration of PSSA is the aggregation chain and foraging trajectory of salp is spiral. Some curves are extremely complex when represented in Cartesian coordinate system, but if they are expressed in polar coordinates, it becomes very simple and easy to handle, and polar coordinates are widely used in scientific computing and engineering issues. It will be more intuitive and convenient if use polar coordinates to define the foraging and aggregation process of salps. At the same time, different from other algorithms proposed in the past, the PSSA directly initialize individuals in polar space instead of using mapping functions to convert to polar coordinates, change the position of particles by updating polar angles and polar diameters. This algorithm is tested on two complex polar coordinate equations, several curve approximation problems and engineering design problems using PSSA. The experimental results illustrated that the proposed PSSA algorithm is superior to the state-of-the-art metaheuristic algorithms in terms of the performance measures.},
  archive      = {J_NPL},
  author       = {Xiang, Zhehong and Zhou, Yongquan and Luo, Qifang and Wen, Chunming},
  doi          = {10.1007/s11063-020-10271-2},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {615-645},
  shortjournal = {Neural Process. Lett.},
  title        = {PSSA: Polar coordinate salp swarm algorithm for curve design problems},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fractional order echo state network for time series
prediction. <em>NPL</em>, <em>52</em>(1), 603–614. (<a
href="https://doi.org/10.1007/s11063-020-10267-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this brief, considering the infinite memory of fractional-order differential equation, a fractional-order echo state network (FESN) is given for time series prediction. For the FESN, the reservoir state differential equation is replaced with fractional-order differential equation. According to the advantages of FESN, the dynamic characteristics of a class of time series can be fully reflected. In order to improve the prediction performance of FESN, a fractional-order output weights learning method and a fractional-order parameter optimization method are given to train the output weights and optimize the reservoir parameters, respectively. Finally, two numerical examples are used to show the effectiveness of FESN.},
  archive      = {J_NPL},
  author       = {Yao, Xianshuang and Wang, Zhanshan},
  doi          = {10.1007/s11063-020-10267-y},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {603-614},
  shortjournal = {Neural Process. Lett.},
  title        = {Fractional order echo state network for time series prediction},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Latent-MVCNN: 3D shape recognition using multiple views from
pre-defined or random viewpoints. <em>NPL</em>, <em>52</em>(1), 581–602.
(<a href="https://doi.org/10.1007/s11063-020-10268-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Multi-view Convolution Neural Network (MVCNN) has achieved considerable success in 3D shape recognition. However, 3D shape recognition using view-images from random viewpoints has not been yet exploited in depth. In addition, 3D shape recognition using a small number of view-images remains difficult. To tackle these challenges, we developed a novel Multi-view Convolution Neural Network, “Latent-MVCNN” (LMVCNN), that recognizes 3D shapes using multiple view-images from pre-defined or random viewpoints. The LMVCNN consists of three types of sub Convolution Neural Networks. For each view-image, the first type of CNN outputs multiple category probability distributions and the second type of CNN outputs a latent vector to help the first type of CNN choose the decent distribution. The third type of CNN outputs the transition probabilities from the category probability distributions of one view to the category probability distributions of another view, which further helps the LMVCNN to find the decent category probability distributions for each pair of view-images. The three CNNs cooperate with each other to the obtain satisfactory classification scores. Our experimental results show that the LMVCNN achieves competitive performance in 3D shape recognition on ModelNet10 and ModelNet40 for both the pre-defined and the random viewpoints and exhibits promising performance when the number of view-images is quite small.},
  archive      = {J_NPL},
  author       = {Yu, Qian and Yang, Chengzhuan and Fan, Honghui and Wei, Hui},
  doi          = {10.1007/s11063-020-10268-x},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {581-602},
  shortjournal = {Neural Process. Lett.},
  title        = {Latent-MVCNN: 3D shape recognition using multiple views from pre-defined or random viewpoints},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptive sampled-data observer design for a class of
nonlinear systems with unknown hysteresis. <em>NPL</em>, <em>52</em>(1),
561–579. (<a href="https://doi.org/10.1007/s11063-020-10275-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel adaptive sampled-data observer design is studied for a class of nonlinear systems with unknown Prandtl–Ishlinskii hysteresis and unknown unmatched disturbances based on radial basis function neural networks (RBFNNs). To begin with, we investigate a sampled-data nonlinear system and present sufficient conditions such that the sampled-data nonlinear system is ultimately uniformly bounded (UUB). Then, an adaptive sampled-data observer is designed to estimate the unknown states of the nonlinear system. The unknown hysteresis and the unknown disturbances are approximated by RBFNNs. We also give the learning laws of the weights of RBFNNs, and prove that the estimation errors of the states and the weights are UUB, based on the obtained sufficient conditions and a special constructing Lyapunov–Krasovskii function. Finally, the effectiveness of the proposed design method is verified by numerical simulations.},
  archive      = {J_NPL},
  author       = {Li, Pengpeng and Shen, Yanjun},
  doi          = {10.1007/s11063-020-10275-y},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {561-579},
  shortjournal = {Neural Process. Lett.},
  title        = {Adaptive sampled-data observer design for a class of nonlinear systems with unknown hysteresis},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Path capsule networks. <em>NPL</em>, <em>52</em>(1),
545–559. (<a href="https://doi.org/10.1007/s11063-020-10273-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Capsule network (CapsNet) was introduced as an enhancement over convolutional neural networks, supplementing the latter’s invariance properties with equivariance through pose estimation. CapsNet achieved a very decent performance with a shallow architecture and a significant reduction in parameters count. However, the width of the first layer in CapsNet is still contributing to a significant number of its parameters and the shallowness may be limiting the representational power of the capsules. To address these limitations, we introduce Path Capsule Network (PathCapsNet), a deep parallel multi-path version of CapsNet. We show that a judicious coordination of depth, max-pooling, regularization by DropCircuit and a new fan-in routing by agreement technique can achieve better or comparable results to CapsNet, while further reducing the parameter count significantly.},
  archive      = {J_NPL},
  author       = {Amer, Mohammed and Maul, Tomás},
  doi          = {10.1007/s11063-020-10273-0},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {545-559},
  shortjournal = {Neural Process. Lett.},
  title        = {Path capsule networks},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Global exponential stability of hybrid non-autonomous neural
networks with markovian switching. <em>NPL</em>, <em>52</em>(1),
525–543. (<a href="https://doi.org/10.1007/s11063-020-10262-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper discusses the global exponential stability for a class of hybrid non-autonomous neural networks (HNNNs) with Markovian switching, which includes the factors of time delays and impulse disturbance. A novel Halanay inequality with cross terms is established by using stochastic analysis technique. Some sufficiency criteria for the global exponential stability of the HNNNs with Markovian switching are derived by the Halanay inequality and some mathematical analysis methods. The results obtained have better fault tolerance and redundancy under certain accuracy than the existing results in the literature. Finally, numerical experiments are provided to illustrate our theoretical results.},
  archive      = {J_NPL},
  author       = {Zhao, Chenhui and Guo, Donghui},
  doi          = {10.1007/s11063-020-10262-3},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {525-543},
  shortjournal = {Neural Process. Lett.},
  title        = {Global exponential stability of hybrid non-autonomous neural networks with markovian switching},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fast and memory-efficient import vector domain description.
<em>NPL</em>, <em>52</em>(1), 511–524. (<a
href="https://doi.org/10.1007/s11063-020-10243-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One-class learning is a classical and hard computational intelligence task. In the literature, there are some effective and powerful solutions to address the problem. There are examples in the kernel machines realm, Support Vector Domain Description, and the recently proposed Import Vector Domain Description (IVDD), which directly delivers the sample probability of belonging to the class. Here, we propose and discuss two optimization techniques for IVDD to significantly improve the memory footprint and consequently to scale to datasets that are larger than the original formulation. We propose two strategies. First, we propose using random features to approximate the gaussian kernel together with a primal optimization algorithm. Second, we propose a Nyström-like approximation of the functional together with a fast converging and accurate self-consistent algorithm. In particular, we replace the a posteriori sparsity of the original optimization method of IVDD by randomly selecting a priori landmark samples in the dataset. We find this second approximation to be superior. Compared to the original IVDD with the RBF kernel, it achieves high accuracy, is much faster, and grants huge memory savings.},
  archive      = {J_NPL},
  author       = {Decherchi, Sergio and Cavalli, Andrea},
  doi          = {10.1007/s11063-020-10243-6},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {511-524},
  shortjournal = {Neural Process. Lett.},
  title        = {Fast and memory-efficient import vector domain description},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fixed-time lag synchronization analysis for delayed
memristor-based neural networks. <em>NPL</em>, <em>52</em>(1), 485–509.
(<a href="https://doi.org/10.1007/s11063-020-10249-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the fixed-time lag synchronization for a general class of memristor-based neural networks (MNNs) with time delays is considered. Under the extended Filippov-framework theory, some sufficient criteria for fixed-time lag synchronization of delayed MNNs are derived based on the Lyapunov function. Besides, two types of controllers are given to ensure the fixed-time lag synchronization of the corresponding system, while the settling time of synchronization are also estimated. Finally, a numerical example is given to demonstrate the effectiveness of the developed method and the theoretical results.},
  archive      = {J_NPL},
  author       = {Haliding, Xiahedan and Jiang, Haijun and Abdurahman, Abdujelil and Hu, Cheng},
  doi          = {10.1007/s11063-020-10249-0},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {485-509},
  shortjournal = {Neural Process. Lett.},
  title        = {Fixed-time lag synchronization analysis for delayed memristor-based neural networks},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Unsupervised domain adaptation via discriminative
classes-center feature learning in adversarial network. <em>NPL</em>,
<em>52</em>(1), 467–483. (<a
href="https://doi.org/10.1007/s11063-020-10266-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial learning has achieved remarkable advance in learning transferable representations across different domains. Generally, previous works are mainly devoted to reducing domain shift between labeled source data and unlabeled target data by extracting domain-invariant features. However, these adversarial methods rarely consider task-specific decision boundaries among classes, causing classification performance degradation in cross domain tasks. In this paper, we propose a novel approach for the task of unsupervised domain adaptation via discriminative classes-center feature learning in adversarial network (C2FAN), which concentrates on learning domain-invariant representation and paying close attention to classification decision boundary simultaneously to improve the ability of transferable knowledge across different domains. C2FAN consists of a feature extractor, a classifier and a discriminator. Firstly, for reducing domain gaps between source and target domains in the feature extractor, we propose to utilize a conditional adversarial learning module to extract domain-invariant feature and improve discriminability of the classifier simultaneously. Further, we present a high-efficiency layer normalization module to reduce domain shift existing in the classifier. Secondly, we design a discriminative classes-center feature learning module in the classifier to diminish the distribution distance of the same-class samples so that the decision boundary can distinguish different classes easily, which can reduce the misclassification on target samples. What’s more, C2FAN is an effective yet considerable simple approach which can be embedded into current domain adaptation approaches conveniently. Extensive experiments demonstrate that our proposed model achieves satisfactory results on some standard domain adaptation benchmarks.},
  archive      = {J_NPL},
  author       = {Chen, Wendong and Hu, Haifeng},
  doi          = {10.1007/s11063-020-10266-z},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {467-483},
  shortjournal = {Neural Process. Lett.},
  title        = {Unsupervised domain adaptation via discriminative classes-center feature learning in adversarial network},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fukunaga–koontz convolutional network with applications on
character classification. <em>NPL</em>, <em>52</em>(1), 443–465. (<a
href="https://doi.org/10.1007/s11063-020-10244-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several convolutional neural network architectures have been proposed for handwritten character recognition. However, most of the conventional architectures demand large scale training data and long training time to obtain satisfactory results. These requirements prevent the use of these methods in a broader range of applications. As an alternative to cope with these problems, we present a new convolutional network for handwritten character recognition based on the Fukunaga–Koontz transform (FKT). Our approach lies in the assumption that Fukunaga–Koontz convolutional kernels can be efficiently learned from subspaces and directly employed to produce high discriminant features in a shallow network architecture. When representing image classes by subspaces, the within-class separability is reduced, since the subspaces form clusters in a low-dimensional space. To increase the between-class separability, we compute a discriminative space from the training subspaces using FKT. By learning convolutional kernels from subspaces, it is possible to extract representative and discriminative features from an image with only a few parameters. Another contribution of the proposed network is the use of pooling layers, which further improves its performance. The proposed method, called Fukunaga–Koontz Network (FKNet), is suitable for solving practical problems, especially when training and processing times are constraints. Four publicly available handwritten character datasets are employed to evaluate the advantages of FKNet. In addition, we demonstrate the flexibility of the proposed method by experiments on LFW dataset.},
  archive      = {J_NPL},
  author       = {Gatto, Bernardo B. and dos Santos, Eulanda M. and Fukui, Kazuhiro and Júnior, Waldir S. S. and dos Santos, Kenny V.},
  doi          = {10.1007/s11063-020-10244-5},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {443-465},
  shortjournal = {Neural Process. Lett.},
  title        = {Fukunaga–Koontz convolutional network with applications on character classification},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An enhanced extreme learning machine based on liu
regression. <em>NPL</em>, <em>52</em>(1), 421–442. (<a
href="https://doi.org/10.1007/s11063-020-10263-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extreme learning machine (ELM) is one of the most remarkable machine learning algorithm in consequence of superior properties particularly its speed. ELM algorithm tends to have some drawbacks like instability and poor generalization performance in the presence of perturbation and multicollinearity. This paper introduces a novel algorithm based on Liu regression estimator (L-ELM) to handle these drawbacks. Different selection approaches have been used to determine the appropriate Liu biasing parameter. The new algorithm is tested against the basic ELM, RR-ELM, AUR-ELM and OP-ELM on nine well-known benchmark data sets. Statistical significance tests have been carried out. Experimental results show that L-ELM for at least one Liu biasing parameter generally outperforms basic ELM, RR-ELM, AUR-ELM and OP-ELM in terms of stability and generalization performance with a little lost of speed. Conversely, the training time of L-ELM is generally much slower than RR-ELM, AUR-ELM and OP-ELM. Consequently, the proposed algorithm can be considered a powerful alternative to avoid the loss of performance in regression studies},
  archive      = {J_NPL},
  author       = {Yıldırım, Hasan and Özkale, M. Revan},
  doi          = {10.1007/s11063-020-10263-2},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {421-442},
  shortjournal = {Neural Process. Lett.},
  title        = {An enhanced extreme learning machine based on liu regression},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Quantized control for synchronization of delayed
fractional-order memristive neural networks. <em>NPL</em>,
<em>52</em>(1), 403–419. (<a
href="https://doi.org/10.1007/s11063-020-10259-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research addresses the synchronization of delayed fractional-order memristive neural networks (DFMNNs) via quantized control. The motivations are twofold: (1) the transmitted information may be constrained by limited bandwidths; (2) the existing analysis techniques are difficult to establish LMI-based synchronization criteria for DFMNNs within a networked control environment. To overcome these difficulties, the logarithmic quantization is adopted to design two types of energy-saving and cost-effective quantized controllers. Then, under the framework of sector bound approach, the closed-loop drive-response DFMNNs can be represented as an interval system with uncertain feedback gains. By utilizing appropriate fractional-order Lyapunov functional and some inequality techniques, two LMI-based synchronization criteria for DFMNNs are derived to establish the relationship between the feedback gain and the quantization parameter. Finally, two illustrative examples are presented to validate the effectiveness of the proposed control schemes.},
  archive      = {J_NPL},
  author       = {Fan, Yingjie and Huang, Xia and Wang, Zhen and Xia, Jianwei and Shen, Hao},
  doi          = {10.1007/s11063-020-10259-y},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {403-419},
  shortjournal = {Neural Process. Lett.},
  title        = {Quantized control for synchronization of delayed fractional-order memristive neural networks},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Spikes and nets (s&amp;n): A new fast, parallel computing,
point process software for multineuronal discharge and connectivity
analysis. <em>NPL</em>, <em>52</em>(1), 385–402. (<a
href="https://doi.org/10.1007/s11063-020-10242-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {S&amp;N is a new multi-platform software for neuronal spike train analysis which offers a comprehensive set of methods to efficiently handle large numbers of neuronal spike train files with a user-friendly interface and automatic results archiving. Selection, grouping, archiving and results matching of point process sequential analysis of neuronal files is a complex and time-consuming task especially for multiple electrode array recordings. Relevant and useful software packages for spike train analysis are already available; however, the aim of this work was to develop an easy to use, fast, short learning curve, multi-platform and parallel computing software able to manage a large number of neuronal spike train files to detect discharge patterns, connectivity, and time-dependent changes. A set of the most used spike train methods to perform single and multi-neuronal discharge pattern recognition and functional connectivity analysis were implemented in an easy-to-use, standalone, Matlab-based software toolbox: spikes and nets (S&amp;N). The methods included for single and multi-neuronal discharge pattern analysis are raster plot, interspike intervals distribution, multiparametric burst, auto-correlation, auto-spectral, fractal, poincaré, and phases. For functional connectivity analysis, cross-correlation and joint interval scatter diagram were implemented. Additionally, time segmentation analysis is available to detect temporal changes for all methods. S&amp;N efficiently handles large numbers of neuronal discharge files at once with fast and automatic archiving of both analytical and graphical results which makes it suitable for multi-electrode array data. S&amp;N applies up to 11 different analytical methods, including automatic file segmentation for time-dependent changes detection, and generates publication quality graphs. The developed toolbox is multi-platform and reads universal spike train files with any temporal resolution, able to process also ECG, EEG or similar data files.},
  archive      = {J_NPL},
  author       = {Valle, Carlos and Rodriguez-Fernandez, Maria and Eblen-Zajjur, Antonio},
  doi          = {10.1007/s11063-020-10242-7},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {385-402},
  shortjournal = {Neural Process. Lett.},
  title        = {Spikes and nets (S&amp;N): A new fast, parallel computing, point process software for multineuronal discharge and connectivity analysis},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Learning stable robust adaptive NARMA controller for UAV and
its application to twin rotor MIMO systems. <em>NPL</em>,
<em>52</em>(1), 353–383. (<a
href="https://doi.org/10.1007/s11063-020-10265-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a nonlinear auto-regressive moving average (NARMA) based online learning controller algorithm providing adaptability, robustness and the closed loop system stability. Both the controller and the plant are identified by the proposed NARMA based input–output models of Wiener and Hammerstein types, respectively. In order to design the NARMA controller, not only the plant but also the closed loop system identification data are obtained from the controlled plant during the online supervised learning mode. The overall closed loop model parameters are determined in suitable parameter regions to provide Schur stability. The identification and controller parameters are calculated by minimizing the $$\varepsilon $$ -insensitive error functions. The proposed controller performances are not only tested on two simulated models such as the quadrotor and twin rotor MIMO system (TRMS) models but also applied to the real TRMS with having severe cross-coupling effect between pitch and yaw. The tracking error performances of the proposed controller are observed better compared to the conventional adaptive and proportional–integral–derivative controllers in terms of the mean squared error, integral squared error and integral absolute error. The most noticeable superiority of the developed NARMA controller over its linear counterpart, namely the adaptive auto-regressive moving average (ARMA) controller, is observed on the TRMS such that the NARMA controller shows a good tracking performance not only for the simulated TRMS model but also the real TRMS. On the other hand, it is seen that the adaptive ARMA is incapable of producing feasible control inputs for the real TRMS whereas it works well for the simulated TRMS model.},
  archive      = {J_NPL},
  author       = {Bulucu, Parvın and Soydemir, Mehmet Uğur and Şahin, Savaş and Kocaoğlu, Aykut and Güzeliş, Cüneyt},
  doi          = {10.1007/s11063-020-10265-0},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {353-383},
  shortjournal = {Neural Process. Lett.},
  title        = {Learning stable robust adaptive NARMA controller for UAV and its application to twin rotor MIMO systems},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Semantic image segmentation with improved position attention
and feature fusion. <em>NPL</em>, <em>52</em>(1), 329–351. (<a
href="https://doi.org/10.1007/s11063-020-10240-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Encoder–decoder structure is an universal method for semantic image segmentation. However, some important information of images will lost with the increasing depth of convolutional neural network (CNN), and the correlation between arbitrary pixels will get worse. This paper designs a novel image segmentation model to obtain dense feature maps and promote segmentation effects. In encoder stage, we employ ResNet-50 to extract features, and then add a spatial pooling pyramid (SPP) to achieve multi-scale feature fusion. In decoder stage, we provide an improved position attention module to integrate contextual information effectively and remove the trivial information through changing the construction way of attention matrix. Furthermore, we also propose the feature fusion structure to generate dense feature maps by preforming element–wise sum operation on the upsampling features and corresponding encoder features. The simulation results illustrate that the average accuracy and mIOU on CamVid dataset can reach 90.7% and 63.1% respectively. It verifies the effectiveness and reliability of the proposed method.},
  archive      = {J_NPL},
  author       = {Zhu, Hegui and Miao, Yan and Zhang, Xiangde},
  doi          = {10.1007/s11063-020-10240-9},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {329-351},
  shortjournal = {Neural Process. Lett.},
  title        = {Semantic image segmentation with improved position attention and feature fusion},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dual-path part-level method for visible–infrared person
re-identification. <em>NPL</em>, <em>52</em>(1), 313–328. (<a
href="https://doi.org/10.1007/s11063-020-10239-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visible–infrared cross-modality person re-identification is a realistic problem of person re-identification. Under poor illumination scenario, general methods of visible–visible person re-identification can not solve the problem well. If we directly compare the visible images of pedestrians captured under dark lighting with the visible images of pedestrians captured under normal light, this extreme color deviation will greatly reduce the recognition ability of the learned representations. In this paper, we propose a dual-path framework for visible–infrared cross-modality person re-identification based human part level features. Feature learning module contains modality-specific dual-path layers and modality-shared human part-level layers, which achieve discriminative global and local representations. In order to better optimize the proposed network, we design a global loss function and a local loss function for the global features and local features, respectively. The two loss functions are integrated together to train the network. We verify the effectiveness of our method on the challenging benchmarks: SYSU-MM01 and RegDB. Experimental results show that, compared with other cross-modality methods, our method has better effect in improving visible–infrared cross-modality person re-identification tasks.},
  archive      = {J_NPL},
  author       = {Xiang, Xuezhi and Lv, Ning and Zhai, Mingliang and Abdeen, Rokia and El Saddik, Abdulmotaleb},
  doi          = {10.1007/s11063-020-10239-2},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {313-328},
  shortjournal = {Neural Process. Lett.},
  title        = {Dual-path part-level method for Visible–Infrared person re-identification},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Finite-time synchronization of hybrid-coupled delayed
dynamic networks via aperiodically intermittent control. <em>NPL</em>,
<em>52</em>(1), 291–311. (<a
href="https://doi.org/10.1007/s11063-020-10245-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate finite-time synchronization for a class of delayed dynamic networks with hybrid coupling via aperiodically intermittent control. First, more general models of dynamic networks with transmission delay and self-feedback delay are given. Second, a lemma with a newly added parameter is proposed to ensure finite-time synchronization of dynamic networks via an aperiodically intermittent control scheme, in which the newly added parameter can make the convergence time shorter. Third, by constructing a novel piecewise Lyapunov function and applying linear matrix inequality technique, some sufficient conditions ensuring finite-time synchronization for delayed dynamic networks are obtained. Moreover, the convergence time is affected by some decision parameters besides the newly added parameter, one of which is a maximum uncontrolled ratio generated by the definition of aperiodic intermittent control itself. Finally, a numerical example is presented to verify its validity and rationality.},
  archive      = {J_NPL},
  author       = {Jing, Taiyan and Zhang, Daoyuan and Jing, Tailong},
  doi          = {10.1007/s11063-020-10245-4},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {291-311},
  shortjournal = {Neural Process. Lett.},
  title        = {Finite-time synchronization of hybrid-coupled delayed dynamic networks via aperiodically intermittent control},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Remerging feigenbaum trees, coexisting behaviors and
bursting oscillations in a novel 3D generalized hopfield neural network.
<em>NPL</em>, <em>52</em>(1), 267–289. (<a
href="https://doi.org/10.1007/s11063-020-10264-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper, a novel 3D generalized Hopfield neural network is proposed and investigated in order to generate and highlight some unknown behaviors related to such type of neural network. This generalized model is constructed by exploiting the effect of an external stimulus on the dynamics of a simplest 3D autonomous Hopfield neural network reported to date. The stability of the model around its ac-equilibrium point is studied. We note that the model has three types of stability depending on the value of the external stimulus. The stable node-focus, the unstable saddle focus, and the stable node characterize the stability of the equilibrium point of the model. Traditional nonlinear analyses tools are used to highlight and support several complex phenomena such as remerging Feigenbaum trees, the coexistence of up to two, four and six disconnected stable states when the amplitude of the external stimulus is set to zero. Furthermore, for some values of the frequency and amplitudes of the external stimulus, bursting oscillations occur. This latter behavior is characterized by the fact that oscillations switch between quiescent states and spiking states, repetitively. The transformed phase portraits are used to support the bursting mode of oscillations found. Finally, PSpice simulations enable to support the results of the theoretical studies.},
  archive      = {J_NPL},
  author       = {Tabekoueng Njitacke, Z. and Laura Matze, C. and Fouodji Tsotsop, M. and Kengne, J.},
  doi          = {10.1007/s11063-020-10264-1},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {267-289},
  shortjournal = {Neural Process. Lett.},
  title        = {Remerging feigenbaum trees, coexisting behaviors and bursting oscillations in a novel 3D generalized hopfield neural network},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). GM-CPSO: A new viewpoint to chaotic particle swarm
optimization via gauss map. <em>NPL</em>, <em>52</em>(1), 241–266. (<a
href="https://doi.org/10.1007/s11063-020-10247-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chaos concept has been appealed in the recent optimization methods to achieve a convenient tradeoff between exploration and exploitation. Different chaotic maps have been considered to find out the appropriate one for the system dynamics. However, on particle swarm optimization (PSO), the usage of these maps has not been handled in an extensive manner, and the best fit one has not known yet. In this paper, ten chaotic maps are handled to reveal the best fit one for PSO, and to explore whether chaotic maps are necessary for PSO or not. Thirteen benchmark functions are used to perform a detailed evaluation at the first experiment. Chaotic PSO (CPSO) methods including different maps are tested on global function optimization. Concerning this, Gauss map based CPSO (GM-CPSO) has come to the forefront by achieving promising fitness values in all function evaluations and in comparison with the state-of-the-art methods. To test the efficiency of GM-CPSO on a different task, GM-CPSO is hybridized with neural network (NN) at the second experiment, and the epileptic seizure recognition is handled. Discrete wavelet transform (DWT) based features, GM-CPSO and NN are considered to design an efficient framework and to specify the type of electroencephalography signals. GM-CPSO-NN is compared with hybrid NNs including two state-of-the-art optimization methods so as to examine the efficiency of GM-CPSO. To accurately test the performances, twofold cross validation is realized on 11,500 instances, and four metrics [accuracy, area under ROC curve (AUC), sensitivity, specificity] are consulted for a detailed assessment beside of computational complexity analysis. In experiments, GM-CPSO including the necessary map, has provided remarkable fitness scores over the state-of-the-art optimization methods on optimization of various functions defined in different dimensions. Besides, the proposed framework including GM-CPSO-NN, has achieved remarkable performance by obtaining reliable accuracy (97.24%), AUC (95.67%), sensitivity (93.04%) and specificity (98.29%) scores, and by including less computational complexity than other algorithms. According to the results, GM-CPSO has arisen as the most convenient optimization method to be preferred in the formation of hybrid NNs. In addition to optimization and classification results, it’s seen that the detail sub-bands of DWT comprise necessary information for seizure recognition. Consequently, it’s revealed that GM-CPSO can be preferred on global function optimization for reliable convergence, and its usage can be extended to different disciplines like signal classification, pattern recognition or hybrid system design.},
  archive      = {J_NPL},
  author       = {Koyuncu, Hasan},
  doi          = {10.1007/s11063-020-10247-2},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {241-266},
  shortjournal = {Neural Process. Lett.},
  title        = {GM-CPSO: A new viewpoint to chaotic particle swarm optimization via gauss map},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal control based on neuro estimator for fractional
order uncertain non-linear continuous-time systems. <em>NPL</em>,
<em>52</em>(1), 221–240. (<a
href="https://doi.org/10.1007/s11063-020-10261-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel method is presented for optimal control of fractional order systems in the presence of an unknown term in system dynamic where fractional order derivative is considered to be between zero and one. In this method, neural network is used to estimate the unknown term in system dynamic. Neural network coefficients are updated adaptively and online. Updating laws are presented considering system requirements to achieve a homogeneous fractional order system. Another problem is formulating optimal control laws for fractional order system which is solved through fractional differential calculus. Since optimal fractional order control is non-causal and does not have a online solution, step-by-step progression and predictive control idea are used to obtain control signal and combine optimal controller and estimator. This method results in an optimal run-time control and resolves unknown terms in system dynamic. In addition, the closed loop system being uniform ultimate bounded is proved through direct Lyapunov method. Finally, simulation results are given to show efficiency of the proposed method.},
  archive      = {J_NPL},
  author       = {Nassajian, Gholamreza and Balochian, Saeed},
  doi          = {10.1007/s11063-020-10261-4},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {221-240},
  shortjournal = {Neural Process. Lett.},
  title        = {Optimal control based on neuro estimator for fractional order uncertain non-linear continuous-time systems},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A context based deep temporal embedding network in action
recognition. <em>NPL</em>, <em>52</em>(1), 187–220. (<a
href="https://doi.org/10.1007/s11063-020-10248-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long term temporal representation methods demand high computational cost, restricting their practical use in real world applications. We propose a two-step deep residual method for efficiently learning long-term discriminative temporal representation, whilst significantly reducing computational cost. In the first step, a novel self-supervision deep temporal embedding method is presented to embed repetitive short-term motions at a cluster-friendly feature space. In the second step, an efficient temporal representation is made by leveraging the differences between the original data and its associated repetitive motion clusters as a novel deep residual method. Experimental results demonstrate that, the proposed method achieves competitive results on some challenging human action recognition datasets like UCF101, HMDB51, THUMOS14, and Kinetics-400.},
  archive      = {J_NPL},
  author       = {Koohzadi, Maryam and Charkari, Nasrollah Moghadam},
  doi          = {10.1007/s11063-020-10248-1},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {187-220},
  shortjournal = {Neural Process. Lett.},
  title        = {A context based deep temporal embedding network in action recognition},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep learning neural network for unconventional images
classification. <em>NPL</em>, <em>52</em>(1), 169–185. (<a
href="https://doi.org/10.1007/s11063-020-10238-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pornographic materials including videos and images are easily in reach for everyone, including under-age youths, allover Internet. It is also an aim for popular social network applications to contain no public pornographic materials. However, their frequent existence throughout all the Internet and huge amount of available images and videos there, make it impossible for manual monitoring to discriminate positive items (porn image or video) from benign images (non-porn image or video). Therefore, automatic detection techniques can be very useful here. But, the traditional machine learning models face many challenges. For example, they need to tune their many parameters, to select the suitable feature set, to select a suitable model. Therefore, this paper proposes an intelligent filtering system model based on a recent convolutional neural networks where it bypasses the aforementioned challenges. We show that the proposed model outperforms the recent machine learning based models. It also outperforms the state of the art deep learning based models.},
  archive      = {J_NPL},
  author       = {Xu, Wei and Parvin, Hamid and Izadparast, Hadi},
  doi          = {10.1007/s11063-020-10238-3},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {169-185},
  shortjournal = {Neural Process. Lett.},
  title        = {Deep learning neural network for unconventional images classification},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Binary output layer of extreme learning machine for solving
multi-class classification problems. <em>NPL</em>, <em>52</em>(1),
153–167. (<a href="https://doi.org/10.1007/s11063-020-10236-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considered in this paper is the design of output layer nodes of extreme learning machine (ELM) for solving multi-class classification problems with r ( $$r\ge 3$$ ) classes of samples. The common and conventional setting of output layer, called “one-to-one approach” in this paper, is as follows: The output layer contains r output nodes corresponding to the r classes. And for an input sample of the ith class ( $$1\le i\le r$$ ), the ideal output is 1 for the ith output node, and 0 for all the other output nodes. We propose in this paper a new “binary approach”: Suppose $$2^{q-1}&lt; r\le 2^q$$ with $$q\ge 2$$ , then we let the output layer contain q output nodes, and let the ideal outputs for the r classes be designed in a binary manner. Numerical experiments carried out in this paper show that our binary approach does equally good job as, but uses less output nodes and hidden-output weights than, the traditional one-to-one approach.},
  archive      = {J_NPL},
  author       = {Yang, Sibo and Zhang, Chao and Bao, Yuan and Yang, Jie and Wu, Wei},
  doi          = {10.1007/s11063-020-10236-5},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {153-167},
  shortjournal = {Neural Process. Lett.},
  title        = {Binary output layer of extreme learning machine for solving multi-class classification problems},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Time series, spectral densities and robust functional
clustering. <em>NPL</em>, <em>52</em>(1), 135–152. (<a
href="https://doi.org/10.1007/s11063-018-9926-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, a robust clustering algorithm for stationary time series is proposed. The algorithm is based on the use of estimated spectral densities, which are considered as functional data, as the basic characteristic of stationary time series for clustering purposes. A robust algorithm for functional data is then applied to the set of spectral densities. Trimming techniques and restrictions on the scatter within groups reduce the effect of noise in the data and help to prevent the identification of spurious clusters. The procedure is tested in a simulation study and is also applied to a real data set.},
  archive      = {J_NPL},
  author       = {Rivera-García, D. and García-Escudero, L. A. and Mayo-Iscar, A. and Ortega, J.},
  doi          = {10.1007/s11063-018-9926-1},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {135-152},
  shortjournal = {Neural Process. Lett.},
  title        = {Time series, spectral densities and robust functional clustering},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An evaluation of equity premium prediction using multiple
kernel learning with financial features. <em>NPL</em>, <em>52</em>(1),
117–134. (<a href="https://doi.org/10.1007/s11063-018-09971-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces and extensively explores a forecasting procedure based on multivariate dynamic kernels to re-examine—under a non-linear, kernel methods framework—the experimental tests reported by Welch and Goyal (Rev Financ Stud 21(4):1455–1508, 2008) showing that several variables proposed in the finance literature are of no use as exogenous information to predict the equity premium under linear regressions. For this new approach to equity premium forecasting, kernel functions for time series are used with multiple kernel learning (MKL) in order to represent the relative importance of each of the variables. We find that, in general, the predictive capabilities of the MKL models do not improve consistently with the use of some or all of the variables, nor does the predictability by single kernels, as determined by different resampling procedures that we implement and compare. This fact tends to corroborate the instability already observed by Welch and Goyal for the predictive power of exogenous variables, now in a non-linear modelling framework.},
  archive      = {J_NPL},
  author       = {Arratia, Argimiro and Belanche, Lluís A. and Fábregues, Luis},
  doi          = {10.1007/s11063-018-09971-7},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {117-134},
  shortjournal = {Neural Process. Lett.},
  title        = {An evaluation of equity premium prediction using multiple kernel learning with financial features},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Machine learning nowcasting of PV energy using satellite
data. <em>NPL</em>, <em>52</em>(1), 97–115. (<a
href="https://doi.org/10.1007/s11063-018-09969-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Satellite-measured radiances are obviously of great interest for photovoltaic (PV) energy prediction. In this work we will use them together with clear sky irradiance estimates for the nowcasting of PV energy productions over peninsular Spain. We will feed them directly into two linear Machine Learning models, Lasso and linear Support Vector Regression (SVR), and two highly non-linear ones, Deep Neural Networks (in particular, Multilayer Perceptrons, MLPs) and Gaussian SVRs. We shall also use a simple clear sky-based persistence model for benchmarking purposes. We consider prediction horizons of up to 6 h, with Gaussian SVR being statistically better than the other models at each horizon, since its errors increase slowly with time (with an average of 1.92% for the first three horizons and of 2.89% for the last three). MLPs performance is close to that of the Gaussian SVR for the longer horizons (with an average of 3.1%) but less so at the initial ones (average of 2.26%), being nevertheless significantly better than the linear models. As it could be expected, linear models give weaker results (in the initial horizons, Lasso and linear SVR have already an error of 3.21% and 3.46%, respectively), but we will take advantage of the spatial sparsity provided by Lasso to try to identify the concrete areas with a larger influence on PV energy nowcasts.},
  archive      = {J_NPL},
  author       = {Catalina, Alejandro and Torres-Barrán, Alberto and Alaíz, Carlos M. and Dorronsoro, José R.},
  doi          = {10.1007/s11063-018-09969-1},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {97-115},
  shortjournal = {Neural Process. Lett.},
  title        = {Machine learning nowcasting of PV energy using satellite data},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A multi-resolution approximation for time series.
<em>NPL</em>, <em>52</em>(1), 75–96. (<a
href="https://doi.org/10.1007/s11063-018-9929-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series is a common and well-known way for describing temporal data. However, most of the state-of-the-art techniques for analysing time series have focused on generating a representation for a single level of resolution. For analysing of a time series at several levels of resolutions, one would require to compute different representations, one for each resolution level. We introduce a multi-resolution representation for time series based on local trends and mean values. We require the level of resolution as parameter, but it can be automatically computed if we consider the maximum resolution of the time series. Our technique represents a time series using trend-value pairs on each segment belonging to a resolution level. To provide a useful representation for data mining tasks, we also propose dissimilarity measures and a symbolic representation based on the SAX technique for efficient similarity search using a multi-resolution indexing scheme. We evaluate our method for classification and discord discovery tasks over a diversity of data domains, achieving a better performance in terms of efficiency and effectiveness compared with some of the best-known classic techniques. Indeed, for some of the experiments, the time series mining algorithms using our multi-resolution representation were an order of magnitude faster, in terms of distance computations, than the state of the art.},
  archive      = {J_NPL},
  author       = {Sanchez, Heider and Bustos, Benjamin},
  doi          = {10.1007/s11063-018-9929-y},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {75-96},
  shortjournal = {Neural Process. Lett.},
  title        = {A multi-resolution approximation for time series},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Ordinal multi-class architecture for predicting wind power
ramp events based on reservoir computing. <em>NPL</em>, <em>52</em>(1),
57–74. (<a href="https://doi.org/10.1007/s11063-018-9922-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wind power ramp events (WPREs) are strong increases or decreases of wind speed in a short period of time. Predicting WPREs in wind farms is of vital importance given that they can produce damages in the turbines, and, in any case, they suddenly affect the wind farm production. In contrast to previous binary definitions of the prediction problem (ramp vs non-ramp), a three-class prediction model is used in this paper, proposing a novel discretization function, able to detect the nature of WPREs: negative ramp, non-ramp and positive ramp events. Moreover, the natural order of these labels is exploited to obtain better results in the prediction of these events. The independent variables used for prediction include, in this case, past wind speed values and meteorological data obtained from physical models (reanalysis data). Reanalysis will be also used for recovering missing data from the measuring stations in the wind farm. The proposed prediction methodology is based on Reservoir Computing and an over-sampling process for alleviating the high degree of unbalance in the dataset (non-ramp events are much more frequent than ramps). Three elements are combined in the prediction method: a recurrent neural network layer, a nonlinear kernel mapping and an ordinal logistic regression,to exploit the information provided by the order of the classes). Preprocessing is based on a variation of the standard synthetic minority over-sampling technique, which is applied to the reservoir activations (since the direct application over the input variables would damage its temporal structure). The performance of the method is analysed by comparing it against other state-of-the-art classifiers, such as Support Vector Machines, nominal logistic regression, an autoregressive ordinal neural network, or the use of leaky integrator neurons instead of the standard sigmoidal units. From the results obtained, the benefits of the kernel mapping and the ordinal model are clear, and, in general, the performance obtained with the Reservoir Computing approach is shown to be very robust in the detection of ramps.},
  archive      = {J_NPL},
  author       = {Dorado-Moreno, M. and Gutiérrez, P. A. and Cornejo-Bueno, L. and Prieto, L. and Salcedo-Sanz, S. and Hervás-Martínez, C.},
  doi          = {10.1007/s11063-018-9922-5},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {57-74},
  shortjournal = {Neural Process. Lett.},
  title        = {Ordinal multi-class architecture for predicting wind power ramp events based on reservoir computing},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fuzzy time series models using pliant- and asymptotically
pliant arithmetic-based inference. <em>NPL</em>, <em>52</em>(1), 21–55.
(<a href="https://doi.org/10.1007/s11063-018-9927-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fuzzy time series modeling techniques proposed in this study are based on a fuzzy inference method in which the fuzzy output is either a so-called pliant or quasi pliant (q-pliant) number. The novelty of the introduced inference method lies in the fact that its fuzzy output is obtained by fuzzy arithmetic operations; namely, via weighted aggregation of pliant numbers or q-pliant numbers, which are the consequents of the fuzzy rules. These fuzzy inference systems are called the pliant arithmetic-based fuzzy inference system (PAFIS) and the quasi pliant arithmetic-based fuzzy inference system (QPAFIS). The advantage of the defuzzification methods of these two systems is twofold. On the one hand, they do not require any numerical integration to generate the crisp output, on the other hand, they run in a constant time. Here, it is discussed how the pliant arithmetic-based fuzzy time series and the quasi pliant arithmetic-based fuzzy time series models can be established by utilizing the PAFIS and QPAFIS methods. Lastly, the modeling capabilities of the introduced methods are also examined on some real-life time series, and the forecasting results are compared with those of some well-known and recent time series forecasting methods. Based on the experimental results, our methods may be viewed as novel viable time series modeling techniques.},
  archive      = {J_NPL},
  author       = {Dombi, József and Jónás, Tamás and Tóth, Zsuzsanna E.},
  doi          = {10.1007/s11063-018-9927-0},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {21-55},
  shortjournal = {Neural Process. Lett.},
  title        = {Fuzzy time series models using pliant- and asymptotically pliant arithmetic-based inference},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Application of quantile graphs to the automated analysis of
EEG signals. <em>NPL</em>, <em>52</em>(1), 5–20. (<a
href="https://doi.org/10.1007/s11063-018-9936-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epilepsy is classified as a chronic neurological disorder of the brain and affects approximately 2% of the world population. This disorder leads to a reduction in people’s productivity and imposes restrictions on their daily lives. Studies of epilepsy often rely on electroencephalogram (EEG) signals to provide information on the behavior of the brain during seizures. Recently, a map from a time series to a network has been proposed and that is based on the concept of transition probabilities; the series results in a so-called “quantile graph” (QG). Here, this map, which is also called the QG method, is applied for the automatic detection of normal, pre-ictal (preceding a seizure), and ictal (occurring during a seizure) conditions from recorded EEG signals. Our main goal is to illustrate how the differences in dynamics in the EEG signals are reflected in the topology of the corresponding QGs. Based on various network metrics, namely, the clustering coefficient, the shortest path length, the mean jump length, the modularity and the betweenness centrality, our results show that the QG method is able to detect differences in dynamical properties of brain electrical activity from different extracranial and intracranial recording regions and from different physiological and pathological brain states.},
  archive      = {J_NPL},
  author       = {Campanharo, Andriana S. L. O. and Doescher, Erwin and Ramos, Fernando M.},
  doi          = {10.1007/s11063-018-9936-z},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {5-20},
  shortjournal = {Neural Process. Lett.},
  title        = {Application of quantile graphs to the automated analysis of EEG signals},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Computational intelligence methods for time series analysis
and forecasting: Special issue of IWANN 2017. <em>NPL</em>,
<em>52</em>(1), 1–4. (<a
href="https://doi.org/10.1007/s11063-020-10302-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NPL},
  author       = {Valenzuela, Olga and Rojas, Fernando and Rojas, Ignacio},
  doi          = {10.1007/s11063-020-10302-y},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {1},
  pages        = {1-4},
  shortjournal = {Neural Process. Lett.},
  title        = {Computational intelligence methods for time series analysis and forecasting: Special issue of IWANN 2017},
  volume       = {52},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A human auditory perception loss function using modified
bark spectral distortion for speech enhancement. <em>NPL</em>,
<em>51</em>(3), 2945–2957. (<a
href="https://doi.org/10.1007/s11063-020-10212-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human listeners often have difficulties understanding speech in the presence of background noise in daily speech communication environments. Recently, deep neural network (DNN)-based techniques have been successfully applied to speech enhancement and achieved significant improvements over the conventional approaches. However, existing DNN-based methods usually minimize the log-power spectral-based or the masking-based mean squared error (MSE) between the enhanced output and the training target (e.g., the ideal ratio mask (IRM) of the clean speech), which is not closely related to human auditory perception. In this letter, a modified bark spectral distortion loss function, which can be considered as an auditory perception-based MSE, is proposed to replace the conventional MSE in DNN-based speech enhancement approaches to further improve the objective perceptual quality. Experimental results reveal that the proposed method can obtain improved speech enhancement performance, especially in terms of objective perceptual quality in all experimental settings when compared with the DNN-based methods using the conventional MSE criterion.},
  archive      = {J_NPL},
  author       = {Shu, Xiaofeng and Zhou, Yi and Liu, Hongqing and Truong, Trieu-Kien},
  doi          = {10.1007/s11063-020-10212-z},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2945-2957},
  shortjournal = {Neural Process. Lett.},
  title        = {A human auditory perception loss function using modified bark spectral distortion for speech enhancement},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Passivity analysis of non-autonomous discrete-time inertial
neural networks with time-varying delays. <em>NPL</em>, <em>51</em>(3),
2929–2944. (<a
href="https://doi.org/10.1007/s11063-020-10235-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the passivity problem for delayed non-autonomous discrete-time inertial neural networks (NDINN), including the discrete-time switched inertial neural networks (DSINN) with state-dependent discontinuous right-hand side as its special case. First, we take a linear transformation to transform the original network into first-order difference equations. Second, by utilizing the Lyapunov direct method and with the help of the property of maximum singular value, we present a passivity criterion for the NDINN with delay-dependent linear matrix inequalities. Combining with the characteristic function method, the proposed analytical approach for NDINN is further extended to the DSINN. Finally, two simulation examples validate the efficacy of the analytical results.},
  archive      = {J_NPL},
  author       = {Chen, Xuan and Lin, Dongyun},
  doi          = {10.1007/s11063-020-10235-6},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2929-2944},
  shortjournal = {Neural Process. Lett.},
  title        = {Passivity analysis of non-autonomous discrete-time inertial neural networks with time-varying delays},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Md-net: Multi-scale dilated convolution network for CT
images segmentation. <em>NPL</em>, <em>51</em>(3), 2915–2927. (<a
href="https://doi.org/10.1007/s11063-020-10230-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate CT image segmentation is of great importance to the clinical diagnosis. Due to the high similarity of gray values in CT image, the segmented areas are easily affected by their surroundings, which leads to the loss of semantic information. In this paper, we propose a multi-scale dilated convolution network (Md-Net) for CT image segmentation with superior segmentation performance compared with state-of-the-art methods. Specifically, our Md-Net utilizes the dilated convolutions with different sizes to form feature pyramids for extracting the semantic information. Moreover, we use a weighted Diceloss to accelerate the convergence in training process. Meanwhile, the bilinear interpolation and multiple convolutions are taken to reduce the computational cost. Experiment results show that our proposed Md-Net outperforms the representative medical image segmentation methods, including Unet, Unet++, MaskRcnn and CE-Net, in terms of sensitivity, accuracy and area under curve both on lung dataset and Bladder dataset.},
  archive      = {J_NPL},
  author       = {Xia, Haiying and Sun, Weifan and Song, Shuxiang and Mou, Xiangwei},
  doi          = {10.1007/s11063-020-10230-x},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2915-2927},
  shortjournal = {Neural Process. Lett.},
  title        = {Md-net: Multi-scale dilated convolution network for CT images segmentation},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Legendre neural network method for several classes of
singularly perturbed differential equations based on mapping and
piecewise optimization technology. <em>NPL</em>, <em>51</em>(3),
2891–2913. (<a
href="https://doi.org/10.1007/s11063-020-10232-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we develop a novel neural network model with mapping and piecewise optimization technology for several classes of the linear singularly perturbed initial value and boundary value differential equations with variable coefficients. First, the Legendre polynomials are selected as the activation function of the artificial neural network, the mapping technology is employed to transform the original uniform partition points and the piecewise optimization technology is used to improve the calculation accuracy. Then, the solution of the linear singularly perturbed differential equations is solved by using the extreme learning machine optimization algorithm. Finally, the numerical experiments show that the developed method can effectively improve the accuracy of the calculation.},
  archive      = {J_NPL},
  author       = {Liu, Hongliang and Xing, Baixue and Wang, Zhen and Li, Lijuan},
  doi          = {10.1007/s11063-020-10232-9},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2891-2913},
  shortjournal = {Neural Process. Lett.},
  title        = {Legendre neural network method for several classes of singularly perturbed differential equations based on mapping and piecewise optimization technology},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Electrical resistivity inversion based on a hybrid
CCSFLA-MSVR method. <em>NPL</em>, <em>51</em>(3), 2871–2890. (<a
href="https://doi.org/10.1007/s11063-020-10229-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {2D electrical resistivity inversion is a complicated nonlinear optimization problem, which is high-dimensional and non-convex. Using traditional neural networks to solve resistivity inversion problem is cost effective but suffers from trapping in local minima. In order to solve the above problem, a multi-output support vector regression (MSVR) nonlinear inversion method with limited ERI learning samples is researched in this paper, which considers the combined fitting errors of all outputs. Moreover, a Cauchy random and chaotic oscillation shuffled frog leaping algorithm is applied to optimize the RBF kernel widths and penalty coefficients of MSVR for improving the inversion accuracy and the computational efficiency. The key issues of data sets generation, data preprocessing and inversion flowchart are analyzed. The experimental results based on the synthetic and field examples demonstrated that the proposed algorithm is accurate, efficient and can be applied in practical engineering applications.},
  archive      = {J_NPL},
  author       = {Jiang, Feibo and Dong, Li and Dai, Qianwei},
  doi          = {10.1007/s11063-020-10229-4},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2871-2890},
  shortjournal = {Neural Process. Lett.},
  title        = {Electrical resistivity inversion based on a hybrid CCSFLA-MSVR method},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimizing deep feedforward neural network architecture: A
tabu search based approach. <em>NPL</em>, <em>51</em>(3), 2855–2870. (<a
href="https://doi.org/10.1007/s11063-020-10234-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optimal architecture of a deep feedforward neural network (DFNN) is essential for its better accuracy and faster convergence. Also, the training of DFNN becomes tedious as the depth of the network increases. The DFNN can be tweaked using several parameters, such as the number of hidden layers, the number of hidden neurons at each hidden layer, and the number of connections between layers. The optimal architecture of DFNN is usually set using a trial-and-error process, which is an exponential combinatorial problem and a tedious task. To address this problem, we need an algorithm that can automatically design an optimal architecture with improved generalization ability. This work aims to propose a new methodology that can simultaneously optimize the number of hidden layers and their respective neurons for DFNN. This work combines the advantages of Tabu search and Gradient descent with a momentum backpropagation training algorithm. The proposed approach has been tested on four different classification benchmark datasets, which show better generalization ability of the optimized networks.},
  archive      = {J_NPL},
  author       = {Gupta, Tarun Kumar and Raza, Khalid},
  doi          = {10.1007/s11063-020-10234-7},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2855-2870},
  shortjournal = {Neural Process. Lett.},
  title        = {Optimizing deep feedforward neural network architecture: A tabu search based approach},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep convolutional generalized classifier neural network.
<em>NPL</em>, <em>51</em>(3), 2839–2854. (<a
href="https://doi.org/10.1007/s11063-020-10233-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Up to date technological implementations of deep convolutional neural networks are at the forefront of many issues, such as autonomous device control, effective image and pattern recognition solutions. Deep neural networks generally utilize a hybrid topology of a feature extractor containing convolutional layers followed by a fully connected classifier network. The characteristic and quality of the produced features differ according to the deep learning structure. In order to get high performance, it is necessary to choose an effective topology. In this study, a novel topology based hybrid structure named as Deep Convolutional Generalized Classifier Neural Network and its learning algoritm are introduced. This novel structure allows the deep learning network to extract features with the desired characteristics. This ensures high performance classification, even for relatively small deep learning networks. This has led to many novelties such as principal feature analysis, better learning ability, one-pass learning for classifier part, new error computation and backpropagation approach for filter weights. Two experiment sets were performed to measure the performance of DC-GCNN. In the first experiment set, DC-GCNN was compared with clasical approach on 10 different datasets. DC-GCNN performed better up to 44.45% for precision, 39.69% for recall and 42.57% for F1-score. In the second experiment set, DC-GCNN’s performance was compared with alternative methods on larger datasets. Proposed structure performed better than alternative deep learning based classifier structures on CIFAR-10 and MNIST datasets with 89.12% and 99.28% accuracy values.},
  archive      = {J_NPL},
  author       = {Sarigul, Mehmet and Ozyildirim, B. Melis and Avci, Mutlu},
  doi          = {10.1007/s11063-020-10233-8},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2839-2854},
  shortjournal = {Neural Process. Lett.},
  title        = {Deep convolutional generalized classifier neural network},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep learning based application for indoor scene
recognition. <em>NPL</em>, <em>51</em>(3), 2827–2837. (<a
href="https://doi.org/10.1007/s11063-020-10231-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recognizing indoor scene and objects and estimating their poses present a wide range of applications in robotic field. This task becomes more challenging especially in cluttered environments like the indoor scenery. Scaling up convnets presents a key component in achieving better accuracy results of deep convolutional neural networks. In this paper, we make use of the rethinked efficient neural networks and we fine-tune them in order to develop a new application used for indoor object and scene recognition system. This new application will be especially dedicated for blind and visually impaired persons to explore new indoor environments and to fully integrate in daily life. The proposed indoor object and scene recognition system achieves new state-of-the-art results in MIT 67 indoor dataset and in scene 15 dataset. We obtained 95.60% and 97% respectively as a recognition rate.},
  archive      = {J_NPL},
  author       = {Afif, Mouna and Ayachi, Riadh and Said, Yahia and Atri, Mohamed},
  doi          = {10.1007/s11063-020-10231-w},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2827-2837},
  shortjournal = {Neural Process. Lett.},
  title        = {Deep learning based application for indoor scene recognition},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A metaphor comprehension method based on culture-related
hierarchical semantic model. <em>NPL</em>, <em>51</em>(3), 2807–2826.
(<a href="https://doi.org/10.1007/s11063-020-10227-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Usually a metaphor is encoded with rich cultural connotation, which signifies that culture plays a key factor in truly comprehending a metaphorically-used utterance. Given that, we developed a culture-related hierarchical semantic model to perform metaphor comprehension. Based on the character of a metaphor, to better represent context and background knowledge, we embedded word-level, attribute-level, perception-level, and context-level information into the model. Moreover, in the attribute-level, a culture mapping is developed to better use cultural information. We use a random walk algorithm to search for the most reasonable comprehension results. The model was tested in a nominal Chinese metaphor corpus. The results show the effectiveness of the model and demonstrate its advantages in understanding cultural metaphors.},
  archive      = {J_NPL},
  author       = {Su, Chang and Peng, Ying and Huang, Shuman and Chen, Yijiang},
  doi          = {10.1007/s11063-020-10227-6},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2807-2826},
  shortjournal = {Neural Process. Lett.},
  title        = {A metaphor comprehension method based on culture-related hierarchical semantic model},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A balanced feature fusion SSD for object detection.
<em>NPL</em>, <em>51</em>(3), 2789–2806. (<a
href="https://doi.org/10.1007/s11063-020-10228-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single shot multibox detector (SSD) takes several feature layers for object detection, but each layer is used independently. This structure may ignore some context information and is not conducive to improving the detection accuracy of small objects. Moreover, the imbalances of samples and multi-tasks during SSD training process can lead to inefficient training and model degradation. In order to improve the performance of SSD, this paper proposes a balanced feature fusion SSD (BFSSD) algorithm. Firstly, a feature fusion module is proposed to fuse and refine different layers of the feature pyramid. Then, a more balanced L1 loss function is proposed to further solve these imbalances. Finally, our model is trained with Pascal VOC2007 and VOC2012 trainval datasets and tested on Pascal VOC2007 test datasets. Simulation results show that, for the input size of 300 × 300, BFSSD exceeds the best results provided by the conventional SSD and other advanced object detection algorithms.},
  archive      = {J_NPL},
  author       = {Zhao, Hui and Li, Zhiwei and Fang, Lufa and Zhang, Tianqi},
  doi          = {10.1007/s11063-020-10228-5},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2789-2806},
  shortjournal = {Neural Process. Lett.},
  title        = {A balanced feature fusion SSD for object detection},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dual global structure preservation based supervised feature
selection. <em>NPL</em>, <em>51</em>(3), 2765–2787. (<a
href="https://doi.org/10.1007/s11063-020-10225-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent literature indicates that the global structure preservation is very important for sparse representation based supervised feature selection. However, the selected features in preserving different global structures are often different and which global structure is the best not yet known. As a result, which feature selection result we should trust is confusing. The reason may be that each global structure does not carry enough information for the data, as the distribution of a real life data is very complex. To overcome the above problem, in this paper, a dual global structure preservation based supervised feature selection (DGSPSFS) method is proposed. In DGSPSFS, the supervised dimensional reduction method based on manifold learning is used to calculate the response matrix, which can contain more information of the data. And a new sparse representation framework that can preserve two global structures in the same time is proposed, which can comprehensively use two response matrices to fully utilize the information of the data. As a result, the features that can carry more information are selected. A comprehensive experimental study is then conducted in order to compare our feature selection algorithms with many state-of-the art ones in supervised learning scenarios. The conducted experiments validate the effectiveness of our feature selection.},
  archive      = {J_NPL},
  author       = {Ye, Qing and Zhang, Xiaolong and Sun, Yaxin},
  doi          = {10.1007/s11063-020-10225-8},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2765-2787},
  shortjournal = {Neural Process. Lett.},
  title        = {Dual global structure preservation based supervised feature selection},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Task-independent spiking central pattern generator: A
learning-based approach. <em>NPL</em>, <em>51</em>(3), 2751–2764. (<a
href="https://doi.org/10.1007/s11063-020-10224-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Legged locomotion is a challenging task in the field of robotics but a rather simple one in nature. This motivates the use of biological methodologies as solutions to this problem. Central pattern generators are neural networks that are thought to be responsible for locomotion in humans and some animal species. As for robotics, many attempts were made to reproduce such systems and use them for a similar goal. One interesting design model is based on spiking neural networks. This model is the main focus of this work, as its contribution is not limited to engineering but also applicable to neuroscience. This paper introduces a new general framework for building central pattern generators that are task-independent, biologically plausible, and rely on learning methods. The abilities and properties of the presented approach are not only evaluated in simulation but also in a robotic experiment. The results are very promising as the used robot was able to perform stable walking at different speeds and to change speed within the same gait cycle.},
  archive      = {J_NPL},
  author       = {Aljalbout, Elie and Walter, Florian and Röhrbein, Florian and Knoll, Alois},
  doi          = {10.1007/s11063-020-10224-9},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2751-2764},
  shortjournal = {Neural Process. Lett.},
  title        = {Task-independent spiking central pattern generator: A learning-based approach},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). RSDCN: A road semantic guided sparse depth completion
network. <em>NPL</em>, <em>51</em>(3), 2737–2749. (<a
href="https://doi.org/10.1007/s11063-020-10226-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Laser radar (Lidar) plays an indispensable role in lots of security critical applications such as autonomous driving. However, the high sparsity and non-uniformity nature of the raw laser data brings large difficulties to reliable 3D scene understanding. Traditional depth completion methods suffer from the highly ill-conditioned nature of the problem. A novel end-to-end road semantic guided depth completion neural network with a special designed Asymmetric Multiscale Convolution (AMC) structure is proposed in this paper. The whole network is composed of two parts: semantic part and depth completion part. The semantic part is constructed by an image-Lidar joint segmentation sub-network which produces semantic masks (ground or object) to the following network. The depth completion part is composed of a series of AMC convolution structure. By combining the semantic masks and treating the ground and non-ground objects separately, the proposed AMC structure can well fit the depth distribution pattern implied in road scene. The experiments carried on both synthesized and real datasets demonstrate that our method can effectively improve the accuracy of depth completion results.},
  archive      = {J_NPL},
  author       = {Zou, Nan and Xiang, Zhiyu and Chen, Yiman},
  doi          = {10.1007/s11063-020-10226-7},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2737-2749},
  shortjournal = {Neural Process. Lett.},
  title        = {RSDCN: A road semantic guided sparse depth completion network},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Intuitionistic fuzzy proximal support vector machines for
pattern classification. <em>NPL</em>, <em>51</em>(3), 2701–2735. (<a
href="https://doi.org/10.1007/s11063-020-10222-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Support vector machine is a powerful technique for classification and regression problems. In the binary data problems, it classifies the points by assigning them to one of the two disjoint halfspaces. However, this method fails to handle the noises and outliers present in the dataset and the solution of a large-sized quadratic programming problem is required to obtain the decision surface in input or in feature space. We propose the intuitionistic fuzzy proximal support vector machine (IFPSVM) which classifies the patterns according to its proximity with the two parallel planes that are kept as distant as possible from each other. These two parallel ‘proximal’ planes can be obtained by solving a system of linear equations only. There is an intuitionistic fuzzy number associated with each training point which is framed by its degree of membership and non-membership. The membership degree of a pattern considers its distance from the corresponding class center and the degree of non-membership of a pattern is given by the ratio of the number of heterogeneous points to the number of total points in its neighborhood. The proposed technique effectively reduces the impact of noises and distinguishes the edge support vectors and outliers. Computational simulations on an artificial and eleven UCI benchmark datasets using linear, polynomial and Gaussian kernel functions, show the effectiveness of the proposed IFPSVM method. The experiments prove that it can handle large datasets with less computational time and yields better accuracy.},
  archive      = {J_NPL},
  author       = {Laxmi, Scindhiya and Gupta, Shiv Kumar},
  doi          = {10.1007/s11063-020-10222-x},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2701-2735},
  shortjournal = {Neural Process. Lett.},
  title        = {Intuitionistic fuzzy proximal support vector machines for pattern classification},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Impulsive-interaction-driven synchronization in an array of
coupled neural networks. <em>NPL</em>, <em>51</em>(3), 2685–2700. (<a
href="https://doi.org/10.1007/s11063-020-10214-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with the problem of globally exponential synchronization and bipartite synchronization of coupled neural networks with impulsive interactions. Impulsive interaction means that a number of neural networks only communicate with each other at impulsive instants, while the array of neural networks are independent from each other at the remaining time. The advantage of the scheme is that communication cost can be largely reduced when only discrete communication is required. Moreover the communication links between nodes can be either positive or negative at impulsive instants. Using the Lyapunov method combined with some mathematical analysis and average impulsive interval, some efficient criteria are obtained to guarantee synchronization of impulsive coupled neural networks. Finally, the validity of our theoretical results is demonstrated by two numerical examples.},
  archive      = {J_NPL},
  author       = {Wang, Nan and Li, Xuechen and Lu, Jianquan},
  doi          = {10.1007/s11063-020-10214-x},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2685-2700},
  shortjournal = {Neural Process. Lett.},
  title        = {Impulsive-interaction-driven synchronization in an array of coupled neural networks},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Gaussian pyramid of conditional generative adversarial
network for real-world noisy image denoising. <em>NPL</em>,
<em>51</em>(3), 2669–2684. (<a
href="https://doi.org/10.1007/s11063-020-10215-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image denoising is an essential and important pre-processing step in digital imaging systems. However, most of existing methods are not adaptive in real-world applications due to the complexity of real noise. To address this problem, a novel pyramidal generative structural network (PGSN) is proposed for robust and efficient real-world noisy image denoising. Specifically, we consider the denoising problem as a process of image generation. The procedure is to first build a Gaussian pyramid where a cascade of encoder-decoder networks are used to adaptively capture multi-scale image features and progressively reconstruct the corresponding noise-free image from coarse to fine granularity. Then, we train a conditional form of GAN at each pyramid level. By integrating the conditional GAN approach into the Gaussian pyramid, the proposed network can well combine the image features from different pyramid levels, and an incremental distinction between the real noise and image details is dynamically built up, hence greatly boosting the denoising performance. Extensive experimental results demonstrate that our PGSN gives satisfactory denoising results, and achieves superior performance against the state-of-the-arts.},
  archive      = {J_NPL},
  author       = {Ma, Ruijun and Zhang, Bob and Hu, Haifeng},
  doi          = {10.1007/s11063-020-10215-w},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2669-2684},
  shortjournal = {Neural Process. Lett.},
  title        = {Gaussian pyramid of conditional generative adversarial network for real-world noisy image denoising},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stacked fusion supervised auto-encoder with an additional
classification layer. <em>NPL</em>, <em>51</em>(3), 2649–2667. (<a
href="https://doi.org/10.1007/s11063-020-10223-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Auto-encoders are unsupervised deep learning models, which try to learn hidden representations to reconstruct the inputs. While the learned representations are suitable for applications related to unsupervised reconstruction, they may not be optimal for classification. In this paper, we propose a supervised auto-encoder (SupAE) with an addition classification layer on the representation layer to jointly predict targets and reconstruct inputs, so it can learn discriminative features specifically for classification tasks. We stack several SupAE and apply a greedy layer-by-layer training approach to learn the stacked supervised auto-encoder (SSupAE). Then an adaptive weighted majority voting algorithm is proposed to fuse the prediction results of SupAE and the SSupAE, because each individual SupAE and the final SSupAE can both get the posterior probability information of samples belong to each class, we introduce Shannon entropy to measure the classification ability for different samples based on the posterior probability information, and assign high weight to sample with low entropy, thus more reasonable weights are assigned to different samples adaptively. Finally, we fuse the different results of classification layer with the proposed adaptive weighted majority voting algorithm to get the final recognition results. Experimental results on several classification datasets show that our model can learn discriminative features and improve the classification performance significantly.},
  archive      = {J_NPL},
  author       = {Li, Rui and Wang, Xiaodan and Quan, Wen and Lei, Lei},
  doi          = {10.1007/s11063-020-10223-w},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2649-2667},
  shortjournal = {Neural Process. Lett.},
  title        = {Stacked fusion supervised auto-encoder with an additional classification layer},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Regularized negative label relaxation least squares
regression for face recognition. <em>NPL</em>, <em>51</em>(3),
2629–2647. (<a
href="https://doi.org/10.1007/s11063-020-10219-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Least squares regression (LSR) is widely used for pattern classification. Some variants based on it try to enlarge the margin between different classes to achieve better performance. However, the large margin classifier doesn’t work well when it deals with the complex applications in the real world, such as face recognition, where images are captured with different facial expressions, lighting conditions or background. To address this problem, we propose a regularized negative label relaxation least squares regression method with the following characteristics. First, we introduce a negative $$ \varepsilon $$ dragging technique to relax the strict binary label matrix into a slack label matrix, which has more freedom to fit the labels and reduces the class margins at the same time. Second, we introduce manifold learning and class compactness graph to devise a regularization item to preserve the intrinsic structure of data and avoid the problem of overfitting. The class compactness graph can enable samples from the same class to be kept close together after they are transformed into the slack label space. The algorithm based on L2-norm loss function is devised. The experimental results show that our algorithm achieves better classification accuracy.},
  archive      = {J_NPL},
  author       = {He, Kai and Peng, Yali and Liu, Shigang and Li, Jun},
  doi          = {10.1007/s11063-020-10219-6},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2629-2647},
  shortjournal = {Neural Process. Lett.},
  title        = {Regularized negative label relaxation least squares regression for face recognition},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Asymptotic stability and polynomial stability of impulsive
cohen–grossberg neural networks with multi-proportional delays.
<em>NPL</em>, <em>51</em>(3), 2607–2627. (<a
href="https://doi.org/10.1007/s11063-020-10209-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the global asymptotic stability (GAS) and global polynomial stability (GPS) of impulsive Cohen–Grossberg neural networks (ICGNNs) with multi-proportional delays. The concept of GPS of the ICGNNs considered is first proposed and it is pointed out that the GPS is also one of the dynamics of recurrent neural networks with proportional delays. The GPS criteria depending on proportional delay factors are made by introducing tunable parameters, skillfully designing Lyapunov functionals and using inequality skills. The application scope of the ICGNNs considered parameters is extended by introducing tunable parameters. And the relationship of exponential stability, polynomial stability and asymptotic stability of the ICGNNs considered is revealed. These criteria proposed are checked by two numerical examples and simulations.},
  archive      = {J_NPL},
  author       = {Zhou, Liqun and Zhao, Zhixue},
  doi          = {10.1007/s11063-020-10209-8},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2607-2627},
  shortjournal = {Neural Process. Lett.},
  title        = {Asymptotic stability and polynomial stability of impulsive Cohen–Grossberg neural networks with multi-proportional delays},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Developer activity motivated bug triaging: Via convolutional
neural network. <em>NPL</em>, <em>51</em>(3), 2589–2606. (<a
href="https://doi.org/10.1007/s11063-020-10213-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As bugs become prevalent in software development, bug triaging has become one of the most important activities in software maintenance. To decrease the time cost in manual work, text classification techniques have been applied in automatic bug triaging. In this paper, we present a new automatic bug triaging approach which is based on convolution neural network (CNN) and developer activities. Firstly, we implement the word vector representation of the text features in bug report by using Word2vec. Then, we combine CNN with batch normalization, pooling and full connection approach to learn from the word vector representation of bug report with known fixers. In addition, we also study the recent activities of the developers which can effectively distinguish similar bug reports and get a more suitable developer recommendation list. We empirically investigate the accuracy of automatic bug triaging on three large open source projects, namely Eclipse, Mozilla and NetBeans. The experimental results show that our approach can effectively improve the performance of automatic bug triaging.},
  archive      = {J_NPL},
  author       = {Guo, Shikai and Zhang, Xinyi and Yang, Xi and Chen, Rong and Guo, Chen and Li, Hui and Li, Tingting},
  doi          = {10.1007/s11063-020-10213-y},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2589-2606},
  shortjournal = {Neural Process. Lett.},
  title        = {Developer activity motivated bug triaging: Via convolutional neural network},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Infrared image extraction algorithm based on adaptive growth
immune field. <em>NPL</em>, <em>51</em>(3), 2575–2587. (<a
href="https://doi.org/10.1007/s11063-020-10218-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In criminal investigation, there are hidden traces that many people can’t find, so infrared image is becoming an effective means to obtain these scene traces. The extraction algorithm with growth immune field can extract the target of infrared image relatively effectively, but it is lack of efficiency and reliability in complex environment. Here we propose a new target extraction algorithm with adaptive growth immune field, combining the image information of region and edge gradient. The region of the target in complex environment is obtained by K-means clustering algorithm and the source seed points are selected from the region. The regional characteristics around the seed points as the criteria for growth and the image gradient information is applied as the condition of the adaptive growth immune field. This algorithm improves the accuracy of target extraction in complex environment while preventing overgrowth. We compare the algorithm with the original algorithm and other algorithms and we find that the new algorithm combining edge gradient information can reduce the probability of over growth and ensure the integrity of target extraction under complex background.},
  archive      = {J_NPL},
  author       = {Xiao, Yu and Zijie, Zhou},
  doi          = {10.1007/s11063-020-10218-7},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2575-2587},
  shortjournal = {Neural Process. Lett.},
  title        = {Infrared image extraction algorithm based on adaptive growth immune field},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Traffic sign recognition in harsh environment using
attention based convolutional pooling neural network. <em>NPL</em>,
<em>51</em>(3), 2551–2573. (<a
href="https://doi.org/10.1007/s11063-020-10211-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) have achieved significant progress in computer vision systems, helping to efficiently obtain feature information by sliding filters on the input images. However, CNNs have difficulty capturing specific properties when the images are affected by various noises. This paper proposes an attention based convolutional pooling neural network (ACPNN) where an attention-mechanism is applied to feature maps to obtain key features, and max pooling is replaced with convolutional pooling to improve recognition accuracy in harsh environments. The ACPNN with attention mechanism and convolutional pooling structure is robust against external noises and maintains classification performance under such conditions. The proposed ACPNN was validated on the German traffic sign recognition benchmark with various cases. Considering the traffic signs are suffered from various noises, the recognition performances were demonstrated with conventional CNN and state-of-the art CNNs such as multi-scale CNN, committee of CNN, hierarchical CNN, and multi-column deep neural network. Under such harsh conditions, the proposed ACPNN shows 66.981% and 83.198% respectively, which are the best performances compared to other CNNs.},
  archive      = {J_NPL},
  author       = {Chung, Jun Ho and Kim, Dong Won and Kang, Tae Koo and Lim, Myo Taeg},
  doi          = {10.1007/s11063-020-10211-0},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2551-2573},
  shortjournal = {Neural Process. Lett.},
  title        = {Traffic sign recognition in harsh environment using attention based convolutional pooling neural network},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Global exponential stability of high-order bidirectional
associative memory (BAM) neural networks with proportional delays.
<em>NPL</em>, <em>51</em>(3), 2531–2549. (<a
href="https://doi.org/10.1007/s11063-020-10206-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the global exponential stability (GES) of high-order bidirectional associative memory (BAM) neural networks with proportional delays. Here, proportional delays are unbounded time-varying delays, which are different from constant delays, bounded time-varying delays and distributed delays. Through variable transformations, the original system can be transformed equivalently into high-order BAM neural networks with multi-constant delays and time-varying coefficients. By utilizing Brouwer’s fixed point theorem and constructing appropriate delay differential inequalities, new sufficient criteria are established to guarantee the existence, uniqueness and GES of the equilibrium point for the considered model. Finally, two examples with numerical simulations are presented to demonstrate the effectiveness of the proposed results.},
  archive      = {J_NPL},
  author       = {Zu, Jiacheng and Yu, Zhixian and Meng, Yanling},
  doi          = {10.1007/s11063-020-10206-x},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2531-2549},
  shortjournal = {Neural Process. Lett.},
  title        = {Global exponential stability of high-order bidirectional associative memory (BAM) neural networks with proportional delays},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Neural network-based optimal tracking control of
continuous-time uncertain nonlinear system via reinforcement learning.
<em>NPL</em>, <em>51</em>(3), 2513–2530. (<a
href="https://doi.org/10.1007/s11063-020-10220-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this note, optimal tracking control for uncertain continuous-time nonlinear system is investigated by using a novel reinforcement learning (RL) scheme. The uncertainty here refers to unknown system drift dynamics. Based on the nonlinear system and reference signal, we firstly formulate the tracking problem by constructing an augmented system. The optimal tracking control problem for original nonlinear system is thus transformed into solving the Hamilton–Jacobi–Bellman (HJB) equation of the augmented system. A new single neural network (NN)-based online RL method is proposed to learn the solution of tracking HJB equation while the corresponding optimal control input that minimizes the tracking HJB equation is calculated in a forward-in-time manner without requiring any value, policy iterations and the system drift dynamics. In order to relax the dependence of the RL method on traditional Persistence of Excitation (PE) conditions, a concurrent learning technique is adopted to design the NN tuning laws. The Uniformly Ultimately Boundedness of NN weight errors and closed-loop augmented system states are rigorous proved. Three numerical simulation examples are given to demonstrate the effectiveness of the proposed scheme.},
  archive      = {J_NPL},
  author       = {Zhao, Jingang},
  doi          = {10.1007/s11063-020-10220-z},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2513-2530},
  shortjournal = {Neural Process. Lett.},
  title        = {Neural network-based optimal tracking control of continuous-time uncertain nonlinear system via reinforcement learning},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Semantically smooth bilingual phrase embeddings based on
recursive autoencoders. <em>NPL</em>, <em>51</em>(3), 2497–2512. (<a
href="https://doi.org/10.1007/s11063-020-10210-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose Semantically Smooth Bilingual Recursive Autoencoders to learn bilingual phrase embeddings. The intuition behind our work is to exploit the intrinsic geometric structure of the embedding space and enforce the learned phrase embeddings to be semantically smooth. Specifically, we extend the conventional bilingual recursive autoencoders by preserving the translation and paraphrase probability distributions via regularization terms to simultaneously exploit richer explicit and implicit similarity constraints for bilingual phrase embeddings. To examine the effectiveness of our model, we incorporate two phrase-level similarity features based on the proposed model into a state-of-the-art phrase-based statistical machine translation system. Experiments on NIST Chinese–English test sets show that our model achieves substantial improvements over the baseline.},
  archive      = {J_NPL},
  author       = {Lin, Qian and Yang, Jing and Zhang, Xiangwen and Wang, Hongji and Lu, Yaojie and Su, Jinsong},
  doi          = {10.1007/s11063-020-10210-1},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2497-2512},
  shortjournal = {Neural Process. Lett.},
  title        = {Semantically smooth bilingual phrase embeddings based on recursive autoencoders},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Distributed pinning impulsive control for inner–outer
synchronization of dynamical networks on time scales. <em>NPL</em>,
<em>51</em>(3), 2481–2495. (<a
href="https://doi.org/10.1007/s11063-020-10204-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, inner–outer synchronization problem of dynamical networks on time scales is studied. This kind of network synchronization means that two dynamical networks can achieve inner/outer synchronization simultaneously. By designing suitable distributed pinning impulsive controllers, the inner–outer synchronization target is realized. Based on the Lyapunov function method and the mathematical induction approach, two sufficient criteria are given for inner–outer synchronization of two networks with identical and non-identical topologies. Due to the structure of time scales, the derived results can be applied to study the inner–outer synchronization problems of continuous/discrete networks and networks on hybrid time domains. A numerical simulation example is given to illustrate the effectiveness of the derived results.},
  archive      = {J_NPL},
  author       = {Lu, Xiaodong and Li, Haitao},
  doi          = {10.1007/s11063-020-10204-z},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2481-2495},
  shortjournal = {Neural Process. Lett.},
  title        = {Distributed pinning impulsive control for Inner–Outer synchronization of dynamical networks on time scales},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-weighted complex structure on fractional order coupled
neural networks with linear coupling delay: A robust synchronization
problem. <em>NPL</em>, <em>51</em>(3), 2453–2479. (<a
href="https://doi.org/10.1007/s11063-019-10188-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This sequel is concerned with the analysis of robust synchronization for a multi-weighted complex structure on fractional-order coupled neural networks (MWCFCNNs) with linear coupling delays via state feedback controller. Firstly, by means of fractional order comparison principle, suitable Lyapunov method, Kronecker product technique, some famous inequality techniques about fractional order calculus and the basis of interval parameter method, two improved robust asymptotical synchronization analysis, both algebraic method and LMI method, respectively are established via state feedback controller. Secondly, when the parameter uncertainties are ignored, several synchronization criterion are also given to ensure the global asymptotical synchronization of considered MWCFCNNs. Moreover, two type of special cases for global asymptotical synchronization MWCFCNNs with and without linear coupling delays, respectively are investigated. Ultimately, the accuracy and feasibility of obtained synchronization criteria are supported by the given two numerical computer simulations.},
  archive      = {J_NPL},
  author       = {Pratap, A. and Raja, R. and Agarwal, Ravi. P. and Cao, J. and Bagdasar, O.},
  doi          = {10.1007/s11063-019-10188-5},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2453-2479},
  shortjournal = {Neural Process. Lett.},
  title        = {Multi-weighted complex structure on fractional order coupled neural networks with linear coupling delay: A robust synchronization problem},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Constrained PSO based center selection for RBF networks
under concurrent fault situation. <em>NPL</em>, <em>51</em>(3),
2437–2451. (<a
href="https://doi.org/10.1007/s11063-020-10202-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the training of radial basis function (RBF) networks, one important issue is to select RBF centers before constructing the networks. Most existing center selection methods are designed for the fault-free situation only. However, as the implementation of the networks may be perturbed by faults, these algorithms may lead to networks with degraded performance. This paper considers the center selection problem for RBF networks under the concurrent fault situation where multiplicative weight noise and open weight fault exist simultaneously. In particular, we introduce a binary label vector indicating the centers selected from training samples. Using the label vector, the fault-tolerant RBF model under the concurrent fault situation is reformulated as a constrained optimization problem, so that fault-tolerance can be considered in the procedure of center selection. To solve this constrained optimization problem, a constrained particle swarm optimization based algorithm is developed to select centers and train the network simultaneously. Simulation results show that the proposed algorithm is superior than state-of-the-art center selection algorithms.},
  archive      = {J_NPL},
  author       = {Dong, Jing and Zhao, Yuxin and Liu, Chang},
  doi          = {10.1007/s11063-020-10202-1},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2437-2451},
  shortjournal = {Neural Process. Lett.},
  title        = {Constrained PSO based center selection for RBF networks under concurrent fault situation},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Selective embedding with gated fusion for 6D object pose
estimation. <em>NPL</em>, <em>51</em>(3), 2417–2436. (<a
href="https://doi.org/10.1007/s11063-020-10198-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning method for 6D object pose estimation based on RGB image and depth (RGB-D) has been successfully applied to robot grasping. The fusion of RGB and depth is one of the most important difficulties. Previous works on the fusion of these two features are mostly concatenated together without considering the different contributions of the two types of features to pose estimation. We propose a selective embedding with gated fusion structure called SEGate, which can adjust the weights of RGB and depth features adaptively. Furthermore, we aggregate the local features of point clouds according to the distance between them. More specifically, the close point clouds contribute a lot to local features, while the distant point clouds contribute a little. Experiments show that our approach achieves the state-of-art performance in both LineMOD and YCB-Video datasets. Meanwhile, our approach is more robust to the pose estimation of occluded objects.},
  archive      = {J_NPL},
  author       = {Sun, Shantong and Liu, Rongke and Du, Qiuchen and Sun, Shuqiao},
  doi          = {10.1007/s11063-020-10198-8},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2417-2436},
  shortjournal = {Neural Process. Lett.},
  title        = {Selective embedding with gated fusion for 6D object pose estimation},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Visual sentiment prediction with attribute augmentation and
multi-attention mechanism. <em>NPL</em>, <em>51</em>(3), 2403–2416. (<a
href="https://doi.org/10.1007/s11063-020-10201-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, many methods that exploit attention mechanism to discover the relevant local regions via visual attributes, have demonstrated promising performance in visual sentiment prediction. In these methods, accurate detection of visual attributes is of vital importance to identify the sentiment relevant regions, which is crucial for successful assessment of visual sentiment. However, existing work merely utilize basic strategies on convolutional neural network for visual attribute detection and fail to obtain satisfactory results due to the semantic gap between visual features and subjective attributes. Moreover, it is difficult for existing attention models to localize subtle sentiment relevant regions, especially when the performance of attribute detection is relatively poor. To address these problems, we first design a multi-task learning based approach for visual attribute detection. By augmenting the attributes with sentiments supervision, the semantic gap can be effectively reduced. We then develop a multi-attention model for jointly discovering and localizing multiple relevant local regions given predicted attributes. The classifier built on top of these regions achieves a significant improvement in visual sentiment prediction. Experimental results demonstrate the superiority of our method against previous approaches.},
  archive      = {J_NPL},
  author       = {Wu, Zhuanghui and Meng, Min and Wu, Jigang},
  doi          = {10.1007/s11063-020-10201-2},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2403-2416},
  shortjournal = {Neural Process. Lett.},
  title        = {Visual sentiment prediction with attribute augmentation and multi-attention mechanism},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Anti-periodic oscillations of fuzzy delayed cellular neural
networks with impulse on time scales. <em>NPL</em>, <em>51</em>(3),
2379–2402. (<a
href="https://doi.org/10.1007/s11063-020-10203-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this manuscript, fuzzy delayed cellular neural networks with impulse are studied. Applying time scale calculus knowledge, mathematical inequalities and constructing Lyapunov function, we establish a sufficient criterion that guarantees the existence and exponential stability of anti-periodic solutions for fuzzy delayed cellular neural networks with impulse. In addition, an example with its numerical simulations is given to illustrate our theoretical predictions.},
  archive      = {J_NPL},
  author       = {Xu, Changjin and Liao, Maoxin and Li, Peiluan and Liu, Zixin},
  doi          = {10.1007/s11063-020-10203-0},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2379-2402},
  shortjournal = {Neural Process. Lett.},
  title        = {Anti-periodic oscillations of fuzzy delayed cellular neural networks with impulse on time scales},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Automatic semantic segmentation with DeepLab dilated
learning network for change detection in remote sensing images.
<em>NPL</em>, <em>51</em>(3), 2355–2377. (<a
href="https://doi.org/10.1007/s11063-019-10174-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic change detection is an interesting research area in remote sensing (RS) technology aims to detect the changes in synthetic aperture radar (SAR) and multi-temporal hyperspectral images acquired at different time intervals. This method identifies the differences between the images and accomplishes the classification result into changed and unchanged areas. However, the existing algorithms are degraded due to noises present in the RS images. The main aim of the proposed method is the automatic semantic segmentation based change detection that produces a final change between the two input images. This paper proposes a feature learning method named deep lab dilated convolutional neural network (DL-DCNN) for the detection of changes from the images. The proposed approach consists of three stages: (i) pre-processing, (ii) semantic segmentation based change detection and (iii) accuracy assessment. Initially, preprocessing is performed to correct the errors and to obtain detailed information from the scene. Then, map the changes between the two images with the help of a trained network. The DCNN network performs fine-tuning and determines the relationship between two images as changed and unchanged pixel areas. The experimental analysis conducted on various datasets and compared with several existing algorithms. The experimental analysis is performed in terms of F-score, percentage correct classification, kappa coefficient, and overall error rate measures to show a better performance measure than the other state-of-art approaches.},
  archive      = {J_NPL},
  author       = {Venugopal, N.},
  doi          = {10.1007/s11063-019-10174-x},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2355-2377},
  shortjournal = {Neural Process. Lett.},
  title        = {Automatic semantic segmentation with DeepLab dilated learning network for change detection in remote sensing images},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Finite-time and fixed-time non-chattering control for
inertial neural networks with discontinuous activations and proportional
delay. <em>NPL</em>, <em>51</em>(3), 2337–2353. (<a
href="https://doi.org/10.1007/s11063-020-10199-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on the framework of Filippov solutions, this paper considers synchronization of inertial neural networks (INNs) with discontinuous activation functions and proportional delay. By designing several non-chattering controllers, both finite-time and fixed-time synchronization are studied. The designed controllers are simple to be implemented and can overcome the effects of both nonidentical uncertainties of Filippov solutions and the proportional delay without inducing any chattering. By designing new Lyapunov functionals and utilizing 1-norm methods, several sufficient conditions are obtained to ensure that the INNs achieve drive-response synchronization in finite time and fixed time, respectively. Moreover, the settling time is estimated for the two types of synchronization. Simulations are provided to illustrate the effectiveness of theoretical analysis.},
  archive      = {J_NPL},
  author       = {Xu, Dengguo and Yang, Xinsong and Tang, Rongqiang},
  doi          = {10.1007/s11063-020-10199-7},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2337-2353},
  shortjournal = {Neural Process. Lett.},
  title        = {Finite-time and fixed-time non-chattering control for inertial neural networks with discontinuous activations and proportional delay},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust exponential stability for discrete-time
quaternion-valued neural networks with time delays and parameter
uncertainties. <em>NPL</em>, <em>51</em>(3), 2317–2335. (<a
href="https://doi.org/10.1007/s11063-020-10196-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the robust exponential stability for discrete-time quaternion-valued neural networks with time delays and parameter uncertainties is investigated. By means of Lyapunov theorem, linear matrix inequality and contraction mapping theorem, new sufficient conditions are derived to ensure the existence, uniqueness and robust exponential stability of the equilibrium point of the proposed quaternion-valued neural networks. Compared with the existed literatures, the obtained results are less conservative. Finally, simulations are presented to illustrate the effectiveness of the theoretical results.},
  archive      = {J_NPL},
  author       = {Tan, Yuanshun and Wang, Xiaodong and Yang, Jin and Hu, Jin},
  doi          = {10.1007/s11063-020-10196-w},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2317-2335},
  shortjournal = {Neural Process. Lett.},
  title        = {Robust exponential stability for discrete-time quaternion-valued neural networks with time delays and parameter uncertainties},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient strategies of static features incorporation into
the recurrent neural network. <em>NPL</em>, <em>51</em>(3), 2301–2316.
(<a href="https://doi.org/10.1007/s11063-020-10195-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recurrent neural networks (RNNs) have evolved to become one of the most powerful tools for making predictions on sequenced data, such as time series, textual data, signals, music etc. In many real-life cases, however, sequenced data are additionally characterized by static features which, due to their non-sequential nature, cannot be transferred directly into RNNs. In this paper, we discuss a method which incorporates static features into RNNs in order to influence and generalize the learning process. Furthermore, we will demonstrate that our approach significantly enhances the performance of RNNs, enabling the networks to learn the sequenced data exhibiting varying characteristics and then distinguish between them through the use of static supplementary information. Finally, we will evaluate our model against real energy consumption measurements of energy time series and verify that high-accuracy demand forecasts for different types of customers can be achieved only by way of incorporation of static features.},
  archive      = {J_NPL},
  author       = {Miebs, Grzegorz and Mochol-Grzelak, Małgorzata and Karaszewski, Adam and Bachorz, Rafał A.},
  doi          = {10.1007/s11063-020-10195-x},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2301-2316},
  shortjournal = {Neural Process. Lett.},
  title        = {Efficient strategies of static features incorporation into the recurrent neural network},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep dual-stream network with scale context selection
attention module for semantic segmentation. <em>NPL</em>,
<em>51</em>(3), 2281–2299. (<a
href="https://doi.org/10.1007/s11063-019-10148-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fusion of multi-scale features has been an effective method to get state-of-the-art performance in semantic segmentation. In this work, we concentrate on two tricky problems—the intra-class inconsistency and the blur on the localization of object boundaries and tackle them by combining two separate multi-scale context features respectively. Specifically, we propose a dual-stream structure with the scale context selection attention module to enhance the capabilities for multi-scale processing, where one stream collects global-scale context and the other captures local-scale information. Meanwhile, the embedded scale context selection attention module in each stream can adaptively focus on different scale context information to get optimal scale features. Based on our dual-stream structure with attention modules, our network can efficiently make use of multi-scale context to generate more comprehensive and powerful features. Our experiments show that our dual-stream network with scale context selection attention module achieves promising performance on the PASCAL VOC 2012 and PASCAL-Person-Part datasets.},
  archive      = {J_NPL},
  author       = {Liu, Yifu and Xu, Chenfeng and Chen, Zhihong and Chen, Chao and Zhao, Han and Jin, Xinyu},
  doi          = {10.1007/s11063-019-10148-z},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2281-2299},
  shortjournal = {Neural Process. Lett.},
  title        = {Deep dual-stream network with scale context selection attention module for semantic segmentation},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An evaluation of RetinaNet on indoor object detection for
blind and visually impaired persons assistance navigation. <em>NPL</em>,
<em>51</em>(3), 2265–2279. (<a
href="https://doi.org/10.1007/s11063-020-10197-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Indoor object detection presents a computer vision task that deals with the detection of specific indoor classes. This task attracts a lot of attention, especially in the last few years. The strong interest related to this field can be explained by the big importance of this task for indoor assistance navigation for visually impaired people and also by the phenomenal development of the deep convolutional neural networks (Deep CNN). In this paper, an effort is made to perform a new indoor object detector using the deep convolutional neural network-based framework. The framework is built based on the deep convolutional neural network “RetinaNet”. Evaluation is done by using various backbones as ResNet, DenseNet, and VGGNet in order to improve detection performances and processing time. We obtained very encouraging results coming up to 84.61% mAP as detection precision.},
  archive      = {J_NPL},
  author       = {Afif, Mouna and Ayachi, Riadh and Said, Yahia and Pissaloux, Edwige and Atri, Mohamed},
  doi          = {10.1007/s11063-020-10197-9},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2265-2279},
  shortjournal = {Neural Process. Lett.},
  title        = {An evaluation of RetinaNet on indoor object detection for blind and visually impaired persons assistance navigation},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Superpixels features extractor network (SP-FEN) for clothing
parsing enhancement. <em>NPL</em>, <em>51</em>(3), 2245–2263. (<a
href="https://doi.org/10.1007/s11063-019-10173-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the research looks at improving clothing parsing using superpixels features extractor network (SP-FEN). Clothing parsing using a fully convolutional network has two parts: an encoder and decoder. The encoder lowers the dimensionality and produces a low-resolution prediction, while the decoder tries to upscale the prediction and returns it to the size of the input image. Typically, fine-grained details get lost in the encoding part of the model is not recovered well in the decoder part. To fix this issue, skip connections are typically used in recovering and adding more fine-grained details to the final prediction. A new method is proposed to introduce superpixels features to the decoder by adding a side network (SP-FEN) that extracts features from superpixels representation of the input image using the SLIC Algorithm. SP-FEN then produces a meaningful superpixels features to be injected into the decoder. The SP-FEN is learning to choose specific features to be fed to the decoder part to boost the outputs overall quality. The proposed method has shown to enhance the MIoU accuracy using the refined Fashionista V1.0 dataset and CFPD dataset. The results showed that the proposed approach achieved superior performance with pixel-wise segmentation and clothing parsing.},
  archive      = {J_NPL},
  author       = {Ihsan, A. Mustafa and Loo, Chu Kiong and Naji, Sinan A. and Seera, Manjeevan},
  doi          = {10.1007/s11063-019-10173-y},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2245-2263},
  shortjournal = {Neural Process. Lett.},
  title        = {Superpixels features extractor network (SP-FEN) for clothing parsing enhancement},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stepanov-like pseudo almost periodic solution of
quaternion-valued for fuzzy recurrent neural networks with mixed delays.
<em>NPL</em>, <em>51</em>(3), 2211–2243. (<a
href="https://doi.org/10.1007/s11063-020-10193-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-valued neural networks or complex-valued neural networks are sometimes inappropriate for some engineering and research problems for instance where the data is multi-dimensional, such as 4-D signals, color images and body images. Hence, researchers explored recently a more general and sophisticated model than the previous one, which is the quaternion-valued neural networks. The quaternions, which can also be defined as $$2\times 2$$ matrix of complex numbers, have the capacity to analyze three or more dimensional signals and represent spatial transformations. In this paper, some sufficient conditions are given for the existence and various kinds of stability for the unique Stepanov-like pseudo almost periodic solution of quaternion-valued fuzzy recurrent neural networks. The results are established by employing Lyapunov functionals, Nemytskii’s operator and Banach fixed point theorem. Also, a new direct method is used to establish our theoretical results in order to avoid the decomposition of the considered model into real-valued or complex-valued system. Finally, a numerical example is given to illustrate the validity of the obtained results.},
  archive      = {J_NPL},
  author       = {Chérif, Farouk and Abdelaziz, Meryem},
  doi          = {10.1007/s11063-020-10193-z},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2211-2243},
  shortjournal = {Neural Process. Lett.},
  title        = {Stepanov-like pseudo almost periodic solution of quaternion-valued for fuzzy recurrent neural networks with mixed delays},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On impulsive synchronization control for coupled inertial
neural networks with pinning control. <em>NPL</em>, <em>51</em>(3),
2195–2210. (<a
href="https://doi.org/10.1007/s11063-019-10189-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The impulsive control for the synchronization problem of coupled inertial neural networks involved distributed-delay coupling is investigated in the present paper. A novel impulsive pinning control method is introduced to obtain the complete synchronization of the coupled inertial neural networks with three different coupling structures. At each impulsive control instant, the pinning-controlled nodes can be selected according to our selection strategy which is dependent on the lower bound of the pinning control ratio. Our criteria can be utilized to declare the synchronization of the coupled neural networks with asymmetric and reducible coupling structures. The effectiveness of our control strategy is exhibited by typical numerical examples.},
  archive      = {J_NPL},
  author       = {Yu, Tianhu and Wang, Huamin and Cao, Jinde and Yang, Yang},
  doi          = {10.1007/s11063-019-10189-4},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2195-2210},
  shortjournal = {Neural Process. Lett.},
  title        = {On impulsive synchronization control for coupled inertial neural networks with pinning control},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A neural network study of blasius equation. <em>NPL</em>,
<em>51</em>(3), 2179–2194. (<a
href="https://doi.org/10.1007/s11063-019-10184-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work we applied a feed forward neural network to solve Blasius equation which is a third-order nonlinear differential equation. Blasius equation is a kind of boundary layer flow. We solved Blasius equation without reducing it into a system of first order equation. Numerical results are presented and a comparison according to some studies is made in the form of their results. Obtained results are found to be in good agreement with the given studies.},
  archive      = {J_NPL},
  author       = {Mutuk, Halil},
  doi          = {10.1007/s11063-019-10184-9},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2179-2194},
  shortjournal = {Neural Process. Lett.},
  title        = {A neural network study of blasius equation},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). State estimation of quaternion-valued neural networks with
leakage time delay and mixed two additive time-varying delays.
<em>NPL</em>, <em>51</em>(3), 2155–2178. (<a
href="https://doi.org/10.1007/s11063-019-10178-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the state estimation of quaternion-valued neural networks (QVNNs) with leakage time delay, both discrete and distributed two additive time-varying delays is studied. By considering the QVNNs as a whole, instead of decomposing it into two complex-valued neural networks or four real-valued neural networks. Via constructing suitable Lyapunov–Krasovskii functionals, combining free weight matrix, reciprocally convex approach, and matrix inequalities, the sufficient criteria for time delays are given in the form of quaternion-valued linear matrix inequalities and complex-valued linear matrix inequalities. Some observable output measurements are used to estimate the state of neurons, which ensures the global asymptotic stability of the error-state system. Finally, the effectiveness of theoretical analysis is illustrated by a numerical simulation.},
  archive      = {J_NPL},
  author       = {Liu, Libin and Chen, Xiaofeng},
  doi          = {10.1007/s11063-019-10178-7},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2155-2178},
  shortjournal = {Neural Process. Lett.},
  title        = {State estimation of quaternion-valued neural networks with leakage time delay and mixed two additive time-varying delays},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Blind image deconvolution via enhancing significant
segments. <em>NPL</em>, <em>51</em>(3), 2139–2154. (<a
href="https://doi.org/10.1007/s11063-019-10123-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blind image deconvolution aims to estimate both a blur kernel and a sharp image from a blurry observation. It is not only a classical problem in image processing, but also serves as preprocessing in many advanced tasks including affective image content analysis. In terms of statistical inference, this problem can be viewed as maximizing the probability of latent image and kernel, given the observed blurry image. Proper formulation of latent image prior is crucial to the success of blind deconvolution methods. A novel latent image prior is proposed to penalize low contrast and dense gradients, thus playing the role of enhancing significant segments. Our latent image prior is based on a one-dimensional regularizer, which involves normalizing reciprocals of absolute differences between two neighbouring unequal components. To solve the resulting optimization problem, a dynamic programming based method is derived to approximately evaluate the proximal operator associated with the proposed regularizer. Both quantitative and qualitative experiments illustrate that our method is comparable to the top-performing algorithms.},
  archive      = {J_NPL},
  author       = {Jiang, Xiaolei and Liao, Erchong and Liu, Xiaofeng},
  doi          = {10.1007/s11063-019-10123-8},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2139-2154},
  shortjournal = {Neural Process. Lett.},
  title        = {Blind image deconvolution via enhancing significant segments},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). An end-to-end perceptual quality assessment method via
score distribution prediction. <em>NPL</em>, <em>51</em>(3), 2123–2137.
(<a href="https://doi.org/10.1007/s11063-019-10057-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image quality assessment (IQA) has become a rapidly growing field of technology as it automatically predicts the perceptual quality, which is of vital importance for consumer-centric services. However, most existing IQA algorithms focus on predicting the mean opinion score regardless of the inevitable opinion diversity. To address this shortcoming, in this paper, we propose to predict the distribution of opinion scores via an end-to-end convolutional neural network. The network is based on a pre-trained ResNet with 50 layers and a novel Statistical Region-of-Interest (ROI) Pooling layer is introduced for lower model complexity, which enables effective training with few datum. Meanwhile, instead of using traditional mean-square-error as loss function, our model is trained with cross-entropy loss, which is more suitable for probability distribution learning. Extensive experiments have been carried out on ESPL-LIVE HDR datasets with highly diverse opinion scores. It is shown that the statistical ROI Pooling is more efficient than traditional ROI Pooling layers and classical dimensionality reduction of principle component analysis. And the proposed algorithm achieves superior performance than state-of-the-art label distribution learning methods in terms of six representative evaluation metrics.},
  archive      = {J_NPL},
  author       = {Liu, Jing and Wang, Jingting and Nie, Weizhi and Su, Yuting and Liu, Anan},
  doi          = {10.1007/s11063-019-10057-1},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2123-2137},
  shortjournal = {Neural Process. Lett.},
  title        = {An end-to-end perceptual quality assessment method via score distribution prediction},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Inferring personality traits from attentive regions of user
liked images via weakly supervised dual convolutional network.
<em>NPL</em>, <em>51</em>(3), 2105–2121. (<a
href="https://doi.org/10.1007/s11063-019-09987-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In social media, users usually unconsciously their preferences on images, which can be considered as the personal cues for inferring their personality traits. Existing methods map the holistic image features into personality traits. However, users’ attention on their liked images is typically localized, which should be taken into account in modeling personality traits. In this paper, we propose an end-to-end weakly supervised dual convolutional network (WSDCN) for personality prediction, which consists of a classification network and a regression network. The classification network captures personality class-specific attentive image regions while only requiring the image-level personality class labels. The regression network is used for predicting personality traits. Firstly, the users’ Big-Five (BF) traits are converted into ten personality class labels for their liked images. Secondly, the Multi-Personality Class Activation Map (MPCAM) is generated based on the classification network and utilized as the localized activation to produce local deep features, which are then combined with the holistic deep features for the regression task. Finally, the user liked images and the associated personality traits are used to train the end-to-end WSDCN model. The proposed method is able to predict the BF personality traits simultaneously by training the WSDCN network only once. Experimental results on the annotated PsychoFlickr database show that the proposed method is superior to the state-of-the-art approaches.},
  archive      = {J_NPL},
  author       = {Zhu, Hancheng and Li, Leida and Jiang, Hongyan and Tan, Allen},
  doi          = {10.1007/s11063-019-09987-7},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2105-2121},
  shortjournal = {Neural Process. Lett.},
  title        = {Inferring personality traits from attentive regions of user liked images via weakly supervised dual convolutional network},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-layer attention based CNN for target-dependent
sentiment classification. <em>NPL</em>, <em>51</em>(3), 2089–2103. (<a
href="https://doi.org/10.1007/s11063-019-10017-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Target-dependent sentiment classification aims at identifying the sentiment polarities of targets in a given sentence. Previous approaches utilize recurrent neural network with attention mechanism incorporated to model the context and learn key sentiment intermediate representation in relation to a given target. However, such methods are incapable either of modeling complex contexts or of processing data parallelly. To address these problems, we propose, in this paper, a new model that employs a multi-layer convolutional neural network to process the context parallelly and model the context multiple times, where the neural network is able to explicitly learn the sentiment intermediate representation via an attention mechanism. Eventually, we integrate these features to form a final sentiment representation, which will be fed into the classifier. Experiments show that our model surpasses the existing approaches on several datasets.},
  archive      = {J_NPL},
  author       = {Zhang, Suqi and Xu, Xinyun and Pang, Yanwei and Han, Jungong},
  doi          = {10.1007/s11063-019-10017-9},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2089-2103},
  shortjournal = {Neural Process. Lett.},
  title        = {Multi-layer attention based CNN for target-dependent sentiment classification},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Correction to: Deep transfer learning for image emotion
analysis: Reducing marginal and joint distribution discrepancies
together. <em>NPL</em>, <em>51</em>(3), 2087–2088. (<a
href="https://doi.org/10.1007/s11063-019-10162-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The original article contains two mistakes.},
  archive      = {J_NPL},
  author       = {He, Yuwei and Ding, Guiguang},
  doi          = {10.1007/s11063-019-10162-1},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2087-2088},
  shortjournal = {Neural Process. Lett.},
  title        = {Correction to: deep transfer learning for image emotion analysis: reducing marginal and joint distribution discrepancies together},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Deep transfer learning for image emotion analysis: Reducing
marginal and joint distribution discrepancies together. <em>NPL</em>,
<em>51</em>(3), 2077–2086. (<a
href="https://doi.org/10.1007/s11063-019-10035-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A lot of research attentions have been paid to image emotion analysis in recent years. Meanwhile, as convolutional neural networks (CNNs) have made great successful in computer vision, many researchers start to employ CNN to discriminate image emotions. However, the training procedure of CNNs depends on sufficient labeled data. Therefore, a CNN is hard to perform well in an image domain with scant labeled information. In this paper, we propose a deep transfer learning method for image emotion analysis. The method can leverage rich emotion knowledge from a source domain to the target domain. Our method reduces both marginal and joint domain distribution discrepancies at fully-connected layers. Through this way, we can effectively extract more transferable features and advance the performance of CNNs on poor-label emotion-image domains.},
  archive      = {J_NPL},
  author       = {He, Yuwei and Ding, Guiguang},
  doi          = {10.1007/s11063-019-10035-7},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2077-2086},
  shortjournal = {Neural Process. Lett.},
  title        = {Deep transfer learning for image emotion analysis: Reducing marginal and joint distribution discrepancies together},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Visual sentiment analysis by combining global and local
information. <em>NPL</em>, <em>51</em>(3), 2063–2075. (<a
href="https://doi.org/10.1007/s11063-019-10027-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of visual social networks, the sentiment analysis of images has quickly emerged for opinion mining. Based on the observation that the sentiments conveyed by some images are related to salient objects in them, we propose a scheme for visual sentiment analysis that combines global and local information. First, the sentiment is predicted from the entire images. Second, it is judged whether there are salient objects in an image or not. If there are, sub-images are cropped from the entire image based on the detection window of the salient objects. Moreover, a CNN model is trained for the set of sub-images. Predictions of sentiments from entire images and sub-images are then fused together to obtain the final results. If no salient object is detected in the images, the sentiment predicted directly from entire images is used as the final result. The compared experimental results show that the proposed approach is superior to state-of-the-art algorithms. It also demonstrates that reasonably utilizing the local information could improve the performance for visual sentiment analysis.},
  archive      = {J_NPL},
  author       = {Wu, Lifang and Qi, Mingchao and Jian, Meng and Zhang, Heng},
  doi          = {10.1007/s11063-019-10027-7},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2063-2075},
  shortjournal = {Neural Process. Lett.},
  title        = {Visual sentiment analysis by combining global and local information},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Learning multi-level deep representations for image emotion
classification. <em>NPL</em>, <em>51</em>(3), 2043–2061. (<a
href="https://doi.org/10.1007/s11063-019-10033-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a new deep network that learns multi-level deep representations for image emotion classification (MldrNet). Image emotion can be recognized through image semantics, image aesthetics and low-level visual features from both global and local views. Existing image emotion classification works using hand-crafted features or deep features mainly focus on either low-level visual features or semantic-level image representations without taking all factors into consideration. The proposed MldrNet combines deep representations of different levels, i.e. image semantics, image aesthetics and low-level visual features to effectively classify the emotion types of different kinds of images, such as abstract paintings and web images. Extensive experiments on both Internet images and abstract paintings demonstrate the proposed method outperforms the state-of-the-art methods using deep features or hand-crafted features. The proposed approach also outperforms the state-of-the-art methods with at least 6% performance improvement in terms of overall classification accuracy.},
  archive      = {J_NPL},
  author       = {Rao, Tianrong and Li, Xiaoxu and Xu, Min},
  doi          = {10.1007/s11063-019-10033-9},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {2043-2061},
  shortjournal = {Neural Process. Lett.},
  title        = {Learning multi-level deep representations for image emotion classification},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). DNN-based cross-lingual voice conversion using bottleneck
features. <em>NPL</em>, <em>51</em>(2), 2029–2042. (<a
href="https://doi.org/10.1007/s11063-019-10149-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-lingual voice conversion (CLVC) is quite challenging since the source and target speakers speak different languages. It is essential for various applications such as developing mixed-language speech synthesis systems, customization of speaking devices, etc. This paper proposes a deep neural network (DNN)-based approach utilizing bottleneck features for CLVC. In the proposed method, the speaker-independent information present in the speech signals from different languages is represented by using the bottleneck features extracted from a deep auto-encoder. A DNN model is trained to learn the mapping between bottleneck features and the corresponding spectral features of the target speaker. The proposed approach can capture speaker-specific characteristics of a target speaker, and requires no speech data from the source speaker during training. The performance of the proposed method is evaluated using data from three Indian languages: Telugu, Tamil and Malayalam. The experimental results show that the proposed method can effectively convert the source speaker voice to target speaker voice in a cross-lingual scenario.},
  archive      = {J_NPL},
  author       = {Kiran Reddy, M. and Sreenivasa Rao, K.},
  doi          = {10.1007/s11063-019-10149-y},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {2029-2042},
  shortjournal = {Neural Process. Lett.},
  title        = {DNN-based cross-lingual voice conversion using bottleneck features},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Image inpainting: A review. <em>NPL</em>, <em>51</em>(2),
2007–2028. (<a
href="https://doi.org/10.1007/s11063-019-10163-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although image inpainting, or the art of repairing the old and deteriorated images, has been around for many years, it has recently gained even more popularity, because of the recent development in image processing techniques. With the improvement of image processing tools and the flexibility of digital image editing, automatic image inpainting has found important applications in computer vision and has also become an important and challenging topic of research in image processing. This paper reviews the existing image inpainting approaches, that were classified into three subcategories, sequential-based, CNN-based, and GAN-based methods. In addition, for each category, a list of methods for different types of distortion on images are presented. Furthermore, the paper also presents available datasets. Last but not least, we present the results of real evaluations of the three categories of image inpainting methods performed on the used datasets, for different types of image distortion. We also present the evaluations metrics and discuss the performance of these methods in terms of these metrics. This overview can be used as a reference for image inpainting researchers, and it can also facilitate the comparison of the methods as well as the datasets used. The main contribution of this paper is the presentation of the three categories of image inpainting methods along with a list of available datasets that the researchers can use to evaluate their proposed methodology against.},
  archive      = {J_NPL},
  author       = {Elharrouss, Omar and Almaadeed, Noor and Al-Maadeed, Somaya and Akbari, Younes},
  doi          = {10.1007/s11063-019-10163-0},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {2007-2028},
  shortjournal = {Neural Process. Lett.},
  title        = {Image inpainting: A review},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Class-specific discriminant regularization in real-time deep
CNN models for binary classification problems. <em>NPL</em>,
<em>51</em>(2), 1989–2005. (<a
href="https://doi.org/10.1007/s11063-019-10156-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we first propose lightweight deep CNN models, capable of effectively operating in real-time on-drone for high-resolution video input, addressing various binary classification problems, e.g. crowd, face, football player, and bicycle detection, in the context of media coverage of specific sport events by drones with increased decisional autonomy. Furthermore, we propose a novel class-specific discriminant regularizer in order to improve the generalization ability of the proposed real-time models, exploiting the nature of the considered two-class problems. The experimental evaluation on four datasets validates the effectiveness of the proposed regularizer in enhancing the generalization ability of the proposed models.},
  archive      = {J_NPL},
  author       = {Tzelepi, Maria and Tefas, Anastasios},
  doi          = {10.1007/s11063-019-10156-z},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1989-2005},
  shortjournal = {Neural Process. Lett.},
  title        = {Class-specific discriminant regularization in real-time deep CNN models for binary classification problems},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An image clustering auto-encoder based on predefined
evenly-distributed class centroids and MMD distance. <em>NPL</em>,
<em>51</em>(2), 1973–1988. (<a
href="https://doi.org/10.1007/s11063-020-10194-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel, effective and simpler end-to-end image clustering auto-encoder algorithm: ICAE. The algorithm uses predefined evenly-distributed class centroids (PEDCC) as the clustering centers, which ensures the inter-class distance of latent features is maximal, and adds data distribution constraint, data augmentation constraint, auto-encoder reconstruction constraint and Sobel smooth constraint to improve the clustering performance. Specifically, we perform one-to-one data augmentation to learn the more effective features. The data and the augmented data are simultaneously input into the autoencoder to obtain latent features and the augmented latent features whose similarity are constrained by an augmentation loss. Then, making use of the maximum mean discrepancy distance, we combine the latent features and augmented latent features to make their distribution close to the PEDCC distribution (uniform distribution between classes, Dirac distribution within the class) to further learn clustering-oriented features. At the same time, the MSE of the original input image and reconstructed image is used as reconstruction constraint, and the Sobel smooth loss to build generalization constraint to improve the generalization ability. Finally, extensive experiments on three common datasets MNIST, Fashion-MNIST, COIL20 are conducted. The experimental results show that the algorithm has achieved the best clustering results so far. In addition, we can use the predefined PEDCC class centers, and the decoder to clearly generate the samples of each class. The code can be downloaded at https://github.com/zyWang-Power/Clustering!},
  archive      = {J_NPL},
  author       = {Zhu, Qiuyu and Wang, Zhengyong},
  doi          = {10.1007/s11063-020-10194-y},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1973-1988},
  shortjournal = {Neural Process. Lett.},
  title        = {An image clustering auto-encoder based on predefined evenly-distributed class centroids and MMD distance},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). ANN based solution of uncertain linear systems of equations.
<em>NPL</em>, <em>51</em>(2), 1957–1971. (<a
href="https://doi.org/10.1007/s11063-019-10183-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Linear systems of equations have many applications in the area of engineering sciences, mathematics, operations research and statistics. It is worth mentioning that the coefficient matrix of the linear systems of equations may not be always crisp due to various uncertainties. These uncertainties may be in the form of interval. Likewise, the solution set and right hand side vector may also be in interval. In this respect, a fully interval linear system of equations $$ (\tilde{P}\tilde{z} = \tilde{q}) $$ is one where the coefficient matrix, the unknown vector and the right hand side vector all are in the form of interval. Although various authors proposed different methods to handle the fully linear systems of equations but those are sometimes problem specific etc. As such, in this paper $$ n \times n $$ fully interval linear systems of equations has been solved based on artificial neural network (ANN) model. In this regard, step by step algorithm has been included. Further, a convergence theorem has also been discussed for choosing suitable learning parameter. Few numerical examples and an application problem related to electrical circuit have been solved using the proposed method. Detail procedure has been discussed with numerical results to show the efficacy and powerfulness of the method.},
  archive      = {J_NPL},
  author       = {Jeswal, S. K. and Chakraverty, S.},
  doi          = {10.1007/s11063-019-10183-w},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1957-1971},
  shortjournal = {Neural Process. Lett.},
  title        = {ANN based solution of uncertain linear systems of equations},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). <span class="math display"><em>H</em><sub>∞</sub></span>
filtering for markov jump neural networks subject to hidden-markov mode
observation and packet dropouts via an improved activation function
dividing method. <em>NPL</em>, <em>51</em>(2), 1939–1955. (<a
href="https://doi.org/10.1007/s11063-019-10175-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is devoted to investigating the $$H_{\infty }$$ filtering problem for Markov jump neural networks with hidden-Markov mode observation and packet dropouts, in which the information regarding to the Markov state can not be completely acquired. To address this circumstance, a hidden Markov model (HMM)-based technique is established. That is employing a detector to detect the information of the Markov state and then giving an estimated signal of the Markov state for the filter design. Some $$H_{\infty }$$ performance analysis criteria for filtering error systems and the corresponding HMM-based filter design procedure are given. An improved activation function dividing method (AFDM) is presented for neural networks to reduce the conservatism of the obtained results. The superiority of the improved AFDM and the validity of obtained results are verified by an illustrative example.},
  archive      = {J_NPL},
  author       = {Li, Feng and Zhao, Jianrong and Song, Shuai and Huang, Xia and Shen, Hao},
  doi          = {10.1007/s11063-019-10175-w},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1939-1955},
  shortjournal = {Neural Process. Lett.},
  title        = {$$H_{\infty }$$ filtering for markov jump neural networks subject to hidden-markov mode observation and packet dropouts via an improved activation function dividing method},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Finite-time synchronization of coupled inertial memristive
neural networks with mixed delays via nonlinear feedback control.
<em>NPL</em>, <em>51</em>(2), 1921–1938. (<a
href="https://doi.org/10.1007/s11063-019-10180-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The finite-time synchronization of coupled inertial memristive neural networks (IMNNs) systems is discussed in this paper. Firstly, a mathematical model of IMNNs with time-varying delays is given, then the original system is transformed into a first-order differential equation by selecting a suitable variable substitution. Secondly, by using two different controllers and the definition of the upper right-hand derivative, it can be guaranteed that finite-time and fixed-time synchronization between response system and drive system based on finite time stability and fixed time theory. Finally, two numerical simulations are given to illustrate the effectiveness of the main results.},
  archive      = {J_NPL},
  author       = {Yang, Cuiping and Xiong, Zuoliang and Yang, Tianqing},
  doi          = {10.1007/s11063-019-10180-z},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1921-1938},
  shortjournal = {Neural Process. Lett.},
  title        = {Finite-time synchronization of coupled inertial memristive neural networks with mixed delays via nonlinear feedback control},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Feature enhancement for multi-scale object detection.
<em>NPL</em>, <em>51</em>(2), 1907–1919. (<a
href="https://doi.org/10.1007/s11063-019-10182-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, deep learning has brought great progress in object detection. However, we believe that traditional hand-crafted features may still contain valuable human knowledge complementary to features learned from raw data. Besides, almost all top-performing object detection methods extract features by using backbones originally designed for image classification. The generated features are often highly semantic, which is beneficial to global image classification, but may lose details useful for object localization and recognition under various scales. To alleviate the problems mentioned above, a feature enhancement method is proposed in this paper. Inspired by the success of histograms of oriented gradients in traditional object detection research, we construct feature channels based on oriented gradients as input to convolutional neural networks to capture discriminative local orientations. The oriented gradients and RGB features are stacked as input of network to enhance the input feature representation. For accurate object localization and recognition, we employ dilated convolutions to increase spatial resolutions of output feature maps while maintaining their respective receptive fields. Hierarchical feature maps with different receptive fields are aggregated into the final feature representation for multi-scale object detection without extra upsampling. Experimental results on PASCAL VOC 2007 and 2012 demonstrate superiority of the proposed method compared with state-of-the-art methods for multi-scale object detection.},
  archive      = {J_NPL},
  author       = {Zheng, Huicheng and Chen, Jiajie and Chen, Lvran and Li, Ye and Yan, Zhiwei},
  doi          = {10.1007/s11063-019-10182-x},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1907-1919},
  shortjournal = {Neural Process. Lett.},
  title        = {Feature enhancement for multi-scale object detection},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Memristor crossbar array based ACO for image edge detection.
<em>NPL</em>, <em>51</em>(2), 1891–1905. (<a
href="https://doi.org/10.1007/s11063-019-10179-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Memristor provides an available way to design and deploy swarm intelligence. As a typical swarm intelligence algorithm, ant colony optimization is implemented by the memristor crossbar array to make image edge detection in this paper. Firstly, a non-linear voltage-controlled memristor model with a relaxation term is proposed. Then, an improved ant colony optimization with padding strategy is designed. Thirdly, a memristor crossbar array with external control circuits is designed to implement ant colony optimization for image edge detection, which offers high device density and parallel computing. In the course of ant colony optimization based image edge detection deployed by memristor crossbar array, the threshold to generating edges can be directly chosen as the mean of the final conductance matrix. On the one hand, experiment results show that more delicate edges can be detected by proposed method compared to holistically-nested edge detection based on neural networks. On the other hand, Figure of merit of proposed method is better than that of Sobel operator.},
  archive      = {J_NPL},
  author       = {Yu, Yongbin and Deng, Quanxin and Ren, Liyong and Tashi, Nyima},
  doi          = {10.1007/s11063-019-10179-6},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1891-1905},
  shortjournal = {Neural Process. Lett.},
  title        = {Memristor crossbar array based ACO for image edge detection},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Performance evaluation of a new BP algorithm for a modified
artificial neural network. <em>NPL</em>, <em>51</em>(2), 1869–1889. (<a
href="https://doi.org/10.1007/s11063-019-10172-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a conventional artificial neural model, the nonlinear activation function (AF) follows the weight sum operation. In this paper, the AF is placed before the connecting weights of each artificial neuron and hence modified artificial neural network (MANN) is proposed and the corresponding backpropagation (BP) learning algorithm is derived. Further, the slope of AF which is conventionally fixed during the training phase is adjusted for achieving better and faster training of the multi-layer artificial neural network (MANN). In this case, also both the weights and slope update algorithms are derived. To assess and compare the performance of these two ANN models, standard applications such as classification, nonlinear system identification (direct modeling), nonlinear channel equalization (inverse modeling) are implemented through simulation and compared with that obtained by conventional BP based MANN. The simulation results demonstrate that the adaptive slope based MANN outperforms the fixed slope as well as conventional MANN in terms of three different performance measures such as the number of iterations to converge, mean of the square of residual error and mean absolute deviation.},
  archive      = {J_NPL},
  author       = {Panda, Sashmita and Panda, Ganapati},
  doi          = {10.1007/s11063-019-10172-z},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1869-1889},
  shortjournal = {Neural Process. Lett.},
  title        = {Performance evaluation of a new BP algorithm for a modified artificial neural network},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Global lagrange stability of inertial neutral type neural
networks with mixed time-varying delays. <em>NPL</em>, <em>51</em>(2),
1849–1867. (<a
href="https://doi.org/10.1007/s11063-019-10177-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with the Lagrange stability of inertial neutral type neural networks with mixed time-varying delays. Two different types of activation functions are considered, including bounded and general unbounded activation functions. Under a proper variable transformation, the original inertial system is converted to a first order differential network. Based on Lyapunov method and applying inequality techniques and analytical method, some sufficient criteria are derived to ensure the global Lagrange exponential stability of the addressed neural networks. Moreover, the global exponential attractive sets are established. These results here generalize and improve the earlier publications on inertial neural networks. Finally, some numerical examples with simulations are given to demonstrate the effectiveness of our theoretical results.},
  archive      = {J_NPL},
  author       = {Duan, Liyan and Jian, Jigui},
  doi          = {10.1007/s11063-019-10177-8},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1849-1867},
  shortjournal = {Neural Process. Lett.},
  title        = {Global lagrange stability of inertial neutral type neural networks with mixed time-varying delays},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Lagrange stability for delayed-impulses in discrete-time
cohen–grossberg neural networks with delays. <em>NPL</em>,
<em>51</em>(2), 1835–1848. (<a
href="https://doi.org/10.1007/s11063-020-10190-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the problem of exponential Lagrange stability for delayed-impulses in discrete-time Cohen–Grossberg neural networks (CGNNs) with delays is considered. By establishing a novel convergent difference inequation, combining with inductive method and Lyapunov theory, some sufficient conditions are obtained to ensure the exponential Lagrange stability for delayed-impulses in discrete-time CGNNs. Meanwhile, the exponential convergent domain for network is given. Finally, some examples with their simulations are given to verify the effectiveness of our results.},
  archive      = {J_NPL},
  author       = {Jiang, Wenlin and Li, Liangliang and Tu, Zhengwen and Feng, Yuming},
  doi          = {10.1007/s11063-020-10190-2},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1835-1848},
  shortjournal = {Neural Process. Lett.},
  title        = {Lagrange stability for delayed-impulses in discrete-time Cohen–Grossberg neural networks with delays},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel model predictive runge–kutta neural network
controller for nonlinear MIMO systems. <em>NPL</em>, <em>51</em>(2),
1789–1833. (<a
href="https://doi.org/10.1007/s11063-019-10167-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel model predictive Runge–Kutta neural network (RK-NN) controller based on Runge–Kutta model is proposed for nonlinear MIMO systems. The proposed adaptive controller structure incorporates system model which provides to approximate the K-step ahead future behaviour of the controlled system, nonlinear controller where Runge–Kutta neural network (RK-NN) controller is directly deployed and adjustment mechanism based on Levenberg–Marquardt optimization method so as to optimize the weights of the Runge–Kutta neural network (RK-NN) controller. RBF neural network is employed as constituent network in order to identify the changing rates of the controller dynamics. So, the learning ability of RBF neural network and Runge Kutta integration method are combined in the MIMO nonlinear controller block. The control performance of the proposed MIMO RK-NN controller has been examined via simulations performed on a nonlinear three tank system and Van de Vusse benchmark system for different cases, and the obtained results indicate that the RK-NN controller and Runge–Kutta model achieve good control and modeling performances for nonlinear MIMO dynamical systems.},
  archive      = {J_NPL},
  author       = {Uçak, Kemal},
  doi          = {10.1007/s11063-019-10167-w},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1789-1833},
  shortjournal = {Neural Process. Lett.},
  title        = {A novel model predictive Runge–Kutta neural network controller for nonlinear MIMO systems},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Daily activity feature selection in smart homes based on
pearson correlation coefficient. <em>NPL</em>, <em>51</em>(2),
1771–1787. (<a
href="https://doi.org/10.1007/s11063-019-10185-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the case of a smart home, the ability to recognize daily activities depends primarily on the strategy used for selecting the appropriate features related to these activities. To achieve the goal, this paper presents a daily activity feature selection strategy based on the Pearson Correlation Coefficient. Firstly, a daily activity feature is viewed as a vector in Pearson Correlation Coefficient formula. Secondly, the relation degree between daily activity features is obtained according to weighted Pearson Correlation Coefficient formula. At last, redundant features are removed by the relation degree between daily activity features. Two distinct datasets are adopted to mitigate the effects of the coupling of the dataset used and the sensor configuration. Three different machine learning techniques are employed to evaluate the performance of the proposed approach in activity recognition. The experiment results show that the proposed approach yields higher recognition rates and achieves average improvement F-measures of 1.56% and 2.7%, respectively.},
  archive      = {J_NPL},
  author       = {Liu, Yaqing and Mu, Yong and Chen, Keyu and Li, Yiming and Guo, Jinghuan},
  doi          = {10.1007/s11063-019-10185-8},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1771-1787},
  shortjournal = {Neural Process. Lett.},
  title        = {Daily activity feature selection in smart homes based on pearson correlation coefficient},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). <span
class="math display"><em>S</em><sup><em>p</em></sup></span> -almost
periodic solutions of clifford-valued fuzzy cellular neural networks
with time-varying delays. <em>NPL</em>, <em>51</em>(2), 1749–1769. (<a
href="https://doi.org/10.1007/s11063-019-10176-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider Clifford-valued fuzzy cellular neural networks with time-varying delays. In order to avoid the inconvenience caused by the non-commutativity of the multiplication of Clifford numbers, we first decompose the considered n-dimensional Clifford-valued systems into $$2^{m}n$$-dimensional real-valued systems. Then by using the Banach fixed point theorem and a proof by contradiction, we establish sufficient conditions ensuring the existence, the uniqueness and the global exponential stability of $$S^{p}$$-almost periodic solutions for the considered neural networks. Finally, we give an example to illustrate the effectiveness of the obtained results. Our results are new even when the considered neural networks degenerates to real-valued, complex-valued and quaternion-valued neural networks.},
  archive      = {J_NPL},
  author       = {Shen, Shiping and Li, Yongkun},
  doi          = {10.1007/s11063-019-10176-9},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1749-1769},
  shortjournal = {Neural Process. Lett.},
  title        = {$$S^{p}$$ -almost periodic solutions of clifford-valued fuzzy cellular neural networks with time-varying delays},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Community detection in complex networks using nonnegative
matrix factorization and density-based clustering algorithm.
<em>NPL</em>, <em>51</em>(2), 1731–1748. (<a
href="https://doi.org/10.1007/s11063-019-10170-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection is a critical issue in the field of complex networks. Capable of extracting inherent patterns and structures in high dimensional data, the non-negative matrix factorization (NMF) method has become one of the hottest research topics in community detection recently. However, this method has a significant drawback; most community detection methods using NMF require the number of communities to be preassigned or determined by searching for the best community structure among all candidates. To address the problem, in this paper, we use an improved density peak clustering to obtain the number of cores as the pre-defined parameter of nonnegative matrix factorization. Then we adopt nonnegative double singular value decomposition initialization which can rapidly reduce the approximation error of nonnegative matrix factorization. Finally, we compare and analyze the performance of different algorithms on artificial networks and real-world networks. Experimental results indicate that the proposed method is superior to the state-of-the-art methods.},
  archive      = {J_NPL},
  author       = {Lu, Hong and Zhao, Qinghua and Sang, Xiaoshuang and Lu, Jianfeng},
  doi          = {10.1007/s11063-019-10170-1},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1731-1748},
  shortjournal = {Neural Process. Lett.},
  title        = {Community detection in complex networks using nonnegative matrix factorization and density-based clustering algorithm},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). General and improved five-step discrete-time zeroing neural
dynamics solving linear time-varying matrix equation with unknown
transpose. <em>NPL</em>, <em>51</em>(2), 1715–1730. (<a
href="https://doi.org/10.1007/s11063-019-10181-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a general five-step discrete-time zeroing neural dynamics (DTZND) model is proposed to solve linear time-varying matrix equation with unknown transpose. Specifically, the explicit continuous-time zeroing neural dynamics (CTZND) model is derived from the time-varying matrix equation with unknown transpose via Kronecker product and vectorization technique. Furthermore, a general five-step discretization formula is designed to approximate the first-order derivative of the target point, and the convergence condition is given. Thus, the general five-step DTZND model is obtained by using the general five-step discretization formula to discretize the CTZND model. Theoretical analyses present the stability and convergence of the proposed general five-step DTZND model. Numerical experiment results substantiate that the proposed DTZND model for solving linear time-varying matrix equation is stable and convergent with the theoretically analyzed errors. In addition, the improved DTZND models are provided in terms of accuracy and computational complexity, and verified by numerical experiments.},
  archive      = {J_NPL},
  author       = {Hu, Chaowei and Zhang, Yunong and Kang, Xiangui},
  doi          = {10.1007/s11063-019-10181-y},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1715-1730},
  shortjournal = {Neural Process. Lett.},
  title        = {General and improved five-step discrete-time zeroing neural dynamics solving linear time-varying matrix equation with unknown transpose},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Growing self-organizing maps for nonlinear time-varying
function approximation. <em>NPL</em>, <em>51</em>(2), 1689–1714. (<a
href="https://doi.org/10.1007/s11063-019-10168-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Function approximation may be described as the task of modeling the input-output relation and therefore yielding an estimation of the real output function value. In many domains, an ideal learning algorithm needs to approximate nonlinear time-varying functions from a high-dimensional input space and avoid problems from irrelevant or redundant input data. Therefore, the method has to meet three requirements, namely, it must: allow incremental learning to deal with changing functions and changing input distributions; keep the computational cost low; and achieve accurate estimations. In this paper, we explore different approaches to perform function approximation based on the Local Adaptive Receptive Fields Self-Organizing Map (LARFSOM). Local models are built by calculating between the output associated with the winning node and the difference vector between the input vector and the weight vector. These models are combined by using a weighted sum to yield the final approximate value. The topology is adapted in a self-organizing way, and the weight vectors are adjusted in a modified unsupervised learning algorithm for supervised problems. Experiments were carried out on synthetic and real-world datasets. Experimental results indicate that the proposed approaches perform competitively against Support Vector Regression (SVR) and can improve function approximation accuracy and computational cost against the locally weighted interpolation (LWI), a state-of-the-art interpolating algorithm for self-organizing maps.},
  archive      = {J_NPL},
  author       = {Ferreira, Paulo H. M. and Araújo, Aluízio F. R.},
  doi          = {10.1007/s11063-019-10168-9},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1689-1714},
  shortjournal = {Neural Process. Lett.},
  title        = {Growing self-organizing maps for nonlinear time-varying function approximation},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Generating text sequence images for recognition.
<em>NPL</em>, <em>51</em>(2), 1677–1688. (<a
href="https://doi.org/10.1007/s11063-019-10166-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, methods based on deep learning have dominated the field of text recognition. With a large number of training data, most of them can achieve the state-of-the-art performances. However, it is hard to harvest and label sufficient text sequence images from the real scenes. To mitigate this issue, several methods to synthesize text sequence images were proposed, yet they usually need complicated preceding or follow-up steps. In this work, we present a method which is able to generate infinite training data without any auxiliary pre/post-process. We tackle the generation task as an image-to-image translation one and utilize conditional adversarial networks to produce realistic text sequence images in the light of the semantic ones. Some evaluation metrics are involved to assess our method and the results demonstrate that the caliber of the data is satisfactory. The code and dataset will be publicly available soon.},
  archive      = {J_NPL},
  author       = {Gong, Yanxiang and Deng, Linjie and Ma, Zheng and Xie, Mei},
  doi          = {10.1007/s11063-019-10166-x},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1677-1688},
  shortjournal = {Neural Process. Lett.},
  title        = {Generating text sequence images for recognition},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Exponential lag synchronization and global dissipativity for
delayed fuzzy cohen–grossberg neural networks with discontinuous
activations. <em>NPL</em>, <em>51</em>(2), 1653–1676. (<a
href="https://doi.org/10.1007/s11063-019-10169-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the qualitative behavior of a new class of fuzzy Cohen–Grossberg neural networks with discontinuous neuron activations and mixed delays. Roughly speaking, some novel sufficient conditions are established in order to demonstrate the global dissipativity and the exponential lag synchronization of the considered model by using the theory of Filippov systems and Lyapunov method. Finally, two examples are presented to show the effectiveness of the obtained results.},
  archive      = {J_NPL},
  author       = {Abdelaziz, Meryem and Chérif, Farouk},
  doi          = {10.1007/s11063-019-10169-8},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1653-1676},
  shortjournal = {Neural Process. Lett.},
  title        = {Exponential lag synchronization and global dissipativity for delayed fuzzy Cohen–Grossberg neural networks with discontinuous activations},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Quantitative analysis in delayed fractional-order neural
networks. <em>NPL</em>, <em>51</em>(2), 1631–1651. (<a
href="https://doi.org/10.1007/s11063-019-10161-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper mainly investigates the influence of self-connection delay on bifurcation in a fractional neural network. The bifurcation criteria for the proposed systems with self-connection delay or without self-connection delay is figured out using time delay as a bifurcation parameter, respectively. The effects of self-connection delay on bifurcation in a fractional neural network are ascertained in this paper. Comparative analysis indicates that the stability performance of the proposed fractional neural networks is overly undermined by self-connection delay, which cannot be disregarded. In addition, the impact of fractional order on the bifurcation point is revealed. To highlight the proposed original results, two numerical examples are finally presented.},
  archive      = {J_NPL},
  author       = {Yuan, Jun and Huang, Chengdai},
  doi          = {10.1007/s11063-019-10161-2},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1631-1651},
  shortjournal = {Neural Process. Lett.},
  title        = {Quantitative analysis in delayed fractional-order neural networks},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A design strategy for the efficient implementation of random
basis neural networks on resource-constrained devices. <em>NPL</em>,
<em>51</em>(2), 1611–1629. (<a
href="https://doi.org/10.1007/s11063-019-10165-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The deployment of connectionist models on resource-constrained, low-power embedded systems brings about specific implementation issues. The paper presents a design strategy, aimed at low-end reconfigurable devices, for implementing the prediction operation supported by a single hidden-layer feedforward neural network (SLFN). The paper first shows that a considerable efficiency can be obtained when hard-limiter thresholding operators support the activation functions of the neurons. Secondly, the analysis highlights the advantages of using random basis networks, thanks to their limited memory requirements. Finally, the paper presents a pair of different architectural approaches to the effective support of SLFNs on CPLDs and low-end FPGAs. The alternatives differ in the specific trade-off strategy between area utilization and latency. Experiments confirm the effectiveness of both schemes, yielding a pair of viable implementation options for satisfying the respective constraints, namely effective area utilization or low latency.},
  archive      = {J_NPL},
  author       = {Ragusa, Edoardo and Gianoglio, Christian and Zunino, Rodolfo and Gastaldo, Paolo},
  doi          = {10.1007/s11063-019-10165-y},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1611-1629},
  shortjournal = {Neural Process. Lett.},
  title        = {A design strategy for the efficient implementation of random basis neural networks on resource-constrained devices},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Maintenance personnel detection and analysis using mask-RCNN
optimization on power grid monitoring video. <em>NPL</em>,
<em>51</em>(2), 1599–1610. (<a
href="https://doi.org/10.1007/s11063-019-10159-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep learning theory and applications have been grown rapidly. Its application aspects has been widely extended to medical care, unmanned driving, intelligent monitoring and other fields. In this paper, we focus on detecting and analyzing the movements of maintenance personnel based on power grid surveillance videos by using MASK-RCNN. Firstly, we detect the maintenance personnel in the video data using optimized MASK-RCNN network. Then, we plot the corresponding personnel path image using segmentation and centroid detection, which can accurately count the personnel trajectory with in-and-out information. Secondly, this paper introduce a tracking-learning-detection algorithm to further track and analyze interested feature events of power grid video. The experimental results show that our algorithm can accurately detect multiple personnel and obtain the key features of the video contents.},
  archive      = {J_NPL},
  author       = {Chen, Tong and Jiang, Ying and Jian, Wang and Qiu, Lanxin and Liu, Huan and Xiao, Zhaolin},
  doi          = {10.1007/s11063-019-10159-w},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1599-1610},
  shortjournal = {Neural Process. Lett.},
  title        = {Maintenance personnel detection and analysis using mask-RCNN optimization on power grid monitoring video},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-parallel extreme learning machine with excitatory and
inhibitory neurons for regression. <em>NPL</em>, <em>51</em>(2),
1579–1597. (<a
href="https://doi.org/10.1007/s11063-019-10160-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared with traditional neural networks, extreme learning machine (ELM) shows outstanding performances on speed and computation. Aiming at the problems that ELM needs more hidden layer neurons and meaningful features of data sometimes are sacrificed in order to improve the training speed, a novelty network multi-parallel extreme learning machine with excitatory and inhibitory neurons (MEI-ELM) is proposed based on the idea of biological neurons. In MEI-ELM, (1) A parallel system is introduced to make it more compact and reduce the number of hidden layer neurons. (2) The property of excitatory and inhibitory of biological neuronal for data processing is introduced to improve its performance. Through applying MEI-ELM, ELM, Fast Learning Network (FLN) and Fast Learning Network with Parallel Layer Perceptrons (PLP-FLN) to 11 classical regression problems, it can be obtained that MEI-ELM performs much better than the other methods in generalization and stability.},
  archive      = {J_NPL},
  author       = {Li, Guoqiang and Zou, Junnan},
  doi          = {10.1007/s11063-019-10160-3},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1579-1597},
  shortjournal = {Neural Process. Lett.},
  title        = {Multi-parallel extreme learning machine with excitatory and inhibitory neurons for regression},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Global attractor of reaction–diffusion gene regulatory
networks with s-type delay. <em>NPL</em>, <em>51</em>(2), 1557–1577. (<a
href="https://doi.org/10.1007/s11063-019-10164-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the existence of the global attractor for the reaction–diffusion gene regulatory networks with s-type delay. Firstly, two Hanalay inequalities are proposed and proved, then the uniform boundedness theorem is proved by using these inequalities and semigroup theory and functional analysis technique, the operator splitting technique based on the superposition principle is also utilized to deal with the asymptotic compact of the semigroup. Then some sufficient conditions on existence of global attractor are established, which are easily verifiable and have a wider application range. At last, two examples are discussed to validate the effectiveness of our results. Moreover, the simulation is given by using Matlab.},
  archive      = {J_NPL},
  author       = {Liang, Xiao and Zhuo, Xianglai and Wang, Ruili},
  doi          = {10.1007/s11063-019-10164-z},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1557-1577},
  shortjournal = {Neural Process. Lett.},
  title        = {Global attractor of Reaction–Diffusion gene regulatory networks with S-type delay},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The optimization of synchronization control parameters for
fractional-order delayed memristive neural networks using SIWPSO.
<em>NPL</em>, <em>51</em>(2), 1541–1556. (<a
href="https://doi.org/10.1007/s11063-019-10157-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper mainly deals with the optimization of synchronization for fractional-order memristive neural networks (FOMNNs) with a time delay. Based on synchronization conditions, an optimization model for control parameters is designed and computed. It’s significative to design an appropriate controller which can synchronize the drive FOMNNs and response FOMNNs. Based on the proposed controller, some synchronization conditions of FOMNNS can be obtained with the help of the linear matrix inequality, along with fractional-order Lyapunov methods and matrix analysis. The optimal model of control parameters includes a target function and some constraints. The target function is the minimal sum of control energy and integral square error index. The constraint conditions choose the sufficient conditions for synchronization of FOMNNs. The optimization model is difficult to compute but can be solved by means of the stochastic inertia weight particle swarm optimization algorithm. A simulation is provided to verify the validity of the proposed theoretical results.},
  archive      = {J_NPL},
  author       = {Chang, Qi and Hu, Aihua and Yang, Yongqing and Li, Li},
  doi          = {10.1007/s11063-019-10157-y},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1541-1556},
  shortjournal = {Neural Process. Lett.},
  title        = {The optimization of synchronization control parameters for fractional-order delayed memristive neural networks using SIWPSO},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Attention-based generative adversarial network for
semi-supervised image classification. <em>NPL</em>, <em>51</em>(2),
1527–1540. (<a
href="https://doi.org/10.1007/s11063-019-10158-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised image classification is one of the areas of interest within the computer vision, which can build better classifiers using a few labeled images and plenty of unlabeled images. Recently, semi-supervised image classification methods based on the generative adversarial network (GAN) get promising results. In this paper, we introduce a self-attention mechanism to propose an attention-based GAN for semi-supervised image classification, which can capture global dependencies and adaptively extract important information. Furthermore, we apply spectral normalization, which can stabilize the training of attention-based GAN. We also adopt manifold regularization as an additional regularization term so that we can make the most of the unlabeled images. We test the proposed method on SVHN and CIFAR-10 datasets. The experimental results show that the proposed method is comparable with the state-of-the-art GAN-based semi-supervised image classification methods.},
  archive      = {J_NPL},
  author       = {Xiang, Xuezhi and Yu, Zeting and Lv, Ning and Kong, Xiangdong and Saddik, Abdulmotaleb El},
  doi          = {10.1007/s11063-019-10158-x},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1527-1540},
  shortjournal = {Neural Process. Lett.},
  title        = {Attention-based generative adversarial network for semi-supervised image classification},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Finite-time mittag-leffler stability of fractional-order
quaternion-valued memristive neural networks with impulses.
<em>NPL</em>, <em>51</em>(2), 1485–1526. (<a
href="https://doi.org/10.1007/s11063-019-10154-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The finite-time Mittag-Leffler stability for fractional-order quaternion-valued memristive neural networks (FQMNNs) with impulsive effect is studied here. A new mathematical expression of the quaternion-value memductance (memristance) is proposed according to the feature of the quaternion-valued memristive and a new class of FQMNNs is designed. In quaternion field, by using the framework of Filippov solutions as well as differential inclusion theoretical analysis, suitable Lyapunov-functional and some fractional inequality techniques, the existence of unique equilibrium point and Mittag-Leffler stability in finite time analysis for considered impulsive FQMNNs have been established with the order $$0&lt;\beta &lt;1$$. Then, for the fractional order $$\beta $$ satisfying $$1&lt;\beta &lt;2$$ and by ignoring the impulsive effects, a new sufficient criterion are given to ensure the finite time stability of considered new FQMNNs system by the employment of Laplace transform, Mittag-Leffler function and generalized Gronwall inequality. Furthermore, the asymptotic stability of such system with order $$1&lt;\beta &lt;2$$ have been investigated. Ultimately, the accuracy and validity of obtained finite time stability criteria are supported by two numerical examples.},
  archive      = {J_NPL},
  author       = {Pratap, A. and Raja, R. and Alzabut, J. and Dianavinnarasi, J. and Cao, J. and Rajchakit, G.},
  doi          = {10.1007/s11063-019-10154-1},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1485-1526},
  shortjournal = {Neural Process. Lett.},
  title        = {Finite-time mittag-leffler stability of fractional-order quaternion-valued memristive neural networks with impulses},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Synchronization control of quaternion-valued neural networks
with parameter uncertainties. <em>NPL</em>, <em>51</em>(2), 1465–1484.
(<a href="https://doi.org/10.1007/s11063-019-10153-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, by starting from basic quaternion algebra properties and algorithms, we develop a comprehensive set of properties to ensure the uncertain quaternion-valued neural networks can receive synchronization and quasi-synchronization goals. By endowing the classic Lyapunov technique, several sufficient criteria for the synchronization and quasi-synchronization analysis of the addressed model are proposed by means of two simple and rigorous control strategies. Particularly, lexicographical ordering approach is proposed in this paper, which can be employed to determine the “magnitude” of two different quaternion-valued. Finally, we have numerical evidences that the mathematical model and the conclusions presented are validate.},
  archive      = {J_NPL},
  author       = {Wei, Hongzhi and Wu, Baowei and Li, Ruoxia},
  doi          = {10.1007/s11063-019-10153-2},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1465-1484},
  shortjournal = {Neural Process. Lett.},
  title        = {Synchronization control of quaternion-valued neural networks with parameter uncertainties},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Semi-supervised fuzzy min–max neural network for data
classification. <em>NPL</em>, <em>51</em>(2), 1445–1464. (<a
href="https://doi.org/10.1007/s11063-019-10142-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning from the lack of labeled data is a challenging task which often limits the performance of the classifier. Since the unlabeled data is easy to obtain, using both of the labeled and unlabeled data in the training process provide a way to solve this problem. In this paper, a semi-supervised classification method based on fuzzy min–max neural network (SS-FMM) is proposed. In SS-FMM, the network has been modified for handling both of the labeled and unlabeled data. In addition, the staged feedback process is designed to modify the network structure of the traditional fuzzy min–max neural network. A staged-threshold function designed in SS-FMM, the hyperbox pruning process and the hyperbox relabeling process can be started dynamically. Moreover, the hyperboxes relabeling process and the hyperbox pruning process are designed to maximize using the unlabeled data and control the amount of the hyperboxes. In order to testify the effectiveness of SS-FMM, various experiments are carried out with several benchmark data sets. In addition, SS-FMM has been applied on the internal inspection data of our system. The results show that SS-FMMM has got good performance.},
  archive      = {J_NPL},
  author       = {Liu, Jinhai and Ma, Yanjuan and Qu, Fuming and Zang, Dong},
  doi          = {10.1007/s11063-019-10142-5},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1445-1464},
  shortjournal = {Neural Process. Lett.},
  title        = {Semi-supervised fuzzy Min–Max neural network for data classification},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Joint robust transfer metric and adaptive transfer function
learning. <em>NPL</em>, <em>51</em>(2), 1411–1443. (<a
href="https://doi.org/10.1007/s11063-019-10152-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding the right distance metric is one of the main challenges in machine learning and computer vision procedures. On the other hand, adapting a good classifier with the learned metric has the same importance. In traditional machine learning problems both training and test data come from a same distribution, however it is not common for many real-world data sets. Therefore, they suffer from poor performance where there is inconsistency and dissimilarity between the training (source) data and the test (target) data domain distributions. In this paper, we present a method to overcome this issue efficiently. To this end, a projection matrix is found by learning a cross-domain metric to map the samples of the source and target datasets to a new feature space where the distance of two domains is reduced by utilizing marginal and conditional adaptation terms. Moreover, the metric becomes powerful by employing marginalized de-noising and low-rank strategies. Also, parallel to learning the projection matrix, an adaptive decision function is learned by minimizing the empirical risk while maximizing the consistency of the manifold structure of data with the classifier. In addition, a distribution adaptation term is incorporated into the learning procedure of the classifier to lessen the distance between two domains by minimizing it. The validity of the proposed technique is tested on different image categorization datasets and the experimental results demonstrate that it performs well compared to the state-of-the-art methods.},
  archive      = {J_NPL},
  author       = {Azarbarzin, Samaneh and Afsari, Fatemeh},
  doi          = {10.1007/s11063-019-10152-3},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1411-1443},
  shortjournal = {Neural Process. Lett.},
  title        = {Joint robust transfer metric and adaptive transfer function learning},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Parameters sharing in residual neural networks.
<em>NPL</em>, <em>51</em>(2), 1393–1410. (<a
href="https://doi.org/10.1007/s11063-019-10143-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNN) have achieved great success in machine learning due to their powerful ability to learn and present knowledge. However, models of such DNN often have massive trainable parameters, which lead to big resource burden in practice. As a result, reducing the amount of parameters and preserving its competitive performance are always critical tasks in the field of DNN. In this paper, we focused on one type of convolution neural network that has many repeated or same-structure convolutional layers. Residual net and its variants are widely used, making the deeper model easy to train. One type block of such a model contains two convolutional layers, and each block commonly has two trainable parameter layers. However, we used only one layer of trainable parameters in the block, which means that the two convolutional layers in one block shared one layer of trainable parameters. We performed extensive experiments for different architectures of the Residual Net with trainable parameter sharing on the CIFAR-10, CIFAR-100, and ImageNet datasets. We found that the model with trainable parameter sharing can obtain fewer errors on the training datasets and had a very close recognition accuracy (within 0.5%), compared to the original models. The parameters of the new model were reduced by more than 1/3 of the total of the original.},
  archive      = {J_NPL},
  author       = {Dai, Dawei and Yu, Liping and Wei, Hui},
  doi          = {10.1007/s11063-019-10143-4},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1393-1410},
  shortjournal = {Neural Process. Lett.},
  title        = {Parameters sharing in residual neural networks},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Finite-time <span
class="math display"><em>L</em><sub>∞</sub></span> performance state
estimation of recurrent neural networks with sampled-data signals.
<em>NPL</em>, <em>51</em>(2), 1379–1392. (<a
href="https://doi.org/10.1007/s11063-019-10114-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper, by proposing a sampled-data control scheme, we investigate the finite-time $$L_\infty $$ performance state estimation of recurrent neural networks. By constructing a novel Lyapunov functional, new stability and stabilization conditions are derived. By utilizing integral inequality techniques, sufficient LMI conditions are derived to ensure the finite-time stability of considered neural networks. Furthermore, finite-time observer gain analysis of recurrent neural networks is set up to measure its disturbance tolerance capability in the fixed time interval. Numerical examples are given to verify the effectiveness of the proposed approach.},
  archive      = {J_NPL},
  author       = {Gunasekaran, N. and Ali, M. Syed and Pavithra, S.},
  doi          = {10.1007/s11063-019-10114-9},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1379-1392},
  shortjournal = {Neural Process. Lett.},
  title        = {Finite-time $$L_\infty $$ performance state estimation of recurrent neural networks with sampled-data signals},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Almost automorphic solutions in distribution sense of
quaternion-valued stochastic recurrent neural networks with mixed
time-varying delays. <em>NPL</em>, <em>51</em>(2), 1353–1377. (<a
href="https://doi.org/10.1007/s11063-019-10151-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider quaternion-valued stochastic recurrent neural networks with mixed time-varying delays by direct method. Base on the Banach fixed point theorem and stochastic analysis techniques, we obtain some sufficient conditions for the existence and global exponential stability of almost automorphic solutions in distribution sense for the neural networks. As special cases of our results, we also obtain the results about the existence and global exponential stability of almost automorphic solutions in distribution sense for complex-valued and real-valued stochastic neural networks. All of these results are new. Finally, we give numerical examples and simulations to illustrate the feasibility of our results.},
  archive      = {J_NPL},
  author       = {Li, Yongkun and Meng, Xiaofang},
  doi          = {10.1007/s11063-019-10151-4},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1353-1377},
  shortjournal = {Neural Process. Lett.},
  title        = {Almost automorphic solutions in distribution sense of quaternion-valued stochastic recurrent neural networks with mixed time-varying delays},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fast synchronization of complex networks via aperiodically
intermittent sliding mode control. <em>NPL</em>, <em>51</em>(2),
1331–1352. (<a
href="https://doi.org/10.1007/s11063-019-10145-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the literature, a lot of work focused on studying intermittent control problems via feedback control strategy. No study on the intermittent control problems via sliding mode control method has been reported so far. This paper studies the problem of fast synchronization between two complex dynamical networks via aperiodically intermittent control and sliding mode control. In order to achieve fast synchronization of complex dynamical networks by using aperiodically intermittent sliding mode controller, new differential inequalities are derived firstly. After that, some sufficient finite-time synchronization criteria and finite-time achieving slide mode surface are obtained based on finite-time stability theory, aperiodically intermittent sliding mode control technique and constructing Lyapunov function. Finally, an example is provided to verify the effectiveness of the proposed theoretical methods.},
  archive      = {J_NPL},
  author       = {Fan, Yihan and Mei, Jun and Liu, Hongmei and Fan, Yuling and Liu, Fuxiang and Zhang, Yanjuan},
  doi          = {10.1007/s11063-019-10145-2},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1331-1352},
  shortjournal = {Neural Process. Lett.},
  title        = {Fast synchronization of complex networks via aperiodically intermittent sliding mode control},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Complex varying-parameter zhang neural networks for
computing core and core-EP inverse. <em>NPL</em>, <em>51</em>(2),
1299–1329. (<a
href="https://doi.org/10.1007/s11063-019-10141-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An improved complex varying-parameter Zhang neural network (CVPZNN) for computing outer inverses is established in this paper. As a consequence, three types of complex Zhang functions (ZFs) which are used for computing the time-varying core-EP inverse and core inverse are given. The convergence rate of the proposed complex varying-parameter Zhang neural networks (CVPZNNs) is accelerated. The super-exponential performance of the proposed CVPZNNs with linear activation is proved. Also, the upper bounds of a finite time convergence which correspond to the proposed CVPZNN with underlying Li and tunable activation functions are estimated. The simulation results, which relate the CVPZNNs with different activation functions, are presented.},
  archive      = {J_NPL},
  author       = {Zhou, Mengmeng and Chen, Jianlong and Stanimirović, Predrag S. and Katsikis, Vasilios N. and Ma, Haifeng},
  doi          = {10.1007/s11063-019-10141-6},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1299-1329},
  shortjournal = {Neural Process. Lett.},
  title        = {Complex varying-parameter zhang neural networks for computing core and core-EP inverse},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). DropFilterR: A novel regularization method for learning
convolutional neural networks. <em>NPL</em>, <em>51</em>(2), 1285–1298.
(<a href="https://doi.org/10.1007/s11063-019-10147-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The past few years have witnessed the fast development of regularization methods for deep learning models such as fully-connected deep neural networks (DNNs) and convolutional neural networks (CNNs). Part of previous methods mainly consider to drop features from input data and hidden layers, such as Dropout, Cutout and DropBlocks. DropConnect select to drop connections between fully-connected layers. By randomly discard some features or connections, the above mentioned methods relieve the overfitting problem and improve the performance of neural networks. In this paper, we proposed a novel regularization methods, namely DropFilterR, for the learning of CNNs. The basic idea of DropFilterR is to relax the rule of weight-sharing in CNNs by randomly drop elements in convolution filters. Specifically, we drop different elements in convolution filters along with their moving on input feature maps. Moreover, we may apply random drop rate to further increase the randomness of the proposed method. Also, we find a suitable way to accelerate the computation for DropFilterR based on theoretical analysis. Experimental results on several widely-used image databases such as MNIST, CIFAR-10 and Pascal VOC 2012 show that using DropFilterR improves performance on image classification tasks.},
  archive      = {J_NPL},
  author       = {Pan, Hengyue and Niu, Xin and Li, Rongchun and Shen, Siqi and Dou, Yong},
  doi          = {10.1007/s11063-019-10147-0},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1285-1298},
  shortjournal = {Neural Process. Lett.},
  title        = {DropFilterR: A novel regularization method for learning convolutional neural networks},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stability analysis on cohen–grossberg neural networks with
saturated impulse inputs. <em>NPL</em>, <em>51</em>(2), 1265–1283. (<a
href="https://doi.org/10.1007/s11063-019-10146-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to analyze the stability of Cohen–Grossberg neural networks with saturated impulse inputs. By using the method of Lyapunov functions, convex analysis and matrix inequality, some sufficient conditions are obtained to ensure the stability of the Cohen–Grossberg networks with saturated impulse inputs, including full state constraints and partial state constraints. And some conservative corollaries are obtained. In addition, the fixed time-delay network with fixed impulsive inputs is analyzed by the similar method. Meanwhile, the effectiveness and validity are verified by some numerical examples.},
  archive      = {J_NPL},
  author       = {Xie, Renyi and Li, Chuandong},
  doi          = {10.1007/s11063-019-10146-1},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1265-1283},
  shortjournal = {Neural Process. Lett.},
  title        = {Stability analysis on Cohen–Grossberg neural networks with saturated impulse inputs},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A feature selection algorithm based on equal interval
division and minimal-redundancy–maximal-relevance. <em>NPL</em>,
<em>51</em>(2), 1237–1263. (<a
href="https://doi.org/10.1007/s11063-019-10144-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Minimal-redundancy–maximal-relevance (mRMR) algorithm is a typical feature selection algorithm. To select the feature which has minimal redundancy with the selected features and maximal relevance with the class label, the objective function of mRMR subtracts the average value of mutual information between features from mutual information between features and the class label, and selects the feature with the maximum difference. However, the problem is that the feature with the maximum difference is not always the feature with minimal redundancy maximal relevance. To solve the problem, the objective function of mRMR is first analyzed and a constraint condition that determines whether the objective function can guarantee the effectiveness of the selected features is achieved. Then, for the case where the objective function is not accurate, an idea of equal interval division is proposed and combined with ranking to process the interval of mutual information between features and the class label, and that of the average value of mutual information between features. Finally, a feature selection algorithm based on equal interval division and minimal-redundancy–maximal-relevance (EID–mRMR) is proposed. To validate the performance of EID–mRMR, we compare it with several incremental feature selection algorithms based on mutual information and other feature selection algorithms. Experimental results demonstrate that the EID–mRMR algorithm can achieve better feature selection performance.},
  archive      = {J_NPL},
  author       = {Gu, Xiangyuan and Guo, Jichang and Xiao, Lijun and Ming, Tao and Li, Chongyi},
  doi          = {10.1007/s11063-019-10144-3},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1237-1263},
  shortjournal = {Neural Process. Lett.},
  title        = {A feature selection algorithm based on equal interval division and minimal-Redundancy–Maximal-relevance},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Compressive sensing of multichannel EEG signals based on
graph fourier transform and cosparsity. <em>NPL</em>, <em>51</em>(2),
1227–1236. (<a
href="https://doi.org/10.1007/s11063-019-10150-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cosparsity as a useful prior has been extensively applied in accurate compressive sensing (CS) recovery of multichannel electroencephalogram (EEG) signals from only a few measurements. Latest studies proved that exploiting cosparsity and channel correlation in a unified framework can obtain accurate recovery results. However, all these methods ignore the adjacent relationship between the real physical electrodes and exploit the inaccurate channel correlation. Another problem is that most methods employ convex regularizations to exploit cosparsity and channel correlation, which cannot obtain competitive results. In this paper, a novel graph Fourier transform and nonconvex optimization (GFTN)-based method is proposed to enforce inherent correlation across different channels and cosparsity. Alternative direction method of multipliers is used to solve the resulting nonconvex optimization problem. Experiments show that GFTN can remarkably improve the performance of CS recovery for multichannel EEG signals.},
  archive      = {J_NPL},
  author       = {Zou, Xiuming and Feng, Lei and Sun, Huaijiang},
  doi          = {10.1007/s11063-019-10150-5},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1227-1236},
  shortjournal = {Neural Process. Lett.},
  title        = {Compressive sensing of multichannel EEG signals based on graph fourier transform and cosparsity},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Piecewise pseudo almost-periodic solutions of impulsive
fuzzy cellular neural networks with mixed delays. <em>NPL</em>,
<em>51</em>(2), 1201–1225. (<a
href="https://doi.org/10.1007/s11063-019-10130-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article examines the existence of the unique piecewise pseudo almost periodic for impulsive fuzzy cellular neural networks by using the contraction mapping principle and piecewise pseudo almost periodic function theory. Further, sufficient certain conditions for their global exponential stability are produced through the use of differential inequality and generalized Gronwall–Bellman inequality. Our results are new and complement some previously known ones. Two examples and their numerical simulations are performed to ensure our theoretical results.},
  archive      = {J_NPL},
  author       = {Aouiti, Chaouki and Ben Gharbia, Imen},
  doi          = {10.1007/s11063-019-10130-9},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1201-1225},
  shortjournal = {Neural Process. Lett.},
  title        = {Piecewise pseudo almost-periodic solutions of impulsive fuzzy cellular neural networks with mixed delays},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bi-directional LSTM model with symptoms-frequency position
attention for question answering system in medical domain. <em>NPL</em>,
<em>51</em>(2), 1185–1199. (<a
href="https://doi.org/10.1007/s11063-019-10136-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online medical intelligent question answering system plays an increasingly important role as a supplement of the traditional medical service systems. The purpose is to provide quick and concise feedback on users’ questions through natural language. The technical challenges mainly lie in symptom semantic understanding and representation of users’ description. Although the performance of phrase-level and numerous attention models have been improved, the lexical gap and position information are not emphasized enough. This paper combines word2vec and the Chinese Ci-Lin [it is a dictionary that plays an auxiliary role in word2vec where processing Chinese (https://www.ltp-cloud.com/download)] to propose synonyms-subject replacement mechanism (i.e., map common words as kernel words) and realize the normalization of the semantic representation; Meanwhile, based on the bi-directional LSTM model, this paper introduces a method of the combination of adaptive weight assignment techniques and positional context, enhancing attention to the typical symptoms of the disease. More attention weight is given to the neighboring words and propose the Bi-directional Long Short Term Memory Model with Symptoms-Frequency Position Attention (BLSTM-SFPA). The good performance of the BLSTM-SFPA model has been demonstrated in comparative experiments on the medical field dataset (MED-QA and GD-QA).},
  archive      = {J_NPL},
  author       = {Bi, Mingwen and Zhang, Qingchuan and Zuo, Min and Xu, Zelong and Jin, Qingyu},
  doi          = {10.1007/s11063-019-10136-3},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1185-1199},
  shortjournal = {Neural Process. Lett.},
  title        = {Bi-directional LSTM model with symptoms-frequency position attention for question answering system in medical domain},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Intelligent fault diagnosis of rolling bearing using
adaptive deep gated recurrent unit. <em>NPL</em>, <em>51</em>(2),
1165–1184. (<a
href="https://doi.org/10.1007/s11063-019-10137-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rolling bearing plays a significant part in enhancing the reliability and security of locomotive. Therefore, how to accurately and automatically identify the rolling bearing faults is becoming more and more urgent. For this purpose, an adaptive rolling bearing fault diagnosis method is proposed in this paper. Firstly, deep gated recurrent unit is constructed to effectively learn the features of bearing vibration signals. Secondly, artificial fish swarm algorithm is applied to obtain the key parameters of deep gated recurrent unit. Finally, extreme learning machine is used to accurately classify the learned features and provide final diagnosis result. The proposed method is verified by the measured locomotive bearing vibration signals and the results indicate the feature learning ability of deep gated recurrent unit is powerful and the proposed method achieves more accurate and robust performance than other diagnosis methods.},
  archive      = {J_NPL},
  author       = {Zhao, Ke and Shao, Haidong},
  doi          = {10.1007/s11063-019-10137-2},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1165-1184},
  shortjournal = {Neural Process. Lett.},
  title        = {Intelligent fault diagnosis of rolling bearing using adaptive deep gated recurrent unit},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Localization approach for tracking the mobile nodes using FA
based ANN in subterranean wireless sensor networks. <em>NPL</em>,
<em>51</em>(2), 1145–1164. (<a
href="https://doi.org/10.1007/s11063-019-10128-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Localization is an essential approach in the branch of wireless sensor networks that have been introduced crucial research interest in academic circles and research association. Main aim is to create the localization scheme to enhance the localization accuracy. With the aim is to support long battery life for network devices with low rate, low power consumption and minimum resource requirements. The ZigBee network formation is carried out in the proposed model. The position of the mobile node is evaluated depend upon received signal strength indicator by means of firefly algorithm based artificial neural network (FA-ANN) technique. RSSI data for mobile points are calculated in advance and they maintained in fingerprint database. The finding phase size and principal component analysis is calculated for reducing the size of RSSI fingerprints. The affinity propagation clustering technique is affiliated to decrease the higher position error and improve the effectiveness of the location prediction. The proposed trained FA neural network is based on the clustered RSSI value for accurate localization. Finally, trained FA based neural network is utilized to find the accurate position of the mobile node with minimal consumption of mobile node energy. Thus the hybrid approach, the localization error is reduced and node prediction is achieved in a faster rate. The implementation output of the presented system shows that can be provide localization accuracy of 95% and significantly improves the prediction speed in terms of minimum location time.},
  archive      = {J_NPL},
  author       = {Rama, P. and Murugan, S.},
  doi          = {10.1007/s11063-019-10128-3},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1145-1164},
  shortjournal = {Neural Process. Lett.},
  title        = {Localization approach for tracking the mobile nodes using FA based ANN in subterranean wireless sensor networks},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Neural network-based hybrid position/force tracking control
for robotic systems without velocity measurement. <em>NPL</em>,
<em>51</em>(2), 1125–1144. (<a
href="https://doi.org/10.1007/s11063-019-10138-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a hybrid position/force tracking control scheme based on neural network observer is proposed for robotic systems with uncertain parameters and external disturbances. First, an observer based on neural network is designed to estimate joint velocities. Then, a neural network-based adaptive hybrid position/force controller is proposed based on the observed joint velocities. By using strict positive real method and Lyapunov stability theory, it is proved that all the signals of the closed-loop system are ultimately uniformly bounded. Finally, the simulation tests on a two-link manipulator are conducted. The simulation results show the feasibility and effectiveness of the control scheme.},
  archive      = {J_NPL},
  author       = {Peng, Jinzhu and Ding, Shuai and Yang, Zeqi and Zhang, Fangfang},
  doi          = {10.1007/s11063-019-10138-1},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1125-1144},
  shortjournal = {Neural Process. Lett.},
  title        = {Neural network-based hybrid Position/Force tracking control for robotic systems without velocity measurement},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mutual improvement between temporal ensembling and virtual
adversarial training. <em>NPL</em>, <em>51</em>(2), 1111–1124. (<a
href="https://doi.org/10.1007/s11063-019-10132-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The research of semi-supervised learning (SSL) is of great significance because it is very expensive to collect a large quantity of data with labels in some fields. Two recent deep learning-based SSL algorithms, temporal ensembling and virtual adversarial training (VAT), have achieved state-of-the-art accuracy in some classical SSL tasks, while both of them have shortcomings. Because of simply adding random noise to training data, temporal ensembling is not fully utilized. In addition, VAT has considerable time costs because there are two inferences in each epoch for unlabeled samples. In this paper, we propose the use of virtual adversarial perturbations (VAP) in temporal ensembling rather than random noises to improve performance. Moreover, we also find that reusing VAP can accelerate the training process of VAT without losing obvious accuracy. The two methods are validated on MNIST, FashionMNIST and SVHN.},
  archive      = {J_NPL},
  author       = {Zhou, Wei and Lian, Cheng and Zeng, Zhigang and Su, Yixin},
  doi          = {10.1007/s11063-019-10132-7},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1111-1124},
  shortjournal = {Neural Process. Lett.},
  title        = {Mutual improvement between temporal ensembling and virtual adversarial training},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A smoothing algorithm with constant learning rate for
training two kinds of fuzzy neural networks and its convergence.
<em>NPL</em>, <em>51</em>(2), 1093–1109. (<a
href="https://doi.org/10.1007/s11063-019-10135-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a smoothing algorithm with constant learning rate is presented for training two kinds of fuzzy neural networks (FNNs): max-product and max-min FNNs. Some weak and strong convergence results for the algorithm are provided with the error function monotonically decreasing, its gradient going to zero, and weight sequence tending to a fixed value during the iteration. Furthermore, conditions for the constant learning rate are specified to guarantee the convergence. Finally, three numerical examples are given to illustrate the feasibility and efficiency of the algorithm and to support the theoretical findings.},
  archive      = {J_NPL},
  author       = {Li, Long and Qiao, Zhijun and Long, Zuqiang},
  doi          = {10.1007/s11063-019-10135-4},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1093-1109},
  shortjournal = {Neural Process. Lett.},
  title        = {A smoothing algorithm with constant learning rate for training two kinds of fuzzy neural networks and its convergence},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-layer adaptive feature fusion for semantic
segmentation. <em>NPL</em>, <em>51</em>(2), 1081–1092. (<a
href="https://doi.org/10.1007/s11063-019-10129-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-layer feature fusion is a very important strategy for semantic segmentation, as a single-layer feature is usually unable to make an accurate prediction on every pixel. However, most current methods adopt direct summing or channel concatenation on multi-layer features, lacking of consideration of the distinction and complementarity between them. To explore their respective importance and to achieve an appropriate fusion on each pixel, in this paper, we propose a novel multi-layer adaptive feature fusion method for semantic segmentation, which is based on attention mechanism. Specifically, our method encourages the network to learn the importance of features from different layer according to the content of input image and the specific capability of each layer of feature, expressed in the form of weight map. By pixel-wisely multiplying the features with their corresponding weight maps, we can change the response values proportionally at each pixel and get several weighted features. Finally, the weighted features are summed up to obtain the highly fused feature for discrimination. A series of comparative experiments are carried out on two public datasets, PASCAL VOC 2012 and PASCAL-Person-Part, which successfully prove the effectiveness of our method. Furthermore, we visualize the weight maps of the multi-layer features to facilitate an intuitive understanding of their importance at different location.},
  archive      = {J_NPL},
  author       = {Chen, Yizhen and Hu, Haifeng},
  doi          = {10.1007/s11063-019-10129-2},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1081-1092},
  shortjournal = {Neural Process. Lett.},
  title        = {Multi-layer adaptive feature fusion for semantic segmentation},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Image set-oriented dual linear discriminant regression
classification and its kernel extension. <em>NPL</em>, <em>51</em>(2),
1061–1079. (<a
href="https://doi.org/10.1007/s11063-019-10133-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Along with the rapid development of computer and image processing technology, it is definitely convenient to obtain various images for subjects, which can be more robust to classification as more feature information is contained. However, how to effectively exploit the rich discriminative information within image sets is the key problem. In this paper, based on the concept of dual linear regression classification method for image set classification, we propose a novel discriminative framework to exploit the superiority of discriminant regression mechanism. We aim to learn a projection matrix to force the represented image points from the same class to be close and those from different class are better separated. The feature extraction strategy in our discriminative framework can appropriately work with the corresponding classification strategy, thus, better classification performance can be achieved. Moreover, we propose a kernel discriminative extension method to address the non-linearity problem by adopting the kernel trick. From the experimental results, our proposed method can obtain competitive recognition rates on face recognition tasks via mapping the original image sets into a more discriminative feature space. Besides, it also shows the effectiveness for object classification task with small image sizes and different number of frames.},
  archive      = {J_NPL},
  author       = {Yan, Wenzhu and Sun, Huaijiang and Sun, Quansen and Li, Yanmeng},
  doi          = {10.1007/s11063-019-10133-6},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1061-1079},
  shortjournal = {Neural Process. Lett.},
  title        = {Image set-oriented dual linear discriminant regression classification and its kernel extension},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stability of impulsive stochastic reaction diffusion
recurrent neural network. <em>NPL</em>, <em>51</em>(2), 1049–1060. (<a
href="https://doi.org/10.1007/s11063-019-10131-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the problem of global asymptotic stability of stochastic Markovian jumping reaction-diffusion neural networks with discrete and distributed delays is investigated. By utilizing the Lyapunov–Krasovskii functional method combined with linear matrix inequality approach, novel sufficient stability conditions are derived for impulsive stochastic reaction-diffusion recurrent neural networks with Markovian jumping parameters and mixed delays. Finally, numerical examples with simulation results are given to illustrate the derived theoretical results.},
  archive      = {J_NPL},
  author       = {Vidhya, C. and Dharani, S. and Balasubramaniam, P.},
  doi          = {10.1007/s11063-019-10131-8},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1049-1060},
  shortjournal = {Neural Process. Lett.},
  title        = {Stability of impulsive stochastic reaction diffusion recurrent neural network},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-class review rating classification using deep
recurrent neural network. <em>NPL</em>, <em>51</em>(1), 1031–1048. (<a
href="https://doi.org/10.1007/s11063-019-10125-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a gated-recurrent-unit (GRU) based recurrent neural network (RNN) architecture titled as DSWE-GRNN for multi-class review rating classification problem. Our model incorporates domain-specific word embeddings and does not depend on the reviewer’s information because we usually don’t have many reviews from the same user to measure the leniency of the user towards a specific sentiment. The RNN based architecture captures the hidden contextual information from the domain-specific word embeddings to effectively and efficiently train the model for review rating classification. In this work, we also demonstrate that downsampling technique for data balancing can be very effective for the model’s performance. We have evaluated our model over two datasets i.e IMDB dataset and the Hotel Reviews dataset. The results demonstrate that our model’s performance (accuracy) is comparable with or even better than the four baseline methods used for sentiment classification in literature.},
  archive      = {J_NPL},
  author       = {Hassan, Junaid and Shoaib, Umar},
  doi          = {10.1007/s11063-019-10125-6},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1031-1048},
  shortjournal = {Neural Process. Lett.},
  title        = {Multi-class review rating classification using deep recurrent neural network},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Tuning parameter selection based on blocked <span
class="math display">3 × 2</span> cross-validation for high-dimensional
linear regression model. <em>NPL</em>, <em>51</em>(1), 1007–1029. (<a
href="https://doi.org/10.1007/s11063-019-10105-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In high-dimensional linear regression, selecting an appropriate tuning parameter is essential for the penalized linear models. From the perspective of the expected prediction error of the model, cross-validation methods are commonly used to select the tuning parameter in machine learning. In this paper, blocked $$3\times 2$$ cross-validation ($$3\times 2$$ BCV) is proposed as the tuning parameter selection method because of its small variance for the prediction error estimation. Under some weaker conditions than leave-$$n_v$$-out cross-validation, the tuning parameter selection method based on $$3\times 2$$ BCV is proved to be consistent for the high-dimensional linear regression model. Furthermore, simulated and real data experiments support the theoretical results and demonstrate that the proposed method works well in several criteria about selecting the true model.},
  archive      = {J_NPL},
  author       = {Yang, Xingli and Wang, Yu and Wang, Ruibo and Chen, Mengmeng and Li, Jihong},
  doi          = {10.1007/s11063-019-10105-w},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1007-1029},
  shortjournal = {Neural Process. Lett.},
  title        = {Tuning parameter selection based on blocked $$3\times 2$$ cross-validation for high-dimensional linear regression model},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptively denoising proposal collection for weakly
supervised object localization. <em>NPL</em>, <em>51</em>(1), 993–1006.
(<a href="https://doi.org/10.1007/s11063-019-10124-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address the problem of weakly supervised object localization, which trains a detection network on the dataset with only image-level annotations. The proposed approach is built on the observation that the proposal set from the training dataset is a collection of background, object parts, and objects. Several strategies are taken to adaptively eliminate the noisy proposals and generate pseudo object-level annotations for the weakly labeled dataset. A multiple instance learning algorithm enhanced by mask-out strategy is adopted to collect the class-specific object proposals, which are then utilized to adapt a pre-trained classification network to a detection network. In addition, the detection results from the detection network are re-weighted by jointly considering the detection scores and the overlap ratio of proposals in a proposal subset optimization framework. The optimal proposals work as object-level labels that enable a pseudo-strongly supervised dataset for training the detection network. Consequently, we establish a fully adaptive detection network. Extensive evaluations on the PASCAL VOC 2007 and 2012 datasets demonstrate a significant improvement compared with the state-of-the-art methods.},
  archive      = {J_NPL},
  author       = {Xu, Wenju and Wu, Yuanwei and Ma, Wenchi and Wang, Guanghui},
  doi          = {10.1007/s11063-019-10124-7},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {993-1006},
  shortjournal = {Neural Process. Lett.},
  title        = {Adaptively denoising proposal collection for weakly supervised object localization},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Second order training and sizing for the multilayer
perceptron. <em>NPL</em>, <em>51</em>(1), 963–991. (<a
href="https://doi.org/10.1007/s11063-019-10116-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An algorithm is developed for automated training of a multilayer perceptron with two nonlinear layers. The initial algorithm approximately minimizes validation error with respect to the numbers of both hidden units and training epochs. A median filtering approach is added to reduce deviations between validation and testing errors. Next, the mean-squared error objective function is modified for use with classifiers using a method similar to Ho–Kashyap. Then, both theoretical and practical reasons are provided for introducing growing steps into the algorithm. Lastly, a sigmoidal input layer is added to limit the effects of input outliers and further improve the method. Using widely available datasets, the final network’s average testing error is shown to be less than that of several other competing algorithms reported in the literature.},
  archive      = {J_NPL},
  author       = {Tyagi, Kanishka and Nguyen, Son and Rawat, Rohit and Manry, Michael},
  doi          = {10.1007/s11063-019-10116-7},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {963-991},
  shortjournal = {Neural Process. Lett.},
  title        = {Second order training and sizing for the multilayer perceptron},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stochastic quasi-synchronization of delayed neural networks:
Pinning impulsive scheme. <em>NPL</em>, <em>51</em>(1), 947–962. (<a
href="https://doi.org/10.1007/s11063-019-10118-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies stochastic quasi-synchronization of delayed neural networks with parameter mismatches and stochastic perturbation mismatch via pinning impulsive control. By pinning selected nodes of stochastic neural network at impulse time, an impulsive control scheme is proposed. Some sufficient conditions are obtained to ensure that the error system can converge to small region in the mean square. Meanwhile, numerical example is provided to illustrate the effectiveness of theoretical results.},
  archive      = {J_NPL},
  author       = {Pan, Lijun},
  doi          = {10.1007/s11063-019-10118-5},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {947-962},
  shortjournal = {Neural Process. Lett.},
  title        = {Stochastic quasi-synchronization of delayed neural networks: Pinning impulsive scheme},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Training a neural network for cyberattack classification
applications using hybridization of an artificial bee colony and monarch
butterfly optimization. <em>NPL</em>, <em>51</em>(1), 905–946. (<a
href="https://doi.org/10.1007/s11063-019-10120-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Arguably the most recurring issue concerning network security is building an approach that is capable of detecting intrusions into network systems. This issue has been addressed in numerous works using various approaches, of which the most popular one is to consider intrusions as anomalies with respect to the normal traffic in the network and classify network packets as either normal or abnormal. Improving the accuracy and efficiency of this classification is still an open problem to be solved. The study carried out in this article is based on a new approach for intrusion detection that is mainly implemented using the Hybrid Artificial Bee Colony algorithm (ABC) and Monarch Butterfly optimization (MBO). This approach is implemented for preparing an artificial neural system (ANN) in order to increase the precision degree of classification for malicious and non-malicious traffic in systems. The suggestion taken into consideration was to place side-by-side nine other metaheuristic algorithms that are used to evaluate the proposed approach alongside the related works. In the beginning the system is prepared in such a way that it selects the suitable biases and weights utilizing a hybrid (ABC) and (MBO). Subsequently the artificial neural network is retrained by using the information gained from the ideal weights and biases which are obtained from the hybrid algorithm (HAM) to get the intrusion detection approach able to identify new attacks. Three types of intrusion detection evaluation datasets namely KDD Cup 99, ISCX 2012, and UNSW-NB15 were used to compare and evaluate the proposed technique against the other algorithms. The experiment clearly demonstrated that the proposed technique provided significant enhancement compared to the other nine classification algorithms, and that it is more efficient with regards to network intrusion detection.},
  archive      = {J_NPL},
  author       = {Ghanem, Waheed A. H. M. and Jantan, Aman},
  doi          = {10.1007/s11063-019-10120-x},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {905-946},
  shortjournal = {Neural Process. Lett.},
  title        = {Training a neural network for cyberattack classification applications using hybridization of an artificial bee colony and monarch butterfly optimization},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Learning the graph edit costs based on a learning model
applied to sub-optimal graph matching. <em>NPL</em>, <em>51</em>(1),
881–904. (<a href="https://doi.org/10.1007/s11063-019-10121-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attributed graphs are used to represent patterns composed of several parts in pattern recognition. The nature of these patterns can be diverse, from images, to handwritten characters, maps or fingerprints. Graph edit distance has become an important tool in structural pattern recognition since it allows us to measure the dissimilarity of attributed graphs. It is based on transforming one graph into another through some edit operations such as substitution, deletion and insertion of nodes and edges. It has two main constraints: it requires an adequate definition of the costs of these operations and its computation cost is exponential with regard to the number of nodes. In this paper, we first present a general framework to automatically learn these edit costs considering graph edit distance is computed in a sub-optima way. Then, we specify this framework in two different models based on neural networks and probability density functions. An exhaustive practical validation on 14 public databases, which have different features such as the size of the graphs, the number of attributes or the number of graphs per class have been performed. This validation shows that with the learned edit costs, the accuracy is higher than with some manually imposed costs or other costs automatically learned by previous methods.},
  archive      = {J_NPL},
  author       = {Santacruz, Pep and Serratosa, Francesc},
  doi          = {10.1007/s11063-019-10121-w},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {881-904},
  shortjournal = {Neural Process. Lett.},
  title        = {Learning the graph edit costs based on a learning model applied to sub-optimal graph matching},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel delay-dependent criterion for global power stability
of cellular neural networks with proportional delay. <em>NPL</em>,
<em>51</em>(1), 867–880. (<a
href="https://doi.org/10.1007/s11063-019-10126-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The global power stability of a class of cellular neural networks with proportional delay is considered in this paper. By proposing a new integral inequality and constructing a Lyapunov functional candidate, a novel delay-dependent condition formulated by linear matrix inequalities is derived to ensure that the equilibrium point of the addressed networks achieves global power stability. The proposed criteria complement and improve some existing results in the recent publications, and their effectiveness and advantage are demonstrated by two numerical examples.},
  archive      = {J_NPL},
  author       = {Guan, Kaizhong and Xi, Jun},
  doi          = {10.1007/s11063-019-10126-5},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {867-880},
  shortjournal = {Neural Process. Lett.},
  title        = {A novel delay-dependent criterion for global power stability of cellular neural networks with proportional delay},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep feature fusion for high-resolution aerial scene
classification. <em>NPL</em>, <em>51</em>(1), 853–865. (<a
href="https://doi.org/10.1007/s11063-019-10119-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of remote sensing technology let us acquire a large collection of remote sensing scene images with high resolution. Aerial scene classification has become a crucial problem for understanding high-resolution remote sensing imagery. In this letter, we propose a novel framework for aerial scene classification. Unlike some traditional methods in which the features are produced by using handcrafted feature descriptors, our proposed method uses the raw RGB network stream and the saliency coded network stream to extract two different types of informative features. Then, we further propose a deep feature fusion model to fuse these two sets of features for final classification. The comprehensive performance evaluation of our proposed method is tested on two publicly available remote sensing scene classification benchmarks, i.e., the UC-Merced dataset and the AID dataset. Experimental results show that our proposed method achieves satisfactory results and outperforms the state-of-the-art approaches.},
  archive      = {J_NPL},
  author       = {Wang, Heng and Yu, Yunlong},
  doi          = {10.1007/s11063-019-10119-4},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {853-865},
  shortjournal = {Neural Process. Lett.},
  title        = {Deep feature fusion for high-resolution aerial scene classification},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Traffic signs detection for real-world application of an
advanced driving assisting system using deep learning. <em>NPL</em>,
<em>51</em>(1), 837–851. (<a
href="https://doi.org/10.1007/s11063-019-10115-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advanced driving systems are used as luxury tools to handle a difficult or repetitive task. One of the most important tasks is traffic signs detection that provides the driver with a global view of traffic signs on the road. A traffic signs detection application should be able to detect and understand each traffic sign. To develop a robust traffic sign detection application, we propose to use the deep learning technique to process visual data. The proposed application is used for an embedded implementation. To solve this task, we propose to use the deep learning technique based on convolutional neural networks. As known, a convolutional neural network needs a big amount of data to be trained. To solve the problem, we build a dataset for traffic signs detection. The dataset contains 10,500 images from 73 traffic signs classes. The images are captured from the Chinese roads under real environmental conditions. The proposed application achieves high performance on the proposed dataset with a mean average precision of 84.22%. Also, the proposed application can be easily used for embedded implementation because of its lightweight model size and its fast inference speed.},
  archive      = {J_NPL},
  author       = {Ayachi, Riadh and Afif, Mouna and Said, Yahia and Atri, Mohamed},
  doi          = {10.1007/s11063-019-10115-8},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {837-851},
  shortjournal = {Neural Process. Lett.},
  title        = {Traffic signs detection for real-world application of an advanced driving assisting system using deep learning},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). AR–ARCH type artificial neural network for forecasting.
<em>NPL</em>, <em>51</em>(1), 819–836. (<a
href="https://doi.org/10.1007/s11063-019-10117-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world time series such as econometric time series are rarely linear and they have characteristics of volatility. Although autoregressive conditional heteroscedasticity models have used for forecasting financial time series, these models are specific models for time series, so they are not generally applied for all-time series. ARCH–GARCH models usually applied on financial time series. Because, since these time series include features like volatility clustering and leptokurtic and therefore cause problem of heteroscedastic. These problems can be handled thanks to these models. However, These model can be modelled by ARCH–GARCH models only if they include arch effect after being checked that whether ARCH effect exists or not. Therefore, in recent years artificial neural networks have been commonly used various fields by many researchers for any nonlinear-or linear time series, especially multiplicative neuron model-based artificial neural networks are commonly used that have successful forecasting results. It is known that hybrid methods in artificial neural networks are useful techniques for forecasting time series. In this study, a new hybrid forecasting method has a multiplicative neural network structure AR–ARCH–ANN model has been proposed. The proposed method is a recurrent model and also it can model volatility with having autoregressive conditional heteroscedasticity structure. In the proposed approach, particle swarm optimization is used for training neural network. Possibilities of avoiding local minimum traps are increased by this algorithm in using trained process. Istanbul Stock Exchange daily data sets from 2011 to 2013 and some time series in using for 2016 International Time Series Forecasting Competition are obtained to evaluate the forecasting performance of AR–ARCH–ANN. Then, results produced by the proposed method were compared with other methods and it has better performance from other methods.},
  archive      = {J_NPL},
  author       = {Corba, Burcin Seyda and Egrioglu, Erol and Dalar, Ali Zafer},
  doi          = {10.1007/s11063-019-10117-6},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {819-836},
  shortjournal = {Neural Process. Lett.},
  title        = {AR–ARCH type artificial neural network for forecasting},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Learning biased SVM with weighted within-class scatter for
imbalanced classification. <em>NPL</em>, <em>51</em>(1), 797–817. (<a
href="https://doi.org/10.1007/s11063-019-10096-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Support vector machine (SVM) is a powerful tool for pattern classification and regression estimation. However, for the class imbalanced problem, conventional SVMs are not suitable to the imbalanced learning tasks since they tend to misclassify the minority class, which is always the more important class. In this paper, we propose an improved biased SVM with weighted within-class structure for imbalanced classification. The new algorithm makes the minority class more clustered by assigning a small weight for the within-class scatter matrix of minority class, which can improve the classification performance. The experimental results on several benchmark datasets demonstrate the effectiveness of the proposed algorithm for imbalanced data classification problems.},
  archive      = {J_NPL},
  author       = {Zhang, Jing-Jing and Zhong, Ping},
  doi          = {10.1007/s11063-019-10096-8},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {797-817},
  shortjournal = {Neural Process. Lett.},
  title        = {Learning biased SVM with weighted within-class scatter for imbalanced classification},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Random regrouping and factorization in cooperative particle
swarm optimization based large-scale neural network training.
<em>NPL</em>, <em>51</em>(1), 759–796. (<a
href="https://doi.org/10.1007/s11063-019-10112-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous studies have shown that factorization and random regrouping significantly improve the performance of the cooperative particle swarm optimization (CPSO) algorithm. However, few studies have examined whether this trend continues when CPSO is applied to the training of feed forward neural networks. Neural network training problems often have very high dimensionality and introduce the issue of saturation, which has been shown to significantly affect the behavior of particles in the swarm; thus it should not be assumed that these trends hold. This study identifies the benefits of random regrouping and factorization to CPSO based neural network training, and proposes a number of approaches to problem decomposition for use in neural network training. Experiments are performed on 11 problems with sizes ranging from 35 up to 32,811 weights and biases, using a number of general approaches to problem decomposition, and state of the art algorithms taken from the literature. This study found that the impact of factorization and random regrouping on solution quality and swarm behavior depends heavily on the general approach to problem decomposition. It is shown that a random problem decomposition is effective in feed forward neural network training. A random problem decomposition has the benefit of reducing the issue of problem decomposition to the tuning of a single parameter.},
  archive      = {J_NPL},
  author       = {Dennis, Cody and Ombuki-Berman, Beatrice M. and Engelbrecht, Andries P.},
  doi          = {10.1007/s11063-019-10112-x},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {759-796},
  shortjournal = {Neural Process. Lett.},
  title        = {Random regrouping and factorization in cooperative particle swarm optimization based large-scale neural network training},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). A discriminative approach to sentiment classification.
<em>NPL</em>, <em>51</em>(1), 749–758. (<a
href="https://doi.org/10.1007/s11063-019-10108-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the explosive growth of user-generated contents, understanding opinions (such as reviews on products) generated by Internet users is important for optimizing business decision. To achieve such understanding, this paper investigates a discriminative approach to classifying opinions according to sentiments. The discriminative approach builds a model with the prior knowledge of the categorization information in order to extract meaningful features from the unstructured texts. The prior knowledge includes ratio factors to reinforce terms’ sentiment polarity by using TF-IDF, short for term frequency-inverse document frequency. Experimental results with four datasets show the proposed approach is very competitive, compared with some of the previous works.},
  archive      = {J_NPL},
  author       = {Li, Guangmin and Lin, Zhiwei and Wang, Hui and Wei, Xin},
  doi          = {10.1007/s11063-019-10108-7},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {749-758},
  shortjournal = {Neural Process. Lett.},
  title        = {A discriminative approach to sentiment classification},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Non-negative matrix factorization with symmetric manifold
regularization. <em>NPL</em>, <em>51</em>(1), 723–748. (<a
href="https://doi.org/10.1007/s11063-019-10111-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-negative matrix factorization (NMF) is becoming an important tool for information retrieval and pattern recognition. However, in the applications of image decomposition, it is not enough to discover the intrinsic geometrical structure of the observation samples by only considering the similarity of different images. In this paper, symmetric manifold regularized objective functions are proposed to develop NMF based learning algorithms (called SMNMF), which explore both the global and local features of the manifold structures for image clustering and at the same time improve the convergence of the graph regularized NMF algorithms. For different initializations, simulations are utilized to confirm the theoretical results obtained in the convergence analysis of the new algorithms. Experimental results on COIL20, ORL, and JAFFE data sets demonstrate the clustering effectiveness of the proposed algorithms by comparing with the state-of-the-art algorithms.},
  archive      = {J_NPL},
  author       = {Yang, Shangming and Liu, Yongguo and Li, Qiaoqin and Yang, Wen and Zhang, Yi and Wen, Chuanbiao},
  doi          = {10.1007/s11063-019-10111-y},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {723-748},
  shortjournal = {Neural Process. Lett.},
  title        = {Non-negative matrix factorization with symmetric manifold regularization},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Higher-order ZNN dynamics. <em>NPL</em>, <em>51</em>(1),
697–721. (<a href="https://doi.org/10.1007/s11063-019-10107-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several improvements of the Zhang neural network (ZNN) dynamics for solving the time-varying matrix inversion problem are presented. Introduced ZNN dynamical design is termed as ZNN models of the order p, $$p\ge 2$$, and it is based on the analogy between the proposed continuous-time dynamical systems and underlying discrete-time pth order hyperpower iterative methods for computing the constant matrix inverse. Such ZNN design is denoted by $$\hbox {ZNN}_H^p$$. Particularly, the $$\hbox {ZNN}_H^2$$ design coincides with the standard ZNN design. Moreover, $$\hbox {ZNN}_H^3$$ design represents a time-varying generalization of the previously defined ZNNCM model. In addition, an integration-enhanced noise-handling $$\hbox {ZNN}_H^p$$ model, termed as $$\hbox {IENHZNN}_H^p$$, is introduced. In the time-invariant case, we present a hybrid enhancement of the $$\hbox {ZNN}_H^p$$ model, shortly termed as $$\hbox {HZNN}_H^p$$, and investigate it theoretically and numerically. Theoretical and numerical comparisons between the improved and standard ZNN dynamics are considered.},
  archive      = {J_NPL},
  author       = {Stanimirović, Predrag S. and Katsikis, Vasilios N. and Li, Shuai},
  doi          = {10.1007/s11063-019-10107-8},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {697-721},
  shortjournal = {Neural Process. Lett.},
  title        = {Higher-order ZNN dynamics},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An improved flower pollination algorithm with three
strategies and its applications. <em>NPL</em>, <em>51</em>(1), 675–695.
(<a href="https://doi.org/10.1007/s11063-019-10103-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The flower pollination algorithm is a recently presented meta-heuristic algorithm, but limited in searching precision and convergence rate when solving some complex problems. In order to enhance its performance, this paper proposes an improved flower pollination algorithm, combined with three strategies, i.e., a new double-direction learning strategy to advance the local searching ability, a new greedy strategy to strengthen the diversity of population and a new dynamic switching probability strategy to balance global and local searching. These strategies can increase searching precision and make solution more accurate. Then 12 standard test functions and two structural design examples are selected to appraise the performance of the newly proposed algorithm. The results show that our new algorithm has outstanding performance, such as high accuracy, fast convergence speed and strong stability on solving some complex optimization problems.},
  archive      = {J_NPL},
  author       = {Yang, Xin and Shen, Yanjun},
  doi          = {10.1007/s11063-019-10103-y},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {675-695},
  shortjournal = {Neural Process. Lett.},
  title        = {An improved flower pollination algorithm with three strategies and its applications},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Unsupervised video object segmentation based on mixture
models and saliency detection. <em>NPL</em>, <em>51</em>(1), 657–674.
(<a href="https://doi.org/10.1007/s11063-019-10110-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose an unsupervised video object segmentation approach which is mainly based on a saliency detection method and the Gaussian mixture model with Markov random field. In our approach, the saliency detection method is developed as a preprocessing technique to calculate the probability of each pixel as the target object. In contrast to traditional saliency detection methods which are normally difficult to obtain the object’s precise boundary and are therefore hard to segment consistent objects, the developed saliency detection method can calculate the saliency of each frame in the video sequence and extract the position and region of the target object with more accurate object boundary. The refined extracted object region is then taken as the prior information and incorporated into the Gaussian mixture model with Markov random field to obtain the precise pixel-wise segmentation result of each frame. The effectiveness of the proposed unsupervised video object segmentation approach is validated through experimental results using both the SegTrack and the SegTrack v2 data sets.},
  archive      = {J_NPL},
  author       = {Lin, Guofeng and Fan, Wentao},
  doi          = {10.1007/s11063-019-10110-z},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {657-674},
  shortjournal = {Neural Process. Lett.},
  title        = {Unsupervised video object segmentation based on mixture models and saliency detection},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Discriminative face recognition methods with structure and
label information via <span
class="math display"><em>l</em><sub>2</sub></span> -norm regularization.
<em>NPL</em>, <em>51</em>(1), 639–655. (<a
href="https://doi.org/10.1007/s11063-019-10106-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing sparse representation methods either fail to incorporate the structure and label information of training samples, or suffer from expensive computation for $$l_1$$- or $$l_{2,1}$$-norm. In this paper, we propose three discriminative sparse representation classification methods with structure and label information based on $$l_2$$-norm regularization for robust face recognition. We propose the first classification method with structure and label information by enforcing competition among the representation results of training samples from different classes in representing a test sample. To make the classification more discriminative, we present the decorrelation classification method with structure and label information by jointly considering the competition and decorrelation regularizations. In addition, by incorporating the locality information of samples, we propose the third method called locality-constrained decorrelation classification method with structure and label information. The proposed methods not only contain the structure and label information of training samples, but also have low computational cost owing to the use of $$l_2$$-norm. All three methods have closed-form solutions, rendering them easy to solve and calculate efficiently. Importantly, the proposed methods can achieve better recognition results than most existing state-of-the-art sparse representation methods. Furthermore, based on the proposed methods, we illustrate the effect of different regularization constraints on the recognition performance. Experiments on the ORL, Extended YaleB, FERET, and LFW databases validate the effectiveness of the proposed methods.},
  archive      = {J_NPL},
  author       = {Wang, Keqi and Hu, Haifeng and Li, Lin and Liu, Tundong},
  doi          = {10.1007/s11063-019-10106-9},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {639-655},
  shortjournal = {Neural Process. Lett.},
  title        = {Discriminative face recognition methods with structure and label information via $$l_2$$ -norm regularization},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dimensionality reduction using discriminant collaborative
locality preserving projections. <em>NPL</em>, <em>51</em>(1), 611–638.
(<a href="https://doi.org/10.1007/s11063-019-10104-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose an effective dimensionality reduction algorithm named Discriminant Collaborative Locality Preserving Projections (DCLPP), which takes advantage of manifold learning and collaborative representation. Firstly, two adjacency graphs of the input data are adaptively constructed by an l2-optimization problem to model discriminant manifold structure. The adjacency graphs characterize the important properties such as the intra-class compactness and the inter-class separability. Next, based on collaborative representation reconstruction weights, both intra-class collaborative representation scatter and inter-class collaborative representation scatter can be calculated. Then, motivated by MMC, DCLPP can obtain optimal projection directions which could maximize the between-class scatter and minimize the within-class compactness. DCLPP naturally avoids the small sample size problem. Finally, after dimension reduction and data projection by DCLPP, the NN classifier is employed for classification. To evaluate the performance of DCLPP, we compare it with the most existing DR methods such as CRP and DSNPE on publicly available face databases and COIL-20 database. The experimental results demonstrate that DCLPP is feasible and effective.},
  archive      = {J_NPL},
  author       = {Wang, Guoqiang and Gong, Lei and Pang, Yajun and Shi, Nianfeng},
  doi          = {10.1007/s11063-019-10104-x},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {611-638},
  shortjournal = {Neural Process. Lett.},
  title        = {Dimensionality reduction using discriminant collaborative locality preserving projections},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A unified self-stabilizing neural network algorithm for
principal takagi component extraction. <em>NPL</em>, <em>51</em>(1),
591–610. (<a href="https://doi.org/10.1007/s11063-019-10109-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we develop efficient methods for the computation of the Takagi components and the Takagi subspaces of complex symmetric matrices via the complex-valued neural network models. Firstly, we present a unified self-stabilizing neural network learning algorithm for principal Takagi components and study the stability of the proposed unified algorithms via the fixed-point analysis method. Secondly, the unified algorithm for extracting principal Takagi components is generalized to compute the principal Takagi subspace. Thirdly, we prove that the associated differential equations will globally asymptotically converge to an invariance set and the corresponding energy function attains a unique global minimum if and only if its state matrices span the principal Takagi subspace. Finally, numerical simulations are carried out to illustrate the theoretical results.},
  archive      = {J_NPL},
  author       = {Che, Maolin and Wang, Xuezhong and Wei, Yimin},
  doi          = {10.1007/s11063-019-10109-6},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {591-610},
  shortjournal = {Neural Process. Lett.},
  title        = {A unified self-stabilizing neural network algorithm for principal takagi component extraction},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improved data modeling using coupled artificial neural
networks. <em>NPL</em>, <em>51</em>(1), 577–590. (<a
href="https://doi.org/10.1007/s11063-019-10089-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our senses perceive the world, but what happens if one of the senses is degraded through illness or injury? In such situations, the brain compensates by enhancing the remaining senses. This suggests that networks that process the data received by the senses are coupled. Similar situations can occur in scientific and engineering problems when independent measurement methods, based on different principles, are used to study the same characteristics of a system. In such situation, one can develop reliable artificial neural network (ANN) based models; each trained using data obtained by a different measurement method. This raises the question if it is possible to couple these different models to obtain and improved more accurate model. In this paper, we explore this possibility by training two ANN models that can recognize alphabet letters in a noisy environment. The performance of these ANNs are optimized by varying the number of hidden neurons (HN). The first ANN model trained using pictorial presentation of the letters while the second by corresponding audio signals. The two separate ANNs are trained using the two alphabet letters presentation to which different levels of white noise are added. Different schemes to couple the two systems are examined. For some coupling schemes, the combined system result in highly improved letter recognition than the two original separate ANNs did. Examination of the entropy related to the number of HNs showed that increased entropy is related to a higher error in letter recognition.},
  archive      = {J_NPL},
  author       = {Boger, Zvi and Kogan, Danny and Joseph, Nadav and Zeiri, Yehuda},
  doi          = {10.1007/s11063-019-10089-7},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {577-590},
  shortjournal = {Neural Process. Lett.},
  title        = {Improved data modeling using coupled artificial neural networks},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Distributed neuro-dynamic algorithm for price-based game in
energy consumption system. <em>NPL</em>, <em>51</em>(1), 559–575. (<a
href="https://doi.org/10.1007/s11063-019-10102-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a plug-in hybrid electric vehicles energy consumption system is studied. In order to protect each player’s privacy, the information exchange is going on the neighboring players, and a connected undirected graph is used to pattern the information flow between the players. Hence, it is impossible for each player to access the aggregate electricity consumption directly, which determines the electricity price. Under the noncooperative game frame, a distributed neuro-dynamic algorithm is proposed to optimize the benefit of each individual player base on the pricing strategies. A dynamic average consensus is applied to estimate the aggregate consumption and a projection neural network is employed to seek the Nash equilibrium point. The convergence of the proposed distributed algorithm is analyzed through the Lyapunov stability analysis. Finally, the effectiveness of the distributed neuro-dynamic algorithm is manifested in the simulation.},
  archive      = {J_NPL},
  author       = {Wen, Shifan and He, Xing and Huang, Tingwen},
  doi          = {10.1007/s11063-019-10102-z},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {559-575},
  shortjournal = {Neural Process. Lett.},
  title        = {Distributed neuro-dynamic algorithm for price-based game in energy consumption system},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Novel sufficient conditions on periodic solutions for
discrete-time neutral-type neural networks. <em>NPL</em>,
<em>51</em>(1), 543–557. (<a
href="https://doi.org/10.1007/s11063-019-10066-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the existence and global exponential stability of periodic solutions for a class of delayed discrete-time neutral-type neural networks. Novel sufficient conditions to guarantee the existence and global exponential stability of periodic solutions are established for above discrete-time neutral-type neural networks by combining Mawhin’s continuation theorem of coincidence degree theory with graph theory as well as Lyapunov sequence method. Our results on the existence and global exponential stability of periodic solutions are more concise and easily verified than those obtained in Du et al. (J Frankl Inst 353:448–461, 2016).},
  archive      = {J_NPL},
  author       = {He, Dan and Zhou, Bin and Zhang, Zhengqiu},
  doi          = {10.1007/s11063-019-10066-0},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {543-557},
  shortjournal = {Neural Process. Lett.},
  title        = {Novel sufficient conditions on periodic solutions for discrete-time neutral-type neural networks},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel geometric mean feature space discriminant analysis
method for hyperspectral image feature extraction. <em>NPL</em>,
<em>51</em>(1), 515–542. (<a
href="https://doi.org/10.1007/s11063-019-10101-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral image contains abundant spectral information with hundreds of spectral continuous bands that allow us to distinguish different classes with more details. However, the number of available training samples is limited and the high dimensionality of hyperspectral data increases the computational complexity and even also may degrade the classification accuracy. In addition, the bottom line is that only original spectral is difficult to well represent or reveal intrinsic geometry structure of the hyperspectral image. Thus, feature extraction is an important step before classification of high dimensional data. In this paper, we proposed a novel supervised feature extraction method that uses a new geometric mean vector to construct geometric between-class scatter matrix ($$S_b^G$$) and geometric within-class scatter matrix ($$S_w^G$$) instead of traditional mean vector of state-of-the-art methods. The geometric mean vector not only can reveal intrinsic geometry structure of the hyperspectral image, but also can improve the ability of learning nonlinear correlation features by maximum likelihood classification (MLC). The proposed method is called geometric mean feature space discriminant analysis (GmFSDA) that uses three measures to produce the extracted features. GmFSDA, at first, maximizes the geometric between-spectral scatter matrix to increase the difference between extracted features. In the second step of GmFSDA, maximizes the between-class scatter and minimizes the within-class scatter simultaneously. The experimental results on three real-world hyperspectral image datasets show the better performance of GmFSDA in comparison with other feature extraction methods in small sample size situation by using MLC.},
  archive      = {J_NPL},
  author       = {Li, Li and Ge, Hongwei and Gao, Jianqiang and Zhang, Yixin and Tong, Yubing and Sun, Jun},
  doi          = {10.1007/s11063-019-10101-0},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {515-542},
  shortjournal = {Neural Process. Lett.},
  title        = {A novel geometric mean feature space discriminant analysis method for hyperspectral image feature extraction},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep learning architectures for accurate millimeter wave
positioning in 5G. <em>NPL</em>, <em>51</em>(1), 487–514. (<a
href="https://doi.org/10.1007/s11063-019-10073-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The introduction of 5G’s millimeter wave transmissions brings a new paradigm to wireless communications. Whereas physical obstacles were mostly associated with signal attenuation, their presence now adds complex, non-linear phenomena, including reflections and scattering. The result is a multipath propagation environment, shaped by the obstacles encountered, indicating a strong presence of hidden spatial information within the received signal. To untangle said information into a mobile device position, this paper proposes the usage of neural networks over beamformed fingerprints, enabling a single-anchor positioning approach. Depending on the mobile device target application, positioning can also be enhanced with tracking techniques, which leverage short-term historical data. The main contributions of this paper are to discuss and evaluate typical neural network architectures suitable to the beamformed fingerprint positioning problem, including convolutional neural networks, hierarchy-based techniques, and sequence learning approaches. Using short sequences with temporal convolutional networks, simulation results show that stable average estimation errors of down to 1.78 m are obtained on realistic outdoor scenarios, containing mostly non-line-of-sight positions. These results establish a new state-of-the-art accuracy value for non-line-of-sight millimeter wave outdoor positioning, making the proposed methods very competitive and promising alternatives in the field.},
  archive      = {J_NPL},
  author       = {Gante, João and Falcão, Gabriel and Sousa, Leonel},
  doi          = {10.1007/s11063-019-10073-1},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {487-514},
  shortjournal = {Neural Process. Lett.},
  title        = {Deep learning architectures for accurate millimeter wave positioning in 5G},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new ExtendFace representation method for face recognition.
<em>NPL</em>, <em>51</em>(1), 473–486. (<a
href="https://doi.org/10.1007/s11063-019-10100-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many traditional face recognition methods based on Fisher discriminant analysis and locally graph embedding are proposed for dimensional reduction in nonlinear data. However, these methods are not effective by using the face images with non-ideal conditions (such as, variations of expression, pose, illumination and noisy environment). That is to say, face recognition methods are difficult to achieve good performance due to the absence of appropriate and sufficient front training images. Unfortunately, most existing discriminant analysis approaches fail to work especially for single image per person problem because there is only a single training sample per person such that the within-class variation of this person cannot be calculated in such case. In this paper, we present a new face recognition method by using complex number based data augmentation. The proposed method first deals with the information provided by the original face images and obtains the new representations. Then, fuse original face images and the obtained new images into complex numbers by using a simple combination. Then, the samples can be mapped into the new representation space for classification by using the kernel function, and a test face image can be expressed by the linear combination of all the training face images. Finally, the classification predication can be completed via using collaborative representation based classification. The proposed method is abbreviated as ExtendFace. The performance of ExtendFace method is evaluated on ORL and Yale databases. Experimental results show that the ExtendFace method outperforms the other related methods in terms of recognition rates.},
  archive      = {J_NPL},
  author       = {Gao, Jianqiang and Li, Li and Guo, Bin},
  doi          = {10.1007/s11063-019-10100-1},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {473-486},
  shortjournal = {Neural Process. Lett.},
  title        = {A new ExtendFace representation method for face recognition},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On infinite horizon optimal control problems with a feed
forward neural network scheme. <em>NPL</em>, <em>51</em>(1), 449–471.
(<a href="https://doi.org/10.1007/s11063-019-10099-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a class of infinite-horizon nonlinear optimal control problems is considered. The main idea is to convert the infinite horizon problem to an equivalent finite-horizon optimal control problem. According to the Pontryagin minimum principle for optimal control problems and by constructing an error function, we define an unconstrained minimization problem. In the optimization problem, we use trial solutions for the state, costate and control functions where these trial solutions are constructed by using two-layer perceptron. We then minimize the error function where weights and biases associated with all neurons are unknown. Substituting the optimal values of the weights and biases into the trial solutions, we obtain the optimal solution of the original problem. We also use a dynamic optimization scheme to learning process and discuss the stability and convergence properties of it. Some examples are given to show the efficiency of the method.},
  archive      = {J_NPL},
  author       = {Mortezaee, Marziyeh and Nazemi, Alireza},
  doi          = {10.1007/s11063-019-10099-5},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {449-471},
  shortjournal = {Neural Process. Lett.},
  title        = {On infinite horizon optimal control problems with a feed forward neural network scheme},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improved delay-derivative-dependent stability analysis for
generalized recurrent neural networks with interval time-varying delays.
<em>NPL</em>, <em>51</em>(1), 427–448. (<a
href="https://doi.org/10.1007/s11063-019-10088-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the problem of delay-derivative-dependent stability analysis for generalized neural networks with interval time-varying delays is considered. First, we divide the whole delay interval into two segmentations with an unequal width and checking the variation of the Lyapunov–Krasovskii functional (LKF) for each subinterval of delay, where the information on the lower and upper bounds of time delay and its derivative are fully exploited. Second, a new delay-derivative-dependent stability condition for time-varying delay systems with interval time-varying delays, which expressed in terms of quadratic forms of linear matrix inequalities (LMIs), and has been derived by constructing the LKF from the delayed-decomposition approach and integral inequality approach. Third, all the conditions are presented in terms of LMIs can be easily calculated by using Matlab LMI control toolbox. Fourth, the computational complexity of newly obtained stability conditions is reduced because fewer variables are involved. Finally, four numerical examples are provided to verify the effectiveness of the proposed criteria.},
  archive      = {J_NPL},
  author       = {Liu, Pin-Lin},
  doi          = {10.1007/s11063-019-10088-8},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {427-448},
  shortjournal = {Neural Process. Lett.},
  title        = {Improved delay-derivative-dependent stability analysis for generalized recurrent neural networks with interval time-varying delays},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Finite time stability analysis of fractional-order
complex-valued memristive neural networks with proportional delays.
<em>NPL</em>, <em>51</em>(1), 407–426. (<a
href="https://doi.org/10.1007/s11063-019-10097-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, finite time stability analysis of fractional-order complex-valued memristive neural networks with proportional delays is investigated. Under the framework of Filippov solution and differential inclusion theory, by using H$$\ddot{o}$$lder inequality, Gronwall inequality and inequality scaling skills, some sufficient conditions are derived to ensure the finite-time stability of concerned fractional-order complex-valued memristive neural networks with fractional order $$\alpha $$: $$0&lt;\alpha &lt;1/2$$ and $$1/2\le \alpha &lt;1$$. In the end, two numerical examples are provided to illustrate the availability of the obtained results.},
  archive      = {J_NPL},
  author       = {Syed Ali, M. and Narayanan, G. and Orman, Zeynep and Shekher, Vineet and Arik, Sabri},
  doi          = {10.1007/s11063-019-10097-7},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {407-426},
  shortjournal = {Neural Process. Lett.},
  title        = {Finite time stability analysis of fractional-order complex-valued memristive neural networks with proportional delays},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A high generalizable feature extraction method using
ensemble learning and deep auto-encoders for operational reliability
assessment of bearings. <em>NPL</em>, <em>51</em>(1), 383–406. (<a
href="https://doi.org/10.1007/s11063-019-10094-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature extraction is a major challenge in operational reliability assessment, which requires techniques and prior knowledge. Deep auto-encoder (DAE) is a popular deep learning method and is widely used in feature extraction. However, low generalization ability and structure parameters design are still the major problems of DAE for operational reliability assessment. To overcome the two problems, an ensemble DAE is proposed for operational reliability assessment. Firstly, different structure parameters are employed to design a series of DAEs for feature learning from the measured data. Secondly, a feature ensemble strategy is designed to enhance the generalization ability of the DAE model, in which the features learned by different DAEs are clustered to remove the irrelevant DAEs and select the more general feature subset. Finally, the operational reliability indicator is defined by the Euclidean distance of the selected features and the operational reliability model is developed. The proposed method is utilized to analyze the experimental bearings and the results indicate that the proposed method is effective for operational reliability assessment.},
  archive      = {J_NPL},
  author       = {Kong, Xianguang and Fu, Yang and Wang, Qibin and Ma, Hongbo and Wu, Xiaodong and Mao, Gang},
  doi          = {10.1007/s11063-019-10094-w},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {383-406},
  shortjournal = {Neural Process. Lett.},
  title        = {A high generalizable feature extraction method using ensemble learning and deep auto-encoders for operational reliability assessment of bearings},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Global asymptotic stability of periodic solutions for
neutral-type BAM neural networks with delays. <em>NPL</em>,
<em>51</em>(1), 367–382. (<a
href="https://doi.org/10.1007/s11063-019-10092-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the neutral-type BAM neural networks with time-varying delays. By applying the continuation theorem and some analysis techniques, some sufficient conditions to guarantee the neutral-type BAM neural networks have at least one periodic solution are proposed. Moreover, we also consider the asymptotic behaviours of periodic solutions by Lyapunov function and inequality $$2ab\le a^{2}+b^{2}$$. At last, an example is given to illustrate the effectiveness and feasibility of the obtain results.},
  archive      = {J_NPL},
  author       = {Gao, Dongdong and Li, Jianli},
  doi          = {10.1007/s11063-019-10092-y},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {367-382},
  shortjournal = {Neural Process. Lett.},
  title        = {Global asymptotic stability of periodic solutions for neutral-type BAM neural networks with delays},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Maximum mean and covariance discrepancy for unsupervised
domain adaptation. <em>NPL</em>, <em>51</em>(1), 347–366. (<a
href="https://doi.org/10.1007/s11063-019-10090-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A fundamental research topic in domain adaptation is how best to evaluate the distribution discrepancy across domains. The maximum mean discrepancy (MMD) is one of the most commonly used statistical distances in this field. However, information about distributions could be lost when adopting non-characteristic kernels by MMD. To address this issue, we devise a new distribution metric named maximum mean and covariance discrepancy (MMCD) by combining MMD and the proposed maximum covariance discrepancy (MCD). MCD probes the second-order statistics in reproducing kernel Hilbert space, which equips MMCD to capture more information compared to MMD alone. To verify the efficacy of MMCD, an unsupervised learning model based on MMCD abbreviated as McDA was proposed and efficiently optimized to resolve the domain adaptation problem. Experiments on image classification conducted on two benchmark datasets show that McDA outperforms other representative domain adaptation methods, which implies the effectiveness of MMCD in domain adaptation.},
  archive      = {J_NPL},
  author       = {Zhang, Wenju and Zhang, Xiang and Lan, Long and Luo, Zhigang},
  doi          = {10.1007/s11063-019-10090-0},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {347-366},
  shortjournal = {Neural Process. Lett.},
  title        = {Maximum mean and covariance discrepancy for unsupervised domain adaptation},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Complex projection synchronization of fractional-order
complex-valued memristive neural networks with multiple delays.
<em>NPL</em>, <em>51</em>(1), 325–345. (<a
href="https://doi.org/10.1007/s11063-019-10093-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the complex projection synchronization problem of fractional-order complex-valued memristive neural networks is investigated, in which the projection factor is set to complex value and multiple time delays are considered. Under the framework of set-valued mapping and differential inclusion theory, a hybrid control strategy is designed to analyze the complex projection synchronization problem of the system. Moreover, some criterion to ensure the synchronization of drive response network is obtained by applying the stability theorem and comparison principle of the fractional order systems with multiple time delays. Finally, numerical simulation example is provided to verify the correctness and effectiveness of the complex projection synchronization strategy.},
  archive      = {J_NPL},
  author       = {Ding, Dawei and Yao, Xiaolei and Zhang, Hongwei},
  doi          = {10.1007/s11063-019-10093-x},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {325-345},
  shortjournal = {Neural Process. Lett.},
  title        = {Complex projection synchronization of fractional-order complex-valued memristive neural networks with multiple delays},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel identification-based convex control scheme via
recurrent high-order neural networks: An application to the internal
combustion engine. <em>NPL</em>, <em>51</em>(1), 303–324. (<a
href="https://doi.org/10.1007/s11063-019-10095-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an identification-based nonlinear control scheme which casts the plant model as a recurrent high-order neural network. The model thus obtained consists on polynomials of a fixed number of nonlinearities, a fact that is exploited by transforming it into an exact tensor-product representation whose nested convex sums may increase with the network order while preserving the number of different interpolating functions. Convexity is then used along the direct Lyapunov method to find conditions for controller design in the form of linear matrix inequalities or sum-of-squares; thanks to the fixed number of nonlinearities, they can be made progressively more relaxed while preventing the computational burden usually associated with Pólya-like relaxations. The control law thus obtained is a generalization of the well-known parallel distributed compensation; its effectiveness is illustrated in academic examples and an internal combustion engine setup.},
  archive      = {J_NPL},
  author       = {Armenta, Carlos and Laurain, Thomas and Estrada-Manzo, Víctor and Bernal, Miguel},
  doi          = {10.1007/s11063-019-10095-9},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {303-324},
  shortjournal = {Neural Process. Lett.},
  title        = {A novel identification-based convex control scheme via recurrent high-order neural networks: An application to the internal combustion engine},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Action recognition with multiple relative descriptors of
trajectories. <em>NPL</em>, <em>51</em>(1), 287–302. (<a
href="https://doi.org/10.1007/s11063-019-10091-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dense trajectory has become one of the most successful hand-crafted features for action recognition. However, most of the existing dense trajectories based methods ignore the relationship between trajectories. In this paper, we propose multiple relative descriptors of trajectories to model the relative information of pairs of trajectories. Specifically, we present relative motion descriptors and relative location descriptors, which are utilized to capture the relative motion information and relative location information respectively. Moreover, we present relative deep feature descriptors which combine the deep features with hand-crafted features. By aggregating the above descriptors, we obtain the fixed-length representation regardless of the various duration of input video. The experimental results on three standard datasets demonstrate the superiority of our method.},
  archive      = {J_NPL},
  author       = {Liao, Zhongke and Hu, Haifeng and Liu, Yichu},
  doi          = {10.1007/s11063-019-10091-z},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {287-302},
  shortjournal = {Neural Process. Lett.},
  title        = {Action recognition with multiple relative descriptors of trajectories},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mean-square exponential input-to-state stability of
stochastic gene regulatory networks with multiple time delays.
<em>NPL</em>, <em>51</em>(1), 271–286. (<a
href="https://doi.org/10.1007/s11063-019-10087-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the input-to-state stability of stochastic gene regulatory networks with multiple time delays. It is well acknowledged that stochastic systems can accurately describe some complex systems with random disturbances. So it is significant that stochastic systems are applied to model gene regulatory networks because of the complex relationship between genes and proteins from a micro perspective. Considering the differences between stochastic differential equations and ordinary differential equations, we introduce the new stability criterion which is different from the general stability criteria. Making use of Lyapunov functionals, It$$\hat{o}$$ formula and Dynkin formula, we present sufficient conditions to guarantee that the proposed system is mean-square exponentially input-to-state stable. Moreover, numerical examples are given to illustrate validity and feasibility of the obtained results.},
  archive      = {J_NPL},
  author       = {Xu, Guoxiong and Bao, Haibo and Cao, Jinde},
  doi          = {10.1007/s11063-019-10087-9},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {271-286},
  shortjournal = {Neural Process. Lett.},
  title        = {Mean-square exponential input-to-state stability of stochastic gene regulatory networks with multiple time delays},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Synchronous reluctance motor speed tracking using a modified
second-order sliding mode control method. <em>NPL</em>, <em>51</em>(1),
251–270. (<a href="https://doi.org/10.1007/s11063-019-10085-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A modified second-order sliding mode control (MSOSMC) combined with radial basis function (RBF) network estimator is developed and proposed to achieve accurate speed tracking performance for synchronous reluctance motor (SynRM). The dynamic model of SynRM system has the properties of parameter variations, external disturbance, and nonlinear friction force. The MSOSMC method that utilizes continuous control input is applied to reduce the chattering phenomenon. Also, this method utilizes two sliding surfaces to solve the problem of system uncertainty and reduce motor power consumption. The RBF network is developed in MSOSMC scheme to estimate the lumped uncertainty in an on-line fashion. The proposed MSOSMC method uses the system error and control input as the convergence criteria. The adaptation scheme adjusts the parameter vectors based on the Lyapunov theorem approach, so that the asymptotic stability of the developed motor system can be guaranteed. Experimental results show that the MSOSMC structure achieves the better tracking performances in terms of root-mean-square error compared with the traditional SOSMC method under different speed tracking conditions.},
  archive      = {J_NPL},
  author       = {Mao, Wei-Lung and Chu, Chao-Ting and Hung, Chung-Wen},
  doi          = {10.1007/s11063-019-10085-x},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {251-270},
  shortjournal = {Neural Process. Lett.},
  title        = {Synchronous reluctance motor speed tracking using a modified second-order sliding mode control method},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Speed up the training of neural machine translation.
<em>NPL</em>, <em>51</em>(1), 231–249. (<a
href="https://doi.org/10.1007/s11063-019-10084-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural machine translation (NMT) has achieved notable achievements in recent years. Although existing models provide reasonable translation performance, they cost too much training time. Especially, when the corpus is enormous, their computational cost will be extremely high. In this paper, we propose a novel NMT model based on the conventional bidirectional recurrent neural network (bi-RNN). In this model, we apply a tanh activation function, which can learn the future and history context information more sufficiently, to speed up the training process. Experimental results on tasks of German–English and English–French translation demonstrate that the proposed model can save much training time compared with the state-of-the-art models and provide better translation performances.},
  archive      = {J_NPL},
  author       = {Liu, Xinyue and Wang, Weixuan and Liang, Wenxin and Li, Yuangang},
  doi          = {10.1007/s11063-019-10084-y},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {231-249},
  shortjournal = {Neural Process. Lett.},
  title        = {Speed up the training of neural machine translation},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Attentive semantic and perceptual faces completion using
self-attention generative adversarial networks. <em>NPL</em>,
<em>51</em>(1), 211–229. (<a
href="https://doi.org/10.1007/s11063-019-10080-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an approach based on self-attention generative adversarial networks to accomplish the task of image completion where completed images become globally and locally consistent. Using self-attention GANs with contextual and other constraints, the generator can draw realistic images, where fine details are generated in the damaged region and coordinated with the whole image semantically. To train the consistent generator, i.e. image completion network, we employ global and local discriminators where the global discriminator is responsible for evaluating the consistency of the entire image, while the local discriminator assesses the local consistency by analyzing local areas containing completed regions only. Last but not least, attentive recurrent neural block is introduced to obtain the attention map about the missing part in the image, which will help the subsequent completion network to fill contents better. By comparing the experimental results of different approaches on CelebA dataset, our method shows relatively good results.},
  archive      = {J_NPL},
  author       = {Liu, Xiaowei and Li, Kenli and Li, Keqin},
  doi          = {10.1007/s11063-019-10080-2},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {211-229},
  shortjournal = {Neural Process. Lett.},
  title        = {Attentive semantic and perceptual faces completion using self-attention generative adversarial networks},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Exponential stability and sampled-data synchronization of
delayed complex-valued memristive neural networks. <em>NPL</em>,
<em>51</em>(1), 193–209. (<a
href="https://doi.org/10.1007/s11063-019-10082-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is devoted to the global exponential stability (GES) and synchronization control of delayed complex-valued memristive neural networks (CVMNNs). The criterion on the existence, uniqueness and GES of the equilibrium point (EP) for delayed CVMNNs is established by constructing a suitable Lyapunov functional and using the homeomorphism theory as well as linear matrix inequality. Meanwhile, a sampled-data controller is designed to synchronize the master and slave systems under the framework of inequality techniques and Lyapunov method. Finally, two examples are presented to show the validity of the obtained results.},
  archive      = {J_NPL},
  author       = {Li, Huilan and Gao, Xingbao and Li, Ruoxia},
  doi          = {10.1007/s11063-019-10082-0},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {193-209},
  shortjournal = {Neural Process. Lett.},
  title        = {Exponential stability and sampled-data synchronization of delayed complex-valued memristive neural networks},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Data-based online optimal temperature tracking control in
continuous microwave heating system by adaptive dynamic programming.
<em>NPL</em>, <em>51</em>(1), 167–191. (<a
href="https://doi.org/10.1007/s11063-019-10081-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Control of continuous microwave heating system (CMHS) is truly a complex problem with time variance, uncertainty and nonlinearity, which becomes prohibitive to use a conventional model-based approach. To overcome this, a novel data-based optimal temperature tracking control is designed for CMHS in this paper. In order to obtain the complex dynamics of CMHS, a neural network model is first constructed driven by process data. After transforming the original temperature tracking problem into an error regulation problem, adaptive dynamic programming is introduced to deal with the regulation problem as well as to decrease operation cost. The design and operation of this controller depend mainly on the online data, and minor prior knowledge is required. Simulation results show that the proposed method can effectively control the CMHS in terms of temperature tracking and energy utilization.},
  archive      = {J_NPL},
  author       = {Liu, Tong and Liang, Shan and Xiong, Qingyu and Wang, Kai},
  doi          = {10.1007/s11063-019-10081-1},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {167-191},
  shortjournal = {Neural Process. Lett.},
  title        = {Data-based online optimal temperature tracking control in continuous microwave heating system by adaptive dynamic programming},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Kernel-based subspace learning on riemannian manifolds for
visual recognition. <em>NPL</em>, <em>51</em>(1), 147–165. (<a
href="https://doi.org/10.1007/s11063-019-10083-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Covariance matrices have attracted increasing attention for data representation in many computer vision tasks. The nonsingular covariance matrices are regarded as points on Riemannian manifolds rather than Euclidean space. A common technique for classification on Riemannian manifolds is to embed the covariance matrices into a reproducing kernel Hilbert space (RKHS), and then construct a map from RKHS to Euclidean space, while the explicit map from RKHS to Euclidean space in most kernel-based methods only depends on a linear hypothesis. In this paper, we propose a subspace learning framework to project Riemannian manifolds to Euclidean space, and give the theoretical derivation for it. Specifically, the Euclidean space is isomorphic to the subspace of RKHS. Under the framework, firstly we define an improved Log-Euclidean Gaussian radial basis function kernel for embedding. The first order statistical features of input images are incorporated into the kernel function to increase the discriminative power. After that we seek the optimal projection matrix of the subspace of the RKHS by conducting a graph embedding discriminant analysis. Texture recognition and object categorization experiments with region covariance descriptors demonstrate the considerable effectiveness of the improved Log-Euclidean Gaussian RBK kernel and the proposed method.},
  archive      = {J_NPL},
  author       = {Liu, Xi and Ma, Zhengming},
  doi          = {10.1007/s11063-019-10083-z},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {147-165},
  shortjournal = {Neural Process. Lett.},
  title        = {Kernel-based subspace learning on riemannian manifolds for visual recognition},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). ELMAENet: A simple, effective and fast deep architecture for
image classification. <em>NPL</em>, <em>51</em>(1), 129–146. (<a
href="https://doi.org/10.1007/s11063-019-10079-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has drawn extensive attention in machine learning because of its excellent performance, especially the convolutional neural network (CNN) architecture for image classification task. Therefore, many variant deep models based on CNN have been proposed in the past few years. However, the success of these models depends mostly on fine-tuning using backpropagation, which is a time-consuming process and suffers from troubles including slow convergence rate, local minima, intensive human intervention,etc. And these models achieve excellent performance only when their architectures are deeper enough. To overcome the above problems, we propose a simple, effective and fast deep architecture called ELMAENet, which uses extreme learning machines auto-encoder (ELM-AE) to get the filters of convolutional layer. ELMAENet incorporates the power of convolutional layer and ELM-AE (Kasun et al. in IEEE Intell Syst 28(6):31–34, 2013), which no longer need parameter tuning but still has a good performance for image classification. Experiments on several datasets have shown that the proposed ELMAENet achieves comparable or even better performance than that of the state-of-the-art models.},
  archive      = {J_NPL},
  author       = {Chang, Peiju and Zhang, Jiangshe and Wang, Jinyan and Fei, Rongrong},
  doi          = {10.1007/s11063-019-10079-9},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {129-146},
  shortjournal = {Neural Process. Lett.},
  title        = {ELMAENet: A simple, effective and fast deep architecture for image classification},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Methodologies of compressing a stable performance
convolutional neural networks in image classification. <em>NPL</em>,
<em>51</em>(1), 105–127. (<a
href="https://doi.org/10.1007/s11063-019-10076-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has made a real revolution in the embedded computing environment. Convolutional neural network (CNN) revealed itself as a reliable fit to many emerging problems. The next step, is to enhance the CNN role in the embedded devices including both implementation details and performance. Resources needs of storage and computational ability are limited and constrained, resulting in key issues we have to consider in embedded devices. Compressing (i.e., quantizing) the CNN network is a valuable solution. In this paper, Our main goals are: memory compression and complexity reduction (both operations and cycles reduction) of CNNs, using methods (including quantization and pruning) that don’t require retraining (i.e., allowing us to exploit them in mobile system, or robots). Also, exploring further quantization techniques for further complexity reduction. To achieve these goals, we compress a CNN model layers (i.e., parameters and outputs) into suitable precision formats using several quantization methodologies. The methodologies are: First, we describe a pruning approach, which allows us to reduce the required storage and computation cycles in embedded devices. Such enhancement can drastically reduce the consumed power and the required resources. Second, a hybrid quantization approach with automatic tuning for the network compression. Third, a K-means quantization approach. With a minor degradation relative to the floating-point performance, the presented pruning and quantization methods are able to produce a stable performance fixed-point reduced networks. A precise fixed-point calculations for coefficients, input/output signals and accumulators are considered in the quantization process.},
  archive      = {J_NPL},
  author       = {Al-Hami, Mo’taz and Pietron, Marcin and Casas, Raul and Wielgosz, Maciej},
  doi          = {10.1007/s11063-019-10076-y},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {105-127},
  shortjournal = {Neural Process. Lett.},
  title        = {Methodologies of compressing a stable performance convolutional neural networks in image classification},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust output feedback stabilization for uncertain
discrete-time stochastic neural networks with time-varying delay.
<em>NPL</em>, <em>51</em>(1), 83–103. (<a
href="https://doi.org/10.1007/s11063-019-10077-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the problem of robust exponential stabilization of uncertain discrete-time stochastic neural networks with time-varying delay based on output feedback control. By choosing an augmented Lyapunov–Krasovskii functional, we established the sufficient conditions of the delay-dependent asymptotical stabilization in the mean square for a class of discrete-time stochastic neural networks with time-varying delay. Furthermore, we obtain the criteria of robust global exponential stabilization in the mean square for uncertain discrete-time stochastic neural networks with time-varying delay. Finally, we give numerical examples to illustrate the effectiveness of the proposed results.},
  archive      = {J_NPL},
  author       = {Dong, Yali and Wang, Huimin},
  doi          = {10.1007/s11063-019-10077-x},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {83-103},
  shortjournal = {Neural Process. Lett.},
  title        = {Robust output feedback stabilization for uncertain discrete-time stochastic neural networks with time-varying delay},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Finite-time stabilization for static neural networks with
leakage delay and time-varying delay. <em>NPL</em>, <em>51</em>(1),
67–81. (<a href="https://doi.org/10.1007/s11063-019-10065-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of finite-time stabilization (FTS) for static neural networks (SNNs) with leakage delay and time-varying delay is investigated in this paper. By introducing an auxiliary function and utilizing the Lyapunov stability theory, we derive some sufficient criteria for FTS in terms of linear matrix inequalities (LMIs). Two feedback controllers are designed based on two different Lyapunov functions, which can be easily solved via MATLAB LMI toolbox, to guarantee the FTS for the SNNs. Finally, two numerical examples are given to illustrate the efficiency of our results.},
  archive      = {J_NPL},
  author       = {Zhang, Xiaoyu and Yuan, Yuan and Li, Xiaodi},
  doi          = {10.1007/s11063-019-10065-1},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {67-81},
  shortjournal = {Neural Process. Lett.},
  title        = {Finite-time stabilization for static neural networks with leakage delay and time-varying delay},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Entropy-based fuzzy least squares twin support vector
machine for pattern classification. <em>NPL</em>, <em>51</em>(1), 41–66.
(<a href="https://doi.org/10.1007/s11063-019-10078-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Least squares twin support vector machine (LSTSVM) is a new machine learning method, as opposed to solving two quadratic programming problems in twin support vector machine (TWSVM), which generates two nonparallel hyperplanes by solving a pair of linear system of equations. However, LSTSVM obtains the resultant classifier by giving same importance to all training samples which may be important for classification performance. In this paper, by considering the fuzzy membership value for each sample, we propose an entropy-based fuzzy least squares twin support vector machine where fuzzy membership values are assigned based on the entropy values of all training samples. The proposed method not only retains the superior characteristics of LSTSVM which is simple and fast algorithm, but also implements the structural risk minimization principle to overcome the possible over- fitting problem. Experiments are performed on several synthetic as well as benchmark datasets and the experimental results illustrate the effectiveness of our method.},
  archive      = {J_NPL},
  author       = {Chen, Sugen and Cao, Junfeng and Chen, Fenglin and Liu, Bingbing},
  doi          = {10.1007/s11063-019-10078-w},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {41-66},
  shortjournal = {Neural Process. Lett.},
  title        = {Entropy-based fuzzy least squares twin support vector machine for pattern classification},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Domain adaptation with few labeled source samples by graph
regularization. <em>NPL</em>, <em>51</em>(1), 23–39. (<a
href="https://doi.org/10.1007/s11063-019-10075-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain Adaptation aims at utilizing source data to establish an exact model for a related but different target domain. In recent years, many effective models have been proposed to propagate label information across domains. However, these models rely on large-scale labeled data in source domain and cannot handle the case where the source domain lacks label information. In this paper, we put forward a Graph Regularized Domain Adaptation (GDA) to tackle this problem. Specifically, the proposed GDA integrates graph regularization with maximum mean discrepancy (MMD). Hence GDA enables sufficient unlabeled source data to facilitate knowledge transfer by utilizing the geometric property of source domain, simultaneously, due to the embedding of MMD, GDA can reduce source and target distribution divergency to learn a generalized classifier. Experimental results validate that our GDA outperforms the traditional algorithms when there are few labeled source samples.},
  archive      = {J_NPL},
  author       = {Li, Jinfeng and Liu, Weifeng and Zhou, Yicong and Tao, Dapeng and Nie, Liqiang},
  doi          = {10.1007/s11063-019-10075-z},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {23-39},
  shortjournal = {Neural Process. Lett.},
  title        = {Domain adaptation with few labeled source samples by graph regularization},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Non-iterative knowledge fusion in deep convolutional neural
networks. <em>NPL</em>, <em>51</em>(1), 1–22. (<a
href="https://doi.org/10.1007/s11063-019-10074-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incorporation of new knowledge into neural networks with simultaneous preservation of the previous knowledge is known to be a nontrivial problem. This problem becomes even more complex when the new knowledge is contained not in new training examples, but inside the parameters (e.g., connection weights) of another neural network. In this correspondence, we propose and test two methods of combining knowledge contained in separate networks. The first method is based on a summation of weights. The second incorporates new knowledge by modification of weights nonessential for the preservation of previously stored information. We show that with these methods, the knowledge can be transferred non-iteratively from one network to another without requiring additional training sessions. The fused network operates efficiently, performing classification at a level similar to that of an ensemble of networks. The efficiency of the methods is quantified on several publicly available data sets in classification tasks both for shallow and deep feedforward neural networks.},
  archive      = {J_NPL},
  author       = {Leontev, Mikhail Iu. and Islenteva, Viktoriia and Sukhov, Sergey V.},
  doi          = {10.1007/s11063-019-10074-0},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Neural Process. Lett.},
  title        = {Non-iterative knowledge fusion in deep convolutional neural networks},
  volume       = {51},
  year         = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
