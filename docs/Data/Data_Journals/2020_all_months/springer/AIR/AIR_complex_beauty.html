<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AIR_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="air---177">AIR - 177</h2>
<ul>
<li><details>
<summary>
(2020). Novel classes of coverings based multigranulation fuzzy
rough sets and corresponding applications to multiple attribute group
decision-making. <em>AIR</em>, <em>53</em>(8), 6197–6256. (<a
href="https://doi.org/10.1007/s10462-020-09846-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The notion of covering based multigranulation fuzzy rough set (CMGFRS) models is a generalization of both granular computing and covering based fuzzy rough sets. Therefore it has become a powerful tool for coping with vague and multigranular information in cognition. In this paper we introduce three kinds of CMGFRS models by means of fuzzy β-neighborhoods and fuzzy complementary β-neighborhoods, and we investigate their axiomatic properties. We investigate three respective types of coverings based CMGFRS models, namely, optimistic, pessimistic and variable precision setups. In particular, by using multigranulation fuzzy measure degrees and multigranulation fuzzy complementary measure degrees, we derive three types of coverings based γ-optimistic (γ-pessimistic) CMGFRSs and E (F, G)-optimistic and E (F, G)-pessimistic CMGFRSs, respectively. We discuss the interrelationships among these three types of CMGFRS models and covering based Zhan-CMGFRS models. In view of the theoretical analysis for these three types of CMGFRS models, we put forward a novel methodology to multiple attribute group decision-making problem with evaluation of fuzzy information. An effective example is fully developed, hence concluding the applicability of the proposed methodology.},
  archive      = {J_AIR},
  author       = {Ma, Xueling and Zhan, Jianming and Sun, Bingzhen and Alcantud, José Carlos R.},
  doi          = {10.1007/s10462-020-09846-1},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {6197-6256},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Novel classes of coverings based multigranulation fuzzy rough sets and corresponding applications to multiple attribute group decision-making},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sentiment analysis with deep neural networks: Comparative
study and performance assessment. <em>AIR</em>, <em>53</em>(8),
6155–6195. (<a
href="https://doi.org/10.1007/s10462-020-09845-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current decade has witnessed the remarkable developments in the field of artificial intelligence, and the revolution of deep learning has transformed the whole artificial intelligence industry. Eventually, deep learning techniques have become essential components of any model in today’s computational world. Nevertheless, deep learning techniques promise a high degree of automation with generalized rule extraction for both text and sentiment classification tasks. This article aims to provide an empirical study on various deep neural networks (DNN) used for sentiment classification and its applications. In the preliminary step, the research carries out a study on several contemporary DNN models and their underlying theories. Furthermore, the performances of different DNN models discussed in the literature are estimated through the experiments conducted over sentiment datasets. Following this study, the effect of fine-tuning various hyperparameters on each model’s performance is also examined. Towards a better comprehension of the empirical results, few simple techniques from data visualization have been employed. This empirical study ensures deep learning practitioners with insights into ways to adapt stable DNN techniques for many sentiment analysis tasks.},
  archive      = {J_AIR},
  author       = {Wadawadagi, Ramesh and Pagi, Veerappa},
  doi          = {10.1007/s10462-020-09845-2},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {6155-6195},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Sentiment analysis with deep neural networks: Comparative study and performance assessment},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Neural networks for online learning of non-stationary data
streams: A review and application for smart grids flexibility
improvement. <em>AIR</em>, <em>53</em>(8), 6111–6154. (<a
href="https://doi.org/10.1007/s10462-020-09844-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning efficient predictive models in dynamic environments requires taking into account the continuous changing nature of phenomena generating the data streams, known in machine learning as “concept drift”. Such changes may affect models’ effectiveness over time, requiring permanent updates of parameters and structure to maintain performance. Several supervised machine learning methods have been developed to be adapted to learn in dynamic and non-stationary environments. One of the most well-known and efficient learning methods is neural networks. This paper focuses on the different neural networks developed to build learning models able to adapt to concept drifts on streaming data. Their performance will be studied and compared using meaningful criteria. Their limits to address the challenges related to the problem of the improvement of electrical grid flexibility in presence of distributed Wind–PV renewable energy resources within the context of energy transition will be highlighted. Finally, the study provides a self-adaptive scheme based on the use of neural networks to overcome these limitations and tackle these challenges.},
  archive      = {J_AIR},
  author       = {Hammami, Zeineb and Sayed-Mouchaweh, Moamar and Mouelhi, Wiem and Ben Said, Lamjed},
  doi          = {10.1007/s10462-020-09844-3},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {6111-6154},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Neural networks for online learning of non-stationary data streams: A review and application for smart grids flexibility improvement},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Soft dominance based multigranulation decision theoretic
rough sets and their applications in conflict problems. <em>AIR</em>,
<em>53</em>(8), 6079–6110. (<a
href="https://doi.org/10.1007/s10462-020-09843-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The extension of rough set model is a crucial and vast research direction in rough set theory. Meanwhile decision making can be considered as a mental process in which human beings make a choice among several alternatives. However, with the increasing complexity of real decision making problems, the decision makers frequently face the challenge of characterizing their preferences in an uncertain context. In the present paper, we initiate a multi attribute group decision making problem in the presence of multi attribute and multi decision in decision making with preferences. We further present the concept of soft preference relation and soft dominance relation corresponding to decision attribute in the multi criteria and multi decision information system. Further we put forward the idea of two types of optimistic/pessimistic multigranulation (soft dominance based optimistic/pessimistic multigranulation decision theoretic) approximations and their applications in solving a multi agent conflict analysis decision problem. The proposed method addresses the limitations of the Pawlak model and Sun’s conflict analysis model and thus improve these models. Finally, the results on labor management negotiation problems show that the proposed algorithms are more effective and efficient for feasible consensus strategy when compared with other techniques.},
  archive      = {J_AIR},
  author       = {Rehman, Noor and Ali, Abbas and Hila, Kostaq},
  doi          = {10.1007/s10462-020-09843-4},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {6079-6110},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Soft dominance based multigranulation decision theoretic rough sets and their applications in conflict problems},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Selective attention to historical comparison or social
comparison in the evolutionary iterated prisoner’s dilemma game.
<em>AIR</em>, <em>53</em>(8), 6043–6078. (<a
href="https://doi.org/10.1007/s10462-020-09842-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates an evolutionary iterated prisoner’s dilemma (IPD) model of multiple agents, in which agents interact in terms of the pair-wise IPD game while adapting their attitudes towards income stream risk. Specifically, agents will become more risk averse (or more risk seeking) if their game payoffs exceed (or fall below) their expectations. In particular, agents use their peers’ average payoffs as expectations (social comparison) when their payoffs are lower than their peers’ averages, but use their own historical payoffs as expectations (historical comparison) when their payoffs are higher than their peers’ averages. Such selective attention to social comparison or historical comparison manifests a desire for continuous improvement of agents. Simulations are conducted to investigate the evolution of cooperation under the selective attention mechanism. Results indicate that agents can sustain a highly cooperative equilibrium when they consider selective attention in adjusting their risk attitudes. This holds true for both the well-mixed and the network-based games, even in the presence of uncertain game payoffs. The reason is that, selective attention can significantly induce agents to adhere to conditional cooperation as well as to identify uncertainty in payoffs, which enhances the risk-averse behavior of agents in the IPD game. As a result, high levels of cooperation can be attained.},
  archive      = {J_AIR},
  author       = {Zeng, Weijun and Li, Minqiang},
  doi          = {10.1007/s10462-020-09842-5},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {6043-6078},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Selective attention to historical comparison or social comparison in the evolutionary iterated prisoner’s dilemma game},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Artificial intelligence, machine learning and process
automation: Existing knowledge frontier and way forward for mining
sector. <em>AIR</em>, <em>53</em>(8), 6025–6042. (<a
href="https://doi.org/10.1007/s10462-020-09841-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning and artificial intelligence are the two fields of computer science dealing with the innovative idea of inducing smartness and intelligence in machines and automating complex tasks and operations through modern learning algorithms. While the rest of the operational fields have been diligent in developing new technologies, the mining industry has been lacking when it comes to applying these innovative methodologies to achieve operation autonomy with intelligence. However, this trend is beginning to change with a few researchers adopting the fields of machine learning and artificial intelligence to improve the existing technologies. This study was an attempt to review and analyze all the recent automation related work in every sector of the mining industry including mineral prospecting and exploration, mine planning, equipment selection, underground and surface equipment operation, drilling and blasting, mineral processing, etc., for establishing the existing frontiers of technological advancement. Shortcomings and challenges were identified within the current research work. Recommendations were provided to progress the existing technology by implementing deep learning, machine learning, and artificial intelligence for smart and intelligence-based evolution in the mining sector. With all of this innovative development and implementation of smart automation systems, the foundation for the mine of the future could be built, thus creating efficient, effective, and safer machines with sustainable mining operations.},
  archive      = {J_AIR},
  author       = {Ali, Danish and Frimpong, Samuel},
  doi          = {10.1007/s10462-020-09841-6},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {6025-6042},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Artificial intelligence, machine learning and process automation: Existing knowledge frontier and way forward for mining sector},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Analytical review of clustering techniques and proximity
measures. <em>AIR</em>, <em>53</em>(8), 5995–6023. (<a
href="https://doi.org/10.1007/s10462-020-09840-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most fundamental approaches to learn and understand from any type of data is by organizing it into meaningful groups (or clusters) and then analyzing them, which is a process known as cluster analysis. During this process of grouping, proximity measures play a significant role in deciding the similarity level of two objects. Moreover, before applying any learning algorithm on a dataset, different aspects related to preprocessing such as dealing with the sparsity of data, leveraging the correlation among features and normalizing the scales of different features are required to be considered. In this study, various proximity measures have been discussed and analyzed from the aforementioned aspects. In addition, a theoretical procedure for selecting a proximity measure for clustering purpose is proposed. This procedure can also be used in the process of designing a new proximity measure. Second, clustering algorithms of different categories have been overviewed and experimentally compared for various datasets of different domains. The datasets have been chosen in such a way that they range from a very low number of dimensions to a very high number of dimensions. Finally, the effect of using different proximity measures is analyzed in partitional and hierarchical clustering techniques based on experiments.},
  archive      = {J_AIR},
  author       = {Mehta, Vivek and Bawa, Seema and Singh, Jasmeet},
  doi          = {10.1007/s10462-020-09840-7},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {5995-6023},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Analytical review of clustering techniques and proximity measures},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-label classification and knowledge extraction from
oncology-related content on online social networks. <em>AIR</em>,
<em>53</em>(8), 5957–5994. (<a
href="https://doi.org/10.1007/s10462-020-09839-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims at automatic processing and knowledge extraction from large amounts of oncology-related content from online social networks (OSN). In this context, a large number of OSN textual posts concerning major cancer types are automatically scraped and structured using natural language processing techniques. Machines are trained to assign multiple labels to these posts based on the type of knowledge enclosed, if any. Trained machines are used to automatically classify large-scale textual posts. Statistical inferences are made based on these predictions to extract general concepts and abstract knowledge. Different approaches for constructing document feature vectors showed no tangible effect on the classification accuracy. Among different classifiers, logistic regression achieved the highest overall accuracy (96.4\%) and $$\overline{F1}$$ (73.4) in a 13-way multi-label classification of textual posts. The most common topic was seeking or providing moral support for cancer patients, followed by providing technical information about cancer causes and treatments. The most common causes and treatments of different types of cancer on OSN are also automatically detected in this study. Seeking or providing moral support for cancer patients shared the largest overlap with other topics, i.e. moral support tends to be present even in OSN posts which focus on other topics. On the other hand, providing technical information about cancer diagnosis or prevention were the most isolated topics, where OSN posts tend not to allude to other topics. OSN posts which seek financial support only overlap with the moral support topic, if any. Our methodology and results provide public health professionals with an opportunity to monitor what topics and to which extent are being discussed on OSN, what specific information and knowledge are being disseminated over OSN, and to assess their veracity in close to real time. This helps them to develop policies that encourage, discourage, or modify the consumption of viral oncology-related information on OSN.},
  archive      = {J_AIR},
  author       = {Hashemi, Mahdi and Hall, Margeret},
  doi          = {10.1007/s10462-020-09839-0},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {5957-5994},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Multi-label classification and knowledge extraction from oncology-related content on online social networks},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A review on the long short-term memory model. <em>AIR</em>,
<em>53</em>(8), 5929–5955. (<a
href="https://doi.org/10.1007/s10462-020-09838-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long short-term memory (LSTM) has transformed both machine learning and neurocomputing fields. According to several online sources, this model has improved Google’s speech recognition, greatly improved machine translations on Google Translate, and the answers of Amazon’s Alexa. This neural system is also employed by Facebook, reaching over 4 billion LSTM-based translations per day as of 2017. Interestingly, recurrent neural networks had shown a rather discrete performance until LSTM showed up. One reason for the success of this recurrent network lies in its ability to handle the exploding/vanishing gradient problem, which stands as a difficult issue to be circumvented when training recurrent or very deep neural networks. In this paper, we present a comprehensive review that covers LSTM’s formulation and training, relevant applications reported in the literature and code resources implementing this model for a toy example.},
  archive      = {J_AIR},
  author       = {Van Houdt, Greg and Mosquera, Carlos and Nápoles, Gonzalo},
  doi          = {10.1007/s10462-020-09838-1},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {5929-5955},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A review on the long short-term memory model},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Intelligent modelling to predict heat transfer coefficient
of vacuum glass insulation based on thinking evolutionary neural
network. <em>AIR</em>, <em>53</em>(8), 5907–5928. (<a
href="https://doi.org/10.1007/s10462-020-09837-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vacuum glass is widely used in many construction applications, including single-family homes, as a proven energy-saving method with outstanding heat preservation characteristics. The thermal insulation performance of vacuum glass is closely related to its heat transfer coefficient. In this study, we applied neural network methods to predict the heat transfer coefficients of vacuum glass. Using MATLAB, a neural network intelligence model was established, and the traditional back-propagation neural network (BPNN) was optimised. First, a genetic algorithm was used to reduce the dimensions of the independent variable. Then, the Mind Evolutionary Computation algorithm was used to optimise the initial weight and threshold. Using the optimised BPNN intelligence model to predict the heat transfer coefficient of vacuum glass insulation, we derived an average absolute error of 0.0076.},
  archive      = {J_AIR},
  author       = {Lei, Wang and Gastro, Omary and Wang, Yuanqi and Felicien, Nomenjanahary Homary and Hui, Li},
  doi          = {10.1007/s10462-020-09837-2},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {5907-5928},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Intelligent modelling to predict heat transfer coefficient of vacuum glass insulation based on thinking evolutionary neural network},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Selective ensemble of uncertain extreme learning machine for
pattern classification with missing features. <em>AIR</em>,
<em>53</em>(8), 5881–5905. (<a
href="https://doi.org/10.1007/s10462-020-09836-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensemble learning is an effective technique to improve performance and stability compared to single classifiers. This work proposes a selective ensemble classification strategy to handle missing data classification, where an uncertain extreme learning machine with probability constraints is used as individual (or base) classifiers. Then, three selective ensemble frameworks are developed to optimize ensemble margin distributions and aggregate individual classifiers. The first two are robust ensemble frameworks with the proposed loss functions. The third is a sparse ensemble classification framework with the zero-norm regularization, to automatically select the required individual classifiers. Moreover, the majority voting method is applied to produce ensemble classifier for missing data classification. We demonstrate some important properties of the proposed loss functions such as robustness, convexity and Fisher consistency. To verify the validity of the proposed methods for missing data, numerical experiments are implemented on benchmark datasets with missing feature values. In experiments, missing features are first imputed by using expectation maximization algorithm. Numerical experiments are simulated in filled datasets. With different probability lower bounds of classification accuracy, experimental results under different proportion of missing values show that the proposed ensemble methods have better or comparable generalization compared to the traditional methods in handling missing-value data classifications.},
  archive      = {J_AIR},
  author       = {Jing, Shibo and Wang, Yidan and Yang, Liming},
  doi          = {10.1007/s10462-020-09836-3},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {5881-5905},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Selective ensemble of uncertain extreme learning machine for pattern classification with missing features},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep learning for face image synthesis and semantic
manipulations: A review and future perspectives. <em>AIR</em>,
<em>53</em>(8), 5847–5880. (<a
href="https://doi.org/10.1007/s10462-020-09835-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image synthesis using representations learned by deep neural networks has gained wide attention in recent years. Among the different categories of natural images, face images are very important because of their broad range of applications. However, it is very challenging to synthesize face images due to their highly complicated hierarchical structure and the uniqueness of information contained in individual face images. This paper aims at providing a comprehensive review of the recent developments and applications of face synthesis and semantic manipulations using deep learning and discusses future perspectives for improving face perception.},
  archive      = {J_AIR},
  author       = {Abdolahnejad, Mahla and Liu, Peter Xiaoping},
  doi          = {10.1007/s10462-020-09835-4},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {5847-5880},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Deep learning for face image synthesis and semantic manipulations: A review and future perspectives},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Design pattern detection approaches: A systematic review of
the literature. <em>AIR</em>, <em>53</em>(8), 5789–5846. (<a
href="https://doi.org/10.1007/s10462-020-09834-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, software engineers have a great tendency to use design patterns (DPs) because they are considered to have an important role in software engineering in the sense that they can make the understanding of nonentities easier. However, most of the systems have no document helping engineers recognize DPs from the codes. As a result, different approaches for design pattern detection have been suggested. The current paper reviews different available literature on design pattern detection and reports a number of different aspects of them such as data representation, type of design pattern, advantages and disadvantages for different approaches, quantitative results, etc. The current paper reviews research studies published between 2008 until 2019 and represents a list of datasets used for evaluations. The present investigation paper is not only to lay the ground for the selection of the optimal design patterns, but also hopes to guide the future studies through raising awareness about the potential defects in the previous researches.},
  archive      = {J_AIR},
  author       = {Yarahmadi, Hadis and Hasheminejad, Seyed Mohammad Hossein},
  doi          = {10.1007/s10462-020-09834-5},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {5789-5846},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Design pattern detection approaches: A systematic review of the literature},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). CHIRPS: Explaining random forest classification.
<em>AIR</em>, <em>53</em>(8), 5747–5788. (<a
href="https://doi.org/10.1007/s10462-020-09833-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern machine learning methods typically produce “black box” models that are opaque to interpretation. Yet, their demand has been increasing in the Human-in-the-Loop processes, that is, those processes that require a human agent to verify, approve or reason about the automated decisions before they can be applied. To facilitate this interpretation, we propose Collection of High Importance Random Path Snippets (CHIRPS); a novel algorithm for explaining random forest classification per data instance. CHIRPS extracts a decision path from each tree in the forest that contributes to the majority classification, and then uses frequent pattern mining to identify the most commonly occurring split conditions. Then a simple, conjunctive form rule is constructed where the antecedent terms are derived from the attributes that had the most influence on the classification. This rule is returned alongside estimates of the rule’s precision and coverage on the training data along with counter-factual details. An experimental study involving nine data sets shows that classification rules returned by CHIRPS have a precision at least as high as the state of the art when evaluated on unseen data (0.91–0.99) and offer a much greater coverage (0.04–0.54). Furthermore, CHIRPS uniquely controls against under- and over-fitting solutions by maximising novel objective functions that are better suited to the local (per instance) explanation setting.},
  archive      = {J_AIR},
  author       = {Hatwell, Julian and Gaber, Mohamed Medhat and Azad, R. Muhammad Atif},
  doi          = {10.1007/s10462-020-09833-6},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {5747-5788},
  shortjournal = {Artif. Intell. Rev.},
  title        = {CHIRPS: Explaining random forest classification},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Visual question answering: A state-of-the-art review.
<em>AIR</em>, <em>53</em>(8), 5705–5745. (<a
href="https://doi.org/10.1007/s10462-020-09832-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual question answering (VQA) is a task that has received immense consideration from two major research communities: computer vision and natural language processing. Recently it has been widely accepted as an AI-complete task which can be used as an alternative to visual turing test. In its most common form, it is a multi-modal challenging task where a computer is required to provide the correct answer for a natural language question asked about an input image. It attracts many deep learning researchers after their remarkable achievements in text, voice and vision technologies. This review extensively and critically examines the current status of VQA research in terms of step by step solution methodologies, datasets and evaluation metrics. Finally, this paper also discusses future research directions for all the above-mentioned aspects of VQA separately.},
  archive      = {J_AIR},
  author       = {Manmadhan, Sruthy and Kovoor, Binsu C.},
  doi          = {10.1007/s10462-020-09832-7},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {5705-5745},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Visual question answering: A state-of-the-art review},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A hybridization of deep learning techniques to predict and
control traffic disturbances. <em>AIR</em>, <em>53</em>(8), 5675–5704.
(<a href="https://doi.org/10.1007/s10462-020-09831-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting traffic disturbances is a challenging problem in urban cities. Emergency vehicles (EV) is one of the biggest disturbances that affect traffic fluidity. The goal of this paper is to provide a machine learning application to deal with emergency cases in traffic networks. Particularly, we investigate the use of deep learning techniques coupled with Artificial Immune System to tackle the issue of EV guidance at signalized intersections. To accomplish this goal, we develop a traffic signal control system capable to estimate traffic status, guide EV to reach their destinations while assuming better traffic condition, control traffic signals, and adapt to new disturbances. For traffic forecasting, the suggested system inherits the advantages of convolutional neural networks, classification, and long short term memory. To control traffic signals, the suggested system uses the immune memory algorithm. To enhance and adapt control decisions to traffic disturbances, the suggested system uses a continuous learning approach assumed by an adapted reinforcement learning algorithm. Assessments using well-known algorithms from the literature are detailed in this work. The benchmarking algorithms are the preemptive longest queue first matching weight matrix system, the pre-emptive immune memory algorithm inspired case-based reasoning, and the preemptive optimized stage based fixed time algorithm. Experiments show a competitive performance of the suggested system compared to benchmarking algorithms.},
  archive      = {J_AIR},
  author       = {Louati, Ali},
  doi          = {10.1007/s10462-020-09831-8},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {5675-5704},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A hybridization of deep learning techniques to predict and control traffic disturbances},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Image segmentation evaluation: A survey of methods.
<em>AIR</em>, <em>53</em>(8), 5637–5674. (<a
href="https://doi.org/10.1007/s10462-020-09830-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image segmentation is a prerequisite for image processing. There are many methods for image segmentation, and as a result, a great number of methods for evaluating segmentation results have also been proposed. How to effectively evaluate the quality of image segmentation is very important. In this paper, the existing image segmentation quality evaluation methods are summarized, mainly including unsupervised methods and supervised methods. Based on hot issues, the application of metrics in natural, medical and remote sensing image evaluation is further outlined. In addition, an experimental comparison for some methods were carried out and the effectiveness of these methods was ranked. At the same time, the effectiveness of classical metrics for remote sensing and medical image evaluation is also verified.},
  archive      = {J_AIR},
  author       = {Wang, Zhaobin and Wang, E. and Zhu, Ying},
  doi          = {10.1007/s10462-020-09830-9},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {5637-5674},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Image segmentation evaluation: A survey of methods},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Performance comparison of five metaheuristic nature-inspired
algorithms to find near-OGRs for WDM systems. <em>AIR</em>,
<em>53</em>(8), 5589–5635. (<a
href="https://doi.org/10.1007/s10462-020-09829-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The metaheuristic approaches inspired by the nature are becoming powerful optimizing algorithms for solving NP-complete problems. This paper presents five nature-inspired metaheuristic optimization algorithms to find near-optimal Golomb ruler (OGR) sequences in a reasonable time. In order to improve the search space and further improve the convergence speed and optimization precision of the metaheuristic algorithms, the improved algorithms based on mutation strategy and Lévy-flight search distribution are proposed. These two strategies help the metaheuristic algorithms to jump out of the local optimum, improve the global search ability so as to maintain the good population diversity. The OGRs found their potential application in channel-allocation method to suppress the four-wave mixing crosstalk in optical wavelength division multiplexing systems. The results conclude that the proposed algorithms are superior to the existing conventional computing algorithms i.e. extended quadratic congruence and search algorithm and nature-inspired optimization algorithms i.e. genetic algorithms, biogeography based optimization and simple big bang–big crunch to find near-OGRs in terms of ruler length, total optical channel bandwidth and computation time. The idea of computational complexity for the proposed algorithms is represented through the Big O notation. In order to validate the proposed algorithms, the non-parametric statistical Wilcoxon analysis is being considered.},
  archive      = {J_AIR},
  author       = {Bansal, Shonak},
  doi          = {10.1007/s10462-020-09829-2},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {5589-5635},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Performance comparison of five metaheuristic nature-inspired algorithms to find near-OGRs for WDM systems},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Empirical evaluation and study of text stemming algorithms.
<em>AIR</em>, <em>53</em>(8), 5559–5588. (<a
href="https://doi.org/10.1007/s10462-020-09828-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text stemming is one of the basic preprocessing step for Natural Language Processing applications which is used to transform different word forms into a standard root form. For Arabic script based languages, adequate analysis of text by stemmers is a challenging task due to large number of ambigious structures of the language. In literature, multiple performance evaluation metrics exist for stemmers, each describing the performance from particular aspect. In this work, we review and analyze the text stemming evaluation methods in order to devise criteria for better measurement of stemmer performance. Role of different aspects of stemmer performance measurement like main features, merits and shortcomings are discussed using a resource scarce language i.e. Urdu. Through our experiments we conclude that the current evaluation metrics can only measure an average conflation of words regardless of the correctness of the stem. Moreover, some evaluation metrics favor some type of languages only. None of the existing evaluation metrics can perfectly measure the stemmer performance for all kind of languages. This study will help researchers to evaluate their stemmer using right methods.},
  archive      = {J_AIR},
  author       = {Jabbar, Abdul and Iqbal, Sajid and Tamimy, Manzoor Ilahi and Hussain, Shafiq and Akhunzada, Adnan},
  doi          = {10.1007/s10462-020-09828-3},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {5559-5588},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Empirical evaluation and study of text stemming algorithms},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Ancient text recognition: A review. <em>AIR</em>,
<em>53</em>(8), 5517–5558. (<a
href="https://doi.org/10.1007/s10462-020-09827-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optical character recognition (OCR) is an important research area in the field of pattern recognition. A lot of research has been done on OCR in the last 60 years. There is a large volume of paper-based data in various libraries and offices. Also, there is a wealth of knowledge in the form of ancient text documents. It is a challenge to maintain and search from this paper-based data. At many places, efforts are being done to digitize this data. Paper based documents are scanned to digitize data but scanned data is in pictorial form. It cannot be recognized by computers because computers can understand standard alphanumeric characters as ASCII or some other codes. Therefore, alphanumeric information must be retrieved from scanned images. Optical character recognition system allows us to convert a document into electronic text, which can be used for edit, search, etc. operations. OCR system is the machine replication of human reading and has been the subject of intensive research for more than six decades. This paper presents a comprehensive survey of the work done in the various phases of an OCR with special focus on the OCR for ancient text documents. This paper will help the novice researchers by providing a comprehensive study of the various phases, namely, segmentation, feature extraction and classification techniques required for an OCR system especially for ancient documents. It has been observed that there is a limited work is done for the recognition of ancient documents especially for Devanagari script. This article also presents future directions for the upcoming researchers in the field of ancient text recognition.},
  archive      = {J_AIR},
  author       = {Narang, Sonika Rani and Jindal, M. K. and Kumar, Munish},
  doi          = {10.1007/s10462-020-09827-4},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {5517-5558},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Ancient text recognition: A review},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey of the recent architectures of deep convolutional
neural networks. <em>AIR</em>, <em>53</em>(8), 5455–5516. (<a
href="https://doi.org/10.1007/s10462-020-09825-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Convolutional Neural Network (CNN) is a special type of Neural Networks, which has shown exemplary performance on several competitions related to Computer Vision and Image Processing. Some of the exciting application areas of CNN include Image Classification and Segmentation, Object Detection, Video Processing, Natural Language Processing, and Speech Recognition. The powerful learning ability of deep CNN is primarily due to the use of multiple feature extraction stages that can automatically learn representations from the data. The availability of a large amount of data and improvement in the hardware technology has accelerated the research in CNNs, and recently interesting deep CNN architectures have been reported. Several inspiring ideas to bring advancements in CNNs have been explored, such as the use of different activation and loss functions, parameter optimization, regularization, and architectural innovations. However, the significant improvement in the representational capacity of the deep CNN is achieved through architectural innovations. Notably, the ideas of exploiting spatial and channel information, depth and width of architecture, and multi-path information processing have gained substantial attention. Similarly, the idea of using a block of layers as a structural unit is also gaining popularity. This survey thus focuses on the intrinsic taxonomy present in the recently reported deep CNN architectures and, consequently, classifies the recent innovations in CNN architectures into seven different categories. These seven categories are based on spatial exploitation, depth, multi-path, width, feature-map exploitation, channel boosting, and attention. Additionally, the elementary understanding of CNN components, current challenges, and applications of CNN are also provided.},
  archive      = {J_AIR},
  author       = {Khan, Asifullah and Sohail, Anabia and Zahoora, Umme and Qureshi, Aqsa Saeed},
  doi          = {10.1007/s10462-020-09825-6},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {5455-5516},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey of the recent architectures of deep convolutional neural networks},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A short survey on end-to-end simple question answering
systems. <em>AIR</em>, <em>53</em>(7), 5429–5453. (<a
href="https://doi.org/10.1007/s10462-020-09826-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Searching for a specific and meaningful piece of information in the humongous textual data volumes found on the internet and knowledge repositories is a very challenging task. This problem is usually constrained to answering simple, factoid questions by resorting to a question answering (QA) system built on top of complex approaches such as heuristics, information retrieval, and machine learning. More precisely, deep learning methods became into sharp focus of this research field because such purposes can realize the benefits of the vast amounts of data to boost the practical results of QA systems. In this paper, we present a systematic survey on deep learning-based QA systems concerning factoid questions, with particular focus on how each existing system addresses their critical features in terms of learning end-to-end models. We also detail the evaluation process carried out on these systems and discuss how each approach differs from the others in terms of the challenges tackled and the strategies employed. Finally, we present the most prominent research problems still open in the field.},
  archive      = {J_AIR},
  author       = {da Silva, José Wellington Franco and Venceslau, Amanda Drielly Pires and Sales, Juliano Efson and Maia, José Gilvan Rodrigues and Pinheiro, Vládia Célia Monteiro and Vidal, Vânia Maria Ponte},
  doi          = {10.1007/s10462-020-09826-5},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5429-5453},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A short survey on end-to-end simple question answering systems},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Completion of multiview missing data based on multi-manifold
regularised non-negative matrix factorisation. <em>AIR</em>,
<em>53</em>(7), 5411–5428. (<a
href="https://doi.org/10.1007/s10462-020-09824-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-source data analysis, the absence of data values or attributes is inevitably brought about by various influencing factors including environment, which results in the loss of knowledge to be conveyed by data. To solve the problem of missing data in multi-source data analysis, completion method for multiview missing data based on multi-manifold regularized non-negative matrix factorization was proposed in this paper. This method was based on the assumption of consistency of the multiview data and an algorithm of multi-manifold regularized non-negative matrix factorization is adopted to obtain homogeneous manifold and global clustering. On this basis, a multiview synergistic discrimination model is built of the non-missing view that referred to the Gaussian mixture model to pre-mark the clustering that the incremental missing data belonged to. Using the consistency of each view in the low-dimensional space, a prediction model of missing data at the specified view is established using the multiple linear regression technique to achieve accurate data completion under conditions of missing multi-attributes. Through the establishment of data filling model with three handling methods for missing values, namely CMMD-MNMF, FIMUS and Hot deck, the completion performance, clustering performance and classification performance of data sets including UCI, Flower17 and Flower102 are analyzed by simulation experiments. As shown in the results, the method of multi-view data missing completion is verified to be effective.},
  archive      = {J_AIR},
  author       = {Jing-Tao, Sun and Qiu-Yu, Zhang},
  doi          = {10.1007/s10462-020-09824-7},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5411-5428},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Completion of multiview missing data based on multi-manifold regularised non-negative matrix factorisation},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Assessment of influence productivity in cognitive models.
<em>AIR</em>, <em>53</em>(7), 5383–5409. (<a
href="https://doi.org/10.1007/s10462-020-09823-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a new influence productivity assessment methodology that is a cognitive intelligence system for the scenario planning of control impacts (generation and choice) for systems that are represented by directed weighted signed graphs based on the algorithm of effective controls. The algorithm implements a control model that expresses the direction of development (growth) of the system. The algorithm is based on the spectral properties of the adjacency matrix of a graph representing the model of a socioeconomic system and does not impose any constraints on the directions of the edges or the sign and weight range on the edges. Scenarios are assessed based on their compliance with tactical and strategic goals according to the codirectionality degree of the response vector with respect to the base vector of the model. The base vector is the effective control vector without constraints on the controls under the conditions of adequate model operation. The new methodology has three distinctive features: (1) the scenario approach is implemented with respect to a set of controls, (2) this approach is applicable for models with heterogeneous factors and does not require preliminary aggregation of the primary model elements of the system; and (3) this approach has a clear formalization metric for the selecting and generating of a set of control impacts. The process does not require the decision maker to have special mathematical training.},
  archive      = {J_AIR},
  author       = {Tselykh, Alexander and Vasilev, Vladislav and Tselykh, Larisa},
  doi          = {10.1007/s10462-020-09823-8},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5383-5409},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Assessment of influence productivity in cognitive models},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A deep granular network with adaptive unequal-length
granulation strategy for long-term time series forecasting and its
industrial applications. <em>AIR</em>, <em>53</em>(7), 5353–5381. (<a
href="https://doi.org/10.1007/s10462-020-09822-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An accurate long-term forecasting for some time series in industrial production is substantially significant for improving the economic efficiency of industry enterprise. In this study, a granular computing (GrC)-based deep learning framework is proposed for long-term time series forecasting, which consists of two stages i.e., the adaptive data granulation and the GrC-based deep model construction. In the first stage, for automatically generating the basic information granules with unequal time span adaptively from data, a stacked sparse auto-encoders granulation network is designed, in which the starting and ending points of a granule are adaptively determined by setting a single neuron in the last hidden layer after multi-layer feature extraction. Then, the second stage sees a definition of a partially overlapping sub-block basis (POSB) matrix to extract the features of these granules, based on which a deep sparse coding feature decomposition-based long-term forecasting model is constructed to transform the unequal-length granules into a product of a POSB matrix and a coefficient matrix layer by layer to serve for forecasting. To verify the effectiveness of the proposed method, two synthetic datasets, two real-world datasets and two practical industrial datasets are employed. The experimental results demonstrate that the proposed method outperforms other data-driven ones on long-term time series forecasting, particularly in an industrial case.},
  archive      = {J_AIR},
  author       = {Wang, Qiang and Chen, Long and Zhao, Jun and Wang, Wei},
  doi          = {10.1007/s10462-020-09822-9},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5353-5381},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A deep granular network with adaptive unequal-length granulation strategy for long-term time series forecasting and its industrial applications},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An overview of distance and similarity functions for
structured data. <em>AIR</em>, <em>53</em>(7), 5309–5351. (<a
href="https://doi.org/10.1007/s10462-020-09821-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The notions of distance and similarity play a key role in many machine learning approaches, and artificial intelligence in general, since they can serve as an organizing principle by which individuals classify objects, form concepts and make generalizations. While distance functions for propositional representations have been thoroughly studied, work on distance functions for structured representations, such as graphs, frames or logical clauses, has been carried out in different communities and is much less understood. Specifically, a significant amount of work that requires the use of a distance or similarity function for structured representations of data usually employs ad-hoc functions for specific applications. Therefore, the goal of this paper is to provide an overview of this work to identify connections between the work carried out in different areas and point out directions for future work.},
  archive      = {J_AIR},
  author       = {Ontañón, Santiago},
  doi          = {10.1007/s10462-020-09821-w},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5309-5351},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An overview of distance and similarity functions for structured data},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep hashing for multi-label image retrieval: A survey.
<em>AIR</em>, <em>53</em>(7), 5261–5307. (<a
href="https://doi.org/10.1007/s10462-020-09820-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Content-based image retrieval (CBIR) aims to display, as a result of a search, images with the same visual contents as a query. This problem has attracted increasing attention in the area of computer vision. Learning-based hashing techniques are amongst the most studied search approaches for approximate nearest neighbors in large-scale image retrieval. With the advance of deep neural networks in image representation, hashing methods for CBIR have started using deep learning to build binary codes. Such strategies are generally known as deep hashing techniques. In this paper, we present a comprehensive deep hashing survey for the task of image retrieval with multiple labels, categorizing the methods according to how the input images are treated: pointwise, pairwise, tripletwise and listwise, as well as their relationships. In addition, we present discussions regarding the cost of space, efficiency and search quality of the described models, as well as open issues and future work opportunities.},
  archive      = {J_AIR},
  author       = {Rodrigues, Josiane and Cristo, Marco and Colonna, Juan G.},
  doi          = {10.1007/s10462-020-09820-x},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5261-5307},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Deep hashing for multi-label image retrieval: A survey},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A graph-based taxonomy of citation recommendation models.
<em>AIR</em>, <em>53</em>(7), 5217–5260. (<a
href="https://doi.org/10.1007/s10462-020-09819-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems have been used since the beginning of the Web to assist users with personalized suggestions related to past preferences for items or products including books, movies, images, research papers and web pages. The availability of millions research articles on various digital libraries makes it difficult for a researcher to find relevant articles to his/er research. During the last years, a lot of research have been conducted through models and algorithms that personalize papers recommendations. With this survey, we explore the state-of-the-art citation recommendation models which we categorize using the following seven criteria: platform used, data factors/features, data representation methods, methodologies and models, recommendation types, problems addressed, and personalization. In addition, we present a novel k-partite graph-based taxonomy that examines the relationships among surveyed algorithms and corresponding k-partite graphs used. Moreover, we present (a) domain’s popular issues, (b) adopted metrics, and (c) commonly used datasets. Finally, we provide some research trends and future directions.},
  archive      = {J_AIR},
  author       = {Ali, Zafar and Qi, Guilin and Kefalas, Pavlos and Abro, Waheed Ahmad and Ali, Bahadar},
  doi          = {10.1007/s10462-020-09819-4},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5217-5260},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A graph-based taxonomy of citation recommendation models},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Research on learning mechanism designing for equilibrated
bipolar spiking neural networks. <em>AIR</em>, <em>53</em>(7),
5189–5215. (<a
href="https://doi.org/10.1007/s10462-020-09818-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence (AI) has become very popular due to both the increasing demands from applications and the booming of computer techniques. Spiking Neural Network (SNN), as the third generation of Artificial Neural Network, receives more and more attention in the field of AI. With the high similarity to biological neural network, SNN has the potential to break through the barriers of strong AI. However, the using of SNNs on practical scenarios is rather limited, as a result of the lack of high efficient learning algorithms. Nowadays, learning methods of SNNs are designed mainly based on previous biological discoveries. The fact that there are both excitatory neurons and inhibitory neurons in the biological neural network has stimulated the motive of this research. The existence of inhibitory neurons could strengthen the self-regulation ability of neural networks and improve learning efficiency. Inspired by the ancient Chinese “Yin and Yang” Theory, we first presented our effort at constructing SNN structure with equilibrated excitatory neurons and inhibitory neurons. Then an ensemble learning optimized supervised learning method is designed and tailored for this SNN structure. Experiments are conducted using MNIST data sets, and results show that, with the designed learning mechanism, our equilibrated bipolar SNN structure could gain reasonable accuracy with much more compact structure and much more sparse synapse connections.},
  archive      = {J_AIR},
  author       = {Yang, Xu and Lin, Jiajun and Zheng, Wenhao and Zhao, Jinfeng and Ji, Mengyao and Lei, Yunlin and Chai, Zenghao},
  doi          = {10.1007/s10462-020-09818-5},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5189-5215},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Research on learning mechanism designing for equilibrated bipolar spiking neural networks},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An MDD-based SAT encoding for pseudo-boolean constraints
with at-most-one relations. <em>AIR</em>, <em>53</em>(7), 5157–5188. (<a
href="https://doi.org/10.1007/s10462-020-09817-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pseudo-Boolean (PB) constraints are ubiquitous in Constraint Satisfaction Problems. Encoding such constraints to SAT has proved to be an efficient solving approach. A commonly used technique for encoding PB constraints consists in representing the constraint as a Binary Decision Diagram (BDD), and then encoding this BDD to SAT. A key point in this technique is to obtain small BDD representations to generate small SAT formulas. In many problems, some subsets of the Boolean variables occurring in a PB constraint may also have other constraints imposed on them. In this work we introduce a way to take advantage of those constraints in order to obtain smaller SAT encodings. The main idea is that decision diagrams may be smaller if they avoid to represent truth assignments that are already forbidden by some other constraints. In particular, we present encodings for monotonic decreasing PB constraints, in conjunction with other constraints such as at-most-one, exactly-one and implication chains on subsets of their variables. We provide empirical evidence of the usefulness of this technique to reduce the size of the encodings as well as the solving time.},
  archive      = {J_AIR},
  author       = {Bofill, Miquel and Coll, Jordi and Suy, Josep and Villaret, Mateu},
  doi          = {10.1007/s10462-020-09817-6},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5157-5188},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An MDD-based SAT encoding for pseudo-boolean constraints with at-most-one relations},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A comprehensive survey on model compression and
acceleration. <em>AIR</em>, <em>53</em>(7), 5113–5155. (<a
href="https://doi.org/10.1007/s10462-020-09816-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, machine learning (ML) and deep learning (DL) have shown remarkable improvement in computer vision, natural language processing, stock prediction, forecasting, and audio processing to name a few. The size of the trained DL model is large for these complex tasks, which makes it difficult to deploy on resource-constrained devices. For instance, size of the pre-trained VGG16 model trained on the ImageNet dataset is more than 500 MB. Resource-constrained devices such as mobile phones and internet of things devices have limited memory and less computation power. For real-time applications, the trained models should be deployed on resource-constrained devices. Popular convolutional neural network models have millions of parameters that leads to increase in the size of the trained model. Hence, it becomes essential to compress and accelerate these models before deploying on resource-constrained devices while making the least compromise with the model accuracy. It is a challenging task to retain the same accuracy after compressing the model. To address this challenge, in the last couple of years many researchers have suggested different techniques for model compression and acceleration. In this paper, we have presented a survey of various techniques suggested for compressing and accelerating the ML and DL models. We have also discussed the challenges of the existing techniques and have provided future research directions in the field.},
  archive      = {J_AIR},
  author       = {Choudhary, Tejalal and Mishra, Vipul and Goswami, Anurag and Sarangapani, Jagannathan},
  doi          = {10.1007/s10462-020-09816-7},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5113-5155},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A comprehensive survey on model compression and acceleration},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Feed-forward versus recurrent architecture and local versus
cellular automata distributed representation in reservoir computing for
sequence memory learning. <em>AIR</em>, <em>53</em>(7), 5083–5112. (<a
href="https://doi.org/10.1007/s10462-020-09815-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reservoir computing based on cellular automata (ReCA) constructs a novel bridge between automata computational theory and recurrent neural networks. ReCA has been trained to solve 5-bit memory tasks. Several methods are proposed to implement the reservoir where the distributed representation of cellular automata (CA) in recurrent architecture could solve the 5-bit tasks with minimum complexity and minimum number of training examples. CA distributed representation in recurrent architecture outperforms the local representation in recurrent architecture (stack reservoir), then echo state networks and feed-forward architecture using local or distributed representation. Extracted features from the reservoir, using the natural diffusion of CA states in the reservoir offers the state-of-the-art results in terms of feature vector length and the required training examples. Another extension is obtained by combining the reservoir CA states using XOR, Binary or Gray operator to produce a single feature vector to reduce the feature space. This method gives promising results, however using the natural diffusion of CA states still outperform. ReCA can be considered to operate around the lower bound of complexity; due to using the elementary CA in the reservoir.},
  archive      = {J_AIR},
  author       = {Margem, Mrwan and Gedik, Osman S.},
  doi          = {10.1007/s10462-020-09815-8},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5083-5112},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Feed-forward versus recurrent architecture and local versus cellular automata distributed representation in reservoir computing for sequence memory learning},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Applicability of machine learning in spam and phishing email
filtering: Review and approaches. <em>AIR</em>, <em>53</em>(7),
5019–5081. (<a
href="https://doi.org/10.1007/s10462-020-09814-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the influx of technological advancements and the increased simplicity in communication, especially through emails, the upsurge in the volume of unsolicited bulk emails (UBEs) has become a severe threat to global security and economy. Spam emails not only waste users’ time, but also consume a lot of network bandwidth, and may also include malware as executable files. Alternatively, phishing emails falsely claim users’ personal information to facilitate identity theft and are comparatively more dangerous. Thus, there is an intrinsic need for the development of more robust and dependable UBE filters that facilitate automatic detection of such emails. There are several countermeasures to spam and phishing, including blacklisting and content-based filtering. However, in addition to content-based features, behavior-based features are well-suited in the detection of UBEs. Machine learning models are being extensively used by leading internet service providers like Yahoo, Gmail, and Outlook, to filter and classify UBEs successfully. There are far too many options to consider, owing to the need to facilitate UBE detection and the recent advances in this domain. In this paper, we aim at elucidating on the way of extracting email content and behavior-based features, what features are appropriate in the detection of UBEs, and the selection of the most discriminating feature set. Furthermore, to accurately handle the menace of UBEs, we facilitate an exhaustive comparative study using several state-of-the-art machine learning algorithms. Our proposed models resulted in an overall accuracy of 99\% in the classification of UBEs. The text is accompanied by snippets of Python code, to enable the reader to implement the approaches elucidated in this paper.},
  archive      = {J_AIR},
  author       = {Gangavarapu, Tushaar and Jaidhar, C. D. and Chanduka, Bhabesh},
  doi          = {10.1007/s10462-020-09814-9},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5019-5081},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Applicability of machine learning in spam and phishing email filtering: Review and approaches},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep neural network based rider-cuckoo search algorithm for
plant disease detection. <em>AIR</em>, <em>53</em>(7), 4993–5018. (<a
href="https://doi.org/10.1007/s10462-020-09813-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Agriculture is the main source of wealth, and its contribution is essential to humans. However, several obstacles faced by the farmers are due to different kinds of plant diseases. The determination and anticipation of plant diseases are the major concerns and should be considered for maximizing productivity. This paper proposes an effective image processing method for plant disease identification. In this research, the input image is subjected to the pre-processing phase for removing the noise and artifacts present in the image. After obtaining the pre-processed image, it is subjected to the segmentation phase for obtaining the segments using piecewise fuzzy C-means clustering (piFCM). Each segment undergoes a feature extraction phase in which the texture features are extracted, which involves information gain, histogram of oriented gradients (HOG), and entropy. The obtained texture features are subjected to the classification phase, which uses the deep belief network (DBN). Here, the proposed Rider-CSA is employed for training the DBN. The proposed Rider-CSA is designed by integrating the rider optimization algorithm (ROA) and Cuckoo Search (CS). The experimental results proved that the proposed Rider-CSA-DBN outperformed other existing methods with maximal accuracy of 0.877, sensitivity of 0.862, and the specificity of 0.877, respectively.},
  archive      = {J_AIR},
  author       = {Cristin, R. and Kumar, B. Santhosh and Priya, C. and Karthick, K.},
  doi          = {10.1007/s10462-020-09813-w},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {4993-5018},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Deep neural network based rider-cuckoo search algorithm for plant disease detection},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multiple-criteria decision making method based on the scaled
prioritized operators with unbalanced linguistic information.
<em>AIR</em>, <em>53</em>(7), 4967–4991. (<a
href="https://doi.org/10.1007/s10462-020-09812-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The unbalanced linguistic terms set (ULTS) is a special linguistic term set which can describe the vagueness assessment that is non-uniform and non-symmetrical distributed. So, it is effective to describe the uncertainty information existed in some special real decision making problems by ULTS. As a special prioritized operator, the scaled prioritized (SP) operator has the advantage of taking the priority among different criteria into account by detailed priority labels in known case and unknown case. In this paper, we combine the merits of SP operators and ULTS for dealing with some special multi-criteria decision making (MCDM) problems where there is a priority relationship between criteria under ULTS evaluation information. We present the unbalanced 2-tuple linguistic scaled prioritized averaging operator and the unbalanced 2-tuple linguistic scaled prioritized geometric averaging operator, which can handle the issues of the detailed priority relationship among different categories of MCDM problems in knowable case. Further, we propose the unbalanced 2-tuple linguistic scaled prioritized weighted averaging operator and the unbalanced 2-tuple linguistic scaled prioritized geometric weighted averaging operator, which can deal with the case when the detailed priority relationship among different categories of different criteria is unknowable. Then, we discussed several characteristics of the proposed operators, such as boundedness, monotonicity, and idempotency. Besides, we presented an approach for the MCDM problems according to the proposed operators. In the last, we provide an example to explain the calculating steps and effectiveness of these methods.},
  archive      = {J_AIR},
  author       = {Liu, Peide and Liu, Weiqiao},
  doi          = {10.1007/s10462-020-09812-x},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {4967-4991},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Multiple-criteria decision making method based on the scaled prioritized operators with unbalanced linguistic information},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The effect of downsampling–upsampling strategy on foreground
detection algorithms. <em>AIR</em>, <em>53</em>(7), 4935–4965. (<a
href="https://doi.org/10.1007/s10462-020-09811-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In video surveillance systems which incorporate stationary cameras, the first phase of movement object detection is crucial for the correct modelling of the behavior of these objects, as well as being the most complex in terms of execution time. There are many algorithms that provide a reliable and adequate segmentation mask, obtaining real-time ratios for reduced image sizes. However, due to the increased performance of camera hardware, the application of previous methods to sequences with higher resolutions (from 640 × 480 to 1920 × 1080) is not carried out in real time, compromising their use in real video surveillance systems. In this paper we propose a methodology to reduce the computational requirements of the algorithms, consisting of a reduction of the input frame and, subsequently, an interpolation of the segmentation mask of each method to recover the original frame size. In addition, the viability of this meta-model is analyzed together with the different selected algorithms, evaluating the quality of the resulting segmentation and its gain in terms of computation time.},
  archive      = {J_AIR},
  author       = {Molina-Cabello, Miguel A. and García-González, Jorge and Luque-Baena, Rafael M. and López-Rubio, Ezequiel},
  doi          = {10.1007/s10462-020-09811-y},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {4935-4965},
  shortjournal = {Artif. Intell. Rev.},
  title        = {The effect of downsampling–upsampling strategy on foreground detection algorithms},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A general framework for multi-granulation rough
decision-making method under q-rung dual hesitant fuzzy environment.
<em>AIR</em>, <em>53</em>(7), 4903–4933. (<a
href="https://doi.org/10.1007/s10462-020-09810-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the realistic decision-making (DM) process, the DM results were provided by multiple DM experts, which are more accurate than those based on one DM expert. Therefore, the multi-granulation rough set (MGRS) model is more accurate in DM problems. It is imperative to apply the idea of multi-granulation to the complex fuzzy uncertain information. By combining q-rung dual hesitant fuzzy sets (q-DHFSs) with multi-granulation rough sets (MGRSs) over two universes, we propose a q-rung dual hesitant fuzzy multi-granulation rough set (q-RDHFMGRS) over two universes, and prove some of their basic properties. Then, based on this model, we propose a new multi-attribute DM algorithm. Finally, we validate the practicability and validity of the algorithm through an example of medical diagnosis.},
  archive      = {J_AIR},
  author       = {Shao, Yabin and Qi, Xiaoding and Gong, Zengtai},
  doi          = {10.1007/s10462-020-09810-z},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {4903-4933},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A general framework for multi-granulation rough decision-making method under q-rung dual hesitant fuzzy environment},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A systematic review of gamification techniques applied to
elderly care. <em>AIR</em>, <em>53</em>(7), 4863–4901. (<a
href="https://doi.org/10.1007/s10462-020-09809-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proportion of the world’s population growing older is rapidly increasing over the last decades. With the recent progresses seen in information and communication technologies, there have been great concerns about developing personalized healthcare services that can ensure the living conditions and active aging of the elderly people. Among these technologies, we highlight and review in this work, the current state of gamification and related techniques applied to the elderly care context. Six research questions were defined to provide an overview on the current state in the development of gamified systems for elderly care through the identification of publication source types, research areas, target groups, game design elements and technologies employed and observed issues and benefits of using gamification in this context. Results have shown a great diversity in publication source types and research areas, even within the health domain. Different target groups were identified based on surrounding environment and physical and cognitive capabilities of the elderly person. Feedback, progression, rewards and social interaction enhancement are highlighted as the most relevant and frequently used game design elements for this context. Technological features observed include self-management systems, portable devices, physical robots, consoles and wearable technologies. The use of gamification techniques to support elderly people has proven to be beneficial to improve wellbeing as well as both physical, cognitive, social, and emotional state of the elderly person. Current challenges are most related with the need for traditional healthcare services to integrate gamification techniques to improve personalized healthcare and answer different necessities and adapt the support provided according to the individual capabilities of elderly people. The findings presented in this systematic literature review should be considered in the development of future personalized elderly care solutions by adapting the support provided according to interests, capabilities, necessities and contexts associated to the elderly person as a means to improve independence, health and wellbeing, capture interest and positive engagement, facilitate social interaction and decrease impact of many different medical conditions affecting older people.},
  archive      = {J_AIR},
  author       = {Martinho, Diogo and Carneiro, João and Corchado, Juan M. and Marreiros, Goreti},
  doi          = {10.1007/s10462-020-09809-6},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {4863-4901},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A systematic review of gamification techniques applied to elderly care},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A review for cervical histopathology image analysis using
machine vision approaches. <em>AIR</em>, <em>53</em>(7), 4821–4862. (<a
href="https://doi.org/10.1007/s10462-020-09808-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Because cervical histopathology image analysis plays a very importation role in the cancer diagnosis and medical treatment processes, since the 1980s, more and more effective machine vision techniques are introduced and applied in this field to assist histopathologists to obtain a more rapid, stable, objective, and quantified analysis result. To discover the inner relation between the visible images and the actual diseases, a variety of machine vision techniques are used to help the histopathologists to get to know more properties and characteristics of cervical tissues, referring to artificial intelligence, pattern recognition, and machine learning algorithms. Furthermore, because the machine vision approaches are usually semi- or full-automatic computer based methods, they are very efficient and labour cost saving, supporting a technical feasibility for cervical histopathology study in our current big data age. Hence, in this article, we comprehensively review the development history of this research field with two crossed pipelines, referring to all related works since 1988 till 2020. In the first pipeline, all related works are grouped by their corresponding application goals, including image segmentation, feature extraction, and classification. By this pipeline, it is easy for histopathologists to have an insight into each special application domain and find their interested applied machine vision techniques. In the second pipeline, the related works on each application goals are reviewed by their detailed technique categories. Using this pipeline, machine vision scientists can see the dynamic of technological development clearly and keep up with the future development trend in this interdisciplinary field.},
  archive      = {J_AIR},
  author       = {Li, Chen and Chen, Hao and Li, Xiaoyan and Xu, Ning and Hu, Zhijie and Xue, Dan and Qi, Shouliang and Ma, He and Zhang, Le and Sun, Hongzan},
  doi          = {10.1007/s10462-020-09808-7},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {4821-4862},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A review for cervical histopathology image analysis using machine vision approaches},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A self-verifying clustering approach to unsupervised
matching of product titles. <em>AIR</em>, <em>53</em>(7), 4777–4820. (<a
href="https://doi.org/10.1007/s10462-020-09807-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The continuous growth of the e-commerce industry has rendered the problem of product retrieval particularly important. As more enterprises move their activities on the Web, the volume and the diversity of the product-related information increase quickly. These factors make it difficult for the users to identify and compare the features of their desired products. Recent studies proved that the standard similarity metrics cannot effectively identify identical products, since similar titles often refer to different products and vice-versa. Other studies employ external data sources to enrich the titles; these solutions are rather impractical, since the process of fetching external data is inefficient. In this paper we introduce UPM, an unsupervised algorithm for matching products by their titles that is independent of any external sources. UPM consists of three stages. During the first stage, the algorithm analyzes the titles and extracts combinations of words out of them. These combinations are evaluated in stage 2 according to several criteria, and the most appropriate of them are selected to form the initial clusters. The third phase is a post-processing verification stage that refines the initial clusters by correcting the erroneous matches. This stage is designed to operate in combination with all clustering approaches, especially when the data possess properties that prevent the co-existence of two data points within the same cluster. The experimental evaluation of UPM with multiple datasets demonstrates its superiority against the state-of-the-art clustering approaches and string similarity metrics, in terms of both efficiency and effectiveness.},
  archive      = {J_AIR},
  author       = {Akritidis, Leonidas and Fevgas, Athanasios and Bozanis, Panayiotis and Makris, Christos},
  doi          = {10.1007/s10462-020-09807-8},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {4777-4820},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A self-verifying clustering approach to unsupervised matching of product titles},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Application of meta-heuristic methods to generation
expansion planning: Advanced formulations and case studies.
<em>AIR</em>, <em>53</em>(7), 4737–4776. (<a
href="https://doi.org/10.1007/s10462-020-09806-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The generation expansion planning (GEP) is a very relevant optimization problem in power systems research. Several factors must be considered in the management of an optimal planning that aims at expanding the generation, such as satisfying a growing demand, dealing with costs of investment, operation and maintenance, dealing with pollutant emission, among others. Considering these aspects, this problem tends to be very complex and meta-heuristics methods have been employed in order to provide satisfactory solutions. This paper aims at reviewing GEP considering five different formulations of the problem and how meta-heuristics approaches can be applied to it. For this purpose, two case studies are presented and, in order to provide a deep analysis, these methods are compared according to their performance, the solution provided by them, and also comparing results obtained among different formulations, which leads to a promising methodology and some interesting results provided.},
  archive      = {J_AIR},
  author       = {Costa Silva, Guilherme and Coelho, Frederico G. F. and Lisboa, Adriano C. and Vieira, Douglas A. G. and Saldanha, Rodney R.},
  doi          = {10.1007/s10462-020-09806-9},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {4737-4776},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Application of meta-heuristic methods to generation expansion planning: Advanced formulations and case studies},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A three-way decision method in a hybrid decision information
system and its application in medical diagnosis. <em>AIR</em>,
<em>53</em>(7), 4707–4736. (<a
href="https://doi.org/10.1007/s10462-020-09805-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the traditional two-way decision, there are only two kinds of decisions (i.e., acceptance and rejection). It will sometimes pay unnecessary costs when one makes decisions in this way. Therefore, a three-way decision is proposed to avoid losses that caused by error acceptance or false rejection in decision-making process. An information system is a database that represents relationships between objects and attributes. A hybrid information system is an information system where there exist many kinds of data (e.g., boolean, categorical, real-valued and set-valued data) and missing data. This paper proposes a three-way decision method in a hybrid decision information system. First, the hybrid distance between two objects based on the conditional attribute set in a given hybrid decision information system is developed. Then, the tolerance relation on the object set of this hybrid decision information system is obtained by using the hybrid distance. Next, as a natural extension of decision-theoretic rough set model in an information system, decision-theoretic rough set model in this hybrid decision information system is presented. Moreover, a three-way decision method based on this decision-theoretic rough set model is proposed by means of probability measure. Finally, an example of medical diagnosis is employed to illustrate the feasibility of the proposed method, which may provide an effective method for hybrid data analysis in real applications.},
  archive      = {J_AIR},
  author       = {Li, Zhaowen and Xie, Ningxin and Huang, Dan and Zhang, Gangqiang},
  doi          = {10.1007/s10462-020-09805-w},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {4707-4736},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A three-way decision method in a hybrid decision information system and its application in medical diagnosis},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Usage and implementation of neuro-fuzzy systems for
classification and prediction in the diagnosis of different types of
medical disorders: A decade review. <em>AIR</em>, <em>53</em>(7),
4651–4706. (<a
href="https://doi.org/10.1007/s10462-020-09804-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In classification and prediction of different types of medical disorders the neuro-fuzzy systems (NFS) are playing vital and significant role. To avoid false diagnosis the NFS assists medical practitioners to a greater extent in automating the domain dealing with medical disorders. With the passage of time the NFS approach has become apparent to enhance accuracy in dealing with a wide range of complicated research problems in the field of medical diagnosis. In this paper the author presents the literature review of the research done in implementing NFS in the field of medical diagnosis for current decade. Total of 100 publications in chronological advancement and up-gradation in models are considered for the time period of 10 years. A detailed study of each disease is carried out to discuss how NFS methodologies have been applied for classification and prediction in the diagnosis of different types of medical disorders. Ten (10) most severe medical disorders i.e. cancer, cardiovascular, depression and anxiety, diabetes, communicable, kidney, liver, neuro-degenerative, respiratory and thyroid has been undertaken for the study. Based on the study carried out it has been observed that NFS found to be effective as compared to the application of other AI techniques in medical diagnosis. Study reveals that effectiveness of NFS increases significantly when integrated with other AI approaches. This review adds into the knowledge of different researchers working in the field of medical diagnosis and will also give the comprehensive view of the effectiveness of the NFS techniques being used in medical diagnosis. The paper also incorporates a few research publications that were submitted in 2019 to incorporate the latest advances in medical science implementation of NFS.},
  archive      = {J_AIR},
  author       = {Kour, Haneet and Manhas, Jatinder and Sharma, Vinod},
  doi          = {10.1007/s10462-020-09804-x},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {4651-4706},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Usage and implementation of neuro-fuzzy systems for classification and prediction in the diagnosis of different types of medical disorders: A decade review},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Intuitionistic 2-tuple linguistic aggregation information
based on einstein operations and their applications in group decision
making. <em>AIR</em>, <em>53</em>(6), 4625–4650. (<a
href="https://doi.org/10.1007/s10462-020-09856-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The linguistic information can be expressed as a 2-tuple of a linguistic variable and a real number in an interval $$[-\frac{1}{2}, \frac{1}{2})$$ . The intuitionistic 2-tuple linguistic (I2TL) set accurately deals with the imprecise and unpredictable information in those decision-making problems where experts prefer the degree of membership and non-membership values in the form of 2-tuple. The existing approaches used for the aggregation operations of I2TL sets are extremely complicated. This work aims to develop new aggregation operations for I2TL sets using Einstein operations. We present intuitionistic 2-tuple linguistic Einstein weighted averaging (I2TLEWA), and intuitionistic 2-tuple linguistic Einstein weighted geometric (I2TLEWG) operators. We also discuss their properties and relationship between them. Moreover, we numerically test the feasibility and significance of our proposed operators by solving a multi-criteria group decision making (MCGDM) problem. Finally, we do a comparative analysis with another method to give insights on our designed operators for I2TL sets.},
  archive      = {J_AIR},
  author       = {Faizi, Shahzad and Nawaz, Shoaib and Ur-Rehman, Attique},
  doi          = {10.1007/s10462-020-09856-z},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4625-4650},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Intuitionistic 2-tuple linguistic aggregation information based on einstein operations and their applications in group decision making},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Theoretical study of GDM-SA-SVR algorithm on RAFM steel.
<em>AIR</em>, <em>53</em>(6), 4601–4623. (<a
href="https://doi.org/10.1007/s10462-020-09803-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of society and the exhaustion of fossil energy, we need to identify new alternative energy sources. Nuclear energy is an ideal choice, but the key to the successful application of nuclear technology is determined primarily by the behavior of nuclear materials in reactors. Therefore, we studied the radiation performance of the fusion material RAFM steel. We used the GDM algorithm to upgrade the annealing stabilization process of simulated annealing algorithm. The yield stress performance of RAFM steel was successfully predicted by the hybrid model, which combined simulated annealing with the support vector machine for the first time. The prediction process was as follows: first, we used the improved annealing algorithm to optimize the SVR model after training on a training dataset. Next, we established the yield stress prediction model of RAFM steel. By testing the model and conducting sensitivity analysis on the model, we can conclude that, compared with other similar models such as the ANN, linear regression, generalized regression neural network, and random forest, the predictive attribute variables cover all of the variables in the training set. Moreover, the generalization performance of the model on the test set is superior to that of other similar prediction models. Thus, this paper introduces a new method for the study of RAFM steel.},
  archive      = {J_AIR},
  author       = {Long, Sifan and Zhao, Ming},
  doi          = {10.1007/s10462-020-09803-y},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4601-4623},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Theoretical study of GDM-SA-SVR algorithm on RAFM steel},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A ground truth contest between modularity maximization and
modularity density maximization. <em>AIR</em>, <em>53</em>(6),
4575–4599. (<a
href="https://doi.org/10.1007/s10462-019-09802-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational techniques for network clustering identification are critical to several application domains. Recently, Modularity Maximization and Modularity Density Maximization have become two of the main techniques that provide computational methods to identify network clusterings. Therefore, understanding their differences and common characteristics is fundamental to decide which one is best suited for a given application. Several heuristics and exact methods have been developed for both Modularity Maximization and Modularity Density Maximization problems. Unfortunately, no structured methodological comparison between the two techniques has been proposed yet. This paper reports a ground truth contest between both optimization problems. We do so aiming to compare their exact solutions and the results of heuristics inspired in these problems. In our analysis, we use branch-and-price exact methods which apply the best-known column generation procedures. The heuristic methods obtain the highest objective function scores and find solutions for networks with hundreds of thousands of nodes. Our experiments suggest that Modularity Density Maximization yields the best results over the tested networks. The experiments also show the behavior and importance of the quantitative factor of the Modularity Density Maximization objective function.},
  archive      = {J_AIR},
  author       = {de Santiago, R. and Lamb, Luís C.},
  doi          = {10.1007/s10462-019-09802-8},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4575-4599},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A ground truth contest between modularity maximization and modularity density maximization},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An implicit opinion analysis model based on feature-based
implicit opinion patterns. <em>AIR</em>, <em>53</em>(6), 4547–4574. (<a
href="https://doi.org/10.1007/s10462-019-09801-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth of social networks, mining customer opinions based on online reviews is crucial to understand consumer needs. Due to the richness of language expressions, customer opinions are often expressed implicitly. However, previous studies usually focus on mining explicit opinions to understand consumer needs. In this paper, we propose a novel implicit opinion analysis model to perform implicit opinion analysis of Chinese customer reviews at both the feature and review levels. First, we extract an implicit-opinionated review/clause dataset from raw review dataset and introduce the concept of the feature-based implicit opinion pattern (FBIOP). Secondly, we develop a clustering algorithm to construct product feature categories. Based on the constructed feature categories, FBIOPs can be mined from the extracted implicit-opinionated clause dataset. Thirdly, the sentiment intensity and polarity of each FBIOP are calculated by using the Chi squared test and pointwise mutual information. Fourthly, according to the resulting FBIOP polarities, the polarities of implicit opinions can be determined at both the feature and review levels. Car forum reviews written in Chinese are collected and labeled as the experimental dataset. The results show that the proposed model outperforms the traditional support vector machine model and the cutting-edge convolutional neural network model.},
  archive      = {J_AIR},
  author       = {Fang, Zhao and Zhang, Qiang and Tang, Xiaoan and Wang, Anning and Baron, Claude},
  doi          = {10.1007/s10462-019-09801-9},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4547-4574},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An implicit opinion analysis model based on feature-based implicit opinion patterns},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey on feature selection approaches for clustering.
<em>AIR</em>, <em>53</em>(6), 4519–4545. (<a
href="https://doi.org/10.1007/s10462-019-09800-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The massive growth of data in recent years has led challenges in data mining and machine learning tasks. One of the major challenges is the selection of relevant features from the original set of available features that maximally improves the learning performance over that of the original feature set. This issue attracts researchers’ attention resulting in a variety of successful feature selection approaches in the literature. Although there exist several surveys on unsupervised learning (e.g., clustering), lots of works concerning unsupervised feature selection are missing in these surveys (e.g., evolutionary computation based feature selection for clustering) for identifying the strengths and weakness of those approaches. In this paper, we introduce a comprehensive survey on feature selection approaches for clustering by reflecting the advantages/disadvantages of current approaches from different perspectives and identifying promising trends for future research.},
  archive      = {J_AIR},
  author       = {Hancer, Emrah and Xue, Bing and Zhang, Mengjie},
  doi          = {10.1007/s10462-019-09800-w},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4519-4545},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey on feature selection approaches for clustering},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey of fracture detection techniques in bone x-ray
images. <em>AIR</em>, <em>53</em>(6), 4475–4517. (<a
href="https://doi.org/10.1007/s10462-019-09799-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radiologists interprets X-ray samples by visually inspecting them to diagnose the presence of fractures in various bones. Interpretation of radiographs is a time-consuming and intense process involving manual examination of fractures. In addition, clinician’s shortage in medically under-resourced areas, unavailability of expert radiologists in busy clinical settings or fatigue caused due to demanding workloads could lead to false detection rate and poor recovery of the fractures. A comprehensive study is imparted here covering fracture diagnosis with the aim to assist investigators in developing models that automatically detects fracture in human bones. The paper is presented in five folds. Firstly, we discuss data preparation stage. Second, we present various image-processing techniques used for fracture detection. Third, we analyze conventional and deep learning based techniques for diagnosing bone fractures. Fourth, we make comparative analysis of existing techniques. Fifth, we discuss different issues and challenges faced by researches while dealing with fracture detection.},
  archive      = {J_AIR},
  author       = {Joshi, Deepa and Singh, Thipendra P.},
  doi          = {10.1007/s10462-019-09799-0},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4475-4517},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey of fracture detection techniques in bone X-ray images},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Towards intrinsic autonomy through evolutionary computation.
<em>AIR</em>, <em>53</em>(6), 4449–4473. (<a
href="https://doi.org/10.1007/s10462-019-09798-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an embodied open-ended environment driven evolutionary algorithm capable of evolving behaviors of autonomous agents without any explicit description of objectives, evaluation metrics or cooperative dynamics. The main novelty of our technique is obtaining intrinsically motivated autonomy of a virtual robot in continuous activity, by internalizing evolutionary dynamics in order to achieve adaptation of a neural controller, and with no need to frequently restart the agent’s initial conditions as in traditional training methods. Our work is grounded on ideas from the enactive artificial intelligence field and the biological concept of enaction, from which it is argued that what makes a living being “intentional” is the ability to autonomously, adaptively rearrange their microstructure to suit some function in order to maintain its own constitution. We bring an alternative understanding of intrinsic motivation than that traditionally approached by intrinsic motivated reinforcement learning, and so we also make a brief discussion of the relationship between both paradigms and the autonomy of an agent. We show the autonomous development of foraging and navigation behaviors of a virtual robot.},
  archive      = {J_AIR},
  author       = {Nogueira, Yuri Lenon Barbosa and de Brito, Carlos Eduardo Fisch and Vidal, Creto Augusto and Cavalcante-Neto, Joaquim Bento},
  doi          = {10.1007/s10462-019-09798-1},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4449-4473},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Towards intrinsic autonomy through evolutionary computation},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey of semantic relatedness evaluation datasets and
procedures. <em>AIR</em>, <em>53</em>(6), 4407–4448. (<a
href="https://doi.org/10.1007/s10462-019-09796-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic relatedness between words is a core concept in natural language processing. While countless approaches have been proposed, measuring which one works best is still a challenging task. Thus, in this article, we give a comprehensive overview of the evaluation protocols and datasets for semantic relatedness covering both intrinsic and extrinsic approaches. One the intrinsic side, we give an overview of evaluation datasets covering more than 100 datasets in 20 different languages from a wide range of domains. To provide researchers with better guidance for selecting suitable dataset or even building new and better ones, we describe also the construction and annotation process of the datasets. We also shortly describe the evaluation metrics most frequently used for intrinsic evaluation. As for the extrinsic side, several applications involving semantic relatedness measures are detailed through recent research works and by explaining the benefit brought by the measures.},
  archive      = {J_AIR},
  author       = {Hadj Taieb, Mohamed Ali and Zesch, Torsten and Ben Aouicha, Mohamed},
  doi          = {10.1007/s10462-019-09796-3},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4407-4448},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey of semantic relatedness evaluation datasets and procedures},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On hesitant neutrosophic rough set over two universes and
its application. <em>AIR</em>, <em>53</em>(6), 4387–4406. (<a
href="https://doi.org/10.1007/s10462-019-09795-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a further generalization of the concepts of fuzzy set, intuitionistic fuzzy set, single valued neutrosophic refined set, hesitant fuzzy set, and dual hesitant fuzzy set, Ye (J Intell Syst 24(1):23–36, 2015) proposed the concept of hesitant neutrosophic sets (also called single valued neutrosophic hesitant fuzzy sets). Following the idea of hesitant neutrosophic sets as introduced by Ye, in this paper, the model of hesitant neutrosophic rough sets is proposed, then the join semi-lattice structure of lower and upper hesitant neutrosophic rough approximation operators over two universes is given. In addition, an algorithm to handle decision making problem in medical diagnosis based on hesitant neutrosophic rough sets over two universes is provided. Finally, a numerical example is employed to demonstrate the validness of the proposed hesitant neutrosophic rough sets.},
  archive      = {J_AIR},
  author       = {Zhao, Hu and Zhang, Hong-Ying},
  doi          = {10.1007/s10462-019-09795-4},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4387-4406},
  shortjournal = {Artif. Intell. Rev.},
  title        = {On hesitant neutrosophic rough set over two universes and its application},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sentiment analysis using deep learning architectures: A
review. <em>AIR</em>, <em>53</em>(6), 4335–4385. (<a
href="https://doi.org/10.1007/s10462-019-09794-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media is a powerful source of communication among people to share their sentiments in the form of opinions and views about any topic or article, which results in an enormous amount of unstructured information. Business organizations need to process and study these sentiments to investigate data and to gain business insights. Hence, to analyze these sentiments, various machine learning, and natural language processing-based approaches have been used in the past. However, deep learning-based methods are becoming very popular due to their high performance in recent times. This paper provides a detailed survey of popular deep learning models that are increasingly applied in sentiment analysis. We present a taxonomy of sentiment analysis and discuss the implications of popular deep learning architectures. The key contributions of various researchers are highlighted with the prime focus on deep learning approaches. The crucial sentiment analysis tasks are presented, and multiple languages are identified on which sentiment analysis is done. The survey also summarizes the popular datasets, key features of the datasets, deep learning model applied on them, accuracy obtained from them, and the comparison of various deep learning models. The primary purpose of this survey is to highlight the power of deep learning architectures for solving sentiment analysis problems.},
  archive      = {J_AIR},
  author       = {Yadav, Ashima and Vishwakarma, Dinesh Kumar},
  doi          = {10.1007/s10462-019-09794-5},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4335-4385},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Sentiment analysis using deep learning architectures: A review},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A comprehensive review of conditional random fields:
Variants, hybrids and applications. <em>AIR</em>, <em>53</em>(6),
4289–4333. (<a
href="https://doi.org/10.1007/s10462-019-09793-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The conditional random fields (CRFs) model plays an important role in the machine learning field. Driven by the development of the artificial intelligence, the CRF models have enjoyed great advancement. To analyze the recent development of the CRFs, this paper presents a comprehensive review of different versions of the CRF models and their applications. On the basis of elaborating on the background and definition of the CRFs, it analyzes three basic problems faced by the CRF models and reviews their latest improvements. Based on that, it presents the applications of the CRFs in the natural language processing, computer vision, biomedicine, Internet intelligence and other relevant fields. At last, specific analysis and future directions of the CRFs are discussed.},
  archive      = {J_AIR},
  author       = {Yu, Bengong and Fan, Zhaodi},
  doi          = {10.1007/s10462-019-09793-6},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4289-4333},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A comprehensive review of conditional random fields: Variants, hybrids and applications},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey of semi- and weakly supervised semantic
segmentation of images. <em>AIR</em>, <em>53</em>(6), 4259–4288. (<a
href="https://doi.org/10.1007/s10462-019-09792-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image semantic segmentation is one of the most important tasks in the field of computer vision, and it has made great progress in many applications. Many fully supervised deep learning models are designed to implement complex semantic segmentation tasks and the experimental results are remarkable. However, the acquisition of pixel-level labels in fully supervised learning is time consuming and laborious, semi-supervised and weakly supervised learning is gradually replacing fully supervised learning, thus achieving good results at a lower cost. Based on the commonly used models such as convolutional neural networks, fully convolutional networks, generative adversarial networks, this paper focuses on the core methods and reviews the semi- and weakly supervised semantic segmentation models in recent years. In the following chapters, existing evaluations and data sets are summarized in details and the experimental results are analyzed according to the data set. The last part of the paper is an objective summary. In addition, it points out the possible direction of research and inspiring suggestions for future work.},
  archive      = {J_AIR},
  author       = {Zhang, Man and Zhou, Yong and Zhao, Jiaqi and Man, Yiyun and Liu, Bing and Yao, Rui},
  doi          = {10.1007/s10462-019-09792-7},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4259-4288},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey of semi- and weakly supervised semantic segmentation of images},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sarcasm identification in textual data: Systematic review,
research challenges and open directions. <em>AIR</em>, <em>53</em>(6),
4215–4258. (<a
href="https://doi.org/10.1007/s10462-019-09791-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sarcasm is a form of sentiment whereby people express the implicit information, usually the opposite of the message content in order to hurt someone emotionally or criticise something in a humorous way. Sarcasm identification in textual data, being one of the hardest challenges in natural language processing (NLP), has recently become an interesting research area due to its importance in improving the sentiment analysis of social media data. A few studies have carried out a comprehensive literature review on sarcasm identification in the existing primary study within the last 11 years. Thus, this study carried out a review on the classification techniques for sarcasm identification under the aspects of datasets, pre-processing, feature engineering, classification algorithms, and performance metrics. The study has considered the published article from the period of 2008 to 2019. Forty (40) academic literature were selected from the 7 standard academic databases in order to carry out the review and realize the objectives. The study revealed that most researchers created their own datasets since there is no standard available datasets in the domain of sarcasm identification. Context and content-based linguistic features were used in most of the studies. This review shows that n-gram and parts of speech tagging techniques were the most commonly used feature extraction techniques. However, binary representation and term frequency were utilized for feature representation whereas Chi squared and information gain were used for the feature selection scheme. Moreover, classification algorithm such as support vector machine, Naïve Bayes, random forest, maximum entropy, and decision tree algorithm were mostly applied using accuracy, precision, recall and F-measure for performance measures. Finally, research challenges and future direction are summarized in this review. This review reveals the impact of sarcasm identification in building effective product reviews and would serve as handle resources for researchers and practitioners in sarcasm identification and text classification in general.},
  archive      = {J_AIR},
  author       = {Eke, Christopher Ifeanyi and Norman, Azah Anir and Liyana Shuib and Nweke, Henry Friday},
  doi          = {10.1007/s10462-019-09791-8},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4215-4258},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Sarcasm identification in textual data: Systematic review, research challenges and open directions},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A comprehensive review of bengali word sense disambiguation.
<em>AIR</em>, <em>53</em>(6), 4183–4213. (<a
href="https://doi.org/10.1007/s10462-019-09790-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The entities of communication have an enormous impact on interaction. Textual data is an important attribute of communication. Textual analysis of this data is carried out by the linguistic researchers in various perspectives. It helps to understand the people’s perception by analyzing the contextual data into its various senses. The sense of a polysemous word is varied according to its context. Hence, the process of identifying the proper meaning of a polysemous word with respect to the context is known as word sense disambiguation (WSD). For the extraction of actual meaning, WSD is an essential technique in Natural Language Processing. Over the last two decades, a lot of algorithms have been proposed to solve this linguistic ambiguity problem in various languages. In addition, a number of review papers have been published in various most spoken languages. Even so, it is elevating that there is a discontinuity in the literature when it comes to the techniques of Bengali WSD. This paper confers an extensive survey work regarding approaches of Bengali WSD. It also presents a survey work of the existing dataset of Bengali WSD.},
  archive      = {J_AIR},
  author       = {Das Dawn, Debapratim and Shaikh, Soharab Hossain and Pal, Rajat Kumar},
  doi          = {10.1007/s10462-019-09790-9},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4183-4213},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A comprehensive review of bengali word sense disambiguation},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Predicting firm failure in the software industry.
<em>AIR</em>, <em>53</em>(6), 4161–4182. (<a
href="https://doi.org/10.1007/s10462-019-09789-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Firm failure rate in the software industry is significantly higher than other industries. Due to the wide use of software products and services, failure in the software industry has implications on the industry itself as well as the economy at the local, national and global levels. This study compares the classification performance of thirteen approaches in terms of predicting firm failure in the US software industry. Seven measures are used to evaluate the classifiers’ performance. We use synthetic minority oversampling technique (SMOTE), SMOTEBoost and SMOTEBagging to account for the data imbalance issue. In order to give managers enough time to develop strategies and take the necessary actions to reduce the likelihood of failing, we use 20 financial indicators collected 4 years before the last available date about each firm. Our findings show that embedding SMOTE into boosting and bagging algorithms is better than preprocessing data using SMOTE before learning the classifier. According to the sensitivity analysis, research and development expense is the most significant predictor of firm failure followed by net sales and total revenue. Our results can be used by managers as a decision support tool to identify high-risk firms at an early stage and take the necessary actions to prevent a firm from failing. The early prediction of firm failure will allow software firms to modularize their products or services into specific “features” and offer them as “digital services” using new business models or combine these services with partner firms’ services to create new products and address evolving customer expectations. Moreover, the early prediction of firm failure in the software industry calls on firms, both new and those in the growth stage, to componentize their design for adaptability and to build agility in the way firms use their resource mix to address both market gaps as well as operational gaps.},
  archive      = {J_AIR},
  author       = {Roumani, Yazan F. and Nwankpa, Joseph K. and Tanniru, Mohan},
  doi          = {10.1007/s10462-019-09789-2},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4161-4182},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Predicting firm failure in the software industry},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Using deep learning techniques in medical imaging: A
systematic review of applications on CT and PET. <em>AIR</em>,
<em>53</em>(6), 4093–4160. (<a
href="https://doi.org/10.1007/s10462-019-09788-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical imaging is a rich source of invaluable information necessary for clinical judgements. However, the analysis of those exams is not a trivial assignment. In recent times, the use of deep learning (DL) techniques, supervised or unsupervised, has been empowered and it is one of the current research key areas in medical image analysis. This paper presents a survey of the use of DL architectures in computer-assisted imaging contexts, attending two different image modalities: the actively studied computed tomography and the under-studied positron emission tomography, as well as the combination of both modalities, which has been an important landmark in several decisions related to numerous diseases. In the making of this review, we analysed over 180 relevant studies, published between 2014 and 2019, that are sectioned by the purpose of the research and the imaging modality type. We conclude by addressing research issues and suggesting future directions for further improvement. To our best knowledge, there is no previous work making a review of this issue.},
  archive      = {J_AIR},
  author       = {Domingues, Inês and Pereira, Gisèle and Martins, Pedro and Duarte, Hugo and Santos, João and Abreu, Pedro Henriques},
  doi          = {10.1007/s10462-019-09788-3},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4093-4160},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Using deep learning techniques in medical imaging: A systematic review of applications on CT and PET},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Systematic review of spell-checkers for highly inflectional
languages. <em>AIR</em>, <em>53</em>(6), 4051–4092. (<a
href="https://doi.org/10.1007/s10462-019-09787-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Performance of any word processor, search engine, social media relies heavily on the spell-checkers, grammar checkers etc. Spell-checkers are the language tools which break down the text to check the spelling errors. It cautions the user if there is any unintentional misspelling occurred in the text. In the area of spell-checking, we still lack an exhaustive study that covers aspects like strengths, limitations, handled errors, performance along with the evaluation parameters. In literature, spell-checkers for different languages are available and each one possesses similar characteristics however, have a different design. This study follows the guidelines of systematic literature review and applies it to the field of spell-checking. The steps of the systematic review are employed on 130 selected articles published in leading journals, premier conferences and workshops in the field of spell-checking of different inflectional languages. These steps include framing of the research questions, selection of research articles, inclusion/exclusion criteria and the extraction of the relevant information from the selected research articles. The literature about spell-checking is divided into key sub-areas according to the languages. Each sub-area is then described based on the technique being used. In this study, various articles are analyzed on certain criteria to reach the conclusion. This article suggests how the techniques from the other domains like morphology, part-of-speech, chunking, stemming, hash-table etc. can be used in development of spell-checkers. It also highlights the major challenges faced by researchers along with the future area of research in the field of spell-checking.},
  archive      = {J_AIR},
  author       = {Singh, Shashank and Singh, Shailendra},
  doi          = {10.1007/s10462-019-09787-4},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4051-4092},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Systematic review of spell-checkers for highly inflectional languages},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Differential evolution algorithm with elite archive and
mutation strategies collaboration. <em>AIR</em>, <em>53</em>(6),
4005–4050. (<a
href="https://doi.org/10.1007/s10462-019-09786-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a differential evolution algorithm with elite archive and mutation strategies collaboration (EASCDE), wherein two main improvements are presented. Firstly, an elite archive mechanism is introduced to make DE/rand/3 and DE/current-to-best/2 mutation strategies converge faster. Secondly, a mutation strategies collaboration mechanism is developed to tightly combine both strategies to balance global exploration and local exploitation. As a result, EASCDE can effectively keep population diversity in the early stage and significantly enhance convergence speed as well as solution quality in the later stage. The performance of EASCDE is verified by experimental analyses on the well-known test functions. The results demonstrate that EASCDE is superior to other compared competitors in terms of solution precision, convergence speed and stability. Moreover, EASCDE is also an efficient method in dealing with arrival flights scheduling problem.},
  archive      = {J_AIR},
  author       = {Li, Yuzhen and Wang, Shihao},
  doi          = {10.1007/s10462-019-09786-5},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4005-4050},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Differential evolution algorithm with elite archive and mutation strategies collaboration},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An interactive multi-agent reasoning model for sentiment
analysis: A case for computational semiotics. <em>AIR</em>,
<em>53</em>(6), 3987–4004. (<a
href="https://doi.org/10.1007/s10462-019-09785-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semiotics is a domain that studies signs. For Peircean semiotics, a sign is not a dyadic entity, composed of a word and its meaning. Instead, meaning-making is a process of signification borne out of a strictly triadic relationship; in which a representative of a sign (word(s)) stands for its object (or meaning,) but never in a vacuum, and always for an interpretant. For Peirce, it is this third, this interpretant, through which the sign displays its meaning. What is even more important is that this rational process of signification is never being carried out by a single Mind, it requires a community of reasoners. In semiotic terms this article translates the sentiment analysis problem as follows: A sentence/comment is a representamen which has a sentiment value (its object) for an evolving community of reasoning agents (interpretant.) This article presents an interactive multi-agent system in which the agents implicitly model other agents, with a semiotic based approach towards sentiment analysis. It then tests the system on an original student evaluation of teachers dataset, compares the results with deep learning and other baseline techniques, and aims to propose semiotics as a reparative alternative to the dominant dichotomies—rule-based and data-based camps within artificial intelligence.},
  archive      = {J_AIR},
  author       = {Akhtar, Junaid},
  doi          = {10.1007/s10462-019-09785-6},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {3987-4004},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An interactive multi-agent reasoning model for sentiment analysis: A case for computational semiotics},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey of regularization strategies for deep models.
<em>AIR</em>, <em>53</em>(6), 3947–3986. (<a
href="https://doi.org/10.1007/s10462-019-09784-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The most critical concern in machine learning is how to make an algorithm that performs well both on training data and new data. No free lunch theorem implies that each specific task needs its own tailored machine learning algorithm to be designed. A set of strategies and preferences are built into learning machines to tune them for the problem at hand. These strategies and preferences, with the core concern of generalization improvement, are collectively known as regularization. In deep learning, because of a considerable number of parameters, a great many forms of regularization methods are available to the deep learning community. Developing more effective regularization strategies has been the subject of significant research efforts in recent years. However, it is difficult for developers to choose the most suitable strategy for their problem at hand, because there is no comparative study regarding the performance of different strategies. In this paper, at the first step, the most effective regularization methods and their variants are presented and analyzed in a systematic approach. At the second step, comparative research on regularization techniques is presented in which the testing errors and computational costs are evaluated in a convolutional neural network, using CIFAR-10 ( https://www.cs.toronto.edu/~kriz/cifar.html ) dataset. In the end, different regularization methods are compared in terms of accuracy of the network, the number of epochs for the network to be trained and the number of operations per input sample. Also, the results are discussed and interpreted based on the employed strategy. The experiment results showed that weight decay and data augmentation regularizations have little computational side effects so can be used in most applications. In the case of enough computational resources, Dropout family methods are rational to be used. Moreover, in the case of abundant computational resources, batch normalization family and ensemble methods are reasonable strategies to be employed.},
  archive      = {J_AIR},
  author       = {Moradi, Reza and Berangi, Reza and Minaei, Behrouz},
  doi          = {10.1007/s10462-019-09784-7},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {3947-3986},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey of regularization strategies for deep models},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On multi-resident activity recognition in ambient
smart-homes. <em>AIR</em>, <em>53</em>(6), 3929–3945. (<a
href="https://doi.org/10.1007/s10462-019-09783-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Increasing attention to the research on activity monitoring in smart homes has motivated the employment of ambient intelligence to reduce the deployment cost and solve the privacy issue. Several approaches have been proposed for multi-resident activity recognition, however, there still lacks a comprehensive benchmark for future research and practical selection of models. In this paper, we study different methods for multi-resident activity recognition and evaluate them on the same sets of data. In particular, we explore the effectiveness and efficiency of temporal learning algorithms using sequential data and non-temporal learning algorithms using temporally-manipulated features. In the experiments we compare and analyse the results of the studied methods using datasets from three smart homes.},
  archive      = {J_AIR},
  author       = {Tran, Son N. and Nguyen, Dung and Ngo, Tung-Son and Vu, Xuan-Son and Hoang, Long and Zhang, Qing and Karunanithi, Mohan},
  doi          = {10.1007/s10462-019-09783-8},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {3929-3945},
  shortjournal = {Artif. Intell. Rev.},
  title        = {On multi-resident activity recognition in ambient smart-homes},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Automatic ontology construction from text: A review from
shallow to deep learning trend. <em>AIR</em>, <em>53</em>(6), 3901–3928.
(<a href="https://doi.org/10.1007/s10462-019-09782-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The explosive growth of textual data on the web coupled with the increase on demand for ontologies to promote the semantic web, have made the automatic ontology construction from the text a very promising research area. Ontology learning (OL) from text is a process that aims to (semi-) automatically extract and represent the knowledge from text in machine-readable form. Ontology is considered one of the main cornerstones of representing the knowledge in a more meaningful way on the semantic web. Usage of ontologies has proven to be beneficial and efficient in different applications (e.g. information retrieval, information extraction, and question answering). Nevertheless, manually construction of ontologies is time-consuming as well extremely laborious and costly process. In recent years, many approaches and systems that try to automate the construction of ontologies have been developed. This paper reviews various approaches, systems, and challenges of automatic ontology construction from the text. In addition, it also discusses ways the ontology construction process could be enhanced in the future by presenting techniques from shallow learning to deep learning (DL).},
  archive      = {J_AIR},
  author       = {Al-Aswadi, Fatima N. and Chan, Huah Yong and Gan, Keng Hoon},
  doi          = {10.1007/s10462-019-09782-9},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {3901-3928},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Automatic ontology construction from text: A review from shallow to deep learning trend},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Semantic association computation: A comprehensive survey.
<em>AIR</em>, <em>53</em>(6), 3849–3899. (<a
href="https://doi.org/10.1007/s10462-019-09781-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic association computation is the process of quantifying the strength of a semantic connection between two textual units, based on different types of semantic relations. Semantic association computation is a key component of various applications belonging to a multitude of fields, such as computational linguistics, cognitive psychology, information retrieval and artificial intelligence. The field of semantic association computation has been studied for decades. The aim of this paper is to present a comprehensive survey of various approaches for computing semantic associations, categorized according to their underlying sources of background knowledge. Existing surveys on semantic computation have focused on a specific aspect of semantic associations, such as utilizing distributional semantics in association computation or types of spatial models of semantic associations. However, this paper has put a multitude of computational aspects and factors in one picture. This makes the article worth reading for those researchers who want to start off in the field of semantic associations computation. This paper introduces the fundamental elements of the association computation process, evaluation methodologies and pervasiveness of semantic measures in a variety of fields, relying on natural language semantics. Along the way, there is a detailed discussion on the main categories of background knowledge sources, classified as formal and informal knowledge sources, and the underlying design models, such as spatial, combinatorial and network models, that are used in the association computation process. The paper classifies existing approaches of semantic association computation into two broad categories, based on their utilization of background knowledge sources: knowledge-rich approaches; and knowledge-lean approaches. Each category is divided further into sub-categories, according to the type of underlying knowledge sources and design models of semantic association. A comparative analysis of strengths and limitations of various approaches belonging to each research stream is also presented. The paper concludes the survey by analyzing the pivotal factors that affect the performance of semantic association measures.},
  archive      = {J_AIR},
  author       = {Jabeen, Shahida and Gao, Xiaoying and Andreae, Peter},
  doi          = {10.1007/s10462-019-09781-w},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {3849-3899},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Semantic association computation: A comprehensive survey},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Pythagorean fuzzy MCDM method based on CoCoSo and CRITIC
with score function for 5G industry evaluation. <em>AIR</em>,
<em>53</em>(5), 3813–3847. (<a
href="https://doi.org/10.1007/s10462-019-09780-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The 5G industry is of great concern to countries to formulate a major national strategy for 5G planning, promote industrial upgrading, and accelerate their economic and technological modernization. When considering the 5G industry evaluation, the basic issues involve strong uncertainty. Pythagorean fuzzy sets, depicted by membership degree and non-membership degree, are a more resultful means for capturing uncertainty. In this paper, the comparison issue in Pythagorean fuzzy environment is disposed by proposing novel score function. Next, the $$\ominus $$ and $$\oslash $$ operations are defined and their properties are proved. Later, the objective weight is calculated by Criteria Importance Through Inter-criteria Correlation method. Meanwhile, the combined weight is determined by reflecting both subjective weight and the objective weight. Then, the Pythagorean fuzzy decision making algorithm based Combined Compromise Solution is developed. Lastly, the validity of algorithm is expounded by the 5G evaluation issue, along with their sensitivity analysis. The main advantages of proposed algorithm are: (1) have no counterintuitive phenomena; (2) without division or antilogarithm by zero problem; (3) own stronger ability to distinguish alternatives.},
  archive      = {J_AIR},
  author       = {Peng, Xindong and Zhang, Xiang and Luo, Zhigang},
  doi          = {10.1007/s10462-019-09780-x},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3813-3847},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Pythagorean fuzzy MCDM method based on CoCoSo and CRITIC with score function for 5G industry evaluation},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A comparative evaluation of novelty detection algorithms for
discrete sequences. <em>AIR</em>, <em>53</em>(5), 3787–3812. (<a
href="https://doi.org/10.1007/s10462-019-09779-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The identification of anomalies in temporal data is a core component of numerous research areas such as intrusion detection, fault prevention, genomics and fraud detection. This article provides an experimental comparison of candidate methods for the novelty detection problem applied to discrete sequences. The objective of this study is to identify which state-of-the-art methods are efficient and appropriate candidates for a given use case. These recommendations rely on extensive novelty detection experiments based on a variety of public datasets in addition to novel industrial datasets. We also perform thorough scalability and memory usage tests resulting in new supplementary insights of the methods’ performance, key selection criteria to solve problems relying on large volumes of data and to meet the expectations of applications subject to strict response time constraints.},
  archive      = {J_AIR},
  author       = {Domingues, Rémi and Michiardi, Pietro and Barlet, Jérémie and Filippone, Maurizio},
  doi          = {10.1007/s10462-019-09779-4},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3787-3812},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A comparative evaluation of novelty detection algorithms for discrete sequences},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Data-based composite control design with critic intelligence
for a wastewater treatment platform. <em>AIR</em>, <em>53</em>(5),
3773–3785. (<a
href="https://doi.org/10.1007/s10462-019-09778-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, by integrating neural network approximators, a data-based composite control technique is developed with critic learning implementation and wastewater treatment verification. The iterative adaptive critic framework is established involving dual heuristic dynamic programming (DHP), so as to obtain an intelligent optimal controller. Besides, a steady control input is computed with the help of the neural identifier. Then, by combining the DHP controller and the steady control input, an effective composite control strategy is derived and applied to the proposed wastewater treatment platform. Through conducting experiments, it is observed that the dissolved oxygen concentration and the nitrate level can be maintained at setting points successfully, which results in an intelligent wastewater treatment system.},
  archive      = {J_AIR},
  author       = {Wang, Ding and Ha, Mingming and Qiao, Junfei and Yan, Jun and Xie, Yingbo},
  doi          = {10.1007/s10462-019-09778-5},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3773-3785},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Data-based composite control design with critic intelligence for a wastewater treatment platform},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Saliency boosting: A novel framework to refine salient
object detection. <em>AIR</em>, <em>53</em>(5), 3731–3772. (<a
href="https://doi.org/10.1007/s10462-019-09777-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Salient object detection is a challenging research area and various methods have been proposed in literature. However, these methods usually focus on detecting salient objects in particular type of images only and fail when exposed to a variety of images. Here, we address this problem by proposing a novel framework called Saliency Boosting for refining saliency maps. In particular, the framework trains an Artificial Neural Network Regressor to refine initial saliency measures which are obtained from existing saliency methods. Extensive experiments on seven publicly available datasets viz. MSRA10K-test, DUT-OMRON-test, ECSSD, PASCAL-S, SED2, THUR15K, and HKU-IS have been performed to determine the effectiveness of the proposed framework. The performance of the proposed framework is measured in terms of Precision, Recall, F-Measure, Precision–Recall curve, Overlapping Ratio, Area Under the Curve and Receiver Operating Characteristic curve. The proposed framework is compared with 20 state-of-the-art-methods including best performing methods in the last decade. Further, performance of the proposed framework is better than each individual saliency detection method used in the framework. The proposed framework outperforms or is comparable with 20 state-of-the-art methods in terms of the aforementioned performance measures on all datasets.},
  archive      = {J_AIR},
  author       = {Singh, Vivek Kumar and Kumar, Nitin and Madhavan, Suresh},
  doi          = {10.1007/s10462-019-09777-6},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3731-3772},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Saliency boosting: A novel framework to refine salient object detection},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Iris recognition in unconstrained environment on graphic
processing units with CUDA. <em>AIR</em>, <em>53</em>(5), 3705–3729. (<a
href="https://doi.org/10.1007/s10462-019-09776-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Newly introduced Iris recognition systems (IRSs) run on serial processors. In this paper, an alternative method has been introduced for parallel processing on Graphic processing unit (GPU) with Compute unified device architecture (CUDA) in order to increase the speed of the system. The IRS has two main parallel processing criteria, which include the division of computations into hundreds of independent units and the time of calculation more than the time of transferring from the GPU. The IRS is divided into six stages including imaging, pre-processing, segmentation, normalization, feature extraction, and matching. In order to increase speed and accuracy, two stages of iris segmentation and matching play an important role in the IRS. In this paper parallel execution of an identical algorithm for these two stages has been used. The reason for paralleling the iris segmentation stage and their low speed matching is due to a great amount of information in the iris database, plenty of calculations and lack of data dependency in these two stages. For parallelism at the segmentation stage, for each radius, the Hough transform (HT) is a processor, and in the matching stage two parts are considered: The first part consists of 32 actions comparing the input code with the database code in parallel and in the second part 2048 bits with the use of threads on each processor is performed in two sub-sections in pairs of bits and in parallel with each other. Finally, the two-way coding is achieved. In compare of existing methods, this method has rather more accurate and is also superior in terms of processing time on the GPU with CUDA. The results of the implementation of the above method on the images in UBIRIS, BATH, CASIA and MMUI databases show that the proposed method has a precision accuracy of 99.12\%, 97.98\%, 98.80\% and 98.34\%, respectively, and the average speedup for parallel processing of images in the database in the proposed method on the GPU with CUDA are 18.8, 14.7, 18, and 19 times, respectively.},
  archive      = {J_AIR},
  author       = {Noruzi, Ali and Mahlouji, Mahmoud and Shahidinejad, Ali},
  doi          = {10.1007/s10462-019-09776-7},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3705-3729},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Iris recognition in unconstrained environment on graphic processing units with CUDA},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). ASRoIL: A comprehensive survey for automatic speech
recognition of indian languages. <em>AIR</em>, <em>53</em>(5),
3673–3704. (<a
href="https://doi.org/10.1007/s10462-019-09775-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {India is the land of language diversity with 22 major languages having more than 720 dialects, written in 13 different scripts. Out of 22, Hindi, Bengali, Punjabi is ranked 3rd, 7th and 10th most spoken languages around the globe. Expect Hindi, where one can find some significant research going on, other two major languages and other Indian languages have not fully developed Automatic Speech Recognition systems. The main aim of this paper is to provide a systematic survey of the existing literature related to automatic speech recognition (i.e. speech to text) for Indian languages. The survey analyses the possible opportunities, challenges, techniques, methods and to locate, appraise and synthesize the evidence from studies to provide empirical answers to the scientific questions. The survey was conducted based on the relevant research articles published from 2000 to 2018. The purpose of this systematic survey is to sum up the best available research on automatic speech recognition of Indian languages that is done by synthesizing the results of several studies.},
  archive      = {J_AIR},
  author       = {Singh, Amitoj and Kadyan, Virender and Kumar, Munish and Bassan, Nancy},
  doi          = {10.1007/s10462-019-09775-8},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3673-3704},
  shortjournal = {Artif. Intell. Rev.},
  title        = {ASRoIL: A comprehensive survey for automatic speech recognition of indian languages},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). TODIM-based multi-criteria decision-making method with
hesitant fuzzy linguistic term sets. <em>AIR</em>, <em>53</em>(5),
3647–3671. (<a
href="https://doi.org/10.1007/s10462-019-09774-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a popular tool for modeling the qualitative assessment information, the hesitant fuzzy linguistic term sets (HFLTSs) can allow the decision makes or experts to give several possible linguistic terms to rate the objects with respect to the criterion. Although there exist many multi-criteria decision-making methods put forward for handling the HFLTSs, they were developed based on the assumption that the decision makers can always provide completely rational assessments and they do not take the decision makers’ psychological behaviors into consideration. In this paper, the traditional TODIM (an acronym in Portuguese for interactive multi-criteria decision making) method is extended to handle the HFLTSs based on the novel comparison function and distance measure. Firstly, we put forward a novel function for comparing two HFLTSs more effectively. After that, a novel hesitance degree function as well as some novel distance measures are given for HFLTSs. Then we apply them to extend the traditional TODIM method for solving the HFLTSs. Finally, a practical example concerning the evaluation and ranking of several satellite launching centers is provided to illustrate the validity and applicability of the proposed method.},
  archive      = {J_AIR},
  author       = {Lin, Mingwei and Wang, Huibing and Xu, Zeshui},
  doi          = {10.1007/s10462-019-09774-9},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3647-3671},
  shortjournal = {Artif. Intell. Rev.},
  title        = {TODIM-based multi-criteria decision-making method with hesitant fuzzy linguistic term sets},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Opportunities and challenges in enhancing access to metadata
of cultural heritage collections: A survey. <em>AIR</em>,
<em>53</em>(5), 3621–3646. (<a
href="https://doi.org/10.1007/s10462-019-09773-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine processable data that narrate digital/non-digital resources are termed as metadata. Different metadata standards exist for describing various types of digital objects. Several researches have reported on how to address issues related to accessing of metadata resources. Most studies on metadata involve cultural heritage domain, and this is an indication of the importance of this domain in metadata research and development. Research on metadata in cultural heritage mainly revolves around three fundamental issues: (1) lack of quality in metadata contents in most of the cases, (2) difficulty in accessing metadata contents due largely to limited user’s knowledge on the content of the metadata, and (3) heterogeneity of the data at the level of schemas which makes the access even more difficult. The lack of quality in metadata makes it difficult for the users to retrieve and explore information that satisfies their needs. So, in order to make its contents more accessible, enhancing the metadata content is required, especially for cultural heritage collections which consist of digital objects (structured documents) described by a variety of metadata schemas. This paper presents issues and challenges in enhancing access to metadata by reviewing the existing approaches in metadata environment with a particular emphasis on cultural heritage collections. In this paper, firstly, we look at the classification of metadata which is divided into two categories namely data retrieval and information retrieval. Then, we present the analysis, findings and suggestions on how to address issues in enhancing access to metadata contents especially in cultural heritage collections. A detailed comparison is given between information retrieval and data retrieval, and it focuses on the applicability of one approach over the other. A framework that aims to improve the effectiveness of retrieval when searching metadata is also proposed and tested. The proposed framework consists of approaches and methods that are expected to enhance access to metadata especially in cultural heritage collections and be useful for those with limited knowledge on cultural heritage. The experiments were conducted on CHiC2013 which is a collection on cultural heritage. The results show a considerable enhancement over other IR approaches that use the expansion methods.},
  archive      = {J_AIR},
  author       = {Alma’aitah, Wafa’ Za’al and Talib, Abdullah Zawawi and Osman, Mohd Azam},
  doi          = {10.1007/s10462-019-09773-w},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3621-3646},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Opportunities and challenges in enhancing access to metadata of cultural heritage collections: A survey},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Novel aggregation operators and ranking method for complex
intuitionistic fuzzy sets and their applications to decision-making
process. <em>AIR</em>, <em>53</em>(5), 3595–3620. (<a
href="https://doi.org/10.1007/s10462-019-09772-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex intuitionistic fuzzy set (CIFS) is a distinctive intuitionistic fuzzy set (IFS) in which the membership degrees are determined on the unit disc of the complex plane and can more clearly express the imprecision and ambiguity in the data. The prevailing studies on IFS deal with the data over the subset of a real number and hence there is a sacrifice of some information during the method under certain conditions. As an alteration to these, CIFS characterized with supplementary terms in membership degrees called as phase terms and hence examine two-dimensional data concurrently in a single set. To get full utilization of these assets, in this paper, the aim of the practice is classified into two turns: (i) to define the possibility degree measure to order the numbers, and (ii) to define some novel operational laws and aggregation operators (AOs) to aggregate the various choices over CIFS environment. The beneficial features of the proposed weighted averaging and geometric AOs are addressed. Finally, a decision-making approach is extended for the multicriteria decision-making problem with complex intuitionistic fuzzy information, in which weights are managed objectively. A practical illustration is furnished to address the availability and advantages of the proposed method by comparison with some existing methods.},
  archive      = {J_AIR},
  author       = {Garg, Harish and Rani, Dimple},
  doi          = {10.1007/s10462-019-09772-x},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3595-3620},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Novel aggregation operators and ranking method for complex intuitionistic fuzzy sets and their applications to decision-making process},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Analyzing rare event, anomaly, novelty and outlier detection
terms under the supervised classification framework. <em>AIR</em>,
<em>53</em>(5), 3575–3594. (<a
href="https://doi.org/10.1007/s10462-019-09771-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, a variety of research areas have contributed to a set of related problems with rare event, anomaly, novelty and outlier detection terms as the main actors. These multiple research areas have created a mix-up between terminology and problems. In some research, similar problems have been named differently; while in some other works, the same term has been used to describe different problems. This confusion between terms and problems causes the repetition of research and hinders the advance of the field. Therefore, a standardization is imperative. The goal of this paper is to underline the differences between each term, and organize the area by looking at all these terms under the umbrella of supervised classification. Therefore, a one-to-one assignment of terms to learning scenarios is proposed. In fact, each learning scenario is associated with the term most frequently used in the literature. In order to validate this proposal, a set of experiments retrieving papers from Google Scholar, ACM Digital Library and IEEE Xplore has been carried out.},
  archive      = {J_AIR},
  author       = {Carreño, Ander and Inza, Iñaki and Lozano, Jose A.},
  doi          = {10.1007/s10462-019-09771-y},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3575-3594},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Analyzing rare event, anomaly, novelty and outlier detection terms under the supervised classification framework},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Computerized acoustical techniques for respiratory
flow-sound analysis: A systematic review. <em>AIR</em>, <em>53</em>(5),
3501–3574. (<a
href="https://doi.org/10.1007/s10462-019-09769-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computerized respiratory sound analysis has recently captured the attention of researchers, and its implementation can assist physicians in the diagnosis of pulmonary pathologies. The relationship between respiratory sounds and breathing flow reveals the pathophysiology of the respiratory system and can be used as a basis for acoustical airflow estimation. Respiratory sound signals are also acoustically analysed for the detection of breath phases. Although this research area is being actively studied, the available literature has not been reviewed. This manuscript highlights the previous studies that focused on the use of computer-based acoustical techniques for the analysis of respiratory sounds and airflow. Articles related to computerized respiratory flow-sound analysis were identified through a search of the Scopus academic database, and 66 articles were ultimately selected for this systematic review. A brief overview of the subject details, auscultation sites, respiratory manoeuvres, sound parameters of interest and techniques used is provided. The findings revealed the following: (1) deterministic relationships can be established between airflow and respiratory sounds, (2) an established strong flow-sound correlation can be used for airflow estimation, (3) breath phase detection and identification without flow measuring devices remains in the infancy research stage and (4) further research needed to examine the potential of computerized respiratory sound analysis in revealing the pathophysiology of airways for future clinical implementation. This review concludes by discussing the possibilities and recommendations for further advancements in computerized acoustical flow-sound analysis.},
  archive      = {J_AIR},
  author       = {Muthusamy, Priya Devi and Sundaraj, Kenneth and Abd Manap, Nurulfajar},
  doi          = {10.1007/s10462-019-09769-6},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3501-3574},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Computerized acoustical techniques for respiratory flow-sound analysis: A systematic review},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A review of applications of artificial intelligent
algorithms in wind farms. <em>AIR</em>, <em>53</em>(5), 3447–3500. (<a
href="https://doi.org/10.1007/s10462-019-09768-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wind farms are enormous and complex control systems. It is challenging and valuable to control and optimize wind farms. Their applications are widely used in various industries. Artificial intelligent algorithms are effective methods for optimization problems due to their distinctive characteristics. They have been successfully applied to wind farms. In this paper, several issues in wind farms are presented. Applications of artificial intelligent algorithms in wind farm controllers, Mach number, wind speed prediction, wind power prediction and other problems of wind farms are reviewed. Two future research directions are pointed out to develop artificial intelligent algorithms for wind farm control systems and wind speed and power prediction.},
  archive      = {J_AIR},
  author       = {Wang, Yirui and Yu, Yang and Cao, Shuyang and Zhang, Xingyi and Gao, Shangce},
  doi          = {10.1007/s10462-019-09768-7},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3447-3500},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A review of applications of artificial intelligent algorithms in wind farms},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cancelable biometrics: A comprehensive survey. <em>AIR</em>,
<em>53</em>(5), 3403–3446. (<a
href="https://doi.org/10.1007/s10462-019-09767-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biometric recognition is a challenging research field but suffers from privacy and security concerns. To address this concern, Cancelable Biometrics is suggested in literature in which a Biometric image of a sample is distorted or transformed in such a manner that it becomes difficult to obtain the original Biometric image from the distorted one. Another important characteristic of Cancelable Biometrics is that it can be reissued if compromised. In this research paper, we present a comprehensive survey of more than 120 techniques suggested by various researchers from time to time for Cancelable Biometrics and a novel taxonomy for the same is developed. Further, various performance measures used in Cancelable Biometrics are reviewed and their mathematical formulations are given. Cancelable Biometrics also suffer from various security attacks as given in literature. A review of these security attacks is carried out. We have also performed a review of databases used in literature for nine different Cancelable Biometrics viz. Face, Iris, Speech, Fingerprint, Signature, Palmprint, ECG, Palmvein and Fingervein. Lastly, we have also given future research directions in this field. This study shall be useful for the researchers and practitioners working in this fascinating research area.},
  archive      = {J_AIR},
  author       = {Manisha and Kumar, Nitin},
  doi          = {10.1007/s10462-019-09767-8},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3403-3446},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Cancelable biometrics: A comprehensive survey},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Brain structural disorders detection and classification
approaches: A review. <em>AIR</em>, <em>53</em>(5), 3349–3401. (<a
href="https://doi.org/10.1007/s10462-019-09766-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is an effort to encapsulate the various developments in the domain of different unsupervised, supervised and half supervised brain anomaly detection approaches or techniques proposed by the researchers working in the domain of the Medical image segmentation and classification. As researchers are constantly working hard in the domain of image segregation, interpretation and computer vision in order to automate the task of tumour segmentation, anomaly detection, classification and other structural disorder prediction at an early stage with the aid of computer. The different medical imaging modalities are used by the doctors in order to diagnose the brain tumour and other structural brain disorders which are an integral part of diagnosis and prognosis process. When these different medical image modalities are used along with various image segmentation methods and machine learning approaches tends to perform brain structural disorder detection and classification in a semi-automated or fully automated manner with high accuracy. This paper presents all such approaches using various medical image modalities for the accurate detection and classification of brain tumour and other brain structural disorders. In this paper, all the major phases of any brain tumour or brain structural disorder detection and classification approach is covered begin with the comparison of various medical image pre-processing techniques then major segmentation approaches followed by the approaches based on machine learning. This paper also presents an evaluation and comparison among the various popular texture and shape based feature extraction methods used in combination with different machine learning classifiers on the BRATS 2013 dataset. The fusion of MRI modalities used along with the hybrid features extraction methods and ensemble model delivers the best result in terms of accuracy.},
  archive      = {J_AIR},
  author       = {Bhatele, Kirti Raj and Bhadauria, Sarita Singh},
  doi          = {10.1007/s10462-019-09766-9},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3349-3401},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Brain structural disorders detection and classification approaches: A review},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Neural networks for facial age estimation: A survey on
recent advances. <em>AIR</em>, <em>53</em>(5), 3299–3347. (<a
href="https://doi.org/10.1007/s10462-019-09765-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft biometrics has emerged out to be a new area of interest for the researchers due to its growing real-world applications. It includes the estimation of demographic traits like age, gender, scars, ethnicity. Moreover, researchers are trying to develop models which can accurately estimate the age or the age group of a person using different biometric traits. Presently, neural networks proves out to give the best classification results for age estimation using human faces. Hence, in this paper, we have surveyed and compared all the neural network models developed and implemented for facial age estimation from 2010 to 2019. We have precisely compared all twenty-three different research works done so far to estimate age from human faces using neural networks. Most of the works are based on convolutional neural networks and a few are based on feed forward back propagation and autoencoders. Important details, issues and results of each work are thoroughly discussed for better knowledge of interested researchers. This paper also includes details on other classification techniques for facial age estimation to give an overall idea of all additional techniques adopted by the scientists till date. Details like neural network model names, datasets used, main contributions, evaluation metrics and results are adopted for a tabular and easy to understand comparison study. Finally, the paper concludes by mentioning the other relevant future research tasks that can be done in this challenging area of research.},
  archive      = {J_AIR},
  author       = {Punyani, Prachi and Gupta, Rashmi and Kumar, Ashwani},
  doi          = {10.1007/s10462-019-09765-w},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3299-3347},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Neural networks for facial age estimation: A survey on recent advances},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A systematic review and meta-analysis on performance of
intelligent systems in lung cancer: Where are we? <em>AIR</em>,
<em>53</em>(5), 3287–3298. (<a
href="https://doi.org/10.1007/s10462-019-09764-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cancer is one of the human’s life-threatening diseases that does not merely pertain to one organ. Despite the varieties of cancers, lung cancer, with its different growth and spreading mechanisms, can affect the normal cells and disrupt the cell signaling procedure that alters the cell division function. In this systematic review and meta-analysis, the well-known databases are searched based on a Boolean query exclusively for lung cancer and the corresponding artificial intelligent systems. By systematically searching the PubMed and Scopus databases, English-language articles published up to 13 July 2017 were extracted that identify the cancerous and normal cell images using different types of predictive models. Then, the search results will be selected for the pertinent articles encompassing the required information (i.e., inclusion criterion) such as total sample size, true positive, true negative, false positive, and false negative values. The studies without enough information were omitted from further analysis. Considering the lung cancer diagnosis and conducting the meta-analysis on the articles, the results for the improvement trends in the amount of success in the performance of the artificially intelligent systems have been reported. Eventually, two publication bias tests have shown that the possibility of publication bias exists. And, the trends on diagnostic odds ratio and AUC values were immeasurably high, respectively, while those of sensitivity and specificity were moderate.},
  archive      = {J_AIR},
  author       = {Sokouti, Massoud and Sokouti, Mohsen and Sokouti, Babak},
  doi          = {10.1007/s10462-019-09764-x},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3287-3298},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A systematic review and meta-analysis on performance of intelligent systems in lung cancer: Where are we?},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An efficient intrusion detection technique based on support
vector machine and improved binary gravitational search algorithm.
<em>AIR</em>, <em>53</em>(5), 3255–3286. (<a
href="https://doi.org/10.1007/s10462-019-09762-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {‘Curse of Dimensionality’ and the trade-off between high detection rate and less false alarm rate make the design of an efficient and robust Intrusion Detection System, an open research challenge. In this way, we present Hyper Clique—Improved Binary Gravitational Search Algorithm based Support Vector Machine (HC-IBGSA SVM), an efficient and adaptive intrusion detection technique to improve the performance of SVM in terms of detection rate and false alarm rate. HC-IBGSA SVM employs hyper clique property of hypergraph, novel mutation operator, and Newton–Raphson inspired position update function to fasten the search for an optimal solution and to prevent premature convergence. Further, HC-IBGSA uses a weighted objective function to maintain the trade-off between maximizing detection rate and minimizing the false alarm rate and the optimal number of features. The experimental evaluations were carried out using two benchmark intrusion datasets, namely NSL-KDD CUP dataset and UNSW-NB15 dataset under two scenarios (1) SVM trained with all features, and (2) SVM trained with the optimal feature subset and model parameters obtained from HC-IBGSA in terms of various quality metrics, stability analysis and statistical test.},
  archive      = {J_AIR},
  author       = {Gauthama Raman, M. R. and Somu, Nivethitha and Jagarapu, Sahruday and Manghnani, Tina and Selvam, Thirumaran and Krithivasan, Kannan and Shankar Sriram, V. S.},
  doi          = {10.1007/s10462-019-09762-z},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3255-3286},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An efficient intrusion detection technique based on support vector machine and improved binary gravitational search algorithm},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Detecting the presence of anterior cruciate ligament
deficiency based on a double pendulum model, intrinsic time-scale
decomposition (ITD) and neural networks. <em>AIR</em>, <em>53</em>(5),
3231–3253. (<a
href="https://doi.org/10.1007/s10462-019-09761-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The anterior cruciate ligament (ACL) possesses the function of stabilizing the knee joint through limiting anterior tibial translation and controlling tibial rotation. Patients with unilateral ACL deficiency often demonstrate alterations of knee kinematics, kinetics and gait patterns in the deficient side in comparison to the unaffected contralateral side. This also leads to the early onset of osteoarthritis. In order to detect and monitor the progression of ACL deficiency over time, various classification approaches using spatiotemporal gait variables have been presented. In this study we propose a novel method for classifying gait patterns between ACL-deficient (ACLD) knee and unaffected contralateral ACL-intact (ACLI) knee based upon gait system dynamics, intrinsic time-scale decomposition (ITD) and neural networks. First, human leg is modeled as a double-pendulum to imitate and simplify the human walking. Since the lower extremities act as a kinetic chain during dynamic tasks, control of the hip joint will interact with knee motion. Related gait kinematic parameters including knee and hip joint angle and angular velocity are decomposed into a series of proper rotation components (PRCs) and a baseline signal by using the ITD method. The first PRCs of knee and hip joint angle and angular velocity are extracted, which contain most of the kinematic signals’ vibration energy and are considered to be the predominant PRCs. Third, neural networks are then used as the classifier with feature vectors as the input to distinguish between ACLD and ACLI knees based on the difference of gait system dynamics between the two groups. Finally, experiments are carried out on forty-three patients to assess the effectiveness of the proposed method. By using the leave-one-out cross-validation style under normal and fast walking speed conditions, the correct classification rates are reported to be $$95.12\%$$ and $$93.28\%$$, respectively. In comparison to other state-of-the-art methods, the results demonstrate superior performance and the proposed method may serve as a potential assistant tool for the automatic detection of ACL deficiency in the clinical application.},
  archive      = {J_AIR},
  author       = {Zeng, Wei and Ismail, Shiek Abdullah and Pappas, Evangelos},
  doi          = {10.1007/s10462-019-09761-0},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3231-3253},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Detecting the presence of anterior cruciate ligament deficiency based on a double pendulum model, intrinsic time-scale decomposition (ITD) and neural networks},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Machine learning in telemetry data mining of space mission:
Basics, challenging and future directions. <em>AIR</em>, <em>53</em>(5),
3201–3230. (<a
href="https://doi.org/10.1007/s10462-019-09760-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of an intelligent artificial satellite health monitoring system is a key issue in aerospace engineering that determines satellite health status and failure using telemetry data. The modern design of data mining and machine learning technologies allows the use of satellite telemetry data and the mining of integrated information to produce an advanced health monitoring system. This paper reviews the current status and presents a framework of necessary processes on data mining to solving various problems in telemetry data such as error detection, prediction, summarization, and visualization of large quantities, and help them understand the health status of the satellite and detect the symptoms of anomalies. Machine learning technologies that include neural networks, fuzzy sets, rough sets, support vector machines, Naive Bayesian, swarm optimization, and deep learning are also presented. Also, this paper reviews a wide range of existing satellite health monitoring solutions and discusses them in the framework of remote data mining techniques. In addition, we are discussing the analysis of space debris flow analysis and the prediction of low earth orbit collision based on our orbital Petri nets model. Challenges to be addressed and future directions of research are identified and an extensive bibliography is also included.},
  archive      = {J_AIR},
  author       = {Hassanien, Aboul Ella and Darwish, Ashraf and Abdelghafar, Sara},
  doi          = {10.1007/s10462-019-09760-1},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3201-3230},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Machine learning in telemetry data mining of space mission: Basics, challenging and future directions},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An integrating genetic algorithm and modified newton method
for tracking control and vibration suppression. <em>AIR</em>,
<em>53</em>(5), 3177–3199. (<a
href="https://doi.org/10.1007/s10462-019-09759-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the trend toward taller and more flexible building structures, a mass-damper shaking table system has been considered as means for vibration suppression to external excitation and disturbances in recent years. However, there are few researches on the control of nonlinear structure using active mass damper under earthquake excitation, especially for high-rise building. This study presents a model combining the advantages of adaptive genetic algorithm and modified Newton method is developed for system identification and vibration suppression of a building structure with an active mass damper. The genetic algorithm with adaptive reproduction, crossover, and mutation operators is to search for initial weight and bias of the neural network, while the modified Newton method, similar to BFGS algorithm, is to increase network training performance. Experimental results show that the controller performance is strongly influenced by the accuracy of system identification. The controller is also shown to be robust to variations in system parameters.},
  archive      = {J_AIR},
  author       = {Chen, Chuen-Jyh},
  doi          = {10.1007/s10462-019-09759-8},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3177-3199},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An integrating genetic algorithm and modified newton method for tracking control and vibration suppression},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Detecting the presence of anterior cruciate ligament injury
based on gait dynamics disparity and neural networks. <em>AIR</em>,
<em>53</em>(5), 3153–3176. (<a
href="https://doi.org/10.1007/s10462-019-09758-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this study is to develop a new pattern recognition-based method to model and discriminate gait dynamics disparity between anterior cruciate ligament (ACL) deficient (ACL-D) knee and contralateral ACL-intact (ACL-I) knee in patients with unilateral ACL deficiency by using kinematic features and neural networks. Thereby the capabilities of these features to detect the presence of injury can be assessed. The proposed method consists of two stages. In the first (training) stage, gait analysis is performed. A two-dimensional five-link biped model used for imitating human gait locomotion is employed to demonstrate that functions containing kinematic data of lower extremities, including knee and hip flexion/extension angles and angular velocities, characterize the gait system dynamics. Knee angle-hip angle cyclograms, knee and hip angle-angular velocity phase portraits visually demonstrate the significant disparity of gait dynamics between the lower extremities of patients with unilateral ACL deficiency. Gait dynamics underlying gait patterns of ACL-D and ACL-I knees are locally accurately modeled and approximated by radial basis function (RBF) neural networks via deterministic learning theory. The derived knowledge of approximated gait dynamics is preserved in constant RBF networks. In the second (classification) stage, a bank of dynamical estimators is constructed using the preserved constant RBF networks to represent the learned training gait patterns. By comparing the set of estimators with a test gait pattern, the generated average $$L_1$$ norms of errors are taken as the disparity and classification measure between the training and test gait patterns to differentiate between ACL-D and ACL-I knees. Finally, experiments are carried out on forty-three patients to assess the effectiveness of the proposed method. By using the leave-one-out cross-validation style under normal and fast walking speed conditions, the correct classification rates for discriminating between ACL-D and ACL-I knees are reported to be 95.61$$\%$$ and 93.03$$\%$$, respectively. Compared with other state-of-the-art methods, the results demonstrate that gait alterations in the presence of chronic ACL deficiency can be visualized through cyclograms and phase portraits, and can be detected with superior performance.},
  archive      = {J_AIR},
  author       = {Zeng, Wei and Ismail, Shiek Abdullah and Pappas, Evangelos},
  doi          = {10.1007/s10462-019-09758-9},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3153-3176},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Detecting the presence of anterior cruciate ligament injury based on gait dynamics disparity and neural networks},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Explicit methods for attribute weighting in multi-attribute
decision-making: A review study. <em>AIR</em>, <em>53</em>(5),
3127–3152. (<a
href="https://doi.org/10.1007/s10462-019-09757-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute weighting is a key aspect when modeling multi-attribute decision analysis problems. Despite the large number of proposals reported in the literature, reaching a consensus on the most convenient method for a certain scenario is difficult, if not impossible. As a first contribution of this paper, we propose a categorization of existing methodologies, which goes beyond the current taxonomy (subjective, objective, hybrid). As a second contribution, supported by the new categorization, we survey and critically discuss the explicit weighting methods (which are closely related to the subjective ones). The critical discussion allows evaluating how much a solution can deviate from the expected one if no foresight is taken. As a final contribution, we summarize the main drawbacks from a global perspective and propose some insights to correct them. Such a discussion attempts to improve the reliability of decision support systems involving human experts.},
  archive      = {J_AIR},
  author       = {Pena, Julio and Nápoles, Gonzalo and Salgueiro, Yamisleydi},
  doi          = {10.1007/s10462-019-09757-w},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3127-3152},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Explicit methods for attribute weighting in multi-attribute decision-making: A review study},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). New multiparametric similarity measure for neutrosophic set
with big data industry evaluation. <em>AIR</em>, <em>53</em>(4),
3089–3125. (<a
href="https://doi.org/10.1007/s10462-019-09756-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the age of big data, we often face the huge Volume, high Velocity, rich Variety, accuracy Veracity and high Value (5Vs) with complicated structures. Big data industrial decision making is crucial for a country or society to improve the effectiveness of leadership, which can remarkably promote scale development and industrialization. Under such circumstance of big data industrial decision assessment, the intrinsic issue involves serious indeterminacy. Single-valued neutrosophic set, depicted by truth membership, indeterminacy membership and falsity membership, is a highly effective way to grasp uncertainty. The dominating aim is to explore multiparametric similarity measure and distance measure with their properties. Then, the objective weight is computed by deviation-based method and the combination weight is presented. Moreover, we propose a novel neutrosophic decision making method based on multiparametric similarity measure with combination weight, which is stated by a big data industry decision making issue, along with the impact of various parameters on the final ranking. In the end, a comparison between the proposed algorithm and some existing neutrosophic algorithms has been built by the antilogarithm by zero problem, counter-intuitive phenomena and division by zero problem for showing their validity.},
  archive      = {J_AIR},
  author       = {Peng, Xindong and Smarandache, Florentin},
  doi          = {10.1007/s10462-019-09756-x},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {3089-3125},
  shortjournal = {Artif. Intell. Rev.},
  title        = {New multiparametric similarity measure for neutrosophic set with big data industry evaluation},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Identification of epileptic seizures in EEG signals using
time-scale decomposition (ITD), discrete wavelet transform (DWT), phase
space reconstruction (PSR) and neural networks. <em>AIR</em>,
<em>53</em>(4), 3059–3088. (<a
href="https://doi.org/10.1007/s10462-019-09755-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditionally, detection of epileptic seizures based on the visual inspection of neurologists is tedious, laborious and subjective. To overcome such disadvantages, numerous seizure detection techniques involving signal processing and machine learning tools have been developed. However, there still remain the problems of automatic detection with high efficiency and accuracy in distinguishing normal, interictal and ictal electroencephalogram (EEG) signals. In this study we propose a novel method for automatic identification of epileptic seizures in singe-channel EEG signals based upon time-scale decomposition (ITD), discrete wavelet transform (DWT), phase space reconstruction (PSR) and neural networks. First, EEG signals are decomposed into a series of proper rotation components (PRCs) and a baseline signal by using the ITD method. The first two PRCs of the EEG signals are extracted, which contain most of the EEG signals’ energy and are considered to be the predominant PRCs. Second, four levels DWT is employed to decompose the predominant PRCs into different frequency bands, in which third-order Daubechies (db3) wavelet function is selected for analysis. Third, phase space of the PRCs is reconstructed based on db3, in which the properties associated with the nonlinear EEG system dynamics are preserved. Three-dimensional (3D) PSR together with Euclidean distance (ED) has been utilized to derive features, which demonstrate significant difference in EEG system dynamics between normal, interictal and ictal EEG signals. Fourth, neural networks are then used to model, identify and classify EEG system dynamics between normal (healthy), interictal and ictal EEG signals. Finally, experiments are carried out on the University of Bonn’s widely used and publicly available epilepsy dataset to assess the effectiveness of the proposed method. By using the 10-fold cross-validation style, the achieved average classification accuracy for eleven cases is reported to be 98.15\%. Compared with many state-of-the-art methods, the results demonstrate superior performance and the proposed method can serve as a potential candidate for the automatic detection of seizure EEG signals in the clinical application.},
  archive      = {J_AIR},
  author       = {Zeng, Wei and Li, Mengqing and Yuan, Chengzhi and Wang, Qinghui and Liu, Fenglin and Wang, Ying},
  doi          = {10.1007/s10462-019-09755-y},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {3059-3088},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Identification of epileptic seizures in EEG signals using time-scale decomposition (ITD), discrete wavelet transform (DWT), phase space reconstruction (PSR) and neural networks},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A systematic review of fundamental and technical analysis of
stock market predictions. <em>AIR</em>, <em>53</em>(4), 3007–3057. (<a
href="https://doi.org/10.1007/s10462-019-09754-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stock market is a key pivot in every growing and thriving economy, and every investment in the market is aimed at maximising profit and minimising associated risk. As a result, numerous studies have been conducted on the stock-market prediction using technical or fundamental analysis through various soft-computing techniques and algorithms. This study attempted to undertake a systematic and critical review of about one hundred and twenty-two (122) pertinent research works reported in academic journals over 11 years (2007–2018) in the area of stock market prediction using machine learning. The various techniques identified from these reports were clustered into three categories, namely technical, fundamental, and combined analyses. The grouping was done based on the following criteria: the nature of a dataset and the number of data sources used, the data timeframe, the machine learning algorithms used, machine learning task, used accuracy and error metrics and software packages used for modelling. The results revealed that 66\% of documents reviewed were based on technical analysis; whiles 23\% and 11\% were based on fundamental analysis and combined analyses, respectively. Concerning the number of data source, 89.34\% of documents reviewed, used single sources; whiles 8.2\% and 2.46\% used two and three sources respectively. Support vector machine and artificial neural network were found to be the most used machine learning algorithms for stock market prediction.},
  archive      = {J_AIR},
  author       = {Nti, Isaac Kofi and Adekoya, Adebayo Felix and Weyori, Benjamin Asubam},
  doi          = {10.1007/s10462-019-09754-z},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {3007-3057},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A systematic review of fundamental and technical analysis of stock market predictions},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modeling empathy: Building a link between affective and
cognitive processes. <em>AIR</em>, <em>53</em>(4), 2983–3006. (<a
href="https://doi.org/10.1007/s10462-019-09753-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational modeling of empathy has recently become an increasingly popular way of studying human relations. It provides a way to increase our understanding of the link between affective and cognitive processes and enhance our interaction with artificial agents. However, the variety of fields contributing to empathy research has resulted in isolated approaches to modeling empathy, and this has led to various definitions of empathy and an absence of common ground regarding underlying empathic processes. Although this diversity may be useful in that it allows for an in-depth examination of various processes linked to empathy, it also may not yet provide a coherent theoretical picture of empathy. We argue that a clear theoretical positioning is required for collective progress. The aim of this article is, therefore, to call for a holistic and multilayered view of a model of empathy, taken from the rich background research from various disciplines. To achieve this, we present a comprehensive background on the theoretical foundations, followed by the working definitions, components, and models of empathy that are proposed by various fields. Following this introduction, we provide a detailed review of the existing techniques used in AI research to model empathy in interactive agents, focusing on the strengths and weaknesses of each approach. We conclude with a discussion of future directions in this emerging field.},
  archive      = {J_AIR},
  author       = {Yalçın, Özge Nilay and DiPaola, Steve},
  doi          = {10.1007/s10462-019-09753-0},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2983-3006},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Modeling empathy: Building a link between affective and cognitive processes},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey of quaternion neural networks. <em>AIR</em>,
<em>53</em>(4), 2957–2982. (<a
href="https://doi.org/10.1007/s10462-019-09752-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quaternion neural networks have recently received an increasing interest due to noticeable improvements over real-valued neural networks on real world tasks such as image, speech and signal processing. The extension of quaternion numbers to neural architectures reached state-of-the-art performances with a reduction of the number of neural parameters. This survey provides a review of past and recent research on quaternion neural networks and their applications in different domains. The paper details methods, algorithms and applications for each quaternion-valued neural networks proposed.},
  archive      = {J_AIR},
  author       = {Parcollet, Titouan and Morchid, Mohamed and Linarès, Georges},
  doi          = {10.1007/s10462-019-09752-1},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2957-2982},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey of quaternion neural networks},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A corporate shuffled complex evolution for parameter
identification. <em>AIR</em>, <em>53</em>(4), 2933–2956. (<a
href="https://doi.org/10.1007/s10462-019-09751-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new version of the shuffled complex evolution (SCE) algorithm for solving parameter identification problems. The SCE divides a population into several parallel subsets called complex and then improves each sub-complex through an evolutionary process using a Nelder–Mead (NM) simplex search method. This algorithm applies its evolutionary process only on the worst member of each sub-complex whereas the role of other members is not operative. Therefore, the number and variety of search moves are limited in the evolutionary process of SCE. The current study focuses to overcome this drawback by proposing a corporate SCE (CSCE). This algorithm provides an evolutionary possibility for all members of a sub-complex. In the CSCE, each member is influenced by a simplex made from all other members of the current sub-complex. The CSCE barrows three actions of NM, i.e. reflection, contraction and expansion, and applied them on each member to find a better candidate than the current one. The efficacy of the proposed algorithm is first tested on six benchmark problems. After achieving satisfactory performance on the test problems, it is applied to parameter identification problems and the obtained results are compared with some other algorithms reported in the literature. Numerical results and non-parametric analysis show that the proposed algorithm is very effective and robust since it produces similar and promising results over repeated runs.},
  archive      = {J_AIR},
  author       = {Ahandani, Morteza Alinia and Kharrati, Hamed},
  doi          = {10.1007/s10462-019-09751-2},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2933-2956},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A corporate shuffled complex evolution for parameter identification},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Feature selection in image analysis: A survey. <em>AIR</em>,
<em>53</em>(4), 2905–2931. (<a
href="https://doi.org/10.1007/s10462-019-09750-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image analysis is a prolific field of research which has been broadly studied in the last decades, successfully applied to a great number of disciplines. Since the apparition of Big Data, the number of digital images is explosively growing, and a large amount of multimedia data is publicly available. Not only is it necessary to deal with this increasing number of images, but also to know which features extract from them, and feature selection can help in this scenario. The goal of this paper is to survey the most recent feature selection methods developed and/or applied to image analysis, covering the most popular fields such as image classification, image segmentation, etc. Finally, an experimental evaluation on several popular datasets using well-known feature selection methods is presented, bearing in mind that the aim is not to provide the best feature selection method, but to facilitate comparative studies for the research community.},
  archive      = {J_AIR},
  author       = {Bolón-Canedo, Verónica and Remeseiro, Beatriz},
  doi          = {10.1007/s10462-019-09750-3},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2905-2931},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Feature selection in image analysis: A survey},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new graph-preserving unsupervised feature selection
embedding LLE with low-rank constraint and feature-level representation.
<em>AIR</em>, <em>53</em>(4), 2875–2903. (<a
href="https://doi.org/10.1007/s10462-019-09749-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised feature selection is a powerful tool to process high-dimensional data, in which a subset of features is selected out for effective data representation. In this paper, we proposes a novel robust unsupervised features selection method based on graph-preserving feature selection embedding LLE. Specifically, we integrate the graph matrix learning and the low-dimensional space learning together to identify the correlation among both features and samples from the intrinsic low-dimensional space of original data. Also, the global and local correlation of features have been taken into consideration through the low-rank constraint and the feature-level representation property to find lower-dimensional representation which preserves not only the global and local correlation of features but also the global and local structure of training samples. Furthermore, we propose a new optimization algorithm to the resulting objective function, which iteratively updates the graph matrix and the intrinsic space in order to collaboratively improve each of them. Experimental analysis on 18 benchmark datasets verified that our proposed method outperformed the state-of-the-art feature selection methods in terms of classification and clustering performance.},
  archive      = {J_AIR},
  author       = {Han, Xiaohong and Chai, Haishui and Liu, Ping and Li, Dengao and Wang, Li},
  doi          = {10.1007/s10462-019-09749-w},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2875-2903},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A new graph-preserving unsupervised feature selection embedding LLE with low-rank constraint and feature-level representation},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Intuitionistic fuzzy <span
class="math display"><em>β</em></span>-covering-based rough sets.
<em>AIR</em>, <em>53</em>(4), 2841–2873. (<a
href="https://doi.org/10.1007/s10462-019-09748-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Covering-based rough set is an important extended type of classical rough set model. In this model, concepts are approximated through substitution of a partition in classical rough set theory with a covering in covering-based rough set theory. Various generalized covering-based rough sets have been investigated, however, little work has been done on extending four classical covering-based rough set to intuitionistic fuzzy (IF) settings. In this study, four novel IF covering-based rough set models are developed by combining an IF $$\beta $$-covering with four classical covering-based rough set models. First, we present the concept of IF $$\beta $$-minimal description, and then construct four order relations on IF $$\beta $$ approximation space. Second, we propose four IF $$\beta $$-covering-based rough set models and derive that they are generalizations of four existing covering-based rough sets in IF settings. We also discuss the properties of these IF $$\beta $$-covering-based rough sets and reveal their relationships. We use the existing distance between two IF sets to characterize the uncertainty of the presented IF $$\beta $$-covering-based rough sets. Third, we define the reducts of IF $$\beta $$-covering decision systems and examine their discernibility-function-based reduction methods for these IF $$\beta $$-covering-based rough sets. Fourth, we present four optimistic and pessimistic multi-granulation IF $$\beta $$-covering-based rough sets and analyze their properties and uncertainty measures from multi-granulation perspective. Fifth, we study the discernibility-function-based reduction methods for the presented multi-granulation IF $$\beta $$-covering-based rough sets. Finally, we discuss another two neighborhood-based IF covering-based rough sets. This study can provide a covering-based rough set method for acquiring knowledge from IF decision systems.},
  archive      = {J_AIR},
  author       = {Huang, Bing and Li, Huaxiong and Feng, Guofu and Guo, Chunxiang},
  doi          = {10.1007/s10462-019-09748-x},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2841-2873},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Intuitionistic fuzzy $$\beta $$-covering-based rough sets},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Flexible slider crank mechanism synthesis using
meta-heuristic optimization techniques: A new designer tool assistance
for a compliant mechanism synthesis. <em>AIR</em>, <em>53</em>(4),
2809–2840. (<a
href="https://doi.org/10.1007/s10462-019-09747-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work bespeaks an insight into a real imperfect multibody systems synthesis, wherein the flexible behaviour of its components is considered. Based on the end-effector mechanism velocity, acceleration and defined transversal deflection for a flexible component, the mechanism optimal design variables have been investigated. Subsequently, the three aforementioned responses have been involved simultaneously for a combined optimization process. To this end, an Assistance Tool Design, subsuming several meta-heuristic optimization techniques such as Genetic Algorithm (GA), Imperialist Competitive Algorithm (ICA), Artificial Bee Colony (ABC), Ant Colony (AC), Differential Evolution (DE) and Simulating Annealing (SA) techniques, has been developed under MATLAB software. The Assistance Tool Design enables designers to carry out the synthesis of mechanisms by means of one or many optimization techniques mentioned above. It has been proven that AC and DE outperform the other optimization techniques. Nevertheless, awkwardness has been bearded for the mechanism synthesis using only a single response, mainly the flexible connecting rod mid-point transversal deflection. The combined synthesis subsuming simultaneously the three responses discussed above settles a perfect trade-off for all the optimization techniques.},
  archive      = {J_AIR},
  author       = {Ben Abdallah, Mohamed Amine and Khemili, Imed and Aifaoui, Nizar},
  doi          = {10.1007/s10462-019-09747-y},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2809-2840},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Flexible slider crank mechanism synthesis using meta-heuristic optimization techniques: A new designer tool assistance for a compliant mechanism synthesis},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The dissimilarity approach: A review. <em>AIR</em>,
<em>53</em>(4), 2783–2808. (<a
href="https://doi.org/10.1007/s10462-019-09746-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dissimilarity representation is a very interesting alternative for the traditional feature space representation when addressing large multi-class problems or even problems with a small number of training samples. This paper describes the existing possibilities in terms of dissimilarity representation through some comprehensive examples. The justification for using such a problem representation strategy is discussed, followed by a complete review of the state-of-art and a critical analysis in which the original purpose of the dissimilarity representation and its perspectives are discussed. Dissimilarity space derived from automatically learned features and the possibility of transiting from one space to another when performing the tasks of the classification process are good examples of promising research directions in this field.},
  archive      = {J_AIR},
  author       = {Costa, Yandre M. G. and Bertolini, Diego and Britto, Alceu S. and Cavalcanti, George D. C. and Oliveira, Luiz E. S.},
  doi          = {10.1007/s10462-019-09746-z},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2783-2808},
  shortjournal = {Artif. Intell. Rev.},
  title        = {The dissimilarity approach: A review},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Parameter identification of engineering problems using a
differential shuffled complex evolution. <em>AIR</em>, <em>53</em>(4),
2749–2782. (<a
href="https://doi.org/10.1007/s10462-019-09745-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An accurate mathematical model has a vital role in controlling and synchronization of different systems. But generally in real-world problems, parameters are mixed with mismatches and distortions. In this paper, an improved shuffled complex evolution (SCE) is proposed for parameter identification of engineering problems. The SCE by employing parallel search efficiently finds neighborhoods of the optimal point. So it carries out exploration in a proper way. But its drawback is due to exploitation stages. The SCE cannot converge accurately to an optimal point, in many cases. The current study focuses to overcome this drawback by inserting a shrinkage stage to an original version of SCE and presents a powerful global numerical optimization method, named the differential SCE. The efficacy of the proposed algorithm is first tested on some benchmark problems. After achieving satisfactory performance on the test problems, to demonstrate the applicability of the proposed algorithm, it is applied to ten identification problems includes parameter identification of ordinary differential equations and chaotic systems. Practical experiences show that the proposed algorithm is very effective and robust so that it produces similar and promising results over repeated runs. Also, a comparison against other evolutionary algorithms reported in the literature demonstrates a significantly better performance of our proposed algorithm.},
  archive      = {J_AIR},
  author       = {Pourasghar, Babak and Ahandani, Morteza Alinia and Kharrati, Hamed},
  doi          = {10.1007/s10462-019-09745-0},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2749-2782},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Parameter identification of engineering problems using a differential shuffled complex evolution},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Recommendation system based on deep learning methods: A
systematic review and new directions. <em>AIR</em>, <em>53</em>(4),
2709–2748. (<a
href="https://doi.org/10.1007/s10462-019-09744-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {These days, many recommender systems (RS) are utilized for solving information overload problem in areas such as e-commerce, entertainment, and social media. Although classical methods of RS have achieved remarkable successes in providing item recommendations, they still suffer from many issues such as cold start and data sparsity. With the recent achievements of deep learning in various applications such as Natural Language Processing (NLP) and image processing, more efforts have been made by the researchers to exploit deep learning methods for improving the performance of RS. However, despite the several research works on deep learning based RS, very few secondary studies were conducted in the field. Therefore, this study aims to provide a systematic literature review (SLR) of deep learning based RSs that can guide researchers and practitioners to better understand the new trends and challenges in the field. This paper is the first SLR specifically on the deep learning based RS to summarize and analyze the existing studies based on the best quality research publications. The paper particularly adopts an SLR approach based on the standard guidelines of the SLR designed by Kitchemen-ham which uses selection method and provides detail analysis of the research publications. Several publications were gathered and after inclusion/exclusion criteria and the quality assessment, the selected papers were finally used for the review. The results of the review indicated that autoencoder (AE) models are the most widely exploited deep learning architectures for RS followed by the Convolutional Neural Networks (CNNs) and the Recurrent Neural Networks (RNNs) models. Also, the results showed that Movie Lenses is the most popularly used datasets for the deep learning-based RS evaluation followed by the Amazon review datasets. Based on the results, the movie and e-commerce have been indicated as the most common domains for RS and that precision and Root Mean Squared Error are the most commonly used metrics for evaluating the performance of the deep leaning based RSs.},
  archive      = {J_AIR},
  author       = {Da’u, Aminu and Salim, Naomie},
  doi          = {10.1007/s10462-019-09744-1},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2709-2748},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Recommendation system based on deep learning methods: A systematic review and new directions},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey of feature extraction and fusion of deep learning
for detection of abnormalities in video endoscopy of
gastrointestinal-tract. <em>AIR</em>, <em>53</em>(4), 2635–2707. (<a
href="https://doi.org/10.1007/s10462-019-09743-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A standard screening procedure involves video endoscopy of the Gastrointestinal tract. It is a less invasive method which is practiced for early diagnosis of gastric diseases. Manual inspection of a large number of gastric frames is an exhaustive, time-consuming task, and requires expertise. Conversely, several computer-aided diagnosis systems have been proposed by researchers to cope with the dilemma of manual inspection of the massive volume of frames. This article gives an overview of different available alternatives for automated inspection, detection, and classification of various GI abnormalities. Also, this work elaborates techniques associated with content-based image retrieval and automated systems for summarizing endoscopic procedures. In this survey, we perform a comprehensive review of feature extraction techniques and deep learning methods which were specifically developed for automatic analysis of endoscopic videos. In addition, we categorize features extraction techniques according to image processing domains and further we classify them based on their visual descriptions. We also review hybrid feature extraction techniques which are developed by the fusion of different kind of basic descriptors. Moreover, this survey covers various endoscopy data-sets available for the bench-marking of vision based algorithms. On the basis of literature, we explain emerging trends in computerized analysis of endoscopy. We also survey important issues, challenges, and future research directions to the development of computer-assisted systems for detection of maladies and interactive surgery in the GI tract.},
  archive      = {J_AIR},
  author       = {Ali, Hussam and Sharif, Muhammad and Yasmin, Mussarat and Rehmani, Mubashir Husain and Riaz, Farhan},
  doi          = {10.1007/s10462-019-09743-2},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2635-2707},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey of feature extraction and fusion of deep learning for detection of abnormalities in video endoscopy of gastrointestinal-tract},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the frontiers of pose invariant face recognition: A
review. <em>AIR</em>, <em>53</em>(4), 2571–2634. (<a
href="https://doi.org/10.1007/s10462-019-09742-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer vision systems open a new challenge to recognize human faces under varied poses in similar capacity and capability as human-beings perform naturally. For surveillance applications, pose-invariant face recognition (PIFR) will become a major break-through by presenting the solution of this unique challenge. In recent decade, several techniques are presented to address this challenge over well-known data-sets. These efforts are divided chronologically into seven different approaches say geometric, statistical, holistic, template, supervised learning, unsupervised learning and deep learning. Among these deep learning techniques have shown more promising results and have gained attention for future research. By reviewing PIFR, it is historically divided into five eras based on 160 referred papers and their cumulative citations.},
  archive      = {J_AIR},
  author       = {Ahmed, Sheikh Bilal and Ali, Syed Farooq and Ahmad, Jameel and Adnan, Muhammad and Fraz, Muhammad Moazam},
  doi          = {10.1007/s10462-019-09742-3},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2571-2634},
  shortjournal = {Artif. Intell. Rev.},
  title        = {On the frontiers of pose invariant face recognition: A review},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new integrated model of the group method of data handling
and the firefly algorithm (GMDH-FA): Application to aeration modelling
on spillways. <em>AIR</em>, <em>53</em>(4), 2549–2569. (<a
href="https://doi.org/10.1007/s10462-019-09741-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the high flow velocity over dam spillways and outlets, severe cavitation damage might occur to the structures. Aeration (introducing air into the passing flow) is a useful remedy for preventing or decreasing cavitation, however, proper estimation of aerators air demand is a complex problem. On that account, the standard GMDH model, integrated GMDH-HS (with the harmony search algorithm) model and a novel integrated GMDH-FA model (with the firefly algorithm), were developed and applied to estimate air demand on spillway aerators in dams. Input parameters including flow rate (Qw), flow depth (d0), relative pressure under the jet (hs), ramp angle (α), step height (s), and spillway slope (θ) were applied as the effective factors for estimating the amount of air flow of the aerators (Qa). General results based on several statistical measures (NRMSE, PCC, NMAE, NSE) and the test of ANOVA for models’ residuals, showed that the standard GMDH improved the accuracy of estimating air flow in comparison to empirical equations (an average enhanced efficiency of 59.86\% in terms of NRMSE) and multiple linear regression method (an enhanced efficiency of 37.15\% in terms of NRMSE). Moreover, findings of the research revealed that the FA and HS algorithms improved the performance of the standard GMDH equal to 17\% and 13\%, respectively.},
  archive      = {J_AIR},
  author       = {Mahdavi-Meymand, Amin and Zounemat-Kermani, Mohammad},
  doi          = {10.1007/s10462-019-09741-4},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2549-2569},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A new integrated model of the group method of data handling and the firefly algorithm (GMDH-FA): Application to aeration modelling on spillways},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Effective lexicon-based approach for urdu sentiment
analysis. <em>AIR</em>, <em>53</em>(4), 2521–2548. (<a
href="https://doi.org/10.1007/s10462-019-09740-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The lexicon-based approach is used for sentiment analysis of Urdu. In the lexicon, apart from the traditional approach of having adjectives, nouns and negations we have also included verbs, intensifiers and context-dependent words. An effective Urdu sentiment analyzer is developed that applies rules and make use of this new lexicon and perform Urdu sentiment analysis by classifying sentences as positive, negative or neutral. Evaluating this Urdu sentiment analyzer, by using sentences from Urdu blogs, yields the most promising results so far in Urdu language with 89.03\% accuracy with 0.86 precision, 0.90 recall and 0.88 F-measure. Results are evaluated using kappa statistics as well. The comparison with the previous work in Urdu shows that the combination of this Urdu sentiment lexicon and Urdu sentiment analyzer is much more effective than the previous such combinations. The main reason for increased efficiency is the development of wide coverage lexicon and effective handling of negations, intensifiers and context-dependent words by the Urdu sentiment analyzer.},
  archive      = {J_AIR},
  author       = {Mukhtar, Neelam and Khan, Mohammad Abid},
  doi          = {10.1007/s10462-019-09740-5},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2521-2548},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Effective lexicon-based approach for urdu sentiment analysis},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey on structured discriminative spoken keyword
spotting. <em>AIR</em>, <em>53</em>(4), 2483–2520. (<a
href="https://doi.org/10.1007/s10462-019-09739-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spoken keyword spotting refers to the detection of all occurrences of desired words in continuous speech utterances. This paper includes a comprehensive review on various spoken keyword spotting (especially discriminative spoken keyword spotting) approaches. The most common datasets and evaluation measures for training and evaluating the spoken keyword spotting systems are reviewed in this paper. Moreover, the main framework for structured discriminative spoken keyword spotting (SDKWS) is presented. Different parts of the SDKWS framework such as feature extraction, model training, search algorithm and thresholding are discussed in this paper. Finally, the paper is concluded in the conclusion section and the future works are presented in the last part of that section.},
  archive      = {J_AIR},
  author       = {Tabibian, Shima},
  doi          = {10.1007/s10462-019-09739-y},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2483-2520},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey on structured discriminative spoken keyword spotting},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Comparison of support vector machine, back propagation
neural network and extreme learning machine for syndrome element
differentiation. <em>AIR</em>, <em>53</em>(4), 2453–2481. (<a
href="https://doi.org/10.1007/s10462-019-09738-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence is a discipline which focuses on the study of simulating and extending human intelligence, while machine learning (ML) is one of the most rapidly developing subfields of AI research. The research of ML in the field of traditional Chinese medicine (TCM), has a bright prospect, as well as a profound significance. To explore the feasibility of using ML methods to approximate the diagnosis of TCM, support vector machine (SVM) is introduced and investigated for syndrome element differentiation of TCM in this paper. Based on 670 medical records, SVM was used to approximate the mapping relations between inputs (set of clinical manifestations) and outputs (set of syndrome elements). The value orders of syndrome elements were adopted to evaluate the approximation results, while attribute partial order structure diagram was employed to discover and visualize the knowledge of the records. Back propagation neural network (BPNN) and extreme learning machine (ELM), as comparative methods, were also employed to deal with the medical data. The value order’s matching results between real and predicted results shows that, for SVM, the matched degree of each record is no less than 65\%, while there are at least 88\% records whose matched degree is more than 80\%; and for BPNN and ELM, the highest proportion of records whose matched degree is more than 80\% is only 45\%. Using methods of ML to approximate the diagnosis of TCM should be feasible, and more relevant research can be conducted in the future.},
  archive      = {J_AIR},
  author       = {Yan, Enliang and Song, Jialin and Liu, Chaonan and Luan, Jingmin and Hong, Wenxue},
  doi          = {10.1007/s10462-019-09738-z},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2453-2481},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Comparison of support vector machine, back propagation neural network and extreme learning machine for syndrome element differentiation},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Reduction foundation with multigranulation rough sets using
discernibility. <em>AIR</em>, <em>53</em>(4), 2425–2452. (<a
href="https://doi.org/10.1007/s10462-019-09737-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When multiple granulated knowledge in multigranulation spaces are involved in decision making, protocol principles are adopted to arrive at the final consensus. Multigranulation rough set theory utilizes a voting principle to combine the decision options derived from individual granulated knowledge. Note that those knowledge may provide different degrees of support to the final results, some are key, some are of less importance and some are even of no use. Selecting valuable knowledge and reducing worthless one are thus necessary for data processing, which can alleviate the storage occupancy and facilitate the logical and statistical analysis. However, the basic reduction foundation of multigranulation spaces has been rarely touched by researchers, which brings in many difficulties in algorithmic and real applications. This work aims to disclose the principles of multiple knowledge reduction in multigranulation spaces from the viewpoint of discernibility. First, the notions of knowledge reduction of multigranulation spaces are defined based on multigranulation rough set theory. Second, a decision function mapping each object into the decision options of its neighborhood granule is introduced. Third, several pairs of discernibility matrices and discernibility functions are successively developed using the decision function. We claim that the valuable and worthless knowledge in multigranulation spaces can be explicitly chose and eliminated respectively by using the proposed discernibility matrices and discernibility functions. That is to say, these discernibility tools provide a precise criterion for the knowledge reduction of multigranulation spaces. As a theoretical extension, a multigranulation information entropy is proposed and an approximate algorithm is constructed to compute a suboptimal reduct of a multigranulation space based on this entropy. In the end, numerical experiments are performed on public data sets to verify the effectiveness of the proposed reduction methods. This study can get us a grasp of the foundational principle of knowledge reduction and may bring a new insight for the designation of substantial reduction algorithms of multigranulation knowledge.},
  archive      = {J_AIR},
  author       = {Tan, Anhui and Wu, Wei-Zhi and Li, Jinjin and Li, Tongjun},
  doi          = {10.1007/s10462-019-09737-0},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2425-2452},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Reduction foundation with multigranulation rough sets using discernibility},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Spatiotemporal clustering: A review. <em>AIR</em>,
<em>53</em>(4), 2381–2423. (<a
href="https://doi.org/10.1007/s10462-019-09736-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An increase in the size of data repositories of spatiotemporal data has opened up new challenges in the fields of spatiotemporal data analysis and data mining. Foremost among them is “spatiotemporal clustering,” a subfield of data mining that is increasingly becoming popular because of its applications in wide-ranging areas such as engineering, surveillance, transportation, environmental and seismology studies, and mobile data analysis. This review paper presents a comprehensive review of spatiotemporal clustering approaches and their applications as well as a brief tutorial on the taxonomy of data types in the spatiotemporal domain and patterns. Additionally, the data pre-processing techniques, access methods, cluster validation, space–time scan statistics, software tools, and datasets used by various spatiotemporal clustering algorithms are highlighted.},
  archive      = {J_AIR},
  author       = {Ansari, Mohd Yousuf and Ahmad, Amir and Khan, Shehroz S. and Bhushan, Gopal and Mainuddin},
  doi          = {10.1007/s10462-019-09736-1},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2381-2423},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Spatiotemporal clustering: A review},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Segmentation of cervical cells for automated screening of
cervical cancer: A review. <em>AIR</em>, <em>53</em>(4), 2341–2379. (<a
href="https://doi.org/10.1007/s10462-019-09735-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In automated screening of cervical cytology, the morphological features of cell play a determining role. To avoid false diagnosis, urgent need of precise extraction of these features led to emergence of new segmentation models. In this paper author aspire to present literature review of research done in the field of segmentation stage in automatic screening of cervical smear images. Total of 78 publications are considered for the time period of 40 years. A detailed study of segmentation technique proposed in each publication is considered, which presents a chronological development and up-gradation of segmentation models. This review assist researcher to have thorough knowledge of various state-of-art segmentation models and the problems and complexities required to be tackled, for unambiguous determination of malignancies in cervical cytology.},
  archive      = {J_AIR},
  author       = {Sarwar, Abid and Sheikh, Abrar Ali and Manhas, Jatinder and Sharma, Vinod},
  doi          = {10.1007/s10462-019-09735-2},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2341-2379},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Segmentation of cervical cells for automated screening of cervical cancer: A review},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Recent trends in deep learning based personality detection.
<em>AIR</em>, <em>53</em>(4), 2313–2339. (<a
href="https://doi.org/10.1007/s10462-019-09770-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the automatic prediction of personality traits has received a lot of attention. Specifically, personality trait prediction from multimodal data has emerged as a hot topic within the field of affective computing. In this paper, we review significant machine learning models which have been employed for personality detection, with an emphasis on deep learning-based methods. This review paper provides an overview of the most popular approaches to automated personality detection, various computational datasets, its industrial applications, and state-of-the-art machine learning models for personality detection with specific focus on multimodal approaches. Personality detection is a very broad and diverse topic: this survey only focuses on computational approaches and leaves out psychological studies on personality detection.},
  archive      = {J_AIR},
  author       = {Mehta, Yash and Majumder, Navonil and Gelbukh, Alexander and Cambria, Erik},
  doi          = {10.1007/s10462-019-09770-z},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2313-2339},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Recent trends in deep learning based personality detection},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A comprehensive survey on symbiotic organisms search
algorithms. <em>AIR</em>, <em>53</em>(3), 2265–2312. (<a
href="https://doi.org/10.1007/s10462-019-09733-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, meta-heuristic algorithms have made remarkable progress in solving types of complex and NP-hard problems. So that, most of this algorithms are inspired by swarm intelligence and biological systems as well as other physical and chemical systems in nature. Of course, different divisions for meta-heuristic algorithms have been presented so far, and the number of these algorithms is increasing day by day. Among the meta-heuristic algorithms, some algorithms have a very high efficiency, which are a suitable method for solving real-world problems, but some algorithms have not been sufficiently studied. One of the nature-inspired meta-heuristic algorithms is symbiotic organisms search (SOS), which has been able to solve the majority of engineering issues so far. In this paper, firstly, the primary principles, the basic concepts, and mathematical relations of the SOS algorithm are presented and then the engineering applications of the SOS algorithm and published researches in different applications are examined as well as types of modified and multi-objective versions and hybridized discrete models of this algorithm are studied. This study encourages the researchers and developers of meta-heuristic algorithms to use this algorithm for solving various problems, because it is a simple and powerful algorithm to solve complex and NP-hard problems. In addition, a detailed and perfect statistical analysis was performed on the studies that had used this algorithm. According to the accomplished studies and investigations, features and factors of this algorithm are better than other meta-heuristic algorithm, which has increased its usability in various fields.},
  archive      = {J_AIR},
  author       = {Gharehchopogh, Farhad Soleimanian and Shayanfar, Human and Gholizadeh, Hojjat},
  doi          = {10.1007/s10462-019-09733-4},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2265-2312},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A comprehensive survey on symbiotic organisms search algorithms},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Novel meta-heuristic bald eagle search optimisation
algorithm. <em>AIR</em>, <em>53</em>(3), 2237–2264. (<a
href="https://doi.org/10.1007/s10462-019-09732-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a bald eagle search (BES) algorithm, which is a novel, nature-inspired meta-heuristic optimisation algorithm that mimics the hunting strategy or intelligent social behaviour of bald eagles as they search for fish. Hunting by BES is divided into three stages. In the first stage (selecting space), an eagle selects the space with the most number of prey. In the second stage (searching in space), the eagle moves inside the selected space to search for prey. In the third stage (swooping), the eagle swings from the best position identified in the second stage and determines the best point to hunt. Swooping starts from the best point and all other movements are directed towards this point. BES is tested by adopting a three-part evaluation methodology that (1) describes the benchmarking of the optimisation problem to evaluate the algorithm performance, (2) compares the algorithm performance with that of other intelligent computation techniques and parameter settings and (3) evaluates the algorithm based on mean, standard deviation, best point and Wilcoxon signed-rank test statistic of the function values. Optimisation results and discussion confirm that the BES algorithm competes well with advanced meta-heuristic algorithms and conventional methods.},
  archive      = {J_AIR},
  author       = {Alsattar, H. A. and Zaidan, A. A. and Zaidan, B. B.},
  doi          = {10.1007/s10462-019-09732-5},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2237-2264},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Novel meta-heuristic bald eagle search optimisation algorithm},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Applicability of LAMDA as classification model in the oil
production. <em>AIR</em>, <em>53</em>(3), 2207–2236. (<a
href="https://doi.org/10.1007/s10462-019-09731-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work analyzes the utilization of classification models in the context of the oil industry and presents examples of application. Particularly, we analyze three case studies, two to explain the behavior of oil wells that produce via artificial methods (the classification as a descriptive model), and another to predict the oil prices (the classification as a predictive model). The classification technique used in this work is LAMDA-HAD, which is an improvement to the well-known technique called learning algorithm multivariable and data analysis (LAMDA), that has been used in diagnostic tasks. Finally, the results with the descriptive and predictive models are discussed, in order to analyze the importance of the classification in the context of the oil business.},
  archive      = {J_AIR},
  author       = {Morales, L. and Lozada, H. and Aguilar, J. and Camargo, E.},
  doi          = {10.1007/s10462-019-09731-6},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2207-2236},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Applicability of LAMDA as classification model in the oil production},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Interval neutrosophic hesitant fuzzy einstein choquet
integral operator for multicriteria decision making. <em>AIR</em>,
<em>53</em>(3), 2171–2206. (<a
href="https://doi.org/10.1007/s10462-019-09730-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently interval neutrosophic hesitant fuzzy sets are found to be more general and useful to express incomplete, indeterminate and inconsistent information. In this paper, we define some new Einstein operational rules on interval neutrosophic hesitant fuzzy elements, then we propose the interval neutrosophic hesitant fuzzy Einstein Choquet integral (INHFECI) operator and discuss its properties. Further, an approach for multicriteria decision making is developed to study the interaction between the input arguments under the interval neutrosophic hesitant fuzzy environment. The main advantage of the proposed operator is that, it can deal with the situations of the positive interaction, negative interaction or non-interaction among the criteria, during the decision making process. Also, the proposed operator can replace the weighted average to aggregate dependent criteria of interval neutrosophic hesistant fuzzy information for obtaining more accurate results. Moreover, some interval neutrosophic hesitant fuzzy weighted average operators are proposed as special cases of INHFECI operator. Finally, an illustrative example follows.},
  archive      = {J_AIR},
  author       = {Kakati, Pankaj and Borkotokey, Surajit and Rahman, Saifur and Davvaz, Bijan},
  doi          = {10.1007/s10462-019-09730-7},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2171-2206},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Interval neutrosophic hesitant fuzzy einstein choquet integral operator for multicriteria decision making},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Linguistic neutrosophic partitioned maclaurin symmetric mean
operators based on clustering algorithm and their application to
multi-criteria group decision-making. <em>AIR</em>, <em>53</em>(3),
2131–2170. (<a
href="https://doi.org/10.1007/s10462-019-09729-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Linguistic neutrosophic number (LNN) can describe evaluation information by three linguistic variables indicating truth-membership, indeterminacy-membership and falsity-membership respectively, which is an effective tool to represent uncertainty, the partitioned Maclaurin symmetric mean (PMSM) operator can reflect the interrelationships among criteria where there are interrelationships among criteria in the same partition, but the criteria in different partitions are irrelevant, so, in this paper, we extend the PMSM operator to LNNs, define linguistic neutrosophic partitioned Maclaurin symmetric mean operator and linguistic neutrosophic weighted partitioned Maclaurin symmetric mean (LNWPMSM) operator, and discuss the properties and theorems of the proposed operators. Then we propose a clustering algorithm for linguistic neutrosophic sets based on the similarity measure to give some objective and reasonable partitions among criteria, and based on the LNWPMSM operator and the objective partition structure of the criteria, a novel multi-criteria group decision-making method is developed for linguistic neutrosophic environment. Finally, one practical example is presented to illustrate the applicability of the proposed method, and a comparison analysis is to show the advantages of the proposed method compared with the existing methods.},
  archive      = {J_AIR},
  author       = {Liu, Peide and You, Xinli},
  doi          = {10.1007/s10462-019-09729-0},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2131-2170},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Linguistic neutrosophic partitioned maclaurin symmetric mean operators based on clustering algorithm and their application to multi-criteria group decision-making},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An extended TOPSIS method based on ordered fuzzy numbers for
group decision making. <em>AIR</em>, <em>53</em>(3), 2099–2129. (<a
href="https://doi.org/10.1007/s10462-019-09728-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple criteria decision making methods have become very popular in recent years and are frequently applied in many real-life situations. One of the most commonly used is the Technique for Order Preference by Similarity to Ideal Solution. Its original version is based on the information provided by the decision maker as exact numerical values. However, in some real-life situations, the decision maker may not be able to precisely express the value of the ratings of alternatives with respect to criteria or else he/she uses linguistic expressions. In such situations he/she may use other data formats, such as: interval numbers, fuzzy numbers, ordered fuzzy numbers, hesitant fuzzy sets, intuitionistic fuzzy sets and other. On the other hand, the increasing complexity of the decision problems analysed makes it less feasible to consider all the relevant aspects of the problems by a single decision maker. As a result, many real-life problems are discussed by a group of decision makers. The aim of this paper and its main contribution is to present a new approach for ranking of alternatives for group decision making using the Technique for Order Preference by Similarity to Ideal Solution method based on ordered fuzzy numbers. This is an alternative to methods that use different forms of averages for the aggregation of the individual matrices into a collective matrix. In the proposed approach aggregation is not needed and all individual decision information of decision makers is taken into account in determining the ranking of alternatives and the selecting the best one. The key stage of this method is the transformation of the decision matrices provided by the decision makers into matrices of alternatives. A matrix corresponding to an alternative is composed of its assessments with respect to all criteria, performed by all the decision makers. A numerical example illustrates the proposed approach.},
  archive      = {J_AIR},
  author       = {Kacprzak, Dariusz},
  doi          = {10.1007/s10462-019-09728-1},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2099-2129},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An extended TOPSIS method based on ordered fuzzy numbers for group decision making},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Performance evaluation of classifiers for the recognition of
offline handwritten gurmukhi characters and numerals: A study.
<em>AIR</em>, <em>53</em>(3), 2075–2097. (<a
href="https://doi.org/10.1007/s10462-019-09727-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification is a process to pull out patterns from a number of classes by using various statistical properties and artificial intelligence techniques. The problem of classification is considered as one of the important problems for the development of applications and for efficient data analysis. Based on the learning adaptability and capability to solve complex computations, classifiers are always the best suited for the pattern recognition problems. This paper presents a comparative study of various classifiers and the results achieved for offline handwritten Gurmukhi characters and numerals recognition. Various classifiers used and evaluated in this study include k-nearest neighbors, linear-support vector machine (SVM), RBF-SVM, Naive Bayes, decision tree, convolution neural network and random forest classifier. For the experimental work, authors used a balanced data set of 13,000 samples that includes 7000 characters and 6000 numerals. To assess the performance of classifiers, authors have used the Waikato Environment for Knowledge Analysis which is an open source tool for machine learning. The performance is assessed by considering various parameters such as accuracy rate, size of the dataset, time taken to train the model, false acceptance rate, false rejection rate and area under receiver operating characteristic Curve. The paper also highlights the comparison of correctness of tests obtained by applying the selected classifiers. Based on the experimental results, it is clear that classifiers considered in this study have complementary rewards and they should be implemented in a hybrid manner to achieve higher accuracy rates. After executing the experimental work, their comparison and analysis, it is concluded that the Random Forest classifier is performing better than other recently used classifiers for character and numeral recognition of offline handwritten Gurmukhi characters and numerals with the recognition accuracy of 87.9\% for 13,000 samples.},
  archive      = {J_AIR},
  author       = {Kumar, Munish and Jindal, M. K. and Sharma, R. K. and Jindal, Simpel Rani},
  doi          = {10.1007/s10462-019-09727-2},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2075-2097},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Performance evaluation of classifiers for the recognition of offline handwritten gurmukhi characters and numerals: A study},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Enhanced leader particle swarm optimisation (ELPSO): A new
algorithm for optimal scheduling of home appliances in demand response
programs. <em>AIR</em>, <em>53</em>(3), 2043–2073. (<a
href="https://doi.org/10.1007/s10462-019-09726-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart grids enable the residential consumers to have an active role in the management of their electricity consumption through home energy management (HEM) systems. HEM systems adjust the ON–OFF status and/or operation modes of home appliances under demand response programs, typically in a way that the electricity bill of the home is minimised and/or the peak load is minimised. This represents a constrained multi-objective optimisation problem with integer decision variables. The existing methodologies for optimal scheduling of home appliances have two drawbacks; most of them have not taken the consumers’ comfort into account and also powerful optimisation algorithms have not been used for solving this problem. In this paper, the problem of optimal scheduling of home appliances in HEM systems is formulated as a constrained, multi-objective optimisation problem with integer decision variables and a powerful variant of particle swarm optimisation, named as enhanced leader particle swarm optimisation (ELPSO) is proposed for solving this problem. Optimal scheduling of appliances is done for ten different scenarios that consider different demand response programs. The problem is solved for two different smart homes respectively with 10 and 11 appliances, both including electric vehicle as a big residential load. The results indicate the superiority of ELPSO over basic PSO, artificial bee colony, backtracking search algorithm, gravitational search algorithm and dragonfly algorithm. In the proposed multi-objective formulation, the effect of weight factor on optimal electricity bill of the home and optimal comfort of the consumers is meticulously investigated.},
  archive      = {J_AIR},
  author       = {Rezaee Jordehi, Ahmad},
  doi          = {10.1007/s10462-019-09726-3},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2043-2073},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Enhanced leader particle swarm optimisation (ELPSO): A new algorithm for optimal scheduling of home appliances in demand response programs},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Leveraging synonymy and polysemy to improve semantic
similarity assessments based on intrinsic information content.
<em>AIR</em>, <em>53</em>(3), 2023–2041. (<a
href="https://doi.org/10.1007/s10462-019-09725-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic similarity measures based on the estimation of the information content (IC) of concepts are currently regarded as the state of the art. Calculating the IC in an intrinsic (i.e., ontology-based) way is particularly convenient due to its accuracy and lack of dependency on annotated corpora. Intrinsic IC calculation models estimate concept probabilities from the taxonomic knowledge (i.e., number of hyponyms and/or hypernyms of the concepts) modelled in an ontology. In this paper, we aim to improve the intrinsic calculation of the IC by leveraging not only the hyponyms and hypernyms of concepts, but also the explicit evidences of synonymy and polysemy that ontologies such as WordNet also model. Specifically, we propose a more accurate intrinsic estimation of the concepts’ probabilities in which the IC calculation relies. We evaluate the accuracy of our proposal through a set of comprehensive experiments in which our IC calculation model is tested on a variety of IC-based similarity measures and benchmarks. Experimental results show that our proposal obtains consistently good accuracies, which vary less across measures and benchmarks than the most prominent intrinsic IC calculation models available in the literature.},
  archive      = {J_AIR},
  author       = {Batet, Montserrat and Sánchez, David},
  doi          = {10.1007/s10462-019-09725-4},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2023-2041},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Leveraging synonymy and polysemy to improve semantic similarity assessments based on intrinsic information content},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Non-intrusive human activity recognition and abnormal
behavior detection on elderly people: A review. <em>AIR</em>,
<em>53</em>(3), 1975–2021. (<a
href="https://doi.org/10.1007/s10462-019-09724-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the world population aging at a fast rate, ambient assisted living systems focused on elderly people gather more attention. Human activity recognition (HAR) is a component connected to those systems, as it allows identification of the actions performed and their utilization on behavioral analysis. This paper aims to provide a review on recent studies focusing on HAR and abnormal behavior detection specifically for seniors. The frameworks proposed in the literature are presented. The results are also discussed and summarized, along with the datasets and metrics used. The absence of a universal evaluation framework makes direct comparison not feasible, thus an analysis is made trying to divide the literature using a taxonomy. Solutions on the challenges identified are proposed, while discussing future work.},
  archive      = {J_AIR},
  author       = {Lentzas, Athanasios and Vrakas, Dimitris},
  doi          = {10.1007/s10462-019-09724-5},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {1975-2021},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Non-intrusive human activity recognition and abnormal behavior detection on elderly people: A review},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Integration of case-based reasoning and fuzzy approaches for
real-time applications in dynamic environments: Current status and
future directions. <em>AIR</em>, <em>53</em>(3), 1943–1974. (<a
href="https://doi.org/10.1007/s10462-019-09723-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This survey reviews recent researches conducted on the application of fuzzy approaches to Case-Based Reasoning (CBR) dealing with real-time applications. Fuzzy approaches have been effectively applied for knowledge representation, feature selection, and learning in CBR. Dealing with imprecise and uncertain knowledge, generalization, mining, and learning also in combination with low computational complexity are the main advantages of fuzzy approaches used in the CBR context. This paper presents and summarizes new findings on the integration of fuzzy approaches with CBR. The survey results highlight the advantages of fuzzy approaches in CBR for real-time applications. They show the current state of fuzzy-based CBR approaches. In addition, fuzzy approaches which are more operative for each operation in CBR are addressed. Those operations most contributing to the advantages of the fuzzy approach will be pointed out and detailed. Low accuracy, storage and computational challenges with a large amount of experiences and uncertainties are important issues in case of real-time applications. This paper proposes a general fuzzy-based CBR approach for real-time applications to benefit the advantages of previous approaches. Finally, some considerations of latest developments in fuzzy approaches which may be introduced as potential research directions for real-time applications are stated.},
  archive      = {J_AIR},
  author       = {Sarkheyli-Hägele, Arezoo and Söffker, Dirk},
  doi          = {10.1007/s10462-019-09723-6},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {1943-1974},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Integration of case-based reasoning and fuzzy approaches for real-time applications in dynamic environments: Current status and future directions},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Computer aided detection in automated 3-d breast ultrasound
images: A survey. <em>AIR</em>, <em>53</em>(3), 1919–1941. (<a
href="https://doi.org/10.1007/s10462-019-09722-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, breast cancer is the leading cause of cancer death for women all over the world. Since the reason of breast cancer is unknown, early detection of the disease plays an important role in cancer control, saving lives and reducing costs. Among different modalities, automated 3-D breast ultrasound (3-D ABUS) is a new and effective imaging modality which has attracted a lot of interest as an adjunct to mammography for women with dense breasts. However, reading ABUS images is time consuming for radiologists and subtle abnormalities may be overlooked. Hence, computer aided detection (CADe) systems can be utilized as a second interpreter to assist radiologists to increase their screening speed and sensitivity. In this paper, a general architecture representing different CADe systems for ABUS images is introduced and the approaches for implementation of each block are categorized and reviewed. In addition, the limitations of these systems are discussed and their performance in terms of sensitivity and number of false positives per volume are compared.},
  archive      = {J_AIR},
  author       = {Kozegar, Ehsan and Soryani, Mohsen and Behnam, Hamid and Salamati, Masoumeh and Tan, Tao},
  doi          = {10.1007/s10462-019-09722-7},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {1919-1941},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Computer aided detection in automated 3-D breast ultrasound images: A survey},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A review of breast boundary and pectoral muscle segmentation
methods in computer-aided detection/diagnosis of breast mammography.
<em>AIR</em>, <em>53</em>(3), 1873–1918. (<a
href="https://doi.org/10.1007/s10462-019-09721-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mammography can be considered as the current gold standard for detecting early signs of breast cancer and is in wide use throughout the world. As confirmed by many studies, breast cancer screening using mammography can reduce breast cancer-related mortality by 30–70\%. However, although the interpretation of mammography images by a second reader has been shown to increase the cancer detection rate, this practice is not widespread due to the cost associated. As a result, computer-aided detection/diagnosis (CAD) of breast mammography has been gaining popularity with various studies illustrating the positive effects of using computers in detecting early breast cancer signs by providing the radiologists with a second opinion with most of these CAD systems requiring the breast outline and pectoral muscle regions (in images acquired using Medio-Lateral-Oblique view) to be segmented from mammograms prior to the classification. This paper discusses recent developments and methods proposed for segmenting the breast and pectoral muscle regions and compares the performance and shortcomings of different approaches grouped together based on the techniques used. While it is arduous to compare these methods using comparative analysis, a set of common performance evaluation criterion is defined in this study and various methods are compared based on their methodology and the validation dataset used. Although many methods can achieve promising results, there is still room for further development, especially in pre-processing and image enhancement steps where most methods do not take the necessary steps for ensuring a smooth segmentation of boundaries. In this paper, the most effective pre-processing, image enhancement and segmentation concepts proposed for breast boundary and pectoral muscle segmentation are identified and discussed in hopes of aiding the readers with identifying the best possible solutions for these segmentation problems.},
  archive      = {J_AIR},
  author       = {Moghbel, Mehrdad and Ooi, Chia Yee and Ismail, Nordinah and Hau, Yuan Wen and Memari, Nogol},
  doi          = {10.1007/s10462-019-09721-8},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {1873-1918},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A review of breast boundary and pectoral muscle segmentation methods in computer-aided detection/diagnosis of breast mammography},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey of mono- and multi-lingual character recognition
using deep and shallow architectures: Indic and non-indic scripts.
<em>AIR</em>, <em>53</em>(3), 1813–1872. (<a
href="https://doi.org/10.1007/s10462-019-09720-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cultural and regional diversity across the world and specifically in India has given birth to a large number of writing systems and scripts having a variety of character sets. For scripts having a larger character set, just a simple keyboard with limited character set is not the optimal way for providing inputs to the computer. Variations in individual handwriting due to mood swings, changes in medium of writing, changes in writing styles, etc. pose a challenge before the character recognition (CR) research community. Similar kinds of symbols in various scripts and languages act as a big barrier in multilingual CR. Lack of benchmark results and corpora for multilingual CR hinder the research in multilingual CR. There have been only a limited number of articles for optimal combination of features and classifiers to process multilingual data. Multilingual CR has least explored the Indic scripts. This paper presents a detailed review and analysis of the work done in multilingual online as well as offline CR for Indic and non-Indic scripts. The paper mainly contributes in two ways: Firstly, it provides a clear perspective about various phases of monolingual and multilingual CR; and secondly, identifies the major deficiencies in monolingual and multilingual CR for printed and handwritten text. It contributes by giving an in-depth view of work done at each phase including data acquisition, pre-processing, segmentation, feature extraction, recognition and post-processing of CR. Issues to be resolved at each phase have also been elaborated. The recent work done using Deep and Shallow architectures has been analysed. Tools used for these architectures have been compared to highlight their pros and cons. The present work also suggests how further research can be conducted in the field of monolingual and multilingual CR. The problems such as CR in hybrid documents, identifying more reliable features, resolving issues of similar characters, identifying optimal combination strategies for deep and shallow architectures, etc. need to be tackled in future research.},
  archive      = {J_AIR},
  author       = {Kaur, Sukhandeep and Bawa, Seema and Kumar, Ravinder},
  doi          = {10.1007/s10462-019-09720-9},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {1813-1872},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey of mono- and multi-lingual character recognition using deep and shallow architectures: Indic and non-indic scripts},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey of swarm and evolutionary computing approaches for
deep learning. <em>AIR</em>, <em>53</em>(3), 1767–1812. (<a
href="https://doi.org/10.1007/s10462-019-09719-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL) has become an important machine learning approach that has been widely successful in many applications. Currently, DL is one of the best methods of extracting knowledge from large sets of raw data in a (nearly) self-organized manner. The technical design of DL depends on the feed-forward information flow principle of artificial neural networks with multiple layers of hidden neurons, which form deep neural networks (DNNs). DNNs have various architectures and parameters and are often developed for specific applications. However, the training process of DNNs can be prolonged based on the application and training set size (Gong et al. 2015). Moreover, finding the most accurate and efficient architecture of a deep learning system in a reasonable time is a potential difficulty associated with this approach. Swarm intelligence (SI) and evolutionary computing (EC) techniques represent simulation-driven non-convex optimization frameworks with few assumptions based on objective functions. These methods are flexible and have been proven effective in many applications; therefore, they can be used to improve DL by optimizing the applied learning models. This paper presents a comprehensive survey of the most recent approaches involving the hybridization of SI and EC algorithms for DL, the architecture of DNNs, and DNN training to improve the classification accuracy. The paper reviews the significant roles of SI and EC in optimizing the hyper-parameters and architectures of a DL system in context to large scale data analytics. Finally, we identify some open problems for further research, as well as potential issues related to DL that require improvements, and an extensive bibliography of the pertinent research is presented.},
  archive      = {J_AIR},
  author       = {Darwish, Ashraf and Hassanien, Aboul Ella and Das, Swagatam},
  doi          = {10.1007/s10462-019-09719-2},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {1767-1812},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey of swarm and evolutionary computing approaches for deep learning},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Recent studies on chicken swarm optimization algorithm: A
review (2014–2018). <em>AIR</em>, <em>53</em>(3), 1737–1765. (<a
href="https://doi.org/10.1007/s10462-019-09718-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving a complex optimization problem in a limited timeframe is a tedious task. Conventional gradient-based optimization algorithms have their limitations in solving complex problems such as unit commitment, microgrid planning, vehicle routing, feature selection, and community detection in social networks. In recent years population-based bio-inspired algorithms have demonstrated competitive performance on a wide range of optimization problems. Chicken Swarm Optimization Algorithm (CSO) is one of such bio-inspired meta-heuristic algorithms mimicking the behaviour of chicken swarm. It is reported in many literature that CSO outperforms a number of well-known meta-heuristics in a wide range of benchmark problems. This paper presents a review of various issues related to CSO like general biology, fundamentals, variants of CSO, performance of CSO, and applications of CSO.},
  archive      = {J_AIR},
  author       = {Deb, Sanchari and Gao, Xiao-Zhi and Tammi, Kari and Kalita, Karuna and Mahanta, Pinakeswar},
  doi          = {10.1007/s10462-019-09718-3},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {1737-1765},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Recent studies on chicken swarm optimization algorithm: A review (2014–2018)},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A review of generative adversarial networks and its
application in cybersecurity. <em>AIR</em>, <em>53</em>(3), 1721–1736.
(<a href="https://doi.org/10.1007/s10462-019-09717-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper reviews Generative Adversarial Networks (GANs) in detail by discussing the strength of the GAN when compared to other generative models, how GANs works and some of the notable problems with training, tuning and evaluating GANs. The paper also briefly reviews notable GAN architectures like the Deep Convolutional Generative Adversarial Network (DCGAN), and Wasserstein GAN, with the aim of showing how design specifications in these architectures help solve some of the problems with the basic GAN model. All this is done with a view of discussing the application of GANs in cybersecurity studies. Here, the paper reviews notable cybersecurity studies where the GAN plays a key role in the design of a security system or adversarial system. In general, from the review, one can observe two major approaches these cybersecurity studies follow. In the first approach, the GAN is used to improve generalization to unforeseen adversarial attacks, by generating novel samples that resembles adversarial data which can then serve as training data for other machine learning models. In the second approach, the GAN is trained on data that contains authorized features with the goal of generating realistic adversarial data that can thus fool a security system. These two approaches currently guide the scope of modern cybersecurity studies with generative adversarial networks.},
  archive      = {J_AIR},
  author       = {Yinka-Banjo, Chika and Ugot, Ogban-Asuquo},
  doi          = {10.1007/s10462-019-09717-4},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {1721-1736},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A review of generative adversarial networks and its application in cybersecurity},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep learning-based breast cancer classification through
medical imaging modalities: State of the art and research challenges.
<em>AIR</em>, <em>53</em>(3), 1655–1720. (<a
href="https://doi.org/10.1007/s10462-019-09716-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer is a common and fatal disease among women worldwide. Therefore, the early and precise diagnosis of breast cancer plays a pivotal role to improve the prognosis of patients with this disease. Several studies have developed automated techniques using different medical imaging modalities to predict breast cancer development. However, few review studies are available to recapitulate the existing literature on breast cancer classification. These studies provide an overview of the classification, segmentation, or grading of many cancer types, including breast cancer, by using traditional machine learning approaches through hand-engineered features. This review focuses on breast cancer classification by using medical imaging multimodalities through state-of-the-art artificial deep neural network approaches. It is anticipated to maximize the procedural decision analysis in five aspects, such as types of imaging modalities, datasets and their categories, pre-processing techniques, types of deep neural network, and performance metrics used for breast cancer classification. Forty-nine journal and conference publications from eight academic repositories were methodically selected and carefully reviewed from the perspective of the five aforementioned aspects. In addition, this study provided quantitative, qualitative, and critical analyses of the five aspects. This review showed that mammograms and histopathologic images were mostly used to classify breast cancer. Moreover, about 55\% of the selected studies used public datasets, and the remaining used exclusive datasets. Several studies employed augmentation, scaling, and image normalization pre-processing techniques to minimize inconsistencies in breast cancer images. Several types of shallow and deep neural network architecture were employed to classify breast cancer using images. The convolutional neural network was utilized frequently to construct an effective breast cancer classification model. Some of the selected studies employed a pre-trained network or developed new deep neural networks to classify breast cancer. Most of the selected studies used accuracy and area-under-the-curve metrics followed by sensitivity, precision, and F-measure metrics to evaluate the performance of the developed breast cancer classification models. Finally, this review presented 10 open research challenges for future scholars who are interested to develop breast cancer classification models through various imaging modalities. This review could serve as a valuable resource for beginners on medical image classification and for advanced scientists focusing on deep learning-based breast cancer classification through different medical imaging modalities.},
  archive      = {J_AIR},
  author       = {Murtaza, Ghulam and Shuib, Liyana and Abdul Wahab, Ainuddin Wahid and Mujtaba, Ghulam and Nweke, Henry Friday and Al-garadi, Mohammed Ali and Zulfiqar, Fariha and Raza, Ghulam and Azmi, Nor Aniza},
  doi          = {10.1007/s10462-019-09716-5},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {1655-1720},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Deep learning-based breast cancer classification through medical imaging modalities: State of the art and research challenges},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Enhanced bag of visual words representations for content
based image retrieval: A comparative study. <em>AIR</em>,
<em>53</em>(3), 1615–1653. (<a
href="https://doi.org/10.1007/s10462-019-09715-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exponential growth of digital image data poses numerous open problems to computer vision researchers. In this regard, designing an efficient and more accurate mechanism that finds and retrieve desired images from large repositories is of greater importance. To this end, various types of content based image retrieval (CBIR) systems have been developed. A typical CBIR system enables the search and retrieval of desired images from large databases that are similar to a given query image by means of automatically extracted visual features from image pixels. In CBIR domain, the bag of visual words (BoVW) model is one of the most widely used feature representation scheme and there exist a number of image retrieval frameworks based on BoVW model. It has been observed that most of them demonstrated promising results for the task of medium and large scale image retrieval. However, image retrieval literature lacks a comparative evaluation of these extended BoVW formulations. To this end, this paper aims to categorize and evaluate the existing BoVW model based formulations for the task of content based image retrieval. The commonly used datasets and the evaluation metrics to assess the retrieval effectiveness of these existing models are discussed. Moreover, quantitative evaluation of state of the art image retrieval systems based on BoVW model is also provided. Finally, certain promising directions for future research are proposed on the basis of the existing models and the demand from real-world.},
  archive      = {J_AIR},
  author       = {Arun, K. S. and Govindan, V. K. and Kumar, S. D. Madhu},
  doi          = {10.1007/s10462-019-09715-6},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {1615-1653},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Enhanced bag of visual words representations for content based image retrieval: A comparative study},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Generation of maximal fuzzy cliques of fuzzy permutation
graph and applications. <em>AIR</em>, <em>53</em>(3), 1585–1614. (<a
href="https://doi.org/10.1007/s10462-019-09714-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy permutation graph (FPG) plays a significant role in solving real-life problems where the scope and application of crisp permutation graph get limited due to the fuzziness involved in real situations. In this article an algorithm is designed to find out all maximal fuzzy cliques of a FPG. A similar algorithm is developed at the same time to find out all maximal fuzzy independent sets of the said graph. The inter-relationship between FPG and its two types of complements is presented based on the facts and theories established on fuzzy cliques and fuzzy independent sets. The importance of fuzzy cliques of FPG is discussed through an application on a daily-life problem. The unique property of a FPG having two types of complement graphs help us to solve many useful problems. Here, we have shown how this property of FPG helps us to overcome a hazardous situation occurred due to disrupted scheduling of trains on a foggy day.},
  archive      = {J_AIR},
  author       = {Raut, Sreenanda and Pal, Madhumangal},
  doi          = {10.1007/s10462-019-09714-7},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {1585-1614},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Generation of maximal fuzzy cliques of fuzzy permutation graph and applications},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimum design of fuzzy controller using hybrid ant lion
optimizer and jaya algorithm. <em>AIR</em>, <em>53</em>(3), 1553–1584.
(<a href="https://doi.org/10.1007/s10462-019-09713-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy logic controller is the most common and versatile control algorithm in the structural motion control. In most cases, the formulation of the fuzzy controller is based on the human knowledge and expert so the membership functions and the rule base are formulated by trials and errors. In recent years, there is an increasing interest to optimize the fuzzy logic controller with different metaheuristics and nature inspired approaches. This paper focuses on the optimization of a fuzzy controller applied to the seismically excited nonlinear buildings. In the majority of cases, this problem is formulated based on the linear behavior of the structure, however in this paper, objective functions and the performance criteria are considered with respect to the nonlinear responses of the structures. The optimization algorithm is based on the implementation of ant lion optimizer and Jaya algorithm as a hybrid method. The new method is utilized to design a fuzzy controller for two benchmark buildings with nonlinear behavior. The performance of the hybrid method is compared with various classical and advanced optimization algorithms.},
  archive      = {J_AIR},
  author       = {Azizi, Mahdi and Mousavi Ghasemi, Seyyed Arash and Ejlali, Reza Goli and Talatahari, Siamak},
  doi          = {10.1007/s10462-019-09713-8},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {1553-1584},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Optimum design of fuzzy controller using hybrid ant lion optimizer and jaya algorithm},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A review of alignment based similarity measures for web
usage mining. <em>AIR</em>, <em>53</em>(3), 1529–1551. (<a
href="https://doi.org/10.1007/s10462-019-09712-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to understand web-based application user behavior, web usage mining applies unsupervised learning techniques to discover hidden patterns from web data that captures user browsing on web sites. For this purpose, web session clustering has been among the most popular approaches to group users with similar browsing patterns that reflect their common interest. An adequate web session clustering implementation significantly depends on the measure that is used to evaluate the similarity of sessions. An efficient approach to evaluate session similarity is sequence alignment, which is known as the task of determining the similarity of elements between sequences. In this paper, we review and compare sequence alignment-based measures for web sessions, and also discuss sequence similarity measures that are not alignment-based. This review also provides a perspective of sequence similarity measures that manipulate web sessions in usage clustering process.},
  archive      = {J_AIR},
  author       = {Luu, Vinh-Trung and Forestier, Germain and Weber, Jonathan and Bourgeois, Paul and Djelil, Fahima and Muller, Pierre-Alain},
  doi          = {10.1007/s10462-019-09712-9},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {1529-1551},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A review of alignment based similarity measures for web usage mining},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A v-twin projection SVR with automatic accuracy adjustment.
<em>AIR</em>, <em>53</em>(2), 1511–1527. (<a
href="https://doi.org/10.1007/s10462-019-09711-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Taking motivation from v-insensitive twin support vector regression (v-TSVR) and the projection idea, this paper proposes a novel v-twin projection support vector regression model, called v-TPSVR. This v-TPSVR, based on v-TSVR, determines the regression function through a pair of nonparallel hyperplanes solved by two smaller sized quadratic programming problems (QPPs). The proposed v-TPSVR model also can automatically optimize the parameters $$ \varepsilon_{1} $$ and $$ \varepsilon_{2} $$ via the user specified parameters $$ v_{1} $$ and $$ v_{2} $$, which is the same as v-TSVR. But different from v-TSVR, v-TPSVR seeks a projection axis in each QPP such that the variance of the projected points is minimized, so the empirical correlation coefficient between each hyperplane and the projected inputs is maximized. Although the training speed of the proposed algorithm is similar to that of other compared algorithms, it is obvious that the introduction of the projection axis makes the number of SV less than that of v -TSVR under the same values of $$ v_{1} $$ and $$ v_{2} $$, it would lead to faster testing speed. In addition, The experimental results indicate that the proposed v-TPSVR obtains the better prediction performance than the popular ɛ-TSVR and v-TSVR.},
  archive      = {J_AIR},
  author       = {Zhao, Nan-nan and Ouyang, Xin-yu and Gao, Chuang and Wang, Li-dong},
  doi          = {10.1007/s10462-019-09711-w},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1511-1527},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A v-twin projection SVR with automatic accuracy adjustment},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Missing value imputation: A review and analysis of the
literature (2006–2017). <em>AIR</em>, <em>53</em>(2), 1487–1509. (<a
href="https://doi.org/10.1007/s10462-019-09709-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Missing value imputation (MVI) has been studied for several decades being the basic solution method for incomplete dataset problems, specifically those where some data samples contain one or more missing attribute values. This paper aims at reviewing and analyzing related studies carried out in recent decades, from the experimental design perspective. Altogether, 111 journal papers published from 2006 to 2017 are reviewed and analyzed. In addition, several technical issues encountered during the MVI process are addressed, such as the choice of datasets, missing rates and missingness mechanisms, and the MVI techniques and evaluation metrics employed, are discussed. The results of analysis of these issues allow limitations in the existing body of literature to be identified based upon which some directions for future research can be gleaned.},
  archive      = {J_AIR},
  author       = {Lin, Wei-Chao and Tsai, Chih-Fong},
  doi          = {10.1007/s10462-019-09709-4},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1487-1509},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Missing value imputation: A review and analysis of the literature (2006–2017)},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel chaotic selfish herd optimizer for global
optimization and feature selection. <em>AIR</em>, <em>53</em>(2),
1441–1486. (<a
href="https://doi.org/10.1007/s10462-019-09707-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Selfish Herd Optimizer (SHO) is a recently proposed population-based metaheuristic inspired by the predatory interactions of herd and predators. It has been proved that SHO can provide competitive results in comparison to other well-known metaheuristics on various optimization problems. Like other metaheuristic algorithms, the main problem faced by the SHO is that it may easily get trapped into local optimal solutions, creating low precision and slow convergence speeds. Therefore, in order to enhance the global convergence speeds, and to obtain better performance, chaotic search have been augmented to searching process of SHO. Various chaotic maps were considered in the proposed Chaotic Selfish Herd Optimizer (CSHO) algorithm in order to replace the value of survival parameter of each searching agent which assists in controlling both exploration and exploitation. The performance of the proposed CSHO is compared with recent high performing meta-heuristics on 13 benchmark functions having unimodal and multimodal properties. Additionally the performance of CSHO as a feature selection approach is compared with various state-of-the-art feature selection approaches. The simulation results demonstrated that the chaotic maps (especially tent map) are able to significantly boost the performance of SHO. Moreover, the results clearly indicated the competency of CSHO in achieving the optimal feature subset by accomplishing maximum accuracy and a minimum number of features.},
  archive      = {J_AIR},
  author       = {Anand, Priyanka and Arora, Sankalap},
  doi          = {10.1007/s10462-019-09707-6},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1441-1486},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A novel chaotic selfish herd optimizer for global optimization and feature selection},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hybrid computational intelligence algorithms and their
applications to detect food quality. <em>AIR</em>, <em>53</em>(2),
1415–1440. (<a
href="https://doi.org/10.1007/s10462-019-09705-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Food security is a major problem faced today. With primitive storage facilities, especially in developing countries, it often leads to extensive losses. This work aims to develop algorithms based on vision data to assess the food quality and deploy them in food storage facilities to detect early signs of spoilage. This paper presents various segmentation techniques for finding spoilt food. Novel optimization techniques have been developed and implemented to improve K-means clustering and multilevel thresholding. A hybrid of moth flame optimization (MFO) and gravitational search algorithm (GSA) has been developed. Also, in another hybrid, particle swarm optimization (PSO) was also incorporated along with MFO and GSA. Both the hybrids performed better than the individual algorithms and the MFO–GSA–PSO hybrid performed better than the MFO–GSA hybrid on the benchmark functions. Segmented images using optimized K-means were used for feature extraction using local binary patterns (LBP). Multiclass support vector machine was used for classification which gave an accuracy of 81\% for features from segmented images obtained using MFO–GSA hybrid and 83.33\% for that using MFO–GSA–PSO hybrid. Results of simple linear iterative clustering superpixels for segmentation have also been discussed. The segmented clusters are then used to judge the rottenness of the food. Classification using LBP and Haralick features of the segmented image obtained using graphs over superpixels gave an accuracy of 81.7\% and 78\% respectively.},
  archive      = {J_AIR},
  author       = {Goel, Lavika and Raman, Sundaresan and Dora, Subham Swastik and Bhutani, Anirudh and Aditya, A. S. and Mehta, Abhinav},
  doi          = {10.1007/s10462-019-09705-8},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1415-1440},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Hybrid computational intelligence algorithms and their applications to detect food quality},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bird swarm algorithms with chaotic mapping. <em>AIR</em>,
<em>53</em>(2), 1373–1414. (<a
href="https://doi.org/10.1007/s10462-019-09704-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Swarm intelligence based optimization methods have been proposed by observing the movements of alive swarms such as bees, birds, cats, and fish in order to obtain a global solution in a reasonable time when mathematical models cannot be formed. However, many swarm intelligence algorithms suffer premature convergence and they may stumble in local optima. Bird swarm algorithm (BSA) is one of the most recent swarm-based methods that suffers the same problems in some situations. In order to obtain a faster convergence with high accuracy from the swarm based optimization algorithms, different methods have been utilized for balancing the exploitation and exploration. In this paper, chaos has been integrated into the standard BSA, for the first time, in order to enhance the global convergence feature by preventing premature convergence and stumbling in the local solutions. Furthermore, a new research area has been introduced for chaotic dynamics. The standard BSA and the chaotic BSAs proposed in this paper have been tested on unimodal and multimodal unconstrained benchmark functions, and on constrained real-life engineering design problems. Generally, the obtained results from the proposed novel chaotic BSAs with an appropriate chaotic map can outperform the standard BSA on benchmark functions and engineering design problems. The proposed chaotic BSAs are expected to be used effectively in many complex problems in future by integrating enhanced multi-dimensional chaotic maps, time-continuous chaotic systems, and hybrid multi-dimensional maps.},
  archive      = {J_AIR},
  author       = {Varol Altay, Elif and Alatas, Bilal},
  doi          = {10.1007/s10462-019-09704-9},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1373-1414},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Bird swarm algorithms with chaotic mapping},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Attribute reducts of multi-granulation information system.
<em>AIR</em>, <em>53</em>(2), 1353–1371. (<a
href="https://doi.org/10.1007/s10462-019-09699-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, more and more methods and theories of multi-granulation information systems have been explored. However, there is very limited investigation on the attribute reducts of multi-granulation rough sets. Therefore, the main objective of this paper is to draw attention to the attribute reducts of multi-granulation information system. For any subset of information system, we usually characterize it by its upper and lower approximations. In order to calculate the upper and lower approximations faster, we must reduce the redundant information of the information system. According to the preceding analysis, we first introduce three types of attribute reduct, which are called arbitrary union reduct, neighborhood union reduct and neighborhood intersection reduct, respectively. Then many basic and important results of these reducts are deeply explored. In order to apply the theories of attribute reducts to deal with practical issues, we develop three algorithms so as to compute multi-granulation upper and lower approximations. Next, we further study the interrelationships among these attribute reducts. Finally, we present a multi-granulation information system with respect to thirty students’ exam scores and calculate the corresponding attribute reducts by using the algorithms listed in the paper.},
  archive      = {J_AIR},
  author       = {Kong, Qingzhao and Zhang, Xiawei and Xu, Weihua and Xie, Shutong},
  doi          = {10.1007/s10462-019-09699-3},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1353-1371},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Attribute reducts of multi-granulation information system},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deceptive consumer review detection: A survey. <em>AIR</em>,
<em>53</em>(2), 1323–1352. (<a
href="https://doi.org/10.1007/s10462-019-09697-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consumer reviews are considered to be of utmost significance in the field of e-commerce, for they have a stronghold in deciding the revenue of a business. When arriving at a purchasing decision, a majority of online consumers rely on reviews since they offer credible means of mining opinions of other consumers regarding a particular product. The trustworthiness of online reviews directly affects a company’s reputation and profitability, which is why certain business owners pay fraudsters to generate deceptive reviews. Such generation of deceptive reviews which manipulate the purchasing decision of consumers is a persistent and harmful issue. Hence, developing methods to assist businesses and consumers by distinguishing between credible reviews and deceptive reviews remains to be a crucial, yet challenging task. In view of that, this paper unravels prominent techniques that have been proposed to solve the issue of deceptive review detection. Accordingly, the primary goal of this paper is to provide an in-depth analysis of current research on detecting deceptive reviews and to identify the characteristics, strengths, and bottlenecks of those methodologies which may need further improvements.},
  archive      = {J_AIR},
  author       = {Vidanagama, Dushyanthi U. and Silva, Thushari P. and Karunananda, Asoka S.},
  doi          = {10.1007/s10462-019-09697-5},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1323-1352},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Deceptive consumer review detection: A survey},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Online AdaBoost-based methods for multiclass problems.
<em>AIR</em>, <em>53</em>(2), 1293–1322. (<a
href="https://doi.org/10.1007/s10462-019-09696-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Boosting is a technique forged to transform a set of weak classifiers into a strong ensemble. To achieve this, the components are trained with different data samples and the hypotheses are aggregated in order to perform a better prediction. The use of boosting in online environments is a comparatively new activity, inspired by its success in offline environments, which is emerging to meet new demands. One of the challenges is to make the methods handle significant amounts of information taking into account computational constraints. This paper proposes two new online boosting methods: the first aims to perform a better weight distribution of the instances to closely match the behavior of AdaBoost.M1 whereas the second focuses on multiclass problems and is based on AdaBoost.M2. Theoretical arguments were used to demonstrate their convergence and also that both methods retain the main features of their traditional counterparts. In addition, we performed experiments to compare the accuracy as well as the memory usage of the proposed methods against other approaches using 20 well-known datasets. Results suggest that, in many different situations, the proposed algorithms maintain high accuracies, outperforming the other tested methods.},
  archive      = {J_AIR},
  author       = {Santos, Silas Garrido Teixeira de Carvalho and de Barros, Roberto Souto Maior},
  doi          = {10.1007/s10462-019-09696-6},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1293-1322},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Online AdaBoost-based methods for multiclass problems},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-agent system for microgrids: Design, optimization and
performance. <em>AIR</em>, <em>53</em>(2), 1233–1292. (<a
href="https://doi.org/10.1007/s10462-019-09695-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart grids are considered a promising alternative to the existing power grid, combining intelligent energy management with green power generation. Decomposed further into microgrids, these small-scaled power systems increase control and management efficiency. With scattered renewable energy resources and loads, multi-agent systems are a viable tool for controlling and improving the operation of microgrids. They are autonomous systems, where agents interact together to optimize decisions and reach system objectives. This paper presents an overview of multi-agent systems for microgrid control and management. It discusses design elements and performance issues, whereby various performance indicators and optimization algorithms are summarized and compared in terms of convergence time and performance in achieving system objectives. It is found that Particle Swarm Optimization has a good convergence time, so it is combined with other algorithms to address optimization issues in microgrids. Further, information diffusion and consensus algorithms are explored, and according to the literature, many variants of average-consensus algorithm are used to asynchronously reach an equilibrium. Finally, multi-agent system for multi-microgrid service restoration is discussed. Throughout the paper, challenges and research gaps are highlighted in each section as an opportunity for future work.},
  archive      = {J_AIR},
  author       = {Tazi, Khadija and Abbou, Fouad Mohamed and Abdi, Farid},
  doi          = {10.1007/s10462-019-09695-7},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1233-1292},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Multi-agent system for microgrids: Design, optimization and performance},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Filtering techniques for channel selection in motor imagery
EEG applications: A survey. <em>AIR</em>, <em>53</em>(2), 1207–1232. (<a
href="https://doi.org/10.1007/s10462-019-09694-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain computer interface (BCI) systems are used in a wide range of applications such as communication, neuro-prosthetic and environmental control for disabled persons using robots and manipulators. A typical BCI system uses different types of inputs; however, Electroencephalography (EEG) signals are most widely used due to their non-invasive EEG electrodes, portability, and cost efficiency. The signals generated by the brain while performing or imagining a motor related task [motor imagery (MI)] signals are one of the important inputs for BCI applications. EEG data is usually recorded from more than 100 locations across the brain, so efficient channel selection algorithms are of great importance to identify optimal channels related to a particular application. The main purpose of applying channel selection is to reduce computational complexity while analysing EEG signals, improve classification accuracy by reducing over-fitting, and decrease setup time. Different channel selection evaluation algorithms such as filtering, wrapper, and hybrid methods have been used for extracting optimal channel subsets by using predefined criteria. After extensively reviewing the literature in the field of EEG channel selection, we can conclude that channel selection algorithms provide a possibility to work with fewer channels without affecting the classification accuracy. In some cases, channel selection increases the system performance by removing the noisy channels. The research in the literature shows that the same performance can be achieved using a smaller channel set, with 10–30 channels in most cases. In this paper, we present a survey of recent development in filtering channel selection techniques along with their feature extraction and classification methods for MI-based EEG applications.},
  archive      = {J_AIR},
  author       = {Baig, Muhammad Zeeshan and Aslam, Nauman and Shum, Hubert P. H.},
  doi          = {10.1007/s10462-019-09694-8},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1207-1232},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Filtering techniques for channel selection in motor imagery EEG applications: A survey},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A comprehensive review of type-2 fuzzy ontology.
<em>AIR</em>, <em>53</em>(2), 1187–1206. (<a
href="https://doi.org/10.1007/s10462-019-09693-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ontologies are not only crucial for extending the traditional web into the Semantic Web but also for developing intelligent applications, by converting the raw data into smart data, through semantic enrichment. However, crisp Ontologies are not able to represent fuzzy knowledge which is often encountered in real-world applications. Fuzzy Ontology introduces fuzzy logical rules in Ontology for representing imprecise domain concepts such as darkness, hotness, thickness, creamy etc. in a machine-readable and interoperable format. The performance of fuzzy Ontology decreases with the increase of fuzziness in the domain knowledge. Type-2 fuzzy Ontologies (T2FO) were introduced to represent the domain knowledge where the concepts are either extremely vague or their vagueness increases gradually. The type-2 fuzzy Ontology domain is continuously expanding and there is a need to provide a comprehensive review incorporating the literature of T2FO development approaches, its applications in different domains, reasoners developed for inferencing on type-2 fuzzy Ontology, and evaluation approaches. To perform a comprehensive survey about the T2FO, we used Google Scholar as the main literature research tool to review papers published between 1998 to 2018. We then summarized the published approaches by comparing their features proposed for T2FO development, reasoning or inference, and evaluation approaches. This paper also identifies the domains wherein the past T2FO has been used to develop real-world applications. We conclude this paper by summarizing the previous work, and by identifying the research gaps for investigators.},
  archive      = {J_AIR},
  author       = {Qasim, Iqbal and Alam, Mahmood and Khan, Shumaila and Khan, Abdul Wahid and Malik, Khalid Mahmood and Saleem, Muhammad and Bukhari, Syed Ahmad Chan},
  doi          = {10.1007/s10462-019-09693-9},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1187-1206},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A comprehensive review of type-2 fuzzy ontology},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An enhanced colliding bodies optimization and its
application. <em>AIR</em>, <em>53</em>(2), 1127–1186. (<a
href="https://doi.org/10.1007/s10462-019-09691-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Colliding bodies optimization (CBO) is a recently proposed algorithm, and there are no algorithm-specific parameters that should be previously determined in updating equations of bodies. CBO has been used to solve various optimization problems because of its simple structure. However, CBO suffers from low convergence speed and premature convergence. To enhance CBO’s performance, a new variant named learning strategy based colliding bodies optimization (LSCBO), which is based on the learning strategy of the Teaching–learning-based optimization algorithm (TLBO), is proposed in this paper. In this method, a hybrid strategy combining the colliding process of CBO and the learning process of TLBO is proposed to generate new positions of the bodies. Compared with some other CBO variants, the guidance of the best individual is introduced to improve the convergence speed of CBO, and a random mutation method based on the historic information is designed to help bodies escape from local optima. Moreover, a new method for determining the mass of bodies is designed to avoid computation overflow. To evaluate the effectiveness of LSCBO, 47 benchmark functions and three real-world structural design problems are tested in the simulation experiments, and the results are compared with those of other well-known meta-heuristic algorithms. The statistical simulation results indicate that the performance of CBO is obviously improved by the developed method.},
  archive      = {J_AIR},
  author       = {Chen, Debao and Lu, Renquan and Li, Suwen and Zou, Feng and Liu, Yajun},
  doi          = {10.1007/s10462-019-09691-x},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1127-1186},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An enhanced colliding bodies optimization and its application},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Covering based multigranulation fuzzy rough sets and
corresponding applications. <em>AIR</em>, <em>53</em>(2), 1093–1126. (<a
href="https://doi.org/10.1007/s10462-019-09690-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By combining covering based rough sets, fuzzy rough sets, and multigranulation rough sets, we introduce covering based multigranulation fuzzy rough set models by means of fuzzy $$\beta $$-neighborhoods. We investigate axiomatic characterizations of covering based optimistic, pessimistic and variable precision multigranulation fuzzy rough set models. We propose coverings based $$\alpha $$-optimistic (pessimistic) multigranulation fuzzy rough sets and D-optimistic (pessimistic) multigranulation fuzzy rough sets from fuzzy measures. We examine the relationships among these kinds of coverings based fuzzy rough sets. Finally, we apply the proposed models to solve problems for multi-criteria group decision-making.},
  archive      = {J_AIR},
  author       = {Zhan, Jianming and Zhang, Xiaohong and Yao, Yiyu},
  doi          = {10.1007/s10462-019-09690-y},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1093-1126},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Covering based multigranulation fuzzy rough sets and corresponding applications},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fall prediction using behavioural modelling from sensor data
in smart homes. <em>AIR</em>, <em>53</em>(2), 1071–1091. (<a
href="https://doi.org/10.1007/s10462-019-09687-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The number of methods for identifying potential fall risk is growing as the rate of elderly fallers continues to rise in the UK. Assessments for identifying risk of falling are usually performed in hospitals and other laboratory environments, however these are costly and cause inconvenience for the subject and health services. Replacing these intrusive testing methods with a passive in-home monitoring solution would provide a less time-consuming and cheaper alternative. As sensors become more readily available, machine learning models can be applied to the large amount of data they produce. This can support activity recognition, falls detection, prediction and risk determination. In this review, the growing complexity of sensor data, the required analysis, and the machine learning techniques used to determine risk of falling are explored. The current research on using passive monitoring in the home is discussed, while the viability of active monitoring using vision-based and wearable sensors is considered. Methods of fall detection, prediction and risk determination are then compared.},
  archive      = {J_AIR},
  author       = {Forbes, Glenn and Massie, Stewart and Craw, Susan},
  doi          = {10.1007/s10462-019-09687-7},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1071-1091},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Fall prediction using behavioural modelling from sensor data in smart homes},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Can autism be catered with artificial intelligence-assisted
intervention technology? A comprehensive survey. <em>AIR</em>,
<em>53</em>(2), 1039–1069. (<a
href="https://doi.org/10.1007/s10462-019-09686-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents an extensive literature review of technology based intervention methodologies for individuals facing autism spectrum disorder (ASD). Reviewed methodologies include: contemporary computer aided systems, computer vision assisted technologies and virtual reality (VR) or artificial intelligence (AI)-assisted interventions. The research over the past decade has provided enough demonstrations that individuals with ASD have a strong interest in technology based interventions, which are useful in both, clinical settings as well as at home and classrooms. Despite showing great promise, research in developing an advanced technology based intervention that is clinically quantitative for ASD is minimal. Moreover, the clinicians are generally not convinced about the potential of the technology based interventions due to non-empirical nature of published results. A major reason behind this lack of acceptability is that a vast majority of studies on distinct intervention methodologies do not follow any specific standard or research design. We conclude from our findings that there remains a gap between the research community of computer science, psychology and neuroscience to develop an AI assisted intervention technology for individuals suffering from ASD. Following the development of a standardized AI based intervention technology, a database needs to be developed, to devise effective AI algorithms.},
  archive      = {J_AIR},
  author       = {Jaliaawala, Muhammad Shoaib and Khan, Rizwan Ahmed},
  doi          = {10.1007/s10462-019-09686-8},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1039-1069},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Can autism be catered with artificial intelligence-assisted intervention technology? a comprehensive survey},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The state of the art and taxonomy of big data analytics:
View from new big data framework. <em>AIR</em>, <em>53</em>(2),
989–1037. (<a href="https://doi.org/10.1007/s10462-019-09685-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Big data has become a significant research area due to the birth of enormous data generated from various sources like social media, internet of things and multimedia applications. Big data has played critical role in many decision makings and forecasting domains such as recommendation systems, business analysis, healthcare, web display advertising, clinicians, transportation, fraud detection and tourism marketing. The rapid development of various big data tools such as Hadoop, Storm, Spark, Flink, Kafka and Pig in research and industrial communities has allowed the huge number of data to be distributed, communicated and processed. Big data applications use big data analytics techniques to efficiently analyze large amounts of data. However, choosing the suitable big data tools based on batch and stream data processing and analytics techniques for development a big data system are difficult due to the challenges in processing and applying big data. Practitioners and researchers who are developing big data systems have inadequate information about the current technology and requirement concerning the big data platform. Hence, the strengths and weaknesses of big data technologies and effective solutions for Big Data challenges are needed to be discussed. Hence, due to that, this paper presents a review of the literature that analyzes the use of big data tools and big data analytics techniques in areas like health and medical care, social networking and internet, government and public sector, natural resource management, economic and business sector. The goals of this paper are to (1) understand the trend of big data-related research and current frames of big data technologies; (2) identify trends in the use or research of big data tools based on batch and stream processing and big data analytics techniques; (3) assist and provide new researchers and practitioners to place new research activity in this domain appropriately. The findings of this study will provide insights and knowledge on the existing big data platforms and their application domains, the advantages and disadvantages of big data tools, big data analytics techniques and their use, and new research opportunities in future development of big data systems.},
  archive      = {J_AIR},
  author       = {Mohamed, Azlinah and Najafabadi, Maryam Khanian and Wah, Yap Bee and Zaman, Ezzatul Akmal Kamaru and Maskat, Ruhaila},
  doi          = {10.1007/s10462-019-09685-9},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {989-1037},
  shortjournal = {Artif. Intell. Rev.},
  title        = {The state of the art and taxonomy of big data analytics: View from new big data framework},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A study on features of social recommender systems.
<em>AIR</em>, <em>53</em>(2), 965–988. (<a
href="https://doi.org/10.1007/s10462-019-09684-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender system is an emerging field of research with the advent of World Wide Web and E-commerce. Recently, an increasing usage of social networking websites plausibly has a great impact on diverse facets of our lives in different ways. Initially, researchers used to consider recommender system and social networks as independent topics. With the passage of time, they realized the importance of merging the two to produce enhanced recommendations. The integration of recommender system with social networks produces a new system termed as social recommender system. In this study, we initially describe the concept of recommender system and social recommender system and then investigates different features of social networks that play a major role in generating effective recommendations. Each feature plays an essential role in giving good recommendations and resolving the issues of traditional recommender systems. Lastly, this paper also discusses future work in this area that can aid in enriching the quality of social recommender systems.},
  archive      = {J_AIR},
  author       = {Shokeen, Jyoti and Rana, Chhavi},
  doi          = {10.1007/s10462-019-09684-w},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {965-988},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A study on features of social recommender systems},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A meta-heuristic proposal for inverse kinematics solution of
7-DOF serial robotic manipulator: Quantum behaved particle swarm
algorithm. <em>AIR</em>, <em>53</em>(2), 949–964. (<a
href="https://doi.org/10.1007/s10462-019-09683-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, a quantum behaved particle swarm algorithm has used for inverse kinematic solution of a 7-degree-of-freedom serial manipulator and the results have been compared with other swarm techniques such as firefly algorithm (FA), particle swarm optimization (PSO) and artificial bee colony (ABC). Firstly, the DH parameters of the robot manipulator are created and transformation matrices are revealed. Afterward, the position equations are derived from these matrices. The position of the end effector of the robotic manipulator in the work space is estimated using Quantum PSO and other swarm algorithms. For this reason, a fitness function which name is Euclidian has been determined. This function calculates the difference between the actual position and the estimated position of the manipulator end effector. In this study, the algorithms have tested with two different scenarios. In the first scenario, values for a single position were obtained while values for a hundred different positions were obtained in the second scenario. In fact, the second scenario confirms the quality of the QPSO in the inverse kinematic solution by verifying the first scenario. According to the results obtained; Quantum behaved PSO has yielded results that are much more efficient than standard PSO, ABC and FA. The advantages of the improved algorithm are the short computation time, fewer iterations and the number of particles.},
  archive      = {J_AIR},
  author       = {Dereli, Serkan and Köker, Raşit},
  doi          = {10.1007/s10462-019-09683-x},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {949-964},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A meta-heuristic proposal for inverse kinematics solution of 7-DOF serial robotic manipulator: Quantum behaved particle swarm algorithm},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A review of unsupervised feature selection methods.
<em>AIR</em>, <em>53</em>(2), 907–948. (<a
href="https://doi.org/10.1007/s10462-019-09682-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, unsupervised feature selection methods have raised considerable interest in many research areas; this is mainly due to their ability to identify and select relevant features without needing class label information. In this paper, we provide a comprehensive and structured review of the most relevant and recent unsupervised feature selection methods reported in the literature. We present a taxonomy of these methods and describe the main characteristics and the fundamental ideas they are based on. Additionally, we summarized the advantages and disadvantages of the general lines in which we have categorized the methods analyzed in this review. Moreover, an experimental comparison among the most representative methods of each approach is also presented. Finally, we discuss some important open challenges in this research area.},
  archive      = {J_AIR},
  author       = {Solorio-Fernández, Saúl and Carrasco-Ochoa, J. Ariel and Martínez-Trinidad, José Fco.},
  doi          = {10.1007/s10462-019-09682-y},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {907-948},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A review of unsupervised feature selection methods},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evaluating the websites of academic departments through SEO
criteria: A hesitant fuzzy linguistic MCDM approach. <em>AIR</em>,
<em>53</em>(2), 875–905. (<a
href="https://doi.org/10.1007/s10462-019-09681-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Search Engine Optimization (SEO) is the process of managing web content in a manner that elevates page rankings in search engines. Among other sectors, academic world is one of the number-one categories for search based on the percentage of web traffic generated through search engine referrals. However, SEO includes a number of factors grouped into two as ‘on page’ and ‘off page.’ To obtain maximum benefit from SEO, relevant factors/criteria should be considered using multi-criteria decision making (MCDM) methods. The focus of this paper is to consider SEO criteria evaluation as a MCDM problem in which the criteria are in different priority levels and the criteria values take the form of hesitant fuzzy linguistic term sets to facilitate the elicitation of information in hesitate situations. A three-step solution approach is developed: (i) determination of 21 SEO criteria, such as page loading time, page size and meta-keyword (ii) prioritizing the criteria using hesitant fuzzy analytic hierarchy process, and (iii) ranking 70 Turkish websites of the industrial engineering departments using Technique for Order Preference by Similarity to Ideal Solution. The results show that trust flow and XML sitemap are the determinant criteria among others. Using the proposed method, web designers can approach SEO from weighted criteria perspective.},
  archive      = {J_AIR},
  author       = {Özkan, Barış and Özceylan, Eren and Kabak, Mehmet and Dağdeviren, Metin},
  doi          = {10.1007/s10462-019-09681-z},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {875-905},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Evaluating the websites of academic departments through SEO criteria: A hesitant fuzzy linguistic MCDM approach},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Expert finding in community question answering: A review.
<em>AIR</em>, <em>53</em>(2), 843–874. (<a
href="https://doi.org/10.1007/s10462-018-09680-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of Community Question Answering (CQA) satisfies users’ quest for professional and personal knowledge about anything. In CQA, one central issue is to find users with expertise and willingness to answer the given questions. Expert finding in CQA often exhibits very different challenges compared to traditional methods. The new features of CQA (such as huge volume, sparse data and crowdsourcing) violate fundamental assumptions of traditional recommendation systems. This paper focuses on reviewing and categorizing the current progress on expert finding in CQA. We classify the recent solutions into four different categories: matrix factorization based models (MF-based models), gradient boosting tree based models (GBT-based models), deep learning based models (DL-based models) and ranking based models (R-based models). We find that MF-based models outperform other categories of models in the crowdsourcing situation. Moreover, we use innovative diagrams to clarify several important concepts of ensemble learning, and find that ensemble models with several specific single models can further boost the performance. Further, we compare the performance of different models on different types of matching tasks, including textvs.text, graphvs.text, audiovs.text and videovs.text. The results will help the model selection of expert finding in practice. Finally, we explore some potential future issues in expert finding research in CQA.},
  archive      = {J_AIR},
  author       = {Yuan, Sha and Zhang, Yu and Tang, Jie and Hall, Wendy and Cabotà, Juan Bautista},
  doi          = {10.1007/s10462-018-09680-6},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {843-874},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Expert finding in community question answering: A review},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Significance of processing chrominance information for scene
classification: A review. <em>AIR</em>, <em>53</em>(2), 811–842. (<a
href="https://doi.org/10.1007/s10462-018-09678-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The primary objective of this paper is to provide a detailed review of various works showing the role of processing chrominance information for color-to-grayscale conversion. The usefulness of perceptually improved color-to-grayscale converted images for scene classification is then studied as a part of this presented work. Various issues identified for the color-to-grayscale conversion and improved scene classification are presented in this paper. The review provided in this paper includes, review on existing feature extraction techniques for scene classification, various existing scene classification systems, different methods available in the literature for color-to-grayscale image conversion, benchmark datasets for scene classification and color-to-gray-scale image conversion, subjective evaluation and objective quality assessments for image decolorization. In the present work, a scene classification system is proposed using the pre-trained convolutional neural network and Support Vector Machines developed utilizing the grayscale images converted by the image decolorization methods. The experimental analysis on Oliva Torralba scene dataset shows that the color-to-grayscale image conversion technique has a positive impact on the performance of scene classification systems.},
  archive      = {J_AIR},
  author       = {Sowmya, V. and Govind, D. and Soman, K. P.},
  doi          = {10.1007/s10462-018-09678-0},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {811-842},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Significance of processing chrominance information for scene classification: A review},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). From ants to whales: Metaheuristics for all tastes.
<em>AIR</em>, <em>53</em>(1), 753–810. (<a
href="https://doi.org/10.1007/s10462-018-09676-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nature-inspired metaheuristics comprise a compelling family of optimization techniques. These algorithms are designed with the idea of emulating some kind natural phenomena (such as the theory of evolution, the collective behavior of groups of animals, the laws of physics or the behavior and lifestyle of human beings) and applying them to solve complex problems. Nature-inspired methods have taken the area of mathematical optimization by storm. Only in the last few years, literature related to the development of this kind of techniques and their applications has experienced an unprecedented increase, with hundreds of new papers being published every single year. In this paper, we analyze some of the most popular nature-inspired optimization methods currently reported on the literature, while also discussing their applications for solving real-world problems and their impact on the current literature. Furthermore, we open discussion on several research gaps and areas of opportunity that are yet to be explored within this promising area of science.},
  archive      = {J_AIR},
  author       = {Fausto, Fernando and Reyna-Orta, Adolfo and Cuevas, Erik and Andrade, Ángel G. and Perez-Cisneros, Marco},
  doi          = {10.1007/s10462-018-09676-2},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {753-810},
  shortjournal = {Artif. Intell. Rev.},
  title        = {From ants to whales: Metaheuristics for all tastes},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust multi-criteria decision making methodology for real
life logistics center location problem. <em>AIR</em>, <em>53</em>(1),
725–751. (<a href="https://doi.org/10.1007/s10462-019-09763-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A logistics center is the hub of a specific area, within various logistics-related activities (distribution, storage, transportation, consolidation, handling, customs clearance, imports, exports, transit processes, infrastructural services, insurance, banking, etc.) that are performed on a commercial basis. Determining the location of the logistics center is an important decision regarding cost and benefit analysis. A three-stage methodology has been applied for presenting a framework for logistics center location selection in the context of Kayseri’s logistics development plan. The first stage includes the determination of criteria through literature review and interviews with experts. The second stage includes the weighting of determined criteria using linear BWM (best–worst method). The third stage includes the ranking of locations using the evaluation based on distance from average solution (EDAS) method with different distance measures. Our proposed methodology BWM–EDAS and also EDAS with different distance measures, which are applied for the first time in the literature, provides helpful findings to rank the logistics center locations. Lastly, sensitivity analysis is conducted to validate the robustness.},
  archive      = {J_AIR},
  author       = {Özmen, Mihrimah and Aydoğan, Emel Kızılkaya},
  doi          = {10.1007/s10462-019-09763-y},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {725-751},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Robust multi-criteria decision making methodology for real life logistics center location problem},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Marketing campaign targeting using bridge extraction in
multiplex social network. <em>AIR</em>, <em>53</em>(1), 703–724. (<a
href="https://doi.org/10.1007/s10462-018-9675-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a methodology for improving the targeting of marketing campaigns using bridge prediction in communities based on the information of multilayer online social networks. The campaign strategy involves the identification of nodes with high brand loyalty and top-ranking nodes in terms of participation in bridges that will be involved in the evolution of the graph. Our approach is based on an efficient classification model combining topological characteristics of crawled social graphs with sentiment and linguistic traits of user-nodes, popularity in social media as well as meta path-based features of multilayer networks. To validate our approach we present a set of experimental results using a well-defined dataset from Twitter and Foursquare. Our methodology is useful to recommendation systems as well as to marketers who are interested to use social influence and run effective marketing campaigns.},
  archive      = {J_AIR},
  author       = {Vikatos, Pantelis and Gryllos, Prokopios and Makris, Christos},
  doi          = {10.1007/s10462-018-9675-6},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {703-724},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Marketing campaign targeting using bridge extraction in multiplex social network},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Covering-based intuitionistic fuzzy rough sets and
applications in multi-attribute decision-making. <em>AIR</em>,
<em>53</em>(1), 671–701. (<a
href="https://doi.org/10.1007/s10462-018-9674-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Covering based intuitionistic fuzzy (IF) rough set is a generalization of granular computing and covering based rough sets. By combining covering based rough sets, IF sets and fuzzy rough sets, we introduce three classes of coverings based IF rough set models via IF$$\beta $$-neighborhoods and IF complementary $$\beta $$-neighborhood (IFC$$\beta $$-neighborhood). The corresponding axiomatic systems are investigated, respectively. In particular, the rough and precision degrees of covering based IF rough set models are discussed. The relationships among these types of coverings based IF rough set models and covering based IF rough set models proposed by Huang et al. (Knowl Based Syst 107:155–178, 2016). Based on the theoretical analysis for coverings based IF rough set models, we put forward intuitionistic fuzzy TOPSIS (IF-TOPSIS) methodology to multi-attribute decision-making (MADM) problem with the evaluation of IF information problem. An effective example is to illustrate the proposed methodology. Finally, we deal with MADM problem with the evaluation of fuzzy information based on CFRS models. By comparative analysis, we find that it is more effective to deal with MADM problem with the evaluation of IF information based on CIFRS models than the one with the evaluation of fuzzy information based on CFRS models.},
  archive      = {J_AIR},
  author       = {Zhan, Jianming and Sun, Bingzhen},
  doi          = {10.1007/s10462-018-9674-7},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {671-701},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Covering-based intuitionistic fuzzy rough sets and applications in multi-attribute decision-making},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust visual line-following navigation system for humanoid
robots. <em>AIR</em>, <em>53</em>(1), 653–670. (<a
href="https://doi.org/10.1007/s10462-018-9672-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper implements a novel line-following system for humanoid robots. Camera embedded on the robot’s head captures the image and then extracts the line using a high-speed and high-accuracy rectangular search method. This method divides the search location into three sides of rectangle and performs image convolution by edge detection matrix. The extracted line is used to calculate relative parameters, including forward velocity, lateral velocity and angular velocity that drive line-following walking. A proposed path curvature estimation method generates the forward velocity and guidance reference point of the robot. A classical PID controller and a PID controller with angle compensation are then used to set the lateral velocity and angular velocity of the robot, improving the performance in tracking a curved line. Line-following experiments for various shapes were conducted using humanoid robot NAO. Experimental results demonstrate the robot can follow different line shapes with the tracking error remaining at a low level. This is a significant improvement from existing biped robot visual navigation systems.},
  archive      = {J_AIR},
  author       = {Juang, Li-Hong and Zhang, Jian-Sen},
  doi          = {10.1007/s10462-018-9672-9},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {653-670},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Robust visual line-following navigation system for humanoid robots},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Detecting anomalies in sequential data augmented with new
features. <em>AIR</em>, <em>53</em>(1), 625–652. (<a
href="https://doi.org/10.1007/s10462-018-9671-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new weighted local outlier factor method for anomaly detection, which is underpinned with three novel components: (1) a piecewise linear representation defined on the basis of the important points that consist of extreme points and additional points; (2) a set of new features which are used to identify anomalies given the new piecewise linear representation; (3) a weighting schema, assigning different weights to different features by accounting for the discriminant power of the features. The underlying idea of the proposed method is to characterize a time series with a set of four features and then discover abnormal changes by taking account of the closeness of any data points augmented with the new features. The comparative experiments demonstrate that the proposed piecewise representation method has performed well in sequential time series data, and the weighted local outlier factor method has achieved better accuracy and RankPower in detecting anomalies from the same data sets in comparison with the conventional local outlier factor, normalized local outlier factor and HOT symbolic aggregate approximation methods.},
  archive      = {J_AIR},
  author       = {Kong, Xiangzeng and Bi, Yaxin and Glass, David H.},
  doi          = {10.1007/s10462-018-9671-x},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {625-652},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Detecting anomalies in sequential data augmented with new features},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel exponential distance and its based TOPSIS method for
interval-valued intuitionistic fuzzy sets using connection number of SPA
theory. <em>AIR</em>, <em>53</em>(1), 595–624. (<a
href="https://doi.org/10.1007/s10462-018-9668-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of this work is to present a novel multi-attribute decision making (MADM) method under interval-valued intuitionistic fuzzy (IVIF) set environment by integrating a Technique for Order Preference by Similarity to Ideal Solution (TOPSIS) method. Set pair analysis (SPA) theory is the modern uncertainty theory which is composed by the three components, namely “identity”, “discrepancy” and “contrary” degrees of the connection number (CN) and overlap with the various existing theories for handling the uncertainties in the data. Thus, motivated by this, in the present work, an attempt is made to enrich the theory of information measure by presented some exponential based distance measures using CNs of the IVIF sets. The supremacy of the proposed measure is also discussed. Afterward, a TOPSIS method based on the proposed distance measures is developed to solve MADM problem under IVIF environment where each of the element is characteristics by IVIF numbers. The utility, as well as supremacy of the approach, is confirmed through a real-life numerical example and validate it by comparing their results with the several existing approaches results.},
  archive      = {J_AIR},
  author       = {Garg, Harish and Kumar, Kamal},
  doi          = {10.1007/s10462-018-9668-5},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {595-624},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A novel exponential distance and its based TOPSIS method for interval-valued intuitionistic fuzzy sets using connection number of SPA theory},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A state of the art review of intelligent scheduling.
<em>AIR</em>, <em>53</em>(1), 501–593. (<a
href="https://doi.org/10.1007/s10462-018-9667-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent scheduling covers various tools and techniques for successfully and efficiently solving the scheduling problems. In this paper, we provide a survey of intelligent scheduling systems by categorizing them into five major techniques containing fuzzy logic, expert systems, machine learning, stochastic local search optimization algorithms and constraint programming. We also review the application case studies of these techniques.},
  archive      = {J_AIR},
  author       = {Fazel Zarandi, Mohammad Hossein and Sadat Asl, Ali Akbar and Sotudian, Shahabeddin and Castillo, Oscar},
  doi          = {10.1007/s10462-018-9667-6},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {501-593},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A state of the art review of intelligent scheduling},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Independence test and canonical correlation analysis based
on the alignment between kernel matrices for multivariate functional
data. <em>AIR</em>, <em>53</em>(1), 475–499. (<a
href="https://doi.org/10.1007/s10462-018-9666-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the case of vector data, Gretton et al. (Algorithmic learning theory. Springer, Berlin, pp 63–77, 2005) defined Hilbert–Schmidt independence criterion, and next Cortes et al. (J Mach Learn Res 13:795–828, 2012) introduced concept of the centered kernel target alignment (KTA). In this paper we generalize these measures of dependence to the case of multivariate functional data. In addition, based on these measures between two kernel matrices (we use the Gaussian kernel), we constructed independence test and nonlinear canonical variables for multivariate functional data. We show that it is enough to work only on the coefficients of a series expansion of the underlying processes. In order to provide a comprehensive comparison, we conducted a set of experiments, testing effectiveness on two real examples and artificial data. Our experiments show that using functional variants of the proposed measures, we obtain much better results in recognizing nonlinear dependence.},
  archive      = {J_AIR},
  author       = {Górecki, Tomasz and Krzyśko, Mirosław and Wołyński, Waldemar},
  doi          = {10.1007/s10462-018-9666-7},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {475-499},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Independence test and canonical correlation analysis based on the alignment between kernel matrices for multivariate functional data},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Reflective agents for personalisation in collaborative
games. <em>AIR</em>, <em>53</em>(1), 429–474. (<a
href="https://doi.org/10.1007/s10462-018-9665-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The collaborative aspect of games has been shown to potentially increase player performance and engagement over time. However, collaborating players need to perform well for the team as a whole to benefit and thus teams often end up performing no better than a strong player would have performed individually. Personalisation offers a means for improving overall performance and engagement, but in collaborative games, personalisation is seldom implemented, and when it is, it is overwhelmingly passive such that the player is not guided to goal states and the effectiveness of the personalisation is not evaluated and adapted accordingly. In this paper, we propose and apply the use of reflective agents to personalisation (‘reflective personalisation’) in collaborative gaming for individual players within collaborative teams via a combination of individual player and team profiling in order to improve player and thus team performance and engagement. The reflective agents self-evaluate, dynamically adapting their personalisation techniques to most effectively guide players towards specific goal states, match players and form teams. We incorporate this agent-based approach within a microservices architecture, which itself is a set of collaborating services, to facilitate a scalable and portable approach that enables both player and team profiles to persist across multiple games. An experiment involving 90 players over a two-month period was used to comparatively assess three versions of a collaborative game that implemented reflective, guided, and passive personalisation for individual players within teams. Our results suggest that the proposed reflective personalisation approach improves team player performance and engagement within collaborative games over guided or passive personalisation approaches, but that it is especially effective for improving engagement.},
  archive      = {J_AIR},
  author       = {Daylamani-Zad, Damon and Agius, Harry and Angelides, Marios C.},
  doi          = {10.1007/s10462-018-9665-8},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {429-474},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Reflective agents for personalisation in collaborative games},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Exploring the influential reviewer, review and product
determinants for review helpfulness. <em>AIR</em>, <em>53</em>(1),
407–427. (<a href="https://doi.org/10.1007/s10462-018-9662-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Helpfulness of online reviews is a multi-faceted concept. The reviews are usually ranked on the basis of perceived helpful votes and aid in making purchase decisions for online customers. This study extends the prior work done for review helpfulness by considering not only the influential characteristics of reviews but also incorporates influential indicators of reviewer and product category. Influential factor based new features (product, reviewer and review) are proposed to predict the helpfulness of online reviews by using five ML methods. The experimental analysis on a real-life review dataset shows that the hybrid set of proposed features deliver the best predictive performance. In addition, the reviewer and the review category features introduced in this research exhibit better predictive performance as a standalone model. Findings show that reviews which have large number of comments, large values of sentiment and polarity scores receive more helpful votes. The reviewer activity length and recency are statistically significant predictors for helpfulness prediction. In addition, number of question answered, ratio of positive reviews and average rating per review are also significant variables of product type. The findings of this study highlight the number of implications for research and provide new insights to retailers for efficient ranking and organization of consumer reviews for online users.},
  archive      = {J_AIR},
  author       = {Malik, M. S. I. and Hussain, Ayyaz},
  doi          = {10.1007/s10462-018-9662-y},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {407-427},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Exploring the influential reviewer, review and product determinants for review helpfulness},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Knowledge discovery and visualization in antimicrobial
resistance surveillance systems: A scoping review. <em>AIR</em>,
<em>53</em>(1), 369–406. (<a
href="https://doi.org/10.1007/s10462-018-9659-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identify the application of computational methods and algorithms reported in the literature based on four main categories including data mining, clinical decision support systems, geographical information systems, and digital dashboards and to summarize them in a qualitative scoping review. A scoping review was presented following Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines. MEDLINE, Emerald, Scopus, and Google Scholar databases were searched in July 2016 using uniform keywords for documents that discuss data mining and knowledge discovery, dashboards, geographical information systems, and electronic surveillance of antimicrobial resistance in surveillance systems. Our study mainly focused on knowledge discovery and visualization algorithms, methods, and techniques used in antimicrobial resistance surveillance systems. Thirteen of the reviewed articles applied algorithms to the data mining process. A comparative table of data elements in the reviewed studies was extracted. The characteristics of antimicrobial dashboards were discussed. Heat maps were the most popular method used to visualize the intensity of resistance. Comparative tables are provided in each section of this paper. Data mining, Decision Support Systems, Geographic Information Systems, and dashboards can be integrated for data analysis and to better solve decision support problems. Bio-surveillance systems should be designed and analyzed based on four categories: data mining, dashboards, geography information system, and decision support modules. Furthermore, some questionnaires and checklists were developed and validated to capture related Business Intelligence and analytical requirements. Future studies should focus on developing fast, flexible, and accurate computational bio-surveillance systems by appropriate selecting and applying the considered methods and algorithms.},
  archive      = {J_AIR},
  author       = {Safdari, Reza and GhaziSaeedi, Marjan and Masoumi-Asl, Hossein and Rezaei-Hachesu, Peyman and Mirnia, Kayvan and Samad-Soltani, Taha},
  doi          = {10.1007/s10462-018-9659-6},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {369-406},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Knowledge discovery and visualization in antimicrobial resistance surveillance systems: A scoping review},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Real-time control of ball balancer using neural integrated
fuzzy controller. <em>AIR</em>, <em>53</em>(1), 351–368. (<a
href="https://doi.org/10.1007/s10462-018-9658-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the design, control, and validation of two degrees of freedom Ball Balancer system. The ball and plate system is a nonlinear, electromechanical, multivariable, closed-loop unstable system on which study is carried out to control the position of ball and plate angle. The model of the system is developed using MATLAB/Simulink, and neural integrated fuzzy and its hybridization with PID have been implemented. The performance of each controller is evaluated in terms of time response analysis and steady-state error. Comparative study of simulation and real-time control results show that by using the neural integrated fuzzy controller and neural integrated fuzzy with proportional-integral-derivative Controller, the peak overshoot is reduced as compared with the PID controller and lead the system prone to appropriate balancing. These control techniques provide a stable and controlled output to the system for ball balancing and plate angle control.},
  archive      = {J_AIR},
  author       = {Singh, Rupam and Bhushan, Bharat},
  doi          = {10.1007/s10462-018-9658-7},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {351-368},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Real-time control of ball balancer using neural integrated fuzzy controller},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Real-world diffusion dynamics based on point process
approaches: A review. <em>AIR</em>, <em>53</em>(1), 321–350. (<a
href="https://doi.org/10.1007/s10462-018-9656-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bursts in human and natural activities are highly clustered in time or space, suggesting that these activities are influenced by previous events within the social or natural system. Such bursty behavior in the real world conveys substantial information of underlying diffusion processes, which have been studied based on point process approaches in diverse scientific communities from online social media to criminology and epidemiology. However, universal components of real-world diffusion dynamics that cut across disciplines remain unexplored with a common overarching perspective. In this review, we introduce a wide range of diffusion processes from diverse research fields, define a taxonomy of common major factors in diffusion dynamics, interpret their diffusion models from the theoretical perspectives of point processes, and compare them with respect to universal effects on diffusion. These all can provide new insights on spatial and temporal bursty events capturing underlying diffusion dynamics. We expect that the comprehensive aspects of diffusion dynamics in the real world can motivate transdisciplinary research and provide contextual components of a fundamental framework for more generalizable diffusion models.},
  archive      = {J_AIR},
  author       = {Kim, Minkyoung and Paini, Dean and Jurdak, Raja},
  doi          = {10.1007/s10462-018-9656-9},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {321-350},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Real-world diffusion dynamics based on point process approaches: A review},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Shilling attacks against collaborative recommender systems:
A review. <em>AIR</em>, <em>53</em>(1), 291–319. (<a
href="https://doi.org/10.1007/s10462-018-9655-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative filtering recommender systems (CFRSs) have already been proved effective to cope with the information overload problem since they merged in the past two decades. However, CFRSs are highly vulnerable to shilling or profile injection attacks since their openness. Ratings injected by malicious users seriously affect the authenticity of the recommendations as well as users’ trustiness in the recommendation systems. In the past two decades, various studies have been conducted to scrutinize different profile injection attack strategies, shilling attack detection schemes, robust recommendation algorithms, and to evaluate them with respect to accuracy and robustness. Due to their popularity and importance, we survey about shilling attacks in CFRSs. We first briefly discuss the related survey papers about shilling attacks and analyze their deficiencies to illustrate the necessity of this paper. Next we give an overall picture about various shilling attack types and their deployment modes. Then we explain profile injection attack strategies, shilling attack detection schemes and robust recommendation algorithms proposed so far in detail. Moreover, we briefly explain evaluation metrics of the proposed schemes. Last, we discuss some research directions to improve shilling attack detection rates robustness of collaborative recommendation, and conclude this paper.},
  archive      = {J_AIR},
  author       = {Si, Mingdan and Li, Qingshan},
  doi          = {10.1007/s10462-018-9655-x},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {291-319},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Shilling attacks against collaborative recommender systems: A review},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Towards the use of fuzzy logic systems in rotary wing
unmanned aerial vehicle: A review. <em>AIR</em>, <em>53</em>(1),
257–290. (<a href="https://doi.org/10.1007/s10462-018-9653-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent times, technological advancement boosts the desire of utilizing the autonomous Unmanned Aerial Vehicle (UAV) in both civil and military sectors. Among various UAVs, the ability of rotary wing UAVs (RUAVs) in vertical take-off and landing, to hover and perform quick maneuvering attract researchers to develop models fully autonomous control framework. The majority of first principle techniques in modeling and controlling RUAV face challenges in incorporating and handling various uncertainties. Recently various fuzzy and neuro-fuzzy based intelligent systems are utilized to enhance the RUAV’s modeling and control performance. However, the majority of these fuzzy systems are based on batch learning methods, have static structure, and cannot adapt to rapidly changing environments. The implication of Evolving Intelligent System based model-free data-driven techniques can be a smart option since they can adapt their structure and parameters to cope with sudden changes in the behavior of RUAVs real-time flight. They work in a single pass learning fashion which is suitable for online real-time deployment. In this paper, state of the art of various fuzzy systems from the basic fuzzy system to evolving fuzzy system, their application in a RUAV namely quadcopter with existing limitations, and possible opportunities are analyzed. Besides, a variety of first principle techniques to control the quadcopter, their impediments, and conceivable solution with recently employed evolving fuzzy controllers are reviewed.},
  archive      = {J_AIR},
  author       = {Ferdaus, Md Meftahul and Anavatti, Sreenatha G. and Pratama, Mahardhika and Garratt, Matthew A.},
  doi          = {10.1007/s10462-018-9653-z},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {257-290},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Towards the use of fuzzy logic systems in rotary wing unmanned aerial vehicle: A review},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A bibliometric analysis of neutrosophic set: Two decades
review from 1998 to 2017. <em>AIR</em>, <em>53</em>(1), 199–255. (<a
href="https://doi.org/10.1007/s10462-018-9652-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neutrosophic set, initiated by Smarandache, is a novel tool to deal with vagueness considering the truth-membership T, indeterminacy-membership I and falsity-membership F satisfying the condition $$0\le T+I+F\le 3$$. It can be used to characterize the uncertain information more sufficiently and accurately than intuitionistic fuzzy set. Neutrosophic set has attracted great attention of many scholars that have been extended to new types and these extensions have been used in many areas such as aggregation operators, decision making, image processing, information measures, graph and algebraic structures. Because of such a growth, we present an overview on neutrosophic set with the aim of offering a clear perspective on the different concepts, tools and trends related to their extensions. A total of 137 neutrosophic set publication records from Web of Science are analyzed. Many interesting results with regard to the annual trends, the top players in terms of country level as well as institutional level, the publishing journals, the highly cited papers, and the research landscape are yielded and explained in-depth. The results indicate that some developing economics (such as China, India, Turkey) are quite active in neutrosophic set research. Moreover, the co-authorship analysis of the country and institution, the co-citation analysis of the journal, reference and author, and the co-occurrence analysis of the keywords are presented by VOSviewer software.},
  archive      = {J_AIR},
  author       = {Peng, Xindong and Dai, Jingguo},
  doi          = {10.1007/s10462-018-9652-0},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {199-255},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A bibliometric analysis of neutrosophic set: Two decades review from 1998 to 2017},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Two types of coverings based multigranulation rough fuzzy
sets and applications to decision making. <em>AIR</em>, <em>53</em>(1),
167–198. (<a href="https://doi.org/10.1007/s10462-018-9649-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Covering based multigranulation rough fuzzy set, as a generalization of granular computing and covering based rough fuzzy set theory, is a vital tool for dealing with the vagueness and multigranularity in artificial intelligence and management sciences. By means of neighborhoods, we introduce two types of coverings based (optimistic, pessimistic and variable precision) multigranulation rough fuzzy set models, respectively. Some axiomatic systems are also obtained. The relationships between two types of coverings based (optimistic, pessimistic and variable precision) multigranulation rough fuzzy set models are established. Based on the theoretical discussion for the covering based multigranulation rough fuzzy set models, we present an approach to multiple criteria group decision making problem. These two types of basic models and the procedure of decision making methods as well as the algorithm for the new approach are given in detail. By comparative analysis, the ranking results based on two different models have a highly consensus. Although there exist some different ranking results on these two methods, the optimal selected alternative is the same.},
  archive      = {J_AIR},
  author       = {Zhan, Jianming and Xu, Weihua},
  doi          = {10.1007/s10462-018-9649-8},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {167-198},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Two types of coverings based multigranulation rough fuzzy sets and applications to decision making},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A review on intelligent process for smart home applications
based on IoT: Coherent taxonomy, motivation, open challenges, and
recommendations. <em>AIR</em>, <em>53</em>(1), 141–165. (<a
href="https://doi.org/10.1007/s10462-018-9648-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Innovative technology on intelligent processes for smart home applications that utilize Internet of Things (IoT) is mainly limited and dispersed. The available trends and gaps were investigated in this study to provide valued visions for technical environments and researchers. Thus, a survey was conducted to create a coherent taxonomy on the research landscape. An extensive search was conducted for articles on (a) smart homes, (b) IoT and (c) applications. Three databases, namely, IEEE Explore, ScienceDirect and Web of Science, were used in the article search. These databases comprised comprehensive literature that concentrate on IoT-based smart home applications. Subsequently, filtering process was achieved on the basis of intelligent processes. The final classification scheme outcome of the dataset contained 40 articles that were classified into four classes. The first class includes the knowledge engineering process that examines data representation to identify the means of accomplishing a task for IoT applications and their utilisation in smart homes. The second class includes papers on the detection process that uses artificial intelligence (AI) techniques to capture the possible changes in IoT-based smart home applications. The third class comprises the analytical process that refers to the use of AI techniques to understand the underlying problems in smart homes by inferring new knowledge and suggesting appropriate solutions for the problem. The fourth class comprises the control process that describes the process of measuring and instructing the performance of IoT-based smart home applications against the specifications with the involvement of intelligent techniques. The basic features of this evolving approach were then identified in the aspects of motivation of intelligent process utilisation for IoT-based smart home applications and open-issue restriction utilisation. The recommendations for the approval and utilisation of intelligent process for IoT-based smart home applications were also determined from the literature.},
  archive      = {J_AIR},
  author       = {Zaidan, A. A. and Zaidan, B. B.},
  doi          = {10.1007/s10462-018-9648-9},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {141-165},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A review on intelligent process for smart home applications based on IoT: Coherent taxonomy, motivation, open challenges, and recommendations},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Social book search: A survey. <em>AIR</em>, <em>53</em>(1),
95–139. (<a href="https://doi.org/10.1007/s10462-018-9647-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social Book Search is a new area of social search. In the modern world everything is going to be amenable due to the web and social media. The web and social media give us access to a wealth of information, not only different in quantity but also in character. Traditional descriptions from professionals are now supplemented with user generated content. Although books have been the predominant source of information for centuries, the way we acquire, share, and publish information has changed and has been changing in fundamental ways due to the web. In the modern era, in order to purchase a book, the users are not only depend on the title, author name, publisher etc of the book available as controlled metadata but also on other aspects which include the reviews, editorial reviews etc available in different social media. Our primary focus in this survey is to describe the features of different social cataloging book sites as well as their recommendation based on books. How the online searching of books is useful to the user and up to what extent, and what are their aim are some of the issues we shall deal with. We will also discuss evolution of those techniques for Social Book Search presented over years at the Initiative for the Evaluation of XML Retrieval (INEX) and Conference and Labs of the Evaluation Forum (CLEF). To what extent the features and functionality of a social sharing platform influence the user behavior, is also discussed in the paper. This survey provides an overview of research done in the area of Social Book Search from perspective of Information Retrieval.},
  archive      = {J_AIR},
  author       = {Kumar, Ritesh and Pamula, Rajendra},
  doi          = {10.1007/s10462-018-9647-x},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {95-139},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Social book search: A survey},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). 40 years of cognitive architectures: Core cognitive
abilities and practical applications. <em>AIR</em>, <em>53</em>(1),
17–94. (<a href="https://doi.org/10.1007/s10462-018-9646-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we present a broad overview of the last 40 years of research on cognitive architectures. To date, the number of existing architectures has reached several hundred, but most of the existing surveys do not reflect this growth and instead focus on a handful of well-established architectures. In this survey we aim to provide a more inclusive and high-level overview of the research on cognitive architectures. Our final set of 84 architectures includes 49 that are still actively developed, and borrow from a diverse set of disciplines, spanning areas from psychoanalysis to neuroscience. To keep the length of this paper within reasonable limits we discuss only the core cognitive abilities, such as perception, attention mechanisms, action selection, memory, learning, reasoning and metareasoning. In order to assess the breadth of practical applications of cognitive architectures we present information on over 900 practical projects implemented using the cognitive architectures in our list. We use various visualization techniques to highlight the overall trends in the development of the field. In addition to summarizing the current state-of-the-art in the cognitive architecture research, this survey describes a variety of methods and ideas that have been tried and their relative success in modeling human cognitive abilities, as well as which aspects of cognitive behavior need more research with respect to their mechanistic counterparts and thus can further inform how cognitive science might progress.},
  archive      = {J_AIR},
  author       = {Kotseruba, Iuliia and Tsotsos, John K.},
  doi          = {10.1007/s10462-018-9646-y},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {17-94},
  shortjournal = {Artif. Intell. Rev.},
  title        = {40 years of cognitive architectures: Core cognitive abilities and practical applications},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improving search engine optimization (SEO) by using hybrid
modified MCDM models. <em>AIR</em>, <em>53</em>(1), 1–16. (<a
href="https://doi.org/10.1007/s10462-018-9644-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Search engine optimization (SEO) has been considered one of the most important techniques in internet marketing. This study establishes a decision model of search engine ranking for administrators to improve the performances of websites that satisfy users’ needs. To probe into the interrelationship and influential weights among criteria of SEO and evaluate the gaps of performance to achieve the aspiration level in real world, this research utilizes hybrid modified multiple criteria decision-making models, including decision-making trial and evaluation laboratory (DEMATEL), DEMATEL-based analytic network process (called DANP), and VlseKriterijumska Optimizacija I Kompromisno Resenje (VIKOR). The empirical findings discover that the criteria of SEO possessed a self-effect relationship based on DEMATEL technique. According to the influential network relation map (INRM), external website optimization is the top priority dimension that needs to be improved when implementing SEO. Among the six criteria for evaluation, meta tags is the most significant criterion influencing search engine ranking, followed by keywords and website design. The evaluation of search engine ranking reveals that the website with lowest gap would be the optimal example for administrators of websites to make high ranking website during the time that this study is executed.},
  archive      = {J_AIR},
  author       = {Tsuei, Hung-Jia and Tsai, Wei-Ho and Pan, Fu-Te and Tzeng, Gwo-Hshiung},
  doi          = {10.1007/s10462-018-9644-0},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Improving search engine optimization (SEO) by using hybrid modified MCDM models},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
