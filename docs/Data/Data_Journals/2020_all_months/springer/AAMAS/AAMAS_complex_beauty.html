<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AAMAS_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="aamas---56">AAMAS - 56</h2>
<ul>
<li><details>
<summary>
(2020b). Correction to: Control in the presence of manipulators:
Cooperative and competitive cases. <em>AAMAS</em>, <em>34</em>(2), 1.
(<a href="https://doi.org/10.1007/s10458-020-09482-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unfortunately, a post-galley copyediting error altered the contents of cells in the Condorcet Elections columns of the table in Footnote 7.},
  archive      = {J_AAMAS},
  author       = {Fitzsimmons, Zack and Hemaspaandra, Edith and Hemaspaandra, Lane A.},
  doi          = {10.1007/s10458-020-09482-7},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Correction to: control in the presence of manipulators: cooperative and competitive cases},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Personalised rating. <em>AAMAS</em>, <em>34</em>(2), 1–38.
(<a href="https://doi.org/10.1007/s10458-020-09479-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce personalised rating, a network-based rating system where individuals, connected in a social network, decide whether or not to consume a service (e.g., a restaurant) based on the evaluations provided by their peers. We compare personalised rating with the more widely used objective rating where, instead, customers receive an aggregate evaluation of what everybody else has declared so far. We focus on the manipulability of such systems, allowing a malicious service provider (e.g., the restaurant owner) to transfer monetary incentive to the individuals in order to manipulate their rating and increase the overall profit. We study manipulation under various constraints, such as the proportion of individuals who evaluate the service and, in particular, how much the attacker knows of the underlying customers’ network, showing the conditions under which the system is bribery-proof, i.e., no manipulation strategy yields a strictly positive expected gain to the service provider. We also look at manipulation strategies that are feasible in theory but might, in general, be infeasible in practice, deriving a number of algorithmic properties of manipulation under personalised rating. In particular we show that establishing the existence of a rewarding manipulation strategy for the attacker—and, notably, an optimal one—is NP-complete, even with full knowledge of the underlying network structure.},
  archive      = {J_AAMAS},
  author       = {Grandi, Umberto and Stewart, James and Turrini, Paolo},
  doi          = {10.1007/s10458-020-09479-2},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-38},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Personalised rating},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Interactive task learning via embodied corrective feedback.
<em>AAMAS</em>, <em>34</em>(2), 1–45. (<a
href="https://doi.org/10.1007/s10458-020-09481-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses a task in Interactive Task Learning (Laird et al. IEEE Intell Syst 32:6–21, 2017). The agent must learn to build towers which are constrained by rules, and whenever the agent performs an action which violates a rule the teacher provides verbal corrective feedback: e.g. “No, red blocks should be on blue blocks”. The agent must learn to build rule compliant towers from these corrections and the context in which they were given. The agent is not only ignorant of the rules at the start of the learning process, but it also has a deficient domain model, which lacks the concepts in which the rules are expressed. Therefore an agent that takes advantage of the linguistic evidence must learn the denotations of neologisms and adapt its conceptualisation of the planning domain to incorporate those denotations. We show that by incorporating constraints on interpretation that are imposed by discourse coherence into the models for learning (Hobbs in On the coherence and structure of discourse, Stanford University, Stanford, 1985; Asher et al. in Logics of conversation, Cambridge University Press, Cambridge, 2003), an agent which utilizes linguistic evidence outperforms a strong baseline which does not.},
  archive      = {J_AAMAS},
  author       = {Appelgren, Mattias and Lascarides, Alex},
  doi          = {10.1007/s10458-020-09481-8},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-45},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Interactive task learning via embodied corrective feedback},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stable roommates with narcissistic, single-peaked, and
single-crossing preferences. <em>AAMAS</em>, <em>34</em>(2), 1–29. (<a
href="https://doi.org/10.1007/s10458-020-09470-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classical Stable Roommates problem is to decide whether there exists a matching of an even number of agents such that no two agents which are not matched to each other would prefer to be with each other rather than with their respectively assigned partners. We investigate Stable Roommates with complete (i.e., every agent can be matched with any other agent) or incomplete preferences, with ties (i.e., two agents are considered of equal value to some agent) or without ties. It is known that in general allowing ties makes the problem NP-complete. We provide algorithms for Stable Roommates that are, compared to those in the literature, more efficient when the input preferences are complete and have some structural property, such as being narcissistic, single-peaked, and single-crossing. However, when the preferences are incomplete and have ties, we show that being single-peaked and single-crossing does not reduce the computational complexity—Stable Roommates remains NP-complete.},
  archive      = {J_AAMAS},
  author       = {Bredereck, Robert and Chen, Jiehua and Finnendahl, Ugo Paavo and Niedermeier, Rolf},
  doi          = {10.1007/s10458-020-09470-x},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-29},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Stable roommates with narcissistic, single-peaked, and single-crossing preferences},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Picky losers and carefree winners prevail in collective risk
dilemmas with partner selection. <em>AAMAS</em>, <em>34</em>(2), 1–29.
(<a href="https://doi.org/10.1007/s10458-020-09463-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding how to design agents that sustain cooperation in multi-agent systems has been a long-lasting goal in distributed artificial intelligence. Proposed solutions rely on identifying free-riders and avoiding cooperating or interacting with them. These mechanisms of social control are traditionally studied in games with linear and deterministic payoffs, such as the prisoner’s dilemma or the public goods game. In reality, however, agents often face dilemmas in which payoffs are uncertain and non-linear, as collective success requires a minimum number of cooperators. The collective risk dilemma (CRD) is one of these games, and it is unclear whether the known mechanisms of cooperation remain effective in this case. Here we study the emergence of cooperation in CRD through partner-based selection. First, we discuss an experiment in which groups of humans and robots play a CRD. This experiment suggests that people only prefer cooperative partners when they lose a previous game (i.e., when collective success was not previously achieved). Secondly, we develop an evolutionary game theoretical model pointing out the evolutionary advantages of preferring cooperative partners only when a previous game was lost. We show that this strategy constitutes a favorable balance between strictness (only interact with cooperators) and softness (cooperate and interact with everyone), thus suggesting a new way of designing agents that promote cooperation in CRD. We confirm these theoretical results through computer simulations considering a more complex strategy space. Third, resorting to online human–agent experiments, we observe that participants are more likely to accept playing in a group with one defector when they won in a previous CRD, when compared to participants that lost the game. These empirical results provide additional support to the human predisposition to use outcome-based partner selection strategies in human–agent interactions.},
  archive      = {J_AAMAS},
  author       = {Santos, Fernando P. and Mascarenhas, Samuel and Santos, Francisco C. and Correia, Filipa and Gomes, Samuel and Paiva, Ana},
  doi          = {10.1007/s10458-020-09463-w},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-29},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Picky losers and carefree winners prevail in collective risk dilemmas with partner selection},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Control in the presence of manipulators: Cooperative and
competitive cases. <em>AAMAS</em>, <em>34</em>(2), 1–32. (<a
href="https://doi.org/10.1007/s10458-020-09475-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Control and manipulation are two of the most studied types of attacks on elections. In this paper, we study the complexity of control attacks on elections in which there are manipulators. We study both the case where the “chair” who is seeking to control the election is allied with the manipulators, and the case where the manipulators seek to thwart the chair. In the latter case, we see that the order of play substantially influences the complexity. We prove upper bounds, holding over every election system with a polynomial-time winner problem, for all standard control cases, and some of these bounds are at the second or third level of the polynomial hierarchy, and we provide matching lower bounds to prove these tight. Nonetheless, for important natural systems the complexity can be much lower. We prove that for approval and plurality elections, the complexity of even competitive clashes between a controller and manipulators falls far below those high bounds, even as low as polynomial time. Yet for a Borda-voting case we show that such clashes raise the complexity unless NP = coNP.},
  archive      = {J_AAMAS},
  author       = {Fitzsimmons, Zack and Hemaspaandra, Edith and Hemaspaandra, Lane A.},
  doi          = {10.1007/s10458-020-09475-6},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-32},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Control in the presence of manipulators: Cooperative and competitive cases},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Object reachability via swaps under strict and weak
preferences. <em>AAMAS</em>, <em>34</em>(2), 1–33. (<a
href="https://doi.org/10.1007/s10458-020-09477-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Housing Market problem is a widely studied resource allocation problem. In this problem, each agent can only receive a single object and has preferences over all objects. Starting from an initial endowment, we want to reach a certain assignment via a sequence of rational trades. We first consider whether an object is reachable for a given agent under a social network, where a trade between two agents is allowed if they are neighbors in the network and no participant has a deficit from the trade. Assume that the preferences of the agents are strict (no tie among objects is allowed). This problem is polynomial-time solvable in a star-network and NP-complete in a tree-network. It is left as a challenging open problem whether the problem is polynomial-time solvable when the network is a path. We answer this open problem positively by giving a polynomial-time algorithm. Then we show that when the preferences of the agents are weak (ties among objects are allowed), the problem becomes NP-hard when the network is a path and can be solved in polynomial time when the network is a star. Besides, we consider the computational complexity of finding different optimal assignments for the problem in the special case where the network is a path or a star.},
  archive      = {J_AAMAS},
  author       = {Huang, Sen and Xiao, Mingyu},
  doi          = {10.1007/s10458-020-09477-4},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-33},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Object reachability via swaps under strict and weak preferences},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A hybrid tree-based algorithm to solve asymmetric
distributed constraint optimization problems. <em>AAMAS</em>,
<em>34</em>(2), 1–42. (<a
href="https://doi.org/10.1007/s10458-020-09476-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Asymmetric distributed constraint optimization problems (ADCOPs) have emerged as an important formalism in multi-agent community due to their ability to capture personal preferences. However, the existing search-based complete algorithms for ADCOPs only exploit local knowledge to calculate lower bounds, which leads to inefficient pruning and prohibits them from solving large scale problems. On the other hand, inference-based complete algorithms (e.g., DPOP) for distributed constraint optimization problems are able to aggregate the global cost promptly but cannot be directly applied into ADCOPs due to a privacy concern. Thus, in this paper, we investigate the possibility of combining inference and search to effectively solve ADCOPs at an acceptable loss of privacy. Specifically, we propose a hybrid complete ADCOP algorithm called PT-ISABB which uses a tailored inference algorithm to provide tight lower bounds and upper bounds, and a tree-based complete search algorithm to guarantee the optimality. Furthermore, we introduce two suboptimal variants of PT-ISABB based on bounded-error approximation mechanisms to enable trade-off between theoretically guaranteed solutions and coordination overheads. We prove the correctness of PT-ISABB and its suboptimal variants. Finally, the experimental results demonstrate that PT-ISABB exhibits great superiorities over other state-of-the-art search-based complete algorithms and its suboptimal variants can quickly find a solution within the user-specified bounded-error.},
  archive      = {J_AAMAS},
  author       = {Chen, Dingding and Deng, Yanchen and Chen, Ziyu and He, Zhongshi and Zhang, Wenxin},
  doi          = {10.1007/s10458-020-09476-5},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-42},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {A hybrid tree-based algorithm to solve asymmetric distributed constraint optimization problems},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Strategic facility location problems with linear
single-dipped and single-peaked preferences. <em>AAMAS</em>,
<em>34</em>(2), 1–47. (<a
href="https://doi.org/10.1007/s10458-020-09472-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the design of mechanisms for locating facilities on an interval. There are multiple agents on the interval, each receiving a utility determined by their distances to the facilities. The objectives considered are maximization of social welfare (sum of utilities) and egalitarian welfare (minimum utility). Agents can misreport their locations, and so we require the mechanisms to be strategyproof—no agent should be able to benefit from misreporting; subject to strategyproofness, we attempt to design mechanisms that are approximately optimal (have small worst-case approximation ratios). The novelty of our work is the consideration of models in which single-dipped and single-peaked preferences exist simultaneously. We consider two models. In the first model, there is a single facility, and agents may disagree about its nature: some agents prefer to be near the facility, while others prefer to be far from it. In the second model, there are two facilities: a desirable facility that all agents want near, and an undesirable facility that all agents want far. We design a variety of approximately optimal strategyproof mechanisms for both models, and prove several lower bounds as well. For the social welfare objective, we provide best-possible deterministic strategyproof mechanisms in the first model and the second model. We then provide improved randomized strategyproof mechanisms for each model, as well as a non-tight lower bound on the worst-case approximation ratio attainable by such mechanisms for the first model. For the egalitarian welfare objective, we provide a lower bound on randomized strategyproof mechanisms for the first model, as well as an optimal (non-approximate) strategyproof mechanism for the second model. All of our mechanisms are also group strategyproof: no coalition of agents can unanimously benefit from misreporting.},
  archive      = {J_AAMAS},
  author       = {Feigenbaum, Itai and Li, Minming and Sethuraman, Jay and Wang, Fangzhou and Zou, Shaokun},
  doi          = {10.1007/s10458-020-09472-9},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-47},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Strategic facility location problems with linear single-dipped and single-peaked preferences},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mobile apps as personal assistant agents: The JaCa-android
framework for programming agents-based applications on mobile devices.
<em>AAMAS</em>, <em>34</em>(2), 1–27. (<a
href="https://doi.org/10.1007/s10458-020-09474-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A relevant application domain for agent-based software is given by mobile and wearable applications. In this context, the impressive progress of technologies in the last decade makes it possible to explore the use of agent-oriented programming languages and frameworks based on cognitive architectures, such as the Belief–Desire–Intention (BDI) one. Accordingly, in this paper we provide a comprehensive description of the JaCa-Android approach, a framework based on the JaCaMo platform that allows for designing and programming smart mobile apps using cognitive agents based on the BDI architecture and the Agents &amp; Artifacts environment conceptual model. In these years, the framework has been applied in real-world projects and application domains, and extended and evolved accordingly. The aim of the paper is to report our experience about designing and programming mobile apps as personal assistant agents, as well as to discuss in detail the architecture of the framework.},
  archive      = {J_AAMAS},
  author       = {Croatti, Angelo and Ricci, Alessandro},
  doi          = {10.1007/s10458-020-09474-7},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-27},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Mobile apps as personal assistant agents: The JaCa-android framework for programming agents-based applications on mobile devices},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Specification testing of agent-based simulation using
property-based testing. <em>AAMAS</em>, <em>34</em>(2), 1–22. (<a
href="https://doi.org/10.1007/s10458-020-09473-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The importance of Agent-Based Simulation (ABS) as scientific method to generate data for scientific models in general and for informed policy decisions in particular has been widely recognised. However, the important technique of code testing of implementations like unit testing has not generated much research interested so far. As a possible solution, in previous work we have explored the conceptual use of property-based testing. In this code testing method, model specifications and invariants are expressed directly in code and tested through automated and randomised test data generation. This paper expands on our previous work and explores how to use property-based testing on a technical level to encode and test specifications of ABS. As use case the simple agent-based SIR model is used, where it is shown how to test agent behaviour, transition probabilities and model invariants. The outcome are specifications expressed directly in code, which relate whole classes of random input to expected classes of output. During test execution, random test data is generated automatically, potentially covering the equivalent of thousands of unit tests, run within seconds on modern hardware. This makes property-based testing in the context of ABS strictly more powerful than unit testing, as it is a much more natural fit due to its stochastic nature.},
  archive      = {J_AAMAS},
  author       = {Thaler, Jonathan and Siebers, Peer-Olaf},
  doi          = {10.1007/s10458-020-09473-8},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-22},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Specification testing of agent-based simulation using property-based testing},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Obtaining costly unverifiable valuations from a single
agent. <em>AAMAS</em>, <em>34</em>(2), 1–25. (<a
href="https://doi.org/10.1007/s10458-020-09469-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A principal needs to elicit the true value of an object she owns from an agent who has a unique ability to compute this information. The principal cannot verify the correctness of the information, so she must incentivize the agent to report truthfully. Previous works coped with this unverifiability by employing two or more information agents and awarding them according to the correlation between their reports. We show that, in a common value setting, the principal can elicit the true information even from a single information agent, and even when computing the value is costly for the agent. Moreover, the principal’s expense is only slightly higher than the cost of computing the value. For this purpose we provide three alternative mechanisms, all providing the same above guarantee, highlighting the advantages and disadvantages in each. Extensions of the basic mechanism include adaptations for cases such as when the principal and the agent value the object differently, when the object is divisible and when the agent’s cost of computation is unknown. Finally, we deal with the case where delivering the information to the principal incurs a cost. Here we show that substantial savings can be obtained in a multi-object setting.},
  archive      = {J_AAMAS},
  author       = {Segal-Halevi, Erel and Alkoby, Shani and Sarne, David},
  doi          = {10.1007/s10458-020-09469-4},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-25},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Obtaining costly unverifiable valuations from a single agent},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). STRATA: Unified framework for task assignments in large
teams of heterogeneous agents. <em>AAMAS</em>, <em>34</em>(2), 1–25. (<a
href="https://doi.org/10.1007/s10458-020-09461-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large teams of heterogeneous agents have the potential to solve complex multi-task problems that are intractable for a single agent working independently. However, solving complex multi-task problems requires leveraging the relative strengths of the different kinds of agents in the team. We present Stochastic TRAit-based Task Assignment (STRATA), a unified framework that models large teams of heterogeneous agents and performs effective task assignments. Specifically, given information on which traits (capabilities) are required for various tasks, STRATA computes the assignments of agents to tasks such that the trait requirements are achieved. Inspired by prior work in robot swarms and biodiversity, we categorize agents into different species (groups) based on their traits. We model each trait as a continuous variable and differentiate between traits that can and cannot be aggregated from different agents. STRATA is capable of reasoning about both species-level and agent-level variability in traits. Further, we define measures of diversity for any given team based on the team’s continuous-space trait model. We illustrate the necessity and effectiveness of STRATA using detailed experiments based in simulation and in a capture-the-flag game environment.},
  archive      = {J_AAMAS},
  author       = {Ravichandar, Harish and Shaw, Kenneth and Chernova, Sonia},
  doi          = {10.1007/s10458-020-09461-y},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-25},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {STRATA: Unified framework for task assignments in large teams of heterogeneous agents},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). From demonstrations to task-space specifications. Using
causal analysis to extract rule parameterization from demonstrations.
<em>AAMAS</em>, <em>34</em>(2), 1–19. (<a
href="https://doi.org/10.1007/s10458-020-09471-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning models of user behaviour is an important problem that is broadly applicable across many application domains requiring human–robot interaction. In this work, we show that it is possible to learn generative models for distinct user behavioural types, extracted from human demonstrations, by enforcing clustering of preferred task solutions within the latent space. We use these models to differentiate between user types and to find cases with overlapping solutions. Moreover, we can alter an initially guessed solution to satisfy the preferences that constitute a particular user type by backpropagating through the learned differentiable models. An advantage of structuring generative models in this way is that we can extract causal relationships between symbols that might form part of the user’s specification of the task, as manifested in the demonstrations. We further parameterize these specifications through constraint optimization in order to find a safety envelope under which motion planning can be performed. We show that the proposed method is capable of correctly distinguishing between three user types, who differ in degrees of cautiousness in their motion, while performing the task of moving objects with a kinesthetically driven robot in a tabletop environment. Our method successfully identifies the correct type, within the specified time, in 99\% [97.8–99.8] of the cases, which outperforms an IRL baseline. We also show that our proposed method correctly changes a default trajectory to one satisfying a particular user specification even with unseen objects. The resulting trajectory is shown to be directly implementable on a PR2 humanoid robot completing the same task.},
  archive      = {J_AAMAS},
  author       = {Angelov, Daniel and Hristov, Yordan and Ramamoorthy, Subramanian},
  doi          = {10.1007/s10458-020-09471-w},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-19},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {From demonstrations to task-space specifications. using causal analysis to extract rule parameterization from demonstrations},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The first twenty years of agent-based software development
with JADE. <em>AAMAS</em>, <em>34</em>(2), 1–19. (<a
href="https://doi.org/10.1007/s10458-020-09460-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A recent survey provides convincing evidence that JADE is among the most widely used tools to develop agent-based software systems. It finds application in industrial settings and to support research, and it has been used to introduce students to software agents in various universities. This paper offers a perspective on the current state of JADE by first presenting a chronicle of the relevant events that contributed to make JADE what it is today. Then, this paper enumerates some of the abstractions that JADE helped to identify and that are now commonly adopted in the community of researchers and practitioners interested in software agents and agent-based software development. Such abstractions have been successfully applied to construct relevant software systems, and among them, this paper reports on a mission-critical system that uses the abstractions that JADE contributed to identify to serve millions of users every day. Finally, this paper discusses an outlook on the near future of JADE by sketching a recent project that could contribute to provide a new perspective on the use of JADE.},
  archive      = {J_AAMAS},
  author       = {Bergenti, Federico and Caire, Giovanni and Monica, Stefania and Poggi, Agostino},
  doi          = {10.1007/s10458-020-09460-z},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-19},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {The first twenty years of agent-based software development with JADE},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Complexity of planning for connected agents. <em>AAMAS</em>,
<em>34</em>(2), 1–31. (<a
href="https://doi.org/10.1007/s10458-020-09468-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a variant of the multi-agent path finding (MAPF) problem in which the group of agents are required to stay connected with a supervising base station throughout the execution. In addition, we consider the problem of covering an area with the same connectivity constraint. We show that both problems are PSPACE-complete on directed and undirected topological graphs while checking the existence of a bounded plan is NP-complete when the bound is given in unary (and PSPACE-hard when the encoding is in binary). Moreover, we identify a realistic class of topological graphs on which the decision problem falls in NLOGSPACE although the bounded versions remain NP-complete for unary encoding.},
  archive      = {J_AAMAS},
  author       = {Charrier, Tristan and Queffelec, Arthur and Sankur, Ocan and Schwarzentruber, François},
  doi          = {10.1007/s10458-020-09468-5},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-31},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Complexity of planning for connected agents},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A genetic algorithm based framework for local search
algorithms for distributed constraint optimization problems.
<em>AAMAS</em>, <em>34</em>(2), 1–31. (<a
href="https://doi.org/10.1007/s10458-020-09464-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Local search algorithms are widely applied in solving large-scale Distributed constraint optimization problems (DCOPs) where each agent holds a value assignment to its variable and iteratively makes a decision on whether to replace its assignment according to its neighbor states. However, the value assignments of their neighbors confine their search to a small space so that agents in local search algorithms easily fall into local optima. Fortunately, Genetic Algorithms (GAs) can direct a search process to a more promising space and help the search process to break up the confine of local states. Accordingly, we propose a GA-based framework (LSGA) to enhance local search algorithms, where a series of genetic operators are redesigned for agents in distributed scenario to accommodate DCOPs. First, a fitness function is designed to evaluate the assignments for each agent, considering the balance of local benefits and global benefits. Then, a new method is provided to decide crossover positions in terms of agent-communication and topological structure of DCOPs. Besides, a self-adaptive crossover probability and a self-adaptive mutation probability are proposed to control the uses of crossover operator and mutation operator, respectively. And more importantly, the LSGA framework can be easily applied in any local search algorithm. The experimental results demonstrate the superiority of the use of LSGA in the typical search algorithms over state-of-the-art incomplete algorithms.},
  archive      = {J_AAMAS},
  author       = {Chen, Ziyu and Liu, Lizhen and He, Jingyuan and Yu, Zhepeng},
  doi          = {10.1007/s10458-020-09464-9},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-31},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {A genetic algorithm based framework for local search algorithms for distributed constraint optimization problems},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Agent programming in the cognitive era. <em>AAMAS</em>,
<em>34</em>(2), 1–31. (<a
href="https://doi.org/10.1007/s10458-020-09453-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is claimed that, in the nascent ‘Cognitive Era’, intelligent systems will be trained using machine learning techniques rather than programmed by software developers. A contrary point of view argues that machine learning has limitations, and, taken in isolation, cannot form the basis of autonomous systems capable of intelligent behaviour in complex environments. In this paper, we explore the contributions that agent-oriented programming can make to the development of future intelligent systems. We briefly review the state of the art in agent programming, focussing particularly on BDI-based agent programming languages, and discuss previous work on integrating AI techniques (including machine learning) in agent-oriented programming. We argue that the unique strengths of BDI agent languages provide an ideal framework for integrating the wide range of AI capabilities necessary for progress towards the next-generation of intelligent systems. We identify a range of possible approaches to integrating AI into a BDI agent architecture. Some of these approaches, e.g., ‘AI as a service’, exploit immediate synergies between rapidly maturing AI techniques and agent programming, while others, e.g., ‘AI embedded into agents’ raise more fundamental research questions, and we sketch a programme of research directed towards identifying the most appropriate ways of integrating AI capabilities into agent programs.},
  archive      = {J_AAMAS},
  author       = {Bordini, Rafael H. and El Fallah Seghrouchni, Amal and Hindriks, Koen and Logan, Brian and Ricci, Alessandro},
  doi          = {10.1007/s10458-020-09453-y},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-31},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Agent programming in the cognitive era},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Runtime revision of sanctions in normative multi-agent
systems. <em>AAMAS</em>, <em>34</em>(2), 1–54. (<a
href="https://doi.org/10.1007/s10458-020-09465-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To achieve system-level properties of a multiagent system, the behavior of individual agents should be controlled and coordinated. One way to control agents without limiting their autonomy is to enforce norms by means of sanctions. The dynamicity and unpredictability of the agents’ interactions in uncertain environments, however, make it hard for designers to specify norms that will guarantee the achievement of the system-level objectives in every operating context. In this paper, we propose a runtime mechanism for the automated revision of norms by altering their sanctions. We use a Bayesian Network to learn, from system execution data, the relationship between the obedience/violation of the norms and the achievement of the system-level objectives. By combining the knowledge acquired at runtime with an estimation of the preferences of rational agents, we devise heuristic strategies that automatically revise the sanctions of the enforced norms. We evaluate our heuristics using a traffic simulator and we show that our mechanism is able to quickly identify optimal revisions of the initially enforced norms.},
  archive      = {J_AAMAS},
  author       = {Dell’Anna, Davide and Dastani, Mehdi and Dalpiaz, Fabiano},
  doi          = {10.1007/s10458-020-09465-8},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-54},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Runtime revision of sanctions in normative multi-agent systems},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-agent active information gathering in discrete and
continuous-state decentralized POMDPs by policy graph improvement.
<em>AAMAS</em>, <em>34</em>(2), 1–44. (<a
href="https://doi.org/10.1007/s10458-020-09467-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decentralized policies for information gathering are required when multiple autonomous agents are deployed to collect data about a phenomenon of interest when constant communication cannot be assumed. This is common in tasks involving information gathering with multiple independently operating sensor devices that may operate over large physical distances, such as unmanned aerial vehicles, or in communication limited environments such as in the case of autonomous underwater vehicles. In this paper, we frame the information gathering task as a general decentralized partially observable Markov decision process (Dec-POMDP). The Dec-POMDP is a principled model for co-operative decentralized multi-agent decision-making. An optimal solution of a Dec-POMDP is a set of local policies, one for each agent, which maximizes the expected sum of rewards over time. In contrast to most prior work on Dec-POMDPs, we set the reward as a non-linear function of the agents’ state information, for example the negative Shannon entropy. We argue that such reward functions are well-suited for decentralized information gathering problems. We prove that if the reward function is convex, then the finite-horizon value function of the Dec-POMDP is also convex. We propose the first heuristic anytime algorithm for information gathering Dec-POMDPs, and empirically prove its effectiveness by solving discrete problems an order of magnitude larger than previous state-of-the-art. We also propose an extension to continuous-state problems with finite action and observation spaces by employing particle filtering. The effectiveness of the proposed algorithms is verified in domains such as decentralized target tracking, scientific survey planning, and signal source localization.},
  archive      = {J_AAMAS},
  author       = {Lauri, Mikko and Pajarinen, Joni and Peters, Jan},
  doi          = {10.1007/s10458-020-09467-6},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-44},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Multi-agent active information gathering in discrete and continuous-state decentralized POMDPs by policy graph improvement},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Teammate-pattern-aware autonomy based on organizational
self-design principles. <em>AAMAS</em>, <em>34</em>(2), 1–30. (<a
href="https://doi.org/10.1007/s10458-020-09462-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We describe an approach for constraining robot autonomy based on the robot’s awareness of patterns of its human teammates’ behaviors, rather than either ignoring its teammates (which is fast but dangerous) or inferring their plans (which is safer but slow). We explore the promise, and limitations, of this approach in a series of simulated problems where an unmanned ground vehicle and its human teammates must rapidly respond to a sudden context shift. Our results help us discern conditions under which a pattern-aware approach can be more effective than the alternatives, and our current efforts investigate how the manned–unmanned team can adopt biases to more readily establish such conditions that are more favorable to the pattern-aware approach.},
  archive      = {J_AAMAS},
  author       = {Durfee, Edmund H. and Thakur, Abhishek and Goldweber, Eli},
  doi          = {10.1007/s10458-020-09462-x},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-30},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Teammate-pattern-aware autonomy based on organizational self-design principles},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Interactively shaping robot behaviour with unlabeled human
instructions. <em>AAMAS</em>, <em>34</em>(2), 1–35. (<a
href="https://doi.org/10.1007/s10458-020-09459-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a framework that enables a human teacher to shape a robot behaviour by interactively providing it with unlabeled instructions. We ground the meaning of instruction signals in the task-learning process, and use them simultaneously for guiding the latter. We implement our framework as a modular architecture, named TICS (Task-Instruction-Contingency-Shaping) that combines different information sources: a predefined reward function, human evaluative feedback and unlabeled instructions. This approach provides a novel perspective for robotic task learning that lies between Reinforcement Learning and Supervised Learning paradigms. We evaluate our framework both in simulation and with a real robot. The experimental results demonstrate the effectiveness of our framework in accelerating the task-learning process and in reducing the number of required teaching signals.},
  archive      = {J_AAMAS},
  author       = {Najar, Anis and Sigaud, Olivier and Chetouani, Mohamed},
  doi          = {10.1007/s10458-020-09459-6},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-35},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Interactively shaping robot behaviour with unlabeled human instructions},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Logic-based specification and verification of homogeneous
dynamic multi-agent systems. <em>AAMAS</em>, <em>34</em>(2), 1–34. (<a
href="https://doi.org/10.1007/s10458-020-09457-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a logic-based framework for formal specification and algorithmic verification of homogeneous and dynamic concurrent multi-agent transition systems. Homogeneity means that all agents have the same available actions at any given state and the actions have the same effects regardless of which agents perform them. The state transitions are therefore determined only by the vector of numbers of agents performing each action and are specified symbolically, by means of conditions on these numbers definable in Presburger arithmetic. The agents are divided into controllable (by the system supervisor/controller) and uncontrollable, representing the environment or adversary. Dynamicity means that the numbers of controllable and uncontrollable agents may vary throughout the system evolution, possibly at every transition. As a language for formal specification we use a suitably extended version of Alternating-time Temporal Logic, where one can specify properties of the type “a coalition of (at least) n controllable agents can ensure against (at most) m uncontrollable agents that any possible evolution of the system satisfies a given objective $$\gamma$$ ″, where $$\gamma$$ is specified again as a formula of that language and each of n and m is either a fixed number or a variable that can be quantified over. We provide formal semantics to our logic $${\mathcal {L}}_{\textsc {hdmas}}$$ and define normal form of its formulae. We then prove that every formula in $${\mathcal {L}}_{\textsc {hdmas}}$$ is equivalent in the finite to one in a normal form and develop an algorithm for global model checking of formulae in normal form in finite HDMAS models, which invokes model checking truth of Presburger formulae. We establish worst case complexity estimates for the model checking algorithm and illustrate it on a running example.},
  archive      = {J_AAMAS},
  author       = {De Masellis, Riccardo and Goranko, Valentin},
  doi          = {10.1007/s10458-020-09457-8},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-34},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Logic-based specification and verification of homogeneous dynamic multi-agent systems},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal action sequence generation for assistive agents in
fixed horizon tasks. <em>AAMAS</em>, <em>34</em>(2), 1–36. (<a
href="https://doi.org/10.1007/s10458-020-09458-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Agents providing assistance to humans are faced with the challenge of automatically adjusting the level of assistance to ensure optimal performance. In this work, we argue that identifying the right level of assistance consists in balancing positive assistance outcomes and some (domain-dependent) measure of cost associated with assistive actions. Towards this goal, we contribute a general mathematical framework for structured tasks where an agent playing the role of a ‘provider’—e.g., therapist, teacher—assists a human ‘receiver’—e.g., patient, student. We specifically consider tasks where the provider agent needs to plan a sequence of actions over a fixed time horizon, where actions are organized along a hierarchy with increasing success probabilities, and some associated costs. The goal of the provider is to achieve a success with the lowest expected cost possible. We present OAssistMe, an algorithm that generates cost-optimal action sequences given the action parameters, and investigate several extensions of it, motivated by different potential application domains. We provide an analysis of the algorithms, including proofs for a number of properties of optimal solutions that, we show, align with typical human provider strategies. Finally, we instantiate our theoretical framework in the context of robot-assisted therapy tasks for children with Autism Spectrum Disorder (ASD). In this context, we present methods for determining action parameters based on a survey of domain experts and real child-robot interaction data. Our contributions unlock increased levels of flexibility for agents introduced in a variety of assistive contexts.},
  archive      = {J_AAMAS},
  author       = {Baraka, Kim and Melo, Francisco S. and Couto, Marta and Veloso, Manuela},
  doi          = {10.1007/s10458-020-09458-7},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-36},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Optimal action sequence generation for assistive agents in fixed horizon tasks},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Learning multi-agent communication with double attentional
deep reinforcement learning. <em>AAMAS</em>, <em>34</em>(1), 1–34. (<a
href="https://doi.org/10.1007/s10458-020-09455-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Communication is a critical factor for the big multi-agent world to stay organized and productive. Recently, Deep Reinforcement Learning (DRL) has been adopted to learn the communication among multiple intelligent agents. However, in terms of the DRL setting, the increasing number of communication messages introduces two problems: (1) there are usually some redundant messages; (2) even in the case that all messages are necessary, how to process a large number of messages in an efficient way remains a big challenge. In this paper, we propose a DRL method named Double Attentional Actor-Critic Message Processor (DAACMP) to jointly address these two problems. Specifically, DAACMP adopts two attention mechanisms. The first one is embedded in the actor part, such that it can select the important messages from all communication messages adaptively. The other one is embedded in the critic part so that all important messages can be processed efficiently. We evaluate DAACMP on three multi-agent tasks with seven different settings. Results show that DAACMP not only outperforms several state-of-the-art methods but also achieves better scalability in all tasks. Furthermore, we conduct experiments to reveal some insights about the proposed attention mechanisms and the learned policies.},
  archive      = {J_AAMAS},
  author       = {Mao, Hangyu and Zhang, Zhengchao and Xiao, Zhen and Gong, Zhibo and Ni, Yan},
  doi          = {10.1007/s10458-020-09455-w},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-34},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Learning multi-agent communication with double attentional deep reinforcement learning},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Strategic voting in the lab: Compromise and leader bias
behavior. <em>AAMAS</em>, <em>34</em>(1), 1–37. (<a
href="https://doi.org/10.1007/s10458-020-09446-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Plurality voting is perhaps the most commonly used way to aggregate the preferences of multiple voters. Yet, there is no consensus on how people vote strategically, even in very simple settings. The purpose of this paper is to provide a comprehensive study of people’s voting behavior in various online settings under the plurality rule. We implemented voting games that replicate two common real-world voting scenarios in controlled experiments. In the first, a single voter votes once after seeing a pre-election poll. In the second game, a group of voters play an iterative game, and change their vote as the game progresses (as in online voting). The winning candidate in each game (and hence the subject’s payment) is determined using the plurality rule. For each of these settings we generated hundreds of game instances, varying conditions such as the number of voters, subjects’ preferences over candidates and the poll information that was made available to the subjects prior to voting. We show that people can be classified into several groups, one of which is not engaged in any strategic behavior, while the largest group demonstrates both a tendency for strategic compromise, and a bias toward voting for the leader in the poll. We provide a detailed analysis of this group behavior for both settings, and how it depends on the poll information. Our study has insight for multi-agent system designers in uncovering patterns that provide reasonable predictions of voters’ behaviors, which may facilitate the design of agents that support people or act autonomously in voting systems.},
  archive      = {J_AAMAS},
  author       = {Meir, Reshef and Gal, Kobi and Tal, Maor},
  doi          = {10.1007/s10458-020-09446-x},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-37},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Strategic voting in the lab: Compromise and leader bias behavior},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Agent based modelling and simulation to estimate movement
time of pilgrims from one place to another at allahabad jn. Railway
station during kumbh mela-2019. <em>AAMAS</em>, <em>34</em>(1), 1–37.
(<a href="https://doi.org/10.1007/s10458-020-09454-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kumbh Mela festival of India is one of the largest mass gathering event of huge religious importance all over the world. Large gatherings in these kind of religious events require rigorous monitoring and attention. Successful organization of such events requires synchronization among officials of different public departments such as police, health, security, communication, railways etc. The railway department plays a significant role in handling huge surge of passengers and their transportation during such events. Every 12-years Kumbh Mela is organized in the city of Prayagraj (formerly Allahabad) in northern India. The Allahabad Jn. railway station experiences huge inflow and outflow of pilgrims during Kumbh Mela. The railway authorities deploy predefined crowd movement strategies and boarding procedures for smooth transportation of pilgrims. However, these strategies are outlined based on previous experiences and ground knowledge of stakeholders. The strategies followed by railway authorities are needed to be evaluated and tested for realistic assessment and possible refinement before actual deployment. Our model is able to capture and simulate the real time behaviour of entities such as pilgrims and trains by programming them as synthetic agents. This model is helpful in analyzing the time taken by a group of pilgrims to move from a designated place to their target platform and board the train. The consumed time is calculated by simulating different movement and boarding procedures including the actual plans followed by the railway authorities. In this way it is possible to assess the efficiency of their movement plans and reasons about possible refinement.},
  archive      = {J_AAMAS},
  author       = {Trivedi, Abha and Pandey, Mayank},
  doi          = {10.1007/s10458-020-09454-x},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-37},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Agent based modelling and simulation to estimate movement time of pilgrims from one place to another at allahabad jn. railway station during kumbh mela-2019},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fast core pricing algorithms for path auction.
<em>AAMAS</em>, <em>34</em>(1), 1–37. (<a
href="https://doi.org/10.1007/s10458-019-09440-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Path auction is held in a graph, where each edge stands for a commodity and the weight of this edge represents the prime cost. Bidders own some edges and make bids for their edges. The auctioneer needs to purchase a sequence of edges to form a path between two specific vertices. Path auction can be considered as a kind of combinatorial reverse auctions. Core-selecting mechanism is a prevalent mechanism for combinatorial auction. However, pricing in core-selecting combinatorial auction is computationally expensive, one important reason is the exponential core constraints. The same is true of path auction. To solve this computation problem, we simplify the constraint set and get the optimal set with only polynomial constraints in this paper. Based on our constraint set, we put forward two fast core pricing algorithms for the computation of bidder-Pareto-optimal core outcome. Among all the algorithms, our new algorithms have remarkable runtime performance. Finally, we validate our algorithms on real-world datasets and obtain excellent results.},
  archive      = {J_AAMAS},
  author       = {Cheng, Hao and Zhang, Wentao and Zhang, Yi and Zhang, Lei and Wu, Jun and Wang, Chongjun},
  doi          = {10.1007/s10458-019-09440-y},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-37},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Fast core pricing algorithms for path auction},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An anytime algorithm for optimal simultaneous coalition
structure generation and assignment. <em>AAMAS</em>, <em>34</em>(1),
1–31. (<a href="https://doi.org/10.1007/s10458-020-09450-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An important research problem in artificial intelligence is how to organize multiple agents, and coordinate them, so that they can work together to solve problems. Coordinating agents in a multi-agent system can significantly affect the system’s performance—the agents can, in many instances, be organized so that they can solve tasks more efficiently, and consequently benefit collectively and individually. Central to this endeavor is coalition formation—the process by which heterogeneous agents organize and form disjoint groups (coalitions). Coalition formation often involves finding a coalition structure (an exhaustive set of disjoint coalitions) that maximizes the system’s potential performance (e.g., social welfare) through coalition structure generation. However, coalition structure generation typically has no notion of goals. In cooperative settings, where coordination of multiple coalitions is important, this may generate suboptimal teams for achieving and accomplishing the tasks and goals at hand. With this in mind, we consider simultaneously generating coalitions of agents and assigning the coalitions to independent alternatives (e.g., tasks/goals), and present an anytime algorithm for the simultaneous coalition structure generation and assignment problem. This combinatorial optimization problem has many real-world applications, including forming goal-oriented teams. To evaluate the presented algorithm’s performance, we present five methods for synthetic problem set generation, and benchmark the algorithm against the industry-grade solver CPLEX using randomized data sets of varying distribution and complexity. To test its anytime-performance, we compare the quality of its interim solutions against those generated by a greedy algorithm and pure random search. Finally, we also apply the algorithm to solve the problem of assigning agents to regions in a major commercial strategy game, and show that it can be used in game-playing to coordinate smaller sets of agents in real-time.},
  archive      = {J_AAMAS},
  author       = {Präntare, Fredrik and Heintz, Fredrik},
  doi          = {10.1007/s10458-020-09450-1},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-31},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {An anytime algorithm for optimal simultaneous coalition structure generation and assignment},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The complexity of bribery and control in group
identification. <em>AAMAS</em>, <em>34</em>(1), 1–31. (<a
href="https://doi.org/10.1007/s10458-019-09427-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of this paper is to analyze the complexity of constructive/destructive bribery and destructive control in the framework of group identification. Group identification applies to situations where a group of individuals determine who among them are socially qualified. We consider consent rules, the consensus-start-respecting rule, and the liberal-start-respecting rule. Each consent rule is characterized by two positive integers s and t, and the socially qualified individuals are determined as follows. If an individual qualifies herself, then she is socially qualified if and only if there are in total at least s individuals qualifying her. Otherwise, she is NOT socially qualified if and only if there are in total at least t individuals disqualifying her. The liberal (resp. consensus)-start-respecting rule determines the socially qualified individuals recursively. In the first step, all individuals qualifying themselves (resp. qualified by all individuals) are socially qualified. Then, the procedure recursively adds individuals who are not socially qualified but are qualified by at least one socially qualified individual into the set of socially qualified individuals until no one can be added this way.},
  archive      = {J_AAMAS},
  author       = {Erdélyi, Gábor and Reger, Christian and Yang, Yongjie},
  doi          = {10.1007/s10458-019-09427-9},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-31},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {The complexity of bribery and control in group identification},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Model primitives for hierarchical lifelong reinforcement
learning. <em>AAMAS</em>, <em>34</em>(1), 1–38. (<a
href="https://doi.org/10.1007/s10458-020-09451-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning interpretable and transferable subpolicies and performing task decomposition from a single, complex task is difficult. Such decomposition can lead to immense sample efficiency gains in lifelong learning. Some traditional hierarchical reinforcement learning techniques enforce this decomposition in a top-down manner, while meta-learning techniques require a task distribution at hand to learn such decompositions. This article presents a framework for using diverse suboptimal world models to decompose complex task solutions into simpler modular subpolicies. Given these world models, this framework performs decomposition of a single source task in a bottom up manner, concurrently learning the required modular subpolicies as well as a controller to coordinate them. We perform a series of experiments on high dimensional continuous action control tasks to demonstrate the effectiveness of this approach at both complex single-task learning and lifelong learning. Finally, we perform ablation studies to understand the importance and robustness of different elements in the framework and limitations to this approach.},
  archive      = {J_AAMAS},
  author       = {Wu, Bohan and Gupta, Jayesh K. and Kochenderfer, Mykel},
  doi          = {10.1007/s10458-020-09451-0},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-38},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Model primitives for hierarchical lifelong reinforcement learning},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Gehrlein stability in committee selection: Parameterized
hardness and algorithms. <em>AAMAS</em>, <em>34</em>(1), 1–21. (<a
href="https://doi.org/10.1007/s10458-020-09452-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a multiwinner election based on the Condorcet criterion, we are given a set of candidates, and a set of voters with strict preference rankings over the candidates. A committee is weakly Gehrlein stable (WGS) if each committee member is preferred to each non-member by at least half of the voters. Recently, Aziz et al. [IJCAI 2017] studied the computational complexity of finding a WGS committee of size k. They show that this problem is NP-hard in general and polynomial-time solvable when the number of voters is odd. In this article, we initiate a systematic study of the problem in the realm of parameterized complexity. We first show that the problem is W[1]-hard when parameterized by the size of the committee. To overcome this intractability result, we use a known reformulation of WGS as a problem on directed graphs and then use parameters that measure the “structure” of these directed graphs. We show that the problem is fixed parameter tractable and admits linear kernels with respect to these parameters; and also present an exact-exponential time algorithm with running in time $${\mathcal {O}}(1.2207^nn^{{\mathcal {O}}(1)})$$, where n denotes the number of candidates.},
  archive      = {J_AAMAS},
  author       = {Gupta, Sushmita and Jain, Pallavi and Roy, Sanjukta and Saurabh, Saket and Zehavi, Meirav},
  doi          = {10.1007/s10458-020-09452-z},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Gehrlein stability in committee selection: Parameterized hardness and algorithms},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Crossmodal attentive skill learner: Learning in atari and
beyond with audio–video inputs. <em>AAMAS</em>, <em>34</em>(1), 1–21.
(<a href="https://doi.org/10.1007/s10458-019-09439-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces the Crossmodal Attentive Skill Learner (CASL), integrated with the recently-introduced Asynchronous Advantage Option-Critic architecture [Harb et al. in When waiting is not an option: learning options with a deliberation cost. arXiv preprint arXiv:1709.04571, 2017] to enable hierarchical reinforcement learning across multiple sensory inputs. Agents trained using our approach learn to attend to their various sensory modalities (e.g., audio, video) at the appropriate moments, thereby executing actions based on multiple sensory streams without reliance on supervisory data. We demonstrate empirically that the sensory attention mechanism anticipates and identifies useful latent features, while filtering irrelevant sensor modalities during execution. Further, we provide concrete examples in which the approach not only improves performance in a single task, but accelerates transfer to new tasks. We modify the Arcade Learning Environment [Bellemare et al. in J Artif Intell Res 47:253–279, 2013] to support audio queries (ALE-audio code available at https://github.com/shayegano/Arcade-Learning-Environment), and conduct evaluations of crossmodal learning in the Atari 2600 games H.E.R.O. and Amidar. Finally, building on the recent work of Babaeizadeh et al. [in: International conference on learning representations (ICLR), 2017], we open-source a fast hybrid CPU–GPU implementation of CASL (CASL code available at https://github.com/shayegano/CASL).},
  archive      = {J_AAMAS},
  author       = {Kim, Dong-Ki and Omidshafiei, Shayegan and Pazis, Jason and How, Jonathan P.},
  doi          = {10.1007/s10458-019-09439-5},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Crossmodal attentive skill learner: Learning in atari and beyond with audio–video inputs},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Competitive equilibrium for almost all incomes: Existence
and fairness. <em>AAMAS</em>, <em>34</em>(1), 1–50. (<a
href="https://doi.org/10.1007/s10458-020-09444-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Competitive equilibrium (CE) is a fundamental concept in market economics. Its efficiency and fairness properties make it particularly appealing as a rule for fair allocation of resources among agents with possibly different entitlements. However, when the resources are indivisible, a CE might not exist even when there is one resource and two agents with equal incomes. Recently, Babaioff and Nisan and Talgam-Cohen (2017–2019) have suggested to consider the entire space of possible incomes, and check whether there exists a CE for almost all income-vectors—all income-space except a subset of measure zero. They proved various existence and non-existence results, but left open the cases of four goods and three or four agents with monotonically-increasing preferences. This paper proves non-existence in both these cases, thus completing the characterization of CE existence for almost all incomes in the domain of monotonically increasing preferences. Additionally, the paper provides a complete characterization of CE existence in the domain of monotonically decreasing preferences, corresponding to allocation of chores. On the positive side, the paper proves that CE exists for almost all incomes when there are four goods and three agents with additive preferences. The proof uses a new tool for describing a CE, as a subgame-perfect equilibrium of a specific sequential game. The same tool also enables substantially simpler proofs to the cases already proved by Babaioff et al. Additionally, this paper proves several strong fairness properties that are satisfied by any CE allocation, illustrating its usefulness for fair allocation among agents with different entitlements.},
  archive      = {J_AAMAS},
  author       = {Segal-Halevi, Erel},
  doi          = {10.1007/s10458-020-09444-z},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-50},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Competitive equilibrium for almost all incomes: Existence and fairness},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Two approximation algorithms for probabilistic coalition
structure generation with quality bound. <em>AAMAS</em>, <em>34</em>(1),
1–27. (<a href="https://doi.org/10.1007/s10458-020-09449-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How to form effective coalitions is an important issue in multi-agent systems. Coalition Structure Generation ($${{\mathsf {CSG}}}$$) is a fundamental problem whose formalization can encompass various applications related to multi-agent cooperation. $${{\mathsf {CSG}}}$$ involves partitioning a set of agents into coalitions such that the social surplus (i.e., the sum of the values of all coalitions) is maximized. In traditional $${\mathsf {CSG}}$$, we are guaranteed that all coalitions will be successfully established, that is, the attendance rate of each agent for joining any coalition is assumed to be 1.0. Having the real world in mind, however, it is natural to consider the uncertainty of agents’ availabilities, e.g., an agent might be available only two or three days a week because of his/her own schedule. Probabilistic Coalition Structure Generation ($${{\mathsf {PCSG}}}$$) is an extension of $${\mathsf {CSG}}$$ where the attendance type of each agent is considered. The aim of this problem is to find the optimal coalition structure which maximizes the sum of the expected values of all coalitions. In $${\mathsf {PCSG}}$$, since finding the optimal coalition structure easily becomes intractable, it is important to consider approximation algorithms, i.e., to consider a trade-off between the quality of the returned solution and tractability. In this paper, a formal framework for $${\mathsf {PCSG}}$$ is introduced. Approximation algorithms for $${\mathsf {PCSG}}$$ called Bounded Approximation Algorithm based on Attendance Types ($${{\mathsf {BAAAT}}}$$) and Involved $${\mathsf {BAAAT}}$$ ($${{\mathsf {IBAAAT}}}$$) are then presented. We prove a priori bounds on the quality of the solution returned by $${\mathsf {BAAAT}}$$ and $${\mathsf {IBAAAT}}$$ with respect to the optimum and perform experimental evaluations on a number of benchmarks.},
  archive      = {J_AAMAS},
  author       = {Matsumura, Kouki and Kodric, Bojana and Okimoto, Tenda and Hirayama, Katsutoshi},
  doi          = {10.1007/s10458-020-09449-8},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-27},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Two approximation algorithms for probabilistic coalition structure generation with quality bound},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The impact of agent definitions and interactions on
multiagent learning for coordination in traffic management domains.
<em>AAMAS</em>, <em>34</em>(1), 1–27. (<a
href="https://doi.org/10.1007/s10458-020-09442-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The state-action space of an individual agent in a multiagent team fundamentally dictates how the individual interacts with the rest of the team. Thus, how an agent is defined in the context of its domain has a significant effect on team performance when learning to coordinate. In this work we explore the trade-offs associated with these design choices, for example, having fewer agents in the team that individually are able to process and act on a wider scope of information about the world versus a larger team of agents where each agent observes and acts in a more local region of the domain. We focus our study on a traffic management domain and highlight the trends in learning performance when applying different agent definitions. In addition, we analyze the impact of agent failure for different agent definitions and investigate the ability of the team to learn new coordination strategies when individual agents become unresponsive.},
  archive      = {J_AAMAS},
  author       = {Chung, Jen Jen and Miklić, Damjan and Sabattini, Lorenzo and Tumer, Kagan and Siegwart, Roland},
  doi          = {10.1007/s10458-020-09442-1},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-27},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {The impact of agent definitions and interactions on multiagent learning for coordination in traffic management domains},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Privacy sensitive environment re-decomposition for junction
tree agent organization construction. <em>AAMAS</em>, <em>34</em>(1),
1–27. (<a href="https://doi.org/10.1007/s10458-019-09438-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A number of frameworks for decentralized probabilistic reasoning, constraint reasoning, and decision theoretic reasoning assume a junction tree agent organization (JT-org). A natural decomposition of agent environment may not admit a JT-org. Hence, JT-org construction involves three related tasks: (1) Recognize whether a JT-org exists for a given environment decomposition. (2) When JT-orgs exist, construct one. (3) When no JT-org exists, revise the environment decomposition so that one exists and then construct it. Task 3 requires re-decomposition of the environment. However, re-decomposition incurs loss of JT-org linked privacy, including agent privacy, topology privacy, privacy on private variables, and privacy on shared variables. We propose a novel algorithm suite Distributed Agent Environment Re-decomposition (DAER) that accomplishes all three tasks distributively. For Tasks 1 and 2, DAER incurs no loss of JT-org linked privacy. For Task 3, it incurs significantly less privacy loss than existing JT-org construction methods. Performance of DAER is formally analyzed and empirically evaluated.},
  archive      = {J_AAMAS},
  author       = {Xiang, Yang and Alshememry, Abdulrahman},
  doi          = {10.1007/s10458-019-09438-6},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-27},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Privacy sensitive environment re-decomposition for junction tree agent organization construction},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An agent for learning new natural language commands.
<em>AAMAS</em>, <em>34</em>(1), 1–27. (<a
href="https://doi.org/10.1007/s10458-019-09425-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Teaching via natural language is an intuitive way for end users to add functionality to a virtual assistant, enabling them to personalize their assistant with new commands without requiring the intervention of the system developer, who cannot possibly anticipate all of an end user’s needs. In this paper we introduce our Learning by Instruction Agent (LIA), the first virtual assistant, for an email domain, that is capable of learning how to perform new commands taught by end users in natural language. LIA grounds the semantics of each command in terms of primitive executable procedures. When a user provides LIA with a command that it does not understand, it prompts the user to explain the command through a sequence of natural language steps. From this input, LIA learns the meaning of the new command and how to generalize the command to novel situations. For example, having been taught how to “forward an email to Alice”, it can correctly understand “forward this email to Bob”. We show that users that were assigned to interact with LIA completed the task quicker than users assigned to interact with a non-learning agent. These results demonstrate the potential of natural language teaching to improve the capabilities of intelligent personal assistants. We annotated 4759 natural language statements with their associated computer readable execution commands (logical forms) to form a dataset (which we publicize in this paper). We present the performance of several different parser methods on this dataset.},
  archive      = {J_AAMAS},
  author       = {Azaria, Amos and Srivastava, Shashank and Krishnamurthy, Jayant and Labutov, Igor and Mitchell, Tom M.},
  doi          = {10.1007/s10458-019-09425-x},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-27},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {An agent for learning new natural language commands},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Computing and testing pareto optimal committees.
<em>AAMAS</em>, <em>34</em>(1), 1–20. (<a
href="https://doi.org/10.1007/s10458-020-09445-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Selecting a set of alternatives based on the preferences of agents is an important problem in committee selection and beyond. Among the various criteria put forth for desirability of a committee, Pareto optimality is a minimal and important requirement. As asking agents to specify their preferences over exponentially many subsets of alternatives is practically infeasible, we assume that each agent specifies a weak order on single alternatives, from which a preference relation over subsets is derived using some preference extension. We consider five prominent extensions (responsive, downward lexicographic, upward lexicographic, best, and worst). For each of them, we consider the corresponding Pareto optimality notion, and we study the complexity of computing and verifying Pareto optimal outcomes. For each of the preference extensions, we give a complete characterization of the complexity of testing Pareto optimality when preferences are dichotomous or linear. We also consider strategic issues: for four of the set extensions, we present a linear-time, Pareto optimal and strategyproof algorithm that even works for weak preferences.},
  archive      = {J_AAMAS},
  author       = {Aziz, Haris and Monnot, Jérôme},
  doi          = {10.1007/s10458-020-09445-y},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Computing and testing pareto optimal committees},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Strategyproof and fair matching mechanism for ratio
constraints. <em>AAMAS</em>, <em>34</em>(1), 1–29. (<a
href="https://doi.org/10.1007/s10458-020-09448-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a new type of distributional constraints called ratio constraints, which explicitly specify the required balance among schools in two-sided matching. Since ratio constraints do not belong to the known well-behaved class of constraints called M-convex set, developing a fair and strategyproof mechanism that can handle them is challenging. We develop a novel mechanism called quota reduction deferred acceptance (QRDA), which repeatedly applies the standard DA by sequentially reducing artificially introduced maximum quotas. As well as being fair and strategyproof, QRDA always yields a weakly better matching for students compared to a baseline mechanism called artificial cap deferred acceptance (ACDA), which uses predetermined artificial maximum quotas. Finally, we experimentally show that, in terms of student welfare and nonwastefulness, QRDA outperforms ACDA and another fair and strategyproof mechanism called Extended Seat Deferred Acceptance (ESDA), in which ratio constraints are transformed into minimum and maximum quotas.},
  archive      = {J_AAMAS},
  author       = {Yahiro, Kentaro and Zhang, Yuzhe and Barrot, Nathanaël and Yokoo, Makoto},
  doi          = {10.1007/s10458-020-09448-9},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-29},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Strategyproof and fair matching mechanism for ratio constraints},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Facial feedback for reinforcement learning: A case study and
offline analysis using the TAMER framework. <em>AAMAS</em>,
<em>34</em>(1), 1–29. (<a
href="https://doi.org/10.1007/s10458-020-09447-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interactive reinforcement learning provides a way for agents to learn to solve tasks from evaluative feedback provided by a human user. Previous research showed that humans give copious feedback early in training but very sparsely thereafter. In this article, we investigate the potential of agent learning from trainers’ facial expressions via interpreting them as evaluative feedback. To do so, we implemented TAMER which is a popular interactive reinforcement learning method in a reinforcement-learning benchmark problem—Infinite Mario, and conducted the first large-scale study of TAMER involving 561 participants. With designed CNN–RNN model, our analysis shows that telling trainers to use facial expressions and competition can improve the accuracies for estimating positive and negative feedback using facial expressions. In addition, our results with a simulation experiment show that learning solely from predicted feedback based on facial expressions is possible and using strong/effective prediction models or a regression method, facial responses would significantly improve the performance of agents. Furthermore, our experiment supports previous studies demonstrating the importance of bi-directional feedback and competitive elements in the training interface.},
  archive      = {J_AAMAS},
  author       = {Li, Guangliang and Dibeklioğlu, Hamdi and Whiteson, Shimon and Hung, Hayley},
  doi          = {10.1007/s10458-020-09447-w},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-29},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Facial feedback for reinforcement learning: A case study and offline analysis using the TAMER framework},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Applying max-sum to asymmetric distributed constraint
optimization problems. <em>AAMAS</em>, <em>34</em>(1), 1–29. (<a
href="https://doi.org/10.1007/s10458-019-09436-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the adjustment and use of the Max-sum algorithm for solving Asymmetric Distributed Constraint Optimization Problems (ADCOPs). First, we formalize asymmetric factor-graphs and apply the different versions of Max-sum to them. Apparently, in contrast to local search algorithms, most Max-sum versions perform similarly when solving symmetric and asymmetric problems and some even perform better on asymmetric problems. Second, we prove that the convergence properties of Max-sum_ADVP (an algorithm that was previously found to outperform standard Max-sum and Bounded Max-sum) and the quality of the solutions it produces, are dependent on the order between nodes involved in each constraint, i.e., the inner constraint order (ICO). A standard ICO allows to reproduce the properties achieved for symmetric problems. Third, we demonstrate that a non-standard ICO can be used to balance exploration and exploitation. Our results indicate that Max-sum_ADVP with non-standard ICO and Damped Max-sum, when solving asymmetric problems, both outperform other versions of Max-sum, as well as local search algorithms specifically designed for solving ADCOPs.},
  archive      = {J_AAMAS},
  author       = {Zivan, Roie and Parash, Tomer and Cohen-Lavi, Liel and Naveh, Yarden},
  doi          = {10.1007/s10458-019-09436-8},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-29},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Applying max-sum to asymmetric distributed constraint optimization problems},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stable outcomes in modified fractional hedonic games.
<em>AAMAS</em>, <em>34</em>(1), 1–29. (<a
href="https://doi.org/10.1007/s10458-019-09431-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In coalition formation games self-organized coalitions are created as a result of the strategic interactions of independent agents. In this paper we assume that for each couple of agents (i, j), weight $$w_{i,j}=w_{j,i}$$ reflects how much agents i and j benefit from belonging to the same coalition. We consider the (symmetric) modified fractional hedonic game, that is a coalition formation game in which agents’ utilities are such that the total benefit of agent i belonging to a coalition (given by the sum of $$w_{i,j}$$ over all other agents j belonging to the same coalition) is averaged over all the other members of that coalition, i.e., excluding herself. Modified fractional hedonic games constitute a class of succinctly representable hedonic games. We are interested in the scenario in which agents, individually or jointly, choose to form a new coalition or to join an existing one, until a stable outcome is reached. To this aim, we consider common stability notions leading to strong Nash stable outcomes, Nash stable outcomes or core stable outcomes: we study their existence, complexity and performance, both in the case of general weights and in the case of 0–1 weights. In particular, we completely characterize the existence of the considered stable outcomes and show many tight or asymptotically tight results on the performance of these natural stable outcomes for modified fractional hedonic games, also highlighting the differences with respect to the model of fractional hedonic games, in which the total benefit of an agent in a coalition is averaged over all members of that coalition, i.e., including herself.},
  archive      = {J_AAMAS},
  author       = {Monaco, Gianpiero and Moscardelli, Luca and Velaj, Yllka},
  doi          = {10.1007/s10458-019-09431-z},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-29},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Stable outcomes in modified fractional hedonic games},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A norm enforcement mechanism for a time-constrained
conditional normative framework. <em>AAMAS</em>, <em>34</em>(1), 1–54.
(<a href="https://doi.org/10.1007/s10458-020-09441-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the formalization for a system that monitors and enforces regulative time-constrained conditional norms through sanctioning, for agent societies. The representation here has the advantage of allowing for qualitative and quantitative interval-based temporal constraints between a norm’s condition and its effect. The system possesses mechanisms for monitoring both norm compliance and violation of reified norms. Each norm has an identity, which enables the identification of norms violated or complied with. The formalism seamlessly treats violation- or conformance-handling norms (such as violation notification, sanctioning and rewarding norms) as regular norms. The implementation formalizes norms as logic program clauses, the head of which specifies what normative position (i.e. the norm’s effect) an agent must observe within some time constraint of some arising situation; and the body of which describes a situation defined as the norm’s pre-condition and the role that the implicated agent plays within it. For the purpose of imposing sanctions, the only violations deemed liable are those violations that the agent fails to mitigate by compliance with all relevant contrary-to-duty norms. An agent may ultimately be sanctioned for a liable norm while norm compliance is rewarded in the system. Sanctioning itself takes place in two norm-guided phases: the obligation of an enforcer agent to notify an erring agent of reparative actions it is obliged to take and the time constraint within which it should be taken, and a norm for monitoring the agent’s compliance with the notification. The violation of the latter norm leads to the meting out of sanctions.},
  archive      = {J_AAMAS},
  author       = {Akinkunmi, B. O. and Babalola, Florence M.},
  doi          = {10.1007/s10458-020-09441-2},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-54},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {A norm enforcement mechanism for a time-constrained conditional normative framework},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Semantics and algorithms for trustworthy commitment
achievement under model uncertainty. <em>AAMAS</em>, <em>34</em>(1),
1–35. (<a href="https://doi.org/10.1007/s10458-020-09443-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We focus on how an agent can exercise autonomy while still dependably fulfilling commitments it has made to another, despite uncertainty about outcomes of its actions and how its own objectives might evolve. Our formal semantics treats a probabilistic commitment as constraints on the actions an autonomous agent can take, rather than as promises about states of the environment it will achieve. We have developed a family of commitment-constrained (iterative) lookahead algorithms that provably respect the semantics, and that support different tradeoffs between computation and plan quality. Our empirical results confirm that our algorithms’ ability to balance (selfish) autonomy and (unselfish) dependability outperforms optimizing either alone, that our algorithms can effectively handle uncertainty about both what actions do and which states are rewarding, and that our algorithms can solve more computationally-demanding problems through judicious parameter choices for how far our algorithms should lookahead and how often they should iterate.},
  archive      = {J_AAMAS},
  author       = {Zhang, Qi and Durfee, Edmund H. and Singh, Satinder},
  doi          = {10.1007/s10458-020-09443-0},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-35},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Semantics and algorithms for trustworthy commitment achievement under model uncertainty},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Solving the fair electric load shedding problem in
developing countries. <em>AAMAS</em>, <em>34</em>(1), 1–35. (<a
href="https://doi.org/10.1007/s10458-019-09428-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Often because of limitations in generation capacity of power stations, many developing countries frequently resort to disconnecting large parts of the power grid from supply, a process termed load shedding. This leaves households in disconnected parts without electricity, causing them inconvenience and discomfort. Without fairness being taken into due consideration during load shedding, some households may suffer more than others. In this paper, we solve the fair load shedding problem (FLSP) by creating solutions which connect households to supply based on some fairness criteria (i.e., to fairly connect homes to supply in terms of duration, their electricity needs, and their demand), which we model as their utilities. First, we briefly describe some state-of-art household-level load shedding heuristics which meet the first criteria. Second, we model the FLSP as a resource allocation problem, which we formulate into two Mixed Integer Programming (MIP) problems based on the Multiple Knapsack Problem. In so doing, we use the utilitarian, egalitarian and envy-freeness social welfare metrics to develop objectives and constraints that ensure our FLSP solutions results in fair allocations that consider the utilities of agents. Then, we solve the FLSP and show that our MIP models maximize the groupwise and individual utilities of agents, and minimize the differences between their pairwise utilities under a number of experiments. When taken together, our endeavour establishes a set of benchmarks for fair load shedding schemes, and provide insights for designing fair allocation solutions for other scarce resources.},
  archive      = {J_AAMAS},
  author       = {Oluwasuji, Olabambo Ifeoluwa and Malik, Obaid and Zhang, Jie and Ramchurn, Sarvapali Dyanand},
  doi          = {10.1007/s10458-019-09428-8},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-35},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Solving the fair electric load shedding problem in developing countries},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A collaborative agent-based traffic signal system for highly
dynamic traffic conditions. <em>AAMAS</em>, <em>34</em>(1), 1–24. (<a
href="https://doi.org/10.1007/s10458-019-09434-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we present DALI, a distributed, collaborative multi-agent traffic signal timing system (TST) for highly dynamic traffic conditions. In DALI, intersection controllers are augmented with software agents which collaboratively adapt signal timings by considering the feedback of all controller agents that may be affected by a change. The model is based on a real-world TST and will be deployed with minimal changes to the infrastructure. DALI has been validated by traffic engineers as well as through extensive simulation of the City of Richardson’s traffic network, comprising 128 signalized intersections. The experimental results show that, in highly dynamic scenarios, DALI outperforms the conventional traffic system used by the city as well as a state-of-the-art reinforcement learning-based TST.},
  archive      = {J_AAMAS},
  author       = {Torabi, Behnam and Wenkstern, Rym Z. and Saylor, Robert},
  doi          = {10.1007/s10458-019-09434-w},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {A collaborative agent-based traffic signal system for highly dynamic traffic conditions},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Truthfulness on a budget: Trading money for approximation
through monitoring. <em>AAMAS</em>, <em>34</em>(1), 1–24. (<a
href="https://doi.org/10.1007/s10458-019-09435-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Albeit a pervasive desideratum when computing in the presence of selfish agents, truthfulness typically imposes severe limitations to what can be implemented. The price of these limitations is typically paid either economically, in terms of the financial resources needed to enforce truthfulness, or algorithmically, in terms of restricting the set of implementable objective functions, which often leads to renouncing optimality and resorting to approximate allocations. In this paper, with regards to utilitarian problems, we ask two fundamental questions: (i) what is the minimum sufficient budget needed by optimal truthful mechanisms, and (ii) whether it is possible to sacrifice optimality in order to achieve truthfulness with a lower budget. To answer these questions, we connect two streams of work on mechanism design and look at monitoring—a paradigm wherein agents’ actual costs are bound to their declarations. In this setting, we prove that the social cost is always a sufficient budget, even for collusion-resistant mechanisms, and, under mild conditions, also a necessary budget for a large class of utilitarian problems that encompass set system problems. Furthermore, for two well-studied problems outside of this class, namely facility location and obnoxious facility location, we draw a novel picture about the relationship between (additive) approximation and frugality. While for optimal mechanisms we prove that the social cost is always a sufficient and necessary budget for both problems, for approximate mechanisms we do have a dichotomy: for the facility location problem (i.e., agents want to be close to the facilities) we show that “good” approximations still need a budget equal to the social cost; on the contrary, for the obnoxious facility location problem (i.e. agents want to be as far away from the facilities as possible) we show that it is possible to trade approximation for frugality, thus obtaining truthfulness with a lower budget.},
  archive      = {J_AAMAS},
  author       = {Serafino, Paolo and Ventre, Carmine and Vidali, Angelina},
  doi          = {10.1007/s10458-019-09435-9},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Truthfulness on a budget: Trading money for approximation through monitoring},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). COMBIMA: Truthful, budget maintaining, dynamic combinatorial
market. <em>AAMAS</em>, <em>34</em>(1), 1–32. (<a
href="https://doi.org/10.1007/s10458-019-09437-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current interest in two-sided markets is motivated by examples of successful practical applications of market mechanisms in supply chain markets, online advertising exchanges, and pollution-rights markets. Many of these examples require markets where agents arrive dynamically and can trade multiple commodities. However, the known literature largely focuses on settings with single-commodity unit demand. We present, prove and evaluate a general solution that matches agents in a dynamic, two-sided combinatorial market. Multiple commodities, each with multiple units, are bought and sold in different bundles by agents that arrive over time. Our mechanism, COMBIMA, provides the first dynamic two-sided combinatorial market that allows truthful and individually-rational behavior for all agents, keeps the market budget balanced and approximates social welfare efficiency. We experimentally examine and compare the allocative efficiency of COMBIMA with respect to our proven theoretical bounds and with respect to all known (dynamic and non-dynamic) social-welfare maximizing two-sided markets under variety of distributions of bids, market demands and market size. COMBIMA performs well by all benchmarks and in many cases improves on previous mechanisms.},
  archive      = {J_AAMAS},
  author       = {Gonen, Rica and Egri, Ozi},
  doi          = {10.1007/s10458-019-09437-7},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-32},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {COMBIMA: Truthful, budget maintaining, dynamic combinatorial market},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Partition decision trees: Representation for efficient
computation of the shapley value extended to games with externalities.
<em>AAMAS</em>, <em>34</em>(1), 1–39. (<a
href="https://doi.org/10.1007/s10458-019-09429-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While coalitional games with externalities model a variety of real-life scenarios of interest to computer science, they pose significant game-theoretic and computational challenges. Specifically, key game-theoretic solution concepts—and the Shapley value in particular—can be extended to games with externalities in multiple, often orthogonal, ways. As for the computational challenges, while there exist two concise representations for coalitional games with externalities—called embedded MC-Nets and weighted MC-Nets—they allow the polynomial-time computation of only two of the six existing direct extensions of the Shapley values to games with externalities. In this article, inspired by the literature on endogenous coalition formation protocols, we propose to represent games with externalities in a way that mimic an intuitive process in which coalitions might form. To this end, we utilize Partition Decision Trees—rooted directed trees, where non-leaf nodes are labelled with agents’ names, leaf nodes are labelled with payoff vectors, and edges indicate membership of agents in coalitions. Interestingly, despite their apparent differences, the representation based on partition decision trees can be considered a subclass of embedded MC-Nets and weighted MC-Nets. The key advantage of this new representation is that it allows the polynomial-time computation of five out of six direct extensions of the Shapley value to games with externalities. In other words, by focusing on narrower Partition Decision Trees instead of wider embedded or weighted MC-Nets, a user is guaranteed to compute most extensions of the Shapley value in polynomial time.},
  archive      = {J_AAMAS},
  author       = {Skibski, Oskar and Michalak, Tomasz P. and Sakurai, Yuko and Wooldridge, Michael and Yokoo, Makoto},
  doi          = {10.1007/s10458-019-09429-7},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-39},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Partition decision trees: Representation for efficient computation of the shapley value extended to games with externalities},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-objective multi-agent decision making: A utility-based
analysis and survey. <em>AAMAS</em>, <em>34</em>(1), 1–52. (<a
href="https://doi.org/10.1007/s10458-019-09433-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The majority of multi-agent system implementations aim to optimise agents’ policies with respect to a single objective, despite the fact that many real-world problem domains are inherently multi-objective in nature. Multi-objective multi-agent systems (MOMAS) explicitly consider the possible trade-offs between conflicting objective functions. We argue that, in MOMAS, such compromises should be analysed on the basis of the utility that these compromises have for the users of a system. As is standard in multi-objective optimisation, we model the user utility using utility functions that map value or return vectors to scalar values. This approach naturally leads to two different optimisation criteria: expected scalarised returns (ESR) and scalarised expected returns (SER). We develop a new taxonomy which classifies multi-objective multi-agent decision making settings, on the basis of the reward structures, and which and how utility functions are applied. This allows us to offer a structured view of the field, to clearly delineate the current state-of-the-art in multi-objective multi-agent decision making approaches and to identify promising directions for future research. Starting from the execution phase, in which the selected policies are applied and the utility for the users is attained, we analyse which solution concepts apply to the different settings in our taxonomy. Furthermore, we define and discuss these solution concepts under both ESR and SER optimisation criteria. We conclude with a summary of our main findings and a discussion of many promising future research directions in multi-objective multi-agent systems.},
  archive      = {J_AAMAS},
  author       = {Rădulescu, Roxana and Mannion, Patrick and Roijers, Diederik M. and Nowé, Ann},
  doi          = {10.1007/s10458-019-09433-x},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-52},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Multi-objective multi-agent decision making: A utility-based analysis and survey},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Agents teaching agents: A survey on inter-agent transfer
learning. <em>AAMAS</em>, <em>34</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s10458-019-09430-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While recent work in reinforcement learning (RL) has led to agents capable of solving increasingly complex tasks, the issue of high sample complexity is still a major concern. This issue has motivated the development of additional techniques that augment RL methods in an attempt to increase task learning speed. In particular, inter-agent teaching—endowing agents with the ability to respond to instructions from others—has been responsible for many of these developments. RL agents that can leverage instruction from a more competent teacher have been shown to be able to learn tasks significantly faster than agents that cannot take advantage of such instruction. That said, the inter-agent teaching paradigm presents many new challenges due to, among other factors, differences between the agents involved in the teaching interaction. As a result, many inter-agent teaching methods work only in restricted settings and have proven difficult to generalize to new domains or scenarios. In this article, we propose two frameworks that provide a comprehensive view of the challenges associated with inter-agent teaching. We highlight state-of-the-art solutions, open problems, prospective applications, and argue that new research in this area should be developed in the context of the proposed frameworks.},
  archive      = {J_AAMAS},
  author       = {Da Silva, Felipe Leno and Warnell, Garrett and Costa, Anna Helena Reali and Stone, Peter},
  doi          = {10.1007/s10458-019-09430-0},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Agents teaching agents: A survey on inter-agent transfer learning},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bounds and dynamics for empirical game theoretic analysis.
<em>AAMAS</em>, <em>34</em>(1), 1–30. (<a
href="https://doi.org/10.1007/s10458-019-09432-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper provides several theoretical results for empirical game theory. Specifically, we introduce bounds for empirical game theoretical analysis of complex multi-agent interactions. In doing so we provide insights in the empirical meta game showing that a Nash equilibrium of the estimated meta-game is an approximate Nash equilibrium of the true underlying meta-game. We investigate and show how many data samples are required to obtain a close enough approximation of the underlying game. Additionally, we extend the evolutionary dynamics analysis of meta-games using heuristic payoff tables (HPTs) to asymmetric games. The state-of-the-art has only considered evolutionary dynamics of symmetric HPTs in which agents have access to the same strategy sets and the payoff structure is symmetric, implying that agents are interchangeable. Finally, we carry out an empirical illustration of the generalised method in several domains, illustrating the theory and evolutionary dynamics of several versions of the AlphaGo algorithm (symmetric), the dynamics of the Colonel Blotto game played by human players on Facebook (symmetric), the dynamics of several teams of players in the capture the flag game (symmetric), and an example of a meta-game in Leduc Poker (asymmetric), generated by the policy-space response oracle multi-agent learning algorithm.},
  archive      = {J_AAMAS},
  author       = {Tuyls, Karl and Perolat, Julien and Lanctot, Marc and Hughes, Edward and Everett, Richard and Leibo, Joel Z. and Szepesvári, Csaba and Graepel, Thore},
  doi          = {10.1007/s10458-019-09432-y},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-30},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Bounds and dynamics for empirical game theoretic analysis},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Strategyproof multi-item exchange under single-minded
dichotomous preferences. <em>AAMAS</em>, <em>34</em>(1), 1–11. (<a
href="https://doi.org/10.1007/s10458-019-09426-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider multi-item exchange markets in which agents want to receive one of their target bundles of resources. The model encompasses well-studied markets for kidney exchange, lung exchange, and multi-organ exchange. We identify a general and sufficient condition called weak consistency for the exchange mechanisms to be strategyproof even if we impose any kind of distributional, diversity, or exchange cycle constraints. Within the class of weakly consistent and strategyproof mechanisms, we highlight two important ones that satisfy constrained Pareto optimality and strong individual rationality. Several results in the literature follow from our insights. We also derive impossibility results when constrained Pareto optimality is defined with respect to more permissive individual rationality requirements.},
  archive      = {J_AAMAS},
  author       = {Aziz, Haris},
  doi          = {10.1007/s10458-019-09426-w},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-11},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Strategyproof multi-item exchange under single-minded dichotomous preferences},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Strategic negotiations for extensive-form games.
<em>AAMAS</em>, <em>34</em>(1), 1–41. (<a
href="https://doi.org/10.1007/s10458-019-09424-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When studying extensive-form games it is commonly assumed that players make their decisions individually. One usually does not allow the possibility for the players to negotiate their respective strategies and formally commit themselves to future moves. As a consequence, many non-zero-sum games have been shown to have equilibrium outcomes that are suboptimal and arguably counter-intuitive. For this reason we feel there is a need to explore a new line of research in which game-playing agents are allowed to negotiate binding agreements before they make their moves. We analyze what happens under such assumptions and define a new equilibrium solution concept to capture this. We show that this new solution concept indeed yields solutions that are more efficient and, in a sense, closer to what one would expect in the real world. Furthermore, we demonstrate that our ideas are not only theoretical in nature, but can also be implemented on bounded rational agents, with a number of experiments conducted with a new algorithm that combines techniques from Automated Negotiations, (Algorithmic) Game Theory, and General Game Playing. Our algorithm, which we call Monte Carlo Negotiation Search, is an adaptation of Monte Carlo Tree Search that equips the agent with the ability to negotiate. It is completely domain-independent in the sense that it is not tailored to any specific game. It can be applied to any non-zero-sum game, provided that its rules are described in Game Description Language. We show with several experiments that it strongly outperforms non-negotiating players, and that it closely approximates the theoretically optimal outcomes, as defined by our new solution concept.},
  archive      = {J_AAMAS},
  author       = {de Jonge, Dave and Zhang, Dongmo},
  doi          = {10.1007/s10458-019-09424-y},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-41},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Strategic negotiations for extensive-form games},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Probabilistic physical search on general graphs:
Approximations and heuristics. <em>AAMAS</em>, <em>34</em>(1), 1–25. (<a
href="https://doi.org/10.1007/s10458-019-09423-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider an agent seeking to obtain an item, potentially available at different locations in a physical environment. The traveling costs between locations are known in advance, but there is only probabilistic knowledge regarding the possible prices of the item at any given location. Given such a setting, the problem is to find a plan that maximizes the probability of acquiring the good while minimizing both travel and purchase costs. Sample applications include agents in search-and-rescue or exploration missions, e.g., a rover on Mars seeking to mine a specific mineral. These probabilistic physical search problems have been previously studied, but we present the first approximation and heuristic algorithms for solving such problems on general graphs. We establish an interesting connection between these problems and classical graph-search problems, which led us to provide the approximation algorithms and hardness of approximation results for our settings. We further suggest several heuristics for practical use, and demonstrate their effectiveness with simulation on a real graph structure.},
  archive      = {J_AAMAS},
  author       = {Hazon, Noam and Gonen, Mira},
  doi          = {10.1007/s10458-019-09423-z},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-25},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Probabilistic physical search on general graphs: Approximations and heuristics},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
