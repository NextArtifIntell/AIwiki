<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>EI_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ei---56">EI - 56</h2>
<ul>
<li><details>
<summary>
(2020). An enhanced moth-flame optimization algorithm for
permutation-based problems. <em>EI</em>, <em>13</em>(4), 741–764. (<a
href="https://doi.org/10.1007/s12065-020-00389-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Moth-flame optimizer (MFO) is one of the recently proposed metaheuristic optimization techniques which has been successfully used in wide range of applications. However, there are two issues with the MFO algorithm. First, as a stochastic technique, MFO may prematurely converge at some local minima during the search process. Second, the original MFO was developed for continuous search space problems and is not directly applicable to, e.g., permutation-based problems (PBP). In this paper, a novel perturbation strategy is introduced to the MFO algorithm to avoid probable local minima regions. This strategy works as follows: if the best solution obtained so far doesn’t improve for a given number of consecutive iterations, the current population of solutions is perturbed using some crossover mechanism as an attempt to explore new promising neighbourhoods in the search space. In addition, smallest position values mapping technique is employed in order for the proposed, termed CrossMFO (COMFO), algorithm to be applicable to PBP problems. It is noticed that, despite these modifications, the proposed COMFO has the same time complexity order as the original MFO. Extensive simulation experiments are conducted to compare the proposed COMFO to the MFO, other enhanced versions of MFO, and some metaheuristic optimizers in solving the well-known Travelling Salesman Problem (TSP). Empirical results show that the solutions obtained using MFO are improved by a factor of 24–47% on average for large TSP instances having more than 100 cities using COMFO and can even reach 38–58% using different settings. In addition, compared to other algorithms in the literature, the proposed algorithm provides, on average, better solutions. Hence, it can be considered a promising and efficient technique for this type of problems.},
  archive      = {J_EI},
  author       = {Helmi, Ahmed and Alenany, Ahmed},
  doi          = {10.1007/s12065-020-00389-6},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {741-764},
  shortjournal = {Evol. Intell.},
  title        = {An enhanced moth-flame optimization algorithm for permutation-based problems},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). ChicWhale optimization algorithm for the VM migration in
cloud computing platform. <em>EI</em>, <em>13</em>(4), 725–739. (<a
href="https://doi.org/10.1007/s12065-020-00386-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, Virtual Machine (VM) migration becomes very popular in the cloud computing platform. Various VM migration based mechanisms are designed for optimal VM placement but remain a challenge due to improper energy consumption in the cloud model. This paper proposes an approach for VM migration in the cloud using an optimization algorithm, Chicken-Whale optimization algorithm (ChicWhale), which is developed by integrating the Whale optimization algorithm in Chicken swarm optimization. In the developed approach, a local migration agent is utilized for monitoring the memory and resources utilization in the cloud continuously, and the VM is migrated using the service provider based on the requirement of the VMs to complete a task assigned. At first, the cloud system is designed, and then the proposed ChicWhale is employed by moving the VMs optimally, and the fitness function for best VM migration is carried out by considering several parameters, like load, migration cost, resource availability, and energy. The performance of the VM migration strategy based on ChicWhale is evaluated in terms of energy consumption, resource availability, migration cost, and load. The proposed ChicWhale method achieves the maximal resource availability of 0.989, minimal migration cost of 0.0564, the minimal energy consumption of 0.481, and the minimal load of 0.0001.},
  archive      = {J_EI},
  author       = {Byatarayanapura Venkataswamy, Srinivas and Mandal, Indrajit and Keshavarao, Seetharam},
  doi          = {10.1007/s12065-020-00386-9},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {725-739},
  shortjournal = {Evol. Intell.},
  title        = {ChicWhale optimization algorithm for the VM migration in cloud computing platform},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An intelligent programmed genetic algorithm with advanced
deterministic diversity creating operator using objective surface
visualization. <em>EI</em>, <em>13</em>(4), 705–723. (<a
href="https://doi.org/10.1007/s12065-020-00385-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new fast Intelligent Programmed Genetic Algorithm (IPGA) based evolutionary optimization algorithm which requires lesser number of objective function evaluation for reaching optima. The proposed algorithm, apart from using probabilistic genetic operator, i.e. crossover and mutation, also uses a deterministic diversity creating operator for generating new solution in the current population. This is done by first projecting objective surface from higher dimension to lower dimension for visualization purpose and then deterministically generates new solution using some predefined rules in the region with higher objective function value. As the newly generated solution is in lower-dimensional space, these solutions are again projected back to higher dimensional space and then the objective function is evaluated at that point. The proposed IPGA is tested on three different categories of standard test functions viz. Unimodal function (2 Test Function), Unrotated Multimodal function (6 Test Function) and Rotated Multimodal function (5 Test Function). Simulation results were compared with that obtained using Binary Coded GA, Real Coded GA, recently proposed GA with Differential Evolution crossover operator (GA–DEx) and another success-history-based adaptive GA with aging mechanism (GA–aDExSPS) in terms of mean and standard deviation of the objective function, average number of objective function evaluation required to reach optima and algorithmic complexity. Simulation results clearly demonstrate better performance of the proposed IPGA when compared with other variants of GAs.},
  archive      = {J_EI},
  author       = {Shah, Devnath and Chatterjee, Saibal},
  doi          = {10.1007/s12065-020-00385-w},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {705-723},
  shortjournal = {Evol. Intell.},
  title        = {An intelligent programmed genetic algorithm with advanced deterministic diversity creating operator using objective surface visualization},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An adaptive hybrid algorithm for social networks to choose
groups with independent members. <em>EI</em>, <em>13</em>(4), 695–703.
(<a href="https://doi.org/10.1007/s12065-020-00384-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Choosing a committee with independent members in social networks can be named as a problem in group selection and independence in the committee is considered as the main criterion of this selection. Independence is calculated based on the social distance between group members. Although there are many solutions to solve the problem of group selection in social networks, such as selection of the target set or community detection, just one solution has been proposed to choose committee members based on their independence as a measure of group performance. In this paper, a new adaptive hybrid algorithm is proposed to select the best committee members to maximize the independence of the committees. This algorithm is a combination of particle swarm optimization algorithm with two local search algorithms. The goal of this work is to combine the exploration and the exploitation to improve the efficiency of the proposed algorithm and obtain the optimal solution. Additionally, to combine local search algorithms with particle swarm optimization, an effective selection mechanism is used to select a suitable local search algorithm to combine with particle swarm optimization during the search process. The results of experimental simulation are compared with the well-known and successful metaheuristic algorithms. This comparison shows that the proposed method improves the group independence by at least 21%.},
  archive      = {J_EI},
  author       = {Hadikhani, Parham and Hadikhani, Pooria},
  doi          = {10.1007/s12065-020-00384-x},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {695-703},
  shortjournal = {Evol. Intell.},
  title        = {An adaptive hybrid algorithm for social networks to choose groups with independent members},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Single layer chebyshev neural network model with
regression-based weights for solving nonlinear ordinary differential
equations. <em>EI</em>, <em>13</em>(4), 687–694. (<a
href="https://doi.org/10.1007/s12065-020-00383-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this investigation, a novel single layer Functional Link Neural Network namely, Chebyshev artificial neural network (ChANN) model with regression-based weights has been developed to handle ordinary differential equations. In ChANN, the hidden layer is removed by an artificial expansion block of the input patterns by using Chebyshev polynomials. Thus the technique is more effectual than the multilayer ANN. Initial weights from the input layer to the output layer are taken by a regression-based model. Here, feed-forward structure and back-propagation algorithm of the unsupervised version have been utilized to make the error values minimal. Numerical examples and comparisons with other methods exhibit the superior behavior of this technique.},
  archive      = {J_EI},
  author       = {Chakraverty, S. and Mall, Susmita},
  doi          = {10.1007/s12065-020-00383-y},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {687-694},
  shortjournal = {Evol. Intell.},
  title        = {Single layer chebyshev neural network model with regression-based weights for solving nonlinear ordinary differential equations},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Motion planning for redundant robotic manipulators using a
novel multi-group particle swarm optimization. <em>EI</em>,
<em>13</em>(4), 677–686. (<a
href="https://doi.org/10.1007/s12065-020-00382-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaheuristic optimization algorithms are widely used in motion planning of redundant robotic manipulators. Existing methods may converge to a local minimum. In this paper, a new multi-group particle swarm optimization algorithm (PSOEL) is proposed to solve the motion planning of manipulators. PSOEL consists of one elite group and several child groups. The population is initialized with a pre-selection mechanism in which the members of the elite group are initialized with the best-performing particles of the child groups. In the process of iteration, the elite group and the child groups evolve separately. When the elite group falls into a local optimum or is inferior to child groups for a certain time, an interaction mechanism is triggered. In the interaction mechanism, some of the best particles selected from the child groups will replace the bad particles of the elite group. With these mechanism of pre-selection and interaction, PSOEL can jump out of the local optimum and reach the global optimum or global suboptimum. Simulation results show that the proposed algorithm PSOEL is superior to the compared algorithms and converges toward the optimum.},
  archive      = {J_EI},
  author       = {Feng, Zikai and Chen, Lijia and Chen, Chung-Hao and Liu, Mingguo and Yuan, Meng-en},
  doi          = {10.1007/s12065-020-00382-z},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {677-686},
  shortjournal = {Evol. Intell.},
  title        = {Motion planning for redundant robotic manipulators using a novel multi-group particle swarm optimization},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stepping away from maximizers of concave quadratics in
random line search. <em>EI</em>, <em>13</em>(4), 663–676. (<a
href="https://doi.org/10.1007/s12065-020-00380-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Random Lines (RL) search relies on finding a minimizer of a given cost function along randomly selected lines in the function domain. Once three points along each line are identified, a quadratic function passing through these points is determined and the minimum of the function is used whenever the function is convex. This paper proposes a two-step approach for handling concave cases: (1) starting from a point with the smallest function value and then (2) stepping in the direction away from the maximizer of the quadratic function. Promising numerical results comparing the improved RL method with other similar evolutionary methods are presented.},
  archive      = {J_EI},
  author       = {Sahin, Ismet and Yilmazer, Nuri and Celebi, Tugcan and Ozcelik, Selahattin and Ajofoyinbo, Abayomi},
  doi          = {10.1007/s12065-020-00380-1},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {663-676},
  shortjournal = {Evol. Intell.},
  title        = {Stepping away from maximizers of concave quadratics in random line search},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Pruning of genetic programming trees using permutation
tests. <em>EI</em>, <em>13</em>(4), 649–661. (<a
href="https://doi.org/10.1007/s12065-020-00379-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a novel approach based on statistical permutation tests for pruning redundant subtrees from genetic programming (GP) trees that allows us to explore the extent of effective redundancy . We observe that over a range of regression problems, median tree sizes are reduced by around 20% largely independent of test function, and that while some large subtrees are removed, the median pruned subtree comprises just three nodes; most take the form of an exact algebraic simplification. Our statistically-based pruning technique has allowed us to explore the hypothesis that a given subtree can be replaced with a constant if this substitution results in no statistical change to the behavior of the parent tree—what we term approximate simplification. In the eventuality, we infer that more than 95% of the accepted pruning proposals are the result of algebraic simplifications, which provides some practical insight into the scope of removing redundancies in GP trees.},
  archive      = {J_EI},
  author       = {Rockett, Peter},
  doi          = {10.1007/s12065-020-00379-8},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {649-661},
  shortjournal = {Evol. Intell.},
  title        = {Pruning of genetic programming trees using permutation tests},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal trained artificial neural network for telugu speaker
diarization. <em>EI</em>, <em>13</em>(4), 631–648. (<a
href="https://doi.org/10.1007/s12065-020-00378-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speaker indexing or diarization is the process of automatically partitioning the conversation involving multiple speakers into homogeneous segments and grouping together all the segments that correspond to the same speaker. So far, certain works have been done under this aspect; still, the need of accurate partitioning process gets lagged under certain criteria. With this in mind, this paper aims to introduce a new speaker indexing or diarization model (Telugu language) that initially involves Mel Frequency Cepstral coefficient based feature extraction. Subsequently, a new Optimized Artificial Neural Network (ANN) is introduced for clustering process. The novelty behind the clustering process is: the training of ANN takes place through optimization logic that updates the weight of ANN by a hybrid concept of Artificial Bee Colony (ABC) and Lion Algorithm (LA). Thereby, the proposed model is named as ANN-ABC-LA model. Finally, the performance of the proposed ANN-ABC-LA model is compared over the state-of-the-art models with respect to different performance measures.},
  archive      = {J_EI},
  author       = {Sethuram, V. and Prasad, Ande and Rao, R. Rajeshwara},
  doi          = {10.1007/s12065-020-00378-9},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {631-648},
  shortjournal = {Evol. Intell.},
  title        = {Optimal trained artificial neural network for telugu speaker diarization},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Discovery of redundant free maximum disjoint set-k-covers
for WSN life enhancement with evolutionary ensemble architecture.
<em>EI</em>, <em>13</em>(4), 611–630. (<a
href="https://doi.org/10.1007/s12065-020-00374-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the wireless sensor network, lifetime enhancement of network is a critical design issue for a wide number of applications. Along with ultra-low power technology, the computational approach in the development of several disjoint covers of sensors, such that each cover must provide the coverage of all targets, can be a more effective means for increasing the life span of the network. This enforces to maximize the number of possible disjoint covers, among available sensors in the network. Effectively this problem can be treated as a Set-K-Cover problem, which has been proven to be NP-complete. To make the solution more power-efficient, in this paper, the complexity of the problem has increased at a further level by expecting not only the upper bound of covers but also making the covers redundant free and formed with the minimal number of sensors. This problem can be considered as a search of multiple components where each component itself carried a multi-dimensional characteristic. In a natural system where evolution is the fundamental principle in the development of any entity, such kind of multi-component complex problem doesn’t handle at one stage. First, an integral approximated solution evolves and later each component evolves separately. This is the reason that for the Set-K-Cover problem, single stages of the various successful evolutionary algorithms have shown their limitation in achieving the upper bound of covers and in delivering redundant free solutions. In the past, some kind of sequential local scanning process has been integrated with evolutionary computation in the iteration for each cover to improve the performance. But discovered covers fail to meet objectives of upper bound and/or redundant free covers with the minimal number of sensors. Hence this research has explored the possibility of finding the solution through more closer to natural way i.e. only through evolution only (without local scanning process). To meet the desired objectives, in this paper an ensemble evolutionary concept has proposed which has delivered redundant free, the upper bound of covers with the minimum number of sensors. Evolutionary Ensemble architecture works at a different level in a cascaded manner to maximize the total possible number of disjoint covers and their refinement along with that there is a feedback mechanism to explore the new covers further if there is any. Based on the natural extinction process, an extinct operator has also introduced in the Genetic algorithm to increase the convergence rate and better exploration. Instead of fitness-oriented, equal opportunity for every parent in offspring creation was introduced to increase the diversity level. The performance results on different simulated networks confirm that without fail the proposed solution has achieved all objectives whereas various variants of Differential evolution and Genetic algorithms and Particle Swarm Optimization fail to deliver desired performances.},
  archive      = {J_EI},
  author       = {Singh, Manoj Kumar},
  doi          = {10.1007/s12065-020-00374-z},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {611-630},
  shortjournal = {Evol. Intell.},
  title        = {Discovery of redundant free maximum disjoint set-k-covers for WSN life enhancement with evolutionary ensemble architecture},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A neighborhood search based cat swarm optimization algorithm
for clustering problems. <em>EI</em>, <em>13</em>(4), 593–609. (<a
href="https://doi.org/10.1007/s12065-020-00373-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is an unsupervised technique that groups the similar data objects into a single subset using a distance function. It is also used to find the optimal set of clusters in a given dataset and each cluster consists of homogenous data objects. In present work, an algorithm based on cat swarm optimization (CSO) is adopted for finding the optimal set of cluster centers for allocating the data objects. Further, some improvements are also incorporated in CSO algorithm for improving clustering performance. These modifications are described as an improved solution search equation to improve convergence rate and an accelerated velocity equation for balancing exploration and exploitation processes of CSO algorithm. Moreover, a neighborhood-based search strategy is introduced to handle local optima problem. The performance of proposed algorithm is tested on eight real-life datasets and compared with well-known clustering algorithms. The simulation results showed that proposed algorithm provides quality results in comparison to existing clustering algorithms.},
  archive      = {J_EI},
  author       = {Singh, Hakam and Kumar, Yugal},
  doi          = {10.1007/s12065-020-00373-0},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {593-609},
  shortjournal = {Evol. Intell.},
  title        = {A neighborhood search based cat swarm optimization algorithm for clustering problems},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sensor placement optimization and damage identification in a
fuselage structure using inverse modal problem and firefly algorithm.
<em>EI</em>, <em>13</em>(4), 571–591. (<a
href="https://doi.org/10.1007/s12065-020-00372-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The structural monitoring of mechanical systems is an extremely important task for ensuring its performance and structural health. To overcome limitations of traditional non-destructive inspections (NDIs), damage identification techniques have been developed from global indicators, mainly those based on modal data. In this study, damages are identified by solving an inverse problem. A fuselage model of an E190 aircraft is considered and the firefly algorithm (FA) metaheuristic is applied to solve the inverse problem in order to identify structural damages (location and severity). The method is then solved in two main fronts: (1) the direct problem using finite element analysis and (2) the inverse problem by minimizing an objective function. Evaluating modal response at many points on a large-scale structure can become prohibitive. For this, a method of optimizing sensors is performed using the Fisher information matrix (FIM). Results are compared considering the sensor placement optimization problem. It is noticed that optimized sensors contribute to an improvement in the identification of damages, mainly for complex and large-scale structures. The proposed optimized damage identification process using FIM-FA has the potential to be extended to a wide range of SHM applications in complex structures. Hence, traditional NDIs have many shortcomings due to the complexity of large-scale structures as well as modern design structures and may not be practicable if the structure has restricted access. Accordingly, an enhanced damage identification method is developed in order to better handle measurement data to find structural changes (or damages) in complex aerospace structures.},
  archive      = {J_EI},
  author       = {Gomes, Guilherme Ferreira and Pereira, João Vitor Purcino},
  doi          = {10.1007/s12065-020-00372-1},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {571-591},
  shortjournal = {Evol. Intell.},
  title        = {Sensor placement optimization and damage identification in a fuselage structure using inverse modal problem and firefly algorithm},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A hybrid EVSA approach in clustered search space with ad-hoc
partitioning for multi-robot searching. <em>EI</em>, <em>13</em>(4),
551–570. (<a href="https://doi.org/10.1007/s12065-020-00356-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper examines the problem of multi-robot target searching in an unknown environment. Since no information is available about the targets, so the search is similar to the exploration problem. In this paper, a new method is proposed to improve the efficiency of exploration. The objective of the proposed approach is to minimize the exploration time by reducing the redundant coverage and computational overhead. For exploration, the concept of frontiers is being used. The following hypothesis formulated in order to improve the exploration: (1) Introduction of an ad-hoc partitioning method to handle redundant coverage. (2) Reduction of the search space by clustering (grouping) the frontier cells to minimize the computational overhead. (3) Introduction of methods for robots’ next position assignment problem, namely, nearest frontier-cluster center method when a single robot is searching in the sub-region. A hybrid of Egyptian vulture and simulated annealing based approach when more than one robots are searching within a sub-region. Performance of the proposed approach is evaluated through simulation in two different workspaces with a team size of 2 and 4 robots. Four different performance measures namely Redundant coverage, Object localization time, Exploration time and Exploration percentage are considered to evaluate the performance of the proposed method. Results show that proposed hybrid-EVSA method completes exploration much faster in both the workspaces with the team size of 2 and 4 robots as compared to other state of art approaches due to low computational overhead and reduced redundant coverage.},
  archive      = {J_EI},
  author       = {Jain, Upma and Tiwari, Ritu and Godfrey, W. Wilfred},
  doi          = {10.1007/s12065-020-00356-1},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {551-570},
  shortjournal = {Evol. Intell.},
  title        = {A hybrid EVSA approach in clustered search space with ad-hoc partitioning for multi-robot searching},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Difficult first strategy GP: An inexpensive sampling
technique to improve the performance of genetic programming.
<em>EI</em>, <em>13</em>(4), 537–549. (<a
href="https://doi.org/10.1007/s12065-020-00355-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Genetic programming (GP) is a top performer in solving classification and clustering problems, in general and symbolic regression problems, in particular. GP has produced impressive results and has outperformed human generated results for 76 different problems taken from 22 different fields. There remain a number of significant open issues despite its impressive results. Among them are high computational cost, premature convergence and high error rate. These issues must be addressed for GP to realise its full potential. In this paper a simple and cost effective technique called Difficult First Strategy-GP (DFS-GP) is proposed to address the aforementioned problems. The proposed technique involves pre-processing and sampling steps. In the pre-processing step, difficult to evolve data points by GP from the given data set are marked and in the sampling step, they are introduced in the evolutionary run by using two newly defined sampling techniques, called difficult points first and difficulty proportionate selection. These techniques are biased towards selecting difficult data points during the initial stage of a run and of easy points in the latter stage of a run. This ensures that GP does not ignore difficult-to-evolve data points during a run. Experiments have shown that GP coupled with DFS avoids premature convergence and attained higher fitness than standard GP using same fitness evaluations. Performance of the proposed technique was evaluated on three commonly known metrics, which are convergence speed, fitness and variance in the best results. Our results have shown that the proposed setups had achieved 10–15% better fitness values than Standard GP. Furthermore, the proposed setups had consistently generated better quality solutions on all the problems and utilized 30–50% less computations to match the best performance of Standard GP.},
  archive      = {J_EI},
  author       = {Ali, Muhammad Quamber and Majeed, Hammad},
  doi          = {10.1007/s12065-020-00355-2},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {537-549},
  shortjournal = {Evol. Intell.},
  title        = {Difficult first strategy GP: An inexpensive sampling technique to improve the performance of genetic programming},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A parallel classification framework for protein fold
recognition. <em>EI</em>, <em>13</em>(3), 525–535. (<a
href="https://doi.org/10.1007/s12065-020-00350-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Proteins’ tertiary structure, which is determined by its amino acid sequence via the protein folding process, have essential role in the function of protein. Protein fold recognition is one of the interesting studies in bioinformatics. In this paper, to address this issue, we propose a Feature Selection (FS) method based on Map_Reduce framework and Vortex Search Algorithm (VSA). FS is one of the most important steps of pre-processing data, which aims to select a variable subset of relevant features. In unparalleled mode and typical data, over hundreds of feature selection and dimension reduction algorithms have been provided such as Principle Component Analysis, Linear Discriminant Analysis, and so on. Nevertheless, these algorithms are not implemented for real-world applications when data instances increasing in three-dimensional: volume, velocity and variety that called Big Data, actually if we want to use previous feature selection methods on Big Data, volume of large and complex computing will be required. VSA was inspired from the vortex pattern created by the vortical flow of the stirred fluids. In Map_Reduce framework, Map and Reduce functions executed in parallel mode. In the proposed method, in each step of Map function, a VSA is employed to find an optimized subset of features and decrease feature search space. In the light of the above consideration, we evaluate the proposed method in classification of a benchmark dataset for protein fold recognition. The experimental results indicate that the proposed method improves prediction accuracy considerably.},
  archive      = {J_EI},
  author       = {Hekmatnia, Elham and Sajedi, Hedieh and Habib Agahi, Ali},
  doi          = {10.1007/s12065-020-00350-7},
  journal      = {Evolutionary Intelligence},
  month        = {9},
  number       = {3},
  pages        = {525-535},
  shortjournal = {Evol. Intell.},
  title        = {A parallel classification framework for protein fold recognition},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Metaheuristic anopheles search algorithm. <em>EI</em>,
<em>13</em>(3), 511–523. (<a
href="https://doi.org/10.1007/s12065-019-00348-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today, various optimization problems have been solved using different optimization techniques such as linear programming, nonlinear programming and dynamic programming. These methods mainly try to find optimal solution in the proximity of starting point. Due to increase in complexity of optimization problems and number of optimal points, efficiency of these methods in finding global optima has decreased. The mentioned challenges encouraged researchers to introduce novel methods inspired by natural phenomena. In this study, Anopheles metaheuristic search algorithm which is inspired by transmission of Malaria disease by Anopheles mosquito is proposed. Our proposed method might be utilized in engineering optimization problems with continuous design variables. The algorithm explores search space using random search in order to eliminate unnecessary information. The efficiency of Anopheles optimization algorithm is evaluated using famous optimization problems. Also, the performance of the proposed method is compared with other optimization methods.},
  archive      = {J_EI},
  author       = {Baloochian, Hossein and Ghaffary, Hamid Reza and Balochian, Saeed},
  doi          = {10.1007/s12065-019-00348-w},
  journal      = {Evolutionary Intelligence},
  month        = {9},
  number       = {3},
  pages        = {511-523},
  shortjournal = {Evol. Intell.},
  title        = {Metaheuristic anopheles search algorithm},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Incremental document clustering using fuzzy-based
optimization strategy. <em>EI</em>, <em>13</em>(3), 497–510. (<a
href="https://doi.org/10.1007/s12065-019-00335-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The technical advances in the information systems contribute towards the massive availability of the documents stored in the electronic database, such as e-mails, internet and web pages. Thus, it becomes a complex task for arranging and browsing the required document. This paper proposes an incremental document clustering method for performing effective document clustering. The proposed model undergoes three steps for document clustering, namely pre-processing, feature extraction and Incremental document categorization. The pre-processing step is carried out for removing the artifacts and redundant data from the documents by undergoing stop word removal process and stemming process. Then, the next step is the feature extraction based on Term Frequency-Inverse Document Frequency (TF–IDF) and Wordnet features. Here, the feature is selected using support measure named ModSupport, and then, the incremental document clustering is performed based on the hybrid fuzzy bounding degree and Rider-Moth Flame optimization algorithm (RMFO) using the boundary degree. Here, the RMFO aims at the selection of the optimal weights for the boundary degree model and is designed by integrating Rider Optimization Algorithm (ROA) with Moth Flame optimization (MFO). The performance of the proposed RMFO outperformed the existing techniques using accuracy, F-measure, precision, and recall with maximal values 93.98%, 94.876%, 93.958% and 93.964% respectively.},
  archive      = {J_EI},
  author       = {Yarlagadda, Madhulika and Kancherla, Gangadhara Rao and Atluri, Srikrishna},
  doi          = {10.1007/s12065-019-00335-1},
  journal      = {Evolutionary Intelligence},
  month        = {9},
  number       = {3},
  pages        = {497-510},
  shortjournal = {Evol. Intell.},
  title        = {Incremental document clustering using fuzzy-based optimization strategy},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Triclustering of gene expression microarray data using
coarse grained and dynamic deme based parallel genetic approach.
<em>EI</em>, <em>13</em>(3), 475–495. (<a
href="https://doi.org/10.1007/s12065-019-00330-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interpretation of microarray data is often crucial in various aspects of computational analysis. Dozens of techniques like clustering, subspace-clustering are often applied to these datasets to pluck-out significant results that provide solutions to drug discovery, disease identification like practical healthcare problems. Clustering techniques are used to group the genes exhibiting similar behavior under particular conditions. This classical method fails while the grouping of genes is done according to a subset of conditions as it performs globally. Biclustering addresses successfully this issue having constraints for evaluation of gene grouping only under a subset of the conditions. However, one of the limitations of the biclustering technique is, it is not capable to analyze the longitudinal experiments which consider different time points for the analysis of the gene expression profiles under a subset of conditions. This affair motivates to adopt triclustering on gene expression microarray data. Triclustering usually finds a set of genes of similar behaviors under a subset of conditions under certain time points. In this research article, two new frameworks based on different versions of parallel genetic algorithms are proposed to detect significant triclusters in gene expression profiles. In the first framework, the proposed algorithm is based on Coarse Grained parallel genetic approach and in the second framework the proposed algorithm is based on the Dynamic Deme parallel genetic approach. Both of them consider the experimental conditions and along with the time points with an advantage of paralleling the process and reducing the computational time. The proposed frameworks are tested on a standard yeast cell cycle(Saccharomyces cerevisiae) dataset and on its different synthetic versions which are widely used in the gene expression analysis. The performance analysis is done with respect to the aspects like the convergence speed of both the algorithms for different input sizes and with respect to the computation time. The statistical analysis is performed followed by the biological relevance of the simulation results is established with their functional annotations derived from the Gene Ontology and KEGG pathway analysis graph. The performance of the proposed frameworks demonstrate its effectiveness with the other state-of-the-art schemes. Experimental results reveal that the proposed architectures are efficient as they consume less computational time due to their inherent parallel behavior. Finally, the suggested architectures are considered as reliable frameworks and can be preferable over the traditional genetic approaches to analyze the gene expression microarray data from the triclustering prospective.},
  archive      = {J_EI},
  author       = {Biswal, Bhawani Sankar and Mohapatra, Anjali and Vipsita, Swati},
  doi          = {10.1007/s12065-019-00330-6},
  journal      = {Evolutionary Intelligence},
  month        = {9},
  number       = {3},
  pages        = {475-495},
  shortjournal = {Evol. Intell.},
  title        = {Triclustering of gene expression microarray data using coarse grained and dynamic deme based parallel genetic approach},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Imaging the search space: A nature-inspired metaheuristic
extension. <em>EI</em>, <em>13</em>(3), 463–474. (<a
href="https://doi.org/10.1007/s12065-019-00325-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans have a long history of exploration throughout which they have devised many imaging technologies such as telescopes, radars and satellites to increase the level of effectiveness and success of their expeditions. This paper proposes the use of imaging concepts to support the search effort of metaheuristics that deploy expedition teams simulating among other things ants, birds and chromosomes to explore the search space of optimization problems. The research involves proposing and developing a set of experimental imaging techniques. Another purpose of the paper is to measure the effectiveness of those proposed imaging techniques on improving the performance of metaheuristic searches that start from initial populations. As a case study an extend to Particle Swarm Optimization metaheuristic algorithm has been performed by implementing and incorporating the proposed imaging techniques and benchmarking them on a platform for comparing continuous optimizers in a black box setting called COCO. The performance of the developed techniques has been evaluated against each other, and against the particle swarm optimization algorithm alone based on the criterion of how many function evaluations were required to reach the set of target values defined by COCO platform. The results show that the use of imaging could produce better results.},
  archive      = {J_EI},
  author       = {Abbas, Anes and Hewahi, Nabil M.},
  doi          = {10.1007/s12065-019-00325-3},
  journal      = {Evolutionary Intelligence},
  month        = {9},
  number       = {3},
  pages        = {463-474},
  shortjournal = {Evol. Intell.},
  title        = {Imaging the search space: A nature-inspired metaheuristic extension},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An evaluation of ear biometric system based on enhanced jaya
algorithm and SURF descriptors. <em>EI</em>, <em>13</em>(3), 443–461.
(<a href="https://doi.org/10.1007/s12065-019-00311-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the ear biometric has received much attention for human recognition due to its unique shape and rich local features. However, extracting discriminative features from ear images is a crucial task in presence of illumination changes, low contrast, noise, and pose variations. With the aim of neutralizing the effect of these factors, this paper proposes an automatic enhancement technique using meta-heuristic optimization to enhance the ear images. Here, we modified a recent and simple yet meta-heuristic optimization technique known as Jaya algorithm by introducing a mutation operator to enhance the ear images in few iterations and the proposed approach is named as enhanced Jaya algorithm. Then, we employed a pose-invariant local feature extractor, SURF to extract local features. Finally, the k-NN classifier has used to evaluate the rate of correct identification. Extensive experiments are conducted on four standard datasets and the performance evaluation is carried out by qualitative and quantitative measures. Experimental results clearly indicate the proposed enhancement approach is competitive as compared to two classical methods HE, CLAHE, and two meta-heuristic algorithms PSO and DE-based image enhancement techniques.},
  archive      = {J_EI},
  author       = {Sarangi, Partha Pratim and Mishra, Bhabani Shankar Prasad and Dehuri, Satchidanand and Cho, Sung-Bae},
  doi          = {10.1007/s12065-019-00311-9},
  journal      = {Evolutionary Intelligence},
  month        = {9},
  number       = {3},
  pages        = {443-461},
  shortjournal = {Evol. Intell.},
  title        = {An evaluation of ear biometric system based on enhanced jaya algorithm and SURF descriptors},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel hybrid bat algorithm with a fast clustering-based
hybridization. <em>EI</em>, <em>13</em>(3), 427–442. (<a
href="https://doi.org/10.1007/s12065-019-00307-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bat algorithm (BA) is a new and promising metaheuristic search algorithm which could outperform existing algorithms. However, BA can be easily trapped in a local optimum regarded to low exploration ability. The present study proposed a new local-search-based hybrid heuristic to escape such scenario. The proposed hybrid BA (hBA) uses a clustering-based hybridization method which detects the early convergence of BA population by analyzing similarities among individuals. The main motivation for such an analysis is that when BA is continually converging, the similarity among individuals becomes higher. The proposed hBA is extensively evaluated on CEC2017 benchmark suite. The Experiments demonstrate that the algorithm achieves better results than continues variants of BA in every way. Moreover, as a case study, a binary version of the proposed hBA (hBBA) is applied to the well-known feature selection problem. The recorded results on 13 datasets demonstrate that hBBA would be considered as a new state-of-art in metaheuristic-based wrapper feature selection methods.},
  archive      = {J_EI},
  author       = {Eskandari, Sadegh and Javidi, Mohammad Masoud},
  doi          = {10.1007/s12065-019-00307-5},
  journal      = {Evolutionary Intelligence},
  month        = {9},
  number       = {3},
  pages        = {427-442},
  shortjournal = {Evol. Intell.},
  title        = {A novel hybrid bat algorithm with a fast clustering-based hybridization},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Comparisons of metaheuristic algorithms for unrelated
parallel machine weighted earliness/tardiness scheduling problems.
<em>EI</em>, <em>13</em>(3), 415–425. (<a
href="https://doi.org/10.1007/s12065-019-00305-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates unrelated parallel machine scheduling problems where the objectives are to minimize total weighted sum of earliness/tardiness costs. Three different metaheuristic algorithms are compared with others to determine what kind (swarm intelligence based, evolutionary or single solution) of metaheuristics is effective to solve these problems. In this study, artificial bee colony (ABC), genetic algorithm and simulated annealing algorithm are chosen as swarm intelligence based algorithm, evolutionary algorithm and single solution algorithm. All proposed algorithms are created without modification in order to determine effectiveness of these metaheuristics. Experimental results show that ABC outperforms its opponents in view of solution quality as swarm intelligence based metaheuristic algorithm.},
  archive      = {J_EI},
  author       = {Arık, Oğuzhan Ahmet},
  doi          = {10.1007/s12065-019-00305-7},
  journal      = {Evolutionary Intelligence},
  month        = {9},
  number       = {3},
  pages        = {415-425},
  shortjournal = {Evol. Intell.},
  title        = {Comparisons of metaheuristic algorithms for unrelated parallel machine weighted earliness/tardiness scheduling problems},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel method for high-level synthesis of datapaths in
digital filters using a moth-flame optimization algorithm. <em>EI</em>,
<em>13</em>(3), 399–414. (<a
href="https://doi.org/10.1007/s12065-019-00302-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-level synthesis (HLS) is one of the most important processes in digital VLSI circuit design. Owing to complexity and enormity of the design space in HLS problems, employing meta-heuristic methods and swarm intelligence has been considered as a highly favorable option when solving such problems. This research work proposes a moth-flame optimization (MFO) algorithm-based method for HLS of datapaths in digital filters, where scheduling, allocating, and binding steps were performed simultaneously. It was observed that the efficiency of the proposed method enjoyed an improved efficiency thanks to the mentioned simultaneous steps while being combined with the MFO algorithm. By comparing the performance of the proposed method with Genetic algorithm based method and particle swarm optimization based method for HLS of digital filters benchmarks, it can be inferred that the proposed method outperforms the other two methods in HLS of digital filters. This is evidently approved by a maximum improvement observed in the rates of the delay, the occupied area of the chip, and the power consumption for 2.99%, 6.58%, and 6.48%, respectively. In addition to the mentioned improvement, another striking characteristic of the proposed method is its fast runtime in reaching a response. This could significantly lower the costs while increasing the design speed of circuits having large dimensions. As well, an averagely 20% rise was also discerned in the algorithm runtime compared to the other two methods.},
  archive      = {J_EI},
  author       = {Esmaeili, Mohammad Reza and Zahiri, Seyed Hamid and Razavi, Seyed Mohammad},
  doi          = {10.1007/s12065-019-00302-w},
  journal      = {Evolutionary Intelligence},
  month        = {9},
  number       = {3},
  pages        = {399-414},
  shortjournal = {Evol. Intell.},
  title        = {A novel method for high-level synthesis of datapaths in digital filters using a moth-flame optimization algorithm},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Solving the twitter sentiment analysis problem based on a
machine learning-based approach. <em>EI</em>, <em>13</em>(3), 381–398.
(<a href="https://doi.org/10.1007/s12065-019-00301-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Twitter Sentiment Analysis (TSA) as part of a text classification task has been widely attended by researchers in recent years. This paper presents a machine learning approach to solving the TSA problem in three phases. In the second phase, a suitable value for representing each feature in the Vector Space Model is determined through the weighted combination of the values obtained from four methods (i.e., Term Frequency and Inverse Document Frequency, semantic similarity, sentiment scoring using SentiWordNet, and sentiment scoring based on the class of tweets). In this manner, finding the percentage of contributions or weights of each method is defined as an optimization problem and solved using a genetic algorithm. Also, the weighted values obtained from four methods are combined based on the Einstein sum as an important T-conorm method. Finally, the performance of the proposed method is tested based on the accuracy of support vector machine and multinomial naïve Bayes classification algorithms on four famous Twitter datasets, namely the Stanford testing dataset, STS-Gold dataset, Obama-McCain Debate dataset, and Strict Obama-McCain Debate dataset. The obtained results show the high superiority of the proposed method in comparison with the other methods.},
  archive      = {J_EI},
  author       = {Zarisfi Kermani, Fatemeh and Sadeghi, Faramarz and Eslami, Esfandiar},
  doi          = {10.1007/s12065-019-00301-x},
  journal      = {Evolutionary Intelligence},
  month        = {9},
  number       = {3},
  pages        = {381-398},
  shortjournal = {Evol. Intell.},
  title        = {Solving the twitter sentiment analysis problem based on a machine learning-based approach},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improving many objective optimisation algorithms using
objective dimensionality reduction. <em>EI</em>, <em>13</em>(3),
365–380. (<a href="https://doi.org/10.1007/s12065-019-00297-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many-objective optimisation problems (MaOPs) have recently received a considerable attention from researchers. Due to the large number of objectives, MaOPs bring serious difficulties to existing multi-objective evolutionary algorithms (MOEAs). The major difficulties includes the poor scalability, the high computational cost and the difficulty in visualisation. A number of many-objective evolutionary algorithms (MaOEAs) has been proposed to tackle MaOPs, but existing MaOEAs have still faced with the difficulties when the number of objectives increases. Real-world MaOPs often have redundant objectives that are not only inessential to describe the Pareto-optimal front, but also deteriorate MaOEAs. A common approach to the problem is to use objective dimensionality reduction algorithms to eliminate redundant objectives. By removing redundant objectives, objective reduction algorithms can improve the search efficiency, reduce computational cost, and support for decision making. The performance of an objective dimensionality reduction strongly depends on nondominated solutions generated by MOEAs/MaOEAs. The impact of objective reduction algorithms on MOEAs and vice versa have been widely investigated. However, the impact of objective reduction algorithms on MaOEAs and vice versa have been rarely investigated. This paper studies the interdependence of objective reduction algorithms on MaOEAs. Experimental results show that combining an objective reduction algorithm with an MOEA can only successfully remove redundant objectives when the total number of objectives is small. In contrast, combining the objective reduction algorithm with an MaOEA can successfully remove redundant objectives even when the total number of objectives is large. Experimental results also show that objective reduction algorithms can significantly improve the performance of MaOEAs.},
  archive      = {J_EI},
  author       = {Nguyen, Xuan Hung and Bui, Lam Thu and Tran, Cao Truong},
  doi          = {10.1007/s12065-019-00297-4},
  journal      = {Evolutionary Intelligence},
  month        = {9},
  number       = {3},
  pages        = {365-380},
  shortjournal = {Evol. Intell.},
  title        = {Improving many objective optimisation algorithms using objective dimensionality reduction},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A space transformational crow search algorithm for
optimization problems. <em>EI</em>, <em>13</em>(3), 345–364. (<a
href="https://doi.org/10.1007/s12065-019-00294-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {New and efficient meta-heuristic algorithms are always in demand to solve real world optimization problems due to its exploiting capability in the search domain to generate the global optimal solution. Crow search algorithm (CSA) is one of the latest meta-heuristic algorithms introduced in the literature to solve optimization tasks. The clever behaviour of crows attracted the researchers to think how to achieve a better optimization by using crow as a base element. Like other optimization algorithms, the CSA suffers with local optima and stagnation problem. In addition, for complex real world problems, CSA has not sufficient exploration capability. Therefore, in the current work, an attempt is made to enhance the explorative behaviour of the CSA by combining the space transform search (STS) method. The proposed algorithm is named as STS-CSA. The proposed STS-CSAintegrates space transformation search technique and computes the solution in current search space and transformed search space simultaneously to generate solutions that is closer to global optimum solution. To assess the performance in solving optimization problems, STS-CSA has been evaluated by applying standard IEEE CEC 2017 benchmark functions. Three real-world engineering problems are also verified to assess the effectiveness of the proposed algorithm in solving the practical problems. The performed analysis such as statistical measure, convergence analysis and complexity measure reveal that the proposed method is reliable and efficient in solving practical optimization problems.},
  archive      = {J_EI},
  author       = {Majhi, Santosh Kumar and Sahoo, Madhusmita and Pradhan, Rosy},
  doi          = {10.1007/s12065-019-00294-7},
  journal      = {Evolutionary Intelligence},
  month        = {9},
  number       = {3},
  pages        = {345-364},
  shortjournal = {Evol. Intell.},
  title        = {A space transformational crow search algorithm for optimization problems},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mutation probability-based lion algorithm for design and
optimization of microstrip patch antenna. <em>EI</em>, <em>13</em>(3),
331–344. (<a href="https://doi.org/10.1007/s12065-019-00292-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advantages and performance of microstrip patch antennas (MPA) namely, reduced weight, reduced profile, and reduced cost formulate them the ideal choice for communication networks. However, the difficulties in structure size and design remain a major concern. Hence, this paper aims to propose a new model that derives a nonlinear objective model for helping in the design of solution space of antenna parameters. To attain this, it is planned to incorporate the optimization concept, thereby a new mutation probability based lion algorithm (MP-LA), which is proposed for the tuning MPA constraints. The main objective model of the antenna design is to maximize the gain by optimizing the patch length, width, thickness of substrate, and value of dielectric substrate. After executing the simulation model, this paper compares the performance of proposed MP-LA-based antenna design with numerous conventional approaches namely, antenna design without optimization, artificial bee colony-based AD, genetic-based AD, firefly-based AD, part icle swarm optimization-based AD and grey wolf optimization-based AD, proposed GWO-based AD and lion optimization algorithm-based AD. Moreover, the analysis is done with respect to radiation pattern, E-plane, and H-plane of proposed and conventional antenna designs. Other performance analysis on characteristics impedance, directivity, efficiency and gain of proposed and conventional models is done.},
  archive      = {J_EI},
  author       = {Guttula, Ramakrishna and Nandanavanam, Venkateswara Rao},
  doi          = {10.1007/s12065-019-00292-9},
  journal      = {Evolutionary Intelligence},
  month        = {9},
  number       = {3},
  pages        = {331-344},
  shortjournal = {Evol. Intell.},
  title        = {Mutation probability-based lion algorithm for design and optimization of microstrip patch antenna},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A study on metaheuristics approaches for gene selection in
microarray data: Algorithms, applications and open challenges.
<em>EI</em>, <em>13</em>(3), 309–329. (<a
href="https://doi.org/10.1007/s12065-019-00306-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the recent decades, researchers have introduced an abundance of feature selection methods many of which are studied and analyzed over the high dimensional datasets typically tiny number of instances and hundreds or thousands of genes. Feature selection methods provide a way of reducing computation cost, improving prediction performance and better understanding of the data structure. However, it is a challenging task due to two reasons such as the considerable solution space and feature interaction. A diversity of feature selection methods is established and applied on high dimensional datasets which includes the metaheuristic algorithms. In this paper, we focus on the basic algorithmic structures of metaheuristic for feature selection that reveals the predominate genes, called biomarkers in microarray gene expression data series with limited resources. In addition, more than hundred articles are carefully screened to prepare the up-to-date comprehensive work on the metaheuristic approach for feature selection and also discussed a range of open issue of recent metaheuristic approaches for feature selection. Furthermore, we have applied some metaheuristic techniques for feature selection on gene expression datasets to demonstrate the applicability of methods. Based on this comprehensive survey, this article suggest some crucial recommendations to researchers for choosing a suitable method from the repository of feature selection methods.},
  archive      = {J_EI},
  author       = {Shukla, Alok Kumar and Tripathi, Diwakar and Reddy, B. Ramachandra and Chandramohan, D.},
  doi          = {10.1007/s12065-019-00306-6},
  journal      = {Evolutionary Intelligence},
  month        = {9},
  number       = {3},
  pages        = {309-329},
  shortjournal = {Evol. Intell.},
  title        = {A study on metaheuristics approaches for gene selection in microarray data: Algorithms, applications and open challenges},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Prediction of corn drying performance for a combined IRC
dryer with a genetically-optimized SVR algorithm. <em>EI</em>,
<em>13</em>(2), 295–307. (<a
href="https://doi.org/10.1007/s12065-019-00347-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grain drying process is a complex nonlinear system which is characterized by long delay process, multi disturbance and strong coupling. In order to explore the modelling of an uncertain system, such as those used in grain drying, and to study the application of the support vector regress algorithm, a corn drying process conducted in a side-heat Infrared Radiation and Convection dryer was modelled by using a support vector regress algorithm combined with a genetic algorithm which is abbreviated as GA-SVR. The algorithm was trained by using the input and output data collected from the practical experiment of corn drying. The predicted performance comparisons between the GA-SVR modelling method and the other two modelling methods (the neural network of BP model and the SVR model based on the grid search algorithm) were also made. Moreover, we successfully used the method to design a model of concurrent-counter flow drying. The designed GA-SVR model has achieved higher modelling prediction accuracy according to the prediction results which have verified the feasibility of the proposed modelling algorithm for modelling the grain drying. The modelling method can also realize the performance prediction of different drying techniques and can be applied in the model prediction control of the grain drying.},
  archive      = {J_EI},
  author       = {Dai, Aini and Zhou, Xiaoguang and Wu, Zidan},
  doi          = {10.1007/s12065-019-00347-x},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {295-307},
  shortjournal = {Evol. Intell.},
  title        = {Prediction of corn drying performance for a combined IRC dryer with a genetically-optimized SVR algorithm},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Performance evaluation of botnet DDoS attack detection using
machine learning. <em>EI</em>, <em>13</em>(2), 283–294. (<a
href="https://doi.org/10.1007/s12065-019-00310-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Botnet is regarded as one of the most sophisticated vulnerability threats nowadays. A large portion of network traffic is dominated by Botnets. Botnets are conglomeration of trade PCs (Bots) which are remotely controlled by their originator (BotMaster) under a Command and-Control (C&amp;C) foundation. They are the keys to several Internet assaults like spams, Distributed Denial of Service Attacks (DDoS), rebate distortions, malwares and phishing. To over the problem of DDoS attack, various machine learning methods typically Support Vector Machine (SVM), Artificial Neural Network (ANN), Naïve Bayes (NB), Decision Tree (DT), and Unsupervised Learning (USML) (K-means, X-means etc.) were proposed. With the increasing popularity of Machine Learning in the field of Computer Security, it will be a remarkable accomplishment to carry out performance assessment of the machine learning methods given a common platform. This could assist developers in choosing a suitable method for their case studies and assist them in further research. This paper performed an experimental analysis of the machine learning methods for Botnet DDoS attack detection. The evaluation is done on the UNBS-NB 15 and KDD99 which are well-known publicity datasets for Botnet DDoS attack detection. Machine learning methods typically Support Vector Machine (SVM), Artificial Neural Network (ANN), Naïve Bayes (NB), Decision Tree (DT), and Unsupervised Learning (USML) are investigated for Accuracy, False Alarm Rate (FAR), Sensitivity, Specificity, False positive rate (FPR), AUC, and Matthews correlation coefficient (MCC) of datasets. Performance of KDD99 dataset has been experimentally shown to be better as compared to the UNBS-NB 15 dataset. This validation is significant in computer security and other related fields.},
  archive      = {J_EI},
  author       = {Tuan, Tong Anh and Long, Hoang Viet and Son, Le Hoang and Kumar, Raghvendra and Priyadarshini, Ishaani and Son, Nguyen Thi Kim},
  doi          = {10.1007/s12065-019-00310-w},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {283-294},
  shortjournal = {Evol. Intell.},
  title        = {Performance evaluation of botnet DDoS attack detection using machine learning},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An initialization method for the latent vectors in
probabilistic matrix factorization for sparse datasets. <em>EI</em>,
<em>13</em>(2), 269–281. (<a
href="https://doi.org/10.1007/s12065-019-00299-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation-based e-commerce applications have been utilized by many companies to increase their sales performance. Probabilistic matrix factorization (PMF) is a widely-used method for collaborative filtering in recommendation systems. Although the method’s performance has been demonstrated successfully in many challenging datasets including Netflix, they are not able to perform well in large sparse datasets where there is considerably low number of rating information. As a remedy, numerous advancements of PMF were proposed which incorporated side information into latent vectors as priors in order to ensure richer prior information in them. However, in cases where such side information is inaccessible, PMF-based algorithms do not perform well. In this study, we propose two new initialization methods for PMF which take into consideration the distribution statistics of user product ratings to enrich latent vectors. The experiments show that the proposed solutions give better results to those in the literature in very sparse datasets.},
  archive      = {J_EI},
  author       = {Ar, Yilmaz},
  doi          = {10.1007/s12065-019-00299-2},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {269-281},
  shortjournal = {Evol. Intell.},
  title        = {An initialization method for the latent vectors in probabilistic matrix factorization for sparse datasets},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-label feature selection based on information entropy
fusion in multi-source decision system. <em>EI</em>, <em>13</em>(2),
255–268. (<a href="https://doi.org/10.1007/s12065-019-00349-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection plays an important role in high-dimensional multi-source data, which can improve classification performance of learning algorithm. Most of existing multi-source information fusion focus on the single decision system without considering multi-source and multi-label problems together. Nevertheless, data from different sources along with multiple labels simultaneously are absolutely frequent in many real-world applications. For this issue, in this paper, a multi-source multi-label decision system is proposed, which has more than one decision label. To remove some redundant or irrelevant features in multi-source multi-label decision system, a feature selection algorithm based on positive region for multi-source multi-label data is explored, which uses the feature dependency carried on the fusion decision table. Finally, examples are introduced to elaborate the detail process of the proposed algorithm, and experimental results show the effective performance of the proposed algorithm on multi-source and multi-label data.},
  archive      = {J_EI},
  author       = {Qian, Wenbin and Yu, Sudan and Yang, Jun and Wang, Yinglong and Zhang, Jihao},
  doi          = {10.1007/s12065-019-00349-9},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {255-268},
  shortjournal = {Evol. Intell.},
  title        = {Multi-label feature selection based on information entropy fusion in multi-source decision system},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A polynomial time algorithm for big data in a special case
of minimum constraint removal problem. <em>EI</em>, <em>13</em>(2),
247–254. (<a href="https://doi.org/10.1007/s12065-019-00331-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The minimum constraint removal (MCR) is one of the most important problems in motion planning and computational geometry. In this problem, there is no feasible path for a robot to move from the starting point towards the goal. Therefore, in order to find a collision-free path, the minimum constraints should be removed. The MCR problem is $$NP-hard$$ when constraints have arbitrary shapes or are in shape of convex polygons. Since it is not possible to solve the problem by deterministic algorithms in an acceptable time for the problem with big data, scientists have tried to solve it by approximation methods. In this paper, we present a deterministic (not approximation) algorithm that solve the problem in a polynomial time. The simplification we used here is about the type of data (neither about the accuracy of the solution, nor about the size of data set). In this paper, a special case of this problem is presented, in which all the constraints are axis-aligned-unit squares and the obstacles have only local effects. Local effect means there are no two cells which have the same label sets. We propose an algorithm for this variant of the problem which can be used for big data. The proposed algorithm has $$O(n^{3})$$ time complexity in the worst case.},
  archive      = {J_EI},
  author       = {Sadeghi Bigham, Bahram and Noorizadeh, Fariba and Khodayifar, Salman},
  doi          = {10.1007/s12065-019-00331-5},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {247-254},
  shortjournal = {Evol. Intell.},
  title        = {A polynomial time algorithm for big data in a special case of minimum constraint removal problem},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Estimation of spreading sequences in LC-DS-CDMA signals
based on sparse auto-encoder. <em>EI</em>, <em>13</em>(2), 235–246. (<a
href="https://doi.org/10.1007/s12065-019-00298-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A method based on a sparse auto-encoder (SAE) network for the estimation of spreading sequences in long-code direct-sequence code-division multiple access (LC-DS-CDMA) signals is proposed. First, a network classification model based on SAE and softmax classifier is established. Next, the effectiveness of the proposed method is verified by estimating Walsh sequences and m sequences. To estimate the spreading sequences, the LC-DS-CDMA signal is divided into fragments. Then, each user’s spreading sequence is separated by the fast independent component analysis (Fast-ICA) algorithm, and the amplitude fuzziness is eliminated by the delay-and-multiply method. Finally, the spreading sequences are estimated by the SAE model. Experimental results showed that the proposed algorithm could effectively estimate the spreading sequences of LC-DS-CDMA signals. Compared to the existing matching algorithm and Fast-ICA algorithm, the estimation time required by the proposed algorithm was shorter, and its estimation performance at low signal-to-noise ratios was superior.},
  archive      = {J_EI},
  author       = {Qiang, Fangfang and Zhao, Zhijin and Shang, Junna and Shen, Lei},
  doi          = {10.1007/s12065-019-00298-3},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {235-246},
  shortjournal = {Evol. Intell.},
  title        = {Estimation of spreading sequences in LC-DS-CDMA signals based on sparse auto-encoder},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mining traffic congestion propagation patterns based on
spatio-temporal co-location patterns. <em>EI</em>, <em>13</em>(2),
221–233. (<a href="https://doi.org/10.1007/s12065-019-00332-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic congestion is a direct reflection of the imbalance between supply and demand for a certain period of time. Owing to the complexity of traffic roads and the propagation of congestion, the evacuation of traffic congestion for local road sections alone cannot achieve significant results. Based on the measured data of traffic flow, this paper combines the topology of the road network and the existence time of congestion to judge the spatio-temporal correlation of congestion between road sections. We proposed a spatio-temporal co-location congestion pattern mining method to discover the orderly set of roads with congestion propagation in urban traffic, and measure its influence in congestion events. The proposed method not only reveals the process of congestion propagation but also uncovers the main propagation paths leading to the large-scale congestion. Finally, we experimented with the algorithm on the traffic dataset in Guiyang city. The experimental results reveal the traffic congestion rule in Guiyang City, including the prevalent co-occurrence of congestion propagation patterns and their influence in congestion events.},
  archive      = {J_EI},
  author       = {Yang, Lu and Wang, Lizhen},
  doi          = {10.1007/s12065-019-00332-4},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {221-233},
  shortjournal = {Evol. Intell.},
  title        = {Mining traffic congestion propagation patterns based on spatio-temporal co-location patterns},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Structural hole detection based on weighted meta path in
heterogeneous networks. <em>EI</em>, <em>13</em>(2), 211–220. (<a
href="https://doi.org/10.1007/s12065-019-00342-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of online social networks, the detection of structural holes, i.e. identifying the key nodes that can bridge with individuals or groups without direct relationship in social networks, has attracted more attention of a large number of researches. The existing researches mainly focus on the influence of a homogeneous network structure, ignoring the importance of node types and different edges in online social networks. In this paper, an algorithm based on weighted meta paths for detecting structural hole in heterogeneous networks (SH_WMP) is proposed. SH_WMP not only flexibly integrates rich semantic information of heterogeneous networks, but also utilizes edge weight and potential link information to improve the performance. Experimental results show that the proposed method outperforms the comparison methods.},
  archive      = {J_EI},
  author       = {Yang, Yudi and Zhang, Jingjing and Chen, Yuexing and Zhou, Lihua and Kong, Bing},
  doi          = {10.1007/s12065-019-00342-2},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {211-220},
  shortjournal = {Evol. Intell.},
  title        = {Structural hole detection based on weighted meta path in heterogeneous networks},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mining high influence co-location patterns from instances
with attributes. <em>EI</em>, <em>13</em>(2), 197–210. (<a
href="https://doi.org/10.1007/s12065-019-00321-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A spatial co-location pattern describes coexistence of spatial features whose instances frequently appear together in geographic space. Numerous studies have been proposed to discover interesting co-location patterns from spatial data sets, but most of them only use the location information of instances. As a result, they cannot adequately reflect the influence between instances. In this paper, we take additional attributes of instances into account in the process of co-location pattern mining, and propose a new approach for discovering the high influence co-location patterns. In our approach, we consider the spatial neighboring relationships and the similarity of instances simultaneously, and utilize the information entropy approach to measure the influence of any instance exerting on its neighbors and the influence of any feature in a co-location pattern. Then, an influence index for measuring the interestingness of a co-location pattern is proposed and we prove the influence index measure satisfies the downward closure property that can be used for pruning the search space, and thus an efficient high influence co-location pattern mining algorithm is designed. At last, extensive experiments are conducted on synthetic and real spatial data sets. Experimental results reveal the effectiveness and efficiency of our method.},
  archive      = {J_EI},
  author       = {Fang, Dianwu and Wang, Lizhen and Yang, Peizhong and Chen, Lan},
  doi          = {10.1007/s12065-019-00321-7},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {197-210},
  shortjournal = {Evol. Intell.},
  title        = {Mining high influence co-location patterns from instances with attributes},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hybrid genetic algorithm and a fuzzy logic classifier for
heart disease diagnosis. <em>EI</em>, <em>13</em>(2), 185–196. (<a
href="https://doi.org/10.1007/s12065-019-00327-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the past two decades, most of the people from developing countries are suffering from heart disease. Diagnosing these diseases at earlier stages helps patients reduce the risk of death and also in reducing the cost of treatment. The objective of adaptive genetic algorithm with fuzzy logic (AGAFL) model is to predict heart disease which will help medical practitioners in diagnosing heart disease at early stages. The model consists of the rough sets based heart disease feature selection module and the fuzzy rule based classification module. The generated rules from fuzzy classifiers are optimized by applying the adaptive genetic algorithm. First, important features which effect heart disease are selected by rough set theory. The second step predicts the heart disease using the hybrid AGAFL classifier. The experimentation is performed on the publicly available UCI heart disease datasets. Thorough experimental analysis shows that our approach has outperformed current existing methods.},
  archive      = {J_EI},
  author       = {Reddy, G. Thippa and Reddy, M. Praveen Kumar and Lakshmanna, Kuruva and Rajput, Dharmendra Singh and Kaluri, Rajesh and Srivastava, Gautam},
  doi          = {10.1007/s12065-019-00327-1},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {185-196},
  shortjournal = {Evol. Intell.},
  title        = {Hybrid genetic algorithm and a fuzzy logic classifier for heart disease diagnosis},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Research on the multiple fuzzy parametric fuzzy sets and its
framework of clustering algorithm. <em>EI</em>, <em>13</em>(2), 159–183.
(<a href="https://doi.org/10.1007/s12065-020-00354-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article first introduces the current research situation of the theory of fuzzy sets, and then, on the basis of type-1 fuzzy sets, according to the different forms and numbers of the parameters of membership functions, put forward the definitions of classical parametric fuzzy sets, multiple classical parametric fuzzy sets, semi fuzzy parametric fuzzy sets, fuzzy parametric fuzzy sets, multiple fuzzy parametric fuzzy sets, etc. Their mathematical expressions are given. On this basis, the multiple parameter fuzzy sets are compared with type-2 fuzzy sets, interval-valued type-2 fuzzy sets, intuitionistic fuzzy sets and interval-valued intuitionistic fuzzy sets. Subsequently, based on clustering by fast search and find of density peaks (CFSFDP), the method and steps of multiple fuzzy parametric fuzzy sets clustering, called “clustering for multiple fuzzy parametric fuzzy sets by fast search and find of density peaks” (MFPFS-CFSFDP), which is further discussed and proposed. In order to reduce the computational complexity of MFPFS-CFSFDP algorithm, referring to the concept of granularity and combining the characteristics of multiple fuzzy parametric fuzzy sets, we propose a “minimum granularity-based key parametric method” to improve the MFPFS-CFSFDP algorithm. Furthermore, two clustering algorithms, which called “clustering plus for multiple fuzzy parametric fuzzy sets by fast search and find of density peaks” (MFPFS-CFSFDP+) and “clustering plus plus for multiple fuzzy parametric fuzzy sets by fast search and find of density peaks” (MFPFS-CFSFDP++) are proposed. Finally, taking the multiple normal fuzzy parametric normal fuzzy sets as an example, the algorithm framework tables of these three clustering algorithms are given, and their advantages and disadvantages are summarized, they provide a theoretical basis for further research on clustering for multiple fuzzy parametric fuzzy sets.},
  archive      = {J_EI},
  author       = {Yiyan, Chen and Ye, Li and Cunjin, Li},
  doi          = {10.1007/s12065-020-00354-3},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {159-183},
  shortjournal = {Evol. Intell.},
  title        = {Research on the multiple fuzzy parametric fuzzy sets and its framework of clustering algorithm},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adapted a novel similarity and its application in fuzzy risk
analysis. <em>EI</em>, <em>13</em>(2), 147–158. (<a
href="https://doi.org/10.1007/s12065-019-00286-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generalized trapezoidal fuzzy numbers (GTFNs) and their similarity measures have been widely applied in fuzzy risk analysis. However, some existing similarity measures of GTFNs cannot identify the similarity of some special GTFNs properly. In this study, we introduce the exponential distance of center of gravity (COG) and an amending value to adapted a novel similarity measure between GTFNs. Then, seven properties of this new method are investigated and proved. In addition, in order to verify the superiority of the new method, fifteen special testing sets are given to compare the performance of seven existing similarity measures with the new method. Moreover, the presented new similarity measure is used to solve a case study about the failure risk analysis of six major subsystems of the reciprocating pump system (RPS) in which different parameters are expressed by generalized trapezoidal fuzzy linguistic term.},
  archive      = {J_EI},
  author       = {Yang, Yan and Liu, Xin and Zhao, Mengchuan},
  doi          = {10.1007/s12065-019-00286-7},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {147-158},
  shortjournal = {Evol. Intell.},
  title        = {Adapted a novel similarity and its application in fuzzy risk analysis},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel fuzzy-markov forecasting model for stock fluctuation
time series. <em>EI</em>, <em>13</em>(2), 133–145. (<a
href="https://doi.org/10.1007/s12065-019-00328-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to reveal intrinsic fluctuation rules hidden in a stock market time series dataset with noise, a novel forecasting model combining Markov chain theory with fuzzy set theory is proposed in this study. A fuzzified one-step transition matrix of Markov Chain in the paper represents inherent rules of historical fluctuation. Comparing with existing models, the advantage of the proposed model is that transition matrix can express the relationship between history and current flexibly while the introduction of fuzzy theory can help to alleviate noises. Therefore, the proposed model could handle complex patterns during state transitions and the relatively simple forecasting algorithm could reduce the calculation cost. We apply the proposed method to forecast well-known stock indexes such as (Taiwan Stock Exchange Capitalization Weighted Stock Index) TAIEX, (Shanghai Stock Exchange Composite Index) SHSECI and so on. Experimental results demonstrate that our proposed method outperforms other traditional models.},
  archive      = {J_EI},
  author       = {Guan, Hongjun and Jie, He and Guan, Shuang and Zhao, Aiwu},
  doi          = {10.1007/s12065-019-00328-0},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {133-145},
  shortjournal = {Evol. Intell.},
  title        = {A novel fuzzy-markov forecasting model for stock fluctuation time series},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Special issue on “intelligent and fuzzy systems in data
science and big data.” <em>EI</em>, <em>13</em>(2), 131. (<a
href="https://doi.org/10.1007/s12065-020-00423-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EI},
  author       = {Tomasiello, Stefania and Feng, Feng and Kotsiantis, Sotiris and Khastan, Alireza},
  doi          = {10.1007/s12065-020-00423-7},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {131},
  shortjournal = {Evol. Intell.},
  title        = {Special issue on “Intelligent and fuzzy systems in data science and big data”},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A construction of smart city evaluation system based on
cloud computing platform. <em>EI</em>, <em>13</em>(1), 119–129. (<a
href="https://doi.org/10.1007/s12065-019-00259-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart city is a complex systematic engineering. It not only needs planing, constructing, managing and running, but also requires evaluating, optimizing and adjusting, in order to keep the smart city construction prospective, reasonable and effective. The application of cloud computing platform can effectively improve the intellectualization of urban. According to the problems such as the blind construction and the unsatisfied results during the process of the smart city construction, we carry on the theoretical exploration about smart city evaluation system based on cloud platform and studying the indexes included in smart city and relation among them, and further propose the method of the smart city evaluation system. The core of the method is the smart city evaluation indexes system, evaluation method and optimization strategy and the feasibility of the method is verified by an example. Finally, we propose an application-oriented cloud computing platform architecture, it can improve the evaluation results and maximize the capacity of smart cities.},
  archive      = {J_EI},
  author       = {Wang, Changhao and Li, Shining and Cheng, Tao and Li, Bingqi},
  doi          = {10.1007/s12065-019-00259-w},
  journal      = {Evolutionary Intelligence},
  month        = {3},
  number       = {1},
  pages        = {119-129},
  shortjournal = {Evol. Intell.},
  title        = {A construction of smart city evaluation system based on cloud computing platform},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Implementation of adaptive scheme in evolutionary technique
for anomaly-based intrusion detection. <em>EI</em>, <em>13</em>(1),
103–117. (<a href="https://doi.org/10.1007/s12065-019-00293-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intrusion detection has become important to network security because of the increasing connectivity between computers and internet. Various Intrusion Detection Systems have been investigated to protect web or networks using several evolutionary methods and classification techniques. In this study, we propose a new technique by combining Ensemble of Feature Selection (EFS) and Adaptive Grasshopper Optimization Algorithm (AGOA) methods, called EFSAGOA which can help to identify the types of attack. In the proposed approach, initially, EFS method is applied to rank the attribute for selecting the high ranked subset of attributes. Then, AGOA is employed to determine important attributes from the reduced datasets that can contribute to predict the networks traffic behavior. Furthermore, adaptive behavior of GOA uses to decide whether a record represents an anomaly or not, differing from some approaches acquainted in the literature. AGOA uses the Support Vector Machine (SVM) as a fitness function to choose the extremely efficient features and to maximize the classification performance. In addition, it is also applied to optimize the penalty factor (C), kernel parameter $$(\sigma )$$, and tube size $$(\epsilon )$$ of SVM classifier. The performance of EFSAGOA has been evaluated on modern intrusion data as ISCX 2012. The experimental results demonstrate that the proposed method performs better and obtain high detection rate, accuracy, and low false alarm rate compared to other state-of-art techniques in ISCX 2012 data.},
  archive      = {J_EI},
  author       = {Dwivedi, Shubhra and Vardhan, Manu and Tripathi, Sarsij and Shukla, Alok Kumar},
  doi          = {10.1007/s12065-019-00293-8},
  journal      = {Evolutionary Intelligence},
  month        = {3},
  number       = {1},
  pages        = {103-117},
  shortjournal = {Evol. Intell.},
  title        = {Implementation of adaptive scheme in evolutionary technique for anomaly-based intrusion detection},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Message broadcasting by opportunistic communication on unit
disk graphs. <em>EI</em>, <em>13</em>(1), 93–102. (<a
href="https://doi.org/10.1007/s12065-018-0189-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Opportunistic communication is one of the key technologies in the area of advertisement, information sharing, disaster evacuation guidance in delay-tolerant networks (DTNs), vehicular ad hoc networks (VANETs) and so on. The efficiency of opportunistic communication is correlated with the movement pattern. Random walks are often used as the movement patterns of a pedestrian. Even amongst those, Lévy walk that is a family of random walks is attracted attention as a human movement pattern. There are lots of works of Lévy walk in the context of target detection in swarm robotics, analyzing human walk patterns, and modeling the behavior of animal foraging in recent years. According to these results, it is known as an efficient method to search and come across one another in a two-dimensional plane. However, all these works assume a continuous plane and hardly any results on graphs are available. In this paper, we assume agents move on a unit disk graph and show the impact of the movement patterns based on Lévy walk and Homesick Lévy walk to the efficiency of message broadcasting by them. Our simulation results show that the configuration of Lévy walk and Homesick Lévy walk movement patterns with the smaller scaling parameter diffuses a message efficiently compared to it with the larger one.},
  archive      = {J_EI},
  author       = {Shinki, Kenya and Sugihara, Kouichirou and Hayashibara, Naohiro},
  doi          = {10.1007/s12065-018-0189-6},
  journal      = {Evolutionary Intelligence},
  month        = {3},
  number       = {1},
  pages        = {93-102},
  shortjournal = {Evol. Intell.},
  title        = {Message broadcasting by opportunistic communication on unit disk graphs},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Performance evaluation of support vector machine and
convolutional neural network algorithms in real-time vehicle type and
color classification. <em>EI</em>, <em>13</em>(1), 83–91. (<a
href="https://doi.org/10.1007/s12065-018-0167-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order for traffic management and information systems to provide proper traffic flow, it is necessary to obtain information about traffic with the help of various sensors. In this context, in recent years the use of video cameras in traffic observation and control has become very widespread and actively used. Numerous studies such as license plate recognition, vehicle number finding, traffic intensity determination, vehicle speed calculation, band violation and vehicle classification can be done with the help of video processing based video monitoring systems. Traffic surveillance videos are very actively used for this purpose. In this paper, we have developed a system that classifies vehicles according to their type. Firstly we create a vehicle dataset from an uncalibrated camera. Then, we test Tiny-YOLO real-time object detection and classification system and support vector machine (SVM) classifier model on our dataset and well-known public BIT-Vehicle dataset in terms of recall, precision, and intersection over union performance metrics. Experimental results show that two methods can be used to classify real-time streaming traffic video data.},
  archive      = {J_EI},
  author       = {Şentaş, Ali and Tashiev, İsabek and Küçükayvaz, Fatmanur and Kul, Seda and Eken, Süleyman and Sayar, Ahmet and Becerikli, Yaşar},
  doi          = {10.1007/s12065-018-0167-z},
  journal      = {Evolutionary Intelligence},
  month        = {3},
  number       = {1},
  pages        = {83-91},
  shortjournal = {Evol. Intell.},
  title        = {Performance evaluation of support vector machine and convolutional neural network algorithms in real-time vehicle type and color classification},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Energy consumption laxity-based quorum selection for
distributed object-based systems. <em>EI</em>, <em>13</em>(1), 71–82.
(<a href="https://doi.org/10.1007/s12065-018-0157-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In object based systems, an object is an unit of computation resource. Distributed applications are composed of multiple objects. Objects in an application are replicated to multiple servers in order to increase reliability, availability, and performance. On the other hand, the large amount of electric energy is consumed in a system compared with non-replication systems since multiple replicas of each object are manipulated on multiple servers. In this paper, the energy consumption laxity-based quorum selection (ECLBQS) algorithm is proposed to construct a quorum for each method issued by a transaction so that the total electric energy consumption of servers to perform methods can be reduced in the quorum based locking protocol. The total electric energy consumption of servers, the average execution time of each transaction, and the number of aborted transactions are shown to be more reduced in the ECLBQS algorithm than the random algorithm in evaluation.},
  archive      = {J_EI},
  author       = {Enokido, Tomoya and Duolikun, Dilawaer and Takizawa, Makoto},
  doi          = {10.1007/s12065-018-0157-1},
  journal      = {Evolutionary Intelligence},
  month        = {3},
  number       = {1},
  pages        = {71-82},
  shortjournal = {Evol. Intell.},
  title        = {Energy consumption laxity-based quorum selection for distributed object-based systems},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Special issue “the convergence of evolutionary intelligence
and networking.” <em>EI</em>, <em>13</em>(1), 69–70. (<a
href="https://doi.org/10.1007/s12065-020-00368-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EI},
  author       = {Xhafa, Fatos and Barolli, Leonard},
  doi          = {10.1007/s12065-020-00368-x},
  journal      = {Evolutionary Intelligence},
  month        = {3},
  number       = {1},
  pages        = {69-70},
  shortjournal = {Evol. Intell.},
  title        = {Special issue “The convergence of evolutionary intelligence and networking”},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A node-priority based large-scale overlapping community
detection using evolutionary multi-objective optimization. <em>EI</em>,
<em>13</em>(1), 59–68. (<a
href="https://doi.org/10.1007/s12065-019-00250-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community structure is one of the most important features in complex networks. However, with increasing of network scale, some existing methods cannot effectively detect the community structure of complex network, and the available methods mostly aimed at non-overlapping networks. In this paper, we focus on overlapping community detection in large-scale networks, because most of the communities in real-world networks are overlapped. In order to improve the accuracy of large-scale overlapping community detection, we suggest a community detection method based on node priority. The proposed algorithm has two advantages: (1) We define a priority function $${\text{f}}_{\text{NN}}$$ to assess the closeness between adjacent nodes. It explores the potential community structure in advance and reduces the scale of networks. (2) We employ NSGA-II and select all Pareto fronts to mine large-scale overlapping communities. The proposed algorithm is tested by the artificial and real datasets. The results show that the proposed algorithm can effectively improve the accuracy of community detection and has better optimization effect.},
  archive      = {J_EI},
  author       = {Chai, Zhengyi and Liang, Shijiao},
  doi          = {10.1007/s12065-019-00250-5},
  journal      = {Evolutionary Intelligence},
  month        = {3},
  number       = {1},
  pages        = {59-68},
  shortjournal = {Evol. Intell.},
  title        = {A node-priority based large-scale overlapping community detection using evolutionary multi-objective optimization},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Structure optimization method based on automatic
vectorization. <em>EI</em>, <em>13</em>(1), 51–58. (<a
href="https://doi.org/10.1007/s12065-019-00229-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structure is used more extensively used in program such as scientific computing. But the non-continuity and the non-aligment of vectorization structure array have a dramatic influence on the efficiency of program’s vectorizaton. To reduce the access to these addresses during the SIMD vectorization, a structure peeling model is proposed based on the structure which combines domain access affinity and domain data type. At the same time, to meet t the requirement of memory access continuity and alignment in the vectorization of structured array, an address conversion method is proposed which structure arrays are mapped one by one map to two-dimensional arrays, further reducing the failure rate of cache. By using the test suites of gcc_vec, spec2000 and spec2006, the experimental results on the compiler of automatic vector show that the performance of optimized method can be improved by more than 8%.},
  archive      = {J_EI},
  author       = {Li, Yu-ping and Guo, Zhan-jie and Liu, Hui},
  doi          = {10.1007/s12065-019-00229-2},
  journal      = {Evolutionary Intelligence},
  month        = {3},
  number       = {1},
  pages        = {51-58},
  shortjournal = {Evol. Intell.},
  title        = {Structure optimization method based on automatic vectorization},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Application of improved time series apriori algorithm by
frequent itemsets in association rule data mining based on temporal
constraint. <em>EI</em>, <em>13</em>(1), 39–49. (<a
href="https://doi.org/10.1007/s12065-019-00234-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The basic idea of Apriori algorithm is first introduced in this paper, which is to find all frequent sets in a transaction. The frequent requirements of these frequent sets are greater than or equal to the minimum support of the set. On this basis, the working principle of the traditional Apriori algorithm is analyzed, and the existing problems are pointed out. To solve these problems, an improved Apriori algorithm is proposed for time series of frequent itemsets. Finally, on the basis of analyzing the methods and processes of mining association rules for time series, this improved time series Apriori algorithm for frequent itemsets is applied to mining association rules based on time constraints. The experimental results show that the improved Apriori algorithm is better than the traditional one in storage space.},
  archive      = {J_EI},
  author       = {Wang, Chunxia and Zheng, Xiaoyue},
  doi          = {10.1007/s12065-019-00234-5},
  journal      = {Evolutionary Intelligence},
  month        = {3},
  number       = {1},
  pages        = {39-49},
  shortjournal = {Evol. Intell.},
  title        = {Application of improved time series apriori algorithm by frequent itemsets in association rule data mining based on temporal constraint},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Analysis of evolutionary process of fog computing system
based on BA and ER network hybrid model. <em>EI</em>, <em>13</em>(1),
33–38. (<a href="https://doi.org/10.1007/s12065-019-00225-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fog computing is oriented to the Internet of Things, which integrates network, computing, storage and application capabilities. It is a semi-virtualized distributed service computing paradigm. It extends data, data processing and applications to the edge of the network and provides intelligent services for users nearby. The purpose of this paper is to design a safe, stable and efficient fog computing model. On the basis of the structure of fog computing system, the evolution process of fog computing nodes is modeled based on BA scale-free network and ER stochastic network model. Then the evolution process of network hybrid model is analyzed. Finally, the evolution model of fog computing system is solved, and a network model with two network characteristics is obtained. Experiments show that the hybrid network model has the advantages of two basic networks.},
  archive      = {J_EI},
  author       = {Kang, Kunpeng},
  doi          = {10.1007/s12065-019-00225-6},
  journal      = {Evolutionary Intelligence},
  month        = {3},
  number       = {1},
  pages        = {33-38},
  shortjournal = {Evol. Intell.},
  title        = {Analysis of evolutionary process of fog computing system based on BA and ER network hybrid model},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Prediction of forest unit volume based on hybrid feature
selection and ensemble learning. <em>EI</em>, <em>13</em>(1), 21–32. (<a
href="https://doi.org/10.1007/s12065-019-00219-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the characteristics of forestry data with high dimensionality and complex samples, this paper explores an ensemble learning method suitable for predicting forest unit volume, which provides a scientific basis for forest resource management and decision-making. According to the real data provided by the National Forestry Science Data Sharing Service Platform, a FL-Stacking model based on hybrid feature selection and ensemble learning is proposed. Firstly, the model extracts features based on Filter-Lasso hybrid method, then constructs the prediction model of forest unit volume based on ensemble learning, and uses eight prediction models such as Linear SVM regression as the fusion basis model in the training set by Stacking scheme. The data are verified by 10 folds cross-validation. Finally, the fusion and optimization of the basic model are carried out. The experimental results show that the optimal accuracy of the single model is 83.81%, the multi-model predicted by FL-Stacking model is 84.55%, and the R2 value is increased by 0.74 percentage points. The comparative analysis results of different models on real data sets show that the FL-Stacking integrated prediction model proposed in this paper has a high accuracy in estimating forest unit volume, and has a great practical research value.},
  archive      = {J_EI},
  author       = {Wang, Jie and Xu, Jing and Peng, Yan and Wang, Hongpeng and Shen, Junhao},
  doi          = {10.1007/s12065-019-00219-4},
  journal      = {Evolutionary Intelligence},
  month        = {3},
  number       = {1},
  pages        = {21-32},
  shortjournal = {Evol. Intell.},
  title        = {Prediction of forest unit volume based on hybrid feature selection and ensemble learning},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An artificial fish swarm algorithm for a multi-objective
grain transportation problem. <em>EI</em>, <em>13</em>(1), 9–19. (<a
href="https://doi.org/10.1007/s12065-019-00228-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of grain transportation optimization is a typical NP-complete problem. To solve the problem, it is necessary to construct a mathematical model for the optimization of grain transportation. As the single-objective grain transportation route optimization model is difficult to better simulate the complex and varied conditions in real life, the multi-objective grain transportation route optimization model is closer to reality and has more guiding significance for practical problems. Therefore, this paper constructs a multi-objective grain transportation optimization problem model. And improved the artificial fish swarm algorithm to make it can be better solution. First, a similar fragment distance is introduced to replace the traditional distance calculation method. Second, we play the guiding role of bulletin board to insert the optimal solution fragment in the bulletin board into the current solution. Finally, according to the characteristics of food transportation problems, three behaviors of artificial fish were improved and mixed neighborhood search was conducted. In simulation experiments, the precision of the traditional artificial fish algorithm and improved algorithm is more and more low with the increase of amount of data. The difference between that and the optimal solution in the database is becoming more and more big, but the error in not only path length but also the number of vehicles of the improved algorithm is still within the scope of the permit. The error of the traditional artificial fish algorithm is far beyond permissible range. Experimental results show that the improved artificial fish swarm algorithm achieves high solution accuracy in path length and the number of vehicles. However, because there is no time window constraint, the conflict between the number of vehicle and the path length is very small. Finally, the set of Pareto solutions converges to 1 or 2 points.},
  archive      = {J_EI},
  author       = {Jia, Shiyu and Zhou, Kang and Zhou, Sisi and Fang, Haocheng and Zhen, Yiting and Zou, Yilin},
  doi          = {10.1007/s12065-019-00228-3},
  journal      = {Evolutionary Intelligence},
  month        = {3},
  number       = {1},
  pages        = {9-19},
  shortjournal = {Evol. Intell.},
  title        = {An artificial fish swarm algorithm for a multi-objective grain transportation problem},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improved normalized graph cut with generalized data for
enhanced segmentation in cervical cancer detection. <em>EI</em>,
<em>13</em>(1), 3–8. (<a
href="https://doi.org/10.1007/s12065-019-00226-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cervical cancer must be detected at an earlier stage since the late diagnosis reduces the probability of survival among the women population of the world. In this paper, improved normalized graph cut with generalized data for enhanced segmentation (INGC-GDES) mechanism was proposed for effective detection of the cytoplasm and nucleus boundary of the pap smear cell in order to detect the cervical cancer in an optimized manner. This proposed INGC-GDES approach is implemented over the pap smear cervix cells in order to analyze its hazy and overlapping boundaries for superior detection of cervical cancer cells. In this INGC-GDES approach, the preprocessed cervical image is converted into an improved normalized graph cut set for combining the merits of spatial and intensity information related to the processed image used for analysis. The method of maximum flow algorithm is applied over the derived normalized graph cut set for determining the optimal pixel points that aid in superior detection of cervical cancer. The results of the proposed INGC-GDES mechanism is determined to be predominant in enhancing the classification accuracy rate by 28% superior to the investigated graph cut-based segmentation approaches.},
  archive      = {J_EI},
  author       = {Rajarao, Ch. and Singh, R. P.},
  doi          = {10.1007/s12065-019-00226-5},
  journal      = {Evolutionary Intelligence},
  month        = {3},
  number       = {1},
  pages        = {3-8},
  shortjournal = {Evol. Intell.},
  title        = {Improved normalized graph cut with generalized data for enhanced segmentation in cervical cancer detection},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Guest editorial on s.i.: Bio-inspired computing: Theories
and application. <em>EI</em>, <em>13</em>(1), 1–2. (<a
href="https://doi.org/10.1007/s12065-020-00369-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EI},
  author       = {Zhao, Xinchao and Gong, Maoguo and Zuo, Xingquan and Pan, Linqiang},
  doi          = {10.1007/s12065-020-00369-w},
  journal      = {Evolutionary Intelligence},
  month        = {3},
  number       = {1},
  pages        = {1-2},
  shortjournal = {Evol. Intell.},
  title        = {Guest editorial on S.I.: bio-inspired computing: theories and application},
  volume       = {13},
  year         = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
