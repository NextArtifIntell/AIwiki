<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AAI_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="aai---57">AAI - 57</h2>
<ul>
<li><details>
<summary>
(2020). An effective way to large-scale robot-path-planning using a
hybrid approach of pre-clustering and greedy heuristic. <em>AAI</em>,
<em>34</em>(14), 1159–1175. (<a
href="https://doi.org/10.1080/08839514.2020.1824094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robot-path-planning seeks the shortest path to optimize the motion cost for robots. In robot-path-planning, the computational time will significantly increase if the moving targets rise largely, also known as the large-scale TSP. Hence, the current algorithms for the shortest path planning may be ineffective in the large-scale TSP. Aimed at the real-time applications that a robot must achieve as many goals as possible within limited time and the computational time of a robot has to be short enough to provide the next moving signal in time. Otherwise, the robot will be trapped into the idle status. This work proposes a hybrid approach, called the pre-clustering greedy heuristic, to tackle the reduction of computational time cost and achieve the near-optimal solutions. The proposed algorithm demonstrates how to lower the computational time cost drastically via smaller data of a sub-group, divided by k -means clustering, and the intra-cluster path planning. An algorithm is also developed to construct the nearest connections between any two unconnected clusters, ensuring the inter-cluster tour is the shortest. As a result, by utilizing the proposed heuristic, the computational time is significantly reduced and the path length is more efficient than the benchmark algorithms, while the input data grow up to a large scale. In applications, the proposed work can be applied practically to the path planning with large-scale moving targets, for example, the employment for the ball-collecting robot in a court.},
  archive      = {J_AAI},
  author       = {W. C. Wang and R. Chen},
  doi          = {10.1080/08839514.2020.1824094},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {14},
  pages        = {1159-1175},
  shortjournal = {Appl. Artif. Intell.},
  title        = {An effective way to large-scale robot-path-planning using a hybrid approach of pre-clustering and greedy heuristic},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bi-direction direct RGB-d visual odometry. <em>AAI</em>,
<em>34</em>(14), 1137–1158. (<a
href="https://doi.org/10.1080/08839514.2020.1824093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Direct visual odometry ( DVO ) is an important vision task which aims to obtain the camera motion via minimizing the photometric error across the different correlated images. However, the previous research on DVO rarely considered the motion bias and only calculated using single direction, therefore potentially ignoring useful information compared with leveraging diverse directions. We assume that jointly considering forward and backward calculation can improve the accuracy of pose estimation. To verify our assumption and solid this contribution, in this paper, we test various combination of direct dense methods, including different error metrics, e.g ., (intensity, gradient magnitude), alignment strategies (Forward-Compositional, Inverse-Compositional), and calculation directions (forward, backward, and bi-direction). We further study the issue of motion bias in RGB-D visual odometry and propose four strategy options to improve pose estimation accuracy, e.g ., joint bi-direction estimation; two stage bi-direction estimation; transform average with weights; and transform fusion with covariance. We demonstrate the effectiveness and efficiency of our proposed algorithms across a range of popular datasets, e.g ., TUM RGB-D and ICL-NUIM, in which we achieve an impressive performance through comparing with state of the art methods and provide benefits for existing RGB-D visual odometry and visual SLAM systems.},
  archive      = {J_AAI},
  author       = {Jiyuan Cai and Lingkun Luo and Shiqiang Hu},
  doi          = {10.1080/08839514.2020.1824093},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {14},
  pages        = {1137-1158},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Bi-direction direct RGB-D visual odometry},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Predicting calorific value of thar lignite deposit: A
comparison between back-propagation neural networks (BPNN), gradient
boosting trees (GBT), and multiple linear regression (MLR).
<em>AAI</em>, <em>34</em>(14), 1124–1136. (<a
href="https://doi.org/10.1080/08839514.2020.1824091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Calorific value provides a strong measure of useful energy during coal utilization. Previously, different AI techniques have been used for the prediction of calorific value; however, one model is not valid for all geographic locations. In this research, Lower Calorific Value (LCV) of the Thar coal region in Pakistan is predicted from proximate analysis of 693 drill holes extending to 9,000 sq. km. Researchers have applied different techniques to produce the best model for prediction of calorific value; however, Gradient Boosting Trees (GBT) has not been used for this purpose. A comparison of GBT, Back-propagation Neural Networks (BPNN), and Multiple Linear Regression (MLR) is presented to predict the calorific value from a total of 8,039 samples with 1 m support interval. The samples were split randomly into 70:15:15 for training, testing, and validation of GBT, BPNN, and MLR models, reporting correlations of 0.90, 0.89, and 0.80, respectively. The features’ importance was reported by the intuitive and best-performing GBT model in decreasing order of importance as: Volatile Matter, Fixed Carbon, Moisture, and Ash with corresponding feature importance values of 0.50, 0.30, 0.12, and 0.08.},
  archive      = {J_AAI},
  author       = {Waqas Ahmed and Khan Muhammad and Fahad Irfan Siddiqui},
  doi          = {10.1080/08839514.2020.1824091},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {14},
  pages        = {1124-1136},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Predicting calorific value of thar lignite deposit: A comparison between back-propagation neural networks (BPNN), gradient boosting trees (GBT), and multiple linear regression (MLR)},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Automatic tongue delineation from MRI images with a
convolutional neural network approach. <em>AAI</em>, <em>34</em>(14),
1115–1123. (<a
href="https://doi.org/10.1080/08839514.2020.1824090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tongue contour extraction from real-time magnetic resonance images is a nontrivial task due to the presence of artifacts manifesting in form of blurring or ghostly contours. In this work, we present results of automatic tongue delineation achieved by means of U-Net auto-encoder convolutional neural network. We present both intra- and inter-subject validation. We used real-time magnetic resonance images and manually annotated 1-pixel wide contours as inputs. Predicted probability maps were post-processed in order to obtain 1-pixel wide tongue contours. The results are very good and slightly outperform published results on automatic tongue segmentation.},
  archive      = {J_AAI},
  author       = {Karyna Isaieva and Yves Laprie and Nicolas Turpault and Alexis Houssard and Jacques Felblinger and Pierre-André Vuissoz},
  doi          = {10.1080/08839514.2020.1824090},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {14},
  pages        = {1115-1123},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Automatic tongue delineation from MRI images with a convolutional neural network approach},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An evaluation of machine learning techniques to predict the
outcome of children treated for hodgkin-lymphoma on the AHOD0031 trial.
<em>AAI</em>, <em>34</em>(14), 1100–1114. (<a
href="https://doi.org/10.1080/08839514.2020.1815151">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this manuscript, we analyze a data set containing information on children with Hodgkin Lymphoma (HL) enrolled on a clinical trial. Treatments received and survival status were collected together with other covariates such as demographics and clinical measurements. Our main task is to explore the potential of machine learning (ML) algorithms in a survival analysis context in order to improve over the Cox Proportional Hazard (CoxPH) model. We discuss the weaknesses of the CoxPH model we would like to improve upon and then we introduce multiple algorithms, from well-established ones to state-of-the-art models, that solve these issues. We then compare every model according to the concordance index and the Brier score. Finally, we produce a series of recommendations, based on our experience, for practitioners that would like to benefit from the recent advances in artificial intelligence.},
  archive      = {J_AAI},
  author       = {Cédric Beaulac and Jeffrey S. Rosenthal and Qinglin Pei and Debra Friedman and Suzanne Wolden and David Hodgson},
  doi          = {10.1080/08839514.2020.1815151},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {14},
  pages        = {1100-1114},
  shortjournal = {Appl. Artif. Intell.},
  title        = {An evaluation of machine learning techniques to predict the outcome of children treated for hodgkin-lymphoma on the AHOD0031 trial},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Handwritten digit classification in bangla and hindi using
deep learning. <em>AAI</em>, <em>34</em>(14), 1074–1099. (<a
href="https://doi.org/10.1080/08839514.2020.1804228">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Handwritten digit classification is a well-known and important problem in the field of optical character recognition (OCR). The primary challenge is correctly classifying digits which are highly varied in their visual characteristics primarily due to the writing styles of different individuals. In this paper, we propose the use of Convolutional Neural Networks (CNN) for the purpose of classifying handwritten Bangla and Hindi numerals. The major advantage that we face by using a CNN-based classifier is that no prior hand-crafted feature needs to be extracted from the images for efficient and accurate classification. An added benefit of a CNN classifier is that it provides translational invariance and a certain extent of rotational invariance during recognition. Applications can be found in real-time OCR systems where input images are often not perfectly oriented along a vertical axis. In this work, we use modified versions of the well-known LeNet CNN architecture. Extensive experiments have revealed a best-case classification accuracy of 98.2% for Bangla and 98.8% for Hindi numerals outperforming competitive models in the literature.},
  archive      = {J_AAI},
  author       = {Jishnu Mukhoti and Sukanya Dutta and Ram Sarkar},
  doi          = {10.1080/08839514.2020.1804228},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {14},
  pages        = {1074-1099},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Handwritten digit classification in bangla and hindi using deep learning},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep learning technique based surveillance video analysis
for the store. <em>AAI</em>, <em>34</em>(14), 1055–1073. (<a
href="https://doi.org/10.1080/08839514.2020.1784611">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {AI technology has developed so fast, and it has been applied to the commercial area. In order to predict the customer preference and adjust the placement of product or advertisement, etc., the intelligent surveillance video analysis technique has been proposed to gather the sufficient customer information and realize crowd counting and density map drawing. In this paper, a series of deep learning techniques are adopted to realize surveillance video analysis. This work covers different subproblems such as object detection, tracking and human identification. A skeleton recognition algorithm is adopted instead of object detection algorithm to overcome the severe occlusion problem. A multiple human tracking algorithm combing the human re-identification technology is adopted to realize the human tracking and counting. Finally, the density map and statistics information are obtained which can be used to evaluate and adjust the current business plan. A real store surveillance video is analyzed by the algorithm, and the results show the advantage of the algorithm.},
  archive      = {J_AAI},
  author       = {Qingyang Xu and Wanqiang Zheng and Xiaoxiao Liu and Punan Jing},
  doi          = {10.1080/08839514.2020.1784611},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {14},
  pages        = {1055-1073},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Deep learning technique based surveillance video analysis for the store},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel basketball result prediction model using a
concurrent neuro-fuzzy system. <em>AAI</em>, <em>34</em>(13), 1038–1054.
(<a href="https://doi.org/10.1080/08839514.2020.1804229">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Including uncertainties such as the performance of the teams, player performance indicators, and the quality of the competitors, there are numerous factors affecting the result of a game. Therefore, prediction of the game results is quite a complicated and a conspicuous research problem. Various artificial intelligence models were developed in order to solve this problem. By drawing together the advantageous sides of various artificial methods, this study aims to develop a hybrid intelligent system in order to better predict the result of a basketball game. Firstly, a prediction model was developed via artificial neural network (ANN), which is frequently used in game result predictions. The success of this developed ANN model in predicting the result of the game was 70.8%. In order to increase this success rate, a new concurrent neuro fuzzy system (CNFS) was suggested which was combined with fuzzy logic system that determined whether the team was favorite. The accurate prediction rate increased to 79.2% via this suggested CNFS model. Moreover, the results of the models developed were compared with each other and previous studies predicting the game results. As the conclusion of the comparisons, it was observed that CNFS model had a remarkable talent in predicting the game results.},
  archive      = {J_AAI},
  author       = {Ilker Ali Ozkan},
  doi          = {10.1080/08839514.2020.1804229},
  journal      = {Applied Artificial Intelligence},
  month        = {11},
  number       = {13},
  pages        = {1038-1054},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A novel basketball result prediction model using a concurrent neuro-fuzzy system},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An effective approach for noise robust and rotation
invariant handwritten character recognition using zernike moments
features and optimal similarity measure. <em>AAI</em>, <em>34</em>(13),
1011–1037. (<a
href="https://doi.org/10.1080/08839514.2020.1796370">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zernike moments (ZMs) are very effective orthogonal rotation invariant moments. Conventionally, the magnitudes of ZMs are used as feature descriptors and the Euclidean distance is used as a classifier. Recently, a few classifiers based on ZM magnitude and phase have been developed which are reported to be very effective in pattern matching problems. One such a recently developed similarity measure, known as optimal similarity measure, is known to provide very good performance over the ZM magnitude-based Euclidean distance measure in pattern recognition problems, especially under noisy conditions. In this paper, we investigate the conventional magnitude-based similarity measure and the new similarity measures including the optimal similarity measure and compare their performance on segmented handwritten characters and numerals. It is observed that the performance of optimal similarity measure is far better than all other similarity measures. Its performance is very much better than other similarity measures even under very high noisy condition. However, it is slow owing to the optimization of the process involved in its computation. Therefore, we also propose a fast algorithm for its computation and reduce its time complexity. Detailed experimental results are provided to support the above observations.},
  archive      = {J_AAI},
  author       = {Chandan Singh and Ashutosh Aggarwal},
  doi          = {10.1080/08839514.2020.1796370},
  journal      = {Applied Artificial Intelligence},
  month        = {11},
  number       = {13},
  pages        = {1011-1037},
  shortjournal = {Appl. Artif. Intell.},
  title        = {An effective approach for noise robust and rotation invariant handwritten character recognition using zernike moments features and optimal similarity measure},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Optimal sizing of recycling folded cascode amplifier for
low frequency applications using new hybrid swarm intelligence-based
technique. <em>AAI</em>, <em>34</em>(13), 994–1010. (<a
href="https://doi.org/10.1080/08839514.2020.1795786">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new efficient design approach for sizing a high performance analog amplifier circuit namely the Recycling Folded Cascode (RFC) amplifier is presented. A RFC amplifier is an enhanced version of the conventional folded cascode amplifier and achieves better slew rate, gain, bandwidth, offset etc. for same area and power budget. Low frequency amplifiers such as biomedical or neural have a demanding requirement of low area, low power and low noise apart from meeting other optimal design specifications which have inherent trade-off amongst themselves. As a result, manual sizing becomes a computationally inefficient approach. Thus, swarm based optimization techniques have been employed to efficiently determine the optimal sizing for the RFC amplifier such that the area is minimized while meeting all the optimal design specifications considering the constraints. A new hybrid whale particle swarm optimization (HWPSO) algorithm is employed which takes advantage of the good qualities of both the whale algorithm and the PSO algorithm to optimize the area with less computational complexity. Simulations and statistical analysis have been performed and comparisons with other state of art algorithms reveals that HWPSO-based approach achieves a minimum circuit area of 21 µm 2 with a mean Friedman’s statistical rank of 2.05 while meeting optimal design specifications for low frequency systems. Finally, validation with circuit design tool Cadence Virtuoso is done and pre as well as post layout analysis have been performed which further illustrated a close agreement with algorithmic results.},
  archive      = {J_AAI},
  author       = {Naushad Manzoor Laskar and Koushik Guha and Sourav Nath and K.L. Baishnab and P.K. Paul},
  doi          = {10.1080/08839514.2020.1795786},
  journal      = {Applied Artificial Intelligence},
  month        = {11},
  number       = {13},
  pages        = {994-1010},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Optimal sizing of recycling folded cascode amplifier for low frequency applications using new hybrid swarm intelligence-based technique},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Transfer learning-based framework for classification of pest
in tomato plants. <em>AAI</em>, <em>34</em>(13), 981–993. (<a
href="https://doi.org/10.1080/08839514.2020.1792034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pest in the plant is a major challenge in the agriculture sector. Hence, early and accurate detection and classification of pests could help in precautionary measures while substantially reducing economic losses. Recent developments in deep convolutional neural network (CNN) have drastically improved the accuracy of image recognition systems. In this paper, we have presented a transfer learning of pre-trained deep CNN-based framework for classification of pest in tomato plants. The dataset for this study has been collected from online sources that consist of 859 images categorized into 10 classes. This study is first of its kind where: (i) dataset with 10 classes of tomato pest are involved; (ii) an exhaustive comparison of the performance of 15 pre-trained deep CNN models has been presented on tomato pest classification. The experimental results show that the highest classification accuracy of 88.83% has been obtained using DenseNet169 model. Further, the encouraging results of transfer learning-based models demonstrate its effectiveness in pest detection and classification tasks.},
  archive      = {J_AAI},
  author       = {Gayatri Pattnaik and Vimal K. Shrivastava and K. Parvathi},
  doi          = {10.1080/08839514.2020.1792034},
  journal      = {Applied Artificial Intelligence},
  month        = {11},
  number       = {13},
  pages        = {981-993},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Transfer learning-based framework for classification of pest in tomato plants},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evolino recurrent neural network ensemble for speculation in
exchange market in time of anomalies. <em>AAI</em>, <em>34</em>(13),
957–980. (<a
href="https://doi.org/10.1080/08839514.2020.1790249">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sharp falls or explosive growths in exchange markets, whether expected or not, generates new challenges for investors who want to protect their investments or achieve an optimum benefit during and after the turmoil. An anomaly of the exchange market, instigated by the Swiss National Bank, occurred when the Swiss Franc decoupled from the euro unexpectedly. The United Kingdom (UK) vote to withdraw from the European Union (Brexit), in contrast, was feared but expected. A comparison of the consequences of the anomalies gives us an unprecedented opportunity to investigate prediction capabilities of the EVOLINO Recurrent Neural Network Ensemble (ERNN) model following an anomaly. By introducing this new information to the ERNN model and analyzing its response, we increase investor resources during large exchange rate fluctuations; this will provide them with additional information that will help them construct different portfolios. Reaction to the anomaly was visible only after the anomaly occurred, this is when the model began to acquire data influenced by the extreme change. Comparing different strategies which are related or unrelated to the anomaly and orthogonal or not orthogonal for conservative, moderate, or aggressive trading shows that in order to profit from the anomaly, speculation depends on prediction-accuracy and on the sets of exchange-rate associated with the anomaly.},
  archive      = {J_AAI},
  author       = {Nijolė Maknickienė and Algirdas Maknickas},
  doi          = {10.1080/08839514.2020.1790249},
  journal      = {Applied Artificial Intelligence},
  month        = {11},
  number       = {13},
  pages        = {957-980},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Evolino recurrent neural network ensemble for speculation in exchange market in time of anomalies},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bank CRM optimization using predictive classification based
on the support vector machine method. <em>AAI</em>, <em>34</em>(12),
941–955. (<a
href="https://doi.org/10.1080/08839514.2020.1790248">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a predictive approach to segmenting credit card users, based on their value to the bank. The approach combines the Recency, Frequency and Monetary (RFM) method, clustering using the k -means method, and predictive classification by the Support Vector Machine (SVM) method. Clustering by non-encoded RFM attributes overcomes the subjectivity in selecting the number of segments and losing information (small differences in the values of these attributes) which are problems of classic RFM segmentation. In order to overcome the problem of class imbalance in predictive classification (which occurs due to the small number of valuable customers), the Support Vector Machine (SVM) method was applied as a pre-processor of data due to its extraordinary generalization capabilities. The end result of predictive classification should be a set of rules that describes the identified customer segments in order to tailor the offer to each segment individually. The extraction of rules from the SVM output was achieved using the Decision Tree (DT) classification method. Using a proposed approach that addresses the issue of the small class, marketing managers can more effectively target the most valuable customers, thereby increasing revenue, but also reducing unnecessary costs due to wrongly targeted valuable clients.},
  archive      = {J_AAI},
  author       = {Vladimir Djurisic and Ljiljana Kascelan and Suncica Rogic and Boban Melovic},
  doi          = {10.1080/08839514.2020.1790248},
  journal      = {Applied Artificial Intelligence},
  month        = {10},
  number       = {12},
  pages        = {941-955},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Bank CRM optimization using predictive classification based on the support vector machine method},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Estimating forest losses using spatio-temporal pattern-based
sequence classification approach. <em>AAI</em>, <em>34</em>(12),
916–940. (<a
href="https://doi.org/10.1080/08839514.2020.1790247">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consistent forest loss estimates are important to enforce forest management regulations. In Tunisia, recent evidence has suggested that the deforestation rate is increasing, especially since the 2011’s Revolution. However, no spatially explicit data on the extent of deforestation before and after the Revolution exists. Here, we quantify deforestation in the country for the period 2001–2014 and we propose a novel spatio-temporal pattern-based sequence classification framework for forest loss estimation. To do so, expert knowledge and spatial techniques are applied to identify deforestation drivers. Then, we adopt sequential pattern mining to extract sets of patterns sharing similar spatiotemporal behavior. The sequence miner generates multidimensional-closed sequential patterns at different time granularities. Then, a discriminative filter is employed to decide on patterns to use as relevant classification features. Lastly, the classifier is trained using random forest and shows an improved result.},
  archive      = {J_AAI},
  author       = {Ahmed Toujani and Hammadi Achour and Sami Yassine Turki and Sami Faïz},
  doi          = {10.1080/08839514.2020.1790247},
  journal      = {Applied Artificial Intelligence},
  month        = {10},
  number       = {12},
  pages        = {916-940},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Estimating forest losses using spatio-temporal pattern-based sequence classification approach},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A classification model for predicting fetus with down
syndrome – a study from turkey. <em>AAI</em>, <em>34</em>(12), 898–915.
(<a href="https://doi.org/10.1080/08839514.2020.1790246">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The triple test is a screening test (blood test) used to calculate the probability of a pregnant woman having a fetus that has a chromosomal abnormality like Down Syndrome (DS). AFP (Alpha-Fetoprotein), hCG (Human Chorionic Gonadotropin), and uE3 (Unconjugated Estriol) values in the blood sample of pregnant women are computed and compared with the similar real records where the outputs (healthy fetus or a fetus with DS) are actually known. The likelihood of the indicators is used to calculate the probability of having a fetus with chromosomal abnormality like DS. However, high false positive rate of the triple test has been a problematic issue. One of the reasons of the high false positives is the differences in the norm values of indicators for the pregnant women from different geographical regions of a country. We use 81 patient records retrieved from Şahinbey Training and Research Hospital of Gaziantep University; Turkey. In our study, nine different classification algorithms were trained based on triple test indicators. Multilayer perceptron outperformed with 94.24% detection rate and 13% false positive rate. The multilayer perceptron can predict the outcome of triple test with a high level of accuracy and fewer patients are suggested for amniocentesis. This study is the first study using the MLP model for Turkish triple test data. Regional MLP models can eliminate the bias due to local biological differences.},
  archive      = {J_AAI},
  author       = {Alptekin Durmuşoğlu and Memet Merhad Ay and Zeynep Didem Unutmaz Durmuşoğlu},
  doi          = {10.1080/08839514.2020.1790246},
  journal      = {Applied Artificial Intelligence},
  month        = {10},
  number       = {12},
  pages        = {898-915},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A classification model for predicting fetus with down syndrome – a study from turkey},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Optimal sizing of recycling folded cascode amplifier for
low-frequency applications using new hybrid swarm intelligence-based
technique. <em>AAI</em>, <em>34</em>(12), 880–897. (<a
href="https://doi.org/10.1080/08839514.2020.1790163">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new efficient design approach for sizing a high-performance analog amplifier circuit namely the recycling folded cascode (RFC) amplifier is presented. An RFC amplifier is an enhanced version of the conventional folded cascode amplifier and achieves better slew rate, gain, bandwidth, offset, etc. for same area and power budget. Low-frequency amplifiers such as biomedical or neural have a demanding requirement of low area, low power, and low noise apart from meeting other optimal design specifications which have inherent trade-off among themselves. As a result, manual sizing becomes a computationally inefficient approach. Thus, swarm-based optimization techniques have been employed to efficiently determine the optimal sizing for the RFC amplifier such that the area is minimized while meeting all the optimal design specifications considering the constraints. A new hybrid whale particle swarm optimization (HWPSO) algorithm is employed which takes advantage of the good qualities of both the whale algorithm and the PSO algorithm to optimize the area with less computational complexity. Simulations and statistical analysis have been performed and comparisons with other state of art algorithms reveals that HWPSO-based approach achieves a minimum circuit area of 21 µm 2 with a mean Friedman’s statistical rank of 2.05 while meeting optimal design specifications for low-frequency systems. Finally, validation with circuit design tool Cadence Virtuoso is done and pre- as well as postlayout analysis have been performed which further illustrated a close agreement with algorithmic results.},
  archive      = {J_AAI},
  author       = {Naushad Manzoor Laskar and Koushik Guha and Sourav Nath and K.L. Baishnab and P.K. Paul},
  doi          = {10.1080/08839514.2020.1790163},
  journal      = {Applied Artificial Intelligence},
  month        = {10},
  number       = {12},
  pages        = {880-897},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Optimal sizing of recycling folded cascode amplifier for low-frequency applications using new hybrid swarm intelligence-based technique},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Moving medical image analysis to GPU embedded systems:
Application to brain tumor segmentation. <em>AAI</em>, <em>34</em>(12),
866–879. (<a
href="https://doi.org/10.1080/08839514.2020.1787678">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growth of medical data stored as bases for researches and diagnosis tasks, healthcare providers are in need of automatic processing methods to make accurate and fast image analysis such as segmentation or restoration. Most of the existing solutions to deal with these tasks are based on Deep Learning methods that require the use of powerful dedicated hardware to be executed and address a power consumption problem that is not compatible with the aforementioned requests. There is thus a demand in the development of low-cost image analysis systems with increased performances. In this work, we address this problem by proposing a fully-automatic brain tumor segmentation method based on a Convolutional Neural Network, executed by a low-cost, Deep Learning ready GPU embedded platform. We validated our approach using the BRaTS 2015 dataset to segment brain tumors and proved that an artificial neural network can be trained and used in the medical field with limited resources by redefining some of its inner operations.},
  archive      = {J_AAI},
  author       = {Brad Niepceron and Ahmed Nait-Sidi-Moh and Filippo Grassia},
  doi          = {10.1080/08839514.2020.1787678},
  journal      = {Applied Artificial Intelligence},
  month        = {10},
  number       = {12},
  pages        = {866-879},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Moving medical image analysis to GPU embedded systems: Application to brain tumor segmentation},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel method of curve fitting based on optimized extreme
learning machine. <em>AAI</em>, <em>34</em>(12), 849–865. (<a
href="https://doi.org/10.1080/08839514.2020.1787677">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we present a new method based on extreme learning machine (ELM) algorithm for solving nonlinear curve fitting problems. Curve fitting is a computational problem in which we seek an underlying target function with a set of data points given. We proposed that the unknown target function is realized by an ELM with introducing an additional linear neuron to correct the localized behavior caused by Gaussian type neurons. The number of hidden layer neurons of ELM is a crucial factor to achieve a good performance. An evolutionary computation algorithm–particle swarm optimization (PSO) technique is applied to determine the optimal number of hidden nodes. Several numerical experiments with benchmark datasets, simulated spectral data and measured data from high energy physics experiments have been conducted to test the proposed method. Accurate fitting has been accomplished for various tough curve fitting tasks. Comparing with the results of other methods, the proposed method outperforms the traditional numerical-based technique. This work clearly demonstrates that the classical numerical analysis problem-curve fitting can be satisfactorily resolved via the approach of artificial intelligence.},
  archive      = {J_AAI},
  author       = {Michael Li and Lily D. Li},
  doi          = {10.1080/08839514.2020.1787677},
  journal      = {Applied Artificial Intelligence},
  month        = {10},
  number       = {12},
  pages        = {849-865},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A novel method of curve fitting based on optimized extreme learning machine},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Identifying significance of product features on customer
satisfaction recognizing public sentiment polarity: Analysis of smart
phone industry using machine-learning approaches. <em>AAI</em>,
<em>34</em>(11), 832–848. (<a
href="https://doi.org/10.1080/08839514.2020.1787676">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The reality about human behavior is that how other people think and evaluate have strong influences on our beliefs and thinking. Consumers get rich information from online reviews that may reduce their uncertainty regarding purchases. Besides, product-developing companies analyze user demands from online reviews to design market-driven product. In this study, a comparison among five major market share holder smart phone brands - Samsung, Apple, Huawei, Xiaomi, and Oppo is performed in different price categories - high, mid, and low range, based on sentiment polarity score. Online public reviews are extracted and sentiment scores of reviews are calculated to construct public sentiment polarity toward the famous brands. By examining both quantitative and qualitative methodologies, we identified the most important smart phone features or attributes that have great significance on consumer satisfaction. By experimenting and comparing five efficient machine-learning algorithms in predicting sentiment polarity and three feature selection algorithms in reducing attributes, an optimal set of 21 smart phone attributes was found those play major roles in determining customer satisfaction.},
  archive      = {J_AAI},
  author       = {Md. Niaz Imtiaz and Md. Khaled Ben Islam},
  doi          = {10.1080/08839514.2020.1787676},
  journal      = {Applied Artificial Intelligence},
  month        = {9},
  number       = {11},
  pages        = {832-848},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Identifying significance of product features on customer satisfaction recognizing public sentiment polarity: Analysis of smart phone industry using machine-learning approaches},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). LoCAR – low-cost autonomous robot for object detection with
voice command and MobileNets. <em>AAI</em>, <em>34</em>(11), 816–831.
(<a href="https://doi.org/10.1080/08839514.2020.1782004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work details the design, construction, implementation and testing of a standalone robot, based on a convolutional neural network, which receives a voice command, searches and recognizes the target through its camera and moves to the object or person properly recognized. The success rate for the recognition stage has reached 82% in the median for objects tested, 100% for chairs, bottles and people. The processing was performed on a Raspberry Pi 3 B board integrated with an Arduino UNO to control the actuators.},
  archive      = {J_AAI},
  author       = {Cristiano Guilherme De Souza Silva and Yuri Souza Padua and Siovani Cintra Felipussi},
  doi          = {10.1080/08839514.2020.1782004},
  journal      = {Applied Artificial Intelligence},
  month        = {9},
  number       = {11},
  pages        = {816-831},
  shortjournal = {Appl. Artif. Intell.},
  title        = {LoCAR – low-cost autonomous robot for object detection with voice command and MobileNets},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal input variables disposition of artificial neural
networks models for enhancing time series forecasting accuracy.
<em>AAI</em>, <em>34</em>(11), 792–815. (<a
href="https://doi.org/10.1080/08839514.2020.1782003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Neural Networks (ANNs) models play an increasingly significant role in accurate time series prediction tools. However, an accurate time series forecasting using ANN requires an optimal model. Hence, great forecasting methods have been developed from optimized ANN models. Most of them focus more on input variables selection and preprocessing, topologies selection, optimum configuration and its associated parameters regardless of their input variables disposition. This paper provides an investigation of the effects of input variables disposition on ANNs models on training and forecasting performances. After investigation, a new ANNs optimization approach is proposed, consisting of finding optimal input variables disposition from the possible combinations. Therefore, a modified Back-Propagation neural networks training algorithm is presented in this paper. This proposed approach is applied to optimize the feed-forward and recurrent neural networks architectures; both built using traditional techniques, and pursuing to forecast the wind speed. Furthermore, the proposed approach is tested in a collaborative optimization method with single-objective optimization technique. Thus, Genetic Algorithm Back-Propagation neural networks aim to improve the forecasting accuracy relative to traditional methods was proposed. The experiment results demonstrate the requirement to take into consideration the input variables disposition to build a more optimal ANN model. They reveal that each proposed model is superior to its old considered model in terms of forecasting accuracy and thus show that the proposed optimization approach can be useful for time series forecasting accuracy improvement.},
  archive      = {J_AAI},
  author       = {Hervice Roméo Fogno Fotso and Claude Vidal Aloyem Kazé and Germaine Djuidje Kenmoe},
  doi          = {10.1080/08839514.2020.1782003},
  journal      = {Applied Artificial Intelligence},
  month        = {9},
  number       = {11},
  pages        = {792-815},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Optimal input variables disposition of artificial neural networks models for enhancing time series forecasting accuracy},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Detection of compromised online social network account with
an enhanced knn. <em>AAI</em>, <em>34</em>(11), 777–791. (<a
href="https://doi.org/10.1080/08839514.2020.1782002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The primary threat to online social network (OSN) users is account compromisation. The challenge in detecting a compromised account is due to the trusted relationship established between the account owners, their friends, and the service providers. The available research which focuses on using machine learning has limitations with human experts involved in feature selection and a standardized dataset. The paper discusses users` various behaviors of users of OSN and the up-to-date approaches in detecting a compromised OSN account with emphasis on the limitations and challenges. Furthermore, we propose an enhanced machine learning approach Word Embedding and KNN (WE-KNN), which addresses the limitations faced by the previous techniques used. We detailed our proposed WE-KNN for feature extraction, selection of behavior of OSN users, and classification. Our proposed model is evaluated using the standard benchmark datasets, namely KDD Cup ‘99 and NSL-KDD and implemented it in WEKA. Besides, we used state-of-the-art evaluation metrics to assess the performance of our model. The results obtained depicts that the proposed approach in compromise account detection performs better.},
  archive      = {J_AAI},
  author       = {Edward Kwadwo Boahen and Wang Changda and Bouya-Moko Brunel Elvire},
  doi          = {10.1080/08839514.2020.1782002},
  journal      = {Applied Artificial Intelligence},
  month        = {9},
  number       = {11},
  pages        = {777-791},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Detection of compromised online social network account with an enhanced knn},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Grade level of lignite coal datas in the different areas
with decison tree, random forest, and discriminant analysis methods.
<em>AAI</em>, <em>34</em>(11), 755–776. (<a
href="https://doi.org/10.1080/08839514.2020.1783849">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lignite is one of the most important energy sources. An important problem in the economic and technical evaluation of lignite reserves is to measure lignite quality. The quality of lignite depends on some parameters such as moisture, ash, sulfur, and calorific values. The assessment of the parameters has a critical importance. The lignite data obtained from Kalburçayı area of the Sivas-Kangal Basin (SKKB) and the dataset in the Turkey Lignite Inventory (TLI) were used in this article. In addition to the average values given in TLI, another set (SKKB), which beyond the inventory, has been employed. By this way, comparable data were created for performing the modeling and classification work. To make lignite quality classification, a study was performed in five steps. In the first step, the calorific values have been used for verification by the k-means method. The coal lignite data are seperated into two groups, low and high quality. In the second step, wavelet families have been applied to the properties of moisture, ash, and sulfur regulated in the first step. The applied wavelet families such as haar, daubechies, symlet, biorspline, and reversebiorspline were used and the approximate coefficients produced by wavelet families have been obtained. In the third step, the features obtained in the second step have been given to random forest, discriminant analysis, and decision tree classifiers as input. In the next step, the quality classification performances have been compared for lignite coal data derived from SKKB and TLI. While the highest quality classification performance of lignite coals in the SKKB area has been found as 93.75%, the highest quality classification performance for lignite coals obtained from TLI has been found about 100%. In the final step, the success rates provided in this study have been compared with the conventional applications in literature. The results showed that the success rates of classification recorded by the proposed method better performs than the studies used for the comparison. Because this study addresses a hybrid work, more transparent and flexible classification structures can be provided. Making an effective and reliable classification between high and low lignite calorifics can provide some possibilities for decision-makers.},
  archive      = {J_AAI},
  author       = {Sevcan Aytaç Korkmaz},
  doi          = {10.1080/08839514.2020.1783849},
  journal      = {Applied Artificial Intelligence},
  month        = {9},
  number       = {11},
  pages        = {755-776},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Grade level of lignite coal datas in the different areas with decison tree, random forest, and discriminant analysis methods},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Effective context-aware recommendations based on context
weighting using genetic algorithm and alleviating data sparsity.
<em>AAI</em>, <em>34</em>(10), 730–753. (<a
href="https://doi.org/10.1080/08839514.2020.1775011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Context-aware collaborative filtering (CACF) is an effective approach for adapting recommendations under users’ specific contextual situations and aims to improve predictive accuracy for Context-aware recommender systems (CARSs). Incorporating context in recommender systems (RSs) considering the equal importance to all contextual dimensions is not appropriate for seeking an intelligent and useful recommendation. In this paper, we propose a Real-coded Genetic Algorithm (RCGA) based CARS framework that exploits contextual pre-filtering and contextual modeling paradigms into CACF with appropriate context feature weights for enhancing accuracy as well as the diversity of the recommendation list. Further to alleviate the data sparsity, an effective missing value prediction (EMVP) algorithm is applied into proposed framework. The accuracy based on RCGA is compared with other two schemes: Support Vector Machine (SVM) and Particle Swarm Optimization (PSO), and RCGA has shown better results. Experimental results based on real-world datasets have clearly established the effectiveness of our proposed CARS schemes.},
  archive      = {J_AAI},
  author       = {Sonal Linda and Sonajharia Minz and K.K. Bharadwaj},
  doi          = {10.1080/08839514.2020.1775011},
  journal      = {Applied Artificial Intelligence},
  month        = {8},
  number       = {10},
  pages        = {730-753},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Effective context-aware recommendations based on context weighting using genetic algorithm and alleviating data sparsity},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-agent cooperation for an active perception based on
driving behavior: Application in a car-following behavior. <em>AAI</em>,
<em>34</em>(10), 710–729. (<a
href="https://doi.org/10.1080/08839514.2020.1771837">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Perception is presented as a predominant concern in the functioning of a driving system, where it is necessary to understand how the information, events, and actions of each influence the state of the environment and the objectives of the driver, immediately and in the near future. In this context, we present in this paper a driving model composed of five layers which ensure the autonomy and road safety of a driver agent, in particular, we are interested in this article in the concept of perception which is translated by the first three layers of our driving model, which are: visual perception, comprehension and projection, where the execution of these three layers is based on the driving behavior adopted by the driver agent, which is in our case the car-following driving behavior. Furthermore, we present in this paper two simulation scenarios, the first one is realized based on urban area conditions, and the second one is conducted by using Next Generation SIMulation (NGSIM) dataset of a highway in Los Angeles, California. In this context, the experimental results present the effectiveness of our driving model based on the imitation of human behavior and according to reducing the duration of perception.},
  archive      = {J_AAI},
  author       = {Anouer Bennajeh and Slim Bechikh and Lamjed Ben Said and Samir Aknine},
  doi          = {10.1080/08839514.2020.1771837},
  journal      = {Applied Artificial Intelligence},
  month        = {8},
  number       = {10},
  pages        = {710-729},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Multi-agent cooperation for an active perception based on driving behavior: Application in a car-following behavior},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An analysis of fast learning methods for classifying forest
cover types. <em>AAI</em>, <em>34</em>(10), 691–709. (<a
href="https://doi.org/10.1080/08839514.2020.1771523">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Proper mapping and classification of Forest cover types are integral in understanding the processes governing the interaction mechanism of the surface with the atmosphere. In the presence of massive satellite and aerial measurements, a proper manual categorization has become a tedious job. In this study, we implement three different modest machine learning classifiers along with three statistical feature selectors to classify different cover types from cartographic variables. Our results showed that, among the chosen classifiers, the standard Random Forest Classifier together with Principal Components performs exceptionally well, not only in overall assessment but across all seven categories. Our results are found to be significantly better than existing studies involving more complex Deep Learning models.},
  archive      = {J_AAI},
  author       = {Hugo Sjöqvist and Martin Längkvist and Farrukh Javed},
  doi          = {10.1080/08839514.2020.1771523},
  journal      = {Applied Artificial Intelligence},
  month        = {8},
  number       = {10},
  pages        = {691-709},
  shortjournal = {Appl. Artif. Intell.},
  title        = {An analysis of fast learning methods for classifying forest cover types},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Short-term demand forecasting for online car-hailing
services using recurrent neural networks. <em>AAI</em>, <em>34</em>(9),
674–689. (<a
href="https://doi.org/10.1080/08839514.2020.1771522">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short-term traffic flow prediction is one of the crucial issues in intelligent transportation system, which is an important part of smart cities. Accurate predictions can enable both the drivers and the passengers to make better decisions about their travel route, departure time, and travel origin selection, which can be helpful in traffic management. Multiple models and algorithms based on time-series prediction and machine learning were applied to this issue and achieved acceptable results. Recently, the availability of sufficient data and computational power motivates us to improve the prediction accuracy via deep-learning approaches. Recurrent neural networks have become one of the most popular methods for time-series forecasting; however, due to the variety of these networks, the question that which type is the most appropriate one for this task remains unsolved. In this paper, we use three kinds of recurrent neural networks including simple RNN units, GRU, and LSTM neural network to predict short-term traffic flow. The dataset from TAP30 Corporation is used for building the models and comparing RNNs with several well-known models, such as DEMA, LASSO, and XGBoost. The results show that all three types of RNNs outperform the others; however, more simple RNNs such as simple recurrent units and GRU perform work better than LSTM in terms of accuracy and training time.},
  archive      = {J_AAI},
  author       = {Alireza Nejadettehad and Hamid Mahini and Behnam Bahrak},
  doi          = {10.1080/08839514.2020.1771522},
  journal      = {Applied Artificial Intelligence},
  month        = {7},
  number       = {9},
  pages        = {674-689},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Short-term demand forecasting for online car-hailing services using recurrent neural networks},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). R-STDP based spiking neural network for human action
recognition. <em>AAI</em>, <em>34</em>(9), 656–673. (<a
href="https://doi.org/10.1080/08839514.2020.1765110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video surveillance systems are omnipresent and automatic monitoring of human activities is gaining importance in highly secured environments. The proposed work explores the use of the bio-inspired third generation neural network called spiking neural network (SNN) in order to recognize the action sequences present in a video. The SNN used in this work carries the neural information in terms of timing of spikes rather than the shape of the spikes. The learning technique used herein is reward-modulated spike time-dependent plasticity (R-STDP). It is based on reinforcement learning that modulates or demodulates the synaptic weights depending on the reward or the punishment signal that it receives from the decision layer. The absence of gradient descent techniques and external classifiers makes the system computationally efficient and simple. Finally, the performance of the network is evaluated on the two benchmark datasets, viz., Weizmann and KTH datasets.},
  archive      = {J_AAI},
  author       = {S. Jeba Berlin and Mala John},
  doi          = {10.1080/08839514.2020.1765110},
  journal      = {Applied Artificial Intelligence},
  month        = {7},
  number       = {9},
  pages        = {656-673},
  shortjournal = {Appl. Artif. Intell.},
  title        = {R-STDP based spiking neural network for human action recognition},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Artificial color constancy via GoogLeNet with angular loss
function. <em>AAI</em>, <em>34</em>(9), 643–655. (<a
href="https://doi.org/10.1080/08839514.2020.1730630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Color constancy is the ability of the human visual system to perceive colors unchanged independently of illumination. Giving a machine this feature will be beneficial in many fields where chromatic information is used. Particularly, it significantly improves scene understanding and object recognition.In this article, we propose a transfer learning-based algorithm, which has two main features: accuracy higher than many state-of-the-art algorithms and simplicity of implementation. Despite the fact that GoogLeNet was used in the experiments, the given approach may be applied to any convolutional neural networks. Additionally, we discuss the design of a new loss function oriented specifically to this problem and propose a few of the most suitable options.},
  archive      = {J_AAI},
  author       = {Oleksii Sidorov},
  doi          = {10.1080/08839514.2020.1730630},
  journal      = {Applied Artificial Intelligence},
  month        = {7},
  number       = {9},
  pages        = {643-655},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Artificial color constancy via GoogLeNet with angular loss function},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Artificial intelligence in purchasing: Facilitating
mechanism design-based negotiations. <em>AAI</em>, <em>34</em>(8),
618–642. (<a
href="https://doi.org/10.1080/08839514.2020.1749337">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Negotiations are central to reach consensus between supply chain partners while, simultaneously, meeting internal cost and quality targets. Purchasing prices can be improved by inducing competition in the supply base. In this context, the application of mechanism design theory in negotiations gained enhanced attention. While such approaches can result in high cost reductions, mechanism design-based negotiations are very complex. The paper aims at answering the question whether artificial intelligence (AI) can facilitate the execution of mechanism design-based negotiations. To this end, a World Café has been conducted at an automotive original equipment manufacturer. A group of 20 experts from the fields of purchasing and AI discussed the potentials of AI for the purchasing function. The results indicate that the application of AI can indeed facilitate the execution of mechanism design-based negotiations and help overcoming bounded rationality problems. Even more, AI might be a game changer for the purchasing function.},
  archive      = {J_AAI},
  author       = {Ines Schulze-Horn and Sabrina Hueren and Paul Scheffler and Holger Schiele},
  doi          = {10.1080/08839514.2020.1749337},
  journal      = {Applied Artificial Intelligence},
  month        = {7},
  number       = {8},
  pages        = {618-642},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Artificial intelligence in purchasing: Facilitating mechanism design-based negotiations},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Analysis of the ebola outbreak in 2014 and 2018 in west
africa and congo by using artificial adaptive systems. <em>AAI</em>,
<em>34</em>(8), 597–617. (<a
href="https://doi.org/10.1080/08839514.2020.1747770">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this manuscript the Ebola outbreaks in 2014 and 2018 have been studied. On March 23, 2014, the World Health Organization announced the beginning of the Ebola outbreak in West Africa. The initial location was in a forested area in the south eastern portion of Guinea. We used three different methods to determine the origin of the outbreak. The first was a suite of artificial adaptive systems called Topological Weighted Centroid which located the outbreak origin at Longitude: −10.5337, Latitude: 8.1517. This area is 64 km from Guekedou, Guinea. We also used a Dynamic Naive Bayesian/Dynamic Networks Block Algorithm. The Bayesian algorithm shows the main source of the Ebola outbreak at Kissidougou. Both of these methods revealed the outbreak started in the forested area southeast of Guinea. The distance between Guekedou and Kissidougou is about 69 km. Furthermore, we used an artificial neural network (ANN) called Selfie to predict the outbreak diffusion. The Ebola outbreak in May 2018 in Democratic Republic of Congo was not as widespread as the outbreak in 2014. The outbreak was effecting the health zones of Bikoro and Iboko, and Wangata in Congo. We have used an ANN algorithm and predicted the origin of the outbreak at (Longitude: 18.3046, Latitude: −0.6865) in the Equator about 20 km at North-West of Bikoro.},
  archive      = {J_AAI},
  author       = {Massimo Buscema and Masoud Asadi-Zeydabadi and Weldon Lodwick and Alphonse Nde Nembot and Alvin Bronstein and Francis Newman},
  doi          = {10.1080/08839514.2020.1747770},
  journal      = {Applied Artificial Intelligence},
  month        = {7},
  number       = {8},
  pages        = {597-617},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Analysis of the ebola outbreak in 2014 and 2018 in west africa and congo by using artificial adaptive systems},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Gesture and speech recognizing helper bot. <em>AAI</em>,
<em>34</em>(7), 585–595. (<a
href="https://doi.org/10.1080/08839514.2020.1740473">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In industries, difficult work is being decreased everywhere scale to expand effectiveness and exactness, and gain benefit by introducing robots that can do repetitive works at lesser expense of preparing. A onetime establishment of such a gadget may cost an enormous sum at first, yet in the more drawn out run, will end up being more beneficial than difficult work. Out of the part, a basic robotic arm is a standout amongst the most generally introduced machines. Robotic arm is one of the significant undertakings in the present computerization industry. Automated arm is a piece of the mechatronic industry which is a quickly versatile and developing industry today. Distinctive changes and extra features are being associated with the first kind of straightforward robotic arm to upgrade its ease of use under various conditions. In this paper, we are building up a robotic arm which will have a free rotation around multiple axes and we are including the technology of Image Processing with it to make it a visual signal based working robotic arm. The model is a pick and place robotic arm you can take the desired article starting with one place and carry it to another place with its gripper claw. The operations will be constrained by a visual processing framework that reads the gestures and will give directions to the Arm for performing various types of movements and tasks. We are making use of low torque servos to lift light weight.},
  archive      = {J_AAI},
  author       = {Kailash Gogineni and Akhil Chitreddy and Anirudh Vattikuti and Natarajan Palaniappan},
  doi          = {10.1080/08839514.2020.1740473},
  journal      = {Applied Artificial Intelligence},
  month        = {6},
  number       = {7},
  pages        = {585-595},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Gesture and speech recognizing helper bot},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Problem specific variable selection rules for constraint
programming: A type II mixed model assembly line balancing problem case.
<em>AAI</em>, <em>34</em>(7), 564–584. (<a
href="https://doi.org/10.1080/08839514.2020.1731782">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main idea of constraint programming (CP) is to determine a solution (or solutions) of a problem assigning values to decision variables satisfying all constraints. Two sub processes, an enumeration strategy and a consistency, run under the constraint programming main algorithm. The enumeration strategy which is managing the order of variables and values to build a search tree and possible solutions is crucial process in CP. In this study problem-based specific variable selection rules are studied on a mixed model assembly line balancing problem. The 18 variable selection rules are generated in three main categories by considering the problem input parameters. These rules are tested with benchmark problems in the literature and experimental results are compared with the results of mathematical model and standard CP algorithm. Also, benchmark problems are run with two CP rules to compare experimental results. In conclusion, experimental results are shown that the outperform rules are listed and also their specifications are defined to guide to researchers who solve optimization problems with CP.},
  archive      = {J_AAI},
  author       = {Hacı Mehmet Alakaş and Bilal Toklu},
  doi          = {10.1080/08839514.2020.1731782},
  journal      = {Applied Artificial Intelligence},
  month        = {6},
  number       = {7},
  pages        = {564-584},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Problem specific variable selection rules for constraint programming: A type II mixed model assembly line balancing problem case},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hybrid multi-evolutionary algorithm to solve optimization
problems. <em>AAI</em>, <em>34</em>(7), 550–563. (<a
href="https://doi.org/10.1080/08839514.2020.1730631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The article presents a Hybrid Multi-Evolutionary Algorithm designed to solve optimization problems. The Genetic Algorithm and Evolutionary Strategy work together to improve the efficiency of optimization and increase resistance to getting stuck to sub-optimal solutions. Genetic Algorithm and Evolutionary Strategy can periodically exchange the best individuals from each other. The algorithm combines the ability of the Genetic Algorithm to explore the search space and the ability of the Evolutionary Strategy to exploit the search space. It maintains the right balance between the exploration and exploitation of the search space. The results of the experiments suggest that the proposed algorithm is more effective than the Genetic Algorithms and Evolutionary Strategy used separately, and can be an effective tool in solving complex optimization problems.},
  archive      = {J_AAI},
  author       = {Krzysztof Pytel},
  doi          = {10.1080/08839514.2020.1730631},
  journal      = {Applied Artificial Intelligence},
  month        = {6},
  number       = {7},
  pages        = {550-563},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Hybrid multi-evolutionary algorithm to solve optimization problems},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A memetic algorithm based on breakout local search for the
generalized traveling salesman problem. <em>AAI</em>, <em>34</em>(7),
537–549. (<a
href="https://doi.org/10.1080/08839514.2020.1730629">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Traveling Salesman Problem (TSP) is one of the most popular Combinatorial Optimization Problem. It is well solicited for the large variety of applications that it can solve, but also for its difficulty to find optimal solutions. One of the variants of the TSP is the Generalized TSP (GTSP), where the TSP is considered as a special case which makes the GTSP harder to solve. We propose in this paper a new memetic algorithm based on the well-known Breakout Local Search (BLS) metaheuristic to provide good solutions for GTSP instances. Our approach is competitive compared to other recent memetic algorithms proposed for the GTSP and gives at the same time some improvements to BLS to reduce its runtime.},
  archive      = {J_AAI},
  author       = {Mehdi El Krari and Belaïd Ahiod and Bouazza El Benani},
  doi          = {10.1080/08839514.2020.1730629},
  journal      = {Applied Artificial Intelligence},
  month        = {6},
  number       = {7},
  pages        = {537-549},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A memetic algorithm based on breakout local search for the generalized traveling salesman problem},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Online learning using multiple times weight updating.
<em>AAI</em>, <em>34</em>(6), 515–536. (<a
href="https://doi.org/10.1080/08839514.2020.1730623">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online learning makes sequence of decisions with partial data arrival where next movement of data is unknown. In this paper, we have presented a new technique as multiple times weight updating that update the weight iteratively for same instance. The proposed technique analyzed with popular state-of-art algorithms from literature and experimented using established tool. The results indicate that mistake rate reduces to zero or close to zero for various datasets and algorithms. The overhead running cost is not too expensive and achieving mistake rate close to zero further strengthens the proposed technique. The present work includes bound nature of weight updating for single instance and achieve optimal weight value. This proposed work could be extended to big datasets problems to reduce mistake rate in online learning environment. Also, the proposed technique could be helpful to meet real life challenges.},
  archive      = {J_AAI},
  author       = {Charanjeet Singh and Anuj Sharma},
  doi          = {10.1080/08839514.2020.1730623},
  journal      = {Applied Artificial Intelligence},
  month        = {5},
  number       = {6},
  pages        = {515-536},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Online learning using multiple times weight updating},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improving naive bayes for regression with optimized
artificial surrogate data. <em>AAI</em>, <em>34</em>(6), 484–514. (<a
href="https://doi.org/10.1080/08839514.2020.1726615">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Can we evolve better training data for machine learning algorithms? To investigate this question we use population-based optimization algorithms to generate artificial surrogate training data for naive Bayes for regression. We demonstrate that the generalization performance of naive Bayes for regression models is enhanced by training them on the artificial data as opposed to the real data. These results are important for two reasons. Firstly, naive Bayes models are simple and interpretable but frequently underperform compared to more complex “black box” models, and therefore new methods of enhancing accuracy are called for. Secondly, the idea of using the real training data indirectly in the construction of the artificial training data, as opposed to directly for model training, is a novel twist on the usual machine learning paradigm.},
  archive      = {J_AAI},
  author       = {Michael Mayo and Eibe Frank},
  doi          = {10.1080/08839514.2020.1726615},
  journal      = {Applied Artificial Intelligence},
  month        = {5},
  number       = {6},
  pages        = {484-514},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Improving naive bayes for regression with optimized artificial surrogate data},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Driver fatigue detection using viola jones and principal
component analysis. <em>AAI</em>, <em>34</em>(6), 456–483. (<a
href="https://doi.org/10.1080/08839514.2020.1723875">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we have proposed a low-cost solution for driver fatigue detection based on micro-sleep patterns. Contrary to conventional methods, we acquired images by placing a camera on the extreme left side of the driver and proposed two algorithms that facilitate accurate face and eye detections, even when the driver is not facing the camera or driver’s eyes are closed. The classification to find whether eye is closed or open is done on the right eye only using SVM and Adaboost. Based on eye states, micro-sleep patterns are determined and an alarm is triggered to warn the driver, when needed. In our dataset, we considered multiple subjects from both genders, having different appearances and under different lightning conditions. The proposed scheme gives 99.9% and 98.7% accurate results for face and eye detection, respectively. For all the subjects, the average accuracy of SVM and Adaboost is 96.5% and 95.4%, respectively.},
  archive      = {J_AAI},
  author       = {Bahjat Fatima and Ahmad R. Shahid and Sheikh Ziauddin and Asad Ali Safi and Huma Ramzan},
  doi          = {10.1080/08839514.2020.1723875},
  journal      = {Applied Artificial Intelligence},
  month        = {5},
  number       = {6},
  pages        = {456-483},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Driver fatigue detection using viola jones and principal component analysis},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Handling sequence-dependent setup time flexible job shop
problem with learning and deterioration considerations using
evolutionary bi-level optimization. <em>AAI</em>, <em>34</em>(6),
433–455. (<a
href="https://doi.org/10.1080/08839514.2020.1723871">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bi-level optimization is a challenging research area that has received significant attention from researchers to model enormous NP-hard optimization problems and real-life applications. In this paper, we propose a new evolutionary bi-level algorithm for Flexible Job Shop Problem with Sequence-Dependent Setup Time (SDST-FJSP) and learning/deterioration effects. There are two main motivations behind this work. On the one hand, learning and deterioration effects might occur simultaneously in real-life production systems. However, there are still ill posed in the scheduling area. On the other hand, bi-level optimization was presented as an interesting resolution scheme easily applied to more complex problems without additional modifications. Motivated by these issues, we attempt in this work to solve the FJSP variant using the bi-level programming framework. We suggest firstly a new bi-level mathematical formulation for the considered FJSP; then we propose a bi-level evolutionary algorithm to solve the problem. The experimental study on well-established benchmarks assesses and validates the advantage of using a bi-level scheme over the compared approaches in this research area to solve such NP-hard problem.},
  archive      = {J_AAI},
  author       = {Ameni Azzouz and Abir Chaabani and Meriem Ennigrou and Lamjed Ben Said},
  doi          = {10.1080/08839514.2020.1723871},
  journal      = {Applied Artificial Intelligence},
  month        = {5},
  number       = {6},
  pages        = {433-455},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Handling sequence-dependent setup time flexible job shop problem with learning and deterioration considerations using evolutionary bi-level optimization},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Religion, robots and rectitude: Communicative affordances
for spiritual knowledge and community. <em>AAI</em>, <em>34</em>(5),
412–431. (<a
href="https://doi.org/10.1080/08839514.2020.1723869">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In light of growing concerns on AI growth and gloomy projections of attendant risks to human well-being and expertise, recent development of robotics designed to fulfill spiritual goals can help provide an alternative, possibly uplifting vision of global futures. To further understanding of the potential of robots as embodied communicators for virtuous knowledge and community, this paper discusses the affordances or possibilities of action of robots for spiritual communication by drawing upon the recent highly publicized case of Xian’Er the robot monk (XE). By discussing XE’s communicative affordances including its searchability, multimediality, liveliness and extendibility, findings illustrate how robots can facilitate religious education, augment priestly authority and cultivate spiritual community. Contrary to abstract and dystopic visions of AI, findings here temper extreme pronouncements of societal disorder and points to prospects for pious and positive interplays between AI technology and society while also identifying various limitations for spiritual communication. In doing so, this paper unpacks the profound relations between religion, robots and rectitude, contributing interdisciplinary insights into an understudied area of AI development as faith leaders and adherents interact with new technological features and applications in their desire for transcendence.},
  archive      = {J_AAI},
  author       = {Pauline Hope Cheong},
  doi          = {10.1080/08839514.2020.1723869},
  journal      = {Applied Artificial Intelligence},
  month        = {4},
  number       = {5},
  pages        = {412-431},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Religion, robots and rectitude: Communicative affordances for spiritual knowledge and community},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A methodology combining cosine similarity with classifier
for text classification. <em>AAI</em>, <em>34</em>(5), 396–411. (<a
href="https://doi.org/10.1080/08839514.2020.1723868">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text Classification has received significant attention in recent years because of the proliferation of digital documents and is widely used in various applications such as filtering and recommendation. Consequently, many approaches, including those based on statistical theory, machine learning, and classifier performance improvement, have been proposed for improving text classification performance. Among these approaches, centroid-based classifier, multinomial naïve bayesian (MNB), support vector machines (SVM), convolutional neural network (CNN) are commonly used. In this paper, we introduce a cosine similarity-based methodology for improving performance. The methodology combines cosine similarity (between a test document and fixed categories) with conventional classifiers such as MNB, SVM, and CNN to improve the accuracy of the classifiers, and then we call the conventional classifiers with cosine similarity as enhanced classifiers. We applied the enhanced classifiers to famous datasets – 20NG, R8, R52, Cade12, and WebKB – and evaluated the performance of the enhanced classifiers in terms of the confusion matrix’s accuracy; we obtained outstanding results in that the enhanced classifiers show significant increases in accuracy. Moreover, through experiments, we identified which of two considered knowledge representation techniques (word count and term frequency-inverse document frequency (TFIDF)) is more suitable in terms of classifier performance.},
  archive      = {J_AAI},
  author       = {Kwangil Park and June Seok Hong and Wooju Kim},
  doi          = {10.1080/08839514.2020.1723868},
  journal      = {Applied Artificial Intelligence},
  month        = {4},
  number       = {5},
  pages        = {396-411},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A methodology combining cosine similarity with classifier for text classification},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Extreme learning regression for nu regularization.
<em>AAI</em>, <em>34</em>(5), 378–395. (<a
href="https://doi.org/10.1080/08839514.2020.1723863">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extreme learning machine for regression (ELR), though efficient, is not preferred in time-limited applications, due to the model selection time being large. To overcome this problem, we reformulate ELR to take a new regularization parameter nu (nu-ELR) which is inspired by Schölkopf et al. The regularization in terms of nu is bounded between 0 and 1, and is easier to interpret compared to C . In this paper, we propose using the active set algorithm to solve the quadratic programming optimization problem of nu-ELR. Experimental results on real regression problems show that nu-ELR performs better than ELM, ELR, and nu-SVR, and is computationally efficient compared to other iterative learning models. Additionally, the model selection time of nu-ELR can be significantly shortened.},
  archive      = {J_AAI},
  author       = {Xiao-Jian Ding and Fan Yang and Jian Liu and Jie Cao},
  doi          = {10.1080/08839514.2020.1723863},
  journal      = {Applied Artificial Intelligence},
  month        = {4},
  number       = {5},
  pages        = {378-395},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Extreme learning regression for nu regularization},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Detection of thin boundaries between different types of
anomalies in outlier detection using enhanced neural networks.
<em>AAI</em>, <em>34</em>(5), 345–377. (<a
href="https://doi.org/10.1080/08839514.2020.1722933">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outlier detection has received special attention in various fields, mainly for those dealing with machine learning and artificial intelligence. As strong outliers, anomalies are divided into point, contextual and collective outliers. The most important challenges in outlier detection include the thin boundary between the remote points and natural area, the tendency of new data and noise to mimic the real data, unlabeled datasets and different definitions for outliers in different applications. Considering the stated challenges, we defined new types of anomalies called Collective Normal Anomaly and Collective Point Anomaly in order to improve a much better detection of the thin boundary between different types of anomalies. Basic domain-independent methods are introduced to detect these defined anomalies in both unsupervised and supervised datasets. The Multi-Layer Perceptron Neural Network is enhanced using the Genetic Algorithm to detect new defined anomalies with a higher precision so as to ensure a test error less than that be calculated for the conventional Multi-Layer Perceptron Neural Network. Experimental results on benchmark datasets indicated reduced error of anomaly detection process in comparison to baselines.},
  archive      = {J_AAI},
  author       = {Rasoul Kiani and Amin Keshavarzi and Mahdi Bohlouli},
  doi          = {10.1080/08839514.2020.1722933},
  journal      = {Applied Artificial Intelligence},
  month        = {4},
  number       = {5},
  pages        = {345-377},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Detection of thin boundaries between different types of anomalies in outlier detection using enhanced neural networks},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Violence detection in videos by combining 3D convolutional
neural networks and support vector machines. <em>AAI</em>,
<em>34</em>(4), 329–344. (<a
href="https://doi.org/10.1080/08839514.2020.1723876">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video-surveillance has always been a vital tool to enforce safety in both public and private environments. Even though (smart) cameras are nowadays relatively widespread and cheap, such monitoring systems lack effectiveness in most scenarios. In addition, there is no guarantee about a human operator who monitors rare events in live video footages, forcing the use of such systems after unwanted events already took their undisturbed course, as a mere tool for investigations. Having an intelligent software to perform the task would allow to unlock the full potential of video-surveillance systems. To this end, in this paper we propose a solution based on a 3D Convolutional Neural Network that can effectively detect fights, aggressive motions and violence scenes in live video streams. Compared to state-of-the-art techniques, our method showed very promising performance on three challenging benchmark datasets: Hockey Fight, Crowd Violence and Movie Violence.},
  archive      = {J_AAI},
  author       = {Simone Accattoli and Paolo Sernani and Nicola Falcionelli and Dagmawi Neway Mekuria and Aldo Franco Dragoni},
  doi          = {10.1080/08839514.2020.1723876},
  journal      = {Applied Artificial Intelligence},
  month        = {3},
  number       = {4},
  pages        = {329-344},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Violence detection in videos by combining 3D convolutional neural networks and support vector machines},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel chaotic interior search algorithm for global
optimization and feature selection. <em>AAI</em>, <em>34</em>(4),
292–328. (<a
href="https://doi.org/10.1080/08839514.2020.1712788">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interior Search Algorithm (ISA) is a recently proposed metaheuristic inspired by the beautification of objects and mirrors. However, similar to most of the metaheuristic algorithms, ISA also encounters two problems, i.e., entrapment in local optima and slow convergence speed. In the past, chaos theory has been successfully employed to solve such problems. In this study, 10 chaotic maps are embedded to improve the convergence rate as well as the resulting accuracy of the ISA algorithms. The proposed Chaotic Interior Search Algorithm (CISA) is validated on a diverse subset of 13 benchmark functions having unimodal and multimodal properties. The simulation results demonstrate that the chaotic maps (especially tent map) are able to significantly boost the performance of ISA. Furthermore, CISA is employed as a feature selection technique in which the aim is to remove features which may comprise irrelevant or redundant information in order to minimize the classification error rate. The performance of the proposed approaches is compared with five state-of-the-art algorithms over 21 data sets and the results proved the potential of the proposed binary approaches in searching the optimal feature subsets.},
  archive      = {J_AAI},
  author       = {Sankalap Arora and Manik Sharma and Priyanka Anand},
  doi          = {10.1080/08839514.2020.1712788},
  journal      = {Applied Artificial Intelligence},
  month        = {3},
  number       = {4},
  pages        = {292-328},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A novel chaotic interior search algorithm for global optimization and feature selection},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Comparison of supervised classifiers and image features for
crop rows segmentation on aerial images. <em>AAI</em>, <em>34</em>(4),
271–291. (<a
href="https://doi.org/10.1080/08839514.2020.1720131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we present a comparison of supervised classifiers and image features for crop row segmentation of aerial images captured from an unmanned aerial vehicle (UAV). The main goal is to investigate which methods are the most suitable to solve this specific problem, as well as to test quantitatively how well they perform for robust segmentation of row patterns. For this purpose, we conducted a systematic literature review over the recent methods specifically designed for aerial image crop row segmentation, and for comparison purposes we implemented the most prominent approaches. Most used Color-texture features were faced against most used classifiers, resulting into a total of 48 combinations, usually having their construction concepts based on the following two step-procedures: (i) supervised training step to build some model over the selected color-texture feature space which is also based upon user-selected samples from the input image; and (ii) classification step, where each pixel of the input image is classified employing the corresponding classifier. The obtained results were compared against a Ground-Truth (GT) image, performed by a human expert, using two distinct evaluation metrics, indicating the most suitable combination of color-texture descriptors and classifiers able to solve the segmentation problem of specific cultures obtained from UAV images.},
  archive      = {J_AAI},
  author       = {Paulo César Pereira Júnior and Alexandre Monteiro and Rafael Da Luz Ribeiro and Antonio Carlos Sobieranski and Aldo Von Wangenheim},
  doi          = {10.1080/08839514.2020.1720131},
  journal      = {Applied Artificial Intelligence},
  month        = {3},
  number       = {4},
  pages        = {271-291},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Comparison of supervised classifiers and image features for crop rows segmentation on aerial images},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A review of automatic end-to-end de-identification: Is high
accuracy the only metric? <em>AAI</em>, <em>34</em>(3), 251–269. (<a
href="https://doi.org/10.1080/08839514.2020.1718343">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {De-identification of electronic health records (EHR) is a vital step toward advancing health informatics research and maximizing the use of available data. It is a two-step process where step one is the identification of protected health information (PHI), and step two is replacing such PHI with surrogates. Despite the recent advances in automatic de-identification of EHR, significant obstacles remain if the abundant health data available are to be used to the full potential. Accuracy in de-identification could be considered a necessary, but not sufficient condition for the use of EHR without individual patient consent. We present here a comprehensive review of the progress to date, both the impressive successes in achieving high accuracy and the significant risks and challenges that remain. To best of our knowledge, this is the first paper to present a complete picture of end-to-end automatic de-identification. We review 18 recently published automatic de-identification systems -designed to de-identify EHR in the form of free text- to show the advancements made in improving the overall accuracy of the system, and in identifying individual PHI. We argue that despite the improvements in accuracy there remain challenges in surrogate generation and replacements of identified PHIs, and the risks posed to patient protection and privacy.},
  archive      = {J_AAI},
  author       = {Vithya Yogarajan and Bernhard Pfahringer and Michael Mayo},
  doi          = {10.1080/08839514.2020.1718343},
  journal      = {Applied Artificial Intelligence},
  month        = {2},
  number       = {3},
  pages        = {251-269},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A review of automatic end-to-end de-identification: Is high accuracy the only metric?},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Self-adaptive multi-population rao algorithms for
engineering design optimization. <em>AAI</em>, <em>34</em>(3), 187–250.
(<a href="https://doi.org/10.1080/08839514.2020.1712789">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of various population-based advanced optimization algorithms has been significantly improved by using the multi-population search scheme. The multi-population search process improves the diversity of solutions by dividing the total population into a number of sub-populations groups to search for the best solution in different areas of a search space. This paper proposes improved optimization algorithms based on self-adaptive multi-population for solving engineering design optimization problems. These proposed algorithms are based on Rao algorithms which are recently proposed simple and algorithm-specific parameter-less advanced optimization algorithms. In this work, Rao algorithms are upgraded with the multi-population search process to enhance the diversity of search. The number of sub-populations is changed adaptively considering the strength of solutions to control the exploration and exploitation of the search process. The performance of proposed algorithms is investigated on 25 unconstrained benchmark functions and 14 complex constrained engineering design optimization problems. The results obtained using proposed algorithms are compared with the various advanced optimization algorithms. The comparison of results shows the effectiveness of proposed algorithms for solving engineering design optimization problems. The significance of the proposed methods has proved using a well-known statistical test known as “Friedman test.” Furthermore, the convergence plots are illustrated to show the convergence speed of the proposed algorithms.},
  archive      = {J_AAI},
  author       = {R. V. Rao and R. B. Pawar},
  doi          = {10.1080/08839514.2020.1712789},
  journal      = {Applied Artificial Intelligence},
  month        = {2},
  number       = {3},
  pages        = {187-250},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Self-adaptive multi-population rao algorithms for engineering design optimization},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A smart environments architecture (search). <em>AAI</em>,
<em>34</em>(2), 155–186. (<a
href="https://doi.org/10.1080/08839514.2020.1712778">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We report on a system architecture, SEArch, and its associated methods and tools we have been developing, testing, and extending for several years through a number of innovation processes in the field of Smart Environments. We have developed these infrastructure in a bottom-up fashion directed by the needs of the different projects as opposed to an ideal one which projects have to conform to. In this sense is practical and although necessarily incomplete, it has significant versatility and reasonable efficiency. Projects developed using this architecture have been funded by different companies and funding bodies in Europe. The different components of the architecture are explained through the software supporting those aspects of the system and through the functionality they exhibit in different practical scenarios, extracted from some of the projects implemented with SEArch.},
  archive      = {J_AAI},
  author       = {J. Augusto and J. Giménez-Manuel and M. Quinde and Ch. Oguego and M. Ali and C. James-Reynolds},
  doi          = {10.1080/08839514.2020.1712778},
  journal      = {Applied Artificial Intelligence},
  month        = {1},
  number       = {2},
  pages        = {155-186},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A smart environments architecture (Search)},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Numerical inspection of heterogeneity in materials using 2D
heat-conduction and hybrid GA-tuned neural-network. <em>AAI</em>,
<em>34</em>(2), 125–154. (<a
href="https://doi.org/10.1080/08839514.2019.1691843">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Present work investigates the effect on heat conduction due to the intrusion in a homogeneous bulk and proposes models to detect its position from the temperature distribution on the surface. Finite volume-based, automated numerical simulations are performed for obtaining the temperature history along/across the bulk surface having different positions of the intrusion. Two approaches are developed to predict the intrusion-position from temperature data. In approach 1, a multi-layer feed-forward neural network (NN) with back-propagation (BP) algorithm is used, whereas the NN parameters are determined through a thorough sequential parametric study. In approach 2, again a NN with BP algorithm is used, but a global evolutionary optimizer, namely genetic algorithm (GA) is employed to optimize the NN parameters. NN with BP algorithm and GA are indigenously developed using ‘C’ programming language in ‘linux’ operating system. NN and GA are indigenously combined in a common monolithic platform using some specially designed system commands so that data transfer take place seamlessly in a fully automated way. The performances of the developed approaches are tested and validated in several ways. After comparison, approach 2 is found to have higher prediction capability.},
  archive      = {J_AAI},
  author       = {Suman Ghosh and Ankit Kumar Dubey and Arup Kumar Das},
  doi          = {10.1080/08839514.2019.1691843},
  journal      = {Applied Artificial Intelligence},
  month        = {1},
  number       = {2},
  pages        = {125-154},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Numerical inspection of heterogeneity in materials using 2D heat-conduction and hybrid GA-tuned neural-network},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). CNN-VSR: A deep learning architecture with validation-based
stopping rule for time series classication. <em>AAI</em>,
<em>34</em>(2), 101–124. (<a
href="https://doi.org/10.1080/08839514.2020.1713454">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning methods for univariate time series classification (TSC) are recently gaining attention. Especially, convolutional neural network (CNN) is utilized to solve the problem of predicting class labels of time series obtained through various important applications, such as engineering, biomedical, and finance. In this work, a novel CNN model is proposed with validation-based stopping rule (VSR) named as CNN-VSR, for univariate TSC using 2-D convolution operation, inspired by image processing properties. For this, first, we develop a novel 2-D transformation approach to convert 1-D time series of any length to 2-D matrix automatically without any manual preprocessing. The transformed time series will be given as an input to the proposed architecture. Further, the implicit and explicit regularization is applied, as time series signal is highly chaotic and prone to over-fitting with learning. Specifically, we define a VSR, which provides a set of parameters associated with a low validation set loss. Moreover, we also conduct a comparative empirical performance evaluation of the proposed CNN-VSR with the best available methods for individual benchmark datasets whose information are provided in a repository maintained by UCR and UEA. Our results reveal that proposed CNN-VSR advances the baseline methods by achieving higher performance accuracy. In addition, we demonstrate that the stopping rule considerably contributes to the classifying performance of the proposed CNN-VSR architecture. Furthermore, we also discuss the optimal model selection and study the effects of different factors on the performance of the proposed CNN-VSR.},
  archive      = {J_AAI},
  author       = {Anjali Gautam and Vrijendra Singh},
  doi          = {10.1080/08839514.2020.1713454},
  journal      = {Applied Artificial Intelligence},
  month        = {1},
  number       = {2},
  pages        = {101-124},
  shortjournal = {Appl. Artif. Intell.},
  title        = {CNN-VSR: A deep learning architecture with validation-based stopping rule for time series classication},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bankruptcy prediction using stacked auto-encoders.
<em>AAI</em>, <em>34</em>(1), 80–100. (<a
href="https://doi.org/10.1080/08839514.2019.1691849">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bankruptcy prediction is considered as one of the vital topics in finance and accounting. The purpose of predicting bankruptcy is to build a predictive model that combines several econometrics parameters, which allow evaluating the firm financial status either bankrupt or non-bankrupt. In this field, various machine learning algorithms such as decision tree, support vector machine, and artificial neural network have been applied to predict bankruptcy. However, deep learning algorithms are experiencing a resurgence of interest. To this end, we propose a novel deep learning-based approach which includes both feature extraction and classification phase into one model for predicting bankruptcy of financial firms. Our approach combines Stacked Auto-Encoders (SAE) with softmax classifier. In the first stage, the stacked auto-encoders are employed to extract the best features from the training dataset. Second, a softmax classification layer is trained to predict the class label. We evaluate our proposed approach on the base of Polish and Darden datasets. The obtained results confirm the efficiency of the SAE with softmax classifier compared to other existing works to accurately predict corporate bankruptcy.},
  archive      = {J_AAI},
  author       = {Makram Soui and Salima Smiti and Mohamed Wiem Mkaouer and Ridha Ejbali},
  doi          = {10.1080/08839514.2019.1691849},
  journal      = {Applied Artificial Intelligence},
  month        = {1},
  number       = {1},
  pages        = {80-100},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Bankruptcy prediction using stacked auto-encoders},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Anomaly detection in power generation plants using machine
learning and neural networks. <em>AAI</em>, <em>34</em>(1), 64–79. (<a
href="https://doi.org/10.1080/08839514.2019.1691839">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The availability of constant electricity supply is a crucial factor to the performance of any industry. Nevertheless, the unstable supply of electricity in Cameroon has led to countless periods of electricity load shedding, hence, making the management of the telecom industry to fall on backup power supply such as diesel generators. The fuel consumption of these generators remain a challenge due to some perturbations in the mechanical fuel level gauges and lack of maintenance at the base stations resulting to fuel pilferage. In order to overcome these effects, we detect anomalies in the recorded data by learning the patterns of the fuel consumption using four classification techniques namely; support vector machines (SVM), K-Nearest Neighbors (KNN), Logistic Regression (LR), and MultiLayer Perceptron (MLP) and then compare the performance of these classification techniques on a test data. In this paper, we show the use of supervised machine learning classification based techniques in detecting anomalies associated with the fuel consumed dataset from TeleInfra base stations using the generator as a source of power. Here, we perform the normal feature engineering, selection, and then fit the model classifiers to obtain results and finally, test the performance of these classifiers on a test data. The results of this study show that MLP has the best performance in the evaluation measurement recording a score of 96 % in the K-fold cross validation test. In addition, because of class imbalance in the observation, we use the precision-recall curve instead of the ROC curve and registered the probability of the Area Under Curve (AUC) as 0.98 .},
  archive      = {J_AAI},
  author       = {Jecinta Mulongo and Marcellin Atemkeng and Theophilus Ansah-Narh and Rockefeller Rockefeller and Gabin Maxime Nguegnang and Marco Andrea Garuti},
  doi          = {10.1080/08839514.2019.1691839},
  journal      = {Applied Artificial Intelligence},
  month        = {1},
  number       = {1},
  pages        = {64-79},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Anomaly detection in power generation plants using machine learning and neural networks},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Semi-supervised classification of fraud data in commercial
auctions. <em>AAI</em>, <em>34</em>(1), 47–63. (<a
href="https://doi.org/10.1080/08839514.2019.1691341">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the magnitude of monetary transactions at auction sites, they are very attractive to fraudsters and scam artists. Shill bidding (SB) is a severe fraud in e-auctions, which occurs during the bidding period and is driven by modern-day technology and clever scammers. SB does not produce any obvious evidence, and it is often unnoticed by the victims. The lack of availability of training datasets for SB and the difficulty in identifying the behavior of sophisticated fraudsters hinder research on SB detection. To safeguard consumers from dishonest bidders, we were incentivized to investigate semi-supervised classification (SSC) for the first time, which is the most suitable approach to solving fraud classification problems. In this study, we first introduce two new SB patterns, and then based on a total of nine SB patterns, we build an SB dataset from commercial auctions and bidder history data. SSC requires the labeling of a few SB data samples, and to this end, we propose an anomaly detection method based on data clustering. We addressed the skewed class distribution with a hybrid data sampling method. Our experiments in training several SSC models show that using primarily unlabeled SB data with a few labeled SB data improves predictive performance when compared to that of supervised models.},
  archive      = {J_AAI},
  author       = {Sulaf Elshaar and Samira Sadaoui},
  doi          = {10.1080/08839514.2019.1691341},
  journal      = {Applied Artificial Intelligence},
  month        = {1},
  number       = {1},
  pages        = {47-63},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Semi-supervised classification of fraud data in commercial auctions},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Virtual machine placement using JAYA optimization algorithm.
<em>AAI</em>, <em>34</em>(1), 31–46. (<a
href="https://doi.org/10.1080/08839514.2019.1689714">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing has become more popular with the ability to run HPC applications on cloud infrastructures. Improving the energy efficiency of these data centers become important for all the cloud providers. We observe that bin-packing heuristics such as Best-Fit Decreasing for energy-aware virtual machine (VM) allocation could not provide the optimal solution to minimize the total energy consumption of the data center. In this work, we explore the virtual machines provisioning considering multi-dimensional resources and energy consumption of the data center. We propose to use JAYA algorithm for optimal placement and minimizing the energy consumption of the data center. Our simulation results show the proposed algorithm could reduce the total energy consumption up to 34% and SLA by 15% compared with the Particle Swarm Optimization and power-aware best-fit decreasing.},
  archive      = {J_AAI},
  author       = {M. Amarendhar Reddy and K. Ravindranath},
  doi          = {10.1080/08839514.2019.1689714},
  journal      = {Applied Artificial Intelligence},
  month        = {1},
  number       = {1},
  pages        = {31-46},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Virtual machine placement using JAYA optimization algorithm},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimizing fraudulent firm prediction using ensemble machine
learning: A case study of an external audit. <em>AAI</em>,
<em>34</em>(1), 20–30. (<a
href="https://doi.org/10.1080/08839514.2019.1680182">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is a case study of utilizing machine learning for developing a decision-making system for auditors before initializing the audit fieldwork of public firms. Annual data of 777 firms from 14 different sectors are collected and a MCTOPE (Multi criteria ToPsis based Ensemble) framework is implemented to build an ensemble classifier. MCTOPE framework optimizes the performance of classification during ensemble building using the TOPSIS multi-criteria decision-making algorithm. Ensemble machine learning is used for optimizing the prediction performance of suspicious firm predictor in the previous work available at https://www.tandfonline.com/doi/full/10.1080/08839514.2018.1451032 . After achieving an accuracy of 94.6% and AUC (area under the curve) value of 0.98, this ensemble classifier is employed in a web application developed for auditors using Python and R script for the prediction of suspicious firm before planning an external audit. The performance of an ensemble classifier is validated using K-fold cross validation technique and is found to be better than the state-of-the-art classifiers.},
  archive      = {J_AAI},
  author       = {Nishtha Hooda and Seema Bawa and Prashant Singh Rana},
  doi          = {10.1080/08839514.2019.1680182},
  journal      = {Applied Artificial Intelligence},
  month        = {1},
  number       = {1},
  pages        = {20-30},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Optimizing fraudulent firm prediction using ensemble machine learning: A case study of an external audit},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Analyzing the brazilian financial market through portuguese
sentiment analysis in social media. <em>AAI</em>, <em>34</em>(1), 1–19.
(<a href="https://doi.org/10.1080/08839514.2019.1673037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {According to the Efficient Market Hypothesis, financial market movements are dependent on news and external events that have a significant impact on the market value of companies. Thus, a great amount of applications has arisen to explore this knowledge through automatic sentiment and opinion extraction. The technique known as Sentiment Analysis (SA) aims to analyze opinions, sentiments, and emotions present in unstructured data, leading many papers to address the impact of news and social media publications on the financial market. However, the literature lacks works considering the effects of sentiment available on social media and its impacts on the Brazilian stock market. This work aims to conduct a study of the Brazilian stock market movement through SA in Twitter considering tree perspectives: (i) absolute number of tweet sentiments; (ii) tweets sentiments weighted by favorites; and (iii) tweets sentiments weighted by retweets. The analyzed period was the Brazilian electoral period of 2018 (01-Oct-2018 to 31-Dec-2018). In this paper, we first developed a comparison study with SA Machine Learning techniques (Naive Bayes, Support Vector Machines, Maximum Entropy, and Multilayer Perceptron) and then applied the best algorithm to establish the relations between sentiments and the Brazilian stock market movement considering different time frames (windows sizes). Results indicate that Multilayer Perceptron was the best technique to perform SA in Portuguese. In addition, we observed that the predominant sentiment in social media relates to the stock market movement, improving accuracy as long as windows sizes are increased.},
  archive      = {J_AAI},
  author       = {A. E. O. Carosia and G. P. Coelho and A. E. A. Silva},
  doi          = {10.1080/08839514.2019.1673037},
  journal      = {Applied Artificial Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Analyzing the brazilian financial market through portuguese sentiment analysis in social media},
  volume       = {34},
  year         = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
