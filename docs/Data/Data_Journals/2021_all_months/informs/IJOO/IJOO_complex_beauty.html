<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IJOO_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ijoo---19">IJOO - 19</h2>
<ul>
<li><details>
<summary>
(2021). Katyusha acceleration for convex finite-sum compositional
optimization. <em>IJOO</em>, <em>3</em>(4), 418–443. (<a
href="https://doi.org/10.1287/ijoo.2021.0055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structured optimization problems arise in many applications. To efficiently solve these problems, it is important to leverage the structure information in the algorithmic design. This paper focuses on convex problems with a finite-sum compositional structure. Finite-sum problems appear as the sample average approximation of a stochastic optimization problem and also arise in machine learning with a huge amount of training data. One popularly used numerical approach for finite-sum problems is the stochastic gradient method (SGM). However, the additional compositional structure prohibits easy access to unbiased stochastic approximation of the gradient, so directly applying the SGM to a finite-sum compositional optimization problem (COP) is often inefficient. We design new algorithms for solving strongly convex and also convex two-level finite-sum COPs. Our design incorporates the Katyusha acceleration technique and adopts the mini-batch sampling from both outer-level and inner-level finite-sum. We first analyze the algorithm for strongly convex finite-sum COPs. Similar to a few existing works, we obtain linear convergence rate in terms of the expected objective error; from the convergence rate result, we then establish complexity results of the algorithm to produce an ε -solution. Our complexity results have the same dependence on the number of component functions as existing works. However, because of the use of Katyusha acceleration, our results have better dependence on the condition number κ and improve to κ 2.5 from the best-known κ 3 . Finally, we analyze the algorithm for convex finite-sum COPs, which uses as a subroutine the algorithm for strongly convex finite-sum COPs. Again, we obtain better complexity results than existing works in terms of the dependence on ε , improving to ε − 2.5 from the best-known ε − 3 .},
  archive      = {J_IJOO},
  doi          = {10.1287/ijoo.2021.0055},
  journal      = {INFORMS Journal on Optimization},
  number       = {4},
  pages        = {418-443},
  shortjournal = {INFORMS J. Optim.},
  title        = {Katyusha acceleration for convex finite-sum compositional optimization},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Portfolio optimization under regime switching and
transaction costs: Combining neural networks and dynamic programs.
<em>IJOO</em>, <em>3</em>(4), 398–417. (<a
href="https://doi.org/10.1287/ijoo.2021.0053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiperiod financial models provide superior capabilities over single-period myopic approaches but, in general, suffer from the curse of dimensionality. Prominent features include transaction costs, rebalancing gains, intermediate cashflows, and short- versus long-term trade-offs. In this paper, we propose and test an algorithm combining dynamic programming with a recurrent neural network. The dynamic program provides advanced starts for the neural network. Empirical tests show the benefits of this novel strategy with optimizing a hidden Markov model in the presence of linear transaction costs. Test problems with 50–250 time steps and up to 11 risky assets are solved efficiently, relative to stand-alone dynamic programs or neural networks. The recurrent neural network addresses transaction costs within difficult multiperiod optimization models in polynomial run time.},
  archive      = {J_IJOO},
  doi          = {10.1287/ijoo.2021.0053},
  journal      = {INFORMS Journal on Optimization},
  number       = {4},
  pages        = {398-417},
  shortjournal = {INFORMS J. Optim.},
  title        = {Portfolio optimization under regime switching and transaction costs: Combining neural networks and dynamic programs},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Augmented lagrangian–based first-order methods for
convex-constrained programs with weakly convex objective. <em>IJOO</em>,
<em>3</em>(4), 373–397. (<a
href="https://doi.org/10.1287/ijoo.2021.0052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {First-order methods (FOMs) have been widely used for solving large-scale problems. A majority of existing works focus on problems without constraint or with simple constraints. Several recent works have studied FOMs for problems with complicated functional constraints. In this paper, we design a novel augmented Lagrangian (AL)–based FOM for solving problems with nonconvex objective and convex constraint functions. The new method follows the framework of the proximal point (PP) method. On approximately solving PP subproblems, it mixes the usage of the inexact AL method (iALM) and the quadratic penalty method, whereas the latter is always fed with estimated multipliers by the iALM. The proposed method achieves the best-known complexity result to produce a near Karush–Kuhn–Tucker (KKT) point. Theoretically, the hybrid method has a lower iteration-complexity requirement than its counterpart that only uses iALM to solve PP subproblems; numerically, it can perform significantly better than a pure-penalty-based method. Numerical experiments are conducted on nonconvex linearly constrained quadratic programs. The numerical results demonstrate the efficiency of the proposed methods over existing ones.},
  archive      = {J_IJOO},
  doi          = {10.1287/ijoo.2021.0052},
  journal      = {INFORMS Journal on Optimization},
  number       = {4},
  pages        = {373-397},
  shortjournal = {INFORMS J. Optim.},
  title        = {Augmented Lagrangian–Based first-order methods for convex-constrained programs with weakly convex objective},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Quasi-stochastic electricity markets. <em>IJOO</em>,
<em>3</em>(4), 350–372. (<a
href="https://doi.org/10.1287/ijoo.2021.0051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With wind and solar becoming major contributors to electricity production in many systems, wholesale market operators have become increasingly aware of the need to address uncertainty when forming prices. Although implementing theoretically ideal stochastic market clearing to address uncertainty may be impossible, the use of operating reserve demand curves allows market designers to inject an element of stochasticity into deterministic market clearing formulations. The construction of these curves, which alter the procurement of reserves and therefore the pricing of both reserves and energy, relies on contentious administrative parameters that lack strong theoretical justification. This paper proposes instead to link their construction to outcomes that would be expected in efficient stochastic markets. The analysis considers the potential of these “quasi-stochastic” market clearing approaches to improve efficiency relative to the deterministic status quo as well as ways in which they are unable to fully replicate the stochastic ideal. Further, the paper argues that efficiently managing uncertainty entails a reexamination of the discriminatory uplift payments and enhanced pricing schemes currently employed to address nonconvexity.},
  archive      = {J_IJOO},
  doi          = {10.1287/ijoo.2021.0051},
  journal      = {INFORMS Journal on Optimization},
  number       = {4},
  pages        = {350-372},
  shortjournal = {INFORMS J. Optim.},
  title        = {Quasi-stochastic electricity markets},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Chvátal rank in binary polynomial optimization.
<em>IJOO</em>, <em>3</em>(4), 315–349. (<a
href="https://doi.org/10.1287/ijoo.2019.0049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, several classes of cutting planes have been introduced for binary polynomial optimization. In this paper, we present the first results connecting the combinatorial structure of these inequalities with their Chvátal rank. We determine the Chvátal rank of all known cutting planes and show that almost all of them have Chvátal rank 1. We observe that these inequalities have an associated hypergraph that is β -acyclic. Our second goal is to derive deeper cutting planes; to do so, we consider hypergraphs that admit β -cycles. We introduce a novel class of valid inequalities arising from odd β -cycles, that generally have Chvátal rank 2. These inequalities allow us to obtain the first characterization of the multilinear polytope for hypergraphs that contain β -cycles. Namely, we show that the multilinear polytope for cycle hypergraphs is given by the standard linearization inequalities, flower inequalities, and odd β -cycle inequalities. We also prove that odd β -cycle inequalities can be separated in linear time when the hypergraph is a cycle hypergraph. This shows that instances represented by cycle hypergraphs can be solved in polynomial time. Last, to test the strength of odd β -cycle inequalities, we perform numerical experiments that imply that they close a significant percentage of the integrality gap.},
  archive      = {J_IJOO},
  doi          = {10.1287/ijoo.2019.0049},
  journal      = {Informs Journal on Optimization},
  number       = {4},
  pages        = {315-349},
  shortjournal = {INFORMS J. Optim.},
  title        = {Chvátal rank in binary polynomial optimization},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust facility location under disruptions. <em>IJOO</em>,
<em>3</em>(3), 298–314. (<a
href="https://doi.org/10.1287/ijoo.2021.0054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facility networks can be disrupted by, for example, power outages, poor weather conditions, or natural disasters, and the probabilities of these events may be difficult to estimate. This could lead to costly recourse decisions because customers cannot be served by the planned facilities. In this paper, we study a fixed-charge location problem (FLP) that considers disruption risks. We adopt a two-stage robust optimization method, by which facility location decisions are made here and now and recourse decisions to reassign customers are made after the uncertainty information on the facility availability has been revealed. We implement a column-and-constraint generation (C&amp;CG) algorithm to solve the robust models exactly. Instead of relying on dualization or reformulation techniques to deal with the subproblem, as is common in the literature, we use a linear programming–based enumeration method that allows us to take into account a discrete uncertainty set of facility failures. This also gives the flexibility to tackle cases when the dualization technique cannot be applied to the subproblem. We further develop an approximation scheme for instances of a realistic size. Numerical experiments show that the proposed C&amp;CG algorithm outperforms existing methods for both the robust FLP and the robust p -median problem.},
  archive      = {J_IJOO},
  doi          = {10.1287/ijoo.2021.0054},
  journal      = {INFORMS Journal on Optimization},
  number       = {3},
  pages        = {298-314},
  shortjournal = {INFORMS J. Optim.},
  title        = {Robust facility location under disruptions},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Benders cut classification via support vector machines for
solving two-stage stochastic programs. <em>IJOO</em>, <em>3</em>(3),
278–297. (<a href="https://doi.org/10.1287/ijoo.2019.0050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider Benders decomposition for solving two-stage stochastic programs with complete recourse based on finite samples of the uncertain parameters. We define the Benders cuts binding at the final optimal solution or the ones significantly improving bounds over iterations as valuable cuts . We propose a learning-enhanced Benders decomposition (LearnBD) algorithm, which adds a cut classification step in each iteration to selectively generate cuts that are more likely to be valuable cuts. The LearnBD algorithm includes two phases: (i) sampling cuts and collecting information from training problems and (ii) solving testing problems with a support vector machine (SVM) cut classifier. We run the LearnBD algorithm on instances of capacitated facility location and multicommodity network design under uncertain demand. Our results show that SVM cut classifier works effectively for identifying valuable cuts, and the LearnBD algorithm reduces the total solving time of all instances for different problems with various sizes and complexities.},
  archive      = {J_IJOO},
  doi          = {10.1287/ijoo.2019.0050},
  journal      = {Informs Journal on Optimization},
  number       = {3},
  pages        = {278-297},
  shortjournal = {INFORMS J. Optim.},
  title        = {Benders cut classification via support vector machines for solving two-stage stochastic programs},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Semi-proximal augmented lagrangian-based decomposition
methods for primal block-angular convex composite quadratic conic
programming problems. <em>IJOO</em>, <em>3</em>(3), 254–277. (<a
href="https://doi.org/10.1287/ijoo.2019.0048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We first propose a semi-proximal augmented Lagrangian-based decomposition method to directly solve the primal form of a convex composite quadratic conic-programming problem with a primal block-angular structure. Using our algorithmic framework, we are able to naturally derive several well-known augmented Lagrangian-based decomposition methods for stochastic programming, such as the diagonal quadratic approximation method of Mulvey and Ruszczyński. Although it is natural to develop an augmented Lagrangian decomposition algorithm based on the primal problem, here, we demonstrate that it is, in fact, numerically more economical to solve the dual problem by an appropriately designed decomposition algorithm. In particular, we propose a semi-proximal symmetric Gauss–Seidel-based alternating direction method of multipliers (sGS-ADMM) for solving the corresponding dual problem. Numerical results show that our dual-based sGS-ADMM algorithm can very efficiently solve some very large instances of primal block-angular convex quadratic-programming problems. For example, one instance with more than 300,000 linear constraints and 12.5 million nonnegative variables is solved to the accuracy of 10 -5 in the relative KKT residual in less than a minute on a modest desktop computer.},
  archive      = {J_IJOO},
  doi          = {10.1287/ijoo.2019.0048},
  journal      = {Informs Journal on Optimization},
  number       = {3},
  pages        = {254-277},
  shortjournal = {INFORMS J. Optim.},
  title        = {Semi-proximal augmented lagrangian-based decomposition methods for primal block-angular convex composite quadratic conic programming problems},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A prescriptive machine-learning framework to the
price-setting newsvendor problem. <em>IJOO</em>, <em>3</em>(3), 227–253.
(<a href="https://doi.org/10.1287/ijoo.2019.0046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a practical procedure for solving the price-setting newsvendor problem employing (a) statistical estimation methods to recover only three distinct aspects of the demand distribution: the mean, quantile and superquantile, and (b) price optimization methods to estimate the optimal solution. This procedure is asymptotically optimal under mild conditions when the estimators are consistent and the price optimization has a unique global maximum. To estimate the quantities of interest in a data-driven, distribution-free fashion with multidimensional datasets, we investigate estimators based on generalized linear regression (GLR), mixed-quantile regression (MQR), and superquantile regression (SQR). We provide two extensions to these estimators that are of independent interest. First, we propose a novel and exact large-scale decomposition method that is computationally efficient for SQR, and second, we extend the MQR estimation method by relaxing its implicit assumptions of homoscedasticity. Our computational experiments indicate the importance of flexible estimation methods that inherently model heteroscedasticity (with improvements in absolute error of resultant profit as high as 90\%), and suggest that quantile-based methods such as MQR and SQR provide better solutions for a wide range of demand distributions, although for certain location-scale demand distributions similar to the Normal distribution, GLR may be preferable.},
  archive      = {J_IJOO},
  doi          = {10.1287/ijoo.2019.0046},
  journal      = {Informs Journal on Optimization},
  number       = {3},
  pages        = {227-253},
  shortjournal = {INFORMS J. Optim.},
  title        = {A prescriptive machine-learning framework to the price-setting newsvendor problem},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The nutritious supply chain: Optimizing humanitarian food
assistance. <em>IJOO</em>, <em>3</em>(2), 200–226. (<a
href="https://doi.org/10.1287/ijoo.2019.0047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The World Food Programme (WFP) is the largest humanitarian agency fighting hunger worldwide, reaching approximately 90 million people with food assistance across 80 countries each year. To deal with the operational complexities inherent in its mandate, WFP has been developing tools to assist its decision makers with integrating supply chain decisions across departments and functional areas. This paper describes a mixed integer linear programming model that simultaneously optimizes the food basket to be delivered, the sourcing plan, the delivery plan, and the transfer modality of a long-term recovery operation for each month in a predefined time horizon. By connecting traditional supply chain elements to nutritional objectives, we are able to make significant breakthroughs in the operational excellence of WFP’s most complex operations. We show three examples of how the optimization model is used to support operations: (1) to reduce the operational costs in Iraq by 12\% without compromising the nutritional value supplied, (2) to manage the scaling-up of the Yemen operation from three to six million beneficiaries, and (3) to identify sourcing strategies during the El Niño drought of 2016.},
  archive      = {J_IJOO},
  doi          = {10.1287/ijoo.2019.0047},
  journal      = {Informs Journal on Optimization},
  number       = {2},
  pages        = {200-226},
  shortjournal = {INFORMS J. Optim.},
  title        = {The nutritious supply chain: Optimizing humanitarian food assistance},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust mixed 0-1 programming and submodularity.
<em>IJOO</em>, <em>3</em>(2), 183–199. (<a
href="https://doi.org/10.1287/ijoo.2019.0042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the solution set of the robust continuous 0-1 knapsack problem with a single unrestricted continuous variable. Using the submodularity of the cardinality-constrained robust 0-1 knapsack set function, we identify extended polymatroid inequalities that can be used as cutting planes in a branch-and-cut algorithm. We propose a polynomial-time separation algorithm for the most violated extended polymatroid inequality. We prove that the convex hull of the feasible solutions to the robust continuous 0-1 knapsack problem can be described completely by extended polymatroid inequalities and bound inequalities. Additionally, we propose a polynomial-time algorithm for the robust continuous 0–1 knapsack problem itself. We report computational results that show the effectiveness of the proposed extended polymatroid inequalities.},
  archive      = {J_IJOO},
  doi          = {10.1287/ijoo.2019.0042},
  journal      = {Informs Journal on Optimization},
  number       = {2},
  pages        = {183-199},
  shortjournal = {INFORMS J. Optim.},
  title        = {Robust mixed 0-1 programming and submodularity},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Inexact nonconvex newton-type methods. <em>IJOO</em>,
<em>3</em>(2), 154–182. (<a
href="https://doi.org/10.1287/ijoo.2019.0043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For solving large-scale nonconvex problems, we propose inexact variants of trust region and adaptive cubic regularization methods, which, to increase efficiency, incorporate various approximations. In particular, in addition to inexact subproblem solves, both the gradient and Hessian are suitably estimated. Using certain conditions on such approximations, we show that our proposed inexact methods achieve similar optimal worst-case iteration complexities as the exact counterparts. In the context of finite-sum problems, we then explore randomized subsampling methods as ways to construct the gradient and Hessian approximations and examine the empirical performance of our algorithms on some model problems. We empirically demonstrate that our proposed algorithms are practically implementable in that failure to precisely fine-tune the associated hyperparameters is unlikely to result in unwanted behaviors, for example, divergence or stagnation.},
  archive      = {J_IJOO},
  doi          = {10.1287/ijoo.2019.0043},
  journal      = {Informs Journal on Optimization},
  number       = {2},
  pages        = {154-182},
  shortjournal = {INFORMS J. Optim.},
  title        = {Inexact nonconvex newton-type methods},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Orbital conflict: Cutting planes for symmetric integer
programs. <em>IJOO</em>, <em>3</em>(2), 139–153. (<a
href="https://doi.org/10.1287/ijoo.2019.0044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cutting planes have been an important factor in the impressive progress made by integer programming (IP) solvers in the past two decades. However, cutting planes have had little impact on improving performance for symmetric IPs. Rather, the main breakthroughs for solving symmetric IPs have been achieved by cleverly exploiting symmetry in the enumeration phase of branch and bound. In this work, we introduce a hierarchy of cutting planes that arise from a reinterpretation of symmetry-exploiting branching methods. There are too many inequalities in the hierarchy to be used efficiently in a direct manner. However, the lowest levels of this cutting-plane hierarchy can be implicitly exploited by enhancing the conflict graph of the integer programming instance and by generating inequalities such as clique cuts valid for the stable set relaxation of the instance. We provide computational evidence that the resulting symmetry-powered clique cuts can improve state-of-the-art symmetry-exploiting methods. The inequalities are then employed in a two-phase approach with high-throughput computations to solve heretofore unsolved symmetric integer programs arising from covering designs, establishing for the first time the covering radii of two binary-ternary codes.},
  archive      = {J_IJOO},
  doi          = {10.1287/ijoo.2019.0044},
  journal      = {Informs Journal on Optimization},
  number       = {2},
  pages        = {139-153},
  shortjournal = {INFORMS J. Optim.},
  title        = {Orbital conflict: Cutting planes for symmetric integer programs},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An ensemble learning framework for model fitting and
evaluation in inverse linear optimization. <em>IJOO</em>, <em>3</em>(2),
119–138. (<a href="https://doi.org/10.1287/ijoo.2019.0045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a generalized inverse optimization framework for fitting the cost vector of a single linear optimization problem given multiple observed decisions. This setting is motivated by ensemble learning, where building consensus from base learners can yield better predictions. We unify several models in the inverse optimization literature under a single framework and derive assumption-free and exact solution methods for each one. We extend a goodness-of-fit metric previously introduced for the problem with a single observed decision to this new setting and demonstrate several important properties. Finally, we demonstrate our framework in a novel inverse optimization-driven procedure for automated radiation therapy treatment planning. Here, the inverse optimization model leverages an ensemble of dose predictions from different machine learning models to construct a consensus treatment plan that outperforms baseline methods. The consensus plan yields better trade-offs between the competing clinical criteria used for plan evaluation.},
  archive      = {J_IJOO},
  doi          = {10.1287/ijoo.2019.0045},
  journal      = {Informs Journal on Optimization},
  number       = {2},
  pages        = {119-138},
  shortjournal = {INFORMS J. Optim.},
  title        = {An ensemble learning framework for model fitting and evaluation in inverse linear optimization},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). First-order methods for constrained convex programming based
on linearized augmented lagrangian function. <em>IJOO</em>,
<em>3</em>(1), 89–117. (<a
href="https://doi.org/10.1287/ijoo.2019.0033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {First-order methods (FOMs) have been popularly used for solving large-scale problems. However, many existing works only consider unconstrained problems or those with simple constraint. In this paper, we develop two FOMs for constrained convex programs, where the constraint set is represented by affine equations and smooth nonlinear inequalities. Both methods are based on the classical augmented Lagrangian function. They update the multipliers in the same way as the augmented Lagrangian method (ALM) but use different primal updates. The first method, at each iteration, performs a single proximal gradient step to the primal variable, and the second method is a block update version of the first one. For the first method, we establish its global iterate convergence and global sublinear and local linear convergence, and for the second method, we show a global sublinear convergence result in expectation. Numerical experiments are carried out on the basis pursuit denoising, convex quadratically constrained quadratic programs, and the Neyman-Pearson classification problem to show the empirical performance of the proposed methods. Their numerical behaviors closely match the established theoretical results.},
  archive      = {J_IJOO},
  doi          = {10.1287/ijoo.2019.0033},
  journal      = {Informs Journal on Optimization},
  number       = {1},
  pages        = {89-117},
  shortjournal = {INFORMS J. Optim.},
  title        = {First-order methods for constrained convex programming based on linearized augmented lagrangian function},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multiobjective maximization of monotone submodular functions
with cardinality constraint. <em>IJOO</em>, <em>3</em>(1), 74–88. (<a
href="https://doi.org/10.1287/ijoo.2019.0041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of multiobjective maximization of monotone submodular functions subject to cardinality constraint, often formulated as max | A | = k min i ∈ { 1 , … , m } f i ( A ) . Although it is widely known that greedy methods work well for a single objective, the problem becomes much harder with multiple objectives. In fact, it is known that when the number of objectives m grows as the cardinality k , that is, m = Ω ( k ) , the problem is inapproximable (unless P = NP ). On the other hand, when m is constant, there exists a a randomized ( 1 − 1 / e ) − ε approximation with runtime (number of queries to function oracle) the scales as n m / ε 3 . We focus on finding a fast algorithm that has (asymptotic) approximation guarantees even when m is super constant. First, through a continuous greedy based algorithm we give a ( 1 − 1 / e ) approximation for m = o ( k log 3 ⁡ k ) . This demonstrates a steep transition from constant factor approximability to inapproximability around m = Ω ( k ) . Then using multiplicative-weight-updates (MWUs), we find a much faster O ˜ ( n / δ 3 ) time asymptotic ( 1 − 1 / e ) 2 − δ approximation. Although these results are all randomized, we also give a simple deterministic ( 1 − 1 / e ) − ε approximation with runtime k n m / ε 4 . Finally, we run synthetic experiments using Kronecker graphs and find that our MWU inspired heuristic outperforms existing heuristics.},
  archive      = {J_IJOO},
  doi          = {10.1287/ijoo.2019.0041},
  journal      = {Informs Journal on Optimization},
  number       = {1},
  pages        = {74-88},
  shortjournal = {INFORMS J. Optim.},
  title        = {Multiobjective maximization of monotone submodular functions with cardinality constraint},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Integer programming for learning directed acyclic graphs
from continuous data. <em>IJOO</em>, <em>3</em>(1), 46–73. (<a
href="https://doi.org/10.1287/ijoo.2019.0040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning directed acyclic graphs (DAGs) from data is a challenging task both in theory and in practice, because the number of possible DAGs scales superexponentially with the number of nodes. In this paper, we study the problem of learning an optimal DAG from continuous observational data. We cast this problem in the form of a mathematical programming model that can naturally incorporate a superstructure to reduce the set of possible candidate DAGs. We use a negative log-likelihood score function with both ℓ 1 and ℓ 0 penalties and propose a new mixed-integer quadratic program, referred to as a layered network (LN) formulation. The LN formulation is a compact model that enjoys as tight an optimal continuous relaxation value as the stronger but larger formulations under a mild condition. Computational results indicate that the proposed formulation outperforms existing mathematical formulations and scales better than available algorithms that can solve the same problem with only ℓ 1 regularization. In particular, the LN formulation clearly outperforms existing methods in terms of computational time needed to find an optimal DAG in the presence of a sparse superstructure.},
  archive      = {J_IJOO},
  doi          = {10.1287/ijoo.2019.0040},
  journal      = {Informs Journal on Optimization},
  number       = {1},
  pages        = {46-73},
  shortjournal = {INFORMS J. Optim.},
  title        = {Integer programming for learning directed acyclic graphs from continuous data},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Tree bounds for sums of bernoulli random variables: A linear
optimization approach. <em>IJOO</em>, <em>3</em>(1), 23–45. (<a
href="https://doi.org/10.1287/ijoo.2019.0038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of computing the tightest upper and lower bounds on the probability that the sum of n dependent Bernoulli random variables exceeds an integer k . Under knowledge of all pairs of bivariate distributions denoted by a complete graph, the bounds are NP-hard to compute. When the bivariate distributions are specified on a tree graph, we show that tight bounds are computable in polynomial time using a compact linear program. These bounds provide robust probability estimates when the assumption of conditional independence in a tree-structured graphical model is violated. We demonstrate, through numericals, the computational advantage of our compact linear program over alternate approaches. A comparison of bounds under various knowledge assumptions, such as univariate information and conditional independence, is provided. An application is illustrated in the context of Chow–Liu trees, wherein our bounds distinguish between various trees that encode the maximum possible mutual information.},
  archive      = {J_IJOO},
  doi          = {10.1287/ijoo.2019.0038},
  journal      = {Informs Journal on Optimization},
  number       = {1},
  pages        = {23-45},
  shortjournal = {INFORMS J. Optim.},
  title        = {Tree bounds for sums of bernoulli random variables: A linear optimization approach},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Parallelizing subgradient methods for the lagrangian dual in
stochastic mixed-integer programming. <em>IJOO</em>, <em>3</em>(1),
1–22. (<a href="https://doi.org/10.1287/ijoo.2019.0029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dual decomposition of stochastic mixed-integer programs can be solved by the projected subgradient algorithm. We show how to make this algorithm more amenable to parallelization in a master-worker model by describing two approaches, which can be combined in a natural way. The first approach partitions the scenarios into batches and makes separate use of subgradient information for each batch. The second approach drops the requirement that evaluation of function and subgradient information is synchronized across the scenarios. We provide convergence analysis of both methods. We also evaluate their performance on two families of problems from SIPLIB on a single server with 32 single-core worker processes, demonstrating that when the number of workers is high relative to the number of scenarios, these two approaches (and their synthesis) can significantly reduce running time.},
  archive      = {J_IJOO},
  doi          = {10.1287/ijoo.2019.0029},
  journal      = {Informs Journal on Optimization},
  number       = {1},
  pages        = {1-22},
  shortjournal = {INFORMS J. Optim.},
  title        = {Parallelizing subgradient methods for the lagrangian dual in stochastic mixed-integer programming},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
