<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IJOC_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ijoc---141">IJOC - 141</h2>
<ul>
<li><details>
<summary>
(2021). Unsupervised learning for human mobility behaviors.
<em>IJOC</em>, <em>34</em>(3), 1565–1586. (<a
href="https://doi.org/10.1287/ijoc.2021.1098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning human mobility behaviors from location-sensing data are crucial to mobility data mining because of its potential to address a range of analytical purposes in mobile context reasoning, including exploration, inference, and prediction. However, existing approaches suffer from two practical problems: temporal and spatial sparsity. To address these shortcomings, we present two unsupervised learning methods to model the mobility behaviors of multiple users (i.e., a population), considering efficiency and accuracy. These methods intelligently overcome the sparsity in individual data by seeking temporal commonality among users’ heterogeneous location behaviors. The advantages of our models are highlighted through experiments on several real-world mobility data sets, which also show how our methods can realize the three analytical purposes in a unified manner.},
  archive      = {J_IJOC},
  author       = {Siyuan Liu and Shaojie Tang and Jiangchuan Zheng and Lionel M. Ni},
  doi          = {10.1287/ijoc.2021.1098},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1565-1586},
  shortjournal = {INFORMS J. Comput.},
  title        = {Unsupervised learning for human mobility behaviors},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A general framework for approximating min sum ordering
problems. <em>IJOC</em>, <em>34</em>(3), 1437–1452. (<a
href="https://doi.org/10.1287/ijoc.2021.1124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a large family of problems in which an ordering (or, more precisely, a chain of subsets) of a finite set must be chosen to minimize some weighted sum of costs. This family includes variations of min sum set cover, several scheduling and search problems, and problems in Boolean function evaluation. We define a new problem, called the min sum ordering problem (MSOP), which generalizes all these problems using a cost and a weight function defined on subsets of a finite set. Assuming a polynomial time α-approximation algorithm for the problem of finding a subset whose ratio of weight to cost is maximal, we show that under very minimal assumptions, there is a polynomial time 4α-approximation algorithm for MSOP. This approximation result generalizes a proof technique used for several distinct problems in the literature. We apply this to obtain a number of new approximation results.},
  archive      = {J_IJOC},
  author       = {Felix Happach and Lisa Hellerstein and Thomas Lidbetter},
  doi          = {10.1287/ijoc.2021.1124},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1437-1452},
  shortjournal = {INFORMS J. Comput.},
  title        = {A general framework for approximating min sum ordering problems},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning-based branch-and-price algorithms for the vehicle
routing problem with time windows and two-dimensional loading
constraints. <em>IJOC</em>, <em>34</em>(3), 1419–1436. (<a
href="https://doi.org/10.1287/ijoc.2021.1110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A capacitated vehicle routing problem with two-dimensional loading constraints is addressed. Associated with each customer are a set of rectangular items, the total weight of the items, and a time window. Designing exact algorithms for the problem is very challenging because the problem is a combination of two NP-hard problems. An exact branch-and-price algorithm and an approximate counterpart are proposed to solve the problem. We introduce an exact dominance rule and an approximate dominance rule. To cope with the difficulty brought by the loading constraints, a new column generation mechanism boosted by a supervised learning model is proposed. Extensive experiments demonstrate the superiority of integrating the learning model in terms of CPU time and calls of the feasibility checker. Moreover, the branch-and-price algorithms are able to significantly improve the solutions of the existing instances from literature and solve instances with up to 50 customers and 103 items.},
  archive      = {J_IJOC},
  author       = {Xiangyi Zhang and Lu Chen and Michel Gendreau and André Langevin},
  doi          = {10.1287/ijoc.2021.1110},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1419-1436},
  shortjournal = {INFORMS J. Comput.},
  title        = {Learning-based branch-and-price algorithms for the vehicle routing problem with time windows and two-dimensional loading constraints},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On a reduction for a class of resource allocation problems.
<em>IJOC</em>, <em>34</em>(3), 1387–1402. (<a
href="https://doi.org/10.1287/ijoc.2021.1104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the resource allocation problem (RAP), the goal is to divide a given amount of a resource over a set of activities while minimizing the cost of this allocation and possibly satisfying constraints on allocations to subsets of the activities. Most solution approaches for the RAP and its extensions allow each activity to have its own cost function. However, in many applications, often the structure of the objective function is the same for each activity, and the difference between the cost functions lies in different parameter choices, such as, for example, the multiplicative factors. In this article, we introduce a new class of objective functions that captures a significant number of the objectives occurring in studied applications. These objectives are characterized by a shared structure of the cost function depending on two input parameters. We show that, given the two input parameters, there exists a solution to the RAP that is optimal for any choice of the shared structure. As a consequence, this problem reduces to the quadratic RAP, making available the vast amount of solution approaches and algorithms for the latter problem. We show the impact of our reduction result on several applications, and in particular, we improve the best-known worst-case complexity bound of two problems in vessel routing and processor scheduling from O(n2) to O(n log n).},
  archive      = {J_IJOC},
  author       = {Martijn H. H. Schoot Uiterkamp and Marco E. T. Gerards and Johann L. Hurink},
  doi          = {10.1287/ijoc.2021.1104},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1387-1402},
  shortjournal = {INFORMS J. Comput.},
  title        = {On a reduction for a class of resource allocation problems},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Periodic event scheduling for automated production systems.
<em>IJOC</em>, <em>34</em>(2), 1291–1304. (<a
href="https://doi.org/10.1287/ijoc.2021.1101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider optimizing a periodic schedule for an automated production plant as a last step of a more comprehensive design process. In our scenario, each robot’s cyclic sequence of operations and trajectories between potential waiting points have already been fully specified. Further given are those precedences that fix sequence requirements on operations between different robots. It remains to determine the starting time for each operation or movement of each robot within a common cyclic time period so as to avoid collisions of robots that operate in the same space simultaneously. So the task is to find a conflict-resolving schedule that minimizes this common periodic cycle time while observing all precedence relations and collision avoidance constraints. The proposed cycle time minimization problem for robot coordination has, to the best of our knowledge, not been studied before. We develop an approach for solving it by employing binary search for determining the smallest feasible period time of an iso-periodic event scheduling problem (IPESP). This is a variant of the periodic event scheduling problem in which the objects that have to be scheduled need to obey exactly the same period time. The possibility to wait arbitrarily long at waiting points turns out to be essential to justify the use of binary search for identifying the minimum cycle time, thereby avoiding bilinear mixed integer formulations. Special properties of the given scenario admit bounds on the periodic tension variables of an integer programming formulation. Although the IPESP subproblems remain NP-complete in general, these bounds allow solving real-world instances sufficiently fast for the approach to be applicable in practice. Numerical experiments on real-world and randomly generated data are supplied to illustrate the potential and limitations of this approach.},
  archive      = {J_IJOC},
  author       = {Christoph Helmberg and Tobias Hofmann and David Wenzel},
  doi          = {10.1287/ijoc.2021.1101},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {1291-1304},
  shortjournal = {INFORMS J. Comput.},
  title        = {Periodic event scheduling for automated production systems},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient solution methods for a general r-interdiction
median problem with fortification. <em>IJOC</em>, <em>34</em>(2),
1272–1290. (<a href="https://doi.org/10.1287/ijoc.2021.1111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study generalizes the r-interdiction median (RIM) problem with fortification to simultaneously consider two types of risks: probabilistic exogenous disruptions and endogenous disruptions caused by intentional attacks. We develop a bilevel programming model that includes a lower-level interdiction problem and a higher-level fortification problem to hedge against such risks. We then prove that the interdiction problem is supermodular and subsequently adopt the cuts associated with supermodularity to develop an efficient cutting-plane algorithm to achieve exact solutions. For the fortification problem, we adopt the logic-based Benders decomposition (LBBD) framework to take advantage of the two-level structure and the property that a facility should not be fortified if it is not attacked at the lower level. Numerical experiments show that the cutting-plane algorithm is more efficient than benchmark methods in the literature, especially when the problem size grows. Specifically, with regard to the solution quality, LBBD outperforms the greedy algorithm in the literature with an up-to 13.2\% improvement in the total cost, and it is as good as or better than the tree-search implicit enumeration method.},
  archive      = {J_IJOC},
  author       = {Kaike Zhang and Xueping Li and Mingzhou Jin},
  doi          = {10.1287/ijoc.2021.1111},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {1272-1290},
  shortjournal = {INFORMS J. Comput.},
  title        = {Efficient solution methods for a general r-interdiction median problem with fortification},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Toward robust monitoring of malicious outbreaks.
<em>IJOC</em>, <em>34</em>(2), 1257–1271. (<a
href="https://doi.org/10.1287/ijoc.2021.1077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, diffusion processes in social networks have attracted increasing attention within computer science, marketing science, social sciences, and political science. Although the majority of existing works focus on maximizing the reach of desirable diffusion processes, we are interested in deploying a group of monitors to detect malicious diffusion processes such as the spread of computer worms. In this work, we introduce and study the-Monitoring Game, we say an attack is successful if and only if the following two conditions are satisfied: (1) the outbreak/propagation reaches at least α individuals without intervention, and (2) it has not been detected before reaching β individuals. Typically, we require that β is no larger than α in order to compensate the reaction delays after the outbreak has been detected. On the other end, the defender’s ultimate goal is to deploy a set of monitors in the network that can minimize attacker’s success ratio in the worst-case. (We also extend the basic model by considering a noisy diffusion model, where the propagation probabilities on each edge could vary within an interval.) Our work is built upon recent work in security games, our adversarial setting provides robust solutions in practice.},
  archive      = {J_IJOC},
  author       = {Shaojie Tang and Siyuan Liu and Xu Han and Yu Qiao},
  doi          = {10.1287/ijoc.2021.1077},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {1257-1271},
  shortjournal = {INFORMS J. Comput.},
  title        = {Toward robust monitoring of malicious outbreaks},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Scalable optimization methods for incorporating
spatiotemporal fractionation into intensity-modulated radiotherapy
planning. <em>IJOC</em>, <em>34</em>(2), 1240–1256. (<a
href="https://doi.org/10.1287/ijoc.2021.1070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It has been recently shown that an additional therapeutic gain may be achieved if a radiotherapy plan is altered over the treatment course using a new treatment paradigm referred to in the literature as spatiotemporal fractionation. Because of the nonconvex and large-scale nature of the corresponding treatment plan optimization problem, the extent of the potential therapeutic gain that may be achieved from spatiotemporal fractionation has been investigated using stylized cancer cases to circumvent the arising computational challenges. This research aims at developing scalable optimization methods to obtain high-quality spatiotemporally fractionated plans with optimality bounds for clinical cancer cases. In particular, the treatment-planning problem is formulated as a quadratically constrained quadratic program and is solved to local optimality using a constraint-generation approach, in which each subproblem is solved using sequential linear/quadratic programming methods. To obtain optimality bounds, cutting-plane and column-generation methods are combined to solve the Lagrangian relaxation of the formulation. The performance of the developed methods are tested on deidentified clinical liver and prostate cancer cases. Results show that the proposed method is capable of achieving local-optimal spatiotemporally fractionated plans with an optimality gap of around 10\%–12\% for cancer cases tested in this study.},
  archive      = {J_IJOC},
  author       = {Ali Adibi and Ehsan Salari},
  doi          = {10.1287/ijoc.2021.1070},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {1240-1256},
  shortjournal = {INFORMS J. Comput.},
  title        = {Scalable optimization methods for incorporating spatiotemporal fractionation into intensity-modulated radiotherapy planning},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Managing advance admission requests for obstetric care.
<em>IJOC</em>, <em>34</em>(2), 1224–1239. (<a
href="https://doi.org/10.1287/ijoc.2021.1093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is devoted to the management of advance admission requests for obstetric care. Pregnant women in China select one hospital and request admission for both antenatal and postnatal care after nine weeks of pregnancy. Schedulers must make the admission decision instantly based on the availability of the most critical resource, that is, hospital beds for postnatal care. The random delay between admission requests and postnatal care has created a distinct advance admission control problem. To address this issue, we propose a basic model that assumes a unit bed requirement for one day. Each admission generates a unit of revenue and each unit of overcapacity use incurs an overcapacity cost. With the objective of maximizing the expected net revenue, we establish an optimal policy for unlimited requests, that is, an expected arrival time quota (EATQ) policy that accepts a fixed quota of advance admission requests with the same expected date of confinement. We then propose an extended model for general capacity requirements. Using the Poisson approximation, we establish the optimality of the EATQ policy, which is shown to be solvable by a simple linear programming model. We compare the numerical results from the different policies and conduct a sensitivity analysis. The EATQ policy is demonstrated to be the best option in all test instances and notably outperforms the current admission rules used in hospitals, which usually accept admission requests according to some empirical monthly quota of the expected delivery month. The Poisson approximation is shown to be effective for determining the optimal EATQ policy for both stationary and nonstationary arrivals.},
  archive      = {J_IJOC},
  author       = {Na Geng and Xiaolan Xie},
  doi          = {10.1287/ijoc.2021.1093},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {1224-1239},
  shortjournal = {INFORMS J. Comput.},
  title        = {Managing advance admission requests for obstetric care},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Surgery sequencing coordination with recovery resource
constraints. <em>IJOC</em>, <em>34</em>(2), 1207–1223. (<a
href="https://doi.org/10.1287/ijoc.2021.1089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surgical practice administrators need to determine the sequence of surgeries and reserved operating room (OR) time for each surgery in the surgery scheduling process. Both decisions require coordination among multiple ORs and the recovery resource in the postanesthesia care unit (PACU) in a surgical suite. Although existing studies have addressed OR time reservation, surgery sequencing coordination is an open challenge in the stochastic surgical environment. In this paper, we propose an algorithmic solution to this problem based on stochastic optimization. The proposed methodology involves the development of a surrogate objective function that is highly correlated with the original one. The resulting surrogate model has network-structured subproblems after Lagrangian relaxation and decomposition, which makes it easier to solve than the impractically difficult original problem. We show that our proposed approach finds near-optimal solutions in small instances and outperforms benchmark methods by 13\%–51\% or equivalently an estimated saving of $760–$7,420 per day in surgical suites with 4–10 ORs. Our results illustrate a mechanism to alleviate congestion in the PACU. We also recommend that practice administrators prioritize sequencing coordination over the optimization of OR time reservation in an effort for performance improvement. Furthermore, we demonstrate how administrators should consider the impact of sequencing decisions when making strategic capacity adjustments for the PACU.},
  archive      = {J_IJOC},
  author       = {Miao Bai and Robert H. Storer and Gregory L. Tonkay},
  doi          = {10.1287/ijoc.2021.1089},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {1207-1223},
  shortjournal = {INFORMS J. Comput.},
  title        = {Surgery sequencing coordination with recovery resource constraints},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Recourse in kidney exchange programs. <em>IJOC</em>,
<em>34</em>(2), 1191–1206. (<a
href="https://doi.org/10.1287/ijoc.2021.1099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce the problem of selecting patient-donor pairs in a kidney exchange program to undergo a crossmatch test, and we model this selection problem as a two-stage stochastic integer programming problem. The optimal solutions of this new formulation yield a larger expected number of realized transplants than previous approaches based on internal recourse or subset recourse. We settle the computational complexity of the selection problem by showing that it remains NP-hard even for maximum cycle length equal to two. Furthermore, we investigate to what extent different algorithmic approaches, including one based on Benders decomposition, are able to solve instances of the model. We empirically investigate the computational efficiency of this approach by solving randomly generated instances and study the corresponding running times as a function of maximum cycle length, and of the presence of nondirected donors.},
  archive      = {J_IJOC},
  author       = {Bart Smeulders and Valentin Bartier and Yves Crama and Frits C. R. Spieksma},
  doi          = {10.1287/ijoc.2021.1099},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {1191-1206},
  shortjournal = {INFORMS J. Comput.},
  title        = {Recourse in kidney exchange programs},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic programming for response-adaptive dose-finding
clinical trials. <em>IJOC</em>, <em>34</em>(2), 1176–1190. (<a
href="https://doi.org/10.1287/ijoc.2021.1082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying the right dose is one of the most important decisions in drug development. Adaptive designs are promoted to conduct dose-finding clinical trials as they are more efficient and ethical compared with static designs. However, current techniques in response-adaptive designs for dose allocation are complex and need significant computational effort, which is a major impediment for implementation in practice. This study proposes a Bayesian nonparametric framework for estimating the dose-response curve, which uses a piecewise linear approximation to the curve by consecutively connecting the expected mean response at each dose. Our extensive numerical results reveal that a first-order Bayesian nonparametric model with a known correlation structure in prior for the expected mean response performs competitively when compared with the standard approach and other more complex models in terms of several relevant metrics and enjoys computational efficiency. Furthermore, structural properties for the optimal learning problem, which seeks to minimize the variance of the target dose, are established under this simple model.},
  archive      = {J_IJOC},
  author       = {Amir Ali Nasrollahzadeh and Amin Khademi},
  doi          = {10.1287/ijoc.2021.1082},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {1176-1190},
  shortjournal = {INFORMS J. Comput.},
  title        = {Dynamic programming for response-adaptive dose-finding clinical trials},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exact branch-price-and-cut for a hospital therapist
scheduling problem with flexible service locations and time-dependent
location capacity. <em>IJOC</em>, <em>34</em>(2), 1157–1175. (<a
href="https://doi.org/10.1287/ijoc.2021.1119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a new variant of the vehicle routing problem, which arises in hospital-wide scheduling of physical therapists. Multiple service locations exist for patients, and resource synchronization for the location capacities is required as only a limited number of patients can be treated at one location at a time. Additionally, operations synchronization between treatments is required as precedence relations exist. We develop an innovative exact branch-price-and-cut algorithm including two approaches targeting the synchronization constraints (1) based on branching on time windows and (2) based on adding combinatorial Benders cuts. We optimally solve realistic hospital instances with up to 120 treatments and find that branching on time windows performs better than adding cutting planes.},
  archive      = {J_IJOC},
  author       = {Alexander Jungwirth and Guy Desaulniers and Markus Frey and Rainer Kolisch},
  doi          = {10.1287/ijoc.2021.1119},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {1157-1175},
  shortjournal = {INFORMS J. Comput.},
  title        = {Exact branch-price-and-cut for a hospital therapist scheduling problem with flexible service locations and time-dependent location capacity},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stabilized column generation via the dynamic separation of
aggregated rows. <em>IJOC</em>, <em>34</em>(2), 1141–1156. (<a
href="https://doi.org/10.1287/ijoc.2021.1094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Column generation (CG) algorithms are well known to suffer from convergence issues due, mainly, to the degenerate structure of their master problem and the instability associated with the dual variables involved in the process. In the literature, several strategies have been proposed to overcome this issue. These techniques rely either on the modification of the standard CG algorithm or on some prior information about the set of dual optimal solutions. In this paper, we propose a new stabilization framework, which relies on the dynamic generation of aggregated rows from the CG master problem. To evaluate the performance of our method and its flexibility, we consider instances of three different problems, namely, vehicle routing with time windows (VRPTW), bin packing with conflicts (BPPC), and multiperson pose estimation (MPPEP). When solving the VRPTW, the proposed stabilized CG method yields significant improvements in terms of CPU time and number of iterations with respect to a standard CG algorithm. Huge reductions in CPU time are also achieved when solving the BPPC and the MPPEP. For the latter, our method has shown to be competitive when compared with a tailored method.},
  archive      = {J_IJOC},
  author       = {Luciano Costa and Claudio Contardo and Guy Desaulniers and Julian Yarkony},
  doi          = {10.1287/ijoc.2021.1094},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {1141-1156},
  shortjournal = {INFORMS J. Comput.},
  title        = {Stabilized column generation via the dynamic separation of aggregated rows},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A first-order optimization algorithm for statistical
learning with hierarchical sparsity structure. <em>IJOC</em>,
<em>34</em>(2), 1126–1140. (<a
href="https://doi.org/10.1287/ijoc.2021.1069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many statistical learning problems, it is desired that the optimal solution conform to an a priori known sparsity structure represented by a directed acyclic graph. Inducing such structures by means of convex regularizers requires nonsmooth penalty functions that exploit group overlapping. Our study focuses on evaluating the proximal operator of the latent overlapping group lasso developed by Jacob et al. in 2009. We implemented an alternating direction method of multiplier with a sharing scheme to solve large-scale instances of the underlying optimization problem efficiently. In the absence of strong convexity, global linear convergence of the algorithm is established using the error bound theory. More specifically, the paper contributes to establishing primal and dual error bounds when the nonsmooth component in the objective function does not have a polyhedral epigraph. We also investigate the effect of the graph structure on the speed of convergence of the algorithm. Detailed numerical simulation studies over different graph structures supporting the proposed algorithm and two applications in learning are provided.},
  archive      = {J_IJOC},
  author       = {Dewei Zhang and Yin Liu and Sam Davanloo Tajbakhsh},
  doi          = {10.1287/ijoc.2021.1069},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {1126-1140},
  shortjournal = {INFORMS J. Comput.},
  title        = {A first-order optimization algorithm for statistical learning with hierarchical sparsity structure},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An analytic center cutting plane method to determine
complete positivity of a matrix. <em>IJOC</em>, <em>34</em>(2),
1115–1125. (<a href="https://doi.org/10.1287/ijoc.2021.1108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an analytic center cutting plane method to determine whether a matrix is completely positive and return a cut that separates it from the completely positive cone if not. This was stated as an open (computational) problem by Berman et al. [Berman A, Dur M, Shaked-Monderer N (2015) Open problems in the theory of completely positive and copositive matrices. Electronic J. Linear Algebra 29(1):46–58]. Our method optimizes over the intersection of a ball and the copositive cone, where membership is determined by solving a mixed-integer linear program suggested by Xia et al. [Xia W, Vera JC, Zuluaga LF (2020) Globally solving nonconvex quadratic programs via linear integer programming techniques. INFORMS J. Comput. 32(1):40–56]. Thus, our algorithm can, more generally, be used to solve any copositive optimization problem, provided one knows the radius of a ball containing an optimal solution. Numerical experiments show that the number of oracle calls (matrix copositivity checks) for our implementation scales well with the matrix size, growing roughly like O(d2) for d × d matrices. The method is implemented in Julia and available at https://github.com/rileybadenbroek/CopositiveAnalyticCenter.jl.},
  archive      = {J_IJOC},
  author       = {Riley Badenbroek and Etienne de Klerk},
  doi          = {10.1287/ijoc.2021.1108},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {1115-1125},
  shortjournal = {INFORMS J. Comput.},
  title        = {An analytic center cutting plane method to determine complete positivity of a matrix},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic discretization discovery algorithms for
time-dependent shortest path problems. <em>IJOC</em>, <em>34</em>(2),
1086–1114. (<a href="https://doi.org/10.1287/ijoc.2021.1084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding a shortest path in a network is a fundamental optimization problem. We focus on settings in which the travel time on an arc in the network depends on the time at which traversal of the arc begins. In such settings, reaching the destination as early as possible is not the only objective of interest. Minimizing the duration of the path, that is, the difference between the arrival time at the destination and the departure from the origin, and minimizing the travel time along the path from origin to destination, are also of interest. We introduce dynamic discretization discovery algorithms to efficiently solve such time-dependent shortest path problems with piecewise linear arc travel time functions. The algorithms operate on partially time-expanded networks in which arc costs represent lower bounds on the arc travel time over the subsequent time interval. A shortest path in this partially time-expanded network yields a lower bound on the value of an optimal path. Upper bounds are easily obtained as by-products of the lower bound calculations. The algorithms iteratively refine the discretization by exploiting breakpoints of the arc travel time functions. In addition to time discretization refinement, the algorithms permit time intervals to be eliminated, improving lower and upper bounds, until, in a finite number of iterations, optimality is proved. Computational experiments show that only a small fraction of breakpoints must be explored and that the fraction decreases as the length of the time horizon and the size of the network increases, making the algorithms highly efficient and scalable.},
  archive      = {J_IJOC},
  author       = {Edward Yuhang He and Natashia Boland and George Nemhauser and Martin Savelsbergh},
  doi          = {10.1287/ijoc.2021.1084},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {1086-1114},
  shortjournal = {INFORMS J. Comput.},
  title        = {Dynamic discretization discovery algorithms for time-dependent shortest path problems},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Models and algorithms for the bin-packing problem with
minimum color fragmentation. <em>IJOC</em>, <em>34</em>(2), 1070–1085.
(<a href="https://doi.org/10.1287/ijoc.2021.1120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the bin-packing problem with minimum color fragmentation (BPPMCF), we are given a fixed number of bins and a collection of items, each associated with a size and a color, and the goal is to avoid color fragmentation by packing items with the same color within as few bins as possible. This problem emerges in areas as diverse as surgical scheduling and group event seating. We present several optimization models for the BPPMCF, including baseline integer programming formulations, alternative integer programming formulations based on two recursive decomposition strategies that utilize decision diagrams, and a branch-and-price algorithm. Using the results from an extensive computational evaluation on synthetic instances, we train a decision tree model that predicts which algorithm should be chosen to solve a given instance of the problem based on a collection of derived features. Our insights are validated through experiments on the aforementioned applications on real-world data.},
  archive      = {J_IJOC},
  author       = {Saharnaz Mehrani and Carlos Cardonha and David Bergman},
  doi          = {10.1287/ijoc.2021.1120},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {1070-1085},
  shortjournal = {INFORMS J. Comput.},
  title        = {Models and algorithms for the bin-packing problem with minimum color fragmentation},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Novel formulations and logic-based benders decomposition for
the integrated parallel machine scheduling and location problem.
<em>IJOC</em>, <em>34</em>(2), 1048–1069. (<a
href="https://doi.org/10.1287/ijoc.2021.1113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the discrete parallel machine scheduling and location problem, which consists of locating multiple machines to a set of candidate locations, assigning jobs from different locations to the located machines, and sequencing the assigned jobs. The objective is to minimize the maximum completion time of all jobs, that is, the makespan. Though the problem is of theoretical significance with a wide range of practical applications, it has not been well studied as reported in the literature. For this problem, we first propose three new mixed-integer linear programs that outperform state-of-the-art formulations. Then, we develop a new logic-based Benders decomposition algorithm for practical-sized instances, which splits the problem into a master problem that determines machine locations and job assignments to machines and a subproblem that sequences jobs on each machine. The master problem is solved by a branch-and-cut procedure that operates on a single search tree. Once an incumbent solution to the master problem is found, the subproblem is solved to generate cuts that are dynamically added to the master problem. A generic no-good cut is first proposed, which is later improved by some strengthening techniques. Two optimality cuts are also developed based on optimality conditions of the subproblem and improved by strengthening techniques. Numerical results on small-sized instances show that the proposed formulations outperform state-of-the-art ones. Computational results on 1,400 benchmark instances with up to 300 jobs, 50 machines, and 300 locations demonstrate the effectiveness and efficiency of the algorithm compared with current approaches.},
  archive      = {J_IJOC},
  author       = {Yantong Li and Jean-François Côté and Leandro Callegari-Coelho and Peng Wu},
  doi          = {10.1287/ijoc.2021.1113},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {1048-1069},
  shortjournal = {INFORMS J. Comput.},
  title        = {Novel formulations and logic-based benders decomposition for the integrated parallel machine scheduling and location problem},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A comparison of two mixed-integer linear programs for
piecewise linear function fitting. <em>IJOC</em>, <em>34</em>(2),
1042–1047. (<a href="https://doi.org/10.1287/ijoc.2021.1114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of fitting continuous piecewise linear (PWL) functions to discrete data has applications in pattern recognition and engineering, amongst many other fields. To find an optimal PWL function, the positioning of the breakpoints connecting adjacent linear segments must not be constrained and should be allowed to be placed freely. Although the univariate PWL fitting problem has often been approached from a global optimisation perspective, recently, two mixed-integer linear programming approaches have been presented that solve for optimal PWL functions. In this paper, we compare the two approaches: the first was presented by Rebennack and Krasko [Rebennack S, Krasko V (2020) Piecewise linear function fitting via mixed-integer linear programming. INFORMS J. Comput. 32(2):507–530] and the second by Kong and Maravelias [Kong L, Maravelias CT (2020) On the derivation of continuous piecewise linear approximating functions. INFORMS J. Comput. 32(3):531–546]. Both formulations are similar in that they use binary variables and logical implications modelled by big-M constructs to ensure the continuity of the PWL function, yet the former model uses fewer binary variables. We present experimental results comparing the time taken to find optimal PWL functions with differing numbers of breakpoints across 10 data sets for three different objective functions. Although neither of the two formulations is superior on all data sets, the presented computational results suggest that the formulation presented by Rebennack and Krasko is faster. This might be explained by the fact that it contains fewer complicating binary variables and sparser constraints.},
  archive      = {J_IJOC},
  author       = {John Alasdair Warwicker and Steffen Rebennack},
  doi          = {10.1287/ijoc.2021.1114},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {1042-1047},
  shortjournal = {INFORMS J. Comput.},
  title        = {A comparison of two mixed-integer linear programs for piecewise linear function fitting},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Combining polyhedral approaches and stochastic dual dynamic
integer programming for solving the uncapacitated lot-sizing problem
under uncertainty. <em>IJOC</em>, <em>34</em>(2), 1024–1041. (<a
href="https://doi.org/10.1287/ijoc.2021.1118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the uncapacitated lot-sizing problem with uncertain demand and costs. The problem is modeled as a multistage stochastic mixed-integer linear program in which the evolution of the uncertain parameters is represented by a scenario tree. To solve this problem, we propose a new extension of the stochastic dual dynamic integer programming algorithm (SDDiP). This extension aims at being more computationally efficient in the management of the expected cost-to-go functions involved in the model, in particular by reducing their number and by exploiting the current knowledge on the polyhedral structure of the stochastic uncapacitated lot-sizing problem. The algorithm is based on a partial decomposition of the problem into a set of stochastic subproblems, each one involving a subset of nodes forming a subtree of the initial scenario tree. We then introduce a cutting plane–generation procedure that iteratively strengthens the linear relaxation of these subproblems and enables the generation of an additional strengthened Benders’ cut, which improves the convergence of the method. We carry out extensive computational experiments on randomly generated large-size instances. Our numerical results show that the proposed algorithm significantly outperforms the SDDiP algorithm at providing good-quality solutions within the computation time limit.},
  archive      = {J_IJOC},
  author       = {Franco Quezada and Céline Gicquel and Safia Kedad-Sidhoum},
  doi          = {10.1287/ijoc.2021.1118},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {1024-1041},
  shortjournal = {INFORMS J. Comput.},
  title        = {Combining polyhedral approaches and stochastic dual dynamic integer programming for solving the uncapacitated lot-sizing problem under uncertainty},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimizing over the closure of rank inequalities with a
small right-hand side for the maximum stable set problem via bilevel
programming. <em>IJOC</em>, <em>34</em>(2), 1006–1023. (<a
href="https://doi.org/10.1287/ijoc.2021.1115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of the maximum stable set problem, rank inequalities impose that the cardinality of any set of vertices contained in a stable set be, at most, as large as the stability number of the subgraph induced by such a set. Rank inequalities are very general, as they subsume many classical inequalities such as clique, hole, antihole, web, and antiweb inequalities. In spite of their generality, the exact separation of rank inequalities has never been addressed without the introduction of topological restrictions on the induced subgraph and the tightness of their closure has never been investigated systematically. In this work, we propose a methodology for optimizing over the closure of all rank inequalities with a right-hand side no larger than a small constant without imposing any restrictions on the topology of the induced subgraph. Our method relies on the exact separation of a relaxation of rank inequalities, which we call relaxed k-rank inequalities, whose closure is as tight. We investigate the corresponding separation problem, a bilevel programming problem asking for a subgraph of maximum weight with a bound on its stability number, whose study could be of independent interest. We first prove that the problem is Σ2P-hard and provide some insights on its polyhedral structure. We then propose two exact methods for its solution: a branch-and-cut algorithm (which relies on a family of faced-defining inequalities which we introduce in this paper) and a purely combinatorial branch-and-bound algorithm. Our computational results show that the closure of rank inequalities with a right-hand side no larger than a small constant can yield a bound that is stronger, in some cases, than Lovász’s Theta function, and substantially stronger than bounds obtained with standard inequalities that are valid for the stable set problem, including odd-cycle inequalities and wheel inequalities.},
  archive      = {J_IJOC},
  author       = {Stefano Coniglio and Stefano Gualandi},
  doi          = {10.1287/ijoc.2021.1115},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {1006-1023},
  shortjournal = {INFORMS J. Comput.},
  title        = {Optimizing over the closure of rank inequalities with a small right-hand side for the maximum stable set problem via bilevel programming},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Network models for multiobjective discrete optimization.
<em>IJOC</em>, <em>34</em>(2), 990–1005. (<a
href="https://doi.org/10.1287/ijoc.2021.1066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper provides a novel framework for solving multiobjective discrete optimization problems with an arbitrary number of objectives. Our framework represents these problems as network models, in that enumerating the Pareto frontier amounts to solving a multicriteria shortest-path problem in an auxiliary network. We design techniques for exploiting network models in order to accelerate the identification of the Pareto frontier, most notably a number of operations to simplify the network by removing nodes and arcs while preserving the set of nondominated solutions. We show that the proposed framework yields orders-of-magnitude performance improvements over existing state-of-the-art algorithms on five problem classes containing both linear and nonlinear objective functions.},
  archive      = {J_IJOC},
  author       = {David Bergman and Merve Bodur and Carlos Cardonha and Andre A. Cire},
  doi          = {10.1287/ijoc.2021.1066},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {990-1005},
  shortjournal = {INFORMS J. Comput.},
  title        = {Network models for multiobjective discrete optimization},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Iterative deepening dynamically improved bounds
bidirectional search. <em>IJOC</em>, <em>34</em>(2), 974–989. (<a
href="https://doi.org/10.1287/ijoc.2021.1116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new bidirectional search algorithm to solve the shortest path problem. The new algorithm uses an iterative deepening technique with a consistent heuristic to improve lower bounds on path costs. The new algorithm contains a novel technique of filtering nodes to significantly reduce the memory requirements. Computational experiments on the pancake problem, sliding tile problem, and Rubik’s cube show that the new algorithm uses significantly less memory and executes faster than A* and other state-of-the-art bidirectional algorithms.},
  archive      = {J_IJOC},
  author       = {John A. Pavlik and Edward C. Sewell and Sheldon H. Jacobson},
  doi          = {10.1287/ijoc.2021.1116},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {974-989},
  shortjournal = {INFORMS J. Comput.},
  title        = {Iterative deepening dynamically improved bounds bidirectional search},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving column generation for vehicle routing problems via
random coloring and parallelization. <em>IJOC</em>, <em>34</em>(2),
953–973. (<a href="https://doi.org/10.1287/ijoc.2021.1105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a variant of the vehicle routing problem (VRP) where each customer has a unit demand and the goal is to minimize the total cost of routing a fleet of capacitated vehicles from one or multiple depots to visit all customers. We propose two parallel algorithms to efficiently solve the column-generation-based linear-programming relaxation for this VRP. Specifically, we focus on algorithms for the “pricing problem,” which corresponds to the resource-constrained elementary shortest path problem. The first algorithm extends the pulse algorithm for which we derive a new bounding scheme on the maximum load of any route. The second algorithm is based on random coloring from parameterized complexity which can be also combined with other techniques in the literature for improving VRPs, including cutting planes and column enumeration. We conduct numerical studies using VRP benchmarks (with 50–957 nodes) and instances of a medical home care delivery problem using census data in Wayne County, Michigan. Using parallel computing, both pulse and random coloring can significantly improve column generation for solving the linear programming relaxations and we can obtain heuristic integer solutions with small optimality gaps. Combining random coloring with column enumeration, we can obtain improved integer solutions having less than 2\% optimality gaps for most VRP benchmark instances and less than 1\% optimality gaps for the medical home care delivery instances, both under a 30-minute computational time limit. The use of cutting planes (e.g., robust cuts) can further reduce optimality gaps on some hard instances, without much increase in the run time.},
  archive      = {J_IJOC},
  author       = {Miao Yu and Viswanath Nagarajan and Siqian Shen},
  doi          = {10.1287/ijoc.2021.1105},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {953-973},
  shortjournal = {INFORMS J. Comput.},
  title        = {Improving column generation for vehicle routing problems via random coloring and parallelization},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Estimating the size of branch-and-bound trees.
<em>IJOC</em>, <em>34</em>(2), 934–952. (<a
href="https://doi.org/10.1287/ijoc.2021.1103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the problem of estimating the size of branch-and-bound (B&amp;amp;B) trees for solving mixed-integer programs. We first prove that the size of the B&amp;amp;B tree cannot be approximated within a factor of 2 for general binary programs, unless P =NP. Second, we review measures of progress of the B&amp;amp;B search, such as the well-known gap and the often-overlooked tree weight, and propose a new measure, which we call leaf frequency. We study two simple ways to transform these progress measures into B&amp;amp;B tree-size estimates, either as a direct projection or via double-exponential smoothing, a standard time-series forecasting technique. We then combine different progress measures and their trends into nontrivial estimates using machine learning techniques, which yield more precise estimates than any individual measure. The best method that we have identified uses all individual measures as features of a random forest model. In a large computational study, we train and validate all methods on the publicly available MIPLIB and Coral general purpose benchmark sets. On average, the best method estimates B&amp;amp;B tree sizes within a factor of 3 on the set of unseen test instances, even during the early stage of the search, and improves in accuracy as the search progresses. It also achieves a factor of 2 over the entire search on each of the six additional sets of homogeneous instances that we tested. All techniques are available in version 7 of the branch-and-cut framework SCIP.},
  archive      = {J_IJOC},
  author       = {Gregor Hendel and Daniel Anderson and Pierre Le Bodic and Marc E. Pfetsch},
  doi          = {10.1287/ijoc.2021.1103},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {934-952},
  shortjournal = {INFORMS J. Comput.},
  title        = {Estimating the size of branch-and-bound trees},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Branch-and-bound for biobjective mixed-integer linear
programming. <em>IJOC</em>, <em>34</em>(2), 909–933. (<a
href="https://doi.org/10.1287/ijoc.2021.1092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a generic branch-and-bound algorithm for finding all the Pareto solutions of a biobjective mixed-integer linear program. The main contributions are new algorithms for obtaining dual bounds at a node, checking node fathoming, presolve, and duality gap measurement. Our branch-and-bound is predominantly a decision space search method because the branching is performed on the decision variables, akin to single objective problems, although we also sometimes split gaps and branch in the objective space. The various algorithms are implemented using a data structure for storing Pareto sets. Computational experiments are carried out on literature instances and on a new set of instances that we generate using a benchmark library (MIPLIB2017) for single objective problems. We also perform comparisons against the triangle splitting method from literature, which is an objective space search algorithm.},
  archive      = {J_IJOC},
  author       = {Nathan Adelgren and Akshay Gupte},
  doi          = {10.1287/ijoc.2021.1092},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {909-933},
  shortjournal = {INFORMS J. Comput.},
  title        = {Branch-and-bound for biobjective mixed-integer linear programming},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A progressive approximation approach for the exact solution
of sparse large-scale binary interdiction games. <em>IJOC</em>,
<em>34</em>(2), 890–908. (<a
href="https://doi.org/10.1287/ijoc.2021.1085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a progressive approximation algorithm for the exact solution of several classes of interdiction games in which two noncooperative players (namely an attacker and a follower) interact sequentially. The follower must solve an optimization problem that has been previously perturbed by means of a series of attacking actions led by the attacker. These attacking actions aim at augmenting the cost of the decision variables of the follower’s optimization problem. The objective, from the attacker’s viewpoint, is that of choosing an attacking strategy that reduces as much as possible the quality of the optimal solution attainable by the follower. The progressive approximation mechanism consists of the iterative solution of an interdiction problem in which the attacker actions are restricted to a subset of the whole solution space and a pricing subproblem invoked with the objective of proving the optimality of the attacking strategy. This scheme is especially useful when the optimal solutions to the follower’s subproblem intersect with the decision space of the attacker only in a small number of decision variables. In such cases, the progressive approximation method can solve interdiction games otherwise intractable for classical methods. We illustrate the efficiency of our approach on the shortest path, 0-1 knapsack and facility location interdiction games.},
  archive      = {J_IJOC},
  author       = {Claudio Contardo and Jorge A. Sefair},
  doi          = {10.1287/ijoc.2021.1085},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {890-908},
  shortjournal = {INFORMS J. Comput.},
  title        = {A progressive approximation approach for the exact solution of sparse large-scale binary interdiction games},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the exact solution of prize-collecting steiner tree
problems. <em>IJOC</em>, <em>34</em>(2), 872–889. (<a
href="https://doi.org/10.1287/ijoc.2021.1087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prize-collecting Steiner tree problem (PCSTP) is a well-known generalization of the classic Steiner tree problem in graphs, with a large number of practical applications. It attracted particular interest during the 11th DIMACS Challenge in 2014, and since then, several PCSTP solvers have been introduced in the literature. Although these new solvers further, and often drastically, improved on the results of the DIMACS Challenge, many PCSTP benchmark instances have remained unsolved. The following article describes further advances in the state of the art in exact PCSTP solving. It introduces new techniques and algorithms for PCSTP, involving various new transformations (or reductions) of PCSTP instances to equivalent problems, for example, to decrease the problem size or to obtain a better integer programming formulation. Several of the new techniques and algorithms provably dominate previous approaches. Further theoretical properties of the new components, such as their complexity, are discussed. Also, new complexity results for the exact solution of PCSTP and related problems are described, which form the base of the algorithm design. Finally, the new developments also translate into a strong computational performance: the resulting exact PCSTP solver outperforms all previous approaches, both in terms of runtime and solvability. In particular, it solves several formerly intractable benchmark instances from the 11th DIMACS Challenge to optimality. Moreover, several recently introduced large-scale instances with up to 10 million edges, previously considered to be too large for any exact approach, can now be solved to optimality in less than two hours.},
  archive      = {J_IJOC},
  author       = {Daniel Rehfeldt and Thorsten Koch},
  doi          = {10.1287/ijoc.2021.1087},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {872-889},
  shortjournal = {INFORMS J. Comput.},
  title        = {On the exact solution of prize-collecting steiner tree problems},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Decomposition-based approaches for a class of two-stage
robust binary optimization problems. <em>IJOC</em>, <em>34</em>(2),
857–871. (<a href="https://doi.org/10.1287/ijoc.2021.1061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study a class of two-stage robust binary optimization problems with objective uncertainty, where recourse decisions are restricted to be mixed-binary. For these problems, we present a deterministic equivalent formulation through the convexification of the recourse-feasible region. We then explore this formulation under the lens of a relaxation, showing that the specific relaxation we propose can be solved by using the branch-and-price algorithm. We present conditions under which this relaxation is exact and describe alternative exact solution methods when this is not the case. Despite the two-stage nature of the problem, we provide NP-completeness results based on our reformulations. Finally, we present various applications in which the methodology we propose can be applied. We compare our exact methodology to those approximate methods recently proposed in the literature under the name K−adaptability. Our computational results show that our methodology is able to produce better solutions in less computational time compared with the K−adaptability approach, as well as to solve bigger instances than those previously managed in the literature.},
  archive      = {J_IJOC},
  author       = {Ayşe N. Arslan and Boris Detienne},
  doi          = {10.1287/ijoc.2021.1061},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {857-871},
  shortjournal = {INFORMS J. Comput.},
  title        = {Decomposition-based approaches for a class of two-stage robust binary optimization problems},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Scalable vertiport hub location selection for air taxi
operations in a metropolitan region. <em>IJOC</em>, <em>34</em>(2),
834–856. (<a href="https://doi.org/10.1287/ijoc.2021.1109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {On-demand air mobility services, often called air taxis, are on the way to revolutionize our urban/regional transportation sector by lifting transportation to the third dimension and thus possibly contribute to solving the congestion-induced transportation deadlock many metropolitan regions face today. Although existing research mainly focuses on the design of efficient vehicles and specifically battery technology, in the near future, a new question will arise: Where to locate the vertiports/landing pads for such air taxis? In this study, we propose a vertiport location selection problem. In contrast to existing studies, we allow the demand to be distributed over the whole metropolitan area, modeled as a grid, and exclude certain grid cells from becoming hubs, for example, because of safety/geographical constraints. The combination of these two contributions makes the problem intriguingly difficult to solve with standard solution techniques. We propose a novel variable neighborhood search heuristic, which is able to solve 12 × 12 grid instances within a few seconds of computation time and zero gaps in our experiments, whereas CPLEX needs up to 10 hours. We believe that our study contributes toward the scalable selection of vertiport locations for air taxis.},
  archive      = {J_IJOC},
  author       = {Liting Chen and Sebastian Wandelt and Weibin Dai and Xiaoqian Sun},
  doi          = {10.1287/ijoc.2021.1109},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {834-856},
  shortjournal = {INFORMS J. Comput.},
  title        = {Scalable vertiport hub location selection for air taxi operations in a metropolitan region},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A fast vertex weighting-based local search for finding
minimum connected dominating sets. <em>IJOC</em>, <em>34</em>(2),
817–833. (<a href="https://doi.org/10.1287/ijoc.2021.1106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The minimum connected dominating set (MCDS) problem consists of selecting a minimum set of vertices from an undirected graph, such that each vertex not in this set is adjacent to at least one of the vertices in it, and the subgraph induced by this vertex set is connected. This paper presents a fast vertex weighting (FVW) algorithm for solving the MCDS problem, which integrates several distinguishing features, such as a vertex weighting-based local search with tabu and perturbation strategies to help the search to jump out of the local optima, as well as a search space reduction strategy to improve the search efficiency. Computational experiments on four sets of 112 commonly used public benchmark instances, as well as 15 newly introduced sparse instances, show that FVW is highly competitive compared with the state-of-the-art algorithms in the literature despite its simplicity. FVW improves the previous best-known results for 20 large public benchmark instances while matching the best-known results for all but 2 of the remaining ones. Several ingredients of FVW are investigated to demonstrate the importance of the proposed ideas and techniques.},
  archive      = {J_IJOC},
  author       = {Xinyun Wu and Zhipeng Lü and Fred Glover},
  doi          = {10.1287/ijoc.2021.1106},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {817-833},
  shortjournal = {INFORMS J. Comput.},
  title        = {A fast vertex weighting-based local search for finding minimum connected dominating sets},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). JANOS: An integrated predictive and prescriptive modeling
framework. <em>IJOC</em>, <em>34</em>(2), 807–816. (<a
href="https://doi.org/10.1287/ijoc.2020.1023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Business research practice is witnessing a surge in the integration of predictive modeling and prescriptive analysis. We describe a modeling framework JANOS that seamlessly integrates the two streams of analytics, allowing researchers and practitioners to embed machine learning models in an end-to-end optimization framework. JANOS allows for specifying a prescriptive model using standard optimization modeling elements such as constraints and variables. The key novelty lies in providing modeling constructs that enable the specification of commonly used predictive models within an optimization model, have the features of the predictive model as variables in the optimization model, and incorporate the output of the predictive models as part of the objective. The framework considers two sets of decision variables: regular and predicted. The relationship between the regular and the predicted variables is specified by the user as pretrained predictive models. JANOS currently supports linear regression, logistic regression, and neural network with rectified linear activation functions. In this paper, we demonstrate the flexibility of the framework through an example on scholarship allocation in a student enrollment problem and provide a numeric performance evaluation.},
  archive      = {J_IJOC},
  author       = {David Bergman and Teng Huang and Philip Brooks and Andrea Lodi and Arvind U. Raghunathan},
  doi          = {10.1287/ijoc.2020.1023},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {807-816},
  shortjournal = {INFORMS J. Comput.},
  title        = {JANOS: An integrated predictive and prescriptive modeling framework},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SHEDR: An end-to-end deep neural event detection and
recommendation framework for hyperlocal news using social media.
<em>IJOC</em>, <em>34</em>(2), 790–806. (<a
href="https://doi.org/10.1287/ijoc.2021.1112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Residents often rely on newspapers and television to gather hyperlocal news for community awareness and engagement. More recently, social media have emerged as an increasingly important source of hyperlocal news. Thus far, the literature on using social media to create desirable societal benefits, such as civic awareness and engagement, is still in its infancy. One key challenge in this research stream is to timely and accurately distill information from noisy social media data streams to community members. In this work, we develop SHEDR (social media–based hyperlocal event detection and recommendation), an end-to-end neural event detection and recommendation framework with a particular use case for Twitter to facilitate residents’ information seeking of hyperlocal events. The key model innovation in SHEDR lies in the design of the hyperlocal event detector and the event recommender. First, we harness the power of two popular deep neural network models, the convolutional neural network (CNN) and long short-term memory (LSTM), in a novel joint CNN-LSTM model to characterize spatiotemporal dependencies for capturing unusualness in a region of interest, which is classified as a hyperlocal event. Next, we develop a neural pairwise ranking algorithm for recommending detected hyperlocal events to residents based on their interests. To alleviate the sparsity issue and improve personalization, our algorithm incorporates several types of contextual information covering topic, social, and geographical proximities. We perform comprehensive evaluations based on two large-scale data sets comprising geotagged tweets covering Seattle and Chicago. We demonstrate the effectiveness of our framework in comparison with several state-of-the-art approaches. We show that our hyperlocal event detection and recommendation models consistently and significantly outperform other approaches in terms of precision, recall, and F-1 scores.},
  archive      = {J_IJOC},
  author       = {Yuheng Hu and Yili Hong},
  doi          = {10.1287/ijoc.2021.1112},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {790-806},
  shortjournal = {INFORMS J. Comput.},
  title        = {SHEDR: An end-to-end deep neural event detection and recommendation framework for hyperlocal news using social media},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Iterative prediction-and-optimization for e-logistics
distribution network design. <em>IJOC</em>, <em>34</em>(2), 769–789. (<a
href="https://doi.org/10.1287/ijoc.2021.1107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of online retailers has brought new opportunities to the design of their distribution networks. Notably, for online retailers that do not operate offline stores, their target customers are more sensitive to the quality of logistic services, such as delivery speed and reliability. This paper is motivated by a leading online retailer for cosmetic products on Taobao.com that aimed to improve its logistics efficiency by redesigning its centralized distribution network into a multilevel one. The multilevel distribution network consists of a layer of primary facilities to hold stocks from suppliers and transshipment and a layer of secondary facilities to provide last-mile delivery. There are two major challenges of designing such a facility network. First, online customers can respond significantly to the change of logistics efficiency with the redesigned network, thereby rendering the network optimized under the original demand distribution suboptimal. Second, because online retailers have relatively small sales volumes and are very flexible in choosing facility locations, the facility candidate set can be large, causing the facility location optimization challenging to solve. To this end, we propose an iterative prediction-and-optimization strategy for distribution network design. Specifically, we first develop an artificial neural network (ANN) to predict customer demands, factoring in the logistic service quality given the network and the city-level purchasing power based on demographic statistics. Then, a mixed integer linear programming (MILP) model is formulated to choose facility locations with minimum transportation, facility setup, and package processing costs. We further develop an efficient two-stage heuristic for computing high-quality solutions to the MILP model, featuring an agglomerative hierarchical clustering algorithm and an expectation and maximization algorithm. Subsequently, the ANN demand predictor and two-stage heuristic are integrated for iterative network design. Finally, using a real-world data set, we validate the demand prediction accuracy and demonstrate the mutual interdependence between the demand and network design.},
  archive      = {J_IJOC},
  author       = {Junming Liu and Weiwei Chen and Jingyuan Yang and Hui Xiong and Can Chen},
  doi          = {10.1287/ijoc.2021.1107},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {769-789},
  shortjournal = {INFORMS J. Comput.},
  title        = {Iterative prediction-and-optimization for E-logistics distribution network design},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Practical nonparametric sampling strategies for
quantile-based ordinal optimization. <em>IJOC</em>, <em>34</em>(2),
752–768. (<a href="https://doi.org/10.1287/ijoc.2021.1071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a finite number of stochastic systems, the goal of our problem is to dynamically allocate a finite sampling budget to maximize the probability of selecting the “best” system. Systems are encoded with the probability distributions that govern sample observations, which are unknown and only assumed to belong to a broad family of distributions that need not admit any parametric representation. The best system is defined as the one with the highest quantile value. The objective of maximizing the probability of selecting this best system is not analytically tractable. In lieu of that, we use the rate function for the probability of error relying on large deviations theory. Our point of departure is an algorithm that naively combines sequential estimation and myopic optimization. This algorithm is shown to be asymptotically optimal; however, it exhibits poor finite-time performance and does not lead itself to implementation in settings with a large number of systems. To address this, we propose practically implementable variants that retain the asymptotic performance of the former while dramatically improving its finite-time performance.},
  archive      = {J_IJOC},
  author       = {Dongwook Shin and Mark Broadie and Assaf Zeevi},
  doi          = {10.1287/ijoc.2021.1071},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {752-768},
  shortjournal = {INFORMS J. Comput.},
  title        = {Practical nonparametric sampling strategies for quantile-based ordinal optimization},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distributionally robust optimization under a
decision-dependent ambiguity set with applications to machine scheduling
and humanitarian logistics. <em>IJOC</em>, <em>34</em>(2), 729–751. (<a
href="https://doi.org/10.1287/ijoc.2021.1096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a new class of distributionally robust optimization problems under decision-dependent ambiguity sets. In particular, as our ambiguity sets, we consider balls centered on a decision-dependent probability distribution. The balls are based on a class of earth mover’s distances that includes both the total variation distance and the Wasserstein metrics. We discuss the main computational challenges in solving the problems of interest and provide an overview of various settings leading to tractable formulations. Some of the arising side results, such as the mathematical programming expressions for robustified risk measures in a discrete space, are also of independent interest. Finally, we rely on state-of-the-art modeling techniques from machine scheduling and humanitarian logistics to arrive at potentially practical applications, and present a numerical study for a novel risk-averse scheduling problem with controllable processing times.},
  archive      = {J_IJOC},
  author       = {Nilay Noyan and Gábor Rudolf and Miguel Lejeune},
  doi          = {10.1287/ijoc.2021.1096},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {729-751},
  shortjournal = {INFORMS J. Comput.},
  title        = {Distributionally robust optimization under a decision-dependent ambiguity set with applications to machine scheduling and humanitarian logistics},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Influence maximization with latency requirements on social
networks. <em>IJOC</em>, <em>34</em>(2), 710–728. (<a
href="https://doi.org/10.1287/ijoc.2021.1095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Targeted marketing strategies are of significant interest in the smartapp economy. Typically, one seeks to identify individuals to strategically target in a social network so that the network is influenced at a minimal cost. In many practical settings, the effects of direct influence predominate, leading to the positive influence dominating set with partial payments (PIDS-PP) problem that we discuss in this paper. The PIDS-PP problem is NP-complete because it generalizes the dominating set problem. We discuss several mixed integer programming formulations for the PIDS-PP problem. First, we describe two compact formulations on the payment space. We then develop a stronger compact extended formulation. We show that when the underlying graph is a tree, this compact extended formulation provides integral solutions for the node selection variables. In conjunction, we describe a polynomial-time dynamic programming algorithm for the PIDS-PP problem on trees. We project the compact extended formulation onto the payment space, providing an equivalently strong formulation that has exponentially many constraints. We present a polynomial time algorithm to solve the associated separation problem. Our computational experience on a test bed of 100 real-world graph instances (with up to approximately 465,000 nodes and 835,000 edges) demonstrates the efficacy of our strongest payment space formulation. It finds solutions that are on average 0.4\% from optimality and solves 80 of the 100 instances to optimality.},
  archive      = {J_IJOC},
  author       = {S. Raghavan and Rui Zhang},
  doi          = {10.1287/ijoc.2021.1095},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {710-728},
  shortjournal = {INFORMS J. Comput.},
  title        = {Influence maximization with latency requirements on social networks},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal power flow in distribution networks under n – 1
disruptions: A multistage stochastic programming approach.
<em>IJOC</em>, <em>34</em>(2), 690–709. (<a
href="https://doi.org/10.1287/ijoc.2021.1080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contingency research to find optimal operations and postcontingency recovery plans in distribution networks has gained major attention in recent years. To this end, we consider a multiperiod optimal power flow problem in distribution networks, subject to the N – 1 contingency in which a line or distributed energy resource fails. The contingency can be modeled as a stochastic disruption, an event with random magnitude and timing. Assuming a specific recovery time, we formulate a multistage stochastic convex program and develop a decomposition algorithm based on stochastic dual dynamic programming. Realistic modeling features, such as linearized AC power flow physics, engineering limits, and battery devices with realistic efficiency curves, are incorporated. We present extensive computational tests to show the efficiency of our decomposition algorithm and out-of-samplex performance of our solution compared with its deterministic counterpart. Operational insights on battery utilization, component hardening, and length of recovery phase are obtained by performing analyses from stochastic disruption-aware solutions.},
  archive      = {J_IJOC},
  author       = {Haoxiang Yang and Harsha Nagarajan},
  doi          = {10.1287/ijoc.2021.1080},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {690-709},
  shortjournal = {INFORMS J. Comput.},
  title        = {Optimal power flow in distribution networks under n – 1 disruptions: A multistage stochastic programming approach},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MathOptInterface: A data structure for mathematical
optimization problems. <em>IJOC</em>, <em>34</em>(2), 672–689. (<a
href="https://doi.org/10.1287/ijoc.2021.1067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce MathOptInterface, an abstract data structure for representing mathematical optimization problems based on combining predefined functions and sets. MathOptInterface is significantly more general than existing data structures in the literature, encompassing, for example, a spectrum of problems classes from integer programming with indicator constraints to bilinear semidefinite programming. We also outline an automated rewriting system between equivalent formulations of a constraint. MathOptInterface has been implemented in practice, forming the foundation of a recent rewrite of JuMP, an open-source algebraic modeling language in the Julia language. The regularity of the MathOptInterface representation leads naturally to a general file format for mathematical optimization we call MathOptFormat. In addition, the automated rewriting system provides modeling power to users while making it easy to connect new solvers to JuMP.},
  archive      = {J_IJOC},
  author       = {Benoît Legat and Oscar Dowson and Joaquim Dias Garcia and Miles Lubin},
  doi          = {10.1287/ijoc.2021.1067},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {672-689},
  shortjournal = {INFORMS J. Comput.},
  title        = {MathOptInterface: A data structure for mathematical optimization problems},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The maximum k-colorable subgraph problem and related
problems. <em>IJOC</em>, <em>34</em>(1), 656–669. (<a
href="https://doi.org/10.1287/ijoc.2021.1086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The maximum k-colorable subgraph (MkCS) problem is to find an induced k-colorable subgraph with maximum cardinality in a given graph. This paper is an in-depth analysis of the MkCS problem that considers various semidefinite programming relaxations, including their theoretical and numerical comparisons. To simplify these relaxations, we exploit the symmetry arising from permuting the colors, as well as the symmetry of the given graphs when applicable. We also show how to exploit invariance under permutations of the subsets for other partition problems and how to use the MkCS problem to derive bounds on the chromatic number of a graph. Our numerical results verify that the proposed relaxations provide strong bounds for the MkCS problem and that those outperform existing bounds for most of the test instances.},
  archive      = {J_IJOC},
  author       = {Olga Kuryatnikova and Renata Sotirov and Juan C. Vera},
  doi          = {10.1287/ijoc.2021.1086},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {656-669},
  shortjournal = {INFORMS J. Comput.},
  title        = {The maximum k-colorable subgraph problem and related problems},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new likelihood ratio method for training artificial neural
networks. <em>IJOC</em>, <em>34</em>(1), 638–655. (<a
href="https://doi.org/10.1287/ijoc.2021.1088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate a new approach to compute the gradients of artificial neural networks (ANNs), based on the so-called push-out likelihood ratio method. Unlike the widely used backpropagation (BP) method that requires continuity of the loss function and the activation function, our approach bypasses this requirement by injecting artificial noises into the signals passed along the neurons. We show how this approach has a similar computational complexity as BP, and moreover is more advantageous in terms of removing the backward recursion and eliciting transparent formulas. We also formalize the connection between BP, a pivotal technique for training ANNs, and infinitesimal perturbation analysis, a classic path-wise derivative estimation approach, so that both our new proposed methods and BP can be better understood in the context of stochastic gradient estimation. Our approach allows efficient training for ANNs with more flexibility on the loss and activation functions, and shows empirical improvements on the robustness of ANNs under adversarial attacks and corruptions of natural noises.},
  archive      = {J_IJOC},
  author       = {Yijie Peng and Li Xiao and Bernd Heidergott and L. Jeff Hong and Henry Lam},
  doi          = {10.1287/ijoc.2021.1088},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {638-655},
  shortjournal = {INFORMS J. Comput.},
  title        = {A new likelihood ratio method for training artificial neural networks},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Combined global and local search for optimization with
gaussian process models. <em>IJOC</em>, <em>34</em>(1), 622–637. (<a
href="https://doi.org/10.1287/ijoc.2021.1078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gaussian process (GP) model based optimization is widely applied in simulation and machine learning. In general, it first estimates a GP model based on a few observations from the true response and then uses this model to guide the search, aiming to quickly locate the global optimum. Despite its successful applications, it has several limitations that may hinder its broader use. First, building an accurate GP model can be difficult and computationally expensive, especially when the response function is multimodal or varies significantly over the design space. Second, even with an appropriate model, the search process can be trapped in suboptimal regions before moving to the global optimum because of the excessive effort spent around the current best solution. In this work, we adopt the additive global and local GP (AGLGP) model in the optimization framework. The model is rooted in the inducing points based GP sparse approximations and is combined with independent local models in different regions. With these properties, the AGLGP model is suitable for multimodal responses with relatively large data sizes. Based on this AGLGP model, we propose a combined global and local search for optimization (CGLO) algorithm. It first divides the whole design space into disjoint local regions and identifies a promising region with the global model. Next, a local model in the selected region is fit to guide detailed search within this region. The algorithm then switches back to the global step when a good local solution is found. The global and local natures of CGLO enable it to enjoy the benefits of both global and local search to efficiently locate the global optimum.},
  archive      = {J_IJOC},
  author       = {Qun Meng and Songhao Wang and Szu Hui Ng},
  doi          = {10.1287/ijoc.2021.1078},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {622-637},
  shortjournal = {INFORMS J. Comput.},
  title        = {Combined global and local search for optimization with gaussian process models},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Statistical tests for cross-validation of kriging models.
<em>IJOC</em>, <em>34</em>(1), 607–621. (<a
href="https://doi.org/10.1287/ijoc.2021.1072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kriging or Gaussian process models are popular metamodels (surrogate models or emulators) of simulation models; these metamodels give predictors for input combinations that are not simulated. To validate these metamodels for computationally expensive simulation models, the analysts often apply computationally efficient cross-validation. In this paper, we derive new statistical tests for so-called leave-one-out cross-validation. Graphically, we present these tests as scatterplots augmented with confidence intervals that use the estimated variances of the Kriging predictors. To estimate the true variances of these predictors, we might use bootstrapping. Like other statistical tests, our tests—with or without bootstrapping—have type I and type II error probabilities; to estimate these probabilities, we use Monte Carlo experiments. We also use such experiments to investigate statistical convergence. To illustrate the application of our tests, we use (i) an example with two inputs and (ii) the popular borehole example with eight inputs.},
  archive      = {J_IJOC},
  author       = {Jack P. C. Kleijnen and Wim C. M. van Beers},
  doi          = {10.1287/ijoc.2021.1072},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {607-621},
  shortjournal = {INFORMS J. Comput.},
  title        = {Statistical tests for cross-validation of kriging models},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Speeding up paulson’s procedure for large-scale problems
using parallel computing. <em>IJOC</em>, <em>34</em>(1), 586–606. (<a
href="https://doi.org/10.1287/ijoc.2020.1054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of computing technology, using parallel computing to solve large-scale ranking-and-selection (R&amp;amp;S) problems has emerged as an important research topic. However, direct implementation of traditionally fully sequential procedures in parallel computing environments may encounter various problems. First, the scheme of all-pairwise comparisons, which is commonly used in fully sequential procedures, requires a large amount of computation and significantly slows down the selection process. Second, traditional fully sequential procedures require frequent communication and coordination among processors, which are also not efficient in parallel computing environments. In this paper, we propose three modifications on one classical fully sequential procedure, Paulson’s procedure, to speed up its selection process in parallel computing environments. First, we show that if no common random numbers are used, then we can significantly reduce the computation spent on all-pairwise comparisons at each round. Second, by batching different alternatives, we show that we can reduce the communication cost among the processors, leading the procedure to achieve better performance. Third, to boost the procedure’s final-stage selection, when the number of surviving alternatives is less than the number of processors, we suggest to sample all surviving alternatives to the maximal number of observations that they should take. We show that, after these modifications, the procedure remains statistically valid and is more efficient compared with existing parallel procedures in the literature.},
  archive      = {J_IJOC},
  author       = {Ying Zhong and Shaoxuan Liu and Jun Luo and L. Jeff Hong},
  doi          = {10.1287/ijoc.2020.1054},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {586-606},
  shortjournal = {INFORMS J. Comput.},
  title        = {Speeding up paulson’s procedure for large-scale problems using parallel computing},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multilevel simulation optimization approach for quantile
functions. <em>IJOC</em>, <em>34</em>(1), 569–585. (<a
href="https://doi.org/10.1287/ijoc.2020.1049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A quantile is a popular performance measure for a stochastic system to evaluate its variability and risk. To reduce the risk, selecting the actions that minimize the tail quantiles of some loss distributions is typically of interest for decision makers. When the loss distribution is observed via simulations, evaluating and optimizing its quantile can be challenging, especially when the simulations are expensive as it may cost a large number of simulation runs to obtain accurate quantile estimators. In this work, we propose a multilevel metamodel (cokriging)-based algorithm to optimize quantiles more efficiently. Utilizing nondecreasing properties of quantiles, we first search on cheaper and informative lower quantiles, which are more accurate and easier to optimize. The quantile level iteratively increases to the objective level, and the search has a focus on the possible promising regions identified by the previous levels. This enables us to leverage the accurate information from the lower quantiles to find the optimums faster and improve algorithm efficiency.},
  archive      = {J_IJOC},
  author       = {Songhao Wang and Szu Hui Ng and William Benjamin Haskell},
  doi          = {10.1287/ijoc.2020.1049},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {569-585},
  shortjournal = {INFORMS J. Comput.},
  title        = {A multilevel simulation optimization approach for quantile functions},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic sampling allocation under finite simulation budget
for feasibility determination. <em>IJOC</em>, <em>34</em>(1), 557–568.
(<a href="https://doi.org/10.1287/ijoc.2020.1057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monte Carlo simulation is a commonly used tool for evaluating the performance of complex stochastic systems. In practice, simulation can be expensive, especially when comparing a large number of alternatives, thus motivating the need to intelligently allocate simulation replications. Given a finite set of alternatives whose means are estimated via simulation, we consider the problem of determining the subset of alternatives that have means smaller than a fixed threshold. A dynamic sampling procedure that possesses not only asymptotic optimality, but also desirable finite-sample properties is proposed. Theoretical results show that there is a significant difference between finite-sample optimality and asymptotic optimality. Numerical experiments substantiate the effectiveness of the new method.},
  archive      = {J_IJOC},
  author       = {Zhongshun Shi and Yijie Peng and Leyuan Shi and Chun-Hung Chen and Michael C. Fu},
  doi          = {10.1287/ijoc.2020.1057},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {557-568},
  shortjournal = {INFORMS J. Comput.},
  title        = {Dynamic sampling allocation under finite simulation budget for feasibility determination},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Detecting product adoption intentions via multiview deep
learning. <em>IJOC</em>, <em>34</em>(1), 541–556. (<a
href="https://doi.org/10.1287/ijoc.2021.1083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting product adoption intentions on social media could yield significant value in a wide range of applications, such as personalized recommendations and targeted marketing. In the literature, no study has explored the detection of product adoption intentions on social media, and only a few relevant studies have focused on purchase intention detection for products in one or several categories. Focusing on a product category rather than a specific product is too coarse-grained for precise advertising. Additionally, existing studies primarily focus on using one type of text representation in target social media posts, ignoring the major yet unexplored potential of fusing different text representations. In this paper, we first formulate the problem of product adoption intention mining and demonstrate the necessity of studying this problem and its practical value. To detect a product adoption intention for an individual product, we propose a novel and general multiview deep learning model that simultaneously taps into the capability of multiview learning in leveraging different representations and deep learning in learning latent data representations using a flexible nonlinear transformation. Specifically, the proposed model leverages three different text representations from a multiview perspective and takes advantage of local and long-term word relations by integrating convolutional neural network (CNN) and long short-term memory (LSTM) modules. Extensive experiments on three Twitter datasets demonstrate the effectiveness of the proposed multiview deep learning model compared with the existing benchmark methods. This study also significantly contributes research insights to the literature about intention mining and provides business value to relevant stakeholders such as product providers.},
  archive      = {J_IJOC},
  author       = {Zhu Zhang and Xuan Wei and Xiaolong Zheng and Qiudan Li and Daniel Dajun Zeng},
  doi          = {10.1287/ijoc.2021.1083},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {541-556},
  shortjournal = {INFORMS J. Comput.},
  title        = {Detecting product adoption intentions via multiview deep learning},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Analyzing firm reports for volatility prediction: A
knowledge-driven text-embedding approach. <em>IJOC</em>, <em>34</em>(1),
522–540. (<a href="https://doi.org/10.1287/ijoc.2020.1046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting stock return volatility is the key to investment and risk management. Traditional volatility-forecasting methods primarily rely on stochastic models. More recently, many machine-learning approaches, particularly text-mining techniques, have been implemented to predict stock return volatility, thus taking advantage of the availability of large amounts of unstructured data such as firm financial reports. Most existing studies develop simple but effective models to analyze text, such as dictionary-based matching algorithms that use a set of manually constructed keywords. However, the latent and deep semantics encoded in text are usually neglected. In this study, we build on recent progress in representation learning and propose a novel word-embedding method that incorporates external knowledge from a well-known finance-domain lexicon (the Loughran and McDonald (2011) word list), which helps us learn semantic relationships among words in firm reports for better volatility prediction. Using over 10 years of annual reports from Russell 3000 firms, we empirically show that, compared with cutting-edge benchmarks, our proposed method achieves significant improvement in terms of prediction error, for example, a 28.4\% reduction on average. We also discuss the practical and methodological implications of our findings. Our financial-specific word-embedding program is available as open-source information so that researchers can use it to analyze financial reports and assess financial risks.},
  archive      = {J_IJOC},
  author       = {Yi Yang and Kunpeng Zhang and Yangyang Fan},
  doi          = {10.1287/ijoc.2020.1046},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {522-540},
  shortjournal = {INFORMS J. Comput.},
  title        = {Analyzing firm reports for volatility prediction: A knowledge-driven text-embedding approach},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving reliability estimation for individual numeric
predictions: A machine learning approach. <em>IJOC</em>, <em>34</em>(1),
503–521. (<a href="https://doi.org/10.1287/ijoc.2020.1019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerical predictive modeling is widely used in different application domains. Although many modeling techniques have been proposed, and a number of different aggregate accuracy metrics exist for evaluating the overall performance of predictive models, other important aspects, such as the reliability (or confidence and uncertainty) of individual predictions, have been underexplored. We propose to use estimated absolute prediction error as the indicator of individual prediction reliability, which has the benefits of being intuitive and providing highly interpretable information to decision makers, as well as allowing for more precise evaluation of reliability estimation quality. As importantly, the proposed reliability indicator allows the reframing of reliability estimation itself as a canonical numeric prediction problem, which makes the proposed approach general-purpose (i.e., it can work in conjunction with any outcome prediction model), alleviates the need for distributional assumptions, and enables the use of advanced, state-of-the-art machine learning techniques to learn individual prediction reliability patterns directly from data. Extensive experimental results on multiple real-world data sets show that the proposed machine learning-based approach can significantly improve individual prediction reliability estimation as compared with a number of baselines from prior work, especially in more complex predictive scenarios.},
  archive      = {J_IJOC},
  author       = {Gediminas Adomavicius and Yaqiong Wang},
  doi          = {10.1287/ijoc.2020.1019},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {503-521},
  shortjournal = {INFORMS J. Comput.},
  title        = {Improving reliability estimation for individual numeric predictions: A machine learning approach},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On cluster-aware supervised learning: Frameworks, convergent
algorithms, and applications. <em>IJOC</em>, <em>34</em>(1), 481–502.
(<a href="https://doi.org/10.1287/ijoc.2020.1053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a cluster-aware supervised learning (CluSL) framework, which integrates the clustering analysis with supervised learning. The objective of CluSL is to simultaneously find the best clusters of the data points and minimize the sum of loss functions within each cluster. This framework has many potential applications in healthcare, operations management, manufacturing, and so on. Because CluSL, in general, is nonconvex, we develop a regularized alternating minimization (RAM) algorithm to solve it, where at each iteration, we penalize the distance between the current clustering solution and the one from the previous iteration. By choosing a proper penalty function, we show that each iteration of the RAM algorithm can be computed efficiently. We further prove that the proposed RAM algorithm will always converge to a stationary point within a finite number of iterations. This is the first known convergence result in cluster-aware learning literature. Furthermore, we extend CluSL to the high-dimensional data sets, termed the F-CluSL framework. In F-CluSL, we cluster features and minimize loss function at the same time. Similarly, to solve F-CluSL, a variant of the RAM algorithm (i.e., F-RAM) is developed and proven to be convergent to an ∈-stationary point. Our numerical studies demonstrate that the proposed CluSL and F-CluSL can outperform the existing ones such as random forests and support vector classification, both in the interpretability of learning results and in prediction accuracy.},
  archive      = {J_IJOC},
  author       = {Shutong Chen and Weijun Xie},
  doi          = {10.1287/ijoc.2020.1053},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {481-502},
  shortjournal = {INFORMS J. Comput.},
  title        = {On cluster-aware supervised learning: Frameworks, convergent algorithms, and applications},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning for constrained optimization: Identifying optimal
active constraint sets. <em>IJOC</em>, <em>34</em>(1), 463–480. (<a
href="https://doi.org/10.1287/ijoc.2020.1037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many engineered systems, optimization is used for decision making at time scales ranging from real-time operation to long-term planning. This process often involves solving similar optimization problems over and over again with slightly modified input parameters, often under tight latency requirements. We consider the problem of using the information available through this repeated solution process to learn important characteristics of the optimal solution as a function of the input parameters. Our proposed method is based on learning relevant sets of active constraints, from which the optimal solution can be obtained efficiently. Using active sets as features preserves information about the physics of the system, enables interpretable results, accounts for relevant safety constraints, and is easy to represent and encode. However, the total number of active sets is also very large, as it grows exponentially with system size. The key contribution of this paper is a streaming algorithm that learns the relevant active sets from training samples consisting of the input parameters and the corresponding optimal solution, without any restrictions on the problem type, problem structure or probability distribution of the input parameters. The algorithm comes with theoretical performance guarantees and is shown to converge fast for problem instances with a small number of relevant active sets. It can thus be used to establish simultaneously learn the relevant active sets and the practicability of the learning method. Through case studies in optimal power flow, supply chain planning, and shortest path routing, we demonstrate that often only a few active sets are relevant in practice, suggesting that active sets provide an appropriate level of abstraction for a learning algorithm to target.},
  archive      = {J_IJOC},
  author       = {Sidhant Misra and Line Roald and Yeesian Ng},
  doi          = {10.1287/ijoc.2020.1037},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {463-480},
  shortjournal = {INFORMS J. Comput.},
  title        = {Learning for constrained optimization: Identifying optimal active constraint sets},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Picker routing in AGV-assisted order picking systems.
<em>IJOC</em>, <em>34</em>(1), 440–462. (<a
href="https://doi.org/10.1287/ijoc.2021.1060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To reduce unproductive picker walking in traditional picker-to-parts warehousing systems, automated guided vehicles (AGVs) are used to support human order pickers. In an AGV-assisted order-picking system, each human order picker is accompanied by an AGV during the order-picking process. AGVs receive the picked items and, once a picking order is complete, autonomously bring the collected items to the shipping area. Meanwhile, a new AGV is requested to meet the picker at the first storage position of the next picking order. Thus, the picker does not have to return to a central depot and continuously picks order after order. This paper addresses both the routing of an AGV-assisted picker through a single-block, parallel-aisle warehouse and the sequencing of incoming orders. We present an exact polynomial time routing algorithm for the case of a given order sequence, which is an extension of the algorithm of Ratliff and Rosenthal [Ratliff HD, Rosenthal AS (1983) Order-picking in a rectangular warehouse: A solvable case of the traveling salesman problem. Oper. Res. 1(3):507–521], and a heuristic for the case in which order sequencing is part of the problem. In addition, we investigate the use of highly effective traveling salesman problem (TSP) solvers that can be applied after a transformation of both problem types into a standard TSP. The numerical studies address the performance of these methods and study the impact of AGV usage on picker travel: by using AGVs to avoid returns to the depot and by sequencing in (near-) optimal fashion, picker walking can be reduced by about 20\% compared with a traditional setting. Sharing AGVs among the picker workforce enables a pooling effect so that, in larger warehouses, only about 1.5 AGVs per picker are required to avoid picker waiting.},
  archive      = {J_IJOC},
  author       = {Maximilian Löffler and Nils Boysen and Michael Schneider},
  doi          = {10.1287/ijoc.2021.1060},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {440-462},
  shortjournal = {INFORMS J. Comput.},
  title        = {Picker routing in AGV-assisted order picking systems},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Template-based minor embedding for adiabatic quantum
optimization. <em>IJOC</em>, <em>34</em>(1), 427–439. (<a
href="https://doi.org/10.1287/ijoc.2021.1065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum annealing (QA) can be used to quickly obtain near-optimal solutions for quadratic unconstrained binary optimization (QUBO) problems. In QA hardware, each decision variable of a QUBO should be mapped to one or more adjacent qubits in such a way that pairs of variables defining a quadratic term in the objective function are mapped to some pair of adjacent qubits. However, qubits have limited connectivity in existing QA hardware. This has spurred work on preprocessing algorithms for embedding the graph representing problem variables with quadratic terms into the hardware graph representing qubits adjacencies, such as the Chimera graph in hardware produced by D-Wave Systems. In this paper, we use integer linear programming to search for an embedding of the problem graph into certain classes of minors of the Chimera graph, which we call template embeddings. One of these classes corresponds to complete bipartite graphs, for which we show the limitation of the existing approach based on minimum odd cycle transversals (OCTs). One of the formulations presented is exact and thus can be used to certify the absence of a minor embedding using that template. On an extensive test set consisting of random graphs from five different classes of varying size and sparsity, we can embed more graphs than a state-of-the-art OCT-based approach, our approach scales better with the hardware size, and the runtime is generally orders of magnitude smaller.},
  archive      = {J_IJOC},
  author       = {Thiago Serra and Teng Huang and Arvind U. Raghunathan and David Bergman},
  doi          = {10.1287/ijoc.2021.1065},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {427-439},
  shortjournal = {INFORMS J. Comput.},
  title        = {Template-based minor embedding for adiabatic quantum optimization},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A general model and efficient algorithms for reliable
facility location problem under uncertain disruptions. <em>IJOC</em>,
<em>34</em>(1), 407–426. (<a
href="https://doi.org/10.1287/ijoc.2021.1063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the reliable uncapacitated facility location problem in which facilities are subject to uncertain disruptions. A two-stage distributionally robust model is formulated, which optimizes the facility location decisions so as to minimize the fixed facility location cost and the expected transportation cost of serving customers under the worst-case disruption distribution. The model is formulated in a general form, where the uncertain joint distribution of disruptions is partially characterized and is allowed to have any prespecified dependency structure. This model extends several related models in the literature, including the stochastic one with explicitly given disruption distribution and the robust one with moment information on disruptions. An efficient cutting plane algorithm is proposed to solve this model, where the separation problem is solved respectively by a polynomial-time algorithm in the stochastic case and by a column generation approach in the robust case. Extensive numerical study shows that the proposed cutting plane algorithm not only outperforms the best-known algorithm in the literature for the stochastic problem under independent disruptions but also efficiently solves the robust problem under correlated disruptions. The practical performance of the robust models is verified in a simulation based on historical typhoon data in China. The numerical results further indicate that the robust model with even a small amount of information on disruption correlation can mitigate the conservativeness and improve the location decision significantly.},
  archive      = {J_IJOC},
  author       = {Yongzhen Li and Xueping Li and Jia Shu and Miao Song and Kaike Zhang},
  doi          = {10.1287/ijoc.2021.1063},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {407-426},
  shortjournal = {INFORMS J. Comput.},
  title        = {A general model and efficient algorithms for reliable facility location problem under uncertain disruptions},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Predictive search for capacitated multi-item lot sizing
problems. <em>IJOC</em>, <em>34</em>(1), 385–406. (<a
href="https://doi.org/10.1287/ijoc.2021.1073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For capacitated multi-item lot sizing problems, we propose a predictive search method that integrates machine learning/advanced analytics, mathematical programming, and heuristic search into a single framework. Advanced analytics can predict the probability that an event will happen and has been applied to pressing industry issues, such as credit scoring, risk management, and default management. Although little research has applied such technique for lot sizing problems, we observe that advanced analytics can uncover optimal patterns of setup variables given properties associated with the problems, such as problem attributes, and solution values yielded by linear programming relaxation, column generation, and Lagrangian relaxation. We, therefore, build advanced analytics models that yield information about how likely a solution pattern is the same as the optimum, which is insightful information used to partition the solution space into incumbent, superincumbent, and nonincumbent regions where an analytics-driven heuristic search procedure is applied to build restricted subproblems. These subproblems are solved by a combined mathematical programming technique to improve solution quality iteratively. We prove that the predictive search method can converge to the global optimal solution point. The discussion is followed by computational tests, where comparisons with other methods indicate that our approach can obtain better results for the benchmark problems than other state-of-the-art methods.},
  archive      = {J_IJOC},
  author       = {Tao Wu},
  doi          = {10.1287/ijoc.2021.1073},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {385-406},
  shortjournal = {INFORMS J. Comput.},
  title        = {Predictive search for capacitated multi-item lot sizing problems},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Combinatorial heuristics for inventory routing problems.
<em>IJOC</em>, <em>34</em>(1), 370–384. (<a
href="https://doi.org/10.1287/ijoc.2021.1064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the deterministic inventory routing problem over a discrete finite time horizon. Given clients on a metric, each with daily demands that must be delivered from a depot and holding costs over the planning horizon, an optimal solution selects a set of daily tours through a subset of clients to deliver all demands before they are due and minimizes the total holding and tour routing costs over the horizon. In the capacitated case, a limited number of vehicles are available, where each vehicle makes at most one trip per day. Each trip from the depot is allowed to carry a limited amount of supply to deliver. We develop fast heuristics for both cases by solving a family of prize-collecting Steiner tree instances. Computational experiments show our heuristics can find near-optimal solutions for both cases and substantially reduce the runtime compared with a pure mixed integer programming formulation approach.},
  archive      = {J_IJOC},
  author       = {Ziye Tang and Yang Jiao and R. Ravi},
  doi          = {10.1287/ijoc.2021.1064},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {370-384},
  shortjournal = {INFORMS J. Comput.},
  title        = {Combinatorial heuristics for inventory routing problems},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). State-variable modeling for a class of two-stage stochastic
optimization problems. <em>IJOC</em>, <em>34</em>(1), 354–369. (<a
href="https://doi.org/10.1287/ijoc.2020.1044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers a class of two-stage stochastic mixed-integer optimization problems where, for a given first-stage solution, we can determine the optimal values of recourse variables sequentially. This class of problems arises in a wide variety of applications. In the case of multivariate discrete distributions for uncertain parameters, a standard stochastic programming formulation of these problems involves an exponential number of scenarios, therefore an exponential number of variables and constraints. We propose a new mixed-integer programming modeling approach where the number of variables and constraints is independent of the number of scenarios and scales at most pseudopolynomially with the problem size. The proposed modeling approach relies on state variables that track the system’s state as the uncertainty realizes sequentially. We demonstrate the advantages of the proposed approach in two applications arising in project scheduling and operating room allocation.},
  archive      = {J_IJOC},
  author       = {Hossein Hashemi Doulabi and Shabbir Ahmed and George Nemhauser},
  doi          = {10.1287/ijoc.2020.1044},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {354-369},
  shortjournal = {INFORMS J. Comput.},
  title        = {State-variable modeling for a class of two-stage stochastic optimization problems},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The value of randomized solutions in mixed-integer
distributionally robust optimization problems. <em>IJOC</em>,
<em>34</em>(1), 333–353. (<a
href="https://doi.org/10.1287/ijoc.2020.1042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Randomized decision making refers to the process of making decisions randomly according to the outcome of an independent randomization device, such as a dice roll or a coin flip. The concept is unconventional, and somehow counterintuitive, in the domain of mathematical programming, in which deterministic decisions are usually sought even when the problem parameters are uncertain. However, it has recently been shown that using a randomized, rather than a deterministic, strategy in nonconvex distributionally robust optimization (DRO) problems can lead to improvements in their objective values. It is still unknown, though, what is the magnitude of improvement that can be attained through randomization or how to numerically find the optimal randomized strategy. In this paper, we study the value of randomization in mixed-integer DRO problems and show that it is bounded by the improvement achievable through its continuous relaxation. Furthermore, we identify conditions under which the bound is tight. We then develop algorithmic procedures, based on column generation, for solving both single- and two-stage linear DRO problems with randomization that can be used with both moment-based and Wasserstein ambiguity sets. Finally, we apply the proposed algorithm to solve three classical discrete DRO problems: the assignment problem, the uncapacitated facility location problem, and the capacitated facility location problem and report numerical results that show the quality of our bounds, the computational efficiency of the proposed solution method, and the magnitude of performance improvement achieved by randomized decisions.},
  archive      = {J_IJOC},
  author       = {Erick Delage and Ahmed Saif},
  doi          = {10.1287/ijoc.2020.1042},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {333-353},
  shortjournal = {INFORMS J. Comput.},
  title        = {The value of randomized solutions in mixed-integer distributionally robust optimization problems},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Solving the type-2 assembly line balancing with setups using
logic-based benders decomposition. <em>IJOC</em>, <em>34</em>(1),
315–332. (<a href="https://doi.org/10.1287/ijoc.2020.1015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We solve the type-2 assembly line balancing problem in the presence of sequence-dependent setup times, denoted SUALBP-2. The problem consists of a set of tasks of a product, requiring to be processed in different assembly stations. Each task has a definite processing and setup times. The magnitude of setup times for each task is dependent on the processing sequence within each station. Processing and setup times of tasks assigned to each station constitute the station time. The goal is to minimize the cycle time (the maximum station time) by optimally (i) assigning tasks to assembly stations and (ii) sequencing these tasks within each station. To solve this challenging optimization problem, we first improve upon an existing mixed-integer programming (MIP) model by our proposed lower and upper bounds. These enhancements reduce the MIP model’s (solved CPLEX) average optimality gap from 41.61\% to 20.77\% on extra-large instances of the problem. To further overcome the intractability of the MIP model, we develop an exact logic-based Benders decomposition (LBBD) algorithm. The LBBD algorithm effectively incorporates a novel two-phase solution approach, the lower and upper bounds, various preprocessing techniques, relaxations, and valid inequalities. Using existing benchmarks in the literature, we demonstrate that our LBBD algorithm finds integer feasible solutions for 100\% of all 788 instances (64\% for the MIP), verifies optimality for 47\% of instances (37\% for the MIP), and achieves an average optimality gap of 5.04\% (7.72\% for the MIP obtained over 64\% solved small instances). The LBBD algorithm also significantly reduces the computational time required to solve these benchmarks.},
  archive      = {J_IJOC},
  author       = {Hassan Zohali and Bahman Naderi and Vahid Roshanaei},
  doi          = {10.1287/ijoc.2020.1015},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {315-332},
  shortjournal = {INFORMS J. Comput.},
  title        = {Solving the type-2 assembly line balancing with setups using logic-based benders decomposition},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Integer programming, constraint programming, and hybrid
decomposition approaches to discretizable distance geometry problems.
<em>IJOC</em>, <em>34</em>(1), 297–314. (<a
href="https://doi.org/10.1287/ijoc.2020.1039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given an integer dimension K and a simple, undirected graph G with positive edge weights, the Distance Geometry Problem (DGP) aims to find a realization function mapping each vertex to a coordinate in RK such that the distance between pairs of vertex coordinates is equal to the corresponding edge weights in G. The so-called discretization assumptions reduce the search space of the realization to a finite discrete one, which can be explored via the branch-and-prune (BP) algorithm. Given a discretization vertex order in G, the BP algorithm constructs a binary tree where the nodes at a layer provide all possible coordinates of the vertex corresponding to that layer. The focus of this paper is on finding optimal BP trees for a class of discretizable DGPs. More specifically, we aim to find a discretization vertex order in G that yields a BP tree with the least number of branches. We propose an integer programming formulation and three constraint programming formulations that all significantly outperform the state-of-the-art cutting-plane algorithm for this problem. Moreover, motivated by the difficulty in solving instances with a large and low-density input graph, we develop two hybrid decomposition algorithms, strengthened by a set of valid inequalities, which further improve the solvability of the problem.},
  archive      = {J_IJOC},
  author       = {Moira MacNeil and Merve Bodur},
  doi          = {10.1287/ijoc.2020.1039},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {297-314},
  shortjournal = {INFORMS J. Comput.},
  title        = {Integer programming, constraint programming, and hybrid decomposition approaches to discretizable distance geometry problems},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exact and approximation algorithms for the expanding search
problem. <em>IJOC</em>, <em>34</em>(1), 281–296. (<a
href="https://doi.org/10.1287/ijoc.2020.1047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Suppose a target is hidden in one of the vertices of an edge-weighted graph according to a known probability distribution. Starting from a fixed root node, an expanding search visits the vertices sequentially until it finds the target, where the next vertex can be reached from any of the previously visited vertices. That is, the time to reach the next vertex equals the shortest-path distance from the set of all previously visited vertices. The expanding search problem then asks for a sequence of the nodes, so as to minimize the expected time to finding the target. This problem has numerous applications, such as searching for hidden explosives, mining coal, and disaster relief. In this paper, we develop exact algorithms and heuristics, including a branch-and-cut procedure, a greedy algorithm with a constant-factor approximation guarantee, and a local search procedure based on a spanning-tree neighborhood. Computational experiments show that our branch-and-cut procedure outperforms existing methods for instances with nonuniform probability distributions and that both our heuristics compute near-optimal solutions with little computational effort.},
  archive      = {J_IJOC},
  author       = {Ben Hermans and Roel Leus and Jannik Matuschke},
  doi          = {10.1287/ijoc.2020.1047},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {281-296},
  shortjournal = {INFORMS J. Comput.},
  title        = {Exact and approximation algorithms for the expanding search problem},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Team orienteering with time-varying profit. <em>IJOC</em>,
<em>34</em>(1), 262–280. (<a
href="https://doi.org/10.1287/ijoc.2020.1026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the team orienteering problem, where the arrival time and service time affect the collection of profits. Such interactions result in a nonconcave profit function. This problem integrates the aspect of time scheduling into the routing decision, which can be applied in humanitarian search and rescue operations where the survival rate declines rapidly. Rescue teams are needed to help trapped people in multiple affected sites, whereas the number of people who could be saved depends as well on how long a rescue team spends at each site. Efficient allocation and scheduling of rescue teams is critical to ensure a high survival rate. To solve the problem, we formulate a mixed-integer nonconcave programming model and propose a Benders branch-and-cut algorithm, along with valid inequalities for tightening the upper bound. To solve it more effectively, we introduce a hybrid heuristic that integrates a modified coordinate search (MCS) into an iterated local search. Computational results show that valid inequalities significantly reduce the optimality gap, and the proposed exact method is capable of solving instances where the mixed-integer nonlinear programming solver SCIP fails in finding an optimal solution. In addition, the proposed MCS algorithm is highly efficient compared with other benchmark approaches, whereas the hybrid heuristic is proven to be effective in finding high-quality solutions within short computing times. We also demonstrate the performance of the heuristic with the MCS using instances with up to 100 customers.},
  archive      = {J_IJOC},
  author       = {Qinxiao Yu and Yossiri Adulyasak and Louis-Martin Rousseau and Ning Zhu and Shoufeng Ma},
  doi          = {10.1287/ijoc.2020.1026},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {262-280},
  shortjournal = {INFORMS J. Comput.},
  title        = {Team orienteering with time-varying profit},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Radius of robust feasibility for mixed-integer problems.
<em>IJOC</em>, <em>34</em>(1), 243–261. (<a
href="https://doi.org/10.1287/ijoc.2020.1030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a mixed-integer linear problem (MIP) with uncertain constraints, the radius of robust feasibility (RRF) determines a value for the maximal size of the uncertainty set such that robust feasibility of the MIP can be guaranteed. The approaches for the RRF in the literature are restricted to continuous optimization problems. We first analyze relations between the RRF of a MIP and its continuous linear (LP) relaxation. In particular, we derive conditions under which a MIP and its LP relaxation have the same RRF. Afterward, we extend the notion of the RRF such that it can be applied to a large variety of optimization problems and uncertainty sets. In contrast to the setting commonly used in the literature, we consider for every constraint a potentially different uncertainty set that is not necessarily full-dimensional. Thus, we generalize the RRF to MIPs and to include safe variables and constraints; that is, where uncertainties do not affect certain variables or constraints. In the extended setting, we again analyze relations between the RRF for a MIP and its LP relaxation. Afterward, we present methods for computing the RRF of LPs and of MIPs with safe variables and constraints. Finally, we show that the new methodologies can be successfully applied to the instances in the MIPLIB 2017 for computing the RRF.},
  archive      = {J_IJOC},
  author       = {Frauke Liers and Lars Schewe and Johannes Thürauf},
  doi          = {10.1287/ijoc.2020.1030},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {243-261},
  shortjournal = {INFORMS J. Comput.},
  title        = {Radius of robust feasibility for mixed-integer problems},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Predicting tactical solutions to operational planning
problems under imperfect information. <em>IJOC</em>, <em>34</em>(1),
227–242. (<a href="https://doi.org/10.1287/ijoc.2021.1091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper offers a methodological contribution at the intersection of machine learning and operations research. Namely, we propose a methodology to quickly predict expected tactical descriptions of operational solutions (TDOSs). The problem we address occurs in the context of two-stage stochastic programming, where the second stage is demanding computationally. We aim to predict at a high speed the expected TDOS associated with the second-stage problem, conditionally on the first-stage variables. This may be used in support of the solution to the overall two-stage problem by avoiding the online generation of multiple second-stage scenarios and solutions. We formulate the tactical prediction problem as a stochastic optimal prediction program, whose solution we approximate with supervised machine learning. The training data set consists of a large number of deterministic operational problems generated by controlled probabilistic sampling. The labels are computed based on solutions to these problems (solved independently and offline), employing appropriate aggregation and subselection methods to address uncertainty. Results on our motivating application on load planning for rail transportation show that deep learning models produce accurate predictions in very short computing time (milliseconds or less). The predictive accuracy is close to the lower bounds calculated based on sample average approximation of the stochastic prediction programs.},
  archive      = {J_IJOC},
  author       = {Eric Larsen and Sébastien Lachapelle and Yoshua Bengio and Emma Frejinger and Simon Lacoste-Julien and Andrea Lodi},
  doi          = {10.1287/ijoc.2021.1091},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {227-242},
  shortjournal = {INFORMS J. Comput.},
  title        = {Predicting tactical solutions to operational planning problems under imperfect information},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Extending the scope of robust quadratic optimization.
<em>IJOC</em>, <em>34</em>(1), 211–226. (<a
href="https://doi.org/10.1287/ijoc.2021.1059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We derive computationally tractable formulations of the robust counterparts of convex quadratic and conic quadratic constraints that are concave in matrix-valued uncertain parameters. We do this for a broad range of uncertainty sets. Our results provide extensions to known results from the literature. We also consider hard quadratic constraints: those that are convex in uncertain matrix-valued parameters. For the robust counterpart of such constraints, we derive inner and outer tractable approximations. As an application, we show how to construct a natural uncertainty set based on a statistical confidence set around a sample mean vector and covariance matrix and use this to provide a tractable reformulation of the robust counterpart of an uncertain portfolio optimization problem. We also apply the results of this paper to norm approximation problems.},
  archive      = {J_IJOC},
  author       = {Ahmadreza Marandi and Aharon Ben-Tal and Dick den Hertog and Bertrand Melenberg},
  doi          = {10.1287/ijoc.2021.1059},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {211-226},
  shortjournal = {INFORMS J. Comput.},
  title        = {Extending the scope of robust quadratic optimization},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust optimization for models with uncertain second-order
cone and semidefinite programming constraints. <em>IJOC</em>,
<em>34</em>(1), 196–210. (<a
href="https://doi.org/10.1287/ijoc.2020.1025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider uncertain second-order cone (SOC) and semidefinite programming (SDP) constraints with polyhedral uncertainty, which are in general computationally intractable. We propose to reformulate an uncertain SOC or SDP constraint as a set of adjustable robust linear optimization constraints with an ellipsoidal or semidefinite representable uncertainty set, respectively. The resulting adjustable problem can then (approximately) be solved by using adjustable robust linear optimization techniques. For example, we show that if linear decision rules are used, then the final robust counterpart consists of SOC or SDP constraints, respectively, which have the same computational complexity as the nominal version of the original constraints. We propose an efficient method to obtain good lower bounds. Moreover, we extend our approach to other classes of robust optimization problems, such as nonlinear problems that contain wait-and-see variables, linear problems that contain bilinear uncertainty, and general conic constraints. Numerically, we apply our approach to reformulate the problem on finding the minimum volume circumscribing ellipsoid of a polytope and solve the resulting reformulation with linear and quadratic decision rules as well as Fourier-Motzkin elimination. We demonstrate the effectiveness and efficiency of the proposed approach by comparing it with the state-of-the-art copositive approach. Moreover, we apply the proposed approach to a robust regression problem and a robust sensor network problem and use linear decision rules to solve the resulting adjustable robust linear optimization problems, which solve the problem to (near) optimality.},
  archive      = {J_IJOC},
  author       = {Jianzhe Zhen and Frans J. C. T. de Ruiter and Ernst Roos and Dick den Hertog},
  doi          = {10.1287/ijoc.2020.1025},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {196-210},
  shortjournal = {INFORMS J. Comput.},
  title        = {Robust optimization for models with uncertain second-order cone and semidefinite programming constraints},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A high-fidelity model to predict length of stay in the
neonatal intensive care unit. <em>IJOC</em>, <em>34</em>(1), 183–195.
(<a href="https://doi.org/10.1287/ijoc.2021.1062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Having an interpretable, dynamic length-of-stay model can help hospital administrators and clinicians make better decisions and improve the quality of care. The widespread implementation of electronic medical record (EMR) systems has enabled hospitals to collect massive amounts of health data. However, how to integrate this deluge of data into healthcare operations remains unclear. We propose a framework grounded in established clinical knowledge to model patients’ lengths of stay. In particular, we impose expert knowledge when grouping raw clinical data into medically meaningful variables that summarize patients’ health trajectories. We use dynamic, predictive models to output patients’ remaining lengths of stay, future discharges, and census probability distributions based on their health trajectories up to the current stay. Evaluated with large-scale EMR data, the dynamic model significantly improves predictive power over the performance of any model in previous literature and remains medically interpretable.},
  archive      = {J_IJOC},
  author       = {Kanix Wang and Walid Hussain and John R. Birge and Michael D. Schreiber and Daniel Adelman},
  doi          = {10.1287/ijoc.2021.1062},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {183-195},
  shortjournal = {INFORMS J. Comput.},
  title        = {A high-fidelity model to predict length of stay in the neonatal intensive care unit},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Min-max optimal design of two-armed trials with side
information. <em>IJOC</em>, <em>34</em>(1), 165–182. (<a
href="https://doi.org/10.1287/ijoc.2021.1068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we study the optimal design of two-armed clinical trials to maximize the accuracy of parameter estimation in a statistical model, where the interaction between patient covariates and treatment are explicitly incorporated to enable precision medication decisions. Such a modeling extension leads to significant complexities for the produced optimization problems because they include optimization over design and covariates concurrently. We take a min-max optimization model and minimize (over design) the maximum (over population) variance of the estimated interaction effect between treatment and patient covariates. This results in a min-max bilevel mixed integer nonlinear programming problem, which is notably challenging to solve. To address this challenge, we introduce a surrogate optimization model by approximating the objective function, for which we propose two solution approaches. The first approach provides an exact solution based on reformulation and decomposition techniques. In the second approach, we provide a lower bound for the inner optimization problem and solve the outer optimization problem over the lower bound. We test our proposed algorithms with synthetic and real-world data sets and compare them with standard (re)randomization methods. Our numerical analysis suggests that the proposed approaches provide higher-quality solutions in terms of the variance of estimators and probability of correct selection. We also show the value of covariate information in precision medicine clinical trials by comparing our proposed approaches to an alternative optimal design approach that does not consider the interaction terms between covariates and treatment.},
  archive      = {J_IJOC},
  author       = {Qiong Zhang and Amin Khademi and Yongjia Song},
  doi          = {10.1287/ijoc.2021.1068},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {165-182},
  shortjournal = {INFORMS J. Comput.},
  title        = {Min-max optimal design of two-armed trials with side information},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal screening of populations with heterogeneous risk
profiles under the availability of multiple tests. <em>IJOC</em>,
<em>34</em>(1), 150–164. (<a
href="https://doi.org/10.1287/ijoc.2020.1051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the design of large-scale group testing schemes under a heterogeneous population (i.e., subjects with potentially different risk) and with the availability of multiple tests. The objective is to classify the population as positive or negative for a given binary characteristic (e.g., the presence of an infectious disease) as efficiently and accurately as possible. Our approach examines components often neglected in the literature, such as the dependence of testing cost on the group size and the possibility of no testing, which are especially relevant within a heterogeneous setting. By developing key structural properties of the resulting optimization problem, we are able to reduce it to a network flow problem under a specific, yet not too restrictive, objective function. We then provide results that facilitate the construction of the resulting graph and finally provide a polynomial time algorithm. Our case study, on the screening of HIV in the United States, demonstrates the substantial benefits of the proposed approach over conventional screening methods.},
  archive      = {J_IJOC},
  author       = {Hrayer Aprahamian and Hadi El-Amine},
  doi          = {10.1287/ijoc.2020.1051},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {150-164},
  shortjournal = {INFORMS J. Comput.},
  title        = {Optimal screening of populations with heterogeneous risk profiles under the availability of multiple tests},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Integrated multiresource capacity planning and multitype
patient scheduling. <em>IJOC</em>, <em>34</em>(1), 129–149. (<a
href="https://doi.org/10.1287/ijoc.2020.1048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The joint optimization problem of multiresource capacity planning and multitype patient scheduling under uncertain demands and random capacity consumption poses a significant computational challenge. The common practice in solving this problem is to first identify capacity levels and then determine patient scheduling decisions separately, which typically leads to suboptimal decisions that often result in ineffective outcomes of care. In order to overcome these inefficiencies, in this paper, we propose a novel two-stage stochastic optimization model that integrates these two decisions, which can lower costs by exploring the coupling relationship between patient scheduling and capacity configuration. The patient scheduling problem is modeled as a Markov decision process. We first analyze the properties for the multitype patient case under specific assumptions and then establish structural properties of the optimal scheduling policy for the one-type patient case. Based on these findings, we propose optimal solution algorithms to solve the joint optimization problem for this special case. Because it is intractable to solve the original two-stage problem for a general multitype system with large state space, we propose a heuristic policy and a two-stage stochastic mixed-integer programming model solved by the Benders decomposition algorithm, which is further improved by combining an approximate linear program and the look-ahead strategy. To illustrate the efficiency of our approaches and draw managerial insights, we apply our solutions to a data set from the day surgery center of a large public hospital in Shanghai, China. The results show that the joint optimization of capacity planning and patient scheduling could significantly improve the performance. Furthermore, our model can be applied to a rolling-horizon framework to optimize dynamic patient scheduling decisions. Through extensive numerical analyses, we demonstrate that our approaches yield good performances, as measured by the gap against an upper bound, and that these approaches outperform several benchmark policies.},
  archive      = {J_IJOC},
  author       = {Liping Zhou and Na Geng and Zhibin Jiang and Shan Jiang},
  doi          = {10.1287/ijoc.2020.1048},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {129-149},
  shortjournal = {INFORMS J. Comput.},
  title        = {Integrated multiresource capacity planning and multitype patient scheduling},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An analytic framework for effective public health program
design using correctional facilities. <em>IJOC</em>, <em>34</em>(1),
113–128. (<a href="https://doi.org/10.1287/ijoc.2020.1056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a decision analytic framework that uses a mathematical model of Chlamydia trachomatis transmission dynamics in two interacting populations using ordinary differential equations. A public health survey informs model parametrization, and analytical findings guide the computational design of the decision-making process. The potential impact of jail-based screen-treat (S-T) programs on community health outcomes is presented. Numerical experiments are conducted for a case study population to quantify the effect and evaluate the cost-effectiveness of considered interventions. Numerical experiments show the effectiveness of increased jail S-T rates on community cases when resources for a community S-T program stays constant. Although this effect decreases when higher S-T rates are in place, jail-based S-T programs are cost-effective relative to community-based programs.},
  archive      = {J_IJOC},
  author       = {Ozgur M. Araz and Mayteé Cruz-Aponte and Fernando A. Wilson and Brock W. Hanisch and Ruth S. Margalit},
  doi          = {10.1287/ijoc.2020.1056},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {113-128},
  shortjournal = {INFORMS J. Comput.},
  title        = {An analytic framework for effective public health program design using correctional facilities},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The star degree centrality problem: A decomposition
approach. <em>IJOC</em>, <em>34</em>(1), 93–112. (<a
href="https://doi.org/10.1287/ijoc.2021.1074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of identifying the induced star with the largest cardinality open neighborhood in a graph. This problem, also known as the star degree centrality (SDC) problem, is shown to be NP-complete. In this work, we first propose a new integer programming (IP) formulation, which has a smaller number of constraints and nonzero coefficients in them than the existing formulation in the literature. We present classes of networks in which the problem is solvable in polynomial time and offer a new proof of NP-completeness that shows the problem remains NP-complete for both bipartite and split graphs. In addition, we propose a decomposition framework that is suitable for both the existing and our formulations. We implement several acceleration techniques in this framework, motivated by techniques used in Benders decomposition. We test our approaches on networks generated based on the Barabási–Albert, Erdös–Rényi, and Watts–Strogatz models. Our decomposition approach outperforms solving the IP formulations in most of the instances in terms of both solution time and quality; this is especially true for larger and denser graphs. We then test the decomposition algorithm on large-scale protein–protein interaction networks, for which SDC is shown to be an important centrality metric.},
  archive      = {J_IJOC},
  author       = {Mustafa C. Camur and Thomas Sharkey and Chrysafis Vogiatzis},
  doi          = {10.1287/ijoc.2021.1074},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {93-112},
  shortjournal = {INFORMS J. Comput.},
  title        = {The star degree centrality problem: A decomposition approach},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient label-correcting algorithm for the
multiobjective shortest path problem. <em>IJOC</em>, <em>34</em>(1),
76–92. (<a href="https://doi.org/10.1287/ijoc.2021.1081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an exact algorithm to solve the one-to-one multiobjective shortest path problem. The solution involves determining a set of nondominated paths between two given nodes in a graph that minimizes several objective functions. This study is motivated by the application of this solution method to determine cycling itineraries. The proposed algorithm improves upon a label-correcting algorithm to rapidly solve the problem on large graphs (i.e., up to millions of nodes and edges). To verify the performance of the proposed algorithm, we use computational experiments to compare it with the best-known methods in the literature. The numerical results confirm the efficiency of the proposed algorithm.},
  archive      = {J_IJOC},
  author       = {Yannick Kergosien and Antoine Giret and Emmanuel Néron and Gaël Sauvanet},
  doi          = {10.1287/ijoc.2021.1081},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {76-92},
  shortjournal = {INFORMS J. Comput.},
  title        = {An efficient label-correcting algorithm for the multiobjective shortest path problem},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Parameterized algorithms for power-efficiently connecting
wireless sensor networks: Theory and experiments. <em>IJOC</em>,
<em>34</em>(1), 55–75. (<a
href="https://doi.org/10.1287/ijoc.2020.1045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a problem of energy-efficiently connecting a symmetric wireless communication network: given an n-vertex graph with edge weights, find a connected spanning subgraph of minimum cost, where the cost is determined by each vertex paying the heaviest edge incident to it in the subgraph. The problem is known to be NP-hard. Strengthening this hardness result, we show that even o(log n)-approximating the difference d between the optimal solution cost and a natural lower bound is NP-hard. Moreover, we show that under the exponential time hypothesis, there are no exact algorithms running in 2o(n) time or in f(d)⋅nO(1) time for any computable function f. We also show that the special case of connecting c network components with minimum additional cost generally cannot be polynomial-time reduced to instances of size cO(1) unless the polynomial-time hierarchy collapses. On the positive side, we provide an algorithm that reconnects O(log n)-connected components with minimum additional cost in polynomial time. These algorithms are motivated by application scenarios of monitoring areas or where an existing sensor network may fall apart into several connected components because of sensor faults. In experiments, the algorithm outperforms CPLEX with known integer linear programming (ILP) formulations when n is sufficiently large compared with c.},
  archive      = {J_IJOC},
  author       = {Matthias Bentert and René van Bevern and André Nichterlein and Rolf Niedermeier and Pavel V. Smirnov},
  doi          = {10.1287/ijoc.2020.1045},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {55-75},
  shortjournal = {INFORMS J. Comput.},
  title        = {Parameterized algorithms for power-efficiently connecting wireless sensor networks: Theory and experiments},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Self-learning threshold-based load balancing. <em>IJOC</em>,
<em>34</em>(1), 39–54. (<a
href="https://doi.org/10.1287/ijoc.2021.1100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a large-scale service system where incoming tasks have to be instantaneously dispatched to one out of many parallel server pools. The user-perceived performance degrades with the number of concurrent tasks and the dispatcher aims at maximizing the overall quality of service by balancing the load through a simple threshold policy. We demonstrate that such a policy is optimal on the fluid and diffusion scales, while only involving a small communication overhead, which is crucial for large-scale deployments. In order to set the threshold optimally, it is important, however, to learn the load of the system, which may be unknown. For that purpose, we design a control rule for tuning the threshold in an online manner. We derive conditions that guarantee that this adaptive threshold settles at the optimal value, along with estimates for the time until this happens. In addition, we provide numerical experiments that support the theoretical results and further indicate that our policy copes effectively with time-varying demand patterns.},
  archive      = {J_IJOC},
  author       = {Diego Goldsztajn and Sem C. Borst and Johan S. H. van Leeuwaarden and Debankur Mukherjee and Philip A. Whiting},
  doi          = {10.1287/ijoc.2021.1100},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {39-54},
  shortjournal = {INFORMS J. Comput.},
  title        = {Self-learning threshold-based load balancing},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Performance approximation for time-dependent queues with
generally distributed abandonments. <em>IJOC</em>, <em>34</em>(1),
20–38. (<a href="https://doi.org/10.1287/ijoc.2021.1090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many stochastic systems face a time-dependent demand. Especially in stochastic service systems, for example, in call centers, customers may leave the queue if their waiting time exceeds their personal patience. As discussed in the extant literature, it can be useful to use general distributions to model such customer patience. This paper analyzes the time-dependent performance of a multiserver queue with a nonhomogeneous Poisson arrival process with a time-dependent arrival rate, exponentially distributed processing times, and generally distributed time to abandon. Fast and accurate performance approximations are essential for decision support in such queueing systems, but the extant literature lacks appropriate methods for the setting we consider. To approximate time-dependent performance measures for small- and medium-sized systems, we develop a new stationary backlog-carryover (SBC) approach that allows for the analysis of underloaded and overloaded systems. Abandonments are considered in two steps of the algorithm: (i) in the approximation of the utilization as a reduced arrival stream and (ii) in the approximation of waiting-based performance measures with a stationary model for general abandonments. To improve the approximation quality, we discuss an adjustment to the interval lengths. We present a limit result that indicates convergence of the method for stationary parameters. The numerical study compares the approximation quality of different adjustments to the interval length. The new SBC approach is effective for instances with small numbers of time-dependent servers and gamma-distributed abandonment times with different coefficients of variation and for an empirical distribution of the abandonment times from real-world data obtained from a call center. A discrete-event simulation benchmark confirms that the SBC algorithm approximates the performance of the queueing system with abandonments very well for different parameter configurations.},
  archive      = {J_IJOC},
  author       = {Gregor Selinka and Raik Stolletz and Thomas I. Maindl},
  doi          = {10.1287/ijoc.2021.1090},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {20-38},
  shortjournal = {INFORMS J. Comput.},
  title        = {Performance approximation for time-dependent queues with generally distributed abandonments},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Alfonso: Matlab package for nonsymmetric conic optimization.
<em>IJOC</em>, <em>34</em>(1), 11–19. (<a
href="https://doi.org/10.1287/ijoc.2021.1058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present alfonso, an open-source Matlab package for solving conic optimization problems over nonsymmetric convex cones. The implementation is based on the authors’ corrected analysis of a method of Skajaa and Ye. It enables optimization over any convex cone as long as a logarithmically homogeneous self-concordant barrier is available for the cone or its dual. This includes many nonsymmetric cones, for example, hyperbolicity cones and their duals (such as sum-of-squares cones), semidefinite and second-order cone representable cones, power cones, and the exponential cone. Besides enabling the solution of problems that cannot be cast as optimization problems over a symmetric cone, algorithms for nonsymmetric conic optimization also offer performance advantages for problems whose symmetric cone programming representation requires a large number of auxiliary variables or has a special structure that can be exploited in the barrier computation. The worst-case iteration complexity of alfonso is the best known for nonsymmetric cone optimization: O(νlog⁡(1/ε)) iterations to reach an ε-optimal solution, where ν is the barrier parameter of the barrier function used in the optimization. Alfonso can be interfaced with a Matlab function (supplied by the user) that computes the Hessian of a barrier function for the cone. A simplified interface is also available to optimize over the direct product of cones for which a barrier function has already been built into the software. This interface can be easily extended to include new cones. Both interfaces are illustrated by solving linear programs. The oracle interface and the efficiency of alfonso are also demonstrated using an optimal design of experiments problem in which the tailored barrier computation greatly decreases the solution time compared with using state-of-the-art, off-the-shelf conic optimization software.},
  archive      = {J_IJOC},
  author       = {Dávid Papp and Sercan Yıldız},
  doi          = {10.1287/ijoc.2021.1058},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {11-19},
  shortjournal = {INFORMS J. Comput.},
  title        = {Alfonso: Matlab package for nonsymmetric conic optimization},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Spatiotemporal data set for out-of-hospital cardiac arrests.
<em>IJOC</em>, <em>34</em>(1), 4–10. (<a
href="https://doi.org/10.1287/ijoc.2020.1022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a spatiotemporal data set of all out-of-hospital sudden cardiac arrests (OHCA) dispatches for the City of Virginia Beach. We also develop a modular toolkit that can be used to process the data and generate problem instances based on user-defined input. The data were collected from multiple sources, and our analysis process was validated by Virginia Beach officials. The data set consists of detailed information about each dispatch made in response to an OHCA; it includes the time the call for service arrived, the response time of the first unit on scene, the address, and the coordinates of each OHCA incident. It also contains detailed spatial information for all existing first-responder stations and both the great-circle and the road distances between all first-responder stations and OHCA incidents. The raw data files were very large in size and were processed using SAS®, MATLAB, and QGIS. In conjunction with the database, we provide a MATLAB code that allows generating multiple random test instances based on user-defined input. The library of problems can be used in healthcare emergency problems and also for facility location models, bilocation problems, and drone studies. The data set was organized such that it can be readily used by researchers in the field of healthcare operations research and those studying the spatiotemporal distribution of OHCAs. Given the difficulty to access OHCA data at the level of detail we provide, the data set will facilitate the implementation of data-driven models to design emergency medical response networks and to study the distribution of OHCAs. Additionally, the provision of data and the toolkit will be very useful in benchmarking algorithms and solvers, which is valuable to the data-driven optimization community in general.},
  archive      = {J_IJOC},
  author       = {Janiele E. S. C. Custodio and Miguel A. Lejeune},
  doi          = {10.1287/ijoc.2020.1022},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {4-10},
  shortjournal = {INFORMS J. Comput.},
  title        = {Spatiotemporal data set for out-of-hospital cardiac arrests},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Note from the editor. <em>IJOC</em>, <em>34</em>(1), 1. (<a
href="https://doi.org/10.1287/ijoc.2021.1146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJOC},
  author       = {Alice E. Smith},
  doi          = {10.1287/ijoc.2021.1146},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {1},
  shortjournal = {INFORMS J. Comput.},
  title        = {Note from the editor},
  volume       = {34},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Note from the editor. <em>IJOC</em>, <em>33</em>(4),
1259–1684. (<a href="https://doi.org/10.1287/ijoc.2021.1126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2021.1126},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {1259-1684},
  shortjournal = {INFORMS J. Comput.},
  title        = {Note from the editor},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SDP-based bounds for the quadratic cycle cover problem via
cutting-plane augmented lagrangian methods and reinforcement learning.
<em>IJOC</em>, <em>33</em>(4), 1259–1684. (<a
href="https://doi.org/10.1287/ijoc.2021.1075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the quadratic cycle cover problem (QCCP), which aims to find a node-disjoint cycle cover in a directed graph with minimum interaction cost between successive arcs. We derive several semidefinite programming (SDP) relaxations and use facial reduction to make these strictly feasible. We investigate a nontrivial relationship between the transformation matrix used in the reduction and the structure of the graph, which is exploited in an efficient algorithm that constructs this matrix for any instance of the problem. To solve our relaxations, we propose an algorithm that incorporates an augmented Lagrangian method into a cutting-plane framework by utilizing Dykstra’s projection algorithm. Our algorithm is suitable for solving SDP relaxations with a large number of cutting-planes. Computational results show that our SDP bounds and efficient cutting-plane algorithm outperform other QCCP bounding approaches from the literature. Finally, we provide several SDP-based upper bounding techniques, among which is a sequential Q-learning method that exploits a solution of our SDP relaxation within a reinforcement learning environment. Summary of Contribution: The quadratic cycle cover problem (QCCP) is the problem of finding a set of node-disjoint cycles covering all the nodes in a graph such that the total interaction cost between successive arcs is minimized. The QCCP has applications in many fields, among which are robotics, transportation, energy distribution networks, and automatic inspection. Besides this, the problem has a high theoretical relevance because of its close connection to the quadratic traveling salesman problem (QTSP). The QTSP has several applications, for example, in bioinformatics, and is considered to be among the most difficult combinatorial optimization problems nowadays. After removing the subtour elimination constraints, the QTSP boils down to the QCCP. Hence, an in-depth study of the QCCP also contributes to the construction of strong bounds for the QTSP. In this paper, we study the application of semidefinite programming (SDP) to obtain strong bounds for the QCCP. Our strongest SDP relaxation is very hard to solve by any SDP solver because of the large number of involved cutting-planes. Because of that, we propose a new approach in which an augmented Lagrangian method is incorporated into a cutting-plane framework by utilizing Dykstra’s projection algorithm. We emphasize an efficient implementation of the method and perform an extensive computational study. This study shows that our method is able to handle a large number of cuts and that the resulting bounds are currently the best QCCP bounds in the literature. We also introduce several upper bounding techniques, among which is a distributed reinforcement learning algorithm that exploits our SDP relaxations.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2021.1075},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {1259-1684},
  shortjournal = {INFORMS J. Comput.},
  title        = {SDP-based bounds for the quadratic cycle cover problem via cutting-plane augmented lagrangian methods and reinforcement learning},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Frvcpy: An open-source solver for the fixed route vehicle
charging problem. <em>IJOC</em>, <em>33</em>(4), 1259–1684. (<a
href="https://doi.org/10.1287/ijoc.2020.1035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electric vehicles offer a pathway to more sustainable transportation, but their adoption entails new challenges not faced by their petroleum-based counterparts. A difficult task in vehicle routing problems addressing these challenges is determining how to make good charging decisions for an electric vehicle traveling a given route. This is known as the fixed route vehicle charging problem. An exact and efficient algorithm for this task exists, but its implementation is sufficiently complex to deter researchers from adopting it. In this work we introduce frvcpy, an open-source Python package implementing this algorithm. Our aim with the package is to make it easier for researchers to solve electric vehicle routing problems, facilitating the development of optimization tools that may ultimately enable the mass adoption of electric vehicles. Summary of Contribution: This work describes a novel software tool for the vehicle routing community. The tool, frvcpy, addresses one of the primary challenges faced by the vehicle routing community when considering problems involving the adoption of electric vehicles (EVs): how to make optimal charging decisions. The state-of-the-art algorithm for solving these problems is sufficiently complex to deter researchers from using it, leading them to adopt less robust methods. frvcpy offers an easy-to-use, lightweight implementation of this algorithm, providing optimal solutions in low (∼5 ms) runtime. It is designed to be easily embedded in larger solution schemes for general EV routing problems, requiring minimal input, offering compatibility with the community standard file types, and offering access both through the command line and a Python API. The tool has thus far proven adaptable, having been used by researchers studying EV routing problems with novel constraints. Our aim with frvcpy is to make it easier for researchers to solve EV routing problems, facilitating the development of optimization tools that may contribute toward the mass adoption of electric vehicles.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.1035},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {1259-1684},
  shortjournal = {INFORMS J. Comput.},
  title        = {Frvcpy: An open-source solver for the fixed route vehicle charging problem},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Approximation methods for multiobjective optimization
problems: A survey. <em>IJOC</em>, <em>33</em>(4), 1259–1684. (<a
href="https://doi.org/10.1287/ijoc.2020.1028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Algorithms for approximating the nondominated set of multiobjective optimization problems are reviewed. The approaches are categorized into general methods that are applicable under mild assumptions and, thus, to a wide range of problems, and into algorithms that are specifically tailored to structured problems. All in all, this survey covers 52 articles published within the last 41 years, that is, between 1979 and 2020. Summary of Contribution: In many problems in operations research, several conflicting objective functions have to be optimized simultaneously, and one is interested in finding Pareto optimal solutions. Because of the high complexity of finding Pareto optimal solutions and their usually very large number, however, the exact solution of such multiobjective problems is often very difficult, which motivates the study of approximation algorithms for multiobjective optimization problems. This research area uses techniques and methods from algorithmics and computing in order to efficiently determine approximate solutions to many well-known multiobjective problems from operations research. Even though approximation algorithms for multiobjective optimization problems have been investigated for more than 40 years and more than 50 research articles have been published on this topic, this paper provides the first survey of this important area at the intersection of computing and operations research.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.1028},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {1259-1684},
  shortjournal = {INFORMS J. Comput.},
  title        = {Approximation methods for multiobjective optimization problems: A survey},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Decomposing loosely coupled mixed-integer programs for
optimal microgrid design. <em>IJOC</em>, <em>33</em>(4), 1259–1684. (<a
href="https://doi.org/10.1287/ijoc.2020.0955">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microgrids are frequently employed in remote regions, in part because access to a larger electric grid is impossible, difficult, or compromises reliability and independence. Although small microgrids often employ spot generation, in which a diesel generator is attached directly to a load, microgrids that combine these individual loads and augment generators with photovoltaic cells and batteries as a distributed energy system are emerging as a safer, less costly alternative. We present a model that seeks the minimum-cost microgrid design and ideal dispatched power to support a small remote site for one year with hourly fidelity under a detailed battery model; this mixed-integer nonlinear program (MINLP) is intractable with commercial solvers but loosely coupled with respect to time. A mixed-integer linear program (MIP) approximates the model, and a partitioning scheme linearizes the bilinear terms. We introduce a novel policy for loosely coupled MIPs in which the system reverts to equivalent conditions at regular time intervals; this separates the problem into subproblems that we solve in parallel. We obtain solutions within 5\% of optimality in at most six minutes across 14 MIP instances from the literature and solutions within 5\% of optimality to the MINLP instances within 20 minutes.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.0955},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {1259-1684},
  shortjournal = {INFORMS J. Comput.},
  title        = {Decomposing loosely coupled mixed-integer programs for optimal microgrid design},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Characterizing social TV activity around televised events: A
joint topic model approach. <em>IJOC</em>, <em>33</em>(4), 1259–1684.
(<a href="https://doi.org/10.1287/ijoc.2020.1038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Viewers often use social media platforms like Twitter to express their views about televised programs and events like the presidential debate, the Oscars, and the State of the Union speech. Although this promises tremendous opportunities to analyze the feedback on a program or an event using viewer-generated content on social media, there are significant technical challenges to doing so. Specifically, given a televised event and related tweets about this event, we need methods to effectively align these tweets and the corresponding event. In turn, this will raise many questions, such as how to segment the event and how to classify a tweet based on whether it is generally about the entire event or specifically about one particular event segment. In this paper, we propose and develop a novel joint Bayesian model that aligns an event and its related tweets based on the influence of the event’s topics. Our model allows the automated event segmentation and tweet classification concurrently. We present an efficient inference method for this model and a comprehensive evaluation of its effectiveness compared with the state-of-the-art methods. We find that the topics, segments, and alignment provided by our model are significantly more accurate and robust.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.1038},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {1259-1684},
  shortjournal = {INFORMS J. Comput.},
  title        = {Characterizing social TV activity around televised events: A joint topic model approach},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Near-linear time local polynomial nonparametric estimation
with box kernels. <em>IJOC</em>, <em>33</em>(4), 1259–1684. (<a
href="https://doi.org/10.1287/ijoc.2020.1021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Local polynomial regression is an important class of methods for nonparametric density estimation and regression problems. However, straightforward implementation of local polynomial regression has quadratic time complexity which hinders its applicability in large-scale data analysis. In this paper, we significantly accelerate the computation of local polynomial estimates by novel applications of multidimensional binary indexed trees. Both time and space complexity of our proposed algorithm is nearly linear in the number of input data points. Simulation results confirm the efficiency and effectiveness of our proposed approach. Summary of Contribution. Big data analytics has become essential for modern operations research and operations management applications. Statistics methods, such as nonparametric density and function estimation, play important roles in predictive and exploratory data analysis for economics and operations management problems. In this paper, we concentrate on efficiently computing local polynomial regression estimates. We significantly accelerate the computation of such local polynomial estimates by novel applications of multidimensional binary indexed trees and lazy memory allocation via hashing. Both time and space complexity of our proposed algorithm are nearly linear in the number of inputs. Simulation results confirm the efficiency and effectiveness of our proposed methods.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.1021},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {1259-1684},
  shortjournal = {INFORMS J. Comput.},
  title        = {Near-linear time local polynomial nonparametric estimation with box kernels},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multivariable branching: A 0-1 knapsack problem case study.
<em>IJOC</em>, <em>33</em>(4), 1259–1684. (<a
href="https://doi.org/10.1287/ijoc.2020.1052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We explore the benefits of multivariable branching schemes for linear-programming-based branch-and-bound algorithms for the 0-1 knapsack problem—that is, the benefits of branching on sets of variables rather than on a single variable (the current default in integer-programming solvers). We present examples where multivariable branching has advantages over single-variable branching and partially characterize situations in which this happens. Chvátal shows that for a specific class of 0-1 knapsack instances, a linear-programming-based branch-and-bound algorithm (employing a single-variable branching scheme) must explore exponentially many nodes. We show that for this class of 0-1 knapsack instances, a linear-programming-based branch-and-bound algorithm employing an appropriately chosen multivariable branching scheme explores either three or seven nodes. Finally, we investigate the performance of various multivariable branching schemes for 0-1 knapsack instances computationally and demonstrate their potential; the multivariable branching schemes explored result in smaller search trees (some in search trees that are an order of magnitude smaller), and some also result in shorter solution times. Summary of Contribution : As a powerful modeling tool, mixed-integer programming (MIP) is ubiquitous in Operations Research and is usually solved via the branch-and-bound framework. However, solving MIPs is computationally challenging in general, where branching affects the performance of solvers dramatically. In this paper, we explore the benefits of branching on multiple variables, which can be viewed as a generalization of the standard single-variable branching. We analyze its theoretical behavior on a special instance introduced by Chvátal, which is proved to be hard for single-variable branching. We also partially characterize situations in which branching on multiple variables is superior to its single-variable counterpart. Lastly, we demonstrate its potential in reducing the overall computational time and possible memory usage for storing unexplored nodes through numerical experiments on 0-1 knapsack problems.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.1052},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {1259-1684},
  shortjournal = {INFORMS J. Comput.},
  title        = {Multivariable branching: A 0-1 knapsack problem case study},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new global optimization scheme for quadratic programs with
low-rank nonconvexity. <em>IJOC</em>, <em>33</em>(4), 1259–1684. (<a
href="https://doi.org/10.1287/ijoc.2020.1017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the classical convex constrained nonconvex quadratic programming problem where the Hessian matrix of the objective to be minimized has r negative eigenvalues, denoted by (QP r ). Based on a biconvex programming reformulation in a slightly higher dimension, we propose a novel branch-and-bound algorithm to solve (QP 1 ) and show that it returns an ɛ -approximate solution of (QP 1 ) in at most O ( 1 / ɛ ) iterations. We further extend the new algorithm to solve the general (QP r ) with r &gt; 1. Computational comparison shows the efficiency of our proposed global optimization method for small r . Finally, we extend the explicit relaxation approach for (QP 1 ) to (QP r ) with r &gt; 1. Summary of Contribution: Nonconvex quadratic program (QP) is a classical optimization problem in operations research. This paper aims at globally solving the QP where the Hessian matrix of the objective to be minimized has r negative eigenvalues. It is known to be nondeterministic polynomial-time hard even when r = 1. This paper presents a novel algorithm to globally solve the QP for r = 1 and then extends to general r . Numerical results demonstrate the superiority of the proposed algorithm in comparison with state-of-the-art algorithms/software for small r .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.1017},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {1259-1684},
  shortjournal = {INFORMS J. Comput.},
  title        = {A new global optimization scheme for quadratic programs with low-rank nonconvexity},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improved computational approaches and heuristics for zero
forcing. <em>IJOC</em>, <em>33</em>(4), 1259–1684. (<a
href="https://doi.org/10.1287/ijoc.2020.1032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero forcing is a graph coloring process based on the following color change rule: all vertices of a graph G are initially colored either blue or white; in each timestep, a white vertex turns blue if it is the only white neighbor of some blue vertex. A zero forcing set of G is a set of blue vertices such that all vertices eventually become blue after iteratively applying the color change rule. The zero forcing number Z ( G ) is the cardinality of a minimum zero forcing set. In this paper, we propose novel exact algorithms for computing Z ( G ) based on formulating the zero forcing problem as a two-stage Boolean satisfiability problem. We also propose several heuristics for zero forcing based on iteratively adding blue vertices which color a large part of the remaining white vertices. These heuristics are used to speed up the exact algorithms and can also be of independent interest in approximating Z ( G ) . Computational results on various types of graphs show that, in many cases, our algorithms offer a significant improvement on the state-of-the-art algorithms for zero forcing. Summary of Contribution: This paper proposes novel algorithms and heuristics for an NP-hard graph coloring problem that has numerous applications. Our exact methods combine Boolean satisfiability modeling with a constraint generation framework commonly used in operations research. The paper also includes an analysis of the facets of the polytope associated with this problem and decomposition techniques which can reduce the size of the problem. Our computational approaches are implemented and tested on a wide variety of graphs and are compared with the state-of-the-art algorithms from the literature. We show that our proposed algorithms based on Boolean satisfiability, in conjunction with the heuristics and order-reduction techniques, yield a significant speedup in some cases.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.1032},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {1259-1684},
  shortjournal = {INFORMS J. Comput.},
  title        = {Improved computational approaches and heuristics for zero forcing},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unifying online and offline preference for social link
prediction. <em>IJOC</em>, <em>33</em>(4), 1259–1684. (<a
href="https://doi.org/10.1287/ijoc.2020.0989">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in network representation learning have enabled significant improvement in the link prediction task, which is at the core of many downstream applications. As an increasing amount of mobility data become available because of the development of location-based technologies, we argue that this resourceful mobility data can be used to improve link prediction tasks. In this paper, we propose a novel link prediction framework that utilizes user offline check-in behavior combined with user online social relations. We model user offline location preference via a probabilistic factor model and represent user social relations using neural network representation learning. To capture the interrelationship of these two sources, we develop an anchor link method to align these two different user latent representations. Furthermore, we employ locality-sensitive hashing to project the aggregated user representation into a binary matrix, which not only preserves the data structure but also improves the efficiency of convolutional network learning. By comparing with several baseline methods that solely rely on social networks or mobility data, we show that our unified approach significantly improves the link prediction performance. Summary of Contribution: This paper proposes a novel framework that utilizes both user offline and online behavior for social link prediction by developing several machine learning algorithms, such as probabilistic factor model, neural network embedding, anchor link model, and locality-sensitive hashing. The scope and mission has the following aspects: (1) We develop a data and knowledge modeling approach that demonstrates significant performance improvement. (2) Our method can efficiently manage large-scale data. (3) We conduct rigorous experiments on real-world data sets and empirically show the effectiveness and the efficiency of our proposed method. Overall, our paper can contribute to the advancement of social link prediction, which can spur many downstream applications in information systems and computer science.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.0989},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {1259-1684},
  shortjournal = {INFORMS J. Comput.},
  title        = {Unifying online and offline preference for social link prediction},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exact facetial odd-cycle separation for maximum cut and
binary quadratic optimization. <em>IJOC</em>, <em>33</em>(4), 1259–1684.
(<a href="https://doi.org/10.1287/ijoc.2020.1008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exact solution of the NP-hard (nondeterministic polynomial-time hard) maximum cut problem is important in many applications across, for example, physics, chemistry, neuroscience, and circuit layout—which is also due to its equivalence to the unconstrained binary quadratic optimization problem. Leading solution methods are based on linear or semidefinite programming and require the separation of the so-called odd-cycle inequalities. In their groundbreaking research, F. Barahona and A. R. Mahjoub have given an informal description of a polynomial-time algorithm for this problem. As pointed out recently, however, additional effort is necessary to guarantee that the inequalities obtained correspond to facets of the cut polytope. In this paper, we shed more light on a so enhanced separation procedure and investigate experimentally how it performs in comparison with an ideal setting where one could even employ the sparsest, most violated, or geometrically most promising facet-defining odd-cycle inequalities. Summary of Contribution: This paper aims at a better capability to solve binary quadratic optimization or maximum cut problems and their various applications using integer programming techniques. To this end, the paper describes enhancements to a well-known algorithm for the central separation problem arising in this context; it is demonstrated experimentally that these enhancements are worthwhile from a computational point of view. The linear relaxations of the aforementioned problems are typically solved using fewer iterations and cutting planes than with a nonenhanced approach. It is also shown that the enhanced procedure is only slightly inferior to an ideal, enumerative, and, in practice, intractable global cutting-plane selection.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.1008},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {1259-1684},
  shortjournal = {INFORMS J. Comput.},
  title        = {Exact facetial odd-cycle separation for maximum cut and binary quadratic optimization},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exact algorithms for the minimum load spanning tree problem.
<em>IJOC</em>, <em>33</em>(4), 1259–1684. (<a
href="https://doi.org/10.1287/ijoc.2020.1011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a minimum load spanning tree (MLST) problem, we are given an undirected graph and nondecreasing load functions for nodes defined on nodes’ degrees in a spanning tree, and the objective is to find a spanning tree that minimizes the maximum load among all nodes. We propose the first O ∗ ( 2 n ) time exact algorithm for the MLST problem, where n is the number of nodes and O ∗ ignores polynomial factor. The algorithm is obtained by repeatedly querying whether a candidate objective value is feasible, where each query can be formulated as a bounded degree spanning tree problem (BDST). We propose a novel solution to BDST by extending an inclusion-exclusion based algorithm. To further enhance the time efficiency of the previous algorithm, we then propose a faster algorithm by generalizing the concept of branching walks. In addition, for the purpose of comparison, we give the first mixed integer linear programming formulation for MLST. In numerical analysis, we consider various load functions on a randomly generated network. The results verify the effectiveness of the proposed algorithms. Summary of Contribution: Minimum load spanning tree (MLST) plays an important role in various applications such as wireless sensor networks (WSNs). In many applications of WSNs, we often need to collect data from all sensors to some specified sink. In this paper, we propose the first exact algorithms for the MLST problem. Besides having theoretical guarantees, our algorithms have extraordinarily good performance in practice. We believe that our results make significant contributions to the field of graph theory, internet of things, and WSNs.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.1011},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {1259-1684},
  shortjournal = {INFORMS J. Comput.},
  title        = {Exact algorithms for the minimum load spanning tree problem},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A branch-and-bound algorithm for building optimal data
gathering tree in wireless sensor networks. <em>IJOC</em>,
<em>33</em>(4), 1259–1684. (<a
href="https://doi.org/10.1287/ijoc.2020.1012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the maximum lifetime data gathering tree (MLDT) problem in sensor networks. A data gathering tree is a spanning tree rooted at a specified sink so that every node can send its messages to the sink along the tree. The lifetime of a tree is defined as the minimum lifetime among nodes where each node’s lifetime is determined by its initial energy and transmission load. The MLDT problem is NP-hard, and the state-of-the-art solution formulates a decision version of the problem as an integer linear program (ILP) and then solves it by conducting binary search over all possible lifetimes. In this paper, we first give an ILP for the optimization problem rather than its decision version, and then show that using ILP solvers to solve these programs could be highly inefficient. We then propose a branch-and-bound algorithm that incorporates two novel features. First, the bounding method takes into account integer flows, and contains a new set of constraints. Second, a special set of edges are deleted to reduce the number of subproblems generated by the branching process. Numerical simulations on randomly generated networks show that the proposed algorithm outperforms existing algorithms in terms of the number of solved problem instances in a fixed amount of time. Summary of Contribution : We study the maximum lifetime data gathering tree (MLDT) problem in the context of wireless sensor network. MLDT is a fundamental problem in both computer science and operations research. Since sensor nodes are often resource limited, the data gathering tree must be carefully constructed to prolong the network lifetime. In this paper, we first give an integer linear program for the optimization problem rather than its decision version, and then show that using ILP solvers to solve these programs could be highly inefficient. We then propose a branch and bound algorithm that incorporates two novel features.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.1012},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {1259-1684},
  shortjournal = {INFORMS J. Comput.},
  title        = {A branch-and-bound algorithm for building optimal data gathering tree in wireless sensor networks},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Integer programming formulations for minimum spanning tree
interdiction. <em>IJOC</em>, <em>33</em>(4), 1259–1684. (<a
href="https://doi.org/10.1287/ijoc.2020.1018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a two-player interdiction problem staged over a graph where the attacker’s objective is to minimize the cost of removing edges from the graph so that the defender’s objective, that is, the weight of a minimum spanning tree in the residual graph, is increased up to a predefined level r . Standard approaches for graph interdiction frame this type of problems as bilevel formulations, which are commonly solved by replacing the inner problem by its dual to produce a single-level reformulation. In this paper, we study an alternative integer program derived directly from the attacker’s solution space and show that this formulation yields a stronger linear relaxation than the bilevel counterpart. Furthermore, we analyze the convex hull of the feasible solutions of the problem and identify several families of facet-defining inequalities that can be used to strengthen this integer program. We then proceed by introducing a different formulation defined by a set of so-called supervalid inequalities that may exclude feasible solutions, albeit solutions whose objective value is not better than that of an edge cut of minimum cost. We discuss several computational aspects required for an efficient implementation of the proposed approaches. Finally, we perform an extensive set of computational experiments to test the quality of these formulations, analyzing and comparing the benefits of each model, as well as identifying further enhancements. Summary of Contribution : Network interdiction has received significant attention over the last couple of decades, with a notable peak of interest in recent years. This paper provides an interesting balance between the theoretical and computational aspects of solving a challenging network interdiction problem via integer programming. We present several technical developments, including a detailed study of the problem&#39;s solution space, multiple formulations, and a polyhedral analysis of the convex hull of feasible solutions. We then analyze the results of an extensive set of computational experiments that were used to validate the effectiveness of the different methods we developed in this paper.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.1018},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {1259-1684},
  shortjournal = {INFORMS J. Comput.},
  title        = {Integer programming formulations for minimum spanning tree interdiction},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fortification against cascade propagation under uncertainty.
<em>IJOC</em>, <em>33</em>(4), 1259–1684. (<a
href="https://doi.org/10.1287/ijoc.2020.0992">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network cascades represent a number of real-life applications: social influence, electrical grid failures, viral spread, and so on. The commonality between these phenomena is that they begin from a set of seed nodes and spread to other regions of the network. We consider a variant of a critical node detection problem dubbed the robust critical node fortification problem, wherein the decision maker wishes to fortify nodes (within a budget) to limit the spread of cascading behavior under uncertain conditions. In particular, the arc weights—how much influence one node has on another in the cascade process—are uncertain but are known to lie in some range bounded by a worst-case budget uncertainty. This problem is shown to be N P -hard even in the deterministic case. We formulate a mixed-integer program (MIP) to solve the deterministic problem and improve its continuous relaxation via nonlinear constraints and convexification. The robust problem is computationally more difficult, and we present an MIP-based expand-and-cut exact solution algorithm, in which the expansion is enhanced by cutting planes, which are themselves tied to the expansion process. Insights from these exact solutions motivate two novel (interrelated) centrality measures , and a centrality-based heuristic that obtains high-quality solutions within a few seconds. Finally, extensive computational results are given to validate our theoretical developments as well as provide insights into structural properties of the robust problem and its solution.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.0992},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {1259-1684},
  shortjournal = {INFORMS J. Comput.},
  title        = {Fortification against cascade propagation under uncertainty},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ranking and selection with covariates for personalized
decision making. <em>IJOC</em>, <em>33</em>(4), 1259–1684. (<a
href="https://doi.org/10.1287/ijoc.2020.1009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a problem of ranking and selection via simulation in the context of personalized decision making, in which the best alternative is not universal, but varies as a function of some observable covariates. The goal of ranking and selection with covariates (R&amp;S-C) is to use simulation samples to obtain a selection policy that specifies the best alternative with a certain statistical guarantee for subsequent individuals upon observing their covariates. A linear model is proposed to capture the relationship between the mean performance of an alternative and the covariates. Under the indifference-zone formulation, we develop two-stage procedures for both homoscedastic and heteroscedastic simulation errors, respectively, and prove their statistical validity in terms of average probability of correct selection. We also generalize the well-known slippage configuration and prove that the generalized slippage configuration is the least favorable configuration for our procedures. Extensive numerical experiments are conducted to investigate the performance of the proposed procedures, the experimental design issue, and the robustness to the linearity assumption. Finally, we demonstrate the usefulness of R&amp;S-C via a case study of selecting the best treatment regimen in the prevention of esophageal cancer. We find that by leveraging disease-related personal information, R&amp;S-C can substantially improve patients’ expected quality-adjusted life years by providing a patient-specific treatment regimen.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.1009},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {1259-1684},
  shortjournal = {INFORMS J. Comput.},
  title        = {Ranking and selection with covariates for personalized decision making},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Computing sensitivities for distortion risk measures.
<em>IJOC</em>, <em>33</em>(4), 1259–1684. (<a
href="https://doi.org/10.1287/ijoc.2020.1016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distortion risk measure, defined by an integral of a distorted tail probability, has been widely used in behavioral economics and risk management as an alternative to expected utility. The sensitivity of the distortion risk measure is a functional of certain distribution sensitivities. We propose a new sensitivity estimator for the distortion risk measure that uses generalized likelihood ratio estimators for distribution sensitivities as input and establish a central limit theorem for the new estimator. The proposed estimator can handle discontinuous sample paths and distortion functions.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.1016},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {1259-1684},
  shortjournal = {INFORMS J. Comput.},
  title        = {Computing sensitivities for distortion risk measures},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust capacity planning for project management.
<em>IJOC</em>, <em>33</em>(4), 1259–1684. (<a
href="https://doi.org/10.1287/ijoc.2020.1033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a significant problem that arises in the planning of many projects. Project companies often use outsourced providers that require capacity reservations that must be contracted before task durations are realized. We model these decisions for a company that, given partially characterized distributional information, assumes the worst-case distribution for task durations. Once task durations are realized, the project company makes decisions about fast tracking and outsourced crashing, to minimize the total capacity reservation, fast tracking, crashing, and makespan penalty costs. We model the company’s objective using the target-based measure of minimizing an underperformance riskiness index. We allow for correlation in task performance, and for piecewise linear costs of crashing and makespan penalties. An optimal solution of the discrete, nonlinear model is possible for small to medium size projects. We compare the performance of our model against the best available benchmarks from the robust optimization literature, and show that it provides lower risk and greater robustness to distributional information. Our work thus enables more effective risk minimization in projects, and provides insights about how to make more robust capacity reservation decisions. Summary of Contribution: This work studies a financially significant planning problem that arises in project management. Companies that face uncertainties in project execution may need to reserve capacity with outsourced providers. Given that decision, they further need to plan their operational decisions to protect against a bad outcome. We model and solve this problem via adjustable distributionally robust optimization. While this problem involves two-stage decision making, which is computationally challenging in general, we develop a computationally efficient algorithm to find the exact optimal solution for instances of practical size.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.1033},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {1259-1684},
  shortjournal = {INFORMS J. Comput.},
  title        = {Robust capacity planning for project management},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Logic-based benders decomposition and binary decision
diagram based approaches for stochastic distributed operating room
scheduling. <em>IJOC</em>, <em>33</em>(4), 1259–1684. (<a
href="https://doi.org/10.1287/ijoc.2020.1036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The distributed operating room (OR) scheduling problem aims to find an assignment of surgeries to ORs across collaborating hospitals that share their waiting lists and ORs. We propose a stochastic extension of this problem where surgery durations are considered to be uncertain. In order to obtain solutions for the challenging stochastic model, we use sample average approximation and develop two enhanced decomposition frameworks that use logic-based Benders (LBBD) optimality cuts and binary decision diagram based Benders cuts. Specifically, to the best of our knowledge, deriving LBBD optimality cuts in a stochastic programming context is new to the literature. Our computational experiments on a hospital data set illustrate that the stochastic formulation generates robust schedules and that our algorithms improve the computational efficiency. Summary of Contribution: We propose a new model for an important problem in healthcare scheduling, namely, stochastic distributed operating room scheduling, which is inspired by a current practice in Toronto, Ontario, Canada. We develop two decomposition methods that are computationally faster than solving the model directly via a state-of-the-art solver. We present both some theoretical results for our algorithms and numerical results for the evaluation of the model and algorithms. Compared with its deterministic counterpart in the literature, our model shows improvement in relevant evaluation metrics for the underlying scheduling problem. In addition, our algorithms exploit the structure of the model and improve its solvability. Those algorithms also have the potential to be used to tackle other planning and scheduling problems with a similar structure.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.1036},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {1259-1684},
  shortjournal = {INFORMS J. Comput.},
  title        = {Logic-based benders decomposition and binary decision diagram based approaches for stochastic distributed operating room scheduling},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modeling defender-attacker problems as robust linear
programs with mixed-integer uncertainty sets. <em>IJOC</em>,
<em>33</em>(4), 1259–1684. (<a
href="https://doi.org/10.1287/ijoc.2020.1041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a class of sequential defender-attacker optimization problems where the defender’s objective is uncertain and depends on the operations of the attacker, which are represented by a mixed-integer uncertainty set. The defender seeks to hedge against the worst possible data realization, resulting in a robust optimization problem with a mixed-integer uncertainty set, which requires the solution of a challenging mixed-integer problem, which can be seen as a saddle-point problem over a nonconvex domain. We study two exact solution algorithms and present two feature applications for which the uncertainty is naturally modeled as a mixed-integer set. Our computational experiments show that the considered algorithms greatly outperform standard algorithms both in terms of computational time and solution quality. Moreover, our results show that modeling uncertainty with mixed-integer sets, instead of approximating the data using convex sets, results in less conservative solutions, which translates to a lower cost for the defender to protect from uncertainty. Summary of Contribution: We consider a class of defender-attacker problems where the defender has to make operational decisions that depend on uncertain actions from an adversarial attacker. Due to the type of information available to the defender, neither probabilistic modeling, nor robust optimization methods with convex uncertainty sets, are well suited to address the defender’s decision-making problem. Consequently, we frame the defender’s problem as a class of robust optimization problems with a mixed-integer uncertainty sets, and devise two exact algorithms that solve this class of problems. A comprehensive computational study shows that for the considered applications, our algorithms improves the performance of existing robust optimization approaches that can be adapted to solve this class of problems. Moreover, we show how mixed-integer uncertainty sets can reduce the level of over-conservatism that is a known issue of robust optimization approaches.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.1041},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {1259-1684},
  shortjournal = {INFORMS J. Comput.},
  title        = {Modeling defender-attacker problems as robust linear programs with mixed-integer uncertainty sets},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Structured robust submodular maximization: Offline and
online algorithms. <em>IJOC</em>, <em>33</em>(4), 1259–1684. (<a
href="https://doi.org/10.1287/ijoc.2020.0998">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained submodular function maximization has been used in subset selection problems such as selection of most informative sensor locations. Although these models have been quite popular, the solutions obtained via this approach are unstable to perturbations in data defining the submodular functions. Robust submodular maximization has been proposed as a richer model that aims to overcome this discrepancy as well as increase the modeling scope of submodular optimization. In this work, we consider robust submodular maximization with structured combinatorial constraints and give efficient algorithms with provable guarantees. Our approach is applicable to constraints defined by single or multiple matroids and knapsack as well as distributionally robust criteria. We consider both the offline setting where the data defining the problem are known in advance and the online setting where the input data are revealed over time. For the offline setting, we give a general (nearly) optimal bicriteria approximation algorithm that relies on new extensions of classical algorithms for submodular maximization. For the online version of the problem, we give an algorithm that returns a bicriteria solution with sublinear regret. Summary of Contribution: Constrained submodular maximization is one of the core areas in combinatorial optimization with a wide variety of applications in operations research and computer science. Over the last decades, both communities have been interested on the design and analysis of new algorithms with provable guarantees. Sensor location, influence maximization and data summarization are some of the applications of submodular optimization that lie at the intersection of the aforementioned communities. Particularly, our work focuses on optimizing several submodular functions simultaneously. We provide new insights and algorithms to the offline and online variants of the problem which significantly expand the related literature. At the same time, we provide a computational study that supports our theoretical results.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.0998},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {1259-1684},
  shortjournal = {INFORMS J. Comput.},
  title        = {Structured robust submodular maximization: Offline and online algorithms},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Location-aware real-time recommender systems for
brick-and-mortar retailers. <em>IJOC</em>, <em>33</em>(4), 1259–1684.
(<a href="https://doi.org/10.1287/ijoc.2020.1020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Providing real-time product recommendations based on consumer profiles and purchase history is a successful marketing strategy in online retailing. However, brick-and-mortar (BAM) retailers have yet to utilize this important promotional strategy because it is difficult to predict consumer preferences as they travel in a physical space but remain anonymous and unidentifiable until checkout. In this paper, we develop such a recommender approach by leveraging the consumer shopping path information generated by radio frequency identification technologies. The system relies on spatial-temporal pattern discovery that measures the similarity between paths and recommends products based on measured similarity. We use a real-world retail data set to demonstrate the feasibility of this real-time recommender system and show that our approach outperforms benchmark methods in key recommendation metrics. Conceptually, this research provides generalizable insights on the correlation between spatial movement and consumer preference. It makes a strong case that the emerging location and path data and the spatial-temporal pattern discovery methods can be effectively utilized for implementable marketing strategies. Managerially, it provides one of the first real-time recommender systems for BAM retailers. Our approach can potentially become the core of the next-generation intelligent shopping environment in which the stores customize marketing efforts to provide real-time, location-aware recommendations.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.1020},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {1259-1684},
  shortjournal = {INFORMS J. Comput.},
  title        = {Location-aware real-time recommender systems for brick-and-mortar retailers},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multirow intersection cuts based on the infinity norm.
<em>IJOC</em>, <em>33</em>(4), 1259–1684. (<a
href="https://doi.org/10.1287/ijoc.2020.1027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When generating multirow intersection cuts for mixed-integer linear optimization problems, an important practical question is deciding which intersection cuts to use. Even when restricted to cuts that are facet defining for the corner relaxation, the number of potential candidates is still very large, especially for instances of large size. In this paper, we introduce a subset of intersection cuts based on the infinity norm that is very small, works for relaxations having arbitrary number of rows and, unlike many subclasses studied in the literature, takes into account the entire data from the simplex tableau. We describe an algorithm for generating these inequalities and run extensive computational experiments in order to evaluate their practical effectiveness in real-world instances. We conclude that this subset of inequalities yields, in terms of gap closure, around 50\% of the benefits of using all valid inequalities for the corner relaxation simultaneously, but at a small fraction of the computational cost, and with a very small number of cuts. Summary of Contribution: Cutting planes are one of the most important techniques used by modern mixed-integer linear programming solvers when solving a variety of challenging operations research problems. The paper advances the state of the art on general-purpose multirow intersection cuts by proposing a practical and computationally friendly method to generate them.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.1027},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {1259-1684},
  shortjournal = {INFORMS J. Comput.},
  title        = {Multirow intersection cuts based on the infinity norm},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bilevel integer programs with stochastic right-hand sides.
<em>IJOC</em>, <em>33</em>(4), 1259–1684. (<a
href="https://doi.org/10.1287/ijoc.2020.1055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop an exact value function-based approach to solve a class of bilevel integer programs with stochastic right-hand sides. We first study structural properties and design two methods to efficiently construct the value function of a bilevel integer program. Most notably, we generalize the integer complementary slackness theorem to bilevel integer programs. We also show that the value function of a bilevel integer program can be characterized by its values on a set of so-called bilevel minimal vectors. We then solve the value function reformulation of the original bilevel integer program with stochastic right-hand sides using a branch-and-bound algorithm. We demonstrate the performance of our solution methods on a set of randomly generated instances. We also apply the proposed approach to a bilevel facility interdiction problem. Our computational experiments show that the proposed solution methods can efficiently optimize large-scale instances. The performance of our value function-based approach is relatively insensitive to the number of scenarios, but it is sensitive to the number of constraints with stochastic right-hand sides. Summary of Contribution: Bilevel integer programs arise in many different application areas of operations research including supply chain, energy, defense, and revenue management. This paper derives structural properties of the value functions of bilevel integer programs. Furthermore, it proposes exact solution algorithms for a class of bilevel integer programs with stochastic right-hand sides. These algorithms extend the applicability of bilevel integer programs to a larger set of decision-making problems under uncertainty.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.1055},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {1259-1684},
  shortjournal = {INFORMS J. Comput.},
  title        = {Bilevel integer programs with stochastic right-hand sides},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Chance-constrained multiple bin packing problem with an
application to operating room planning. <em>IJOC</em>, <em>33</em>(4),
1259–1684. (<a href="https://doi.org/10.1287/ijoc.2020.1010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the chance-constrained bin packing problem, with an application to hospital operating room planning. The bin packing problem allocates items of random sizes that follow a discrete distribution to a set of bins with limited capacity, while minimizing the total cost. The bin capacity constraints are satisfied with a given probability. We investigate a big-M and a 0-1 bilinear formulation of this problem. We analyze the bilinear structure of the formulation and use the lifting techniques to identify cover, clique, and projection inequalities to strengthen the formulation. We show that in certain cases these inequalities are facet-defining for a bilinear knapsack constraint that arises in the reformulation. An extensive computational study is conducted for the operating room planning problem that minimizes the number of open operating rooms. The computational tests are performed using problems generated based on real data from a hospital. A lower-bound improvement heuristic is combined with the cuts proposed in this paper in a branch-and-cut framework. The computations illustrate that the techniques developed in this paper can significantly improve the performance of the branch-and-cut method. Problems with up to 1,000 scenarios are solved to optimality in less than an hour. A safe approximation based on conditional value at risk (CVaR) is also solved. The computations show that the CVaR approximation typically leaves a gap of one operating room (e.g., six instead of five) to satisfy the chance constraint. Summary of Contribution: This paper investigates a branch-and-cut algorithm for a chance-constrained bin packing problem with multiple bins. The chance-constrained bin packing provides a modeling framework for applied operations research problems, such as health care, scheduling, and so on. This paper studies alternative computational approaches to solve this problem. Moreover, this paper uses real data from a hospital operating room planning setting as an application to test the algorithmic ideas. This work, therefore, is at the intersection of computing and operations research. Several interesting ideas are developed and studied. These include a strengthened big-M reformulation, analysis of a bilinear reformulation, and identifying certain facet-defining inequalities for this formulation. This paper also gives a lower-bound generation heuristic for a model that minimizes the number of bins. Computational experiments for an operating room planning model that uses data from a hospital demonstrate the computational improvement and importance of the proposed approaches. The techniques proposed in this paper and computational experiments further enhance the interface of computing and operations research.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.1010},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {1259-1684},
  shortjournal = {INFORMS J. Comput.},
  title        = {Chance-constrained multiple bin packing problem with an application to operating room planning},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Appreciation to reviewers. <em>IJOC</em>, <em>33</em>(4),
1259–1684. (<a href="https://doi.org/10.1287/ijoc.2021.1131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {On behalf of the Editorial Board, I would like to thank the following people, who acted as Reviewers during the past year. Reviewers are the cornerstone of the peer review system and give their time unselfishly which has been especially difficult during the continuing pandemic. IJOC reviewers, please know you are greatly appreciated! Alice Smith, Editor-in-Chief},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2021.1131},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {1259-1684},
  shortjournal = {INFORMS J. Comput.},
  title        = {Appreciation to reviewers},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Editorial board. <em>IJOC</em>, <em>33</em>(3), C2. (<a
href="https://doi.org/10.1287/ijoc.2021.eb.v3303">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2021.eb.v3303},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {C2},
  shortjournal = {INFORMS J. Comput.},
  title        = {Editorial board},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modeling and solving the intersection inspection rural
postman problem. <em>IJOC</em>, <em>33</em>(3), 1245–1257. (<a
href="https://doi.org/10.1287/ijoc.2020.1013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Local governments inspect roads to decide which segments and intersections to repair. Videos are taken using a camera mounted on a vehicle. The vehicle taking the videos proceeds straight or takes a left turn to cover an intersection fully. We introduce the intersection inspection rural postman problem (IIRPP), which is a new variant of the rural postman problem (RPP) that involves turns. We develop integer programming formulations of the IIRPP based on two different graph transformations to generate least-cost vehicle routes. One formulation is based on a new idea of transforming a graph. A second formulation is based on a graph transformation idea from the literature. Computational experiments show that the formulation involving the new graph transformation idea performs much better than the other formulation. We also develop an RPP-based heuristic and a heuristic based on a modified RPP. Heuristic solutions are improved by solving integer programming formulations on an induced subgraph. Computational experiments show that the heuristics based on the modified RPP perform much better than the RPP-based heuristics. The best-performing heuristic generates very good quality IIRPP-feasible routes on large street networks quickly.},
  archive      = {J_IJOC},
  author       = {Debdatta Sinha Roy and Adriano Masone and Bruce Golden and Edward Wasil},
  doi          = {10.1287/ijoc.2020.1013},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1245-1257},
  shortjournal = {INFORMS J. Comput.},
  title        = {Modeling and solving the intersection inspection rural postman problem},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An exact algorithm for large-scale continuous nonlinear
resource allocation problems with minimax regret objectives.
<em>IJOC</em>, <em>33</em>(3), 1213–1228. (<a
href="https://doi.org/10.1287/ijoc.2020.0999">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a large-scale resource allocation problem with a convex, separable, not necessarily differentiable objective function that includes uncertain parameters falling under an interval uncertainty set, considering a set of deterministic constraints. We devise an exact algorithm to solve the minimax regret formulation of this problem, which is NP-hard, and we show that the proposed Benders-type decomposition algorithm converges to an ɛ-optimal solution in finite time. We evaluate the performance of the proposed algorithm via an extensive computational study, and our results show that the proposed algorithm provides efficient solutions to large-scale problems, especially when the objective function is differentiable. Although the computation time takes longer for problems with nondifferentiable objective functions as expected, we show that good quality, near-optimal solutions can be achieved in shorter runtimes by using our exact approach. We also develop two heuristic approaches, which are partially based on our exact algorithm, and show that the merit of the proposed exact approach lies in both providing an ɛ-optimal solution and providing good quality near-optimal solutions by laying the foundation for efficient heuristic approaches.},
  archive      = {J_IJOC},
  author       = {Jungho Park and Hadi El-Amine and Nevin Mutlu},
  doi          = {10.1287/ijoc.2020.0999},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1213-1228},
  shortjournal = {INFORMS J. Comput.},
  title        = {An exact algorithm for large-scale continuous nonlinear resource allocation problems with minimax regret objectives},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new combinatorial algorithm for separable convex resource
allocation with nested bound constraints. <em>IJOC</em>, <em>33</em>(3),
1197–1212. (<a href="https://doi.org/10.1287/ijoc.2020.1006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The separable convex resource allocation problem with nested bound constraints aims to allocate B units of resources to n activities to minimize a separable convex cost function, with lower and upper bounds on the total amount of resources that can be consumed by nested subsets of activities. We develop a new combinatorial algorithm to solve this model exactly. Our algorithm is capable of solving instances with millions of activities in several minutes. The running time of our algorithm is at most 73\% of the running time of the current best algorithm for benchmark instances with three classes of convex objectives. The efficiency of our algorithm derives from a combination of constraint relaxation and divide and conquer based on infeasibility information. In particular, nested bound constraints are relaxed first; if the solution obtained violates some bound constraints, we show that the problem can be divided into two subproblems of the same structure and smaller sizes according to the bound constraint with the largest violation.},
  archive      = {J_IJOC},
  author       = {Zeyang Wu and Kameng Nip and Qie He},
  doi          = {10.1287/ijoc.2020.1006},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1197-1212},
  shortjournal = {INFORMS J. Comput.},
  title        = {A new combinatorial algorithm for separable convex resource allocation with nested bound constraints},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Combinatorial benders decomposition for the two-dimensional
bin packing problem. <em>IJOC</em>, <em>33</em>(3), 963–978. (<a
href="https://doi.org/10.1287/ijoc.2020.1014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The two-dimensional bin packing problem calls for packing a set of rectangular items into a minimal set of larger rectangular bins. Items must be packed with their edges parallel to the borders of the bins, cannot be rotated, and cannot overlap among them. The problem is of interest because it models many real-world applications, including production, warehouse management, and transportation. It is, unfortunately, very difficult, and instances with just 40 items are unsolved to proven optimality, despite many attempts, since the 1990s. In this paper, we solve the problem with a combinatorial Benders decomposition that is based on a simple model in which the two-dimensional items and bins are just represented by their areas, and infeasible packings are imposed by means of exponentially many no-good cuts. The basic decomposition scheme is quite naive, but we enrich it with a number of preprocessing techniques, valid inequalities, lower bounding methods, and enhanced algorithms to produce the strongest possible cuts. The resulting algorithm behaved very well on the benchmark sets of instances, improving on average on previous algorithms from the literature and solving for the first time a number of open instances.},
  archive      = {J_IJOC},
  author       = {Jean-François Côté and Mohamed Haouari and Manuel Iori},
  doi          = {10.1287/ijoc.2020.1014},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {963-978},
  shortjournal = {INFORMS J. Comput.},
  title        = {Combinatorial benders decomposition for the two-dimensional bin packing problem},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Tagging items automatically based on both content
information and browsing behaviors. <em>IJOC</em>, <em>33</em>(3),
882–897. (<a href="https://doi.org/10.1287/ijoc.2020.1007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tags have been adopted by many online services as a method to manage their online resources. Effective tagging benefits both users and firms. In real applications providing a user tagging mechanism, only a small portion of tags are usually provided by users. Therefore, an automatic tagging method, which can assign tags to different items automatically, is urgently needed. Previous works on automatic tagging focus on exploring the tagging behavior of users or the content information of items. In online service platforms, users frequently browse items related to their interests, which implies users’ judgment about the underlying features of items and is helpful for automatic tagging. Browsing-behavior records are much more plentiful compared with tagging behavior and easy to collect. However, existing studies about automatic tagging ignore this kind of information. To properly integrate both browsing behaviors and content information for automatic tagging, we propose a novel probabilistic graphical model and develop a new algorithm for the model parameter inference. We conduct thorough experiments on a real-world data set to evaluate and analyze the performance of our proposed method. The experimental results demonstrate that our approach achieves better performance than state-of-the-art automatic tagging methods.},
  archive      = {J_IJOC},
  author       = {Shen Liu and Hongyan Liu},
  doi          = {10.1287/ijoc.2020.1007},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {882-897},
  shortjournal = {INFORMS J. Comput.},
  title        = {Tagging items automatically based on both content information and browsing behaviors},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). 3-d dynamic UAV base station location problem.
<em>IJOC</em>, <em>33</em>(3), 839–860. (<a
href="https://doi.org/10.1287/ijoc.2020.1034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address a dynamic covering location problem of an unmanned aerial vehicle base station (UAV-BS), in which the location sequence of a single UAV-BS in a wireless communication network is determined to satisfy data demand arising from ground users. This problem is especially relevant in the context of smart grid and disaster relief. The vertical movement ability of the UAV-BS and nonconvex covering functions in wireless communication restrict utilizing classical planar covering location approaches. Therefore, we develop new formulations to this emerging problem for a finite time horizon to maximize the total coverage. In particular, we develop a mixed-integer nonlinear programming formulation that is nonconvex in nature and propose a Lagrangean decomposition algorithm (LDA) to solve this formulation. Because of the high complexity of the problem, the LDA is still unable to find good local solutions to large-scale problems. Therefore, we develop a continuum approximation (CA) model and show that CA would be a promising approach in terms of both computational time and solution accuracy. Our numerical study also shows that the CA model can be a remedy to build efficient initial solutions for exact solution algorithms.},
  archive      = {J_IJOC},
  author       = {Cihan Tugrul Cicek and Zuo-Jun Max Shen and Hakan Gultekin and Bulent Tavli},
  doi          = {10.1287/ijoc.2020.1034},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {839-860},
  shortjournal = {INFORMS J. Comput.},
  title        = {3-D dynamic UAV base station location problem},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Note from the editor. <em>IJOC</em>, <em>33</em>(3),
837–838. (<a href="https://doi.org/10.1287/ijoc.2021.1102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJOC},
  author       = {Alice E. Smith},
  doi          = {10.1287/ijoc.2021.1102},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {837-838},
  shortjournal = {INFORMS J. Comput.},
  title        = {Note from the editor},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Note from the editor. <em>IJOC</em>, <em>33</em>(2),
419–835. (<a href="https://doi.org/10.1287/ijoc.2021.1076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2021.1076},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {419-835},
  shortjournal = {INFORMS J. Comput.},
  title        = {Note from the editor},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Conflict analysis for MINLP. <em>IJOC</em>, <em>33</em>(2),
419–835. (<a href="https://doi.org/10.1287/ijoc.2020.1050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The generalization of mixed integer program (MIP) techniques to deal with nonlinear, potentially nonconvex, constraints has been a fruitful direction of research for computational mixed integer nonlinear programs (MINLPs) in the last decade. In this paper, we follow that path in order to extend another essential subroutine of modern MIP solvers toward the case of nonlinear optimization: the analysis of infeasible subproblems for learning additional valid constraints. To this end, we derive two different strategies, geared toward two different solution approaches. These are using local dual proofs of infeasibility for LP-based branch-and-bound and the creation of nonlinear dual proofs for NLP-based branch-and-bound, respectively. We discuss implementation details of both approaches and present an extensive computational study, showing that both techniques can significantly enhance performance when solving MINLPs to global optimality. Summary of Contribution: This original article concerns the advancement of exact general-purpose algorithms for solving one of the largest and most prominent problem classes in optimization, mixed integer nonlinear programs (MINLPs). It demonstrates how methods for conflict analysis that learn from infeasible subproblems can be transferred to nonlinear optimization. Further, it develops theory for how nonlinear dual infeasibility proofs can be derived from a nonlinear relaxation. This paper features a thoroughly computational study regarding the impact of conflict analysis techniques on the overall performance of a state-of-the-art MINLP solver when solving MINLPs to global optimality.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.1050},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {419-835},
  shortjournal = {INFORMS J. Comput.},
  title        = {Conflict analysis for MINLP},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modeling single-picker routing problems in classical and
modern warehouses. <em>IJOC</em>, <em>33</em>(2), 419–835. (<a
href="https://doi.org/10.1287/ijoc.2020.1040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The standard single-picker routing problem (SPRP) seeks the cost-minimal tour to collect a set of given articles in a rectangular single-block warehouse with parallel picking aisles and a dedicated storage policy, that is, each stock-keeping unit is only available from one storage location in the warehouse. We present a compact formulation that forgoes classical subtour elimination constraints by directly exploiting two of the properties of an optimal picking tour used in the dynamic programming algorithm published in the seminal paper of Ratliff and Rosenthal. We extend the formulation to three important settings prevalent in modern e-commerce warehouses: scattered storage, decoupling of picker and cart, and multiple end depots. In numerical studies, our formulation outperforms existing standard SPRP formulations from the literature and proves able to solve large instances within short runtimes. Realistically sized instances of the three problem extensions can also be solved with low computational effort. For scattered storage, we note a rough tendency that runtimes increase with longer pick lists or a higher degree of duplication. In addition, we find that decoupling of picker and cart can lead to substantial cost savings depending on the speed and capacity of the picker when traveling alone, whereas additional end depots have rather limited benefits in a single-block warehouse. Summary of Contribution: Efficiently routing order pickers is of great practical interest because picking costs make up a substantial part of operational warehouse costs. For the prevalent case of a rectangular warehouse with parallel picking aisles, we present a highly effective modeling approach that covers—in addition to the standard setting—several important storage and order-picking strategies employed in modern e-commerce warehouses: scattered storage, decoupling of picker and cart, and multiple end depots. In this way, we provide practitioners as well as scientists with an easy and quick way of implementing a high-quality solution approach for routing pickers in the described settings. In addition, we shed some light on the cost benefits of the different storage and picking strategies in numerical experiments.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.1040},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {419-835},
  shortjournal = {INFORMS J. Comput.},
  title        = {Modeling single-picker routing problems in classical and modern warehouses},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A branch-and-price-and-cut algorithm for the cable-routing
problem in solar power plants. <em>IJOC</em>, <em>33</em>(2), 419–835.
(<a href="https://doi.org/10.1287/ijoc.2020.0981">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A solar power plant is a large-scale photovoltaic (PV) system designed to supply usable solar power to the electricity grid. Building a solar power plant needs consideration of arrangements of several important components, such as PV arrays, solar inverters, combiner boxes, cables, and other electrical accessories. The design of solar power plants is very complex because of various optimization parameters and design regulations. In this study, we address the cable-routing problem arising in the planning of large-scale solar power plants, which aims to determine the partition of the PV arrays, the location of combiner boxes, and cable routing such that the installation cost of the cables connecting the components is minimized. We formulate the problem as a mathematical programming problem, which can be viewed as a generalized capacitated minimum spanning tree (CMST) problem, and then devise a branch-and-price-and-cut (BPC) algorithm to solve it. The BPC algorithm uses two important valid inequalities, namely the capacity inequalities and the subset-row inequalities, to tighten the lower bounds. We also adopt several acceleration strategies to speed up the algorithm. Using real-world data sets, we show by numerical experiments that our BPC algorithm is superior to the typical manual-based planning approach used by many electric power planning companies. In addition, when solving the CMST problem with unitary demands, our algorithm is highly competitive compared with the best exact algorithm in the literature.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.0981},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {419-835},
  shortjournal = {INFORMS J. Comput.},
  title        = {A branch-and-price-and-cut algorithm for the cable-routing problem in solar power plants},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Vehicle sequencing at transshipment terminals with handover
relations. <em>IJOC</em>, <em>33</em>(2), 419–835. (<a
href="https://doi.org/10.1287/ijoc.2020.0964">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Operational planning at transshipment nodes is a wide and challenging field of research that covers a vast number of distinct relevant applications, spanning from seaport container terminals to rail terminals to cross-docks. In this work, we study the feasibility version of a fundamental synchronization problem that assigns incoming vehicles to docking resources subject to handover relations. We carry out a comprehensive analysis of computational complexity of various problem variants and establish structural connections to famous decision problems in graph theory. We further propose an exact solution algorithm for finding feasible dock assignments, if vehicles can visit the node only once and evaluate its performance in a comprehensive computational study.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.0964},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {419-835},
  shortjournal = {INFORMS J. Comput.},
  title        = {Vehicle sequencing at transshipment terminals with handover relations},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Addressing orientation symmetry in the time window
assignment vehicle routing problem. <em>IJOC</em>, <em>33</em>(2),
419–835. (<a href="https://doi.org/10.1287/ijoc.2020.0974">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The time window assignment vehicle routing problem (TWAVRP) is the problem of assigning time windows for delivery before demand volume becomes known. This implies that vehicle routes in different demand scenarios have to be synchronized such that the same client is visited around the same time in each scenario. For TWAVRP instances that are relatively difficult to solve, we observe many similar solutions in which one or more routes have a different orientation, that is, the clients are visited in the reverse order. We introduce an edge-based branching method combined with additional components to eliminate orientation symmetry from the search tree, and we present enhancements to make this method efficient in practice. Next, we present a branch-price-and-cut algorithm based on this branching method. Our computational experiments show that addressing orientation symmetry significantly improves our algorithm: The number of nodes in the search tree is reduced by 92.6\% on average, and 25 additional benchmark instances are solved to optimality. Furthermore, the resulting algorithm is competitive with the state of the art. The main ideas of this paper are not TWAVRP specific and can be applied to other vehicle routing problems with consistency considerations or synchronization requirements.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.0974},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {419-835},
  shortjournal = {INFORMS J. Comput.},
  title        = {Addressing orientation symmetry in the time window assignment vehicle routing problem},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sparse solutions by a quadratically constrained ℓ q (0 &lt;
q &lt; 1) minimization model. <em>IJOC</em>, <em>33</em>(2), 419–835.
(<a href="https://doi.org/10.1287/ijoc.2020.1004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding sparse solutions to a system of equations and/or inequalities is an important topic in many application areas such as signal processing, statistical regression and nonparametric modeling. Various continuous relaxation models have been proposed and widely studied to deal with the discrete nature of the underlying problem. In this paper, we propose a quadratically constrained ℓ q (0 &lt; q &lt; 1) minimization model for finding sparse solutions to a quadratic system. We prove that solving the proposed model is strongly NP-hard. To tackle the computation difficulty, a first order necessary condition for local minimizers is derived. Various properties of the proposed model are studied for designing an active-set-based descent algorithm to find candidate solutions satisfying the proposed condition. In addition to providing a theoretical convergence proof, we conduct extensive computational experiments using synthetic and real-life data to validate the effectiveness of the proposed algorithm and to show the superior capability in finding sparse solutions of the proposed model compared with other known models in the literature. We also extend our results to a quadratically constrained ℓ q (0 &lt; q &lt; 1) minimization model with multiple convex quadratic constraints for further potential applications. Summary of Contribution: In this paper, we propose and study a quadratically constrained ℓ q minimization (0 &lt; q &lt; 1) model for finding sparse solutions to a quadratic system which has wide applications in sparse signal recovery, image processing and machine learning. The proposed quadratically constrained ℓ q minimization model extends the linearly constrained ℓ q and unconstrained ℓ 2 - ℓ q models. We study various properties of the proposed model in aim of designing an efficient algorithm. Especially, we propose an unrelaxed KKT condition for local/global minimizers. Followed by the properties studied, an active-set based descent algorithm is then proposed with its convergence proof being given. Extensive numerical experiments with synthetic and real-life Sparco datasets are conducted to show that the proposed algorithm works very effectively and efficiently. Its sparse recovery capability is superior to that of other known models in the literature.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.1004},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {419-835},
  shortjournal = {INFORMS J. Comput.},
  title        = {Sparse solutions by a quadratically constrained ℓ q (0 &lt; q &lt; 1) minimization model},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the solution of ℓ0-constrained sparse inverse covariance
estimation problems. <em>IJOC</em>, <em>33</em>(2), 419–835. (<a
href="https://doi.org/10.1287/ijoc.2020.0991">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sparse inverse covariance matrix is used to model conditional dependencies between variables in a graphical model to fit a multivariate Gaussian distribution. Estimating the matrix from data are well known to be computationally expensive for large-scale problems. Sparsity is employed to handle noise in the data and to promote interpretability of a learning model. Although the use of a convex ℓ 1 regularizer to encourage sparsity is common practice, the combinatorial ℓ 0 penalty often has more favorable statistical properties. In this paper, we directly constrain sparsity by specifying a maximally allowable number of nonzeros, in other words, by imposing an ℓ 0 constraint. We introduce an efficient approximate Newton algorithm using warm starts for solving the nonconvex ℓ 0 -constrained inverse covariance learning problem. Numerical experiments on standard data sets show that the performance of the proposed algorithm is competitive with state-of-the-art methods. Summary of Contribution: The inverse covariance estimation problem underpins many domains, including statistics, operations research, and machine learning. We propose a scalable optimization algorithm for solving the nonconvex ℓ 0 -constrained problem.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.0991},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {419-835},
  shortjournal = {INFORMS J. Comput.},
  title        = {On the solution of ℓ0-constrained sparse inverse covariance estimation problems},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A mixed-integer fractional optimization approach to best
subset selection. <em>IJOC</em>, <em>33</em>(2), 419–835. (<a
href="https://doi.org/10.1287/ijoc.2020.1031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the best subset selection problem in linear regression—that is, finding a parsimonious subset of the regression variables that provides the best fit to the data according to some predefined criterion. We are primarily concerned with alternatives to cross-validation methods that do not require data partitioning and involve a range of information criteria extensively studied in the statistical literature. We show that the problem of interest can be modeled using fractional mixed-integer optimization, which can be tackled by leveraging recent advances in modern optimization solvers. The proposed algorithms involve solving a sequence of mixed-integer quadratic optimization problems (or their convexifications) and can be implemented with off-the-shelf solvers. We report encouraging results in our computational experiments, with respect to both the optimization and statistical performance. Summary of Contribution: This paper considers feature selection problems with information criteria. We show that by adopting a fractional optimization perspective (a well-known field in nonlinear optimization and operations research), it is possible to leverage recent advances in mixed-integer quadratic optimization technology to tackle traditional statistical problems long considered intractable. We present extensive computational experiments, with both synthetic and real data, illustrating that the new fractional optimization approach is orders of magnitude faster than existing approaches in the literature.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.1031},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {419-835},
  shortjournal = {INFORMS J. Comput.},
  title        = {A mixed-integer fractional optimization approach to best subset selection},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Supervised t-distributed stochastic neighbor embedding for
data visualization and classification. <em>IJOC</em>, <em>33</em>(2),
419–835. (<a href="https://doi.org/10.1287/ijoc.2020.0961">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel supervised dimension-reduction method called supervised t-distributed stochastic neighbor embedding (St-SNE) that achieves dimension reduction by preserving the similarities of data points in both feature and outcome spaces. The proposed method can be used for both prediction and visualization tasks with the ability to handle high-dimensional data. We show through a variety of data sets that when compared with a comprehensive list of existing methods, St-SNE has superior prediction performance in the ultrahigh-dimensional setting in which the number of features p exceeds the sample size n and has competitive performance in the p ≤ n setting. We also show that St-SNE is a competitive visualization tool that is capable of capturing within-cluster variations. In addition, we propose a penalized Kullback–Leibler divergence criterion to automatically select the reduced-dimension size k for St-SNE. Summary of Contribution: With the fast development of data collection and data processing technologies, high-dimensional data have now become ubiquitous. Examples of such data include those collected from environmental sensors, personal mobile devices, and wearable electronics. High-dimensionality poses great challenges for data analytics routines, both methodologically and computationally. Many machine learning algorithms may fail to work for ultrahigh-dimensional data, where the number of the features p is (much) larger than the sample size n . We propose a novel method for dimension reduction that can (i) aid the understanding of high-dimensional data through visualization and (ii) create a small set of good predictors, which is especially useful for prediction using ultrahigh-dimensional data.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.0961},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {419-835},
  shortjournal = {INFORMS J. Comput.},
  title        = {Supervised t-distributed stochastic neighbor embedding for data visualization and classification},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Data-driven preference learning methods for value-driven
multiple criteria sorting with interacting criteria. <em>IJOC</em>,
<em>33</em>(2), 419–835. (<a
href="https://doi.org/10.1287/ijoc.2020.0977">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The learning of predictive models for data-driven decision support has been a prevalent topic in many fields. However, construction of models that would capture interactions among input variables is a challenging task. In this paper, we present a new preference learning approach for multiple criteria sorting with potentially interacting criteria. It employs an additive piecewise-linear value function as the basic preference model, which is augmented with components for handling the interactions. To construct such a model from a given set of assignment examples concerning reference alternatives, we develop a convex quadratic programming model. Because its complexity does not depend on the number of training samples, the proposed approach is capable for dealing with data-intensive tasks. To improve the generalization of the constructed model on new instances and to overcome the problem of overfitting, we employ the regularization techniques. We also propose a few novel methods for classifying nonreference alternatives in order to enhance the applicability of our approach to different data sets. The practical usefulness of the proposed approach is demonstrated on a problem of parametric evaluation of research units, whereas its predictive performance is studied on several monotone classification problems. The experimental results indicate that our approach compares favourably with the classical UTilités Additives DIScriminantes (UTADIS) method and the Choquet integral-based sorting model. Summary of Contribution . The paper tackles vital challenges at the intersections of multiple criteria decision analysis and machine learning, showing how computationally advanced techniques can be used for faithfully representing human preferences and dealing with complex decision problems. Specifically, we propose a novel preference learning method for multiple criteria sorting problems. The introduced approach incorporates convex quadratic programming to construct a value-based preference model based on large sets of preference statements. In this way, we extend the applicability of decision analysis methods to preferences derived from historical data or observation of users&#39; behavior in addition to the preference judgments explicitly revealed by the decision-makers. The method&#39;s practical usefulness is illustrated on a variety of real-world datasets from fields such as higher education, medicine, human resources, and housing market. Its potential for supporting better decision-making is enhanced by both an interpretable form of the assumed model handling interactions between criteria as well as a high predictive performance demonstrated in the extensive computational experiments.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.0977},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {419-835},
  shortjournal = {INFORMS J. Comput.},
  title        = {Data-driven preference learning methods for value-driven multiple criteria sorting with interacting criteria},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Semidefinite programming and nash equilibria in bimatrix
games. <em>IJOC</em>, <em>33</em>(2), 419–835. (<a
href="https://doi.org/10.1287/ijoc.2020.0960">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We explore the power of semidefinite programming (SDP) for finding additive ɛ-approximate Nash equilibria in bimatrix games. We introduce an SDP relaxation for a quadratic programming formulation of the Nash equilibrium problem and provide a number of valid inequalities to improve the quality of the relaxation. If a rank-1 solution to this SDP is found, then an exact Nash equilibrium can be recovered. We show that, for a strictly competitive game, our SDP is guaranteed to return a rank-1 solution. We propose two algorithms based on the iterative linearization of smooth nonconvex objective functions whose global minima by design coincide with rank-1 solutions. Empirically, we demonstrate that these algorithms often recover solutions of rank at most 2 and ɛ close to zero. Furthermore, we prove that if a rank-2 solution to our SDP is found, then a 5 11 -Nash equilibrium can be recovered for any game, or a 1 3 -Nash equilibrium for a symmetric game. We then show how our SDP approach can address two (NP-hard) problems of economic interest: finding the maximum welfare achievable under any Nash equilibrium, and testing whether there exists a Nash equilibrium where a particular set of strategies is not played. Finally, we show the connection between our SDP and the first level of the Lasserre/sum of squares hierarchy.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.0960},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {419-835},
  shortjournal = {INFORMS J. Comput.},
  title        = {Semidefinite programming and nash equilibria in bimatrix games},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new scatter search design for multiobjective combinatorial
optimization with an application to facility location. <em>IJOC</em>,
<em>33</em>(2), 419–835. (<a
href="https://doi.org/10.1287/ijoc.2020.0966">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scatter search (SS) is a well-established metaheuristic solution methodology that has seen most of its success in single-objective optimization. The literature includes a few examples of the SS methodology adapted to multiobjective optimization, almost all dealing with continuous, nonlinear problems. We describe an SS design that we believe has general applicability in the area of multiobjective combinatorial optimization and show its effectiveness by applying it to a facility location problem. Facility location consists of identifying the best locations for a set of facilities. The set of best locations may vary substantially according to the objective function employed to solve the optimization problem. We employ a facility location problem with multiple objectives (mo-FLP) to test our design ideas for a multiobjective optimization scatter search. We focus on the objective functions associated with three well-known location problems in the literature: the p -Median Problem (pMP), the Maximal Coverage Location Problem (MCLP), and the p -Center Problem (pCP). Our computational experiments are configured to show that the proposed SS design is capable of producing high-quality Pareto-front approximations. Summary of Contribution: Metaheuristic optimization is at the heart of the intersection between computer science and operations research. The INFORMS Journal on Computing has been fundamental in advancing the ideas behind metaheuristic methodologies. Fred Glover&#39;s Tabu Search–Part I was published more than 30 years ago in the first volume of the then ORSA Journal on Computing . This article, one of the most cited in the area of heuristic optimization, paved the way for many contributions to the methodology and practice of operations research. As a continuation of this stream of research, we describe a new scatter search design for multiobjective optimization. The design includes a short-term memory tabu search and a path relinking combination method. We show how the strategies and mechanisms within scatter search and tabu search can be combined to produce a highly effective approach to multiobjective optimization.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.0966},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {419-835},
  shortjournal = {INFORMS J. Comput.},
  title        = {A new scatter search design for multiobjective combinatorial optimization with an application to facility location},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A learning-based matheuristic for stochastic multicommodity
network design. <em>IJOC</em>, <em>33</em>(2), 419–835. (<a
href="https://doi.org/10.1287/ijoc.2020.0967">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a solution approach for the multicommodity capacitated fixed-charge network design problem with uncertain demand modeled as a two-stage stochastic program. The proposed learning-based matheuristic combines heuristic search techniques with mathematical programming. It provides a systematic approach to identifying structures of good-quality solutions by gradually considering scenarios and their influences on design decisions. Extensive computational experiments illustrate the efficiency of the proposed matheuristic in obtaining high-quality solutions with limited computational efforts.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.0967},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {419-835},
  shortjournal = {INFORMS J. Comput.},
  title        = {A learning-based matheuristic for stochastic multicommodity network design},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Selecting the best alternative based on its quantile.
<em>IJOC</em>, <em>33</em>(2), 419–835. (<a
href="https://doi.org/10.1287/ijoc.2020.0965">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A value-at-risk, or quantile, is widely used as an appropriate investment selection measure for risk-conscious decision makers. We present two quantile-based sequential procedures—with and without consideration of equivalency between alternatives—for selecting the best alternative from a set of simulated alternatives. These procedures asymptotically guarantee a user-defined target probability of correct selection within a prespecified indifference zone. Experimental results demonstrate the trade-off between the indifference-zone size and the number of simulation iterations needed to render a correct selection while satisfying a desired probability of correct selection.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.0965},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {419-835},
  shortjournal = {INFORMS J. Comput.},
  title        = {Selecting the best alternative based on its quantile},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reducing simulation input-model risk via input model
averaging. <em>IJOC</em>, <em>33</em>(2), 419–835. (<a
href="https://doi.org/10.1287/ijoc.2020.0994">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Input uncertainty is an aspect of simulation model risk that arises when the driving input distributions are derived or “fit” to real-world, historical data. Although there has been significant progress on quantifying and hedging against input uncertainty, there has been no direct attempt to reduce it via better input modeling. The meaning of “better” depends on the context and the objective: Our context is when (a) there are one or more families of parametric distributions that are plausible choices; (b) the real-world historical data are not expected to perfectly conform to any of them; and (c) our primary goal is to obtain higher-fidelity simulation output rather than to discover the “true” distribution. In this paper, we show that frequentist model averaging can be an effective way to create input models that better represent the true, unknown input distribution, thereby reducing model risk. Input model averaging builds from standard input modeling practice, is not computationally burdensome, requires no change in how the simulation is executed nor any follow-up experiments, and is available on the Comprehensive R Archive Network (CRAN). We provide theoretical and empirical support for our approach.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.0994},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {419-835},
  shortjournal = {INFORMS J. Comput.},
  title        = {Reducing simulation input-model risk via input model averaging},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Lagrangian duality for robust problems with decomposable
functions: The case of a robust inventory problem. <em>IJOC</em>,
<em>33</em>(2), 419–835. (<a
href="https://doi.org/10.1287/ijoc.2020.0978">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a class of min-max robust problems in which the functions that need to be “robustified” can be decomposed as the sum of arbitrary functions. This class of problems includes many practical problems, such as the lot-sizing problem under demand uncertainty. By considering a Lagrangian relaxation of the uncertainty set, we derive a tractable approximation, called the dual Lagrangian approach, that we relate with both the classical dualization approximation approach and an exact approach. Moreover, we show that the dual Lagrangian approach coincides with the affine decision rule approximation approach. The dual Lagrangian approach is applied to a lot-sizing problem, in which demands are assumed to be uncertain and to belong to the uncertainty set with a budget constraint for each time period. Using the insights provided by the interpretation of the Lagrangian multipliers as penalties in the proposed approach, two heuristic strategies, a new guided iterated local search heuristic, and a subgradient optimization method are designed to solve more complex lot-sizing problems in which additional practical aspects, such as setup costs, are considered. Computational results show the efficiency of the proposed heuristics that provide a good compromise between the quality of the robust solutions and the running time required in their computation. Summary of Contribution: The paper includes both theoretical and algorithmic contributions for a class of min-max robust optimization problems where the objective function includes the maximum of a sum of affine functions. From the theoretical point of view, a tractable Lagrangian dual model resulting from a relaxation of the well-known adversarial problem is proposed, providing a new perspective of well-known models, such as the affinely adjustable robust counterpart (AARC) and the dualization technique introduced by Bertsimas and Sim. These results are particularized to lot-sizing problems. From the algorithm point of view, efficient heuristic schemes—which exploit the information based on the interpretation of the Lagrangian multipliers to solve large size robust problems—are proposed, and their performance is evaluated through extensive computational results based on the lot-sizing problem. In particular, a guided iterated local search and a subgradient optimization method are proposed and compared against the dualization approach proposed by Bertsimas and Sim and with several heuristics based on the AARC approach, which include an iterated local search heuristic and a Benders decomposition approach. Computational results show the efficiency of the proposed heuristics, which provide a good compromise between the quality of the robust solutions and the running time.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.0978},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {419-835},
  shortjournal = {INFORMS J. Comput.},
  title        = {Lagrangian duality for robust problems with decomposable functions: The case of a robust inventory problem},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Conflict-driven heuristics for mixed integer programming.
<em>IJOC</em>, <em>33</em>(2), 419–835. (<a
href="https://doi.org/10.1287/ijoc.2020.0973">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two essential ingredients of modern mixed-integer programming solvers are diving heuristics, which simulate a partial depth-first search in a branch-and-bound tree, and conflict analysis, which learns valid constraints from infeasible subproblems. So far, these techniques have mostly been studied independently: primal heuristics for finding high-quality feasible solutions early during the solving process and conflict analysis for fathoming nodes of the search tree and improving the dual bound. In this paper, we pose the question of whether and how the orthogonal goals of proving infeasibility and generating improving solutions can be pursued in a combined manner such that a state-of-the-art solver can benefit. To do so, we integrate both concepts in two different ways. First, we develop a diving heuristic that simultaneously targets the generation of valid conflict constraints from the Farkas dual and the generation of improving solutions. We show that, in the primal, this is equivalent to the optimistic strategy of diving toward the best bound with respect to the objective function. Second, we use information derived from conflict analysis to enhance the search of a diving heuristic akin to classic coefficient diving. In a detailed computational study, both methods are evaluated on the basis of an implementation in the source-open-solver SCIP. The experimental results underline the potential of combining both diving heuristics and conflict analysis. Summary of Contribution. This original article concerns the advancement of exact general-purpose algorithms for solving one of the largest and most prominent problem classes in optimization, mixed-integer linear programs. It demonstrates how methods for conflict analysis that learn from infeasible subproblems can be combined successfully with diving heuristics that aim at finding primal solutions. For two newly designed diving heuristics, this paper features a thoroughly computational study regarding their impact on the overall performance of a state-of-the-art MIP solver.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.0973},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {419-835},
  shortjournal = {INFORMS J. Comput.},
  title        = {Conflict-driven heuristics for mixed integer programming},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exact multiple sequence alignment by synchronized decision
diagrams. <em>IJOC</em>, <em>33</em>(2), 419–835. (<a
href="https://doi.org/10.1287/ijoc.2019.0937">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops an exact solution algorithm for the multiple sequence alignment (MSA) problem. In the first step, we design a dynamic programming model and use it to construct a novel multivalued decision diagram (MDD) representation of all pairwise sequence alignments (PSA). PSA MDDs are then synchronized using side constraints to model the MSA problem as a mixed-integer program (MIP), for the first time, in polynomial space complexity. Two bound-based filtering procedures are developed to reduce the size of the MDDs, and the resulting MIP is solved using logic-based Benders decomposition. For a more effective algorithm, we develop a two-phase solution approach. In the first phase, we use optimistic filtering to quickly obtain a near-optimal bound, which we then use for exact filtering in the second phase to prove or obtain an optimal solution. Numerical results on benchmark instances show that our algorithm solves several instances to optimality for the first time, and, in case optimality cannot be proven, considerably improves upon a state-of-the-art heuristic MSA solver. Comparison with an existing state-of-the-art exact MSA algorithm shows that our approach is more time efficient and yields significantly smaller optimality gaps.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2019.0937},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {419-835},
  shortjournal = {INFORMS J. Comput.},
  title        = {Exact multiple sequence alignment by synchronized decision diagrams},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning to solve large-scale security-constrained unit
commitment problems. <em>IJOC</em>, <em>33</em>(2), 419–835. (<a
href="https://doi.org/10.1287/ijoc.2020.0976">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Security-constrained unit commitment (SCUC) is a fundamental problem in power systems and electricity markets. In practical settings, SCUC is repeatedly solved via mixed-integer linear programming (MIP), sometimes multiple times per day, with only minor changes in input data. In this work, we propose a number of machine learning techniques to effectively extract information from previously solved instances in order to significantly improve the computational performance of MIP solvers when solving similar instances in the future. Based on statistical data, we predict redundant constraints in the formulation, good initial feasible solutions, and affine subspaces where the optimal solution is likely to lie, leading to a significant reduction in problem size. Computational results on a diverse set of realistic and large-scale instances show that using the proposed techniques, SCUC can be solved on average 4.3 times faster with optimality guarantees and 10.2 times faster without optimality guarantees, with no observed reduction in solution quality. Out-of-distribution experiments provide evidence that the method is somewhat robust against data-set shift. Summary of Contribution. The paper describes a novel computational method, based on a combination of mixed-integer linear programming (MILP) and machine learning (ML), to solve a challenging and fundamental optimization problem in the energy sector. The method advances the state-of-the-art, not only for this particular problem, but also, more generally, in solving discrete optimization problems via ML. We expect that the techniques presented can be readily used by practitioners in the energy sector and adapted, by researchers in other fields, to other challenging operations research problems that are solved routinely.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.0976},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {419-835},
  shortjournal = {INFORMS J. Comput.},
  title        = {Learning to solve large-scale security-constrained unit commitment problems},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Scenario grouping and decomposition algorithms for
chance-constrained programs. <em>IJOC</em>, <em>33</em>(2), 419–835. (<a
href="https://doi.org/10.1287/ijoc.2020.0970">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A lower bound for a finite-scenario-based chance-constrained program is the quantile value corresponding to the sorted optimal objective values of scenario subproblems. This quantile bound can be improved by grouping subsets of scenarios at the expense of solving larger subproblems. The quality of the bound depends on how the scenarios are grouped. In this paper, we formulate a mixed-integer bilevel program that optimally groups scenarios to tighten the quantile bounds. For general chance-constrained programs, we propose a branch-and-cut algorithm to optimize the bilevel program, and for chance-constrained linear programs, a mixed-integer linear-programming reformulation is derived. We also propose several heuristics for grouping similar or dissimilar scenarios. Our computational results demonstrate that optimal grouping bounds are much tighter than heuristic bounds, resulting in smaller root-node gaps and better performance of scenario decomposition for solving chance-constrained 0-1 programs. Also, the optimal grouping bounds can be greatly strengthened using larger group size. Summary of Contribution: Chance-constrained programs are in general NP-hard but widely used in practice for lowering the risk of undesirable outcomes during decision making under uncertainty. Assuming finite scenarios of uncertain parameter, chance-constrained programs can be reformulated as mixed-integer linear programs with binary variables representing whether or not the constraints are satisfied in corresponding scenarios. A useful quantile bound for solving chance-constrained programs can be improved by grouping subsets of scenarios at the expense of solving larger subproblems. In this paper, we develop algorithms for optimally and heuristically grouping scenarios to tighten the quantile bounds. We aim to improve both the computation and solution quality of a variety of chance-constrained programs formulated for different Operations Research problems.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.0970},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {419-835},
  shortjournal = {INFORMS J. Comput.},
  title        = {Scenario grouping and decomposition algorithms for chance-constrained programs},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Breaking the rmax barrier: Enhanced approximation algorithms
for partial set multicover problem. <em>IJOC</em>, <em>33</em>(2),
419–835. (<a href="https://doi.org/10.1287/ijoc.2020.0975">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given an element set E of order n , a collection of subsets S ⊆ 2 E , a cost c S on each set S ∈ S , a covering requirement r e for each element e ∈ E , and an integer k , the goal of a minimum partial set multicover problem (MinPSMC) is to find a subcollection F ⊆ S to fully cover at least k elements such that the cost of F is as small as possible and element e is fully covered by F if it belongs to at least r e sets of F . This problem generalizes the minimum k -union problem (Min k U) and is believed not to admit a subpolynomial approximation ratio. In this paper, we present a ( 4 log ⁡ n H ( Δ ) In k + 2 ⁡ log n n ) -approximation algorithm for MinPSMC, in which Δ is the maximum size of a set in S . And when k = Ω ( n ) , we present a bicriteria algorithm fully covering at least ( 1 − ε 2 log n ) k elements with approximation ratio O ( 1 ε ( log n ) 2 H ( Δ ) ) , where 0 &lt; ε &lt; 1 is a fixed number. These results are obtained by studying the minimum density subcollection problem with (or without) cardinality constraint, which might be of interest by itself.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.0975},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {419-835},
  shortjournal = {INFORMS J. Comput.},
  title        = {Breaking the rmax barrier: Enhanced approximation algorithms for partial set multicover problem},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Monge properties, optimal greedy policies, and policy
improvement for the dynamic stochastic transportation problem.
<em>IJOC</em>, <em>33</em>(2), 419–835. (<a
href="https://doi.org/10.1287/ijoc.2020.0990">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a dynamic, stochastic extension to the transportation problem. For the deterministic problem, there are known necessary and sufficient conditions under which a greedy algorithm achieves the optimal solution. We define a distribution-free type of optimality and provide analogous necessary and sufficient conditions under which a greedy policy achieves this type of optimality in the dynamic, stochastic setting. These results are used to prove that a greedy algorithm is optimal when planning a type of air-traffic management initiative. We also provide weaker conditions under which it is possible to strengthen an existing policy. These results can be applied to the problem of matching passengers with drivers in an on-demand taxi service. They specify conditions under which a passenger and driver should not be left unassigned.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.0990},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {419-835},
  shortjournal = {INFORMS J. Comput.},
  title        = {Monge properties, optimal greedy policies, and policy improvement for the dynamic stochastic transportation problem},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multistage stochastic programming approach to the optimal
surveillance and control of the emerald ash borer in cities.
<em>IJOC</em>, <em>33</em>(2), 419–835. (<a
href="https://doi.org/10.1287/ijoc.2020.0963">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emerald ash borer (EAB), a wood-boring insect native to Asia and invading North America, has killed untold millions of high-value ash trees that shade streets, homes, and parks and caused significant economic damage in cities of the United States. Local actions to reduce damage include surveillance to find EAB and control to slow its spread. We present a multistage stochastic mixed-integer programming (M-SMIP) model for the optimization of surveillance, treatment, and removal of ash trees in cities. Decision-dependent uncertainty is modeled by representing surveillance decisions and the realizations of the uncertain infestation parameter contingent on surveillance as branches in the M-SMIP scenario tree. The objective is to allocate resources to surveillance and control over space and time to maximize public benefits. We develop a new cutting-plane algorithm to strengthen the M-SMIP formulation and facilitate an optimal solution. We calibrate and validate our model of ash dynamics using seven years of observational data and apply the optimization model to a possible infestation in Burnsville, Minnesota. Proposed cutting planes improve the solution time by an average of seven times over solving the original M-SMIP model without cutting planes. Our comparative analysis shows that the M-SMIP model outperforms six different heuristic approaches proposed for the management of EAB. Results from optimally solving our M-SMIP model imply that under a belief of infestation, it is critical to apply surveillance immediately to locate EAB and then prioritize treatment of minimally infested trees followed by removal of highly infested trees. Summary of Contributions: Emerald ash borer (EAB) is one of the most damaging invasive species ever to reach the United States, damaging millions of ash trees. Much of the economic impact of EAB occurs in cities, where high-value ash trees grow in abundance along streets and in yards and parks. This paper addresses the joint optimization of surveillance and control of the emerald ash borer invasion, which is a novel application for the INFORMS society because, to our knowledge, this specific problem of EAB management has not been published before in any OR/MS journals. We develop a new multi-stage stochastic mixed-integer programming (MSS-MIP) formulation, and we apply our model to surveillance and control of EAB in cities. Our MSS-MIP model aims to help city managers maximize the net benefits of their healthy ash trees by determining the optimal timing and target population for surveying, treating, and removing infested ash trees while taking into account the spatio-temporal stochastic growth of the EAB infestation. We develop a new cutting plane methodology motivated by our problem, which could also be applied to other stochastic MIPs. Our cutting plane approach provides significant computational benefit in solving the problem. Specifically, proposed cutting planes improve the solution time by an average of seven times over solving the original M-SMIP model without cutting planes. We calibrate and validate our model using seven years of ash infestation observations in forests near Toledo, Ohio. We then apply our model to an urban forest in Burnsville, Minnesota, that is threatened by EAB. Our results provide insights into the optimal timing and location of EAB surveillance and control strategies.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.0963},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {419-835},
  shortjournal = {INFORMS J. Comput.},
  title        = {A multistage stochastic programming approach to the optimal surveillance and control of the emerald ash borer in cities},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Corrigendum to “a bucket indexed formulation for
nonpreemptive single machine scheduling problems,” INFORMS journal on
computing 28(1): 14–30, 2016. <em>IJOC</em>, <em>33</em>(2), 419–835.
(<a href="https://doi.org/10.1287/ijoc.2020.0979">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This note corrects an error in our paper “N. Boland, R. Clement, and H. Waterer. A bucket indexed formulation for nonpreemptive single machine scheduling problems. INFORMS Journal on Computing 28(1):14–30, 2016.”},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2020.0979},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {419-835},
  shortjournal = {INFORMS J. Comput.},
  title        = {Corrigendum to “A bucket indexed formulation for nonpreemptive single machine scheduling problems,” INFORMS journal on computing 28(1): 14–30, 2016},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Editorial board. <em>IJOC</em>, <em>33</em>(1), C2. (<a
href="https://doi.org/10.1287/ijoc.2021.eb.v3301">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2021.eb.v3301},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {C2},
  shortjournal = {INFORMS J. Comput.},
  title        = {Editorial board},
  volume       = {33},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
