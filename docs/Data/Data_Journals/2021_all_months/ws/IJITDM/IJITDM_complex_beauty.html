<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IJITDM_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ijitdm---63">IJITDM - 63</h2>
<ul>
<li><details>
<summary>
(2021). ARIMA model estimation based on genetic algorithm for
COVID-19 mortality rates. <em>IJITDM</em>, <em>20</em>(6), 1775–1798.
(<a href="https://doi.org/10.1142/S0219622021500528">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a forecasting model for the mortality rates of COVID-19 in six of the top most affected countries depending on the hybrid Genetic Algorithm and Autoregressive Integrated Moving Average (GA-ARIMA). It was aimed to develop an advanced and reliable predicting model that provides future forecasts of possible confirmed cases and mortality rates (Total Deaths per 1 million Population of COVID-19) that could help the public health authorities to develop plans required to resolve the crisis of the pandemic threat in a timely and efficient manner. The study focused on predicting the mortality rates of COVID-19 because the mortality rate determines the prevalence of highly contagious diseases. The Genetic algorithm (GA) has the capability of improving the forecasting performance of the ARIMA model by optimizing the ARIMA model parameters. The findings of this study revealed the high prediction accuracy of the proposed (GA-ARIMA) model. Moreover, it has provided better and consistent predictions compared to the traditional ARIMA model and can be a reliable method in predicting expected death rates as well as confirmed cases of COVID-19. Hence, it was concluded that combining ARIMA with GA is further accurate than ARIMA alone and GA can be an alternative to find the parameters and model orders for the ARIMA model.},
  archive      = {J_IJITDM},
  author       = {Mohanad A. Deif and Ahmed A. A. Solyman and Rania E. Hammam},
  doi          = {10.1142/S0219622021500528},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {6},
  pages        = {1775-1798},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {ARIMA model estimation based on genetic algorithm for COVID-19 mortality rates},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploring industry benchmarks for continuous improvement and
investment decision-making. <em>IJITDM</em>, <em>20</em>(6), 1747–1774.
(<a href="https://doi.org/10.1142/S0219622021500498">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Measuring company efficiency is an important issue for both managers and investors. Efficiency measurement is always important because organizations are constantly striving to increase internal productivity. However, investors are more concerned about sustainability than many executives believe. Almost 75% of investment community respondents strongly believed that improvements in operational efficiency were often accompanied by progress in terms of sustainability. This study examined companies listed on the Taiwan 50 and Taiwan Mid-Cap 100 Indexes and measured and ranked their operational efficiencies, identifying representatives with high investment potential among these highly capitalized blue chip stocks from various industries. The results will provide managers with recommendations for improving operational efficiency through competitive mapping, as well as a list of the most attractive targets for investment.},
  archive      = {J_IJITDM},
  author       = {Tien-Chin Wang and Shu-Li Huang and Chien-Hui Lee},
  doi          = {10.1142/S0219622021500498},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {6},
  pages        = {1747-1774},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Exploring industry benchmarks for continuous improvement and investment decision-making},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Strategic supplier selection in payment industry: A
multi-criteria solution for insufficient and interrelated data sources.
<em>IJITDM</em>, <em>20</em>(6), 1711–1745. (<a
href="https://doi.org/10.1142/S0219622021500474">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our goal is to address the complicated problem of strategic supplier selection with interrelated and insufficient data. To achieve this goal, we proposed our Strategic Supplier Selection Methodology (SSSM). First, SSSM formulates the enterprise strategies and evaluation criteria. Then, we developed a novel method called Grey Principal Component Analysis-Data Envelopment Analysis (GPCA-DEA) to evaluate suppliers in SSSM. GPCA-DEA overcomes the major disadvantages and limitations of former methodologies (e.g., DEA) while dealing with insufficient and interrelated data. Finally, SSSM applies Multiple Attribute Decision-Making (MADM) methods to select suppliers based on the ranking score. The application of SSSM is illustrated in the payment industry to select Payment Initiation Service Providers (PISP). For the first time, we considered the payment industry-specific criteria in compliance with the latest regulation (PSD2). The Spearman rank correlation statistical test showed that our method (GPCA-DEA used in SSSM) yields more reliable results than a former version of DEA.},
  archive      = {J_IJITDM},
  author       = {Siavash Hekmat and Maghsoud Amiri and Golshan Madraki},
  doi          = {10.1142/S0219622021500474},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {6},
  pages        = {1711-1745},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Strategic supplier selection in payment industry: A multi-criteria solution for insufficient and interrelated data sources},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hybrid methodology for prioritizing of store plan
alternatives produced with rule-based design. <em>IJITDM</em>,
<em>20</em>(6), 1685–1709. (<a
href="https://doi.org/10.1142/S0219622021500486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread use of computers, in the design world, rule-based design methods, which can work in harmony with computer logic and can be easily adapted to the computer environment, have come to the fore. It is possible to analyze the logic of a design made with the rule-based design method. It is even possible to change the design which is placed on the rule base by removing the rules, in the computer environment, or creating new designs with the same design logic. In this paper, a new hybrid model is proposed based on Interval Type-2 Fuzzy Analytic Network Process (IT2 FANP) and Interval Type-2 Fuzzy TOPSIS (IT2 Fuzzy TOPSIS) for the evaluation of store plan alternatives produced with rule-based design method. The IT2 FANP method is used to determine the weight of criteria determined by experts in the selection of store plan alternatives. Then, the IT2 Fuzzy TOPSIS method is used to obtain the ranking of alternatives with Interval Type-2 trapezoidal fuzzy numbers. The originality of the paper comes from the first-time usage of a hybrid approach based on IT2 FANP and IT2 Fuzzy TOPSIS methodology in the prioritizing of store plan alternatives produced with rule-based design method.},
  archive      = {J_IJITDM},
  author       = {Yavuz Ozdemir and Sahika Ozdemir and Kemal Gokhan Nalbant},
  doi          = {10.1142/S0219622021500486},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {6},
  pages        = {1685-1709},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {A hybrid methodology for prioritizing of store plan alternatives produced with rule-based design},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Online simulation optimization using neutrosophic
cross-efficiency DEA and box–behnken experimental design (a case study
on the automotive paint shop). <em>IJITDM</em>, <em>20</em>(6),
1657–1684. (<a href="https://doi.org/10.1142/S0219622021500462">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Paint shops are considered as bottlenecks in many automobile companies. As all processes in the paint shop are involved with chemical materials, time is really crucial in the production process, so offering instant remedial actions is crucial. This paper optimizes an online simulation (OS) model, using Discrete-Event Simulation (DES), applied to a paint shop in the automotive industry. To this aim, an integrated Box–Behnken design (BBD) and cross-efficiency data envelopment analysis (DEA) under a neutrosophic environment have been implemented. The former has generated cost-effective scenarios with the minimum number of experimental design, and the latter has provided the efficiency of each scenario enabling to obtain a unique weight for each decision-making unit (DMU) using aggressive and benevolent models as well as a general representation of the human perception toward risks arising from uncertain information, leading to determine the optimal scenario. The proposed approach has been implemented in an automotive industrial plant in Iran, and the results have shown that this approach, compared with previous studies, is a practical way for online monitoring and optimizing the paint shop.},
  archive      = {J_IJITDM},
  author       = {Nafiseh Monazzam and Alireza Alinezhad and Hossein Malek},
  doi          = {10.1142/S0219622021500462},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {6},
  pages        = {1657-1684},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Online simulation optimization using neutrosophic cross-efficiency DEA and Box–Behnken experimental design (A case study on the automotive paint shop)},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Operational indicators to manage the replacement of
electromechanical equipment in wastewater treatment facilities.
<em>IJITDM</em>, <em>20</em>(6), 1637–1656. (<a
href="https://doi.org/10.1142/S0219622021500437">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal management is usually at the top of the concerns in the context of water infrastructures. In the specific domain of wastewater treatment plants (WWTPs), European Directive 91/271 established the need of implementing a biological treatment of wastewater leading to an intensive construction of WWTPs in several European countries, which now present important problems of maintenance. These facilities are composed of different types of assets, which should be managed efficiently in order to optimize the performance of the processes as well as the maintenance and replacement costs of the equipment. In fact, the deterioration of these assets increases the operational risk and endangers the continuity of the service of these WWTPs. In this paper, the authors combine multicriteria methodologies (MCDM) and economic aspects of the equipment to define an appropriate technical–economical replacement policy. With the aim of developing a reference procedure in the wastewater sector, an approach has been made to blower pump, which is an equipment widely used in WWTPs to provide a continuous air flow to the reactor facilitating the elimination of organic matter and the nutrients contained in the wastewater. The proposal integrates aspects such as acquisition costs and corrective maintenance, interest rate, and amortization based on the condition of the equipment.},
  archive      = {J_IJITDM},
  author       = {Vicent Hernández-Chover and Lledó Castellet-Viciano and Francesc Hernández-Sancho},
  doi          = {10.1142/S0219622021500437},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {6},
  pages        = {1637-1656},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Operational indicators to manage the replacement of electromechanical equipment in wastewater treatment facilities},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hybrid validity index to determine k parameter value of
k-means algorithm for time series clustering. <em>IJITDM</em>,
<em>20</em>(6), 1615–1636. (<a
href="https://doi.org/10.1142/S0219622021500449">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series is a set of sequential data point in time order. The sizes and dimensions of the time series datasets are increasing day by day. Clustering is an unsupervised data mining technique that groups objects based on their similarities. It is used to analyze various datasets, such as finance, climate, and bioinformatics datasets. k -means is one of the most used clustering algorithms. However, it is challenging to determine the value of k parameter, which is the number of clusters. One of the most used methods to determine the number of clusters (such as k ) is cluster validity indexes. Several internal and external validity indexes are used to find suitable cluster numbers based on characteristics of datasets. In this study, we propose a hybrid validity index to determine the value of k parameter of k -means algorithm. The proposed hybrid validity index comprises four internal validity indexes, such as Dunn, Silhouette, C index, and Davies–Bouldin indexes. The proposed method was applied to nine real-life finance and benchmarks time series datasets. The financial dataset was obtained from Yahoo Finance, consisting of daily closing data of stocks. The other eight benchmark datasets were obtained from UCR time series classification archive. Experimental results showed that the proposed hybrid validity index is promising for finding the suitable number of clusters with respect to the other indexes for clustering time-series datasets.},
  archive      = {J_IJITDM},
  author       = {Fatma Ozge Ozkok and Mete Celik},
  doi          = {10.1142/S0219622021500449},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {6},
  pages        = {1615-1636},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {A hybrid validity index to determine k parameter value of k-means algorithm for time series clustering},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A grey wolf optimization-based method for segmentation and
evaluation of scaling in reinforced concrete bridges. <em>IJITDM</em>,
<em>20</em>(6), 1561–1614. (<a
href="https://doi.org/10.1142/S0219622021500425">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bridges are prone to severe deterioration agents which promote their degradation over the course of their lifetime. Furthermore, maintenance budgets are being trimmed. This state of circumstances entails the development of a computer vision-based method for the condition assessment of bridge elements in an attempt to circumvent the drawbacks of visual inspection-based models. Scaling is progressive local flaking or loss in the surface portion of concrete that affects the functional and structural integrity of reinforced concrete bridges. As such, this research study proposes a self-adaptive three-tier method for the automated detection and assessment of scaling severity levels in reinforced concrete bridges. The first tier relies on the integration of cross entropy function and grey wolf optimization (GWO) algorithm for the segmentation of scaling pixels. The second tier is designated for the autonomous interpretation of scaling area. In this model, a hybrid feature extraction algorithm is proposed based on the fusion of singular value decomposition and discrete wavelet transform for the efficient and robust extraction of the most dominant features in scaling images. Then an integration of Elman neural network and GWO algorithm is proposed for the sake of improving the prediction accuracies of scaling area though optimization of both structure and parameters of Elman neural network. The third tier aims at establishing a unified scaling severity index to assess the extent of severities of scaling according to its area and depth. The developed method is validated through multi-layered comparative analysis that involved performance evaluation comparisons, statistical comparisons and box plots. Results demonstrated that the developed scaling detection model significantly outperformed a set of widely-utilized classical segmentation models achieving mean squared error, mean absolute error, peak signal to noise ratio and cross entropy of 0.175, 0.407, 55.754 and 26011.019, respectively. With regards to the developed scaling evaluation model, it accomplished remarkable better and more robust performance that other meta-heuristic-based Elman neural network models and conventional prediction models. In this context, it obtained mean absolute percentage error, root-mean squared error and mean absolute error 1.513%, 29.836 and 12.066, respectively, as per split validation. It is anticipated that the developed integrated computer vision-based method could serve as the basis of automated, reliable and cost-effective inspection platform of reinforced concrete bridges which can assist departments of transportation in taking effective preventive maintenance and rehabilitation actions.},
  archive      = {J_IJITDM},
  author       = {Eslam Mohammed Abdelkader and Osama Moselhi and Mohamed Marzouk and Tarek Zayed},
  doi          = {10.1142/S0219622021500425},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {6},
  pages        = {1561-1614},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {A grey wolf optimization-based method for segmentation and evaluation of scaling in reinforced concrete bridges},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Editor’s introduction. <em>IJITDM</em>, <em>20</em>(6),
1557–1560. (<a href="https://doi.org/10.1142/S0219622021030061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJITDM},
  author       = {Yong Shi},
  doi          = {10.1142/S0219622021030061},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {6},
  pages        = {1557-1560},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Editor’s introduction},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A neuro-fuzzy hybrid framework for augmenting resources of
mobile device. <em>IJITDM</em>, <em>20</em>(5), 1519–1555. (<a
href="https://doi.org/10.1142/S0219622021500413">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the drastic exploitation of mobile devices and mobile apps in the day-to-day activities of people, the enhancement in hardware and software tools for mobile devices is also rising rapidly to cater to the requirements of mobile users. However, the progress of resource-intensive mobile applications is still inhibited by the limited battery power, restricted memory, and scarce resources of mobile devices. By employing mobile cloud computing, mobile edge computing, and fog computing, many researchers are providing their frameworks and offloading algorithms to augment the resources of mobile devices. In the existing solutions, offloading resource-intensive tasks is adopted only for specific scenarios and also not supporting the flexible exploitation of IoT-based smart mobile applications. So, a novel neuro-fuzzy modeling framework is proposed to augment the inadequate resources of a mobile device by offloading the resource-intensive tasks to external entities, and also a Bat optimization algorithm is exploited to schedule as many tasks as possible to the augmentation entities thereby improving the total execution time of all tasks and minimizing the resource exploitation of the mobile device. In this research work, external augmentation entities like distant cloud, edge cloud, and microcontroller devices are providing Resource augmentation as a Service (RaaS) to mobile devices. An IoT-based smart transport mobile app is implemented based on the proposed framework which depicts a significant reduction in execution time, energy consumption, bandwidth utilization, and average delay. Performance analysis depicts that the neuro-fuzzy hybrid model with Bat optimization provides a significant improvement compared with proximate computing and web service frameworks on the Quality of Service (QoS) parameters namely energy consumption, execution time, bandwidth utilization, and latency. Thus, the proposed framework exhibits a feasible solution of RaaS to resource-constrained mobile devices by exploiting edge computing.},
  archive      = {J_IJITDM},
  author       = {S. Anitha and T. Padma},
  doi          = {10.1142/S0219622021500413},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {5},
  pages        = {1519-1555},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {A neuro-fuzzy hybrid framework for augmenting resources of mobile device},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adjusting trade-offs in multi-criteria decision-making
problems. <em>IJITDM</em>, <em>20</em>(5), 1499–1517. (<a
href="https://doi.org/10.1142/S0219622021500401">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-criteria decision-making (MCDM) methods, allowing trade-offs between the decision criteria may result in inappropriate conclusions. Allowing trade-offs implies that the weaknesses of an alternative in some criteria may be compensated by its strengths in other criteria. While, with some problems, there are no concerns with regard to allowing a full trade-off, in other cases, such a trade-off may not follow the actual decision-making problem. This paper proposes a new approach based on defining an upper and lower expectation level for each decision-making criterion. Indeed, the proposed approach is a framework by which the requirements of a decision-maker are considered in the criteria involved in MCDM problems. That distinction generates two primary and secondary performance matrices. The primary matrix includes the values of the alternatives with respect to the individual criterion up to the upper expectation levels of the decision-maker, while the secondary matrix, which is defined by the amounts above the upper levels and below the lower levels of the decision-maker’s expectations, contains each alternative in all the criteria and, to some extent, can exceed the upper levels of the decision-maker’s expectations. The final result of each alternative is calculated by adding its outcome in the two matrices. The results of a numerical example involving cellphone selection show how controlling the trade-offs could affect the results.},
  archive      = {J_IJITDM},
  author       = {Siamak Kheybari},
  doi          = {10.1142/S0219622021500401},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {5},
  pages        = {1499-1517},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Adjusting trade-offs in multi-criteria decision-making problems},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An intuitionistic fuzzy multi-objective goal programming
approach to portfolio selection. <em>IJITDM</em>, <em>20</em>(5),
1477–1497. (<a href="https://doi.org/10.1142/S0219622021500395">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Portfolio selection can be regarded as a type of multi-objective decision problem. However, traditional solution methods rarely discussed the decision maker’s nonsatisfaction and hesitation degrees with regard to multiple objectives and they require many extra binary variables, which lead to tedious computational burden. Based on the above, the aim of this paper is to develop a new and unified intuitionistic fuzzy multi-objective linear programming (IFMOLP) model for such portfolio selection problems. The nonmembership functions are constructed by the pessimistic, optimistic, and mixed approaches so as to perfect the traditional intuitionistic fizzy (IF) inequalities and IF theory. The decision maker’s hesitation degrees with regard to multiple objectives are represented by using IF inequalities, and the new IFMOLP model based on IF inequalities is proposed. The IFMOLP problems are solved by the S-shaped membership functions without extra binary variables required by the piecewise-linear method. Finally, the portfolio selection model under IF environments based on IFMOLP is established, and a real example is analyzed to demonstrate its validity and superiority. The developed unified IFMOLP model and method can not only effectively solve multi-objective decision problems with nonsatisfaction and hesitation degrees but also remarkably reduce the complexity of the nondeterministic polynomial-hard problems.},
  archive      = {J_IJITDM},
  author       = {Gao-Feng Yu and Deng-Feng Li and De-Cui Liang and Guang-Xu Li},
  doi          = {10.1142/S0219622021500395},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {5},
  pages        = {1477-1497},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {An intuitionistic fuzzy multi-objective goal programming approach to portfolio selection},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving logistics of the public services in smart cities
using a novel clustering method. <em>IJITDM</em>, <em>20</em>(5),
1447–1475. (<a href="https://doi.org/10.1142/S0219622021500383">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart City public services need detailed and relevant public information to increase their efficiency. To have relevant information, collecting and processing the data about its previous uses are crucial. Clustering is one of the most powerful, yet computationally demanding, tools that can be used to process such information. Since public services data are vast, but usually not accurate, the objects clustered are considered as uncertain. In this paper, we propose a novel clustering method for uncertain objects called Improved Bisector Pruning (IBP), which uses bisectors to reduce the number of computations. We combine IBP with a modified segmentation of a data set area (SDSA) method that enables the parallelization of the clustering process. In the experiments, we show that IBP-SDSA is superior in performance to the most used clustering method UK-means combined with Voronoi or MinMax pruning, regardless of the problem size. We applied IBP-SDSA on clustering the public services data in the city of Osijek and show that the acquired data can be used to improve public services logistics.},
  archive      = {J_IJITDM},
  author       = {Ivica Lukić and Zdravko Krpić and Mirko Köhler and Tomislav Galba},
  doi          = {10.1142/S0219622021500383},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {5},
  pages        = {1447-1475},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Improving logistics of the public services in smart cities using a novel clustering method},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multidimensional benchmarking framework for AQMs of network
congestion control based on AHP and group-TOPSIS. <em>IJITDM</em>,
<em>20</em>(5), 1409–1446. (<a
href="https://doi.org/10.1142/S0219622021500127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to propose a grouping framework for benchmarking the active queue management (AQM) methods of network congestion control based on multicriteria decision-making (MCDM) techniques to assist developers of AQM methods in selecting the best AQM method. Given the current rapid development of the AQM techniques, determining which of these algorithms is better than the other is difficult because each algorithm performs better in a specific metric(s). Current benchmarking studies benchmark the AQM methods from a single incomplete prospective. In each proposed AQM method, the benchmarking was achieved with reference to some evaluation measures that are relatively close to the desired goal being followed during the development of the AQM methods. Furthermore, the benchmarking frameworks of AQM methods are complicated and challenging because of the following reasons: (1) the technical details of the AQM methods are adapted and the input parameters are selected according to the sensitivity of the AQM methods; and (2) a framework is developed and designed for simulating AQM methods, the simulated network and the collected results. For this purpose, a set of criteria for AQM comparison are determined. These criteria are performance, processing overhead and configuration. The benchmarking framework is developed based on the crossover of three groups of multi-evaluation criteria and several AQM methods as a proof of concept. The AQM families that are implemented and utilized in experiments to generate the data that are used as a proof of concept of our proposed framework are the parameter-based (pars) and fuzzy-based AQM methods. Accordingly, constructing the decision matrix (DM) that will be used to generate the final results is necessary. Subsequently, the underlying AQM methods are benchmarked and ranked using MCDM techniques, namely, integrated analytical hierarchy process (AHP) and technique for order of preference by similarity to ideal solution (TOPSIS). The validation was performed objectively. The mean ± standard deviation was computed to ensure that the AQM methods ranking undergo systematic ranking. Results illustrate that (1) the integration of AHP and TOPSIS solves the AQM method benchmarking problems; (2) results of the individual TOPSIS context clearly show variances among the ranking results of the six experts; (3) the ranks of the AQM methods obtained from internal and external TOPSIS group decision-making are nearly similar, with random early detection method being ranked as the best one; and (4) in the objective validation, significant differences were found between the groups’ scores, thereby indicating that the ranking results of internal and external TOPSIS group decision-making were valid.},
  archive      = {J_IJITDM},
  author       = {Maimuna Khatari and A. A. Zaidan and B. B. Zaidan and O. S. Albahri and M. A. Alsalem and A. S. Albahri},
  doi          = {10.1142/S0219622021500127},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {5},
  pages        = {1409-1446},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Multidimensional benchmarking framework for AQMs of network congestion control based on AHP and group-TOPSIS},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A computer assisted decision support system for education
planning. <em>IJITDM</em>, <em>20</em>(5), 1383–1407. (<a
href="https://doi.org/10.1142/S021962202150036X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advances in technology are eliminating the demand for certain occupations and creating new opportunities. Thus, the universities, teachers, and students have to collaboratively work together to restructure their departments, course offerings, and course contents. Failure to realize the aforementioned initiatives may lead to a loss of quality and competitiveness. This study proposes a decision support system capable of maintaining the quality and competitiveness of the departments and the course offerings. The proposed system consists of three stages. The first stage is the data collection stage. At this stage, data are collected from the internet using web scraping methods. In the second stage, the collected data are turned into meaningful and processable information by natural language processing methods. In the third stage, the alternatives are ranked using multi-criteria decision-making methods. The proposed decision support system provides useful information to several educational stakeholders. First, universities are informed on which departments to create or close as well as the relevant course offerings. Second, information are provided to the teachers to create new courses or shape the course contents. Finally, students are better informed on how to go about choosing the universities, departments, courses, or career paths to pursue. The applicability and reliability of the proposed decision support system were experimentally proven through the use of computer engineering-related job postings and course contents of the universities in Turkey.},
  archive      = {J_IJITDM},
  author       = {Yigit Alisan and Faruk Serin},
  doi          = {10.1142/S021962202150036X},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {5},
  pages        = {1383-1407},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {A computer assisted decision support system for education planning},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Discovering traffic anomaly propagation in urban space using
enhanced traffic change peaks. <em>IJITDM</em>, <em>20</em>(5),
1363–1382. (<a href="https://doi.org/10.1142/S0219622021410017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discovering traffic anomaly propagation enables a thorough understanding of traffic anomalies and dynamics. Existing methods, such as Outlier-Tree, are not accurate to find out the trend of abnormal traffic for two reasons. First, they discover the propagation pattern based on the detected traffic anomalies. The imperfection of the detection method itself may introduce false anomalies and miss the real anomaly. Second, they develop a propagation tree of anomalies by searching continuous spatial and temporal outlier neighborhoods rather than considering from a global perspective, and thus cannot form a complete propagation tree if a spatial or temporal gap exists. In this paper, we propose a novel discovering traffic anomaly propagation method using the mesh data and enhanced traffic change peaks (en-TCP) to visualize the change of traffic anomalies (e.g., an area where vehicles are gathering or evacuating) and thus accurately capture traffic anomaly propagation. Inspired by image processing techniques, the GPS trajectory dataset in each time bin can be converted to one grid traffic image and be stored in the grid density matrix, in which the grid cell corresponds to the pixel and the density of grid cells corresponds to the Gray level ( 0 ∼ 2 5 5 ) of pixels. An enhanced adaptive filter is developed to generate traffic change graph sequences from grid traffic images in consecutive periods, and clustering en-TCP in a continuous period is to discover the propagation of traffic anomalies. The accuracy and effectiveness of the proposed method have been demonstrated using a real-world GPS trajectory dataset.},
  archive      = {J_IJITDM},
  author       = {Guang-Li Huang and Tuba Kocaturk and Chi-Hung Chi},
  doi          = {10.1142/S0219622021410017},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {5},
  pages        = {1363-1382},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Discovering traffic anomaly propagation in urban space using enhanced traffic change peaks},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploring the success factors of security token offerings:
An empirical approach. <em>IJITDM</em>, <em>20</em>(5), 1339–1362. (<a
href="https://doi.org/10.1142/S0219622021500358">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Initial coin offerings (ICOs) have been established as an innovative capital-raising method. Nevertheless, numerous cases of ICO fraud are having a negative impact on investors. In particular, the lack of legal certainty (e.g., creditor protection) and the lack of direct participation in a company’s success (e.g., profit distribution) have led to an increasing number of security token offerings (STOs). These offer investors a degree of legal certainty and direct participation in company profits. However, to date, little scientifically-based knowledge exists regarding the factors that influence the funding success of an STO. We address this research gap by first identifying possible success factors for funding and then systematically analyzing 38 STOs that have already been carried out in order to determine the influence of those factors. Our analysis indicates that high-quality prototypes and high-quality teams are major drivers of STO funding success. Based on these results, we discuss the implications for science and practice, outline the limitations of our work, and identify further research needs.},
  archive      = {J_IJITDM},
  author       = {Jan Heinrich Beinke and Kai Rohde and Fabian Pohl and Frank Teuteberg},
  doi          = {10.1142/S0219622021500358},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {5},
  pages        = {1339-1362},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Exploring the success factors of security token offerings: An empirical approach},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Editor’s introduction. <em>IJITDM</em>, <em>20</em>(5),
1335–1337. (<a href="https://doi.org/10.1142/S021962202103005X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJITDM},
  author       = {Yong Shi},
  doi          = {10.1142/S021962202103005X},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {5},
  pages        = {1335-1337},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Editor’s introduction},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards automation of short-term financial distress
detection: A real-world case study. <em>IJITDM</em>, <em>20</em>(4),
1299–1333. (<a href="https://doi.org/10.1142/S0219622021500334">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The bankruptcy prediction research domain continues to evolve with the main aim of developing a model suitable for real-world application in order to detect early stages of financial distress of a company. The recent developments in computing, combined with the potential applications of big data technologies and artificial intelligence solutions have already made possible the integration of timely and recent information about business activities in order to monitor the financial health of companies. Therefore, this paper focuses on the predictions made a few months prior to the potential default of a company with the aim of identifying the determinants that signal about the insolvency. The experiments include in-depth analysis of model performances using different dataset configurations.},
  archive      = {J_IJITDM},
  author       = {Kristina Sutiene and Kestutis Luksys and Kristina Kundeliene},
  doi          = {10.1142/S0219622021500334},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {4},
  pages        = {1299-1333},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Towards automation of short-term financial distress detection: A real-world case study},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimization assisted convolutional neural network for
sentiment analysis with weighted holoentropy-based features.
<em>IJITDM</em>, <em>20</em>(4), 1261–1297. (<a
href="https://doi.org/10.1142/S0219622021500292">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analyzing and gathering the people’s reactions on product trading, public services, etc. are crucial. Sentiment analysis (also termed as opinion mining) is a usual dialogue preparing act that plans on discovering the sentiments after opinions in texts on changing subjects. This research work adopts a novel sentiment analysis approach that comprises six phases like (i) Pre-processing, (ii) Keyword extraction and its sentiment categorization, (iii) Semantic word extraction, (iv) Semantic similarity checking, (v) Feature extraction, and (vi) Classification. Accordingly, the Mongodb documented tweets initially underwent pre-processing with stop word removal, stemming, and blank space removal. Regarding the extracted keywords, the existing semantic words are derived after categorizing the sentiment of keywords. Additionally, the semantic similarity score is evaluated along with their keywords. The subsequent step is feature extraction, where the Holoentropy features such as cross Holoentropy and joint Holoentropy are formulated. Along with this, the extraction of weighted holoentropy features is the major work, where weight is multiplied with the holoentropy features. Moreover, in order to enhance the performance of classification results, the constant term utilized in evaluating the weight function is optimized. For this optimal tuning, a new, improved algorithm termed as Self Adaptive Moth Flame Optimization (SA-MFO) is introduced, which is the adaptive version of MFO algorithm. For classification, this paper aims to use the Deep Convolutional Neural network (DCNN), where the batch size is fine-tuned using the same SA-MFO algorithm. Finally, the performance of the proposed work is compared over other conventional models with respect to different performance measures.},
  archive      = {J_IJITDM},
  author       = {Hema Krishnan and M. Sudheep Elayidom and T. Santhanakrishnan},
  doi          = {10.1142/S0219622021500292},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {4},
  pages        = {1261-1297},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Optimization assisted convolutional neural network for sentiment analysis with weighted holoentropy-based features},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Risk assessment of logistics enterprises using FMEA under
free double hierarchy hesitant fuzzy linguistic environments.
<em>IJITDM</em>, <em>20</em>(4), 1221–1259. (<a
href="https://doi.org/10.1142/S0219622021500218">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Failure Mode and Effects Analysis (FMEA) is an effective tool for prioritization of the failures by identifying and eliminating potential risks, free double hierarchy hesitant fuzzy linguistic term set (FDHHFLTS) can describe the hesitation more accurately and reasonably by adding the free second hierarchy hesitant fuzzy linguistic terms, and multiattribute decision-making (MADM) methods have advantages in ranking and selecting different alternatives. By considering the advantages of MADM methods and FMEA model, in this paper, we propose a novel model to evaluate the risk failure modes (FMs) under FDHHFLTS context. First, an extended Complex Proportional Assessment (COPRAS) method is proposed to address the risk assessment problems. The proposed risk assessment model is utilized to assess and rank the FMs to address the limitations of the traditional FMEA. Second, a weight determination model is constructed based on the Kemeny Median (KEM) method and Stepwise Weight Assessment Ratio Analysis (SWARA) method, which can make the weight more practical and effective under the situation of completely unknown weights. Finally, the proposed model is used to the case of logistics enterprises’ risk assessment. The application of the case shows the feasibility of the proposed model, and the comparisons with some existing methods illustrate the advantages of the proposed risk assessment model.},
  archive      = {J_IJITDM},
  author       = {Mengjiao Shen and Peide Liu},
  doi          = {10.1142/S0219622021500218},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {4},
  pages        = {1221-1259},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Risk assessment of logistics enterprises using FMEA under free double hierarchy hesitant fuzzy linguistic environments},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An ensemble clusterer framework based on valid and diverse
basic small clusters. <em>IJITDM</em>, <em>20</em>(4), 1189–1219. (<a
href="https://doi.org/10.1142/S0219622021500309">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering ensemble is a new problem where it is aimed to extract a clustering out of a pool of base clusterings. The pool of base clusterings is sometimes referred to as ensemble. An ensemble is to be considered to be a suitable one, if its members are diverse and any of them has a minimum quality. The method that maps an ensemble into an output partition (called also as consensus partition) is named consensus function. The consensus function should find a consensus partition that all of the ensemble members agree on it as much as possible. In this paper, a novel clustering ensemble framework that guarantees generation of a pool of the base clusterings with the both conditions (diversity among ensemble members and high-quality members) is introduced. According to its limitations, a novel consensus function is also introduced. We experimentally show that the proposed clustering ensemble framework is scalable, efficient and general. Using different base clustering algorithms, we show that our improved base clustering algorithm is better. Also, among different consensus functions, we show the effectiveness of our consensus function. Finally, comparing with the state of the art, we find that the clustering ensemble framework is comparable or even better in terms of scalability and efficacy.},
  archive      = {J_IJITDM},
  author       = {Tao Sun and Saeed Mashdour and Mohammad Reza Mahmoudi},
  doi          = {10.1142/S0219622021500309},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {4},
  pages        = {1189-1219},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {An ensemble clusterer framework based on valid and diverse basic small clusters},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Composite techniques of structural equation modeling and
analytic hierarchy process for information technology vendor selection.
<em>IJITDM</em>, <em>20</em>(4), 1153–1187. (<a
href="https://doi.org/10.1142/S0219622021500346">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper had developed an effective information technology (IT) vendor selection model for banking &amp; financial services industries (BFSI). For any business, profitability and growth depends on the right vendor selection in their purchase process. This paper identifies ten most influencing and important criteria with 43 sub-criteria to comprehend the vendor selection process. Furthermore, the authors developed a vendor selection score model using Structural Equation Modelling (SEM) and Analytic Hierarchy Process (AHP). This article intends to inform practice and conclude with practical recommendations to BFSI for vendor selection. The proposed composite technique identified the most eligible vendor to meet up with the buyer’s strategies. This article suggests the most desirable vendor for the required benefit. Vendor 1 (Silverlake) with a score of 44% promised to be the most recommended one that also performed consistently in the sensitivity test.},
  archive      = {J_IJITDM},
  author       = {Dhanapal Durai Dominic Panneer Selvam and Sarit Maitra and Parthiban P and Abdul Zubar Hameed},
  doi          = {10.1142/S0219622021500346},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {4},
  pages        = {1153-1187},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Composite techniques of structural equation modeling and analytic hierarchy process for information technology vendor selection},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evaluating sustainable conceptual designs using an AHP-based
ELECTRE i method. <em>IJITDM</em>, <em>20</em>(4), 1121–1152. (<a
href="https://doi.org/10.1142/S0219622021500280">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evaluating sustainable conceptual designs is a crucial part of the development of new products in various sectors because it contributes to the survival and prosperity of companies. Such designs must be compatible with a product’s functional requirements and be sustainable in economic, environmental, and social terms. Various criteria, some qualitative and others quantitative, are considered when evaluating sustainable conceptual designs; some criteria may also have sub-criteria, and these criteria and sub-criteria may differ in importance. How to effectively evaluate various criteria and sub-criteria and weight them are the major research problem. This study developed an analytic hierarchy process (AHP)-based ELECTRE I method to resolve the evaluation problem; the method entails a two-level hierarchical structure to depict the relationships between the major criteria and sub-criteria and their corresponding weights, with weights obtained through an AHP. Furthermore, an extension based on the addition of net concordance value and net adjusted discordance value is proposed for ranking alternative designs; this extension yields more distinguishable results than the method of [Nijkamp and Van Delft Multi-Criteria Analysis and Regional Decision-Making , Vol. 8 (Springer Science &amp; Business Media, 1977)], and the proposed extension in the ELECTRE I method captures more information in the modified summation matrix when aggregating values in the concordance matrix and the modified discordance matrix, representing an advantage over the method of [Zhang et al . Virtual network embedding using node multiple metrics based on simplified ELECTRE method, IEEE Access 6 (2018) 37314–37327]. In addition, to demonstrate the feasibility of the proposed method, the example of the evaluation and selection of sustainable conceptual designs in the furniture manufacturing industry is presented. Finally, a numerical comparison is made to show the advantages of the proposed method.},
  archive      = {J_IJITDM},
  author       = {Thi Bich Ha Nghiem and Ta-Chung Chu},
  doi          = {10.1142/S0219622021500280},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {4},
  pages        = {1121-1152},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Evaluating sustainable conceptual designs using an AHP-based ELECTRE i method},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A framework for time-cost-quality optimization in project
management problems using an exploratory grid concept in the
multi-objective simulated-annealing. <em>IJITDM</em>, <em>20</em>(4),
1095–1120. (<a href="https://doi.org/10.1142/S0219622021500322">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time, cost, and quality are the three indispensable factors for the realization and success of a project. In this context, we propose a framework composed of a multi-objective approach and multi-criteria decision-making methods (MCDM) to solve time-cost-quality trade-off optimization problems. A multi-objective Simulated Annealing (MOSA) algorithm is used to compute an approximation to the Pareto optimal set. The concept of the exploratory grid is introduced in the MOSA to improve its performance. MCDM are used to assist the decision-making process. The Shannon entropy and AHP methods assign weights to criteria. The first methodology is for the inexperienced decision-makers, and the second concedes a personal and flexible weighting of the criteria weights, based on the project manager’s assessment. The TOPSIS and VIKOR methods are considered to rank the solutions. Although they have the same purpose, the rankings achieved are different. A tool is implemented to solve a time-cost-quality trade-off problem on a project activities network. The computational experiments are analyzed and the results with the exploratory grid in Simulated Annealing (SA) are promising. Despite the framework aims to solve multi-objective trade-off optimization problems, supporting the decisions of the project manager, the methodologies used can also be applied in other areas.},
  archive      = {J_IJITDM},
  author       = {Alzira Mota and Paulo Ávila and Ricardo Albuquerque and Lino Costa and João Bastos},
  doi          = {10.1142/S0219622021500322},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {4},
  pages        = {1095-1120},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {A framework for time-cost-quality optimization in project management problems using an exploratory grid concept in the multi-objective simulated-annealing},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Rec-CFSVD++: Implementing recommendation system using
collaborative filtering and singular value decomposition (SVD)++.
<em>IJITDM</em>, <em>20</em>(4), 1075–1093. (<a
href="https://doi.org/10.1142/S0219622021500310">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recommender systems, Collaborative Filtering (CF) plays an essential role in promoting recommendation services. The conventional CF approach has limitations, namely data sparsity and cold-start. The matrix decomposition approach is demonstrated to be one of the effective approaches used in developing recommendation systems. This paper presents a new approach that uses CF and Singular Value Decomposition (SVD) + + for implementing a recommendation system. Therefore, this work is an attempt to extend the existing recommendation systems by (i) finding similarity between user and item from rating matrices using cosine similarity; (ii) predicting missing ratings using a matrix decomposition approach, and (iii) recommending top-N user-preferred items. The recommender system’s performance is evaluated considering Root Mean Square Error (RMSE) and Mean Absolute Error (MAE). Performance evaluation is accomplished by comparing the systems developed using CF in combination with six different algorithms, namely SVD, SVD + + , Co-Clustering, KNNBasic, KNNBaseline, and KNNWithMeans. We have experimented using MovieLens 100 K, MovieLens 1 M, and BookCrossing datasets. The results prove that the proposed approach gives a lesser error rate when cross-validation ( CV = { 5 , 1 0 , 1 5 } ) is performed. The experimental results show that the lowest error rate is achieved with MovieLens 100 K dataset ( RMSE = 0 . 9 1 2 3 , MAE = 0 . 7 1 4 9 ). The proposed approach also alleviates the sparsity and cold-start problems and recommends the relevant items.},
  archive      = {J_IJITDM},
  author       = {Taushif Anwar and V. Uma and Gautam Srivastava},
  doi          = {10.1142/S0219622021500310},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {4},
  pages        = {1075-1093},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Rec-CFSVD++: Implementing recommendation system using collaborative filtering and singular value decomposition (SVD)++},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). Editor’s introduction. <em>IJITDM</em>, <em>20</em>(4),
1071–1074. (<a href="https://doi.org/10.1142/S0219622021030048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJITDM},
  author       = {Yong Shi},
  doi          = {10.1142/S0219622021030048},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {4},
  pages        = {1071-1074},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Editor’s introduction},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Construction of an AI-driven risk management framework for
financial service firms using the MRDM approach. <em>IJITDM</em>,
<em>20</em>(3), 1037–1069. (<a
href="https://doi.org/10.1142/S0219622021500279">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complex problem of risk factors has greatly increased globally due to the quick ever-changing digital era. The development of suitable techniques for facilitating the performance of risk management in the financial service domain is thus an urgent task, especially in today’s highly turbulent business environment. The development of such techniques involves many factors like the classical multiple criteria decision-making (MCDM) problem, but too many factors surrounding the users will confuse them and lead to improper judgments. To deal with this critical task, this study proposes a fusion multiple rule-based decision-making (MRDM) approach that integrates a rule-based technique [i.e., the fuzzy rough set theory (FRST) with particle swarm optimization (PSO)] into MCDM (i.e., DEMATEL, DANP, and modified-VIKOR) techniques that can help decision makers choose the optimal model necessary for achieving aspiration-level effects in a risk control strategy. The results indicate that the improvement priority, which runs in the order as (a) AI algorithm model, (c) AI regulatory and compliance, (d) AI conduct, and (b) AI technology based on the magnitude of the impact, can effectively improve the performance of AI-driven risk management for financial service firms.},
  archive      = {J_IJITDM},
  author       = {Kuang-Hua Hu and Fu-Hsiang Chen and Ming-Fu Hsu and Gwo-Hshiung Tzeng},
  doi          = {10.1142/S0219622021500279},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {3},
  pages        = {1037-1069},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Construction of an AI-driven risk management framework for financial service firms using the MRDM approach},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Extending ARAS with integration of objective attribute
weighting under spherical fuzzy environment. <em>IJITDM</em>,
<em>20</em>(3), 1011–1036. (<a
href="https://doi.org/10.1142/S0219622021500267">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various fuzzy sets have been developed in the recent years to model the uncertainty in judgments. Spherical fuzzy set (SFS) concept is one of these developments. It can provide an extensive preference domain for decision-makers by allowing them to state their hesitancy more explicitly. The peculiarity of SFS is that the squared sum of membership, nonmembership, and hesitancy degrees should be between 0 and 1 while each is independently defined in [0, 1]. In this study, ARAS as one of the most applied multiple attribute decision-making approaches is extended into a spherical fuzzy environment. Entropy-based and OWA operator-based objective attribute weights are also integrated with the newly proposed spherical fuzzy ARAS for coping with the drawbacks of subjective weighting such as longer data collection time and manipulation risk. The applicability of the proposition is shown in a hypothetical example of a product design problem and its robustness is shown by a comparative analysis.},
  archive      = {J_IJITDM},
  author       = {Sait Gül},
  doi          = {10.1142/S0219622021500267},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {3},
  pages        = {1011-1036},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Extending ARAS with integration of objective attribute weighting under spherical fuzzy environment},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel multi-criteria risk matrix to assist in the strategy
formulation process: The case of SMEs. <em>IJITDM</em>, <em>20</em>(3),
987–1009. (<a href="https://doi.org/10.1142/S0219622021500255">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Small and medium-sized enterprises (SMEs) are the spine of the European economy and play a key role in adding value in all sectors of the economy. However, due to a lack of methodology and time, SME entrepreneurs struggle to formalize their strategies and too often remain ill-prepared to face today’s potential crises. This paper aims to propose a Risk Management (RM) tool to identify and assess the impact of risks on specific business strategic dimensions. The hypotheses and robustness of the model are tested using Monte Carlo simulation. The analysis shows that a reduced strategic risk matrix (size 4 × 4 ) could provide the same quality of information as a full strategic risk matrix (size 2 0 × 1 0 ) in about 80% of the cases, regardless of the weight of each criterion and the values of each risk factor. The results extend the limited use of RM tool in the field of SME Risk Management.},
  archive      = {J_IJITDM},
  author       = {Jean-Marc Vasnier and Mourad Messaadia and Nicolas Maranzana and Ameziane Aoussat},
  doi          = {10.1142/S0219622021500255},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {3},
  pages        = {987-1009},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {A novel multi-criteria risk matrix to assist in the strategy formulation process: The case of SMEs},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fibonacci series-based pairwise comparison scale for
analytic hierarchy process. <em>IJITDM</em>, <em>20</em>(3), 959–986.
(<a href="https://doi.org/10.1142/S0219622021500243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Analytic Hierarchy Process (AHP) is one of the most widely used quantitative tools in multi-criteria decision-making problems. Despite its popularity and use due to its simple but systematic procedure, AHP has limitations especially in terms of the numerical comparison scale used in one of its core steps: pairwise comparisons. AHP is based on verbal comparisons of alternatives/criteria, which are, then, converted into quantitative scores with a one-to-one mapping between the verbal comparisons and a predetermined numerical scale. The choice of the numerical scale affects an essential characteristic of pairwise comparisons: consistency. In order to understand the intrinsic consistency propinquities, this study evaluates the most widely used numerical pairwise comparison scale (Fundamental Scale) and other numerical scales that have been proposed since the initial formulation of AHP. After identifying the limitations of known scales, a new scale based on Fibonacci series is developed considering these limitations, and further analysis is conducted through extensive simulations. The results show that the proposed scale performs well when compared to the other scales.},
  archive      = {J_IJITDM},
  author       = {Boğaç Can Yıldırım and Gülşah Karakaya and Mustafa Sinan Gönül},
  doi          = {10.1142/S0219622021500243},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {3},
  pages        = {959-986},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Fibonacci series-based pairwise comparison scale for analytic hierarchy process},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Factors influencing consumers’ adoption of wearable
technology: A systematic review and meta-analysis. <em>IJITDM</em>,
<em>20</em>(3), 933–958. (<a
href="https://doi.org/10.1142/S0219622021500206">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Echoing the increasing availability of various kinds of wearable technologies in the marketplace, a growing body of literature has examined which factors are related to consumers’ adoption of wearable devices. While previous studies have applied several major theories to explain consumers’ adoption of wearable devices, some findings are inconsistent, and the understanding of the relationships between variables has been limited due to the lack of a comprehensive framework. By reviewing 36 empirical studies on adoption intention of wearable devices, we developed the comprehensive framework for adoption intention of wearable devices and conducted a meta-analysis in order to examine 24 pairwise relationships among 18 factors. The meta-analysis reveals that most of the key variables identified have significant effect sizes in their relations to attitude and adoption intention. Also, the moderation analysis shows that the effect sizes of relationships vary depending on the culture (i.e., Eastern culture versus Western culture). Together, the findings based on the comprehensive framework provide theoretical and practical implications for how consumers’ adoption of wearable devices can be facilitated.},
  archive      = {J_IJITDM},
  author       = {Weisheng Chiu and Ga Eun (Grace) Oh and Heetae Cho},
  doi          = {10.1142/S0219622021500206},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {3},
  pages        = {933-958},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Factors influencing consumers’ adoption of wearable technology: A systematic review and meta-analysis},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A bi-objective simulation-based optimization approach for
optimizing price, warranty, and spare part production decisions under
imperfect repair. <em>IJITDM</em>, <em>20</em>(3), 903–932. (<a
href="https://doi.org/10.1142/S021962202150022X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an efficient methodology based on the Monte-Carlo simulation-based bi-objective optimization, to determine base-warranty (BW) and extended warranty (EW) parameters based on the product lifecycle. The first objective, which is from the manufacturer’s perspective, maximizes the profit while the second objective minimizes the expected number of failures that occurred during the out-of-warranty period. The manufacturer can rectify failed products via minimal repair, imperfect repair and perfect repair. The optimization model has decision variables including the product price, BW length, EW length, EW price, product failure rate, imperfect repair level, and spare part production rate in each time interval. The structure of the model admits the design of a hybrid method based on the multi-objective optimization search algorithm, Monte-Carlo simulation and an exact Out-Of-Kilter (OOK) algorithm. The nondominated sorting genetic algorithm (NSGA-II) and the multi-objective particle swarm optimization (MOPSO) algorithm are used as search algorithms. The proposed approach consists of three stages, where in the first stage, product price, BW length, EW length, EW price, product failure rate, imperfect repair level are set by NSGA-II/MOPSO. In the second stage, the number of failed products is calculated by the Monte-Carlo simulation and in the third stage, we show that the spare part inventory control sub problem can be transformed to a minimum cost network flow problem which is optimized by the OOK algorithm to attain a unified solution. A Taguchi approach is used to find the optimum level of parameters. The performance of algorithms is compared based on three different metrics. Results on a real-world problem demonstrate that the NSGA-II-OOK algorithm is more effective than the MOPSO-OOK algorithm. Through a sensitivity analysis, we analyze how various levels of planning horizon can affect Pareto-set which indicates valuable managerial insight.},
  archive      = {J_IJITDM},
  author       = {Mohsen Afsahi and Ali Husseinzadeh Kashan and Bakhtiar Ostadi},
  doi          = {10.1142/S021962202150022X},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {3},
  pages        = {903-932},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {A bi-objective simulation-based optimization approach for optimizing price, warranty, and spare part production decisions under imperfect repair},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A fuzzy MCDM method based on new fermatean fuzzy theories.
<em>IJITDM</em>, <em>20</em>(3), 881–902. (<a
href="https://doi.org/10.1142/S021962202150019X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new Multi-criteria Decision-Making (MCDM) method with Fermatean fuzzy sets (FFSs). The proposed method uses the entropy theory to determine the weights of criteria and utilize cosine similarity measures to determine the best alternative. First, we develop a new Fermatean fuzzy entropy formula based on the Euclidean distance between Fermatean fuzzy number (FFN) and its compliment. The properties of the proposed formula and the proof of the properties are also given. Then, Fermatean fuzzy cosine similarity measures are introduced. We develop four different Fermatean fuzzy cosine similarity measures, also properties and proof of the properties are worked out systematically. Then, the algorithm of the proposed Fermatean fuzzy MCDM method, which includes Fermatean fuzzy entropy and Fermatean fuzzy cosine similarity measures, is introduced. The advantage of the proposed method is that Fermatean fuzzy entropy calculates how much valuable knowledge the current data provides in weights of criteria, and Fermatean fuzzy cosine similarity measures define the similarity between alternatives and ideal solution and negative ideal solution, in this way the method determines the best alternative smoothly. To show the applicability of the proposed method, an illustrative example is given for third party logistic (3PL) firm evaluation problem in cold chain management. In the illustrative example section, we determine six different criteria and six different 3PL alternatives. Then, alternatives are evaluated according to the proposed Fermatean fuzzy MCDM method. Moreover, the results are compared to the Euclidean measure, and sensitivity analysis is also performed. The comparison analysis results show that our model works efficiently and effectively.},
  archive      = {J_IJITDM},
  author       = {Serhat Aydın},
  doi          = {10.1142/S021962202150019X},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {3},
  pages        = {881-902},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {A fuzzy MCDM method based on new fermatean fuzzy theories},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Composite indicators as decision making tools: The joint use
of compensatory and noncompensatory schemes. <em>IJITDM</em>,
<em>20</em>(3), 847–879. (<a
href="https://doi.org/10.1142/S0219622021500231">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Composite indicators are powerful tools for summarizing, focusing and condensing the complexity of our dynamic environment, and their use has become indispensable for managing huge amounts of information. An important aspect to emphasize when constructing composite indicators is the compensatory character among the individual indicators. In general, a fully compensatory scheme provides an overall assessment of the performance of each unit, while a non-compensatory scheme detects the worst single performances. When used in a decision making framework, the joint consideration of both schemes may, therefore, be helpful. Nevertheless, in the literature, few approaches allow the construction of composite indicators for different compensation degrees. On these premises, the aim of this paper is to illustrate the behavior of some methodologies that build composite indicators allowing different compensation degrees. We analyze the results provided by each of these methods and which of them provide a more varied complementary information when considering both compensatory and non-compensatory scenarios. An illustrative example is used to visualize the results.},
  archive      = {J_IJITDM},
  author       = {Samira El Gibari and José M. Cabello and Trinidad Gómez and Francisco Ruiz},
  doi          = {10.1142/S0219622021500231},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {3},
  pages        = {847-879},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Composite indicators as decision making tools: The joint use of compensatory and noncompensatory schemes},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021d). Editor’s introduction. <em>IJITDM</em>, <em>20</em>(3),
843–845. (<a href="https://doi.org/10.1142/S0219622021030036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJITDM},
  author       = {Yong Shi},
  doi          = {10.1142/S0219622021030036},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {3},
  pages        = {843-845},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Editor’s introduction},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Detection and correction of abnormal data with optimized
dirty data: A new data cleaning model. <em>IJITDM</em>, <em>20</em>(2),
809–841. (<a href="https://doi.org/10.1142/S0219622021500188">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Each and every business enterprises require noise-free and clean data. There is a chance of an increase in dirty data as the data warehouse loads and refreshes a large quantity of data continuously from the various sources. Hence, in order to avoid the wrong conclusions, the data cleaning process becomes a vital one in various data-connected projects. This paper made an effort to introduce a novel data cleaning technique for the effective removal of dirty data. This process involves the following two steps: (i) dirty data detection and (ii) dirty data cleaning. The dirty data detection process has been assigned with the following process namely, data normalization, hashing, clustering, and finding the suspected data. In the clustering process, the optimal selection of centroid is the promising one and is carried out by employing the optimization concept. After the finishing of dirty data prediction, the subsequent process: dirty data cleaning begins to activate. The cleaning process also assigns with some processes namely, the leveling process, Huffman coding, and cleaning the suspected data. The cleaning of suspected data is performed based on the optimization concept. Hence, for solving all optimization problems, a new hybridized algorithm is proposed, the so-called Firefly Update Enabled Rider Optimization Algorithm (FU-ROA), which is the hybridization of the Rider Optimization Algorithm (ROA) and Firefly (FF) algorithm is introduced. To the end, the analysis of the performance of the implanted data cleaning method is scrutinized over the other traditional methods like Particle Swarm Optimization (PSO), FF, Grey Wolf Optimizer (GWO), and ROA in terms of their positive and negative measures. From the result, it can be observed that for iteration 12, the performance of the proposed FU-ROA model for test case 1 on was 0.013%, 0.7%, 0.64%, and 0.29% better than the extant PSO, FF, GWO, and ROA models, respectively.},
  archive      = {J_IJITDM},
  author       = {Kumar Rahul and Rohitash Kumar Banyal},
  doi          = {10.1142/S0219622021500188},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {2},
  pages        = {809-841},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Detection and correction of abnormal data with optimized dirty data: A new data cleaning model},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). HSCWMA: A new hybrid SCA-WMA algorithm for solving
optimization problems. <em>IJITDM</em>, <em>20</em>(2), 775–808. (<a
href="https://doi.org/10.1142/S0219622021500176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hybrid metaheuristic algorithms have recently become an interesting topic in solving optimization problems. The woodpecker mating algorithm (WMA) and the sine cosine algorithm (SCA) have been integrated in this paper to propose a hybrid metaheuristic algorithm for solving optimization problems called HSCWMA. Despite the high capacity of the WMA algorithm for exploration, this algorithm needs to augment exploitation especially in initial iterations. Also, the sine and cosine relations used in the SCA provide the good exploitation for this algorithm, but SCA suffers the lack of an efficient process for the implementation of effective exploration. In HSCWMA, the modified mathematical search functions of SCA by Levy flight mechanism is applied to update the female woodpeckers in WMA. Moreover, the local search memory is used for all search elements in the proposed hybrid algorithm. The goal of proposing the HSCWMA is to use exploration capability of WMA and Levy flight, utilize exploitation susceptibility of the SCA and the local search memory, for developing exploration and exploitation qualification, and providing the dynamic balance between these two phases. For efficiency evaluation, the proposed algorithm is tested on 28 mathematical benchmark functions. The HSCWMA algorithm has been compared with a series of the most recent and popular metaheuristic algorithms and it outperforms them for solving nonconvex, inseparable, and highly complex optimization problems. The proposed algorithm is also used as a Multi-Layer Perceptron (MLP) neural network trainer to solve the software development effort estimation (SDEE) problem on three real-world datasets. The simulation results proved the superior and promising performance of the HSCWMA algorithm in the majority of evaluations.},
  archive      = {J_IJITDM},
  author       = {Morteza Karimzadeh Parizi and Farshid Keynia and Amid Khatibi Bardsiri},
  doi          = {10.1142/S0219622021500176},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {2},
  pages        = {775-808},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {HSCWMA: A new hybrid SCA-WMA algorithm for solving optimization problems},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient decision-making approach for short term indoor
room temperature forecasting in smart environment: Evidence from india.
<em>IJITDM</em>, <em>20</em>(2), 733–774. (<a
href="https://doi.org/10.1142/S0219622021500164">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {“Smart cities” start with “Smart Buildings” that improve the quality of urban services while ensuring sustainability. The current scenario in India reveals that the corporate and residential building structures are incorporating various self-sustainable techniques. Out of the multiple factors governing the comfort of smart buildings, indoor room temperature is an important one, since it drives the need of cooling or heating through controlling systems. Around one-third of total energy consumption of commercial buildings in India is attributed to Heating, Ventilation and Air Conditioning (HVAC) systems. Accurate prediction of indoor room temperature helps in creating an efficient equilibrium between energy consumption and comfort level of the building, thus providing opportunities for efficient decision making for energy optimization. Considering Indian climatic and geographical conditions, this paper proposes an efficient decision making approach using Bayesian Dynamic Models (BDM) for short-term indoor room temperature forecasting of a corporate building structure. The results obtained from Bayesian Dynamic linear model, using Expectation Maximization (EM) algorithm, have been compared to standard Auto Regressive Integrated Moving Average (ARIMA) model, and have been found to be more accurate. Forecasting of indoor room temperature is a highly nonlinear phenomenon, so to further improve the accuracy of the linear models, a hybrid modeling approach has been proposed. The inclusion of state-of-the-art nonlinear models such as Artificial Neural Networks (ANNs) and Support Vector Regression (SVR) improves the forecasting accuracy of the linear models significantly. Results show that the hybrid model obtained using BDM and ANN is the best fit model.},
  archive      = {J_IJITDM},
  author       = {Kamal Pandey and Bhaskar Basu and Sandipan Karmakar},
  doi          = {10.1142/S0219622021500164},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {2},
  pages        = {733-774},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {An efficient decision-making approach for short term indoor room temperature forecasting in smart environment: Evidence from india},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DEA efficiency region for variations of inputs and outputs.
<em>IJITDM</em>, <em>20</em>(2), 707–732. (<a
href="https://doi.org/10.1142/S0219622021500103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding efficiency regions (ERs) for extremely efficient decision-making units (DMUs) is one of the important issues from the managerial and economic viewpoints. An extremely efficient DMU will remain efficient if and only if after changing its inputs and/or its outputs this DMU stays within its ER. Thus, by applying the ER information, decision maker(s) of the evaluated extremely efficient DMU can precisely understand the values of input(s) increment and output(s) decrement of this DMU so that it remains efficient. Hence, in this study, we propose a data envelopment analysis (DEA) approach based on the defining hyperplanes of the production possibility set (PPS), which is capable of finding the ERs of the DMUs when their inputs increase and/or their outputs decrease. To demonstrate the applicability of the proposed approach, in the real world, a numerical example and an empirical application to the banking industry in the Czech Republic are provided.},
  archive      = {J_IJITDM},
  author       = {Mohammad Khoveyni and Robabeh Eslami},
  doi          = {10.1142/S0219622021500103},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {2},
  pages        = {707-732},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {DEA efficiency region for variations of inputs and outputs},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An adaptive personalized property investment risk analysis
method based on data-driven approach. <em>IJITDM</em>, <em>20</em>(2),
671–706. (<a href="https://doi.org/10.1142/S0219622021500115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Risk assessment analysis for investment decisions largely depends on expert judgment using traditional approaches and is lacking in considering investors’ different preferences and limitations. This paper proposes an adaptive personalized property investment risk analysis (APPIRA) method to identify the property investment determinants using a data-driven and personalized approach to weight the risk factors using the multicriteria decision model for optimal solutions. Result for predictive modeling using value prediction technique that measures the median house price depicts that the best method used was nonseasonal ARIMA. Furthermore, classification technique indicates that in each of the three selected suburbs, different property characteristics determined the rental properties desirable. As shown in result, for the investors who plan to invest in property for rental purposes, they need to choose townhouse type or property to make it rentable while for Vaucluse, terrace houses. These results can be applied into practice and will benefit the property industry directly.},
  archive      = {J_IJITDM},
  author       = {Nur Atiqah Rochin Demong and Jie Lu and Farookh Khadeer Hussain},
  doi          = {10.1142/S0219622021500115},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {2},
  pages        = {671-706},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {An adaptive personalized property investment risk analysis method based on data-driven approach},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A decision-making method for boosting new digitalization
technologies. <em>IJITDM</em>, <em>20</em>(2), 635–669. (<a
href="https://doi.org/10.1142/S0219622021500097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Market acceptance of new digitalization technologies is low. To help to address this shortcoming, the following paper defines a quantitative decision-making methodology for the exante evaluation of the market acceptance of new digitalization solutions in the initial stages of design and development. The proposed decision-making methodology includes a first evaluation, using Volere methodology, for the quantification of how useful the new digitalization solution is for the end users, and a second method, the calculation of the net present value (NPV) based on potential benefits in terms of costs and intangible benefits of the new tool. A new tool for the management of freight transport was used as a case study. The usefulness of a new information technology tool was assessed in six different companies. It was designed to help developers and decision makers in information and communication technology (ICT) product development, and company managers in the evaluation of technical solutions that might better satisfy their needs. Further studies could measure the power of this methodology by comparing the implementation levels of two different prototypes designed for the same function and with different Volere and NPV scorings.},
  archive      = {J_IJITDM},
  author       = {Francisco E. Santarremigia and Sara Poveda-Reyes and Miguel Hervás-Peralta and Gemma D. Molero},
  doi          = {10.1142/S0219622021500097},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {2},
  pages        = {635-669},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {A decision-making method for boosting new digitalization technologies},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-criteria decision-making method based on a weighted
2-tuple fuzzy linguistic representation model. <em>IJITDM</em>,
<em>20</em>(2), 619–634. (<a
href="https://doi.org/10.1142/S0219622021500085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-criteria decision-making (MCDM) methods are used in the selection and evaluation of alternatives. However, too many decision criteria and numerical calculations will increase the computational complexity and make the calculation process difficult to understand. In this paper, a weighted 2-tuple fuzzy linguistic representation model is proposed. The contributions of this study are as follows: (1) Feature selection method was used to remove the redundant or irrelevant feature attributes, thereby simplifying calculations and reducing calculation complexities. (2) The integration of the 2-tuple linguistic representation model simplifies the complexity of numerical calculations. The calculation of qualitative scales can be closer to the human thinking model, and loss of information can be avoided during calculations through the appropriate model. (3) Information fusion technology, i.e., ordered weighted average operator (OWA), was used. The method simplifies the traditional OWA calculation and can be calculated according to the priority order of the indicators. (4) Four major shareholding companies in Taiwan 50 ETF stocks were selected as experimental cases. In total, 992 tuples were obtained and 29 technical indicators were analyzed. The results indicate that case A1 is the most stable among the four stocks considered under different decision-making situations, and it has the first priority ranking.},
  archive      = {J_IJITDM},
  author       = {Jia-Wen Wang},
  doi          = {10.1142/S0219622021500085},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {2},
  pages        = {619-634},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Multi-criteria decision-making method based on a weighted 2-tuple fuzzy linguistic representation model},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Integrated ranking algorithm for efficient decision making.
<em>IJITDM</em>, <em>20</em>(2), 597–618. (<a
href="https://doi.org/10.1142/S0219622021500152">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision making remains a prominent issue in all the problem domains. To make better decisions, multiple factors of the given problem need to be considered and evaluated. Multi-criteria decision-making methods have been used popularly for solving decision-making problems characterized by multiple factors. When multiple factors are considered, it is recommended to categorize the factors into the main criteria and sub-criteria. In this paper, GRAP-an integrated ranking algorithm has been developed by combining Grey Relational Analysis, Rank Sum, and Preference Ranking Organization Method Enrichment Evaluation methods (PROMETHEE) to solve decision-making problems. The weights of the sub-criteria are calculated using the Rank Sum method. Grey Relational Analysis method is used to convert the sub-criteria values into main criteria values in the form of evaluation scores of alternatives. The final ranking scores of the alternatives are obtained using the PROMETHEE method. A decision model is developed using the proposed GRAP algorithm and applied to the Job Profile selection case study. The developed decision model showed much better results compared to other MCDM approaches namely the Simple Additive Weight method, TOPSIS, VIKOR, and Complex Proportional Assessment (COPRAS). Further, a sanity check has been carried out by comparing the results of the decision model with experts’ opinions.},
  archive      = {J_IJITDM},
  author       = {N. Deepa and B. Prabadevi and Gautam Srivastava},
  doi          = {10.1142/S0219622021500152},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {2},
  pages        = {597-618},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Integrated ranking algorithm for efficient decision making},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hybrid recommender system using KNN and clustering.
<em>IJITDM</em>, <em>20</em>(2), 553–596. (<a
href="https://doi.org/10.1142/S021962202150005X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender Systems ( R S s ) are known in the E-Commerce ( E C ) field. They are expected to suggest the accurate goods/musics/films/items to the consumers/clients/people/users. Recent Hybrid R S s ( H R S s ) have made us able to deal with the most important shortages of traditional Con tent-based F iltering ( C o n F ) and Col laborative F iltering ( C o l F ). Cold start, scalability and sparsity are the most important challenges to E C recommender systems ( E C R S ). H R S s combine C o n F and C o l F . While the R S s that are based on memory have high accuracy, they are not scalable. Contrarily, the RSs on the basis of models have low accuracy but high scalability. Thus, aiming at dealing with cold start, scalability and sparsity challenges, H R S is proposed to use both methods and also it has been evaluated on a real benchmark. An ontology, which is automatically created by an intelligently collected wordnet, has been employed in C o n F segment of the proposed H R S . It has been automatically created and enhanced by an additional process. The functionality of the recommended framework has been superior to the performance of the state-of-the-art methods and the traditional C o n F and C o l F embedded in our method. Using a real dataset as a benchmark, the experimentations indicate that the proposed method not only has better performance but also has more efficacy rather than the state-of-the-art methods.},
  archive      = {J_IJITDM},
  author       = {Hao Fan and Kaijun Wu and Hamid Parvin and Akram Beigi and Kim-Hung Pho},
  doi          = {10.1142/S021962202150005X},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {2},
  pages        = {553-596},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {A hybrid recommender system using KNN and clustering},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel spherical fuzzy bi-objective linear assignment
method and its application to insurance options selection.
<em>IJITDM</em>, <em>20</em>(2), 521–551. (<a
href="https://doi.org/10.1142/S0219622021500073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spherical fuzzy sets are the latest extension of the ordinary fuzzy sets. The main characteristic of the spherical fuzzy sets is satisfying the condition that the squared sum of the membership, nonmembership, and hesitancy degrees must be at least zero and at most one. In this research, by extending the classical linear assignment method to bi-objective linear assignment and integrating it with cosine similarity measure, we presented a novel beneficial method for solving multiple criteria group decision-making problems in the spherical fuzzy environment. A new concept for weighting the criteria, which is composed of positive and negative impacts (weights), is introduced. The proposed bi-objective model tries to maximize positive impacts and minimize the negative impacts simultaneously. In order to solve the bi-objective linear assignment model, ε -constraint method is applied. Therefore, a trade-off solution is formed between maximizing positive impacts and minimizing negative impacts. The applicability and validity of the proposed method are shown through an insurance options selection problem. To test the reliability and validity of the proposed method, comparative and sensitivity analysis are performed.},
  archive      = {J_IJITDM},
  author       = {Seyed Amin Seyfi-Shishavan and Fatma Kutlu Gündoğdu and Yaser Donyatalab and Elmira Farrokhizadeh and Cengiz Kahraman},
  doi          = {10.1142/S0219622021500073},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {2},
  pages        = {521-551},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {A novel spherical fuzzy bi-objective linear assignment method and its application to insurance options selection},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021e). Editor’s introduction. <em>IJITDM</em>, <em>20</em>(2),
517–520. (<a href="https://doi.org/10.1142/S0219622021030024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJITDM},
  author       = {Yong Shi},
  doi          = {10.1142/S0219622021030024},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {2},
  pages        = {517-520},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Editor’s introduction},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Feature selection with binary symbiotic organisms search
algorithm for email spam detection. <em>IJITDM</em>, <em>20</em>(1),
469–515. (<a href="https://doi.org/10.1142/S0219622020500546">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One method to increase classifier accuracy is using Feature Selection (FS). The main idea in the FS is reducing complexity, eliminating irrelevant information, and deleting a subset of input features that either have little information or have no information for prediction. In this paper, three efficient binary methods based on the Symbiotic Organisms Search (SOS) algorithm were presented for solving the FS problem. In the first and second methods, several S_shaped and V_shaped transfer functions were used for the binarization of the SOS, respectively. These methods were called BSOSS and BSOSV. In the third method, two new operators called Binary Mutualism Phase (BMP) and Binary Commensalism Phase (BCP) were presented for binarization of the SOS, named Efficient Binary SOS (EBSOS). The proposed methods were run on 18 standard UCI datasets and compared to the base and important meta-heuristic algorithms. The test results showed that the EBSOS method has the best performance among the three proposed methods for the binarization of the SOS. Finally, the EBSOS method was compared to the Genetic Algorithm (GA), Binary Bat Algorithm (BBA), Binary Particle Swarm Optimization (BPSO) Algorithm, Binary Flower Pollination Algorithm (BFPA), Binary Grey Wolf Optimizer (BGWO) Algorithm, Binary Dragonfly Algorithm (BDA), and Binary Chaotic Crow Search Algorithm (BCCSA). In addition, the EBSOS method was executed on the spam email dataset with the KNN, NB, SVM, and MLP classifiers. The results showed that the EBSOS method has better performance compared to other methods in terms of feature count and accuracy criteria. Furthermore, it was practically evaluated on spam email detection in particular.},
  archive      = {J_IJITDM},
  author       = {Hekmat Mohammadzadeh and Farhad Soleimanian Gharehchopogh},
  doi          = {10.1142/S0219622020500546},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {1},
  pages        = {469-515},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Feature selection with binary symbiotic organisms search algorithm for email spam detection},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An advanced stochastic risk assessment approach proposal
based on KEMIRA-m, QFD and fine–kinney hybridization. <em>IJITDM</em>,
<em>20</em>(1), 431–468. (<a
href="https://doi.org/10.1142/S0219622021500036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, an advanced stochastic risk assessment approach based on integration of advanced version of quality function deployment (AV-QFD) and Modified Kemeny Median Indicator Rank Accordance (KEMIRA-M) is proposed. It is aimed to perform a new criterion weighting procedure based on four different distributions as uniform, symmetric triangular, left asymmetric triangular, right asymmetric triangular distributions. The AV-QFD includes correlations between criteria (top roof of QFD), risk degrees (RDs) of risk types (RTs) (customer needs part of QFD), correlations between RTs and criteria sets (CSs) (in the middle of QFD) to obtain the criteria priorities. Correlations on the top roof of QFD comprises three types: correlations between criteria in the first CS, correlations between criteria in the second CS and correlations between criteria in both CSs. Additionally, Fine–Kinney method is performed in AV-QFD to compute RDs of RTs in the customer needs part. Then for each expert, the correlation-based importance degree (CBID) of each criterion is obtained to rank criteria for each CS. MATLAB code was performed to see the effect of different trial numbers and replications on risk assessment. It was observed that although uniform distribution provides the best value, the same alternative ranking was obtained for all distributions. In addition, right asymmetric triangular distribution converged to the best value rapidly in practice made in this study.},
  archive      = {J_IJITDM},
  author       = {Gülin Feryal Can and Pelin Toktaş},
  doi          = {10.1142/S0219622021500036},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {1},
  pages        = {431-468},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {An advanced stochastic risk assessment approach proposal based on KEMIRA-m, QFD and Fine–Kinney hybridization},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hotel recommender system for tourists using the artificial
bee colony algorithm and fuzzy TOPSIS model: A case study of
TripAdvisor. <em>IJITDM</em>, <em>20</em>(1), 399–429. (<a
href="https://doi.org/10.1142/S0219622020500522">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation systems play an indispensable role in tourists’ decision-making process. An important issue for tourists concerns the selection of accommodation in accordance with the criteria on their minds, which may include several items at the same time. This paper proposes a novel approach to recommendation systems in the tourism industry involving a combination of the Artificial Bee Colony (ABC) algorithm and the fuzzy TOPSIS model. The Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS), a multi-criteria decision-making method, has been utilized to optimize the system. The solution presented in this research includes two major parts, where the employed ABC algorithm has been improved and is more efficient than the standard version. This research has addressed the TripAdvisor dataset and presented a method for hotel recommendations based on user preferences according to real data. The obtained results demonstrate the high accuracy of the method presented in the research.},
  archive      = {J_IJITDM},
  author       = {Saman Forouzandeh and Kamal Berahmand and Elahe Nasiri and Mehrdad Rostami},
  doi          = {10.1142/S0219622020500522},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {1},
  pages        = {399-429},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {A hotel recommender system for tourists using the artificial bee colony algorithm and fuzzy TOPSIS model: A case study of TripAdvisor},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new interactive algorithm for continuous multiple criteria
problems: A portfolio optimization example. <em>IJITDM</em>,
<em>20</em>(1), 371–398. (<a
href="https://doi.org/10.1142/S0219622020500510">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In continuous multiple criteria problems, finding a distinct preferred solution for a decision maker (DM) is not straightforward. There are few recent studies proposed for this task, and the algorithms developed are cognitively difficult and complex for the DM in general. We propose a novel interactive algorithm to guide the DM in converging highly-preferred solutions in continuous multiple criteria problems. We test our algorithm on portfolio optimization problems formed with the stocks included in the S&amp;P 100 index using expected return, liquidity, conditional value at risk, and mean absolute deviation as criteria. We simulate DM responses with linear and nonlinear preference functions and use various weights for the criteria. The experiments show that our algorithm is able to find highly-preferred solutions in considerably low number of iterations. We also test our algorithm against benchmark algorithms and demonstrate that our algorithm produces superior or comparable results.},
  archive      = {J_IJITDM},
  author       = {Gülşah Karakaya and Ceren Tuncer Şakar},
  doi          = {10.1142/S0219622020500510},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {1},
  pages        = {371-398},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {A new interactive algorithm for continuous multiple criteria problems: A portfolio optimization example},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). EWNStream+: Effective and real-time clustering of short text
streams using evolutionary word relation network. <em>IJITDM</em>,
<em>20</em>(1), 341–370. (<a
href="https://doi.org/10.1142/S0219622021500024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The real-time clustering of short text streams has various applications, such as event tracking, text summarization and sentimental analysis. However, accurately and efficiently clustering short text streams is challenging due to the sparsity problem (i.e., the limited information comprised in a single short text document leads to high-dimensional and sparse vectors when we represent short texts using traditional vector space models), topic drift and the fast generated text streams. In this paper, we provide an effective and real-time Evolutionary Word relation Network for short text streams clustering (EWNStream + ) method. The EWNStream + method constructs a bi-weighted word relation network using the aggregated term frequencies and term co-occurrence statistics at corpus level to overcome the sparsity problem and topic drift of short texts. Better still, as the query window in the stream shifts to the newly arriving data, EWNStream + is capable of incrementally updating the word relation network by incorporating new word statistics and decaying the old ones to naturally capture the underlying topic drift in the data streams and reduce the size of the network. The experimental results on a real-world dataset show that EWNStream + can achieve better clustering accuracy and time efficiency than several counterpart methods.},
  archive      = {J_IJITDM},
  author       = {Shuiqiao Yang and Guangyan Huang and Xiangmin Zhou and Vicky Mak and John Yearwood},
  doi          = {10.1142/S0219622021500024},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {1},
  pages        = {341-370},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {EWNStream+: Effective and real-time clustering of short text streams using evolutionary word relation network},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Opinions and actions dynamics under bounded confidence.
<em>IJITDM</em>, <em>20</em>(1), 321–340. (<a
href="https://doi.org/10.1142/S0219622021500012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Psychologically, agents always like to consider similar opinions. Moreover, in real opinion dynamics, people’s opinions usually influence their actions. Therefore, inspired by the HK bounded confidence model, and continuous opinions and discrete action model, in this paper, we propose opinions and actions dynamics model under bounded confidence to investigate the evolution of opinions and actions in a group of agents. In this model, it is assumed that agents have continuous opinions and discrete actions for a certain issue. Each agent often can notice the discrete actions of other agents, but cannot acquire their continuous opinions. So, agents always try to estimate other agents’ opinions based on their actions. Then based on the estimation opinions and bounded confidence, agents update their opinions and actions. Simulation experiments analysis shows that more agents keep silence or undecided as the hesitation range increases. Larger bounded confidence value leads to the stronger attracting power of agents. When the opinion distribution widths of agents with an action are smaller than the bounded confidence value, the agents will be completely attracted by the adjacent agents with large opinion distribution widths and show adjacent actions in the final time.},
  archive      = {J_IJITDM},
  author       = {Min Zhan and Haiming Liang and Can Zhu and Yucheng Dong},
  doi          = {10.1142/S0219622021500012},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {1},
  pages        = {321-340},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Opinions and actions dynamics under bounded confidence},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Belief-based best worst method. <em>IJITDM</em>,
<em>20</em>(1), 287–320. (<a
href="https://doi.org/10.1142/S0219622020500480">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Best-Worst Method (BWM) is a Multi-Criteria Decision Making (MCDM) method that has recently been introduced. The original BWM assumes that decision-makers are always certain about their judgments even if, in reality, decision-makers often express uncertain preferences. To deal with uncertainty, we introduce a belief structure in the BWM, a concept involving the preference degree adopted via Dempster-Shafer theory. A new approach is proposed to allow BWM to cope with this kind of information, where the level of belief in preferences being expressed is taken into account. In addition, an inconsistency measurement and an uncertainty measurement are proposed for the belief-based BWM, providing the foundation for a reliability degree of the decision-makers, after which the belief-based BWM is extended to include a group of decision-makers. Based on their reliability degrees and the weights of the criteria obtained from the various individuals, the overall criteria weights can be aggregated accordingly. Finally, a case study on the assessment of the infrastructure project criteria system in Indonesia is provided to demonstrate the applicability and feasibility of the proposed method.},
  archive      = {J_IJITDM},
  author       = {Fuqi Liang and Matteo Brunelli and Kevin Septian and Jafar Rezaei},
  doi          = {10.1142/S0219622020500480},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {1},
  pages        = {287-320},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Belief-based best worst method},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Data-driven evidential reasoning method for evaluating
e-government performance. <em>IJITDM</em>, <em>20</em>(1), 261–285. (<a
href="https://doi.org/10.1142/S0219622020500479">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The construction of electronic government (e-government) systems is a process of continuous improvement. It is necessary to evaluate the performance of e-government systems regularly to improve the services provided by government agencies and enhance the exchange of information between governments and citizens. Evaluating e-government performance based on citizens’ experience is a multiple criterion decision making (MCDM) problem under uncertainty, where assessments are qualitative, and many e-government system users are involved. Deriving criterion weights from a large amount of evaluation data is rarely discussed in previous MCDM studies. This paper proposes a data-driven evidential reasoning (DDER) method for evaluating e-government performance. A criteria framework from the citizens’ experience perspective, including service guide clarity, site usability, information sharing, documentation, and the availability of e-services, is proposed. Belief structures are used to portray uncertain assessments from e-government system users. The criterion weights are learned from the data by minimizing the dissimilarity between the aggregation assessments of the alternatives on each criterion and citizens’ historical observations on a whole. A case study is conducted in 16 cities of Anhui province in China to evaluate the performance of e-government systems. The ranking results verified the applicability and effectiveness of the proposed method.},
  archive      = {J_IJITDM},
  author       = {Ying Yang and Rui-Xue Lu and Min Xue and Zhi-Qin Shou and Jian-Bo Yang and Lei Fu},
  doi          = {10.1142/S0219622020500479},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {1},
  pages        = {261-285},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Data-driven evidential reasoning method for evaluating e-government performance},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multiple attribute decision-making method based on free
double hierarchy hesitant fuzzy linguistic information considering the
prioritized and interactive attributes. <em>IJITDM</em>, <em>20</em>(1),
225–259. (<a href="https://doi.org/10.1142/S0219622020500467">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the development and extension of hesitant fuzzy linguistic term sets (HFLTSs), free double hierarchy hesitant fuzzy linguistic term sets (FDHHFLTSs) can describe the evaluation information in more detail. In addition, in practical multiple attribute decision-making (MADM) problems, priority relations and interaction relations usually exist among attributes, and the prioritized interactive Choquet (PIC) operator based on generalized prioritized measure-guided aggregation (GPMGA) operator and Choquet integral (CI) operator is an effective tool for dealing with decision-making problems with priority relations and interaction relations. Under the above contexts, we improve the PIC operator and propose the FDHHFLPIC operator which can aggregate the evaluation information under free double hesitant fuzzy linguistic environment and take both priority and interaction relations into account. Furthermore, we propose an approach based on the FDHHFLPIC operators to address the real MADM problem, and the proposed method considering the different relations between attributes in decision-making process. Finally, two numerical examples are given to demonstrate the effectiveness and advantages of the proposed method which can consider priority relations and interaction relations under the FDHHFLTSs.},
  archive      = {J_IJITDM},
  author       = {Peide Liu and Mengjiao Shen and Fei Teng and Baoying Zhu and Lili Rong},
  doi          = {10.1142/S0219622020500467},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {1},
  pages        = {225-259},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {A multiple attribute decision-making method based on free double hierarchy hesitant fuzzy linguistic information considering the prioritized and interactive attributes},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Culturally inclusive adaptive user interface (CIAUI)
framework: Exploration of plasticity of user interface design.
<em>IJITDM</em>, <em>20</em>(1), 199–224. (<a
href="https://doi.org/10.1142/S0219622020500455">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a Culturally Inclusive Adaptive User Interface (CIAUI) Framework for developing Mobile Learning (M-Learning) and other mobile applications. The CIAUI Framework specifically incorporates the concepts of universal design aimed for culturally diverse users. This was derived as an outcome of a research project involving the design, analysis and evaluation of artificial intelligence (AI)-based adaptive interface development, known as the “Mobile Academy”, using plasticity of user interface (UI) design techniques for culturally inclusive design. The CIAUI Framework, was one of the major and significant output of the research, which satisfied the broad requirement for cross-cultural usability. The framework was not only defined but a complete analysis was conducted. Its parameters, validation, examples of developing applications and indicated direction of further research are presented here. The principles of culturally inclusive design are finally reviewed.},
  archive      = {J_IJITDM},
  author       = {Mahdi H. Miraz and Peter S. Excell and Maaruf Ali},
  doi          = {10.1142/S0219622020500455},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {1},
  pages        = {199-224},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Culturally inclusive adaptive user interface (CIAUI) framework: Exploration of plasticity of user interface design},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An overview on recent researches of uncertain group decision
making: Methodology, framework and development. <em>IJITDM</em>,
<em>20</em>(1), 165–198. (<a
href="https://doi.org/10.1142/S0219622021500048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The uncertain group decision-making (UGDM) methodology has developed rapidly in recent years, which is synchronous with the evolution of fuzzy set (FS) theory and linguistic term set theory. Generally, the UGDM methods can be divided into three categories, i.e., the multi-attribute decision-making (MADM) methods, the preference-based methods and the dynamic decision-making methods. In this paper, we present an overview on UGDM, including the methodology, framework and recent development of the methods. These methods are classified into different types according to their features and calculation processes. Also, we connect the recent decision-making methods with the development of FS theory, linguistic term set theory and their extensions, etc. We can find that the development of UGDM methodology and the evolution of information expressions interactively influence and promote each other’s progress. This paper integrates the recent development and provides a framework containing different aspects of uncertain decision-making methods.},
  archive      = {J_IJITDM},
  author       = {Yue He and Zeshui Xu},
  doi          = {10.1142/S0219622021500048},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {1},
  pages        = {165-198},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {An overview on recent researches of uncertain group decision making: Methodology, framework and development},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ABX-LEX: An argument-driven approach for the digital
facilitation of efficient group decisions. <em>IJITDM</em>,
<em>20</em>(1), 137–164. (<a
href="https://doi.org/10.1142/S0219622020500431">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quality of a group decision depends on its members sharing and adopting their various perspectives. Multi-criteria models provide an appropriate vehicle for managing this information sharing because they break down the decision into small, single-issue questions that can be treated independently. We present a new lexicographic decision method with three equivalence classes for use by a group. Our algorithm is the first to combine the hidden profile and multi-criteria paradigms and thereby improving the consensus by identifying critical disagreements and inviting the decision makers to share their mental models of them. A computer simulation demonstrates the algorithm’s effectiveness and efficiency. Unless the problem parameters are very unfavorable, the method achieves the desired choice set or a close approximation to it significantly faster than the commonly used compensatory methods. Our algorithm can either provide step-by-step instructions to a human facilitator, or it can be implemented as a software agent acting as a fully automated digital facilitator, allowing decision makers to participate “on the go” using their internet-connected mobile devices.},
  archive      = {J_IJITDM},
  author       = {Graham Horton and Jana Goers},
  doi          = {10.1142/S0219622020500431},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {1},
  pages        = {137-164},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {ABX-LEX: An argument-driven approach for the digital facilitation of efficient group decisions},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Novel triplex procedure for ranking the ability of software
engineering students based on two levels of AHP and group TOPSIS
techniques. <em>IJITDM</em>, <em>20</em>(1), 67–135. (<a
href="https://doi.org/10.1142/S021962202050042X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ranking the strengths and weaknesses of software engineering students in software development life cycle (SDLC) process level is a challenging task owing to (1) data variation, (2) multievaluation criteria, (3) criterion importance and (4) alternative member importance. According to the existing literature, no specified procedure can rank the ability of software engineering students based on SDLC process levels to figure out the strengths and weaknesses of each student. This study aims to present a novel triplex procedure for ranking the ability of software engineering students to address the literature gap. The methodology of the proposed work is presented on the basis of three phases. In the identification phase, four steps are implemented, namely, processing dataset, identifying the criteria, distributing the courses to the software engineering body of knowledge and proposing the pre-decision matrix (DM). The data comprise the GPA and soft skills from 60 software engineering students who graduated from Universiti Pendidikan Sultan Idris in 2016. In the pre-processing phase, three steps are involved as follows. Analytic hierarchy process (AHP) is first used to assign weights to the courses and then multiply the assigned weight by courses, which is the first procedure in the proposed work. In this phase, the construction of DM is presented based on multimeasurement criteria (GPA and soft skills), with SDLC process levels as alternatives. In the development phase, AHP is used again to weight the multimeasurement criteria, and this is the second procedure. In such case, the coordinator and head of the software engineering department are consulted to obtain subjective judgments for each criterion. Technique for order performance by similarity to ideal solution (TOPSIS) is then used to rank the students, which is the third procedure. In the validation, statistical analysis is performed to validate the results by checking the accuracy of the systematic ranking. Results show that (1) integrating AHP and group TOPSIS is suitable for ranking the ability of students. (2) The 60 students are categorized into five ranking groups based on their strength level: 14 collector requirements, 13 designers, 5 programmers, 13 testers and 15 maintenances. (3) Significant differences are observed between the groups’ scores for each level of SDLC, indicating that the ranking results are identical for all levels.},
  archive      = {J_IJITDM},
  author       = {O. Zughoul and A. A. Zaidan and B. B. Zaidan and O. S. Albahri and M. Alazab and U. Amomeni and A. S. Albahri and Mahmood M. Salih and R. T. Mohammed and K. I. Mohammed and F. Momani and B. Amomeni},
  doi          = {10.1142/S021962202050042X},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {1},
  pages        = {67-135},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Novel triplex procedure for ranking the ability of software engineering students based on two levels of AHP and group TOPSIS techniques},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new enhanced ARAS method for critical path selection of
engineering projects with interval type-2 fuzzy sets. <em>IJITDM</em>,
<em>20</em>(1), 37–65. (<a
href="https://doi.org/10.1142/S0219622020500418">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Appraising the alternative among a set versus conflicting factors is taken into account as an essential issue in real-world decision problems. In this paper, a new multicriteria group decision-making (MCGDM) model is introduced with a fuzzy relative preference relation (FRPR) concept and additive ratio assessment (ARAS) method. FRPR is a useful way to reduce time complexity and to avoid pairwise comparisons. Also, a new method for determining the weights of experts by using an extension of the reference point method is presented and added to this new MCGDM model for an aggregation of the experts’ judgments. Finally, a case study about the selection problem of the engineering project in exploration and sampling projects of lead and zinc mine by decisive criteria are solved to denote the capability of the presented model. Furthermore, to illustrate the various applications of the proposed method in different decision problems, an example of literature is solved.},
  archive      = {J_IJITDM},
  author       = {Yahya Dorfeshan and Seyed Meysam Mousavi and Edmundas Kazimieras Zavadskas and Jurgita Antucheviciene},
  doi          = {10.1142/S0219622020500418},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {1},
  pages        = {37-65},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {A new enhanced ARAS method for critical path selection of engineering projects with interval type-2 fuzzy sets},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Analysis of collaboration evolution in AHP research:
1982–2018. <em>IJITDM</em>, <em>20</em>(1), 7–36. (<a
href="https://doi.org/10.1142/S0219622020500406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bibliometric analysis is effective for evaluating the merits of a given discipline. This study provides an analysis of collaboration evolution in analytic hierarchy process (AHP) research from 1982 to 2018. As an important developed approach of AHP, analytic network process (ANP) is also considered in this review. 9859 publications are harvested from Web of Science to conduct this bibliometric analysis. Country and institution are the two primary objectives to investigate the collaboration pattern of the 9859 publications. The most prolific countries and institutions are identified based on bibliometric indicators, and the collaboration relationships between connected countries or institutions are explored based on science mapping techniques. Further, a dynamic analysis is provided to investigate the collaboration evolution of AHP publications at the levels of country and institution. This study offers a new topic on the overview research of AHP publications, and could help in developing the collaboration evolution analysis in the AHP field.},
  archive      = {J_IJITDM},
  author       = {Dejian Yu and Gang Kou and Zeshui Xu and Shunshun Shi},
  doi          = {10.1142/S0219622020500406},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {1},
  pages        = {7-36},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Analysis of collaboration evolution in AHP research: 1982–2018},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021f). Editor’s introduction. <em>IJITDM</em>, <em>20</em>(1),
1–6. (<a href="https://doi.org/10.1142/S0219622021030012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJITDM},
  author       = {Yong Shi},
  doi          = {10.1142/S0219622021030012},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {1},
  pages        = {1-6},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Editor’s introduction},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
