<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IJCIA_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ijcia---29">IJCIA - 29</h2>
<ul>
<li><details>
<summary>
(2021a). Calendar of events. <em>IJCIA</em>, <em>20</em>(4),
2183004. (<a href="https://doi.org/10.1142/S1469026821830042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJCIA},
  doi          = {10.1142/S1469026821830042},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {4},
  pages        = {2183004},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Calendar of events},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal sizing and location of distributed generators for
power flow analysis in smart grid using IAS-MVPA strategy.
<em>IJCIA</em>, <em>20</em>(4), 2150027. (<a
href="https://doi.org/10.1142/S1469026821500279">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the optimal distribution generation (DG) size and location for power flow analysis at the smart grid by hybrid method are proposed. The proposed hybrid method is the Interactive Autodidactic School (IAS) and the Most Valuable Player Algorithm (MVPA) and commonly named as IAS-MVPA method. The main aim of this work is to reduce line loss and total harmonic distortion (THD), similarly, to recover the voltage profile of system through the optimal location and size of the distributed generators and optimal rearrangement of network. Here, IAS-MVPA method is utilized as a rectification tool to get the maximum DG size and the maximal reconfiguration of network at environmental load variation. In case of failure, the IAS method is utilized for maximizing the DG location. The IAS chooses the line of maximal power loss as optimal location to place the DG based on the objective function. The fault violates the equality and inequality restrictions of the safe limit system. From the control parameters, the low voltage drift is improved using the MVPA method. The low-voltage deviation has been exploited for obtaining the maximum capacity of the DG. After that, the maximum capacity is used at maximum location that improves the power flow of the system. The proposed system is performed on MATLAB/Simulink platform, and the effectiveness is assessed by comparing it with various existing processes such as generic algorithm (GA), Cuttle fish algorithm (CFA), adaptive grasshopper optimization algorithm (AGOA) and artificial neural network (ANN).},
  archive      = {J_IJCIA},
  author       = {Kumar Cherukupalli and Vijaya Anand N},
  doi          = {10.1142/S1469026821500279},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {4},
  pages        = {2150027},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Optimal sizing and location of distributed generators for power flow analysis in smart grid using IAS-MVPA strategy},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Real-time human action recognition using deep learning
architecture. <em>IJCIA</em>, <em>20</em>(4), 2150026. (<a
href="https://doi.org/10.1142/S1469026821500267">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, efficient human activity recognition (HAR) algorithm based on deep learning architecture is proposed to classify activities into seven different classes. In order to learn spatial and temporal features from only 3D skeleton data captured from a “Microsoft Kinect” camera, the proposed algorithm combines both convolution neural network (CNN) and long short-term memory (LSTM) architectures. This combination allows taking advantage of LSTM in modeling temporal data and of CNN in modeling spatial data. The captured skeleton sequences are used to create a specific dataset of interactive activities; these data are then transformed according to a view invariant and a symmetry criterion. To demonstrate the effectiveness of the developed algorithm, it has been tested on several public datasets and it has achieved and sometimes has overcome state-of-the-art performance. In order to verify the uncertainty of the proposed algorithm, some tools are provided and discussed to ensure its efficiency for continuous human action recognition in real time.},
  archive      = {J_IJCIA},
  author       = {Souhila Kahlouche and Mahmoud Belhocine and Abdallah Menouar},
  doi          = {10.1142/S1469026821500267},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {4},
  pages        = {2150026},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Real-time human action recognition using deep learning architecture},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive optimization-enabled neural networks to handle the
imbalance churn data in churn prediction. <em>IJCIA</em>,
<em>20</em>(4), 2150025. (<a
href="https://doi.org/10.1142/S1469026821500255">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The churn prediction based on telecom data has been paid great attention because of the increasing the number telecom providers, but due to inconsistent data, sparsity, and hugeness, the churn prediction becomes complicated and challenging. Hence, an effective and optimal prediction of churns mechanism, named adaptive firefly-spider optimization (adaptive FSO) algorithm, is proposed in this research to predict the churns using the telecom data. The proposed churn prediction method uses telecom data, which is the trending domain of research in predicting the churns; hence, the classification accuracy is increased. However, the proposed adaptive FSO algorithm is designed by integrating the spider monkey optimization (SMO), firefly optimization algorithm (FA), and the adaptive concept. The input data is initially given to the master node of the spark framework. The feature selection is carried out using Kendall’s correlation to select the appropriate features for further processing. Then, the selected unique features are given to the master node to perform churn prediction. Here, the churn prediction is made using a deep convolutional neural network (DCNN), which is trained by the proposed adaptive FSO algorithm. Moreover, the developed model obtained better performance using the metrics, like dice coefficient, accuracy, and Jaccard coefficient by varying the training data percentage and selected features. Thus, the proposed adaptive FSO-based DCNN showed improved results with a dice coefficient of 99.76%, accuracy of 98.65%, Jaccard coefficient of 99.52%.},
  archive      = {J_IJCIA},
  author       = {Bharathi Garimella and G. V. S. N. R. V. Prasad and M. H. M. Krishna Prasad},
  doi          = {10.1142/S1469026821500255},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {4},
  pages        = {2150025},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Adaptive optimization-enabled neural networks to handle the imbalance churn data in churn prediction},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Quadratic convex reformulation for solving task assignment
problem with continuous hopfield network. <em>IJCIA</em>,
<em>20</em>(4), 2150024. (<a
href="https://doi.org/10.1142/S1469026821500243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research is an optimal allocation of tasks to processors in order to minimize the total costs of execution and communication. This problem is called the Task Assignment Problem (TAP) with nonuniform communication costs. To solve the latter, the first step concerns the formulation of the problem by an equivalent zero-one quadratic program with a convex objective function using a convexification technique, based on the smallest eigenvalue. The second step concerns the application of the Continuous Hopfield Network (CHN) to solve the obtained problem. The calculation results are presented for the instances from the literature, compared to solutions obtained both the CPLEX solver and by the heuristic genetic algorithm, and show an improvement in the results obtained by applying only the CHN algorithm. We can see that the proposed approach evaluates the efficiency of the theoretical results and achieves the optimal solutions in a short calculation time.},
  archive      = {J_IJCIA},
  author       = {Youssef Hami and Chakir Loqman},
  doi          = {10.1142/S1469026821500243},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {4},
  pages        = {2150024},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Quadratic convex reformulation for solving task assignment problem with continuous hopfield network},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Human emotion recognition using polar-based lagged poincare
plot indices of eye-blinking data. <em>IJCIA</em>, <em>20</em>(4),
2150023. (<a href="https://doi.org/10.1142/S1469026821500231">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion recognition using bio-signals is currently a hot and challenging topic in human–computer interferences, robotics, and affective computing. A broad range of literature has been published by analyzing the internal/external behaviors of the subjects in confronting emotional events/stimuli. Eye movements, as an external behavior, are frequently used in the multi-modal emotion recognition system. On the other hand, classic statistical features of the signal have generally been assessed, and the evaluation of its dynamics has been neglected so far. For the first time, the dynamics of single-modal eye-blinking data are characterized. Novel polar-based indices of the lagged Poincare plots were introduced. The optimum lag was estimated using mutual information. After reconstruction of the plot, the polar measures of all points were characterized using statistical measures. The support vector machine (SVM), decision tree, and Naïve Bayes were implemented to complete the process of classification. The highest accuracy of 100% with an average accuracy of 84.17% was achieved for fear/sad discrimination using SVM. The suggested framework provided outstanding performances in terms of recognition rates, simplicity of the methodology, and less computational cost. Our results also showed that eye-blinking data possesses the potential for emotion recognition, especially in classifying fear emotion.},
  archive      = {J_IJCIA},
  author       = {Atefeh Goshvarpour and Ateke Goshvarpour},
  doi          = {10.1142/S1469026821500231},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {4},
  pages        = {2150023},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Human emotion recognition using polar-based lagged poincare plot indices of eye-blinking data},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimization of interval type-2 intuitionistic fuzzy logic
system for prediction problems. <em>IJCIA</em>, <em>20</em>(4), 2150022.
(<a href="https://doi.org/10.1142/S146902682150022X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Derivative-based algorithms have been adopted in the literature for the optimization of membership and non-membership function parameters of interval type-2 (T2) intuitionistic fuzzy logic systems (FLSs). In this study, a non-derivative-based algorithm called sliding mode control learning algorithm is proposed to tune the parameters of interval T2 intuitionistic FLS for the first time. The proposed rule-based learning system employs the Takagi–Sugeno–Kang inference with artificial neural network to pilot the learning process. The new learning system is evaluated using some nonlinear prediction problems. Analyses of results reveal that the proposed learning apparatus outperforms its type-1 version and many existing solutions in the literature and competes favorably with others on the investigated problem instances with low cost in terms of running time.},
  archive      = {J_IJCIA},
  author       = {Imo Eyoh and Jeremiah Eyoh and Uduak Umoh and Roy Kalawsky},
  doi          = {10.1142/S146902682150022X},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {4},
  pages        = {2150022},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Optimization of interval type-2 intuitionistic fuzzy logic system for prediction problems},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). FUSIONET: A hybrid model towards image classification.
<em>IJCIA</em>, <em>20</em>(4), 2150021. (<a
href="https://doi.org/10.1142/S1469026821500218">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image classification, a topic of pattern recognition in computer vision, is an approach of classification based on contextual information in images. Contextual here means this approach is focusing on the relationship of the nearby pixels also called neighborhood. An open topic of research in computer vision is to devise an effective means of transferring human’s informal knowledge into computers, such that computers can also perceive their environment. However, the occurrence of object with respect to image representation is usually associated with various features of variation causing noise in the image representation. Hence, it tends to be very difficult to actually disentangle these abstract factors of influence from the principal object. In this paper, we have proposed a hybrid model: FUSIONET, which has been modeled for studying and extracting meaning facts from images. Our proposition combines two distinct stack of convolution operation (3 × 3 and 1 × 1, respectively). Successively, these relatively low-feature maps from the above operation are fed as input to a downstream classifier for classification of the image in question.},
  archive      = {J_IJCIA},
  author       = {Molokwu C. Reginald and Molokwu C. Bonaventure and Molokwu C. Victor and Okeke C. Ogochukwu},
  doi          = {10.1142/S1469026821500218},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {4},
  pages        = {2150021},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {FUSIONET: A hybrid model towards image classification},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Calendar of events. <em>IJCIA</em>, <em>20</em>(3),
2183003. (<a href="https://doi.org/10.1142/S1469026821830030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJCIA},
  doi          = {10.1142/S1469026821830030},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {3},
  pages        = {2183003},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Calendar of events},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Discrete social spider algorithm for solving traveling
salesman problem. <em>IJCIA</em>, <em>20</em>(3), 2150020. (<a
href="https://doi.org/10.1142/S1469026821500206">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Social Spider Algorithm (SSA) was introduced based on the information-sharing foraging strategy of spiders to solve the continuous optimization problems. SSA was shown to have better performance than the other state-of-the-art meta-heuristic algorithms in terms of best-achieved fitness values, scalability, reliability, and convergence speed. By preserving all strengths and outstanding performance of SSA, we propose a novel algorithm named Discrete Social Spider Algorithm (DSSA), for solving discrete optimization problems by making some modifications to the calculation of distance function, construction of follow position, the movement method, and the fitness function of the original SSA. DSSA is employed to solve the symmetric and asymmetric traveling salesman problems. To prove the effectiveness of DSSA, TSPLIB benchmarks are used, and the results have been compared to the results obtained by six different optimization methods: discrete bat algorithm (IBA), genetic algorithm (GA), an island-based distributed genetic algorithm (IDGA), evolutionary simulated annealing (ESA), discrete imperialist competitive algorithm (DICA) and a discrete firefly algorithm (DFA). The simulation results demonstrate that DSSA outperforms the other techniques. The experimental results show that our method is better than other evolutionary algorithms for solving the TSP problems. DSSA can also be used for any other discrete optimization problem, such as routing problems.},
  archive      = {J_IJCIA},
  author       = {Asieh Khosravanian and Mohammad Rahmanimanesh and Parviz Keshavarzi},
  doi          = {10.1142/S1469026821500206},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {3},
  pages        = {2150020},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Discrete social spider algorithm for solving traveling salesman problem},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A real-time approach for automatic food quality assessment
based on shape analysis. <em>IJCIA</em>, <em>20</em>(3), 2150019. (<a
href="https://doi.org/10.1142/S146902682150019X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Products sorting is a task of paramount importance for many countries’ agricultural industry. An accurate quality check assures that good products are not wasted, and rotten, broken and bent food are properly discarded, which is extremely important for food production chains. Such products sorting and quality controls are often performed with consolidated instruments, since simple systems are easier to maintain, validate, and they speed up the processing in terms of production line speed and products per second. Moreover, industries often lack advanced formation, required for more sophisticated solutions. As a result, the sorting task for many food products is mainly done by color information only. Sorting machines typically detect the color response of products to specific LEDs with various light wavelengths. Unfortunately, a color check is often not enough to detect some very common defects. The shape of a product, instead, reveals many important defects and is highly reliable in detecting external objects mixed with food. Also, shape can be used to take detailed measurements of a product, such as its area, length, width, anisotropy, etc. This paper proposes a complete treatment of the problem of sorting food by its shape. It treats real-world problems such as accuracy, execution time, latency and it provides an overview of a full system used on state-of-the-art measurement machines.},
  archive      = {J_IJCIA},
  author       = {Luca Donati and Eleonora Iotti and Andrea Prati},
  doi          = {10.1142/S146902682150019X},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {3},
  pages        = {2150019},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {A real-time approach for automatic food quality assessment based on shape analysis},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A method of environmental sound classification based on
residual networks and data augmentation. <em>IJCIA</em>, <em>20</em>(3),
2150018. (<a href="https://doi.org/10.1142/S1469026821500188">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Environmental sound classification (ESC) is a challenging problem due to the complexity of sounds. To date, a variety of signal processing and machine learning techniques have been applied to ESC task, including matrix factorization, dictionary learning, wavelet filterbanks and deep neural networks. It is observed that features extracted from deeper networks tend to achieve higher performance than those extracted from shallow networks. However, in ESC task, only the deep convolutional neural networks (CNNs) which contain several layers are used and the residual networks are ignored, which lead to degradation in the performance. Meanwhile, a possible explanation for the limited exploration of CNNs and the difficulty to improve on simpler models is the relative scarcity of labeled data for ESC. In this paper, a residual network called EnvResNet for the ESC task is proposed. In addition, we propose to use audio data augmentation to overcome the problem of data scarcity. The experiments will be performed on the ESC-50 database. Combined with data augmentation, the proposed model outperforms baseline implementations relying on mel-frequency cepstral coefficients and achieves results comparable to other state-of-the-art approaches in terms of classification accuracy.},
  archive      = {J_IJCIA},
  author       = {Jinfang Zeng and Youming Li and Yu Zhang and Da Chen},
  doi          = {10.1142/S1469026821500188},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {3},
  pages        = {2150018},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {A method of environmental sound classification based on residual networks and data augmentation},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Instrument identification technology based on deep learning.
<em>IJCIA</em>, <em>20</em>(3), 2150017. (<a
href="https://doi.org/10.1142/S1469026821500176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous improvement of science and technology, the substation remote control system has been constantly improved, which provides the possibility for the complete realization of intelligent and unmanned substation. However, due to the special substation environment, it is easy to cause interference, coupled with the low accuracy of today’s video image processing algorithm, which leads to the frequent occurrence of false alarms and missing alarms. Manual intervention is needed to deal with this, which inhibits the display of automatic intelligent substation processing functions. Therefore, in this paper, the most rapidly developed machine learning algorithm — deep learning is applied to the substation instrument equipment identification processing, in order to improve the accuracy and efficiency of instrument equipment identification, and make due contributions to the full realization of unattended substation.},
  archive      = {J_IJCIA},
  author       = {Yunhai Song and Zhenzhen Zhou and Hourong Zhang and Haohui Su and Han Zhang and Qi Wang},
  doi          = {10.1142/S1469026821500176},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {3},
  pages        = {2150017},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Instrument identification technology based on deep learning},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The exploitation of distance distributions for clustering.
<em>IJCIA</em>, <em>20</em>(3), 2150016. (<a
href="https://doi.org/10.1142/S1469026821500164">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although distance measures are used in many machine learning algorithms, the literature on the context-independent selection and evaluation of distance measures is limited in the sense that prior knowledge is used. In cluster analysis, current studies evaluate the choice of distance measure after applying unsupervised methods based on error probabilities, implicitly setting the goal of reproducing predefined partitions in data. Such studies use clusters of data that are often based on the context of the data as well as the custom goal of the specific study. Depending on the data context, different properties for distance distributions are judged to be relevant for appropriate distance selection. However, if cluster analysis is based on the task of finding similar partitions of data, then the intrapartition distances should be smaller than the interpartition distances. By systematically investigating this specification using distribution analysis through the mirrored-density (MD plot), it is shown that multimodal distance distributions are preferable in cluster analysis. As a consequence, it is advantageous to model distance distributions with Gaussian mixtures prior to the evaluation phase of unsupervised methods. Experiments are performed on several artificial datasets and natural datasets for the task of clustering.},
  archive      = {J_IJCIA},
  author       = {Michael C. Thrun},
  doi          = {10.1142/S1469026821500164},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {3},
  pages        = {2150016},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {The exploitation of distance distributions for clustering},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Heuristic-assisted BERT for twitter sentiment analysis.
<em>IJCIA</em>, <em>20</em>(3), 2150015. (<a
href="https://doi.org/10.1142/S1469026821500152">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The identification of opinions and sentiments from tweets is termed as “Twitter Sentiment Analysis (TSA)”. The major process of TSA is to determine the sentiment or polarity of the tweet and then classifying them into a negative or positive tweet. There are several methods introduced for carrying out TSA, however, it remains to be challenging due to slang words, modern accents, grammatical and spelling mistakes, and other issues that could not be solved by existing techniques. This work develops a novel customized BERT-oriented sentiment classification that encompasses two main phases: pre-processing and tokenization, and a “Customized Bidirectional Encoder Representations from Transformers (BERT)”-based classification. At first, the gathered raw tweets are pre-processed under stop-word removal, stemming and blank space removal. After pre-processing, the semantic words are obtained, from which the meaningful words (tokens) are extracted in the tokenization phase. Consequently, these extracted tokens are classified via optimized BERT, where biases and weight are tuned optimally by Particle-Assisted Circle Updating Position (PA-CUP). Moreover, the maximal sequence length of the BERT encoder is updated using standard PA-CUP. Finally, the performance analysis is carried out to substantiate the enhancement of the proposed model.},
  archive      = {J_IJCIA},
  author       = {Gokul Yenduri and B. R. Rajakumar and K. Praghash and D. Binu},
  doi          = {10.1142/S1469026821500152},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {3},
  pages        = {2150015},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Heuristic-assisted BERT for twitter sentiment analysis},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). Calendar of events. <em>IJCIA</em>, <em>20</em>(2),
2183002. (<a href="https://doi.org/10.1142/S1469026821830029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJCIA},
  doi          = {10.1142/S1469026821830029},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {2},
  pages        = {2183002},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Calendar of events},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multi-swarm ABC algorithm for parameters optimization of
SOFM neural network in dynamic environment. <em>IJCIA</em>,
<em>20</em>(2), 2150014. (<a
href="https://doi.org/10.1142/S1469026821500140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-organizing feature map (SOFM) neural network is a kind of competitive unsupervised learning neural network, which has strong self-organizing and self-learning capabilities. It has been widely used in the fields of data classification and data clustering. A crucial step for SOFM neural network is to set its weight parameters correctly because the output accuracy and efficiency of the network depend much on these parameters. Most of current methods for parameter setting are based on static data. However, in a dynamic environment, the statistical characteristics of the generated data will change unpredictably over time. If the SOFM network cannot react to the changes of the environment, its performance will degrade. To deal with this problem, a more powerful multi-swarm artificial bee colony algorithm (MABC) is proposed. In the algorithm, the classic ABC algorithm is improved with multi-swarm and exclusive operation strategies to make it suitable for tracking optimal parameter settings of the SOFM network, so that the SOFM network can be applied to a dynamic environment. Two real data streams, which are regarded as coming from dynamic environments, are used to evaluate the effectiveness of the algorithm. Results show that the proposed algorithm is superior to the classic SOFM algorithm in terms of clustering purity and effectiveness. It is a promising method for the classification of data streams from dynamic environments.},
  archive      = {J_IJCIA},
  author       = {Dongli Jia and Fan Li and Jun Tu},
  doi          = {10.1142/S1469026821500140},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {2},
  pages        = {2150014},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {A multi-swarm ABC algorithm for parameters optimization of SOFM neural network in dynamic environment},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Regularized semi-supervised metric learning with latent
structure preserved. <em>IJCIA</em>, <em>20</em>(2), 2150013. (<a
href="https://doi.org/10.1142/S1469026821500139">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metric learning is a critical problem in classification. Most classifiers are based on a metric, the simplest one is the KNN classifier, whose outcome is directly decided by the given metric. This paper will discuss semi-supervised metric learning. Most traditional semi-supervised metric learning algorithms preserve the local structure of all the samples (including labeled and unlabeled) in the input space, when making the same labeled samples together and separating different labeled samples. In most existing methods, the local structure is calculated by the Euclidean distance which uses all the features. As we all know, high dimensional data lies on a low dimension manifold, and not all the features are discriminative. Thus, in this paper, we try to explore the latent structure of the samples and use the more discriminative features to calculate the local structure. The latent structure is learned by clustering random forest and cast into similarity between samples. Based on the hierarchical structure of the trees and the split function, the similarity is obtained from discriminant features. Experimental results on public data sets show our algorithm outperforms the traditional similar related algorithms.},
  archive      = {J_IJCIA},
  author       = {Qianying Wang and Ming Lu and Meng Li and Fei Guan},
  doi          = {10.1142/S1469026821500139},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {2},
  pages        = {2150013},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Regularized semi-supervised metric learning with latent structure preserved},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). GA2RM: A GA-based action rule mining method. <em>IJCIA</em>,
<em>20</em>(2), 2150012. (<a
href="https://doi.org/10.1142/S1469026821500127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Action Mining is a subfield of Data Mining that tries to extract actions from traditional data sets. Action Rule is a type of rule that suggests some changes in its consequent part. Extracting action rules from data has been one of the research interests in recent years. Current state-of-the-art action rule mining methods like DEAR typically take classification rules as their input; Since traditional classification methods have been designed for prediction and not for manipulation, therefore extracting action rules directly from data can result in more valuable action rules. Here, we have proposed a method to generate action rules directly from data. To tackle the problem of huge search space of action rules, a Genetic Algorithm has been devised. Different metrics have been defined for investigating the effectiveness of our proposed method and a large number of experiments have been done on real and synthetic data sets. The results show that our method can find from 20% to 10 times more interesting (in case of support and confidence) action rules in comparison with its competitors.},
  archive      = {J_IJCIA},
  author       = {Shervin Hashemi and Pirooz Shamsinejad},
  doi          = {10.1142/S1469026821500127},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {2},
  pages        = {2150012},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {GA2RM: A GA-based action rule mining method},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel adaptive sampling strategy for deep reinforcement
learning. <em>IJCIA</em>, <em>20</em>(2), 2150011. (<a
href="https://doi.org/10.1142/S1469026821500115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning, as an effective method to solve complex sequential decision-making problems, plays an important role in areas such as intelligent decision-making and behavioral cognition. It is well known that the sample experience replay mechanism contributes to the development of current deep reinforcement learning by reusing past samples to improve the efficiency of samples. However, the existing priority experience replay mechanism changes the sample distribution in the sample set due to the higher sampling frequency assigned to a specific transition, and it cannot be applied to actor-critic and other on-policy reinforcement learning algorithm. To address this, we propose an adaptive factor based on TD-error, which further increases sample utilization by giving more attention weight to samples of larger TD-error, and embeds it flexibly into the original Deep Q Network and Advantage Actor-Critic algorithm to improve their performance. Then we carried out the performance evaluation for the proposed architecture in the context of CartPole-V1 and 6 environments of Atari game experiments, respectively, and the obtained results either on the conditions of fixed temperature or annealing temperature, when compared to those produced by the vanilla DQN and original A2C, highlight the advantages in cumulative rewards and climb speed of the improved algorithms.},
  archive      = {J_IJCIA},
  author       = {Xingxing Liang and Li Chen and Yanghe Feng and Zhong Liu and Yang Ma and Kuihua Huang},
  doi          = {10.1142/S1469026821500115},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {2},
  pages        = {2150011},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {A novel adaptive sampling strategy for deep reinforcement learning},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stretch sensor-based facial expression recognition and
classification using machine learning. <em>IJCIA</em>, <em>20</em>(2),
2150010. (<a href="https://doi.org/10.1142/S1469026821500103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sensor-based Facial expression recognition (FER) is an attractive research topic. Nowadays, FER is used for different application such as smart environments and healthcare solutions. The machine can learn human emotion by using FER technology. It is the primary and essential for quantitative analysis of human sentiments. FER is an image recognition problem within the broader field of computer vision. Face detection and tracking, reliable face recognition still present a considerable challenge for researchers in computer vision and pattern recognition. First, data processing and analytics are intensive and require a large number of computation resources and memory. Second, the fundamental technical limitation is its robustness in changes in the environment. Finally, illumination variation further complicates the design of robust algorithms because of changes in shadow casts. However, sensor-based FER overcomes all these limitations. Sensor technologies, especially low-power, wireless communication, high-capacity, and data processing have made substantial progress, making it possible for sensors to evolve from low-level data collection and transmission to high-level inference. This study aims to develop a stretchable sensor-based FER system. We use random forest machine learning algorithms used for training the FER model. Commercial stretchable facial expression dataset is simulated into the anaconda software. In this research, our stretch sensor FER dataset obtained around 95% accuracy for four different emotions (Neutral, Happy, Sad, and Disgust).},
  archive      = {J_IJCIA},
  author       = {Chowdhury Mohammad Masum Refat and Norsinnira Zainul Azlan},
  doi          = {10.1142/S1469026821500103},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {2},
  pages        = {2150010},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Stretch sensor-based facial expression recognition and classification using machine learning},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Decision support system based on fuzzy logic for assessment
of expected corporate income performance. <em>IJCIA</em>,
<em>20</em>(2), 2150009. (<a
href="https://doi.org/10.1142/S1469026821500097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a decision-support method to estimate the next year performance of corporate Operating Income Margin (OIM). It is based on a unique combination of cross-section model and the rules-based evaluation mechanism. The estimate is done in terms of broad categories, and not precise numerical values. The model is constructed as follows: its dependent variable (OIM) is one year ahead vs. the corresponding explanatory variables. This structure of the model allows us to view explanatory variables as reflecting financial potential of corporations. The evaluation component consists of a set of rules designed to identify the companies whose “potential” clearly points to an opportunity to invest. For the method presented here to succeed, it is necessary to utilize a highly reliable modeling method, even if it is “Fuzzy”. We apply Soft Regression (SR), which is a Soft Computing modeling tool based on Fuzzy Logic, and utilize all available proxy variables by creating intervals of values. Advantages of utilizing SR, and the intervals’-based modeling are extensively discussed. Modeling results for five consecutive years are consistent and stable, thus indicating high degree of reliability. Testing indicates very high success rate for the stock market related domain, the lowest being 87.9%.},
  archive      = {J_IJCIA},
  author       = {Arthur Yosef and Eli Shnaider and Rimona Palas and Amos Baranes},
  doi          = {10.1142/S1469026821500097},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {2},
  pages        = {2150009},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Decision support system based on fuzzy logic for assessment of expected corporate income performance},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021d). Calendar of events. <em>IJCIA</em>, <em>20</em>(1),
2183001. (<a href="https://doi.org/10.1142/S1469026821830017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJCIA},
  doi          = {10.1142/S1469026821830017},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2183001},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Calendar of events},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hybrid fuzzy-genetic model for fitness-based performance
optimization in wireless networks. <em>IJCIA</em>, <em>20</em>(1),
2150008. (<a href="https://doi.org/10.1142/S1469026821500085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent times, the application of autonomic soft computing techniques for design and optimization of wireless access networks is progressively becoming prevalent. These computational learning techniques are capable of handling uncertain and imprecise networking information while driving toward the optimal solution set in the problem search space. The approach proposed by this paper presents the application of the fuzzy logic inference combined with the evolutionary genetic algorithm to optimize the performance parameters in wireless networks. In particular, we consider optimal bit rate allocation and transmission power consumption through the joint design of fuzzy-genetic modeling framework. The sample training data generated through simulations of IEEE 802.11 wireless access network are analyzed for optimization by supplying it to the expert hybrid model comprising of the conjunctive design of both the computational intelligent techniques. Specifically, we contemplate the binary encoding scheme, single-point crossover, reversing mutation, and two fitness functions for executing the binary genetic operations of crossover and mutation. It is generally observed that the proposed hybrid model with polynomial fitness function yields better performance with scalable network datasets than the logarithmic fitness function in terms of higher objective value. Moreover, the results obtained through simulation experiments exhibit significant throughput gains and power efficiency for the deployed fitness functions with the evolving size of training dataset. Compared with the existing methods, our hybrid learning model demonstrates performance enhancement with higher expected fitness measure, improved throughput and power efficiency.},
  archive      = {J_IJCIA},
  author       = {Ridhima Mehta},
  doi          = {10.1142/S1469026821500085},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2150008},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Hybrid fuzzy-genetic model for fitness-based performance optimization in wireless networks},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Performance analysis using a deep belief network by a
self-organizing map. <em>IJCIA</em>, <em>20</em>(1), 2150007. (<a
href="https://doi.org/10.1142/S1469026821500073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since resource consumption is the main reason for software aging occurrences, many methods have been applied to accurately predict the resource consumption series. Among these methods, neural networks are powerfully applied to forecast the series data. For some existing problems of artificial neural networks such as the choice of initialization and local optimization, the improvements of neural networks are not only a hot research topic in the field of time series prediction but also a research hotspot in resource consumption prediction of software aging. In this paper, we propose a method for resource consumption prediction of software aging using deep belief nets (DBNs) with the restricted Boltzmann machine (RBM). This presented method contains the following steps. First, a pre-processing is introduced by two parts: smoothing data by a self-organizing map (SOM) and removing a linear trend by a difference method. Second, a method, DBN with two RBMs, is presented to capture the features and forecast future values. Third, a glowworm swarm optimization (GSO) method is used to learn the hyper-parameters of DBN with two RBMs. In the experiments, two types of resource consumption series are used to validate our proposed method compared with some state-of-the-art algorithms.},
  archive      = {J_IJCIA},
  author       = {Yongquan Yan and Yu Zhu and Yanjun Li},
  doi          = {10.1142/S1469026821500073},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2150007},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Performance analysis using a deep belief network by a self-organizing map},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A computer vision-based method for classification of red
meat quality after nitrosamine appendage. <em>IJCIA</em>,
<em>20</em>(1), 2150005. (<a
href="https://doi.org/10.1142/S146902682150005X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nitrosamine is a carcinogenic chemical used as a preservative in red meat whose identification is an ordeal. This paper presents a computer vision-based non-destructive method for identifying quality disparities between preservative treated and untreated (control) red meat. To access the discrepancy in the quality of red meat, both traditional machine learning and deep learning-based methods have been used. Support vector machine (SVM) classifier and artificial neural network (ANN) models have been used to detect the presence of nitrosamine in test samples. The paper also made use of different pre-trained deep convolutional neural networks (DCNN) with transfer learning approach such as ResNet-34, ResNet-50, ResNet-101, VGG-16, VGG-19, AlexNet and MobileNetv2 to examine the presence of nitrosamine in the food samples. While the ANN classifier performed better in comparison to the SVM classifier, the highest testing accuracy and F1-score were obtained using the deep learning model, ResNet-101 with 95.45% and 96.54%, respectively. The experimental results demonstrate an improved performance in comparison to the existing methods; indicating the feasibility of the proposed work for food quality control in real-time applications.},
  archive      = {J_IJCIA},
  author       = {Monika Arora and Parthasarathi Mangipudi},
  doi          = {10.1142/S146902682150005X},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2150005},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {A computer vision-based method for classification of red meat quality after nitrosamine appendage},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Supervised retinal vessel segmentation based average filter
and iterative self organizing data analysis technique. <em>IJCIA</em>,
<em>20</em>(1), 2150003. (<a
href="https://doi.org/10.1142/S1469026821500036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinal fundus is the inner surface of the eye associated with the lens. The identification of disease needs some parts of retinal fundus, such as blood vessel. Blood vessels are part of circulation system which functions to supply blood to retina area. This research proposed a method for segmentation of blood vessel in retinal image with Average Filter and Iterative Self-Organizing Data Analysis (ISODATA) Technique. The first step with the input image changed to Gamma Correction, increasing contrast with Contrast Limited Adaptive Histogram Equalization (CLAHE), the filtering process with Average Filter. The segmentation is used for ISODATA. Region of Interest was applied to take the center of a vessel object and remove the background. In the final stage, the process of noise reduction and removal of small pixel values with Median Filter and Closing Morphology. Datasets used in this research were DRIVE and STARE. The average result was obtained for STARE dataset with an accuracy of 94.41%, Sensitivity of 55.57%, Specification of 98.31%, F1 Score of 64.81% while for the DRIVE dataset with accuracy of 94.78%, Sensitivity of 43.46%, Specification of 99.81%, and F1 Score of 59.39%.},
  archive      = {J_IJCIA},
  author       = {Erwin and Heranti Reza Damayanti},
  doi          = {10.1142/S1469026821500036},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2150003},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Supervised retinal vessel segmentation based average filter and iterative self organizing data analysis technique},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Gradient descent optimization algorithms for decoding SCMA
signals. <em>IJCIA</em>, <em>20</em>(1), 2150002. (<a
href="https://doi.org/10.1142/S1469026821500024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, technologies based on neural networks (NNs) and deep learning have improved in different areas of Science such as wireless communications. This study demonstrates the applicability of NN-based receivers for detecting and decoding sparse code multiple access (SCMA) codewords. The simulation results reveal that the proposed receiver provides highly accurate predictions based on new data. Moreover, the performance analysis results of the primary optimization algorithms used in machine learning are presented in this study.},
  archive      = {J_IJCIA},
  author       = {Sergio Vidal-Beltrán and José Luis López Bonilla and Fernando Martínez Piñón and Jesús Yalja-Montiel},
  doi          = {10.1142/S1469026821500024},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2150002},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Gradient descent optimization algorithms for decoding SCMA signals},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). One-class fault detection using multi-layer elm-based
auto-encoder. <em>IJCIA</em>, <em>20</em>(1), 2150001. (<a
href="https://doi.org/10.1142/S1469026821500012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new approach for one-class fault detection trained only by normal samples has been proposed in this paper. The approach contains multi-anterior-layers for feature extraction and one post-layer for one-class classification. The multi-anterior-layers are based on extreme learning machine-based auto-encoder (ELM-AE). Multi-ELM-AEs are stacked in the front hidden layers to extract abstract features from the raw input. The post-layer is based on the reconstruction error-based ELM-AE (Re-ELM-AE) to act as one-class classifier. As the extension of ELM-AE, the decision threshold and function are given in the Re-ELM-AE, which are utilized to identify whether the test sample is faulty. The efficacy of the presented algorithm is demonstrated on a mathematic example and fault dataset from motor bearing. The method has been compared with shallow learning methods such as one-class support vector machine (OCSVM), the Re-ELM-AE, and one multi-layer neural network named stacked auto-encoder (SAE). The experiment results show that the proposed method outperforms OCSVM and Re-ELM-AE in classification accuracy. Though the classification accuracy of the proposed method and SAE is similar, the training and testing time of the proposed method is much lower than SAE.},
  archive      = {J_IJCIA},
  author       = {Li Wuke and Yin Guangluan and Chen Xiaoxiao},
  doi          = {10.1142/S1469026821500012},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2150001},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {One-class fault detection using multi-layer elm-based auto-encoder},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
