<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IDA_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ida---86">IDA - 86</h2>
<ul>
<li><details>
<summary>
(2021). Multidimensional indexing technique for medical images
retrieval. <em>IDA</em>, <em>25</em>(6), 1629–1666. (<a
href="https://doi.org/10.3233/IDA-205495">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retrieving required medical images from a huge amount of images is one of the most widely used features in medical information systems, including medical imaging search engines. For example, diagnostic decision making has traditionally been accompanied by patient data (image or non-image) and previ ous medical experiences from similar cases. Indexing as part of search engines (or retrieval system), increases the speed of a search. The goal of this study, is to provide an effective and efficient indexing technique for medical images search engines. In this paper, in order to archive this goal, a multidimensional indexing technique for medical images is designed using the normalization technique that is used to reduce redundancy in relational database design. Data structure of the proposed multidimensional index and also different required operations are designed to create and handle such a multidimensional index. Time complexity of each operation is analyzed and also average memory space required to store any medical image (along with its related metadata) is calculated as the space complexity analysis of the proposed indexing technique. The results show that the proposed indexing technique has a good performance in terms of memory usage, as well as execution time for the usual operations. Moreover, and may be more important, the proposed indexing techniques improves the precision and recall of the information retrieval system (i.e., search engine) which uses this technique for indexing medical images. Besides, a user of such search engine can retrieve medical images which s/he has specified its attributes is some different aspects (dimensions), e.g., tissue, image modality and format, sickness and trauma, etc. So, the proposed multidimensional indexing techniques can improve effectiveness of a medical image information retrieval system (in terms of precision and recall), while having a proper efficiency (in terms of execution time and memory usage), and can improve the information retrieval process for healthcare search engines.},
  archive      = {J_IDA},
  author       = {Safaei, Ali Asghar and Habibi-Asl, Saeede},
  doi          = {10.3233/IDA-205495},
  journal      = {Intelligent Data Analysis},
  month        = {10},
  number       = {6},
  pages        = {1629-1666},
  shortjournal = {Intell. Data Anal.},
  title        = {Multidimensional indexing technique for medical images retrieval},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Attention mechanism based LSTM in classification of stressed
speech under workload. <em>IDA</em>, <em>25</em>(6), 1603–1627. (<a
href="https://doi.org/10.3233/IDA-205429">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to improve the robustness of speech recognition systems, this study attempts to classify stressed speech caused by the psychological stress under multitasking workloads. Due to the transient nature and ambiguity of stressed speech, the stress characteristics is not represented in all the s egments in stressed speech as labeled. In this paper, we propose a multi-feature fusion model based on the attention mechanism to measure the importance of segments for stress classification. Through the attention mechanism, each speech frame is weighted to reflect the different correlations to the actual stressed state, and the multi-channel fusion of features characterizing the stressed speech to classify the speech under stress. The proposed model further adopts SpecAugment in view of the feature spectrum for data augment to resolve small sample sizes problem among stressed speech. During the experiment, we compared the proposed model with traditional methods on CASIA Chinese emotion corpus and Fujitsu stressed speech corpus, and results show that the proposed model has better performance in speaker-independent stress classification. Transfer learning is also performed for speaker-dependent classification for stressed speech, and the performance is improved. The attention mechanism shows the advantage for continuous speech under stress in authentic context comparing with traditional methods.},
  archive      = {J_IDA},
  author       = {Yao, Xiao and Sheng, Zhengyan and Gu, Min and Wang, Haibin and Xu, Ning and Liu, Xiaofeng},
  doi          = {10.3233/IDA-205429},
  journal      = {Intelligent Data Analysis},
  month        = {10},
  number       = {6},
  pages        = {1603-1627},
  shortjournal = {Intell. Data Anal.},
  title        = {Attention mechanism based LSTM in classification of stressed speech under workload},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Forecasting emergency department admissions. <em>IDA</em>,
<em>25</em>(6), 1579–1601. (<a
href="https://doi.org/10.3233/IDA-205390">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergency department of a hospital plays an extremely important role in the healthcare of patients. To maintain a high quality service, clinical professionals need information on how patient flow will evolve in the immediate future. With accurate emergency department forecasts it is possible to better manage available human resources by allocating clinical staff before peak periods, thus preventing service congestion, or releasing clinical staff at less busy times. This paper describes a solution developed for the presentation of hourly, four-hour, eight-hour and daily number of admissions to a hospital’s emergency department. A 10-year history (2009–2018) of the number of emergency admissions in a Portuguese hospital was used. To create the models several methods were tested, including exponential smoothing, SARIMA, autoregressive and recurrent neural network, XGBoost and ensemble learning. The models that generated the most accurate hourly time predictions were the recurrent neural network with one-layer (sMAPE = 23.26%) and with three layers (sMAPE = 23.12%) and XGBoost (sMAPE = 23.70%). In terms of efficiency, the XGBoost method has by far outperformed all others. The success of the recurrent neuronal network and XGBoost machine learning methods applied to the prediction of the number of emergency department admissions has been demonstrated here, with an accuracy that surpasses the models found in the literature.},
  archive      = {J_IDA},
  author       = {Rocha, Carlos Narciso and Rodrigues, Fátima},
  doi          = {10.3233/IDA-205390},
  journal      = {Intelligent Data Analysis},
  month        = {10},
  number       = {6},
  pages        = {1579-1601},
  shortjournal = {Intell. Data Anal.},
  title        = {Forecasting emergency department admissions},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An improved YOLOv3 model for detecting location information
of ovarian cancer from CT images. <em>IDA</em>, <em>25</em>(6),
1565–1578. (<a href="https://doi.org/10.3233/IDA-205542">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ovarian cancer is a malignant tumor that poses a serious threat to women’s lives. Computer-aided diagnosis (CAD) systems can classify the type of ovarian tumors, but few of them can provide exactly the location information of ovarian cancer cells. Recently, deep learning technology becomes hot for automatic detection of cancer cells, particularly for detecting their locations. In this work, we propose a novel end-to-end network YOLO-OC (Ovarian cancer) model, which can extract the characteristics of ovarian cancer more efficiently. In our method, deformable convolution is used to enhance the model’s ability to learn geometric deformation in space. Squeeze-and-Excitation (SE) module is proposed to automatically learn the importance of different channel features. Data experiments are conducted on datasets collected from The Affiliated Hospital of Qingdao University Medical College, China. Experimental results show that our YOLO-OC model achieves 91.83%, 85.66% and 73.82% on mean average precision [email protected] , [email protected] and mAP@[.5,.95], respectively, which performs better than Faster R-CNN, SSD and RetinaNet on both accuracy and efficiency.},
  archive      = {J_IDA},
  author       = {Wang, Xun and Li, Hanlin and Wang, Lisheng and Yu, Yongzhi and Zhou, Hao and Wang, Lei and Song, Tao},
  doi          = {10.3233/IDA-205542},
  journal      = {Intelligent Data Analysis},
  month        = {10},
  number       = {6},
  pages        = {1565-1578},
  shortjournal = {Intell. Data Anal.},
  title        = {An improved YOLOv3 model for detecting location information of ovarian cancer from CT images},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MEGA: Predicting the best classifier combination using
meta-learning and a genetic algorithm. <em>IDA</em>, <em>25</em>(6),
1547–1563. (<a href="https://doi.org/10.3233/IDA-205494">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classifier combination through ensemble systems is one of the most effective approaches to improve the accuracy of classification systems. Ensemble systems are generally used to combine classifiers; However, selecting the best combination of individual classifiers is a challenging task. In this paper, we propose an efficient assembling method that employs both meta-learning and a genetic algorithm for the selection of the best classifiers. Our method is called MEGA, standing for using MEta-learning and a Genetic Algorithm for algorithm recommendation. MEGA has three main components: Training, Model Interpretation and Testing. The Training component extracts meta-features of each training dataset and uses a genetic algorithm to discover the best classifier combination. The Model Interpretation component interprets the relationships between meta-features and classifiers using a priori and multi-label decision tree algorithms. Finally, the Testing component uses a weighted k-nearest-neighbors algorithm to predict the best combination of classifiers for unseen datasets. We present extensive experimental results that demonstrate the performance of MEGA. MEGA achieves superior results in a comparison of three other methods and, most importantly, is able to find novel interpretable rules that can be used to select the best combination of classifiers for an unseen dataset.},
  archive      = {J_IDA},
  author       = {Golshanrad, Paria and Rahmani, Hossein and Karimian, Banafsheh and Karimkhani, Fatemeh and Weiss, Gerhard},
  doi          = {10.3233/IDA-205494},
  journal      = {Intelligent Data Analysis},
  month        = {10},
  number       = {6},
  pages        = {1547-1563},
  shortjournal = {Intell. Data Anal.},
  title        = {MEGA: Predicting the best classifier combination using meta-learning and a genetic algorithm},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mutual information-based multi-output tree learning
algorithm. <em>IDA</em>, <em>25</em>(6), 1525–1545. (<a
href="https://doi.org/10.3233/IDA-205367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A tree model with low time complexity can support the application of artificial intelligence to industrial systems. Variable selection based tree learning algorithms are more time efficient than existing Classification and Regression Tree (CART) algorithms. To our best knowledge, there is no attemp t to deal with categorical input variable in variable selection based multi-output tree learning. Also, in the case of multi-output regression tree, a conventional variable selection based algorithm is not suitable to large datasets. We propose a mutual information-based multi-output tree learning algorithm that consists of variable selection and split optimization. The proposed method discretizes each variable based on k-means into 2–4 clusters and selects the variable for splitting based on the discretized variables using mutual information. This variable selection component has relatively low time complexity and can be applied regardless of output dimension and types. The proposed split optimization component is more efficient than an exhaustive search. The performance of the proposed tree learning algorithm is similar to or better than that of a multi-output version of CART algorithm on a specific dataset. In addition, with a large dataset, the time complexity of the proposed algorithm is significantly reduced compared to a CART algorithm.},
  archive      = {J_IDA},
  author       = {Kang, Hyun-Seok and Jun, Chi-Hyuck},
  doi          = {10.3233/IDA-205367},
  journal      = {Intelligent Data Analysis},
  month        = {10},
  number       = {6},
  pages        = {1525-1545},
  shortjournal = {Intell. Data Anal.},
  title        = {Mutual information-based multi-output tree learning algorithm},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MD-SPKM: A set pair k-modes clustering algorithm for
incomplete categorical matrix data. <em>IDA</em>, <em>25</em>(6),
1507–1524. (<a href="https://doi.org/10.3233/IDA-205340">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to solve the clustering problem with incomplete and categorical matrix data sets, and considering the uncertain relationship between samples and clusters, a set pair k-modes clustering algorithm is proposed (MD-SPKM). Firstly, the correlation theory of set pair information granule is intro duced into k-modes clustering. By improving the distance formula of traditional k-modes algorithm, a set pair distance measurement method between incomplete matrix samples is defined. Secondly, considering the uncertain relationship between the sample and the cluster, the definition of the intra-cluster average distance and the threshold calculation formula to determine whether the sample belongs to multiple clusters is given, and then the result of set pair clustering is formed, which includes positive region, boundary region and negative region. Finally, through the selected three data sets and four contrast algorithms for experimental evaluation, the experimental results show that the set pair k-modes clustering algorithm can effectively handle incomplete categorical matrix data sets, and has good clustering performance in Accuracy, Recall, ARI and NMI.},
  archive      = {J_IDA},
  author       = {Zhang, Chunying and Gao, Ruiyan and Wang, Jiahao and Chen, Song and Liu, Fengchun and Ren, Jing and Feng, Xiaoze},
  doi          = {10.3233/IDA-205340},
  journal      = {Intelligent Data Analysis},
  month        = {10},
  number       = {6},
  pages        = {1507-1524},
  shortjournal = {Intell. Data Anal.},
  title        = {MD-SPKM: A set pair k-modes clustering algorithm for incomplete categorical matrix data},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Time-series data dynamic density clustering. <em>IDA</em>,
<em>25</em>(6), 1487–1506. (<a
href="https://doi.org/10.3233/IDA-205459">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many clustering problems, the whole data is not always static. Over time, part of it is likely to be changed, such as updated, erased, etc. Suffer this effect, the timeline can be divided into multiple time segments. And, the data at each time slice is static. Then, the data along the timeline s hows a series of dynamic intermediate states. The union set of data from all time slices is called the time-series data. Obviously, the traditional clustering process does not apply directly to the time-series data. Meanwhile, repeating the clustering process at every time slices costs tremendous. In this paper, we analyze the transition rules of the data set and cluster structure when the time slice shifts to the next. We find there is a distinct correlation of data set and succession of cluster structure between two adjacent ones, which means we can use it to reduce the cost of the whole clustering process. Inspired by it, we propose a dynamic density clustering method (DDC) for time-series data. In the simulations, we choose 6 representative problems to construct the time-series data for testing DDC. The results show DDC can get high accuracy results for all 6 problems while reducing the overall cost markedly.},
  archive      = {J_IDA},
  author       = {Chen, Hao and Xia, Yu and Pan, Yuekai and Yang, Qing},
  doi          = {10.3233/IDA-205459},
  journal      = {Intelligent Data Analysis},
  month        = {10},
  number       = {6},
  pages        = {1487-1506},
  shortjournal = {Intell. Data Anal.},
  title        = {Time-series data dynamic density clustering},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Differential evolution algorithm-based multiple-factor
optimization methods for data assimilation. <em>IDA</em>,
<em>25</em>(6), 1473–1486. (<a
href="https://doi.org/10.3233/IDA-205471">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The methods of searching for optimized parameters have substantial effects on the forecast accuracy of ensemble data assimilation systems. The selection of these factors is usually performed using trial-and-error methods, and poor parameterizations may lead to filter divergence. Combined with the l ocal ensemble transform Kalman filtering method (LETKF), a technique for an automated search of the best configuration (parameters) of a data assimilation system is proposed. To obtain better assimilation, a differential evolution (DE) algorithm-based multiple-factor parameterization method results in the corresponding circumstances. By combining with fast-searching DE algorithms, we may retrieve the most ideal parameter combinations. Several numerical experiments performed with the Lorenz-96 model show that new methods performed better than the original one-parameter optimization methods. As the basis of DE methods, the best combinations of the local radius and the covariance inflation parameter, which can guarantee the best DA performances in the corresponding circumstances, are retrieved. It is found that the new method is capable of outperforming previous search algorithms under both perfect and imperfect model scenarios, and the calculation cost in Lorenz-96 model is lower. However, how to apply the new proposed method to more complex atmospheric or land surface models requires further verification.},
  archive      = {J_IDA},
  author       = {Bai, Yulong and Wang, Di and Wang, Yizhao and Chang, Mingheng},
  doi          = {10.3233/IDA-205471},
  journal      = {Intelligent Data Analysis},
  month        = {10},
  number       = {6},
  pages        = {1473-1486},
  shortjournal = {Intell. Data Anal.},
  title        = {Differential evolution algorithm-based multiple-factor optimization methods for data assimilation},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An improved OPTICS clustering algorithm for discovering
clusters with uneven densities. <em>IDA</em>, <em>25</em>(6), 1453–1471.
(<a href="https://doi.org/10.3233/IDA-205497">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most density-based clustering algorithms have the problems of difficult parameter setting, high time complexity, poor noise recognition, and weak clustering for datasets with uneven density. To solve these problems, this paper proposes FOP-OPTICS algorithm (Finding of the Ordering Peaks Based on OP TICS), which is a substantial improvement of OPTICS (Ordering Points To Identify the Clustering Structure). The proposed algorithm finds the demarcation point (DP) from the Augmented Cluster-Ordering generated by OPTICS and uses the reachability-distance of DP as the radius of neighborhood eps of its corresponding cluster. It overcomes the weakness of most algorithms in clustering datasets with uneven densities. By computing the distance of the k-nearest neighbor of each point, it reduces the time complexity of OPTICS; by calculating density-mutation points within the clusters, it can efficiently recognize noise. The experimental results show that FOP-OPTICS has the lowest time complexity, and outperforms other algorithms in parameter setting and noise recognition.},
  archive      = {J_IDA},
  author       = {Tang, Chunhua and Wang, Han and Wang, Zhiwen and Zeng, Xiangkun and Yan, Huaran and Xiao, Yingjie},
  doi          = {10.3233/IDA-205497},
  journal      = {Intelligent Data Analysis},
  month        = {10},
  number       = {6},
  pages        = {1453-1471},
  shortjournal = {Intell. Data Anal.},
  title        = {An improved OPTICS clustering algorithm for discovering clusters with uneven densities},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Alleviating the independence assumptions of averaged
one-dependence estimators by model weighting. <em>IDA</em>,
<em>25</em>(6), 1431–1451. (<a
href="https://doi.org/10.3233/IDA-205400">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Of numerous proposals to refine naive Bayes by weakening its attribute independence assumption, averaged one-dependence estimators (AODE) has been shown to be able to achieve significantly higher classification accuracy at a moderate cost in classification efficiency. However, all one-dependence es timators (ODEs) in AODE have the same weights and are treated equally. To address this issue, model weighting, which assigns discriminate weights to ODEs and then linearly combine their probability estimates, has been proved to be an efficient and effective approach. Most information-theoretic weighting metrics, including mutual information, Kullback-Leibler measure and the information gain, place more emphasis on the correlation between root attribute (value) and class variable. We argue that the topology of each ODE can be divided into a set of local directed acyclic graphs (DAGs) based on the independence assumption, and multivariate mutual information is introduced to measure the extent to which the DAGs fit data. Based on this premise, in this study we propose a novel weighted AODE algorithm, called AWODE, that adaptively selects weights to alleviate the independence assumption and make the learned probability distribution fit the instance. The proposed approach is validated on 40 benchmark datasets from UCI machine learning repository. The experimental results reveal that, AWODE achieves bias-variance trade-off and is a competitive alternative to single-model Bayesian learners (such as TAN and KDB) and other weighted AODEs (such as WAODE).},
  archive      = {J_IDA},
  author       = {Wang, Li-Min and Chen, Peng and Mammadov, Musa and Liu, Yang and Wu, Si-Yuan},
  doi          = {10.3233/IDA-205400},
  journal      = {Intelligent Data Analysis},
  month        = {10},
  number       = {6},
  pages        = {1431-1451},
  shortjournal = {Intell. Data Anal.},
  title        = {Alleviating the independence assumptions of averaged one-dependence estimators by model weighting},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Detecting a multigranularity event in an unequal interval
time series based on self-adaptive segmenting. <em>IDA</em>,
<em>25</em>(6), 1407–1429. (<a
href="https://doi.org/10.3233/IDA-205480">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analyzing the temporal behaviors and revealing the hidden rules of objects that produce time series data to detect the events that users are interested in have recently received a large amount of attention. Generally, in various application scenarios and most research works, the equal interval samp ling of a time series is a requirement. However, this requirement is difficult to guarantee because of the presence of sampling errors in most situations. In this paper, a multigranularity event detection method for an unequal interval time series, called SSED (self-adaptive segmenting based event detection), is proposed. First, in view of the trend features of a time series, a self-adaptive segmenting algorithm is proposed to divide a time series into unfixed-length segmentations based on the trends. Then, by clustering the segmentations and mapping the clusters to different identical symbols, a symbol sequence is built. Finally, based on unfixed-length segmentations, the multigranularity events in the discrete symbol sequence are detected using a tree structure. The SSED is compared to two previous methods with ten public datasets. In addition, the SSED is applied to the public transport systems in Xiamen, China, using bus-speed time-series data. The experimental results show that the SSED can achieve higher efficiency and accuracy than existing algorithms.},
  archive      = {J_IDA},
  author       = {Li, Haibo and Yu, Yongbo},
  doi          = {10.3233/IDA-205480},
  journal      = {Intelligent Data Analysis},
  month        = {10},
  number       = {6},
  pages        = {1407-1429},
  shortjournal = {Intell. Data Anal.},
  title        = {Detecting a multigranularity event in an unequal interval time series based on self-adaptive segmenting},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Privacy preserving defect prediction using generalization
and entropy-based data reduction. <em>IDA</em>, <em>25</em>(6),
1369–1405. (<a href="https://doi.org/10.3233/IDA-205504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The software engineering community produces data that can be analyzed to enhance the quality of future software products, and data regarding software defects can be used by data scientists to create defect predictors. However, sharing such data raises privacy concerns, since sensitive software feat ures are usually considered as business assets that should be protected in accordance with the law. Early research efforts on protecting the privacy of software data found that applying conventional data anonymization to mask sensitive attributes of software features degrades the quality of the shared data. In addition, data produced by such approaches is not immune to attacks such as inference and background knowledge attacks. This research proposes a new approach to share protected release of software defects data that can still be used in data science algorithms. We created a generalization (clustering)-based approach to anonymize sensitive software attributes. Tomek link and AllNN data reduction approaches were used to discard noisy records that may affect the usefulness of the shared data. The proposed approach considers diversity of sensitive attributes as an important factor to avoid inference and background knowledge attacks on the anonymized data, therefore data discarded is removed from both defective and non-defective records. We conducted experiments conducted on several benchmark software defect datasets, using both data quality and privacy measures to evaluate the proposed approach. Our findings showed that the proposed approach outperforms existing well-known techniques using accuracy and privacy measures.},
  archive      = {J_IDA},
  author       = {Saifan, Ahmad A. and Lataifeh, Zainab},
  doi          = {10.3233/IDA-205504},
  journal      = {Intelligent Data Analysis},
  month        = {10},
  number       = {6},
  pages        = {1369-1405},
  shortjournal = {Intell. Data Anal.},
  title        = {Privacy preserving defect prediction using generalization and entropy-based data reduction},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Analyzing mixed-type data by using word embedding for
handling categorical features. <em>IDA</em>, <em>25</em>(6), 1349–1368.
(<a href="https://doi.org/10.3233/IDA-205453">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of real-world datasets are of mixed type including both numeric and categorical attributes. Unlike numbers, operations on categorical values are limited, and the degree of similarity between distinct values cannot be measured directly. In order to properly analyze mixed-type data, dedicated me thods to handle categorical values in the datasets are needed. The limitation of most existing methods is lack of appropriate numeric representations of categorical values. Consequently, some of analysis algorithms cannot be applied. In this paper, we address this deficiency by transforming categorical values to their numeric representation so as to facilitate various analyses of mixed-type data. In particular, the proposed transformation method preserves semantics of categorical values with respect to the other values in the dataset, resulting in better performance on data analyses including classification and clustering. The proposed method is verified and compared with other methods on extensive real-world datasets.},
  archive      = {J_IDA},
  author       = {Hsu, Chung-Chian and Tsao, Wei-Cyun and Chang, Arthur and Chang, Chuan-Yu},
  doi          = {10.3233/IDA-205453},
  journal      = {Intelligent Data Analysis},
  month        = {10},
  number       = {6},
  pages        = {1349-1368},
  shortjournal = {Intell. Data Anal.},
  title        = {Analyzing mixed-type data by using word embedding for handling categorical features},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Editorial. <em>IDA</em>, <em>25</em>(6), 1345–1347. (<a
href="https://doi.org/10.3233/IDA-210004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IDA},
  author       = {Famili, A.},
  doi          = {10.3233/IDA-210004},
  journal      = {Intelligent Data Analysis},
  month        = {10},
  number       = {6},
  pages        = {1345-1347},
  shortjournal = {Intell. Data Anal.},
  title        = {Editorial},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient computation of target-oriented link criticalness
centrality in uncertain graphs. <em>IDA</em>, <em>25</em>(5), 1323–1343.
(<a href="https://doi.org/10.3233/IDA-205539">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We challenge the problem of efficiently identifying critical links that substantially degrade network performance if they do not function under a realistic situation where each link is probabilistically disconnected, e.g., unexpected traffic accident in a road network and unexpected server down in a communication network. To solve this problem, we utilize the bridge detection technique in graph theory and efficiently identify critical links in case the node reachability is taken as the performance measure.To be more precise, we define a set of target nodes and a new measure associated with it, Target-oriented latent link Criticalness Centrality (TCC), which is defined as the marginal loss of the expected number of nodes in the network that can reach, or equivalently can be reached from, one of the target nodes, and compute TCC for each link by use of detected bridges. We apply the proposed method to two real-world networks, one from social network and the other from spatial network, and empirically show that the proposed method has a good scalability with respect to the network size and the links our method identified possess unique properties. They are substantially more critical than those obtained by the others, and no known measures can replace the TCC measure.},
  archive      = {J_IDA},
  author       = {Saito, Kazumi and Fushimi, Takayasu and Ohara, Kouzou and Kimura, Masahiro and Motoda, Hiroshi},
  doi          = {10.3233/IDA-205539},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1323-1343},
  shortjournal = {Intell. Data Anal.},
  title        = {Efficient computation of target-oriented link criticalness centrality in uncertain graphs},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ensemble machine learning methods for spatio-temporal data
analysis of plant and ratoon sugarcane. <em>IDA</em>, <em>25</em>(5),
1291–1322. (<a href="https://doi.org/10.3233/IDA-205302">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent technological enhancements in the field of information technology and statistical techniques allowed the sophisticated and reliable analysis based on machine learning methods. A number of machine learning data analytical tools may be exploited for the classification and regression problems. These tools and techniques can be effectively used for the highly data-intensive operations such as agricultural and meteorological applications, bioinformatics and stock market analysis based on the daily prices of the market. Machine learning ensemble methods such as Decision Tree (C5.0), Classification and Regression (CART), Gradient Boosting Machine (GBM) and Random Forest (RF) has been investigated in the proposed work. The proposed work demonstrates that temporal variations in the spectral data and computational efficiency of machine learning methods may be effectively used for the discrimination of types of sugarcane. The discrimination has been considered as a binary classification problem to segregate ratoon from plantation sugarcane. Variable importance selection based on Mean Decrease in Accuracy (MDA) and Mean Decrease in Gini (MDG) have been used to create the appropriate dataset for the classification. The performance of the binary classification model based on RF is the best in all the possible combination of input images. Feature selection based on MDA and MDG measures of RF is also important for the dimensionality reduction. It has been observed that RF model performed best with 97% accuracy, whereas the performance of GBM method is the lowest. Binary classification based on the remotely sensed data can be effectively handled using random forest method.},
  archive      = {J_IDA},
  author       = {Singla, Sandeep Kumar and Garg, Rahul Dev and Dubey, Om Prakash},
  doi          = {10.3233/IDA-205302},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1291-1322},
  shortjournal = {Intell. Data Anal.},
  title        = {Ensemble machine learning methods for spatio-temporal data analysis of plant and ratoon sugarcane},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Virtual samples based robust block-diagonal dictionary
learning for face recognition. <em>IDA</em>, <em>25</em>(5), 1273–1290.
(<a href="https://doi.org/10.3233/IDA-205466">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is an open question to learn an over-complete dictionary from a limited number of face samples, and the inherent attributes of the samples are underutilized. Besides, the recognition performance may be adversely affected by the noise (and outliers), and the strict binary label based linear class ifier is not appropriate for face recognition. To solve above problems, we propose a virtual samples based robust block-diagonal dictionary learning for face recognition. In the proposed model, the original samples and virtual samples are combined to solve the small sample size problem, and both the structure constraint and the low rank constraint are exploited to preserve the intrinsic attributes of the samples. In addition, the fidelity term can effectively reduce negative effects of noise (and outliers), and the ε-dragging is utilized to promote the performance of the linear classifier. Finally, extensive experiments are conducted in comparison with many state-of-the-art methods on benchmark face datasets, and experimental results demonstrate the efficacy of the proposed method.},
  archive      = {J_IDA},
  author       = {Wang, Shuangxi and Ge, Hongwei and Yang, Jinlong and Su, Shuzhi},
  doi          = {10.3233/IDA-205466},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1273-1290},
  shortjournal = {Intell. Data Anal.},
  title        = {Virtual samples based robust block-diagonal dictionary learning for face recognition},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Personalized trajectory privacy-preserving method based on
sensitive attribute generalization and location perturbation.
<em>IDA</em>, <em>25</em>(5), 1247–1271. (<a
href="https://doi.org/10.3233/IDA-205306">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trajectory data may include the user’s occupation, medical records, and other similar information. However, attackers can use specific background knowledge to analyze published trajectory data and access a user’s private information. Different users have different requirements regarding the anonymi ty of sensitive information. To satisfy personalized privacy protection requirements and minimize data loss, we propose a novel trajectory privacy preservation method based on sensitive attribute generalization and trajectory perturbation. The proposed method can prevent an attacker who has a large amount of background knowledge and has exchanged information with other attackers from stealing private user information. First, a trajectory dataset is clustered and frequent patterns are mined according to the clustering results. Thereafter, the sensitive attributes found within the frequent patterns are generalized according to the user requirements. Finally, the trajectory locations are perturbed to achieve trajectory privacy protection. The results of theoretical analyses and experimental evaluations demonstrate the effectiveness of the proposed method in preserving personalized privacy in published trajectory data.},
  archive      = {J_IDA},
  author       = {Chen, Chuanming and Lin, Wenshi and Zhang, Shuanggui and Ye, Zitong and Yu, Qingying and Luo, Yonglong},
  doi          = {10.3233/IDA-205306},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1247-1271},
  shortjournal = {Intell. Data Anal.},
  title        = {Personalized trajectory privacy-preserving method based on sensitive attribute generalization and location perturbation},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust face recognition based on a new kernel-PCA using RRQR
factorization. <em>IDA</em>, <em>25</em>(5), 1233–1245. (<a
href="https://doi.org/10.3233/IDA-205377">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last ten years, many variants of the principal component analysis were suggested to fight against the curse of dimensionality. Recently, A. Sharma et al. have proposed a stable numerical algorithm based on Householder QR decomposition (HQR) called QR PCA. This approach improves the performan ce of the PCA algorithm via a singular value decomposition (SVD) in terms of computation complexity. In this paper, we propose a new algorithm called RRQR PCA in order to enhance the QR PCA performance by exploiting the Rank-Revealing QR Factorization (RRQR). We have also improved the recognition rate of RRQR PCA by developing a nonlinear extension of RRQR PCA. In addition, a new robust RBF Lp-norm kernel is proposed in order to reduce the effect of outliers and noises. Extensive experiments on two well-known standard face databases which are ORL and FERET prove that the proposed algorithm is more robust than conventional PCA, 2DPCA, PCA-L1, WTPCA-L1, LDA, and 2DLDA in terms of face recognition accuracy.},
  archive      = {J_IDA},
  author       = {Maafiri, Ayyad and Chougdali, Khalid},
  doi          = {10.3233/IDA-205377},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1233-1245},
  shortjournal = {Intell. Data Anal.},
  title        = {Robust face recognition based on a new kernel-PCA using RRQR factorization},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). GOW-stream: A novel approach of graph-of-words based mixture
model for semantic-enhanced text stream clustering. <em>IDA</em>,
<em>25</em>(5), 1211–1231. (<a
href="https://doi.org/10.3233/IDA-205443">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, rapid growth of social networks and online news resources from Internet have made text stream clustering become an insufficient application in multiple domains (e.g.: text retrieval diversification, social event detection, text summarization, etc.) Different from traditional static text c lustering approach, text stream clustering task has specific key challenges related to the rapid change of topics/clusters and high-velocity of coming streaming document batches. Recent well-known model-based text stream clustering models, such as: DTM, DCT, MStream, etc. are considered as word-independent evaluation approach which means largely ignoring the relations between words while sampling clusters/topics. It definitely leads to the decrease of overall model accuracy performance, especially for short-length text documents such as comments, microblogs, etc. in social networks. To tackle these existing problems, in this paper we propose a novel approach of graph-of-words (GOWs) based text stream clustering, called GOW-Stream. The application of common GOWs which are generated from each document batch while sampling clusters/topics can support to overcome the word-independent evaluation challenge. Our proposed GOW-Stream is promising to significantly achieve better text stream clustering performance than recent state-of-the-art baselines. Extensive experiments on multiple benchmark real-world datasets demonstrate the effectiveness of our proposed model in both accuracy and time-consuming performances.},
  archive      = {J_IDA},
  author       = {Vo, Tham and Do, Phuc},
  doi          = {10.3233/IDA-205443},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1211-1231},
  shortjournal = {Intell. Data Anal.},
  title        = {GOW-stream: A novel approach of graph-of-words based mixture model for semantic-enhanced text stream clustering},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Location prediction for facility placement by incorporating
multi-characteristic information. <em>IDA</em>, <em>25</em>(5),
1187–1210. (<a href="https://doi.org/10.3233/IDA-205420">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the course of recommending locations for establishing new facilities on urban planning or commercial programming, the location prediction offers the optimal candidates, which maximizes the number of served customers or minimize customer inconvenience, therefore brings the maximum profits. In mos t existing studies, only the spatial-temporal features are recognized to evaluate the location popularity, where social relationships of customers, which are significant factors for popularity assessing, have been ignored. Additionally, current researches also fail to take capacities and categories of the facilities into consideration. To overcome the drawbacks, we introduce a novel model of Multi-characteristic Information based Top-k Location Prediction (MITLP), it captures the spatio-temporal behaviors of customers based on historical trajectories, exploits the social relevancy from their friend relationships, as well as examines the category competitiveness of specific facilities thoroughly. Subsequently, by drawing on the feature evaluation and popularity quantization, MITLP will be implemented within a hybrid B-tree-liked recommending framework, Constrained Location and Social-Trajectory Clustered forest (CLSTC-forest), which can not only produce better performance in practice but also address the facility service constraints. Finally, extensive experiments conducted on real-world datasets demonstrate the higher efficiency and effectiveness of the proposed model.},
  archive      = {J_IDA},
  author       = {Wang, Pu and Chen, Wei and Huang, Jinjing and Wei, Yuyang and Fang, Junhua and Zhao, Lei},
  doi          = {10.3233/IDA-205420},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1187-1210},
  shortjournal = {Intell. Data Anal.},
  title        = {Location prediction for facility placement by incorporating multi-characteristic information},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A two-stage clustering-based cold-start method for active
learning. <em>IDA</em>, <em>25</em>(5), 1169–1185. (<a
href="https://doi.org/10.3233/IDA-205393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of initialization of active learning is considered in this paper. Especially, this paper studies the problem in an imbalanced data scenario, which is called as class-imbalance active learning cold-start. The novel method is two-stage clustering-based active learning cold-start (ALCS). I n the first stage, to separate the instances of minority class from that of majority class, a multi-center clustering is constructed based on a new inter-cluster tightness measure, thus the data is grouped into multiple clusters. Then, in the second stage, the initial training instances are selected from each cluster based on an adaptive candidate representative instances determination mechanism and a clusters-cyclic instance query mechanism. The comprehensive experiments demonstrate the effectiveness of the proposed method from the aspects of class coverage, classification performance, and impact on active learning.},
  archive      = {J_IDA},
  author       = {He, Deniu and Yu, Hong and Wang, Guoyin and Li, Jie},
  doi          = {10.3233/IDA-205393},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1169-1185},
  shortjournal = {Intell. Data Anal.},
  title        = {A two-stage clustering-based cold-start method for active learning},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Biogc: A novel framework for biological network
classification via machine learning. <em>IDA</em>, <em>25</em>(5),
1153–1168. (<a href="https://doi.org/10.3233/IDA-205240">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biological network classification is an eminently challenging task in the domain of data mining since the networks contain complex structural information. Conventional biochemical experimental methods and the existing intelligent algorithms still suffer from some limitations such as immense experim ental cost and inferior accuracy rate. To solve these problems, in this paper, we propose a novel framework for Biological graph classification named Biogc, which is specifically developed to predict the label of both small-scale and large-scale biological network data flexibly and efficiently. Our framework firstly presents a simplified graph kernel method to capture the structural information of each graph. Then, the obtained informative features are adopted to train different scale biological network data-oriented classifiers to construct the prediction model. Extensive experiments on five benchmark biological network datasets on graph classification task show that the proposed model Biogc outperforms the state-of-the-art methods with an accuracy rate of 98.90% on a larger dataset and 99.32% on a smaller dataset.},
  archive      = {J_IDA},
  author       = {Li, Bentian and Pi, Dechang and Lin, Yunxia and Khan, Izhar Ahmed},
  doi          = {10.3233/IDA-205240},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1153-1168},
  shortjournal = {Intell. Data Anal.},
  title        = {Biogc: A novel framework for biological network classification via machine learning},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ADAW: Age decay accuracy weighted ensemble method for
drifting data stream mining. <em>IDA</em>, <em>25</em>(5), 1131–1152.
(<a href="https://doi.org/10.3233/IDA-205249">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic environment data generators are very often in real-world that produce data streams. A data source of a dynamic environment generates data streams in which the underlying data distribution changes very frequently with respect to time and hence results in concept drifts. As compared to the st ationary environment, learning in the dynamic environment is very difficult due to the presence of concept drifts. Learning in dynamic environment requires evolutionary and adaptive approaches to be accommodated with the learning algorithms. Ensemble methods are commonly used to build classifiers for learning in a dynamic environment. The ensemble methods of learning are generally described at three very crucial aspects, namely, the learning and testing method employed, result integration method and forgetting mechanism for old concepts. In this paper, we propose a novel approach called Age Decay Accuracy Weighted (ADAW) ensemble architecture for learning in concept drifting data streams. The ADAW method assigned weights to the component classifiers based on its accuracy and its remaining life-time in the ensemble is such a way that ensures maximum accuracy. We empirically evaluated ADAW on benchmark artificial drifting data stream generators and real datasets and compared its performance with ten well-known state-of-the-art existing methods. The experimental results show that ADAW outperforms over the existing methods.},
  archive      = {J_IDA},
  author       = {Srivastava, Ritesh and Mittal, Veena},
  doi          = {10.3233/IDA-205249},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1131-1152},
  shortjournal = {Intell. Data Anal.},
  title        = {ADAW: Age decay accuracy weighted ensemble method for drifting data stream mining},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Attribute interaction aware matrix factorization method for
recommendation. <em>IDA</em>, <em>25</em>(5), 1115–1130. (<a
href="https://doi.org/10.3233/IDA-205407">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Matrix factorization (MF) models are effective and easy to expand and are widely used in industry, such as rating prediction and item recommendation. The basic MF model is relatively simple. In practical applications, side information such as attributes or implicit feedback is often combined to imp rove accuracy by modifying the model and optimizing the algorithm. In this paper, we propose an attribute interaction-aware matrix factorization (AIMF) method for recommendation tasks. We partition the original rating matrix into different sub-matrices according to the attribute interactions, train each sub-matrix independently, and merge all the latent vectors to generate the final score. Since the generated sub-matrices vary in size, an adaptive regularization coefficient optimization strategy and an adaptive latent vector dimension optimization strategy are proposed for sub-matrix training, and a variety of latent vector merging methods are put forward. The method AIMF has two advantages. When the original rating matrix is particularly large, the training time complexity of the MF-based model becomes higher and the update cost of the model is also higher. In AIMF, because each sub-matrix is usually much smaller than the original rating matrix, the training time complexity is greatly reduced after using parallel computing technology. Secondly, in AIMF, it is not necessary to modify the matrix factorization model to incorporate attributes and their interactive information into the model to improve the performance. The experimental results on the two classic public datasets MovieLens 1M and MovieLens 100k show that AIMF can not only effectively improve the accuracy of recommendation, but also make full use of parallel computing technology to improve training efficiency without modifying the matrix factorization model.},
  archive      = {J_IDA},
  author       = {Wan, Yongquan and Zhu, Lihua and Yan, Cairong and Zhang, Bofeng},
  doi          = {10.3233/IDA-205407},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1115-1130},
  shortjournal = {Intell. Data Anal.},
  title        = {Attribute interaction aware matrix factorization method for recommendation},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A non-binary hierarchical tree overlapping community
detection based on multi-dimensional similarity. <em>IDA</em>,
<em>25</em>(5), 1099–1113. (<a
href="https://doi.org/10.3233/IDA-205418">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Overlapping communities exist in real networks, where the communities represent hierarchical community structures, such as schools and government departments. A non-binary tree allows a vertex to belong to multiple communities to obtain a more realistic overlapping community structure. It is challe nging to select appropriate leaf vertices and construct a hierarchical tree that considers a large amount of structural information. In this paper, we propose a non-binary hierarchical tree overlapping community detection based on multi-dimensional similarity. The multi-dimensional similarity fully considers the local structure characteristics between vertices to calculate the similarity between vertices. First, we construct a similarity matrix based on the first and second-order neighbor vertices and select a leaf vertex. Second, we expand the leaf vertex based on the principle of maximum community density and construct a non-binary tree. Finally, we choose the layer with the largest overlapping modularity as the result of community division. Experiments on real-world networks demonstrate that our proposed algorithm is superior to other representative algorithms in terms of the quality of overlapping community detection.},
  archive      = {J_IDA},
  author       = {Chen, Jie and Wang, Huijun and Zhao, Shu and Wang, Ying and Zhang, Yanping},
  doi          = {10.3233/IDA-205418},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1099-1113},
  shortjournal = {Intell. Data Anal.},
  title        = {A non-binary hierarchical tree overlapping community detection based on multi-dimensional similarity},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Predictive modelling of hospital readmission: Evaluation of
different preprocessing techniques on machine learning classifiers.
<em>IDA</em>, <em>25</em>(5), 1073–1098. (<a
href="https://doi.org/10.3233/IDA-205468">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hospital readmission is a major cost for healthcare systems worldwide. If patients with a higher potential of readmission could be identified at the start, existing resources could be used more efficiently, and appropriate plans could be implemented to reduce the risk of readmission. Therefore, it is important to predict the right target patients. Medical data is usually noisy, incomplete, and inconsistent. Hence, before developing a prediction model, it is crucial to efficiently set up the predictive model so that improved predictive performance is achieved. The current study aims to analyse the impact of different preprocessing methods on the performance of different machine learning classifiers. The preprocessing applied by previous hospital readmission studies were compared, and the most common approaches highlighted such as missing value imputation, feature selection, data balancing, and feature scaling. The hyperparameters were selected using Bayesian optimisation. The different preprocessing pipelines were assessed using various performance metrics and computational costs. The results indicated that the preprocessing approaches helped improve the model’s prediction of hospital readmission.},
  archive      = {J_IDA},
  author       = {Miswan, Nor Hamizah and Chan, Chee Seng and Ng, Chong Guan},
  doi          = {10.3233/IDA-205468},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1073-1098},
  shortjournal = {Intell. Data Anal.},
  title        = {Predictive modelling of hospital readmission: Evaluation of different preprocessing techniques on machine learning classifiers},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving discretization based pattern discovery for
multivariate time series by additional preprocessing. <em>IDA</em>,
<em>25</em>(5), 1051–1072. (<a
href="https://doi.org/10.3233/IDA-205329">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In technical systems the analysis of similar load situations is a promising technique to gain information about the system’s state, its health or wearing. Very often, load situations are challenging to be defined by hand. Hence, these situations need to be discovered as recurrent patterns within mu ltivariate time series data of the system under consideration. Unsupervised algorithms for finding such recurrent patterns in multivariate time series must be able to cope with very large data sets because the system might be observed over a very long time. In our previous work we identified discretization-based approaches to be very interesting for variable length pattern discovery because of their low computing time due to the simplification (symbolization) of the time series. In this paper we propose additional preprocessing steps for symbolic representation of time series aiming for enhanced multivariate pattern discovery. Beyond that we show the performance (quality and computing time) of our algorithms in a synthetic test data set as well as in a real life example with 100 millions of time points. We also test our approach with increasing dimensionality of the time series.},
  archive      = {J_IDA},
  author       = {Noering, Fabian Kai-Dietrich and Jonas, Konstantin and Klawonn, Frank},
  doi          = {10.3233/IDA-205329},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1051-1072},
  shortjournal = {Intell. Data Anal.},
  title        = {Improving discretization based pattern discovery for multivariate time series by additional preprocessing},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Editorial. <em>IDA</em>, <em>25</em>(5), 1047–1049. (<a
href="https://doi.org/10.3233/IDA-210003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IDA},
  author       = {Famili, A.},
  doi          = {10.3233/IDA-210003},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1047-1049},
  shortjournal = {Intell. Data Anal.},
  title        = {Editorial},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multimodal emotion recognition with hierarchical memory
networks. <em>IDA</em>, <em>25</em>(4), 1031–1045. (<a
href="https://doi.org/10.3233/IDA-205183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion recognition in conversations is crucial as there is an urgent need to improve the overall experience of human-computer interactions. A promising improvement in this field is to develop a model that can effectively extract adequate contexts of a test utterance. We introduce a novel model, te rmed hierarchical memory networks (HMN), to address the issues of recognizing utterance level emotions. HMN divides the contexts into different aspects and employs different step lengths to represent the weights of these aspects. To model the self dependencies, HMN takes independent local memory networks to model these aspects. Further, to capture the interpersonal dependencies, HMN employs global memory networks to integrate the local outputs into global storages. Such storages can generate contextual summaries and help to find the emotional dependent utterance that is most relevant to the test utterance. With an attention-based multi-hops scheme, these storages are then merged with the test utterance using an addition operation in the iterations. Experiments on the IEMOCAP dataset show our model outperforms the compared methods with accuracy improvement.},
  archive      = {J_IDA},
  author       = {Lai, Helang and Wu, Keke and Li, Lingli},
  doi          = {10.3233/IDA-205183},
  journal      = {Intelligent Data Analysis},
  month        = {7},
  number       = {4},
  pages        = {1031-1045},
  shortjournal = {Intell. Data Anal.},
  title        = {Multimodal emotion recognition with hierarchical memory networks},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Feature-based multi-criteria recommendation system using a
weighted approach with ranking correlation. <em>IDA</em>,
<em>25</em>(4), 1013–1029. (<a
href="https://doi.org/10.3233/IDA-205388">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increase of online businesses, recommendation algorithms are being researched a lot to facilitate the process of using the existing information. Such multi-criteria recommendation (MCRS) helps a lot the end-users to attain the required results of interest having different selective criteri a – such as combinations of implicit and explicit interest indicators in the form of ranking or rankings on different matched dimensions. Current approaches typically use label correlation, by assuming that the label correlations are shared by all objects. In real-world tasks, however, different sources of information have different features. Recommendation systems are more effective if being used for making a recommendation using multiple criteria of decisions by using the correlation between the features and items content (content-based approach) or finding a similar user rating to get targeted results (Collaborative filtering). To combine these two filterings in the multicriteria model, we proposed a features-based fb-knn multi-criteria hybrid recommendation algorithm approach for getting the recommendation of the items by using multicriteria features of items and integrating those with the correlated items found in similar datasets. Ranks were assigned to each decision and then weights were computed for each decision by using the standard deviation of items to get the nearest result. For evaluation, we tested the proposed algorithm on different datasets having multiple features of information. The results demonstrate that proposed fb-knn is efficient in different types of datasets.},
  archive      = {J_IDA},
  author       = {Zeeshan, Zeeshan and ul Ain, Qurat and Bhatti, Uzair Aslam and Memon, Waqar Hussain and Ali, Sajid and Nawaz, Saqib Ali and Nizamani, Mir Muhammad and Mehmood, Anum and Bhatti, Mughair Aslam and Shoukat, Muhammad Usman},
  doi          = {10.3233/IDA-205388},
  journal      = {Intelligent Data Analysis},
  month        = {7},
  number       = {4},
  pages        = {1013-1029},
  shortjournal = {Intell. Data Anal.},
  title        = {Feature-based multi-criteria recommendation system using a weighted approach with ranking correlation},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). TextureMask: A merged architecture for low-resolution
instance segmentation. <em>IDA</em>, <em>25</em>(4), 993–1012. (<a
href="https://doi.org/10.3233/IDA-205250">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Instance segmentation has a wide range of applications, including video surveillance, autonomous driving, and behavior analysis. Nevertheless, as a type of pixel-level segmentation, its prediction performance in practice is substantially affected by low-resolution (LR) images resulting from the lim itations of image acquisition equipment and poor acquisition conditions. Moreover, because their immense computational costs prevent the implementation of existing segmentation models on embedded devices, the development of a lightweight segmentation model has become an urgent necessity. However, it is challenging to achieve sound results with high efficiency and portability. From another perspective, to improve understanding of detailed objects, an architecture is needed that promotes an advanced interpretation of the segmentation, that is, a refined mask with texture. Our main contribution, called TextureMask, consists of the MobileNet-FPN for Mask R-CNN methods, segmentation with cropping, and a gradient sensitivity map, which are then merged into a unified map to refine and enrich the mask with texture information. Furthermore, preprocessing and post-processing algorithms are incorporated. Experiments demonstrated that our technique exhibits good pixel-level segmentation performance in terms of both accuracy and computational efficiency for a given LR input, and it can be easily implemented in embedded platforms.},
  archive      = {J_IDA},
  author       = {Da, Ting and Yang, Liang},
  doi          = {10.3233/IDA-205250},
  journal      = {Intelligent Data Analysis},
  month        = {7},
  number       = {4},
  pages        = {993-1012},
  shortjournal = {Intell. Data Anal.},
  title        = {TextureMask: A merged architecture for low-resolution instance segmentation},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Quantitative predicting propagation breadth and depth of
microblog users’ forwarding behavior. <em>IDA</em>, <em>25</em>(4),
973–991. (<a href="https://doi.org/10.3233/IDA-205262">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the microblog network, users’ forwarding behavior is widespread and the propagation range is difficult to predict quantitatively. To solve this problem, machine learning algorithms are used to quantitatively predict propagation breadth and depth of microblog users’ forwarding behavior. The datas et is preprocessed, and the extracted features are divided into three types: user features, microblog features and social features. Then the dataset is analyzed in detail; machine learning algorithms are used to predict the propagation breadth and depth of users’ forwarding behavior; and the influence of the three types of features on prediction precision is studied. The experimental results show that the prediction precision of the improved random forest algorithm has less fluctuations, and it is not sensitive to the changes of various features. The improved random forest algorithm has higher precision and better generalization ability than the other algorithms, which shows that the prediction results have high reference value. Social features have the greatest influence on the prediction precision for each prediction algorithm. User features have the similar influence as microblog features on the prediction precision.},
  archive      = {J_IDA},
  author       = {Wang, Yanben and Bai, Jurong},
  doi          = {10.3233/IDA-205262},
  journal      = {Intelligent Data Analysis},
  month        = {7},
  number       = {4},
  pages        = {973-991},
  shortjournal = {Intell. Data Anal.},
  title        = {Quantitative predicting propagation breadth and depth of microblog users’ forwarding behavior},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The prediction of online time series with concept drift
based on dynamic intuitionistic fuzzy cognitive map. <em>IDA</em>,
<em>25</em>(4), 949–972. (<a
href="https://doi.org/10.3233/IDA-205271">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy cognitive maps (FCMs) have widely been applied for knowledge representation and reasoning. However, in real life, reasoning is always accompanied with hesitation, which is deriving from the uncertainty and fuzziness. Especially, when processing the online data, since the internal and external interference, the distribution and characteristics of sequence data would be considerably changed along with the passage of time, which further increase the difficulty of modeling. In this article, based on intuitionistic fuzzy set theory, a new dynamic intuitionistic fuzzy cognitive map (DIFCM) scheme is proposed for online data prediction. Combined with a novel detection algorithm of concept drift, the structure of DIFCM can be adaptively updated with the online learning scheme, which can effectively improve the representation of online information by capturing the real-time changes of sequence data. Moreover, in order to tackle with the possible hesitancy in the process of modeling, intuitionistic fuzzy set is applied in the construction of dynamic FCM, where hesitation degree as a quantitative index explicitly expresses the hesitancy. Finally, a series of experiments using public data sets verify the effectiveness of the proposed method.},
  archive      = {J_IDA},
  author       = {Zhang, Nannan and Yao, Xixi and Luo, Chao},
  doi          = {10.3233/IDA-205271},
  journal      = {Intelligent Data Analysis},
  month        = {7},
  number       = {4},
  pages        = {949-972},
  shortjournal = {Intell. Data Anal.},
  title        = {The prediction of online time series with concept drift based on dynamic intuitionistic fuzzy cognitive map},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). C_CART: An instance confidence-based decision tree algorithm
for classification. <em>IDA</em>, <em>25</em>(4), 929–948. (<a
href="https://doi.org/10.3233/IDA-205361">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In classification, a decision tree is a common model due to its simple structure and easy understanding. Most of decision tree algorithms assume all instances in a dataset have the same degree of confidence, so they use the same generation and pruning strategies for all training instances. In fact, the instances with greater degree of confidence are more useful than the ones with lower degree of confidence in the same dataset. Therefore, the instances should be treated discriminately according to their corresponding confidence degrees when training classifiers. In this paper, we investigate the impact and significance of degree of confidence of instances on the classification performance of decision tree algorithms, taking the classification and regression tree (CART) algorithm as an example. First, the degree of confidence of instances is quantified from a statistical perspective. Then, a developed CART algorithm named C_CART is proposed by introducing the confidence of instances into the generation and pruning processes of CART algorithm. Finally, we conduct experiments to evaluate the performance of C_CART algorithm. The experimental results show that our C_CART algorithm can significantly improve the generalization performance as well as avoiding the over-fitting problem to a certain extend.},
  archive      = {J_IDA},
  author       = {Yu, Shuang and Li, Xiongfei and Wang, Hancheng and Zhang, Xiaoli and Chen, Shiping},
  doi          = {10.3233/IDA-205361},
  journal      = {Intelligent Data Analysis},
  month        = {7},
  number       = {4},
  pages        = {929-948},
  shortjournal = {Intell. Data Anal.},
  title        = {C_CART: An instance confidence-based decision tree algorithm for classification},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Content-aware data distribution over cluster nodes.
<em>IDA</em>, <em>25</em>(4), 907–927. (<a
href="https://doi.org/10.3233/IDA-205360">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Proper data items distribution may seriously improve the performance of data processing in distributed environment. However, typical datastorage systems as well as distributed computational frameworks do not pay special attention to that aspect. In this paper author introduces two custom data items addressing methods for distributed datastorage on the example of Scalable Distributed Two-Layer Datastore. The basic idea of those methods is to preserve that data items stored on the same cluster node are similar to each other following concepts of data clustering. Still, most of the data clustering mechanisms have serious problem with data scalability which is a severe limitation in Big Data applications. The proposed methods allow to efficiently distribute data set over a set of buckets. As it was shown by the experimental results, all proposed methods generate good results efficiently in comparison to traditional clustering techniques like k-means, agglomerative and birch clustering. Distributed environment experiments shown that proper data distribution can seriously improve the effectiveness of Big Data processing.},
  archive      = {J_IDA},
  author       = {Krechowicz, Adam},
  doi          = {10.3233/IDA-205360},
  journal      = {Intelligent Data Analysis},
  month        = {7},
  number       = {4},
  pages        = {907-927},
  shortjournal = {Intell. Data Anal.},
  title        = {Content-aware data distribution over cluster nodes},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A graphical approach for multiclass classification and for
correcting the labeling errors in mislabeled training data.
<em>IDA</em>, <em>25</em>(4), 879–906. (<a
href="https://doi.org/10.3233/IDA-205223">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiclass data classification, where the goal is to segment data into classes, is an important task in machine learning. However, the task is challenging due to reasons including the scarcity of labeled training data; in fact, most machine learning algorithms require a large amount of labeled exam ples to perform well. Moreover, the accuracy of a classifier can be dependent on the accuracy of the training labels which can be corrupted. In this paper, we present an efficient and unconditionally stable semi-supervised graph-based method for multiclass data classification which requires considerably less labeled training data to accurately classify a data set compared to current techniques, due to properties such as the embedding of data into a similarity graph. In particular, it performs very well and more accurately than current approaches in the common scenario of few labeled training elements. Morever, we show that the algorithm performs with good accuracy even with a large number of mislabeled examples and is also able to incorporate class size information. The proposed method uses a modified auction dynamics technique. Extensive experiments on benchmark datasets are performed and the results are compared to other methods.},
  archive      = {J_IDA},
  author       = {Merkurjev, Ekaterina},
  doi          = {10.3233/IDA-205223},
  journal      = {Intelligent Data Analysis},
  month        = {7},
  number       = {4},
  pages        = {879-906},
  shortjournal = {Intell. Data Anal.},
  title        = {A graphical approach for multiclass classification and for correcting the labeling errors in mislabeled training data},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new semi-supervised algorithm combined with MCICA
optimizing SVM for motion imagination EEG classification. <em>IDA</em>,
<em>25</em>(4), 863–877. (<a
href="https://doi.org/10.3233/IDA-205188">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposed a new semi-supervised algorithm combined with Mutual-cross Imperial Competition Algorithm (MCICA) optimizing Support Vector Machine (SVM) for motion imagination EEG classification, which not only reduces the tedious and time-consuming training process and enhances the adaptabili ty of Brain Computer Interface (BCI), but also utilizes the MCICA to optimize the parameters of SVM in the semi-supervised process. This algorithm combines mutual information and cross validation to construct objective function in the semi-supervised training process, and uses the constructed objective function to establish the semi-supervised model of MCICA for optimizing the parameters of SVM, and finally applies the selected optimal parameters to the data set Iva of 2005 BCI competition to verify its effectiveness. The results showed that the proposed algorithm is effective in optimizing parameters and has good robustness and generalization in solving small sample classification problems.},
  archive      = {J_IDA},
  author       = {Tan, Xuemin and Guo, Chao and Jiang, Tao and Fu, Kechang and Zhou, Nan and Yuan, Jianying and Zhang, Guoliang},
  doi          = {10.3233/IDA-205188},
  journal      = {Intelligent Data Analysis},
  month        = {7},
  number       = {4},
  pages        = {863-877},
  shortjournal = {Intell. Data Anal.},
  title        = {A new semi-supervised algorithm combined with MCICA optimizing SVM for motion imagination EEG classification},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Manifold regularization ensemble clustering with many
objectives using unsupervised extreme learning machines. <em>IDA</em>,
<em>25</em>(4), 847–862. (<a
href="https://doi.org/10.3233/IDA-205362">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spectral clustering has been an effective clustering method, in last decades, because it can get an optimal solution without any assumptions on data’s structure. The basic key in spectral clustering is its similarity matrix. Despite many empirical successes in similarity matrix construction, almost all previous methods suffer from handling just one objective. To address the multi-objective ensemble clustering, we introduce a new ensemble manifold regularization (MR) method based on stacking framework. In our Manifold Regularization Ensemble Clustering (MREC) method, several objective functions are considered simultaneously, as a robust method for constructing the similarity matrix. Using it, the unsupervised extreme learning machine (UELM) is employed to find the generalized eigenvectors to embed the data in low-dimensional space. These eigenvectors are then used as the base point in spectral clustering to find the best partitioning of the data. The aims of this paper are to find robust partitioning that satisfy multiple objectives, handling noisy data, keeping diversity-based goals, and dimension reduction. Experiments on some real-world datasets besides to three benchmark protein datasets demonstrate the superiority of MREC over some state-of-the-art single and ensemble methods.},
  archive      = {J_IDA},
  author       = {Homayouni, Haleh and Mansoori, Eghbal G.},
  doi          = {10.3233/IDA-205362},
  journal      = {Intelligent Data Analysis},
  month        = {7},
  number       = {4},
  pages        = {847-862},
  shortjournal = {Intell. Data Anal.},
  title        = {Manifold regularization ensemble clustering with many objectives using unsupervised extreme learning machines},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Handling incomplete data classification using imputed
feature selected bagging (IFBag) method. <em>IDA</em>, <em>25</em>(4),
825–846. (<a href="https://doi.org/10.3233/IDA-205331">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Almost all real-world datasets contain missing values. Classification of data with missing values can adversely affect the performance of a classifier if not handled correctly. A common approach used for classification with incomplete data is imputation. Imputation transforms incomplete data with m issing values to complete data. Single imputation methods are mostly less accurate than multiple imputation methods which are often computationally much more expensive. This study proposes an imputed feature selected bagging (IFBag) method which uses multiple imputation, feature selection and bagging ensemble learning approach to construct a number of base classifiers to classify new incomplete instances without any need for imputation in testing phase. In bagging ensemble learning approach, data is resampled multiple times with substitution, which can lead to diversity in data thus resulting in more accurate classifiers. The experimental results show the proposed IFBag method is considerably fast and gives 97.26% accuracy for classification with incomplete data as compared to common methods used.},
  archive      = {J_IDA},
  author       = {Khan, Ahmad Jaffar and Raza, Basit and Shahid, Ahmad Raza and Kumar, Yogan Jaya and Faheem, Muhammad and Alquhayz, Hani},
  doi          = {10.3233/IDA-205331},
  journal      = {Intelligent Data Analysis},
  month        = {7},
  number       = {4},
  pages        = {825-846},
  shortjournal = {Intell. Data Anal.},
  title        = {Handling incomplete data classification using imputed feature selected bagging (IFBag) method},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Human interaction recognition method based on parallel
multi-feature fusion network. <em>IDA</em>, <em>25</em>(4), 809–823. (<a
href="https://doi.org/10.3233/IDA-205217">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human activity recognition is a key technology in intelligent video surveillance and an important research direction in the field of computer vision. However, the complexity of human interaction features and the differences in motion characteristics at different time periods have always existed. In this paper, a human interaction recognition algorithm based on parallel multi-feature fusion network is proposed. First of all, in view of the different amount of information provided by the different time periods of action, an improved time-phased video down sampling method based on Gaussian model is proposed. Second, the Inception module uses different scale convolution kernels for feature extraction. It can improve network performance and reduce the amount of network parameters at the same time. The ResNet module mitigates degradation problem due to increased depth of neural networks and achieves higher classification accuracy. The amount of information provided in the motion video in different stages of motion time is also different. Therefore, we combine the advantages of the Inception network and ResNet to extract feature information, and then we integrate the extracted features. After the extracted features are merged, the training is continued to realize parallel connection of the multi-feature neural network. In this paper, experiments are carried out on the UT dataset. Compared with the traditional activity recognition algorithm, this method can accomplish the recognition tasks of six kinds of interactive actions in a better way, and its accuracy rate reaches 88.9%.},
  archive      = {J_IDA},
  author       = {Ye, Qing and Zhong, Haoxin and Qu, Chang and Zhang, Yongmei},
  doi          = {10.3233/IDA-205217},
  journal      = {Intelligent Data Analysis},
  month        = {7},
  number       = {4},
  pages        = {809-823},
  shortjournal = {Intell. Data Anal.},
  title        = {Human interaction recognition method based on parallel multi-feature fusion network},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Development of a data generator for multivariate numerical
data with arbitrary correlations and distributions. <em>IDA</em>,
<em>25</em>(4), 789–807. (<a
href="https://doi.org/10.3233/IDA-205253">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial or simulated data are particularly relevant in tests and benchmarks for machine learning methods, in teaching for exercises and for setting up analysis workflows. They are relevant when real data may not be used for reasons of data protection, or when special distributions or effects sho uld be present in the data to test certain machine learning methods. In this paper a generator for multivariate numerical data with arbitrary marginal distributions and – as far as possible – arbitrary correlations is presented. The data generator is implemented in the open source statistics software R. It can also be used for categorical variables, if data are generated separately for the corresponding characteristics of a categorical variable. Additionally, outliers can be integrated. The use of the data generator is demonstrated with a concrete example.},
  archive      = {J_IDA},
  author       = {Vahldiek, Kai and Zhou, Libing and Zhu, Wenfeng and Klawonn, Frank},
  doi          = {10.3233/IDA-205253},
  journal      = {Intelligent Data Analysis},
  month        = {7},
  number       = {4},
  pages        = {789-807},
  shortjournal = {Intell. Data Anal.},
  title        = {Development of a data generator for multivariate numerical data with arbitrary correlations and distributions},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Methods for detecting and correcting contextual data quality
problems. <em>IDA</em>, <em>25</em>(4), 763–787. (<a
href="https://doi.org/10.3233/IDA-205282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge extraction, data mining, e-learning or web applications platforms use heterogeneous and distributed data. The proliferation of these multifaceted platforms faces many challenges such as high scalability, the coexistence of complex similarity metrics, and the requirement of data quality ev aluation. In this study, an extended complete formal taxonomy and some algorithms that utilize in achieving the detection and correction of contextual data quality anomalies were developed and implemented on structured data. Our methods were effective in detecting and correcting more data anomalies than existing taxonomy techniques, and also highlighted the demerit of Support Vector Machine (SVM). These proposed techniques, therefore, will be of relevance in detection and correction of errors in large contextual data (Big data).},
  archive      = {J_IDA},
  author       = {Ngueilbaye, Alladoumbaye and Wang, Hongzhi and Mahamat, Daouda Ahmat and Elgendy, Ibrahim A. and Junaidu, Sahalu B.},
  doi          = {10.3233/IDA-205282},
  journal      = {Intelligent Data Analysis},
  month        = {7},
  number       = {4},
  pages        = {763-787},
  shortjournal = {Intell. Data Anal.},
  title        = {Methods for detecting and correcting contextual data quality problems},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Editorial. <em>IDA</em>, <em>25</em>(4), 759–761. (<a
href="https://doi.org/10.3233/IDA-210002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IDA},
  doi          = {10.3233/IDA-210002},
  journal      = {Intelligent Data Analysis},
  month        = {7},
  number       = {4},
  pages        = {759-761},
  shortjournal = {Intell. Data Anal.},
  title        = {Editorial},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A directed link prediction method using graph convolutional
network based on social ranking theory. <em>IDA</em>, <em>25</em>(3),
739–757. (<a href="https://doi.org/10.3233/IDA-195006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional networks (GCN) have recently emerged as powerful node embedding methods in network analysis tasks. Particularly, GCNs have been successfully leveraged to tackle the challenging link prediction problem, aiming at predicting missing links that exist yet were not found. However, mo st of these models are oriented to undirected graphs, which are limited to certain real-life applications. Therefore, based on the social ranking theory, we extend the GCN to address the directed link prediction problem. Firstly, motivated by the reciprocated and unreciprocated nature of social ties, we separate nodes in the neighbor subgraph of the missing link into the same, a higher-ranked and a lower-ranked set. Then, based on the three kinds of node sets, we propose a method to correctly aggregate and propagate the directional information across layers of a GCN model. Empirical study on 8 real-world datasets shows that our proposed method is capable of reserving rich information related to directed link direction and consistently performs well on graphs from numerous domains.},
  archive      = {J_IDA},
  author       = {Wu, Zheng and Chen, Hongchang and Zhang, Jianpeng and Liu, Shuxin and Huang, Ruiyang and Pei, Yulong},
  doi          = {10.3233/IDA-195006},
  journal      = {Intelligent Data Analysis},
  month        = {4},
  number       = {3},
  pages        = {739-757},
  shortjournal = {Intell. Data Anal.},
  title        = {A directed link prediction method using graph convolutional network based on social ranking theory},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). W-MMP2Vec: Topic-driven network embedding model for link
prediction in content-based heterogeneous information network.
<em>IDA</em>, <em>25</em>(3), 711–738. (<a
href="https://doi.org/10.3233/IDA-205168">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction on heterogeneous information network (HIN) is considered as a challenge problem due to the complexity and diversity in types of nodes and links. Currently, there are remained challenges of meta-path-based link prediction in HIN. Previous works of link prediction in HIN via network e mbedding approach are mainly focused on exploiting features of node rather than existing relations in forms of meta-paths between nodes. In fact, predicting the existence of new links between non-linked nodes is absolutely inconvincible. Moreover, recent HIN-based embedding models also lack of thorough evaluations on the topic similarity between text-based nodes along given meta-paths. To tackle these challenges, in this paper, we proposed a novel approach of topic-driven multiple meta-path-based HIN representation learning framework, namely W-MMP2Vec. Our model leverages the quality of node representations by combining multiple meta-paths as well as calculating the topic similarity weight for each meta-path during the processes of network embedding learning in content-based HINs. To validate our approach, we apply W-TMP2Vec model in solving several link prediction tasks in both content-based and non-content-based HINs (DBLP, IMDB and BlogCatalog). The experimental outputs demonstrate the effectiveness of proposed model which outperforms recent state-of-the-art HIN representation learning models.},
  archive      = {J_IDA},
  author       = {Pham, Phu and Do, Phuc},
  doi          = {10.3233/IDA-205168},
  journal      = {Intelligent Data Analysis},
  month        = {4},
  number       = {3},
  pages        = {711-738},
  shortjournal = {Intell. Data Anal.},
  title        = {W-MMP2Vec: Topic-driven network embedding model for link prediction in content-based heterogeneous information network},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Regression trees with splitting based on changes of
dependencies among covariates. <em>IDA</em>, <em>25</em>(3), 687–710.
(<a href="https://doi.org/10.3233/IDA-205140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regression trees are powerful tools in data mining for analyzing data sets. Observations are usually divided into homogeneous groups, and then statistical models for responses are derived in the terminal nodes. This paper proposes a new approach for regression trees that considers the dependency st ructures among covariates for splitting the observations. The mathematical properties of the proposed method are discussed in detail. To assess the accuracy of the proposed model, various criteria are defined. The performance of the new approach is assessed by conducting a Monte-Carlo simulation study. Two real data sets on classification and regression problems are analyzed by using the obtained results.},
  archive      = {J_IDA},
  author       = {Boskabadi, Mostafa and Doostparast, Mahdi},
  doi          = {10.3233/IDA-205140},
  journal      = {Intelligent Data Analysis},
  month        = {4},
  number       = {3},
  pages        = {687-710},
  shortjournal = {Intell. Data Anal.},
  title        = {Regression trees with splitting based on changes of dependencies among covariates},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cross-modal variable-length hashing based on hierarchy.
<em>IDA</em>, <em>25</em>(3), 669–685. (<a
href="https://doi.org/10.3233/IDA-205162">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the emergence of the era of big data, cross-modal learning have been applied to many research fields. As an efficient retrieval method, hash learning is widely used frequently in many cross-modal retrieval scenarios. However, most of existing hashing methods use fixed-length hash codes, whic h increase the computational costs for large-size datasets. Furthermore, learning hash functions is an NP hard problem. To address these problems, we initially propose a novel method named Cross-modal Variable-length Hashing Based on Hierarchy (CVHH), which can learn the hash functions more accurately to improve retrieval performance, and also reduce the computational costs and training time. The main contributions of CVHH are: (1) We propose a variable-length hashing algorithm to improve the algorithm performance; (2) We apply the hierarchical architecture to effectively reduce the computational costs and training time. To validate the effectiveness of CVHH, our extensive experimental results show the superior performance compared with recent state-of-the-art cross-modal methods on three benchmark datasets, WIKI, NUS-WIDE and MIRFlickr.},
  archive      = {J_IDA},
  author       = {Qi, Xiaojun and Zeng, Xianhua and Wang, Shumin and Xie, Yicai and Xu, Liming},
  doi          = {10.3233/IDA-205162},
  journal      = {Intelligent Data Analysis},
  month        = {4},
  number       = {3},
  pages        = {669-685},
  shortjournal = {Intell. Data Anal.},
  title        = {Cross-modal variable-length hashing based on hierarchy},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bagging k-dependence bayesian network classifiers.
<em>IDA</em>, <em>25</em>(3), 641–667. (<a
href="https://doi.org/10.3233/IDA-205125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bagging has attracted much attention due to its simple implementation and the popularity of bootstrapping. By learning diverse classifiers from resampled datasets and averaging the outcomes, bagging investigates the possibility of achieving substantial classification performance of the base classif ier. Diversity has been recognized as a very important characteristic in bagging. This paper presents an efficient and effective bagging approach, that learns a set of independent Bayesian network classifiers (BNCs) from disjoint data subspaces. The number of bits needed to describe the data is measured in terms of log likelihood, and redundant edges are identified to optimize the topologies of the learned BNCs. Our extensive experimental evaluation on 54 publicly available datasets from the UCI machine learning repository reveals that the proposed algorithm achieves a competitive classification performance compared with state-of-the-art BNCs that use or do not use bagging procedures, such as tree-augmented naive Bayes (TAN), k-dependence Bayesian classifier (KDB), bagging NB or bagging TAN.},
  archive      = {J_IDA},
  author       = {Wang, Limin and Qi, Sikai and Liu, Yang and Lou, Hua and Zuo, Xin},
  doi          = {10.3233/IDA-205125},
  journal      = {Intelligent Data Analysis},
  month        = {4},
  number       = {3},
  pages        = {641-667},
  shortjournal = {Intell. Data Anal.},
  title        = {Bagging k-dependence bayesian network classifiers},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An attention network based on feature sequences for
cross-domain sentiment classification. <em>IDA</em>, <em>25</em>(3),
627–640. (<a href="https://doi.org/10.3233/IDA-205130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The difficulty of cross-domain text sentiment classification is that the data distributions in the source domain and the target domain are inconsistent. This paper proposes an attention network based on feature sequences (ANFS) for cross-domain sentiment classification, which focuses on important s emantic features by using the attention mechanism. Particularly, ANFS uses a three-layer convolutional neural network (CNN) to perform deep feature extraction on the text, and then uses a bidirectional long short-term memory (BiLSTM) to capture the long-term dependency relationship among the text feature sequences. We first transfer the ANFS model trained on the source domain to the target domain and share the parameters of the convolutional layer; then we use a small amount of labeled target domain data to fine-tune the model of the BiLSTM layer and the attention layer. The experimental results on cross-domain sentiment analysis tasks demonstrate that ANFS can significantly outperform the state-of-the-art methods for cross-domain sentiment classification problems.},
  archive      = {J_IDA},
  author       = {Meng, Jiana and Dong, Yu and Long, Yingchun and Zhao, Dandan},
  doi          = {10.3233/IDA-205130},
  journal      = {Intelligent Data Analysis},
  month        = {4},
  number       = {3},
  pages        = {627-640},
  shortjournal = {Intell. Data Anal.},
  title        = {An attention network based on feature sequences for cross-domain sentiment classification},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel krill herd algorithm with orthogonality and its
application to data clustering. <em>IDA</em>, <em>25</em>(3), 605–626.
(<a href="https://doi.org/10.3233/IDA-195056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Krill herd algorithm (KHA) is an emerging nature-inspired approach that has been successfully applied to optimization. However, KHA may get stuck into local optima owing to its poor exploitation. In this paper, the orthogonal learning (OL) mechanism is incorporated to enhance the performance of KHA for the first time, then an improved method named orthogonal krill herd algorithm (OKHA) is obtained. Compared with the existing hybridizations of KHA, OKHA could discover more useful information from historical data and construct a more promising solution. The proposed algorithm is applied to solve CEC2017 numerical problems, and its robustness is verified based on the simulation results. Moreover, OKHA is applied to tackle data clustering problems selected from the UCI Machine Learning Repository. The experimental results illustrate that OKHA is superior to or at least competitive with other representative clustering techniques.},
  archive      = {J_IDA},
  author       = {Zhao, Chen and Liu, Zhongxin and Chen, Zengqiang and Ning, Yao},
  doi          = {10.3233/IDA-195056},
  journal      = {Intelligent Data Analysis},
  month        = {4},
  number       = {3},
  pages        = {605-626},
  shortjournal = {Intell. Data Anal.},
  title        = {A novel krill herd algorithm with orthogonality and its application to data clustering},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unsupervised latent event representation learning and
storyline extraction from news articles based on neural networks.
<em>IDA</em>, <em>25</em>(3), 589–603. (<a
href="https://doi.org/10.3233/IDA-195061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Storyline extraction aims to generate concise summaries of related events unfolding over time from a collection of temporally-ordered news articles. Some existing approaches to storyline extraction are typically built on probabilistic graphical models that jointly model the extraction of events and the storylines from news published in different periods. However, their parameter inference procedures are often complex and require a long time to converge, which hinders their use in practical applications. More recently, a neural network-based approach has been proposed to tackle such limitations. However, event representations of documents, which are important for the quality of the generated storylines, are not learned. In this paper, we propose a novel unsupervised neural network-based approach to extract latent events and link patterns of storylines jointly from documents over time. Specifically, event representations are learned by a stacked autoencoder and clustered for event extraction, then a fusion component is incorporated to link the related events across consecutive periods for storyline extraction. The proposed model has been evaluated on three news corpora and the experimental results show that it outperforms state-of-the-art approaches with significant improvements.},
  archive      = {J_IDA},
  author       = {Si, Jiasheng and Guo, Linsen and Zhou, Deyu},
  doi          = {10.3233/IDA-195061},
  journal      = {Intelligent Data Analysis},
  month        = {4},
  number       = {3},
  pages        = {589-603},
  shortjournal = {Intell. Data Anal.},
  title        = {Unsupervised latent event representation learning and storyline extraction from news articles based on neural networks},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new perceptual evaluation method of video quality based on
neural network. <em>IDA</em>, <em>25</em>(3), 571–587. (<a
href="https://doi.org/10.3233/IDA-205085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel method for video quality evaluation based on machine learning technique. The current research deals with the correct interpretation of objective video quality evaluation (Quality of Service – QoS) in relation to subjective end-user perception (Quality of Experience – QoE ), typically expressed by mean opinion score (MOS). Our method allows us to interconnect results obtained from video objective and subjective assessment methods in the form of a neural network (computing model inspired by biological neural networks). So far, no unified interpretation scale has been standardized for both approaches, therefore it is difficult to determine the level of end-user satisfaction obtained from the objective assessment. Thus, contribution of the proposed method lies in description of the way to create a hybrid metric that delivers fast and reliable subjective score of perceived video quality for internet television (IPTV) broadcasting companies.},
  archive      = {J_IDA},
  author       = {Frnda, Jaroslav and Pavlicko, Michal and Durica, Marek and Sevcik, Lukas and Voznak, Miroslav and Fournier-Viger, Philippe and Lin, Jerry Chun-Wei},
  doi          = {10.3233/IDA-205085},
  journal      = {Intelligent Data Analysis},
  month        = {4},
  number       = {3},
  pages        = {571-587},
  shortjournal = {Intell. Data Anal.},
  title        = {A new perceptual evaluation method of video quality based on neural network},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sentiment classification based on weak tagging information
and imbalanced data. <em>IDA</em>, <em>25</em>(3), 555–570. (<a
href="https://doi.org/10.3233/IDA-205408">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment classification aims to solve the problem of automatic judgment of sentiment polarity. In the sentiment classification task of text data, such as online reviews, traditional deep learning models are dedicated to algorithm optimization but ignore the characteristics of imbalanced distributi on of the number of classified samples and the inclusion of weak tagging information such as ratings and tags. Based on the traditional deep learning model, the method of random oversampling and cost sensitivity is used to increase the contribution of a minority of samples to the model loss function and avoid the model biasing to the majority of samples. The model training is divided into two stages. In the first stage, a large amount of weak tagging data is used to train the model, therefore a model that captures the sentiment semantics of the data is obtained. After that, the model parameters trained in the first stage are used as the initial parameters of the second stage model training, and only a small amount of tagging data is used to continue training the model to reduce the impact of noise, thus reducing the use of manual tagging samples. The experimental results show that the method is considerably better than traditional deep learning models in the sentiment classification task of hotel review data.},
  archive      = {J_IDA},
  author       = {Wang, Chuantao and Yang, Xuexin and Ding, Linkai},
  doi          = {10.3233/IDA-205408},
  journal      = {Intelligent Data Analysis},
  month        = {4},
  number       = {3},
  pages        = {555-570},
  shortjournal = {Intell. Data Anal.},
  title        = {Sentiment classification based on weak tagging information and imbalanced data},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimization of SMOTE for imbalanced data based on AdaRBFNN
and hybrid metaheuristics. <em>IDA</em>, <em>25</em>(3), 541–554. (<a
href="https://doi.org/10.3233/IDA-205176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Oversampling ratio N and the minority class’ nearest neighboring number k are key hyperparameters of synthetic minority oversampling technique (SMOTE) to reconstruct the class distribution of dataset. No optimal default value exists there. Therefore, it is of necessity to discuss the influence of t he output dataset on the classification performance when SMOTE adopts various hyperparameter combinations. In this paper, we propose a hyperparameter optimization algorithm for imbalanced data. By iterating to find reasonable N and k for SMOTE, so as to build a balanced and high-quality dataset. As a result, a model with outstanding performance and strong generalization ability is trained, thus effectively solving imbalanced classification. The proposed algorithm is based on the hybridization of simulated annealing mechanism (SA) and particle swarm optimization algorithm (PSO). In the optimization, Cohen’s Kappa is used to construct the fitness function, and AdaRBFNN, a new classifier, is integrated by multiple trained RBF neural networks based on AdaBoost algorithm. Kappa of each generation is calculated according to the classification results, so as to evaluate the quality of candidate solution. Experiments are conducted on seven groups of KEEL datasets. Results show that the proposed algorithm delivers excellent performance and can significantly improve the classification accuracy of the minority class.},
  archive      = {J_IDA},
  author       = {Wang, Zicheng and Sun, Yanrui},
  doi          = {10.3233/IDA-205176},
  journal      = {Intelligent Data Analysis},
  month        = {4},
  number       = {3},
  pages        = {541-554},
  shortjournal = {Intell. Data Anal.},
  title        = {Optimization of SMOTE for imbalanced data based on AdaRBFNN and hybrid metaheuristics},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-modal neuroimaging feature fusion via 3D convolutional
neural network architecture for schizophrenia diagnosis. <em>IDA</em>,
<em>25</em>(3), 527–540. (<a
href="https://doi.org/10.3233/IDA-205113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early and precise diagnosis of schizophrenia disorder (SZ) has an essential role in the quality of a patient’s life and future treatments. Structural and functional neuroimaging provides robust biomarkers for understanding the anatomical and functional changes associated with SZ. Each of the neuroi maging techniques shows only a different perspective on the functional or structural of the brain, while multi-modal fusion can reveal latent connections in the brain. In this paper, we propose an approach for the fusion of structural and functional brain data with a deep learning-based model to take advantage of data fusion and increase the accuracy of schizophrenia disorder diagnosis. The proposed method consists of an architecture of 3D convolutional neural networks (CNNs) that applied to magnetic resonance imaging (MRI), functional magnetic resonance imaging (fMRI), and diffusion tensor imaging (DTI) extracted features. We use 3D MRI patches, fMRI spatial independent component analysis (ICA) map, and DTI fractional anisotropy (FA) as model inputs. Our method is validated on the COBRE dataset, and an average accuracy of 99.35% is obtained. The proposed method demonstrates promising classification performance and can be applied to real data.},
  archive      = {J_IDA},
  author       = {Masoudi, Babak and Daneshvar, Sabalan and Razavi, Seyed Naser},
  doi          = {10.3233/IDA-205113},
  journal      = {Intelligent Data Analysis},
  month        = {4},
  number       = {3},
  pages        = {527-540},
  shortjournal = {Intell. Data Anal.},
  title        = {Multi-modal neuroimaging feature fusion via 3D convolutional neural network architecture for schizophrenia diagnosis},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient n-gram construction for text categorization using
feature selection techniques. <em>IDA</em>, <em>25</em>(3), 509–525. (<a
href="https://doi.org/10.3233/IDA-205154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a novel approach for n-gram generation in text classification. The a-priori algorithm is adapted to prune word sequences by combining three feature selection techniques. Unlike the traditional two-step approach for text classification in which feature selection is performe d after the n-gram construction process, our proposal performs an embedded feature elimination during the application of the a-priori algorithm. The proposed strategy reduces the number of branches to be explored, speeding up the process and making the construction of all the word sequences tractable. Our proposal has the additional advantage of constructing a low-dimensional dataset with only the features that are relevant for classification, that can be used directly without the need for a feature selection step. Experiments on text classification datasets for sentiment analysis demonstrate that our approach yields the best predictive performance when compared with other feature selection approaches, while also facilitating a better understanding of the words and phrases that explain a given task; in our case online reviews and ratings in various domains.},
  archive      = {J_IDA},
  author       = {García, Maximiliano and Maldonado, Sebastián and Vairetti, Carla},
  doi          = {10.3233/IDA-205154},
  journal      = {Intelligent Data Analysis},
  month        = {4},
  number       = {3},
  pages        = {509-525},
  shortjournal = {Intell. Data Anal.},
  title        = {Efficient n-gram construction for text categorization using feature selection techniques},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Editorial. <em>IDA</em>, <em>25</em>(3), 505–507. (<a
href="https://doi.org/10.3233/IDA-210001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IDA},
  doi          = {10.3233/IDA-210001},
  journal      = {Intelligent Data Analysis},
  month        = {4},
  number       = {3},
  pages        = {505-507},
  shortjournal = {Intell. Data Anal.},
  title        = {Editorial},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An adaptive node embedding framework for multiplex networks.
<em>IDA</em>, <em>25</em>(2), 483–503. (<a
href="https://doi.org/10.3233/IDA-195065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network Embedding (NE) has emerged as a powerful tool in many applications. Many real-world networks have multiple types of relations between the same entities, which are appropriate to be modeled as multiplex networks. However, at random walk-based embedding study for multiplex networks, very litt le attention has been paid to the problems of sampling bias and imbalanced relation types. In this paper, we propose an Adaptive Node Embedding Framework (ANEF) based on cross-layer sampling strategies of nodes for multiplex networks. ANEF is the first framework to focus on the bias issue of sampling strategies. Through metropolis hastings random walk (MHRW) and forest fire sampling (FFS), ANEF is less likely to be trapped in local structure with high degree nodes. We utilize a fixed-length queue to record previously visited layers, which can balance the edge distribution over different layers in sampled node sequence processes. In addition, to adaptively sample the cross-layer context of nodes, we also propose a node metric called Neighbors Partition Coefficient (NPC). Experiments on real-world networks in diverse fields show that our framework outperforms the state-of-the-art methods in application tasks such as cross-domain link prediction and mutual community detection.},
  archive      = {J_IDA},
  author       = {Ning, Nianwen and Yang, Yilin and Song, Chenguang and Wu, Bin},
  doi          = {10.3233/IDA-195065},
  journal      = {Intelligent Data Analysis},
  month        = {3},
  number       = {2},
  pages        = {483-503},
  shortjournal = {Intell. Data Anal.},
  title        = {An adaptive node embedding framework for multiplex networks},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automatic image detection of multi-type surface defects on
wind turbine blades based on cascade deep learning network.
<em>IDA</em>, <em>25</em>(2), 463–482. (<a
href="https://doi.org/10.3233/IDA-205143">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A safe operation protocol of the wind blades is a critical factor to ensure the stability of a wind turbine. Sensors are most commonly applied for defect detection on wind turbine blades (WTBs). However, due to the high cost and the sensitivity to stochastic noise, computer vision-guided automatic detection remains a challenge for surface defect detection on WTBs in particularly, its accuracy in locating defects is yet to be optimized. In this paper, we developed a visual inspection model that can automatically and precisely classify and locate the surface defects, through the utilization of a deep learning framework based on the Cascade R-CNN. In order to obtain high mean average precision (mAP) according to the characteristics of the dataset, a model named Contextual Aligned-Deformable Cascade R-CNN (CAD Cascade R-CNN) using improved strategies of transfer learning, Deformable Convolution and Deformable RoI Align, as well as context information fusion is proposed and a dataset with surface defects categorized and labeled as crack, breakage and oil pollution is generated. Moreover to alleviate the problem of false detection under a complex background, an improved bisecting k-means is presented during the test process. The adaptability and generalization of the proposed CAD Cascade R-CNN model were validated by each type of defects in dataset and different IoU thresholds, whereas, each of the above improved strategies was verified by gradual ablation experiments. Finally experiments that compared with the baseline Cascade R-CNN, Faster R-CNN and YOLO-v3 demonstrate its superiority over these existing approaches with a maximum of 92.1% mAP.},
  archive      = {J_IDA},
  author       = {Mao, Yulin and Wang, Shuangxin and Yu, Dingli and Zhao, Juchao},
  doi          = {10.3233/IDA-205143},
  journal      = {Intelligent Data Analysis},
  month        = {3},
  number       = {2},
  pages        = {463-482},
  shortjournal = {Intell. Data Anal.},
  title        = {Automatic image detection of multi-type surface defects on wind turbine blades based on cascade deep learning network},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient method for time series similarity search using
binary code representation and hamming distance. <em>IDA</em>,
<em>25</em>(2), 439–461. (<a
href="https://doi.org/10.3233/IDA-194876">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series similarity search is an essential operation in time series data mining and has received much higher interest along with the growing popularity of time series data. Although many algorithms to solve this problem have been investigated, there is a challenging demand for supporting similar ity search in a fast and accurate way. In this paper, we present a novel approach, TS2BC, to perform time series similarity search efficiently and effectively. TS2BC uses binary code to represent time series and measures the similarity under the Hamming Distance. Our method is able to represent original data compactly and can handle shifted time series and work with time series of different lengths. Moreover, it can be performed with reasonably low complexity due to the efficiency of calculating the Hamming Distance. We extensively compare TS2BC with state-of-the-art algorithms in classification framework using 61 online datasets. Experimental results show that TS2BC achieves better or comparative performance than other the state-of-the-art in accuracy and is much faster than most existing algorithms. Furthermore, we propose an approximate version of TS2BC to speed up the query procedure and test its efficiency by experiment.},
  archive      = {J_IDA},
  author       = {Zhang, Haowen and Dong, Yabo and Li, Jing and Xu, Duanqing},
  doi          = {10.3233/IDA-194876},
  journal      = {Intelligent Data Analysis},
  month        = {3},
  number       = {2},
  pages        = {439-461},
  shortjournal = {Intell. Data Anal.},
  title        = {An efficient method for time series similarity search using binary code representation and hamming distance},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep spatial-temporal fusion network for fine-grained air
pollutant concentration prediction. <em>IDA</em>, <em>25</em>(2),
419–438. (<a href="https://doi.org/10.3233/IDA-195029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Air pollution is a serious environmental problem that has attracted much attention. Predicting air pollutant concentration can provide useful information for urban environmental governance decision-making and residents’ daily health control. However, existing methods fail to model the temporal depe ndencies or have suffer from a weak ability to capture the spatial correlations of air pollutants. In this paper, we propose a general approach to predict air pollutant concentration, named DSTFN, which consists of a data completion component, a similar region selection component, and a deep spatial-temporal fusion network. The data completion component uses tensor decomposition method to complete the missing data of historical air quality. The similar region selection component uses region metadata to calculate the spatial similarity between regions. The deep spatial-temporal fusion network fuses urban heterogeneous data to capture factors affecting air quality and predict air pollutant concentration. Extensive experiments on a real-world dataset demonstrate that our model achieves the highest performance compared with state-of-the-art models for air quality prediction.},
  archive      = {J_IDA},
  author       = {Ge, Liang and Wu, Kunyan and Chang, Feng and Zhou, Aoli and Li, Hang and Liu, Junling},
  doi          = {10.3233/IDA-195029},
  journal      = {Intelligent Data Analysis},
  month        = {3},
  number       = {2},
  pages        = {419-438},
  shortjournal = {Intell. Data Anal.},
  title        = {Deep spatial-temporal fusion network for fine-grained air pollutant concentration prediction},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Microbloggers’ interest inference using a subgraph stream.
<em>IDA</em>, <em>25</em>(2), 397–417. (<a
href="https://doi.org/10.3233/IDA-195042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inferring user interest over large-scale microblogs have attracted much attention in recent years. However, the emergence of the massive data, dynamic change of information and persistence of microblogs pose challenges to interest inference. Most of the existing approaches rarely take into account the combination of these microbloggers’ characteristics within the model, which may incur information loss with nontrivial magnitude in real-time extraction of user interest and massive social data processing. To address these problems, in this paper, we propose a novel User-Networked Interest Topic Extraction in the form of Subgraph Stream (UNITE_SS) for microbloggers’ interest inference. To be specific, we develop several strategies for the construction of subgraph stream to select the better strategy for user interest inference. Moreover, the information of microblogs in each subgraph is utilized to obtain a real-time and effective interest for microbloggers. The experimental evaluation on a large dataset from Sina Weibo, one of the most popular microblogs in China, demonstrates that the proposed approach outperforms the state-of-the-art baselines in terms of precision, mean reciprocal rank (MRR) as well as runtime from the effectiveness and efficiency perspectives.},
  archive      = {J_IDA},
  author       = {Huang, Xiaoling and Wang, Hao and Li, Lei and Zhu, Yi and Hu, Chengxiang},
  doi          = {10.3233/IDA-195042},
  journal      = {Intelligent Data Analysis},
  month        = {3},
  number       = {2},
  pages        = {397-417},
  shortjournal = {Intell. Data Anal.},
  title        = {Microbloggers’ interest inference using a subgraph stream},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Similarity-based sales forecasting using improved ConvLSTM
and prophet. <em>IDA</em>, <em>25</em>(2), 383–396. (<a
href="https://doi.org/10.3233/IDA-205103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sales forecasting is an important part of e-commerce and is critical to smart business decisions. The traditional forecasting methods mainly focus on building a forecasting model, training the model through historical data, and then using it to forecast future sales. Such methods are feasible and e ffective for the products with rich historical data while they are not performing as well for the newly listed products with little or no historical data. In this paper, with the idea of collaborative filtering, a similarity-based sales forecasting (S-SF) method is proposed. The implementation framework of S-SF includes three modules in order. The similarity module is responsible for generating top-k similar products of a given new product. We calculate the similarity based on two data types: time series data of sales and text data such as product attributes. In the learning module, we propose an attention-based ConvLSTM model which we called AttConvLSTM, and optimize its loss function with the convex function information entropy. Then AttConvLSTM is integrated with Facebook Prophet model to forecast top-k similar products sales based on their historical data. The prediction results of all top-k similar products will be fused in the forecasting module through operations of alignment and scaling to forecast the target products sales. The experimental results show that the proposed S-SF method can simultaneously adapt to the sales forecasting of mature products and new products, which shows excellent diversity, and the forecasting idea based on similar products improves the accuracy of sales forecasting.},
  archive      = {J_IDA},
  author       = {Wan, Yongquan and Chen, Yizhou and Yan, Cairong and Zhang, Bofeng},
  doi          = {10.3233/IDA-205103},
  journal      = {Intelligent Data Analysis},
  month        = {3},
  number       = {2},
  pages        = {383-396},
  shortjournal = {Intell. Data Anal.},
  title        = {Similarity-based sales forecasting using improved ConvLSTM and prophet},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-task prediction model based on ConvLSTM and
encoder-decoder. <em>IDA</em>, <em>25</em>(2), 359–382. (<a
href="https://doi.org/10.3233/IDA-194969">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The energy load data in the micro-energy network are a time series with sequential and nonlinear characteristics. This paper proposes a model based on the encode-decode architecture and ConvLSTM for multi-scale prediction of multi-energy loads in the micro-energy network. We apply ConvLSTM, LSTM, a ttention mechanism and multi-task learning concepts to construct a model specifically for processing the energy load forecasting of the micro-energy network. In this paper, ConvLSTM is used to encode the input time series. The attention mechanism is used to assign different weights to the features, which are subsequently decoded by the decoder LSTM layer. Finally, the fully connected layer interprets the output. This model is applied to forecast the multi-energy load data of the micro-energy network in a certain area of Northwest China. The test results prove that our model is convergent, and the evaluation index value of the model is better than that of the multi-task FC-LSTM and the single-task FC-LSTM. In particular, the application of the attention mechanism makes the model converge faster and with higher precision.},
  archive      = {J_IDA},
  author       = {Luo, Tao and Cao, Xudong and Li, Jin and Dong, Kun and Zhang, Rui and Wei, Xueliang},
  doi          = {10.3233/IDA-194969},
  journal      = {Intelligent Data Analysis},
  month        = {3},
  number       = {2},
  pages        = {359-382},
  shortjournal = {Intell. Data Anal.},
  title        = {Multi-task prediction model based on ConvLSTM and encoder-decoder},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep multiple non-negative matrix factorization for
multi-view clustering. <em>IDA</em>, <em>25</em>(2), 339–357. (<a
href="https://doi.org/10.3233/IDA-195075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering aims to group similar samples into the same clusters and dissimilar samples into different clusters by integrating heterogeneous information from multi-view data. Non-negative matrix factorization (NMF) has been widely applied to multi-view clustering owing to its interpretabi lity. However, most NMF-based algorithms only factorize multi-view data based on the shallow structure, neglecting complex hierarchical and heterogeneous information in multi-view data. In this paper, we propose a deep multiple non-negative matrix factorization (DMNMF) framework based on AutoEncoder for multi-view clustering. DMNMF consists of multiple Encoder Components and Decoder Components with deep structures. Each pair of Encoder Component and Decoder Component are used to hierarchically factorize the input data from a view for capturing the hierarchical information, and all Encoder and Decoder Components are integrated into an abstract level to learn a common low-dimensional representation for combining the heterogeneous information across multi-view data. Furthermore, graph regularizers are also introduced to preserve the local geometric information of each view. To optimize the proposed framework, an iterative updating scheme is developed. Besides, the corresponding algorithm called MVC-DMNMF is also proposed and implemented. Extensive experiments on six benchmark datasets have been conducted, and the experimental results demonstrate the superior performance of our proposed MVC-DMNMF for multi-view clustering compared to other baseline algorithms.},
  archive      = {J_IDA},
  author       = {Du, Guowang and Zhou, Lihua and Lü, Kevin and Ding, Haiyan},
  doi          = {10.3233/IDA-195075},
  journal      = {Intelligent Data Analysis},
  month        = {3},
  number       = {2},
  pages        = {339-357},
  shortjournal = {Intell. Data Anal.},
  title        = {Deep multiple non-negative matrix factorization for multi-view clustering},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A model to estimate the self-organizing maps grid dimension
for prototype generation. <em>IDA</em>, <em>25</em>(2), 321–338. (<a
href="https://doi.org/10.3233/IDA-205123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the high accuracy of the K nearest neighbor algorithm in different problems, KNN is one of the most important classifiers used in data mining applications and is recognized in the literature as a benchmark algorithm. Despite its high accuracy, KNN has some weaknesses, such as the time taken by the classification process, which is a disadvantage in many problems, particularly in those that involve a large dataset. The literature presents some approaches to reduce the classification time of KNN by selecting only the most important dataset examples. One of these methods is called Prototype Generation (PG) and the idea is to represent the dataset examples in prototypes. Thus, the classification process occurs in two steps; the first is based on prototypes and the second on the examples represented by the nearest prototypes. The main problem of this approach is a lack of definition about the ideal number of prototypes. This study proposes a model that allows the best grid dimension of Self-Organizing Maps and the ideal number of prototypes to be estimated using the number of dataset examples as a parameter. The approach is contrasted with other PG methods from the literature based on artificial intelligence that propose to automatically define the number of prototypes. The main advantage of the proposed method tested here using eighteen public datasets is that it allows a better relationship between a reduced number of prototypes and accuracy, providing a sufficient number that does not degrade KNN classification performance.},
  archive      = {J_IDA},
  author       = {Silva, Leandro A. and de Vasconcelos, Bruno P. and Del-Moral-Hernandez, Emilio},
  doi          = {10.3233/IDA-205123},
  journal      = {Intelligent Data Analysis},
  month        = {3},
  number       = {2},
  pages        = {321-338},
  shortjournal = {Intell. Data Anal.},
  title        = {A model to estimate the self-organizing maps grid dimension for prototype generation},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A parametric approximation algorithm for spatial group
keyword queries. <em>IDA</em>, <em>25</em>(2), 305–319. (<a
href="https://doi.org/10.3233/IDA-195071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the application of big data, various queries arise for information retrieval. Spatial group keyword queries aim to find a set of spatial objects that cover the query keywords and minimize a goal function such as the total distance between the objects and the query point. This problem is widely found in database applications and is known to be NP-hard. Efficient algorithms for solving this problem can only provide approximate solutions, and most of these algorithms achieve a fixed approximation ratio (the upper bound of the ratio of an approximate goal value to the optimal goal value). Thus, to obtain a self-adjusting algorithm, we propose an approximation algorithm for achieving a parametric approximation ratio. The algorithm makes a trade-off between the approximation ratio and time consumption enabling the users to assign arbitrary query accuracy. Additionally, it runs in an on-the-fly manner, making it scalable to large-scale applications. The efficiency and scalability of the algorithm were further validated using benchmark datasets.},
  archive      = {J_IDA},
  author       = {Li, Jincao and Xu, Ming},
  doi          = {10.3233/IDA-195071},
  journal      = {Intelligent Data Analysis},
  month        = {3},
  number       = {2},
  pages        = {305-319},
  shortjournal = {Intell. Data Anal.},
  title        = {A parametric approximation algorithm for spatial group keyword queries},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Suffix array for multi-pattern matching with variable length
wildcards. <em>IDA</em>, <em>25</em>(2), 283–303. (<a
href="https://doi.org/10.3233/IDA-205087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Approximate multi-pattern matching is an important issue that is widely and frequently utilized, when the pattern contains variable-length wildcards. In this paper, two suffix array-based algorithms have been proposed to solve this problem. Suffix array is an efficient data structure for exact stri ng matching in existing studies, as well as for approximate pattern matching and multi-pattern matching. An algorithm called MMSA-S is for the short exact characters in a pattern by dynamic programming, while another algorithm called MMSA-L deals with the long exact characters by the edit distance method. Experimental results of Pizza &amp; Chili corpus demonstrate that these two newly proposed algorithms, in most cases, are more time-efficient than the state-of-the-art comparison algorithms.},
  archive      = {J_IDA},
  author       = {Liu, Na and Xie, Fei and Wu, Xindong},
  doi          = {10.3233/IDA-205087},
  journal      = {Intelligent Data Analysis},
  month        = {3},
  number       = {2},
  pages        = {283-303},
  shortjournal = {Intell. Data Anal.},
  title        = {Suffix array for multi-pattern matching with variable length wildcards},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Quadratic hyper-surface kernel-free least squares support
vector regression. <em>IDA</em>, <em>25</em>(2), 265–281. (<a
href="https://doi.org/10.3233/IDA-205094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a novel kernel-free regressor, called quadratic hyper-surface kernel-free least squares support vector regression (QLSSVR), for some regression problems. The task of this approach is to find a quadratic function as the regression function, which is obtained by solving a quadratic program ming problem with the equality constraints. Basically, the new model just needs to solve a system of linear equations to achieve the optimal solution instead of solving a quadratic programming problem. Therefore, compared with the standard support vector regression, our approach is much efficient due to kernel-free and solving a set of linear equations. Numerical results illustrate that our approach has better performance than other existing regression approaches in terms of regression criterion and CPU time.},
  archive      = {J_IDA},
  author       = {Ye, Junyou and Yang, Zhixia and Li, Zhilin},
  doi          = {10.3233/IDA-205094},
  journal      = {Intelligent Data Analysis},
  month        = {3},
  number       = {2},
  pages        = {265-281},
  shortjournal = {Intell. Data Anal.},
  title        = {Quadratic hyper-surface kernel-free least squares support vector regression},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A robust anomaly detection algorithm based on principal
component analysis. <em>IDA</em>, <em>25</em>(2), 249–263. (<a
href="https://doi.org/10.3233/IDA-195054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantifying the abnormal degree of each instance within data sets to detect outlying instances, is an issue in unsupervised anomaly detection research. In this paper, we propose a robust anomaly detection method based on principal component analysis (PCA). Traditional PCA-based detection algorithms commonly obtain a high false alarm for the outliers. The main reason is that ignores the difference of location and scale to each component of the outlier score, this leads to the cumulated outlier score deviates from the true values. To address the issue, we introduce the median and the Median Absolute Deviation (MAD) to rescale each outlier score that mapped onto the corresponding principal direction. And then, the true outlier scores of instances can be obtained as the sum of weighted squares of the rescaled scores. Also, the issue that the assignment of the weight for each outlier score will be solved. The main advantage of our new approach is easy to build with unsupervised data and the recognition performance is better than the classical PCA-based methods. We compare our method to the five different anomaly detection techniques, including two traditional PCA-based methods, in our experiment analysis. The experimental results show that the proposed method has a good performance for effectiveness, efficiency, and robustness.},
  archive      = {J_IDA},
  author       = {Huang, Yingkun and Jin, Weidong and Yu, Zhibin and Li, Bing},
  doi          = {10.3233/IDA-195054},
  journal      = {Intelligent Data Analysis},
  month        = {3},
  number       = {2},
  pages        = {249-263},
  shortjournal = {Intell. Data Anal.},
  title        = {A robust anomaly detection algorithm based on principal component analysis},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). Editorial. <em>IDA</em>, <em>25</em>(2), 245–247. (<a
href="https://doi.org/10.3233/IDA-200018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IDA},
  doi          = {10.3233/IDA-200018},
  journal      = {Intelligent Data Analysis},
  month        = {3},
  number       = {2},
  pages        = {245-247},
  shortjournal = {Intell. Data Anal.},
  title        = {Editorial},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A citation recommendation method based on context
correlation. <em>IDA</em>, <em>25</em>(1), 225–243. (<a
href="https://doi.org/10.3233/IDA-195041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Researchers need to formulate their achievements as research papers. Representative references are essential to high-quality papers. Academic citation recommendation refers to providing the recommendation of citations for the author of papers when they write. With the help of citation recommendatio n, researchers can improve the efficiency of writing academic papers and reduce the omission of important related literature. To achieve this goal, some methods were proposed. Many of them used citation networks to learn the representation of papers and chose references, they tended to ignore the content properties of papers. There are also some methods used partial properties to recommend citation. But their performance can be further improved. In this paper, we propose a citation recommendation method based on context correlation. We use two neural network models to learn the representations of papers and their references, then calculate the context similarity of them. Besides, we also introduce the publishing time and authority of papers, two key properties of papers for citation evaluation. In the experiment section, we compare our method with other methods and evaluate the performance of different properties choice in our method, it shows that our method outperforms some baselines and the combination of the dimensions including time, authority and context performs better.},
  archive      = {J_IDA},
  author       = {Zhao, Weidong and Yu, Zhaoxin and Wu, Ran},
  doi          = {10.3233/IDA-195041},
  journal      = {Intelligent Data Analysis},
  month        = {1},
  number       = {1},
  pages        = {225-243},
  shortjournal = {Intell. Data Anal.},
  title        = {A citation recommendation method based on context correlation},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hierarchical features-based targeted aspect extraction from
online reviews. <em>IDA</em>, <em>25</em>(1), 205–223. (<a
href="https://doi.org/10.3233/IDA-194952">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the prevalence of online review websites, large-scale data promote the necessity of focused analysis. This task aims to capture the information that is highly relevant to a specific aspect. However, the broad scope of the aspects of the various products makes this task overarching but challeng ing. A commonly used solution is to modify the topic models with additional information to capture the features for a specific aspect (referred to as a targeted aspect). However, the existing topic models, either perform the full analysis to capture features as many as possible or estimate the similarity to capture features as coherent as possible, overlook the fine-grained semantic relations between the features, resulting in the captured features coarse and confusing. In this paper, we propose a novel Hierarchical Features-based Topic Model (HFTM) to extract targeted aspects from online reviews, then to capture the aspect-specific features. Specifically, our model can not only capture the direct features posing target-to-feature semantics but also capture the latent features posing feature-to-feature semantics. The experiments conducted on real-world datasets demonstrate that HFTMl outperforms the state-of-the-art baselines in terms of both aspect extraction and document classification.},
  archive      = {J_IDA},
  author       = {He, Jin and Li, Lei and Wang, Yan and Wu, Xindong},
  doi          = {10.3233/IDA-194952},
  journal      = {Intelligent Data Analysis},
  month        = {1},
  number       = {1},
  pages        = {205-223},
  shortjournal = {Intell. Data Anal.},
  title        = {Hierarchical features-based targeted aspect extraction from online reviews},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A time series approach to player churn and conversion in
videogames. <em>IDA</em>, <em>25</em>(1), 177–203. (<a
href="https://doi.org/10.3233/IDA-194940">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Players of a free-to-play game are divided into three main groups: non-paying active users, paying active users and inactive users. A State Space time series approach is then used to model the daily conversion rates between the different groups, i.e., the probability of transitioning from one group to another. This allows, not only for predictions on how these rates are to evolve, but also for a deeper understanding of the impact that in-game planning and calendar effects have. It is also used in this work for the detection of marketing and promotion campaigns about which no information is available. In particular, two different State Space formulations are considered and compared: an Autoregressive Integrated Moving Average process and an Unobserved Components approach, in both cases with a linear regression to explanatory variables. Both yield very close estimations for covariate parameters, producing forecasts with similar performances for most transition rates. While the Unobserved Components approach is more robust and needs less human intervention in regards to model definition, it produces significantly worse forecasts for non-paying user abandonment probability. More critically, it also fails to detect a plausible marketing and promotion campaign scenario.},
  archive      = {J_IDA},
  author       = {Fernández del Río, Ana and Guitart, Anna and Periánẽz, África},
  doi          = {10.3233/IDA-194940},
  journal      = {Intelligent Data Analysis},
  month        = {1},
  number       = {1},
  pages        = {177-203},
  shortjournal = {Intell. Data Anal.},
  title        = {A time series approach to player churn and conversion in videogames},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Using optimized statistical distances to confront
distributed denial of service attacks in software defined networks.
<em>IDA</em>, <em>25</em>(1), 155–176. (<a
href="https://doi.org/10.3233/IDA-194796">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software-defined networks (SDN) are an emerging architecture that provides promising amends to put an end to current infrastructure constraints by optimized bandwidth utilization, flexibility in network management and configuration, and pulling down operating costs in traditional network structures . Despite the advantages of this architecture, SDNs may become the victim of a distributed denial of service (DDOS) attacks as the result of potential vulnerabilities in various layers. Therefore, the rapid detection of attack traffic in the early stages is very important. In this paper, we have proposed statistical solution to detect and to mitigate distributed denial of service attack in software-defined networks utilizing the unique capabilities of the SDN architecture. Here, the exponential weighted moving average protection mechanism (EWMA) in statistical distances is exploited. The simulation results of our extensive experiments showed that our mechanism is able to quick detection of attack traffics and take amendatory actions. Moreover, the evaluations show the superiority of the proposed algorithm with respect to other statistical methods.},
  archive      = {J_IDA},
  author       = {Ghasabi, Mozhgan and Deypir, Mahmood},
  doi          = {10.3233/IDA-194796},
  journal      = {Intelligent Data Analysis},
  month        = {1},
  number       = {1},
  pages        = {155-176},
  shortjournal = {Intell. Data Anal.},
  title        = {Using optimized statistical distances to confront distributed denial of service attacks in software defined networks},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient facial expression recognition based on
convolutional neural network. <em>IDA</em>, <em>25</em>(1), 139–154. (<a
href="https://doi.org/10.3233/IDA-194965">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of research in Facial Expression Recognition (FER) is to build a robust and strong recognizability model. In this paper, we propose a new scheme for FER systems based on convolutional neural network. Part of the regular convolution operation is replaced by depthwise separable convolution t o reduce the number of parameters and the computational workload; the self-adaption joint loss function is adopted to improve the classification performance. In addition, we balance our train set through data augmentation, and we preprocess the input images through illumination processing, face detection, and other methods, effectively maximizing the expression recognition rate. Experiments to validate our methods are conducted based on the TensorFlow platform and Fer2013 dataset. We analyze the experimental results before and after train set balancing and network model modification, and we compare our results with those of other researchers. The results show that our method is effective at increasing the expression recognition rate under the same experiment conditions. We further conduct an experiment on our own expression dataset relevant to driving safety, and it yields similar results.},
  archive      = {J_IDA},
  author       = {Cai, Yongxiang and Gao, Jingwen and Zhang, Gen and Liu, Yuangang},
  doi          = {10.3233/IDA-194965},
  journal      = {Intelligent Data Analysis},
  month        = {1},
  number       = {1},
  pages        = {139-154},
  shortjournal = {Intell. Data Anal.},
  title        = {Efficient facial expression recognition based on convolutional neural network},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Using the beta distribution technique to detect attacked
items from collaborative filtering. <em>IDA</em>, <em>25</em>(1),
121–137. (<a href="https://doi.org/10.3233/IDA-194935">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A recommendation system is based on the user and the items, providing appropriate items to the user and effectively helping the user to find items that may be of interest. The most commonly used recommendation method is collaborative filtering. However, in this case, the recommendation system will be injected with false data to create false ratings to push or nuke specific items. This will affect the user’s trust in the recommendation system. After all, it is important that the recommendation system provides a trusted recommendation item. Therefore, there are many algorithms for detecting attacks. In this article, it proposes a method to detect attacks based on the beta distribution. Different researchers in the past assumed that the attacker only attacked one target item in the user data. This research simulated an attacker attacking multiple target items in the experiment. The result showed a detection rate of more than 80%, and the false rate was within 16%.},
  archive      = {J_IDA},
  author       = {Hsu, Ping-Yu and Chung, Jui-Yi and Liu, Yu-Chin},
  doi          = {10.3233/IDA-194935},
  journal      = {Intelligent Data Analysis},
  month        = {1},
  number       = {1},
  pages        = {121-137},
  shortjournal = {Intell. Data Anal.},
  title        = {Using the beta distribution technique to detect attacked items from collaborative filtering},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Comparative study on credit card fraud detection based on
different support vector machines. <em>IDA</em>, <em>25</em>(1),
105–119. (<a href="https://doi.org/10.3233/IDA-195011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Credit card fraud is the new financial fraud crime accompanied by the gradual development of the economy which causes billions of dollars of losses every year. Credit card fraud case not only seriously violated the cardholder benefits and financial institutions, but also undermined the credit manag ement order. However, fraudsters keep exploring new crime strategies constantly which exacerbates the crime rate of fraud. Thus, a predictive model for credit card fraud detection is essential to minimize its losses. By distinguishing between fraud and non-fraud, machine learning is one of the most efficient solutions for detecting fraud. Support vector machines have proven to be a novel algorithm with excellent performance. Nevertheless, the performance of SVM depends largely on the correct choice of model parameters (C and g), which could cause that the false positive was very high if the kernel function type and parameter cannot be selected properly. In this paper, based on the real transaction data of the credit card business, firstly, it will find the optimal kernel function suitable for the data set. Secondly, this paper will propose the method of optimizing the support vector machine parameters by the cuckoo search algorithm, genetic algorithm and particle swarm optimization algorithm. Last but not least, the Linear kernel function was found to be the best kernel function with an accuracy rate of 91.56%. Furthermore, the Radial basis function is used to optimize the kernel function, which can improve the accuracy from 42.86% to the highest accuracy rate of 98.05%. Compared with CS-SVM and GA-SVM, PSO-SVM has the best overall performance.},
  archive      = {J_IDA},
  author       = {Li, Chenglong and Ding, Ning and Zhai, Yiming and Dong, Haoyun},
  doi          = {10.3233/IDA-195011},
  journal      = {Intelligent Data Analysis},
  month        = {1},
  number       = {1},
  pages        = {105-119},
  shortjournal = {Intell. Data Anal.},
  title        = {Comparative study on credit card fraud detection based on different support vector machines},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Energy modeling of hoeffding tree ensembles. <em>IDA</em>,
<em>25</em>(1), 81–104. (<a
href="https://doi.org/10.3233/IDA-194890">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy consumption reduction has been an increasing trend in machine learning over the past few years due to its socio-ecological importance. In new challenging areas such as edge computing, energy consumption and predictive accuracy are key variables during algorithm design and implementation. State-of-the-art ensemble stream mining algorithms are able to create highly accurate predictions at a substantial energy cost. This paper introduces the nmin adaptation method to ensembles of Hoeffding tree algorithms, to further reduce their energy consumption without sacrificing accuracy. We also present extensive theoretical energy models of such algorithms, detailing their energy patterns and how nmin adaptation affects their energy consumption. We have evaluated the energy efficiency and accuracy of the nmin adaptation method on five different ensembles of Hoeffding trees under 11 publicly available datasets. The results show that we are able to reduce the energy consumption significantly, by 21% on average, affecting accuracy by less than one percent on average.},
  archive      = {J_IDA},
  author       = {García-Martín, Eva and Bifet, Albert and Lavesson, Niklas},
  doi          = {10.3233/IDA-194890},
  journal      = {Intelligent Data Analysis},
  month        = {1},
  number       = {1},
  pages        = {81-104},
  shortjournal = {Intell. Data Anal.},
  title        = {Energy modeling of hoeffding tree ensembles},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Classification from positive and unlabeled data based on
likelihood invariance for measurement. <em>IDA</em>, <em>25</em>(1),
57–79. (<a href="https://doi.org/10.3233/IDA-194980">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose novel approaches for classification from positive and unlabeled data (PUC) based on maximum likelihood principle. These are particularly suited to measurement tasks in which the class prior of the target object in each measurement is unknown and significantly different from the class prior used for training, while the likelihood function representing the observation process is invariant over the training and measurement stages. Our PUCs effectively work without estimating the class priors of the unlabeled objects. First, we present a PUC approach called Naive Likelihood PUC (NL-PUC) using the maximum likelihood principle in a nontrivial but rather straightforward manner. The extended version called Enhanced Likelihood PUC (EL-PUC) employs an algorithm iteratively improving the likelihood estimation of the positive class. This is advantageous when the availability of the labeled positive data is limited. These characteristics are demonstrated both theoretically and experimentally. Moreover, the practicality of our PUCs is demonstrated in a real application to single molecule measurement.},
  archive      = {J_IDA},
  author       = {Yoshida, Takeshi and Washio, Takashi and Ohshiro, Takahito and Taniguchi, Masateru},
  doi          = {10.3233/IDA-194980},
  journal      = {Intelligent Data Analysis},
  month        = {1},
  number       = {1},
  pages        = {57-79},
  shortjournal = {Intell. Data Anal.},
  title        = {Classification from positive and unlabeled data based on likelihood invariance for measurement},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel approach to fully representing the diversity in
conditional dependencies for learning bayesian network classifier.
<em>IDA</em>, <em>25</em>(1), 35–55. (<a
href="https://doi.org/10.3233/IDA-194959">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian network classifiers (BNCs) have proved their effectiveness and efficiency in the supervised learning framework. Numerous variations of conditional independence assumption have been proposed to address the issue of NP-hard structure learning of BNC. However, researchers focus on identifying conditional dependence rather than conditional independence, and information-theoretic criteria cannot identify the diversity in conditional (in)dependencies for different instances. In this paper, the maximum correlation criterion and minimum dependence criterion are introduced to sort attributes and identify conditional independencies, respectively. The heuristic search strategy is applied to find possible global solution for achieving the trade-off between significant dependency relationships and independence assumption. Our extensive experimental evaluation on widely used benchmark data sets reveals that the proposed algorithm achieves competitive classification performance compared to state-of-the-art single model learners (e.g., TAN, KDB, KNN and SVM) and ensemble learners (e.g., ATAN and AODE).},
  archive      = {J_IDA},
  author       = {Wang, Limin and Chen, Peng and Chen, Shenglei and Sun, Minghui},
  doi          = {10.3233/IDA-194959},
  journal      = {Intelligent Data Analysis},
  month        = {1},
  number       = {1},
  pages        = {35-55},
  shortjournal = {Intell. Data Anal.},
  title        = {A novel approach to fully representing the diversity in conditional dependencies for learning bayesian network classifier},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A lazy feature selection method for multi-label
classification. <em>IDA</em>, <em>25</em>(1), 21–34. (<a
href="https://doi.org/10.3233/IDA-194878">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many important application domains, such as text categorization, biomolecular analysis, scene or video classification and medical diagnosis, instances are naturally associated with more than one class label, giving rise to multi-label classification problems. This has led, in recent years, to a substantial amount of research in multi-label classification. More specifically, feature selection methods have been developed to allow the identification of relevant and informative features for multi-label classification. This work presents a new feature selection method based on the lazy feature selection paradigm and specific for the multi-label context. Experimental results show that the proposed technique is competitive when compared to multi-label feature selection techniques currently used in the literature, and is clearly more scalable, in a scenario where there is an increasing amount of data.},
  archive      = {J_IDA},
  author       = {Pereira, Rafael B. and Plastino, Alexandre and Zadrozny, Bianca and Merschmann, Luiz H.C.},
  doi          = {10.3233/IDA-194878},
  journal      = {Intelligent Data Analysis},
  month        = {1},
  number       = {1},
  pages        = {21-34},
  shortjournal = {Intell. Data Anal.},
  title        = {A lazy feature selection method for multi-label classification},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Real-time adaptive fuzzy density clustering for multi-target
data association. <em>IDA</em>, <em>25</em>(1), 5–19. (<a
href="https://doi.org/10.3233/IDA-194978">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of data association for tracking multiple targets based on using the ship-borne radar is addressed in this study. A robust fuzzy density clustering algorithm is proposed, that contains three steps. At first, a customized form of adaptive density clustering is used to determine valid mea surements for each target’s state. In the second step, the degree of fuzzy membership for each valid measurement is determined based on the maximum entropy approach. At the final step, the measurements with a maximum degree of membership are used for updating the position of the targets. The proposed approach does not require gating techniques and led to the reduction of steps in comparison with other data association methods. In addition, the effect of ship movement in the performance of the tracking filter, based on the adaptive extended Kalman filter (AEKF) was studied. The efficiency and effectiveness of the proposed algorithm are compared with the nearest neighbor (NN) with Mahalanobis distance and Fuzzy nearest neighbor (FNN) methods. The results demonstrate the main advantages of the proposed algorithm, including its simplicity and suitability for real-time target tracking in cluttered environments.},
  archive      = {J_IDA},
  author       = {Nazari, Mousa and Pashazadeh, Saeid},
  doi          = {10.3233/IDA-194978},
  journal      = {Intelligent Data Analysis},
  month        = {1},
  number       = {1},
  pages        = {5-19},
  shortjournal = {Intell. Data Anal.},
  title        = {Real-time adaptive fuzzy density clustering for multi-target data association},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021d). Editorial. <em>IDA</em>, <em>25</em>(1), 1–3. (<a
href="https://doi.org/10.3233/IDA-200017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IDA},
  doi          = {10.3233/IDA-200017},
  journal      = {Intelligent Data Analysis},
  month        = {1},
  number       = {1},
  pages        = {1-3},
  shortjournal = {Intell. Data Anal.},
  title        = {Editorial},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
