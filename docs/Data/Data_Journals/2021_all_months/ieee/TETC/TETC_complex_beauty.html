<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TETC_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tetc---185">TETC - 185</h2>
<ul>
<li><details>
<summary>
(2021). Enhancing reliability of emerging memory technology for
machine learning accelerators. <em>TETC</em>, <em>9</em>(4), 2234–2240.
(<a href="https://doi.org/10.1109/TETC.2020.2984992">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An efficient and reliable Multi-Level Cell (MLC) Spin-Transfer Torque Random Access Memory (STT-RAM) is proposed based on a Drop-And-Rearrange Approach , called DARA . Since CNN models are rather robust, less important bits are dropped, allowing important bits to be written in safe and reliable Single-Level Cell mode. Also, bits are rearranged to make the representation better aligned with memory cell characteristics. Bits with higher impact on the features value are stored in safer bit positions reducing the chance of read/write circuits to malfunction. Experimental results show that our approach provides comparable to error-free scenario reliability level, while doubling the bandwidth and maintaining error rate of less than 0.02 percent.},
  archive      = {J_TETC},
  author       = {Masoomeh Jasemi and Shaahin Hessabi and Nader Bagherzadeh},
  doi          = {10.1109/TETC.2020.2984992},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {2234-2240},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Enhancing reliability of emerging memory technology for machine learning accelerators},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A high performance, multi-bit output logic-in-memory adder.
<em>TETC</em>, <em>9</em>(4), 2223–2233. (<a
href="https://doi.org/10.1109/TETC.2020.2982951">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alternative approaches beyond charge-only-based electronics, and particularly, spin-based non-volatile (VN) devices, show promising potential to overcome power and latency issues. The NV spin-transfer torque magnetic random access memory (STT-MRAM), as one of the NV candidates can provide for the digital world the opportunity of an instant-on/off computing system design. It reduces both static and dynamic power caused mainly by the intrinsic leakage currents and large data traffic delay in CMOS logic circuits thanks to its high endurance, admissible read power consumption, and comparable read latency. In this paper, a novel multi-output logic-in-memory (LiM) adder based on STT-MRAM with monolith scheme is proposed, which can be used to design any multi-output LiM-based circuit. Two well-known schemes based on STT-MRAM, serialization, and carry prediction, selected for comparison along with state-of-the art methods. Due to serious reliability challenge in nanometer scale technology, the robustness of proposed adder is also analyzed in presence of CMOS and magnetic tunnel junction (MTJ) process variation. Finally, using the MTJ compact model, as a core element of STT-MRAM and the 16nm PTM CMOS model functional simulations have been done. Our results show that in the worst case, execution time of proposed method is 2x faster than the best related work, 400 and 250 percent improvement is observed in MTJ write energy and average power consumption respectively, and ∼4 percent degradation is found in read error rate and comparable area overhead. Adder is considered as a case study because of its highest applicability in the processors and the capability of extension to a multi-output one.},
  archive      = {J_TETC},
  author       = {Javad Talafy and Farzaneh Zokaee and Hamid R. Zarandi and Nader Bagherzadeh},
  doi          = {10.1109/TETC.2020.2982951},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {2223-2233},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {A high performance, multi-bit output logic-in-memory adder},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A blockchain-powered decentralized and secure computing
paradigm. <em>TETC</em>, <em>9</em>(4), 2201–2222. (<a
href="https://doi.org/10.1109/TETC.2020.2983007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thanks to the advances in machine learning, data-driven analysis tools have become valuable solutions for various applications. However, there still remain essential challenges to develop effective data-driven methods because of the need to acquire a large amount of data and to have sufficient computing power to handle the data. In many instances these challenges are addressed by relying on a cloud computing vendor. However, although commercial cloud vendors provide valuable platforms for data analytics, they can suffer from a lack of transparency, security, and privacy-preservation. Furthermore, reliance on cloud servers prevents applying big data analytics in environments where the computing power is distributed. To address these challenges, a decentralized, secure, and privacy-preserving computing paradigm is proposed to enable an asynchronized cooperative computing process amongst distributed and untrustworthy computing nodes that may have limited computing power and computing intelligence. This paradigm is designed by exploring blockchain, decentralized learning, and homomorphic encryption techniques. The performance of the proposed paradigm is evaluated via different scenarios in the simulation section.},
  archive      = {J_TETC},
  author       = {Gihan J. Mendis and Yifu Wu and Jin Wei and Moein Sabounchi and Rigoberto Roche},
  doi          = {10.1109/TETC.2020.2983007},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {2201-2222},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {A blockchain-powered decentralized and secure computing paradigm},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A stochastic geo-partitioning problem for mobile edge
computing. <em>TETC</em>, <em>9</em>(4), 2189–2200. (<a
href="https://doi.org/10.1109/TETC.2020.2978229">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The success of a mobile edge computing network depends critically on how to assign the edge servers to the user cells. The criterion for this assignment is application-specific. In many practical applications, the workload demanded by each cell is unknown and time-varying. So are the effective capacities of the servers. We need an assignment incurring minimum backhaul cost that is robust to these uncertainties. We also want to make the cells assigned to the same server form a geographically compact cluster. This challenge motivates us to introduce a novel stochastic geo-aware partitioning problem. As it is computationally hard, we propose a heuristic algorithm that can produce a range of solutions representing different tradeoffs between cost minimization versus geographical awareness. We evaluate the proposed algorithm using a real-world dataset.},
  archive      = {J_TETC},
  author       = {Duc A. Tran and Thuy T. Do and Ting Zhang},
  doi          = {10.1109/TETC.2020.2978229},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {2189-2200},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {A stochastic geo-partitioning problem for mobile edge computing},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). 3-phase adiabatic logic and its sound SCA evaluation.
<em>TETC</em>, <em>9</em>(4), 2175–2188. (<a
href="https://doi.org/10.1109/TETC.2020.2976711">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays there is no doubt on the susceptibility of pure cryptographic devices to side-channel analysis attacks. During the last decade, integration of corresponding countermeasures into devices which deal with security and privacy of the users has become a must. This motivated several research on designing countermeasures, one of which is to make use of power-balancing feature of adiabatic logic families which have been originally motivated for low-power applications. In this work we introduce the first such a construction which operates in three phases compared to the entire state-of-the-art schemes requiring at least four phases. We especially designed our proposed scheme to harden power-analysis SCA attacks. To this end, we considered several relevant design criteria. For example, we payed particular attention to the symmetry of the fundamental gates of our proposed 3-phase construction. Based on simulation results and information-theoretic based SCA evaluations we claim that our construction can harden power analysis attacks more than the state-of-the-art adiabatic logic families. We further highlight the importance of the way power clocks are generated for an adiabatic circuit, and show the negative effect of the widely-known stepwise charge sharing power clock generator on the SCA security. Accordingly, we present an adjustment on such a circuit followed by corresponding SCA evaluation of its application on various adiabatic logic families.},
  archive      = {J_TETC},
  author       = {Bijan Fadaeinia and Amir Moradi},
  doi          = {10.1109/TETC.2020.2976711},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {2175-2188},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {3-phase adiabatic logic and its sound SCA evaluation},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Lightweight privacy-preserving raw data publishing scheme.
<em>TETC</em>, <em>9</em>(4), 2170–2174. (<a
href="https://doi.org/10.1109/TETC.2020.2974183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data publishing or data sharing is an important part of analyzing network environments and improving the Quality of Service (QoS) in the Internet of Things (IoT). In order to stimulate data providers (i.e., IoT end-users) to contribute their data, privacy requirement is necessary when data is collected and published. In traditional privacy preservation techniques, such as k-anonymity, data aggregation and differential privacy, data is modified, aggregated, or added noise, the utility of the published data are reduced. Privacy-preserving raw data publishing is a more valuable solution, and &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$n$&lt;/tex-math&gt;&lt;/inline-formula&gt; -source anonymity based raw data collection is most promising by delinking raw data and their sources. In this article, a lightweight raw data collection scheme for publishing is proposed, in which the rawness and the unlinkability of published data are all really guaranteed with Shamir’s secret sharing, and shuffling algorithm. Moreover, it is lightweight and practical for the IoT environment by the performance evaluation.},
  archive      = {J_TETC},
  author       = {Jingxue Chen and Gao Liu and Yining Liu},
  doi          = {10.1109/TETC.2020.2974183},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {2170-2174},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Lightweight privacy-preserving raw data publishing scheme},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Design space exploration of stochastic computing
architectures implemented using integrated optics. <em>TETC</em>,
<em>9</em>(4), 2158–2169. (<a
href="https://doi.org/10.1109/TETC.2020.2969435">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Approximate computing allows to trade-off design energy efficiency with computing accuracy. Stochastic computing is an approximate computing technique, where numbers are represented as bit streams corresponding to probabilities. The serial computation of the bit streams leads to reduced hardware complexity but involves high latency, which is the main limitation of the technique. Integrated optics technology relies on high propagation speed of signals, which has the potential to reduce the processing latency in stochastic computing. However, the design of stochastic computing architectures implemented using integrated optics involves the exploration of numerous parameters at system and technological levels. In this work, we propose a design space exploration framework that allows to optimize energy efficiency, computing accuracy, and latency of such architectures. The efficiency of the framework is evaluated using a Gamma correction image processing application. Results show that, for processing 160 x 160 pixels images, an acceptable &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$ \times 4.5$&lt;/tex-math&gt;&lt;/inline-formula&gt; increase in the errors leads to &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$ \times 47$&lt;/tex-math&gt;&lt;/inline-formula&gt; energy efficiency and &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$ \times 16$&lt;/tex-math&gt;&lt;/inline-formula&gt; processing speed. We also show that the same computing accuracy can be obtained for different energy efficiency and computing latency, thus, validating the ability of the framework to explore the design space.},
  archive      = {J_TETC},
  author       = {Hassnaa El-Derhalli and SÉbastien Le Beux and SofiÈne Tahar},
  doi          = {10.1109/TETC.2020.2969435},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {2158-2169},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Design space exploration of stochastic computing architectures implemented using integrated optics},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Probabilistic interpolation recoder for energy-error-product
efficient DBNs with p-bit devices. <em>TETC</em>, <em>9</em>(4),
2146–2157. (<a href="https://doi.org/10.1109/TETC.2020.2965079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, a probabilistic interpolation recoder (PIR) circuit is developed for deep belief networks (DBNs) with probabilistic spin logic (p-bit)-based neurons. To verify the functionality and evaluate the performance of the PIRs, we have implemented a &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$784 \times 200 \times 10$&lt;/tex-math&gt;&lt;/inline-formula&gt; DBN circuit in SPICE for a pattern recognition application using the MNIST dataset. The PIR circuits are leveraged in the last hidden layer to interpolate the probabilistic output of the neurons, which are representing different output classes, through sampling the p-bit&#39;s output values and then counting them in a defined sampling time window. The PIR circuit is proposed as an alternative for conventional interpolation methods which were based on using a resistor-capacitor tank to integrate each neuron&#39;s output, followed by an analog-to-digital converter to generate the digital output. The circuit simulation results of PIR circuit exhibit at least 54, 81, and 78 percent reductions in power, energy, and energy-error-product, respectively, compared to previous techniques, without using any of the area-consuming analog components in the interpolation circuit. In addition, PIR circuits provide an inherent single stuck-at fault tolerant feature to mitigate both transient and permanent faults at the circuit&#39;s output. Reliability properties of the PIR circuits for single stuck-at faults are shown to be enhanced relative to conventional interpolation without requiring hardware redundancy.},
  archive      = {J_TETC},
  author       = {Hossein Pourmeidani and Shadi Sheikhfaal and Ramtin Zand and Ronald F. DeMara},
  doi          = {10.1109/TETC.2020.2965079},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {2146-2157},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Probabilistic interpolation recoder for energy-error-product efficient DBNs with p-bit devices},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Combined symbol error correction and spare through-silicon
vias for 3D memories. <em>TETC</em>, <em>9</em>(4), 2139–2145. (<a
href="https://doi.org/10.1109/TETC.2020.2965193">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three dimensional technology provides high density and bandwidth solutions for high-speed computing. Through-silicon vias (TSVs) are used to interconnect different layers of the stacked dies. Covering for faulty TSVs caused by manufacturing irregularities can be done by including spare TSVs in the chip design and rerouting signals to avoid the problematic vias. Temporary and permanent faulty TSVs can also be produced by other effects such as radiation and mechanical stress. Reed-Solomon (RS) codes are error correcting codes that are able to protect against errors in symbols. A set of bits transmitted through a TSV can be considered as a symbol and protected using RS codes. This article presents a scheme to combine spare TSVs, RS and hardwired seed bits to cope with faulty TSVs.},
  archive      = {J_TETC},
  author       = {Francisco Garcia-Herrero and Alfonso SÁnchez-MaciÁn and Juan Antonio Maestro},
  doi          = {10.1109/TETC.2020.2965193},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {2139-2145},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Combined symbol error correction and spare through-silicon vias for 3D memories},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ARMOR: An anti-counterfeit security mechanism for low cost
radio frequency identification systems. <em>TETC</em>, <em>9</em>(4),
2125–2138. (<a href="https://doi.org/10.1109/TETC.2020.2964435">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Counterfeited products are costing the global economy hundreds of billions of dollars annually. Radio frequency identification(RFID) technology provides a promising solution for this problem, wherein each product is fitted with a secure tag, which is difficult to forge. However, RFID technology is faced with numerous security threats, for example, if the communication link between the reader and the tag is compromised, then it will be possible for a malicious adversary to obtain the private data stored on the device. Tag cloning attacks have also been demonstrated to be feasible, which severely undermines the capabilities of the RFID technology to protect against counterfeiting. One solution to this problem is the use of authentication protocol; however, existing schemes do not support mutual authentication and are still vulnerable to tag cloning attacks. In this article, a new security mechanism is proposed, which consists of a lightweight three-flights mutual authentication protocol and an anti-counterfeit tag design. The proposed solution is based on combining the Rabin public-key encryption scheme with physically unclonable functions (PUF) technology. The security of the proposed protocol is systematically analysed and compared with existing schemes. The implementation cost of the proposed security primitives, assuming the 1024-bit public key, is 10139 GEs, which is suitable for low-cost RFID tags. Our results show that the proposed design is up-to 50 percent more area-efficient compared to systems based on Elliptic Curve Cryptography (ECC).},
  archive      = {J_TETC},
  author       = {Yildiran Yilmaz and Viet-Hoa Do and Basel Halak},
  doi          = {10.1109/TETC.2020.2964435},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {2125-2138},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {ARMOR: An anti-counterfeit security mechanism for low cost radio frequency identification systems},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient key-gate placement and dynamic scan obfuscation
towards robust logic encryption. <em>TETC</em>, <em>9</em>(4),
2109–2124. (<a href="https://doi.org/10.1109/TETC.2019.2963094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Logic encryption has emerged to be a potential solution to the problem of Intellectual Property (IP)-Piracy and counterfeiting. However, in the recent past, several attacks have been mounted on existing logic encryption strategies to extract the secret key. SAT attack, the most predominant one among them, exploits the unprotected Design-for-Testability (DfT) infrastructure as a backdoor to launch attacks on sequential circuits. Protecting the DfT infrastructure is of paramount importance to ensure the security of an Integrated Chip (IC). In this paper, we propose a new logic encryption scheme which dynamically obfuscates the scan operation for an unauthorized attempt of scan access. A detailed security analysis on the proposed secure DfT infrastructure demonstrates its ability to thwart SAT attack without compromising the testability of the design. A methodical key-gate placement strategy enables the proposed scheme to eliminate the leakage of key information through weak key-gate locations, offering protection against path sensitization and logic cone based attacks. Unlike other state-of-the-art SAT preventive schemes, our proposed method does not suffer from poor output corruption, which is a fundamental requirement of a logic encryption scheme.},
  archive      = {J_TETC},
  author       = {Rajit Karmakar and Harshit Kumar and Santanu Chattopadhyay},
  doi          = {10.1109/TETC.2019.2963094},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {2109-2124},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Efficient key-gate placement and dynamic scan obfuscation towards robust logic encryption},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Edge cloud server deployment with transmission power control
through machine learning for 6G internet of things. <em>TETC</em>,
<em>9</em>(4), 2099–2108. (<a
href="https://doi.org/10.1109/TETC.2019.2963091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing is an important technology for bringing a big pool of elastic resources to client devices. Their main drawback has long been the long distance between users and servers, but this has been remedied by Edge Cloud Computing, where the cloud servers are located in the network edge. Edge Cloud Computing is regarded as essential for future networks and consequently, there is plenty of research on how to optimize its operation. However, the vast majority of them ignore the decision of where the edge servers should be deployed, despite how severely this can affect the performance of the system. Furthermore, future networks must also deal with massive amounts of clients and servers, such as the ones characteristic of the Internet of Things and 6G Networks. This demands solutions that are scalable. Given these two points, we propose a Machine Learning-based server deployment policy in 6G Internet of Things environments. Our solution is proven to approach optimality while being feasible. Furthermore, we also prove that our proposal leads to lower latency and higher resource efficiency than conventional Edge Cloud Computing server deployment solutions.},
  archive      = {J_TETC},
  author       = {Tiago Koketsu Rodrigues and Katsuya Suto and Nei Kato},
  doi          = {10.1109/TETC.2019.2963091},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {2099-2108},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Edge cloud server deployment with transmission power control through machine learning for 6G internet of things},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Voting margin: A scheme for error-tolerant k nearest
neighbors classifiers for machine learning. <em>TETC</em>,
<em>9</em>(4), 2089–2098. (<a
href="https://doi.org/10.1109/TETC.2019.2963268">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning (ML) techniques such as classifiers are used in many applications, some of which are related to safety or critical systems. In this case, correct processing is a strict requirement and thus ML algorithms (such as for classification) must be error tolerant. A naive approach to implement error tolerant classifiers is to resort to general protection techniques such as modular redundancy. However, modular redundancy incurs in large overheads in many metrics such as hardware utilization and power consumption that may not be acceptable in applications that run on embedded or battery powered systems. Another option is to exploit the algorithmic properties of the classifier to provide protection and error tolerance at a lower cost. This paper explores this approach for a widely used classifier, the k Nearest Neighbors ( k NNs), and proposes an efficient scheme to protect it against errors. The proposed technique is based on a time-based modular redundancy (TBMR) scheme. The proposed scheme exploits the intrinsic redundancy of k NNs to drastically reduce the number of re-computations needed to detect errors. This is achieved by noting that when voting among the k nearest neighbors has a large majority, an error in one of the voters cannot change the result, hence voting margin (VM). This observation has been refined and extended in the proposed VM scheme to also avoid re-computations in some cases in which the majority vote is tight. The VM scheme has been implemented and evaluated with publicly available data sets that cover a wide range of applications and settings. The results show that by exploiting the intrinsic redundancy of the classifier, the proposed scheme is able to reduce the cost compared to modular redundancy by more than 60 percent in all configurations evaluated.},
  archive      = {J_TETC},
  author       = {Shanshan Liu and Pedro Reviriego and JosÉ Alberto HernÁndez and Fabrizio Lombardi},
  doi          = {10.1109/TETC.2019.2963268},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {2089-2098},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Voting margin: A scheme for error-tolerant k nearest neighbors classifiers for machine learning},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). COACH: Consistency aware check-pointing for nonvolatile
processor in energy harvesting systems. <em>TETC</em>, <em>9</em>(4),
2076–2088. (<a href="https://doi.org/10.1109/TETC.2019.2961007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, energy harvesting systems that utilize hybrid NVM-SRAM memory in their designs are introduced as a promising alternative for battery-operated systems. Since the ambient input power of an energy harvesting system fluctuates as the environmental conditions change, the system may stop the execution of programs until it receives enough energy to continue the execution. Resuming the execution of a program after the suspension may lead to data inconsistency in an energy harvesting system and threatens the correct functionality of the programs. In this article, we propose COACH, an energy-efficient consistency-aware memory scheme which guarantees the correct functionality and consistency of the program in an energy harvesting system. The experimental results show that COACH improves forward-progress of the programs in the system by up to 60 percent compared with the state of the art consistency-aware approaches without imposing considerable energy overhead to the system.},
  archive      = {J_TETC},
  author       = {Ali Hoseinghorban and Amir Mahdi Hosseini Monazzah and Mostafa Bazzaz and Bardia Safaei and Alireza Ejlali},
  doi          = {10.1109/TETC.2019.2961007},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {2076-2088},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {COACH: Consistency aware check-pointing for nonvolatile processor in energy harvesting systems},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploiting asymmetry in eDRAM errors for redundancy-free
error-tolerant design. <em>TETC</em>, <em>9</em>(4), 2064–2075. (<a
href="https://doi.org/10.1109/TETC.2019.2960491">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For some applications, errors have a different impact on data and memory systems depending on whether they change a zero to a one or the other way around; for an unsigned integer, a one to zero (or zero to one) error reduces (or increases) the value. For some memories, errors are also asymmetric; for example, in a DRAM, retention failures discharge the storage cell. The tolerance of such asymmetric errors can result in a robust and efficient system design. Error Control Codes (ECCs) are one common technique for memory protection against these errors by introducing some redundancy in memory cells. In this paper, the asymmetry in the errors in Embedded DRAMs (eDRAMs) is exploited for error-tolerant designs without using any ECC or parity, which are redundancy-free in terms of memory cells. A model for the impact of retention errors and refresh time of eDRAMs on the False Positive rate or False Negative rate of some eDRAM applications is proposed and analyzed. Bloom Filters (BFs) and read-only or write-through caches implemented in eDRAMs are considered as the first case studies for this model. For BFs, their tolerance to some zero to one errors (but not one to zero errors) is combined with the asymmetry of retention errors in eDRAMs to show that no ECC or parity is needed to protect the filter; moreover, the eDRAM refresh time can significantly be increased, thus reducing its power consumption. For caches, this paper shows that asymmetry in errors can be exploited also by using a redundancy-free error-tolerant scheme, which only introduces false negatives, but no false positives, therefore causing no data corruption. The proposed redundancy-free implementations have been compared with existing schemes for BFs and caches to show the benefits in terms of different figures of merit such as memory size, area, decoder/encoder complexity and delay. Finally, in the last case study, we show that the asymmetry of retention errors can be used to develop additional error correction capabilities in Modular Redundancy Schemes.},
  archive      = {J_TETC},
  author       = {SHANSHAN LIU and Pedro Reviriego and Jing Guo and JIE HAN and Fabrizio Lombardi},
  doi          = {10.1109/TETC.2019.2960491},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {2064-2075},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Exploiting asymmetry in eDRAM errors for redundancy-free error-tolerant design},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Joint distribution estimation and naïve bayes classification
under local differential privacy. <em>TETC</em>, <em>9</em>(4),
2053–2063. (<a href="https://doi.org/10.1109/TETC.2019.2959581">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Naïve Bayes classifier (NBC) is a fundamental and widely-used data mining tool. To respond to the growing privacy concern, several privacy-preserving NBC schemes have been proposed recently. Generally, the existing schemes mainly exploit two different techniques: one is secure multi-party computation (SMCP); and the other is (local) differential privacy (DP/LDP). However, the approaches with SMCP would employ some encryption algorithms, which results in heavy computation and communication costs and impedes the usage of the approaches in practice. The existing methods with DP/LDP also have some deficiencies. For instance, a trusted data curator is required or the class labels of individuals are revealed. To make up the drawbacks of previous schemes, in this article, we develop a novel scheme to train a Naïve Bayes classifier with privacy guarantee in the local setting. We first design a method (JESS) for joint distribution estimation under LDP. Then we apply JESS to calculate the conditional probability, the key of the Naïve Bayes classification and train a Naïve Bayes classifier. Additionally, we leverage extensive experiments to evaluate the effectiveness of our schemes designed for joint distribution and Naïve Bayes classification. Compared with the existing schemes, ours can achieve higher accuracy.},
  archive      = {J_TETC},
  author       = {Qiao Xue and Youwen Zhu and Jian Wang},
  doi          = {10.1109/TETC.2019.2959581},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {2053-2063},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Joint distribution estimation and naïve bayes classification under local differential privacy},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Subjective evaluation of high dynamic range imaging for face
matching. <em>TETC</em>, <em>9</em>(4), 2042–2052. (<a
href="https://doi.org/10.1109/TETC.2019.2958738">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human facial recognition in the context of surveillance, forensics and photo-ID verification is a task for which accuracy is critical. Quite often limitations in the overall quality of facial images reduces individuals’ ability in taking decisions regarding a person’s identity. To verify the suitability of advanced imaging techniques to improve individuals’ performance in face matching we investigate how High Dynamic Range (HDR) imaging compares with traditional low (or standard) dynamic range (LDR) imaging in a facial recognition task. An HDR face dataset with five different lighting conditions is created. Subsequently, this dataset is used in a controlled experiment ( &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$N$&lt;/tex-math&gt;&lt;/inline-formula&gt; = 40) to measure performance and accuracy of human participants when identifying faces in HDR versus LDR. Results demonstrate that face matching accuracy and reaction time are improved significantly by HDR imaging. This work demonstrates scope for realistic image reproduction and delivery in face matching tasks and suggests that security systems could benefit from the adoption of HDR imaging techniques.},
  archive      = {J_TETC},
  author       = {Rossella Suma and Kurt Debattista and Derrick Watson and Elisabeth Blagrove and Alan Chalmers},
  doi          = {10.1109/TETC.2019.2958738},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {2042-2052},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Subjective evaluation of high dynamic range imaging for face matching},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Trustee: A trust management system for fog-enabled cyber
physical systems. <em>TETC</em>, <em>9</em>(4), 2030–2041. (<a
href="https://doi.org/10.1109/TETC.2019.2957394">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a lightweight trust management system (TMS) for fog-enabled cyber physical systems (Fog-CPS). Trust computation is based on multi-factor and multi-dimensional parameters, and formulated as a statistical regression problem which is solved by employing random forest regression model. Additionally, as the Fog-CPS systems could be deployed in open and unprotected environments, the CPS devices and fog nodes are vulnerable to numerous attacks namely, collusion, self-promotion, bad-mouthing, ballot-stuffing, and opportunistic service. The compromised entities can impact the accuracy of trust computation model by increasing/decreasing the trust of other nodes. These challenges are addressed by designing a generic trust credibility model which can countermeasure the compromise of both CPS devices and fog nodes. The credibility of each newly computed trust value is evaluated and subsequently adjusted by correlating it with a standard deviation threshold. The standard deviation is quantified by computing the trust in two configurations of hostile environments and subsequently comparing it with the trust value in a legitimate/normal environment. Our results demonstrate that credibility model successfully countermeasures the malicious behaviour of all Fog-CPS entities i.e., CPS devices and fog nodes. The multi-factor trust assessment and credibility evaluation enable accurate and precise trust computation and guarantee a dependable Fog-CPS system.},
  archive      = {J_TETC},
  author       = {Aisha Kanwal Junejo and Nikos Komninos and Mithileysh Sathiyanarayanan and Bhawani Shankar Chowdhry},
  doi          = {10.1109/TETC.2019.2957394},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {2030-2041},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Trustee: A trust management system for fog-enabled cyber physical systems},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Highly-parallel FPGA accelerator for simulated quantum
annealing. <em>TETC</em>, <em>9</em>(4), 2019–2029. (<a
href="https://doi.org/10.1109/TETC.2019.2957177">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum annealing (QA) is a method to find the global optimum of a combinatorial optimization problem by using quantum fluctuations. Quantum annealers such as D-wave are efficient to solve small problems with less than 2048 variables. Simulated quantum annealing on digital computers allows us to solve large real-world problems. However, the processing time increases exponentially with the number of variables. This article proposes a highly-parallel accelerator for simulated quantum annealing exploiting spatial and temporal parallelism. The accelerator is implemented using “open computing language (OpenCL)” on FPGA. For 8,192 spin models, we achieve 145 times speed using 32 Trotters in one FPGA and 290 times speed-up using 64 Trotters in two FPGAs, compared to single-core CPU implementation.},
  archive      = {J_TETC},
  author       = {Hasitha Muthumala Waidyasooriya and Masanori Hariyama},
  doi          = {10.1109/TETC.2019.2957177},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {2019-2029},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Highly-parallel FPGA accelerator for simulated quantum annealing},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Audio hotspot attack: An attack on voice assistance systems
using directional sound beams and its feasibility. <em>TETC</em>,
<em>9</em>(4), 2004–2018. (<a
href="https://doi.org/10.1109/TETC.2019.2953041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel attack, called an “Audio Hotspot Attack,” which performs an inaudible malicious voice command attack, by targeting voice assistance systems, e.g., smart speakers or in-car navigation systems. The key idea of the approach is to leverage directional sound beams generated from parametric loudspeakers, which emit amplitude-modulated ultrasounds that will be self-demodulated in the air. Our work goes beyond the previous studies of inaudible voice command attack in the following three aspects: (1) the attack can succeed on a long distance (3.5 meters in a small room, and 12 meters in a long hallway), (2) it can control the spot of the audible area by using two directional sound beams, which consist of a carrier wave and a sideband wave, and (3) the proposed attack leverages a physical phenomenon i.e., non-linearity in the air, to attack voice assistance systems. To evaluate the feasibility of the attack, we performed extensive in-lab experiments and a user study involving 20 participants. The results demonstrated that the attack was feasible in a real-world setting. We discussed the extent of the threat, as well as the possible countermeasures against the attack.},
  archive      = {J_TETC},
  author       = {Ryo Iijima and Shota Minami and Yunao Zhou and Tatsuya Takehisa and Takeshi Takahashi and Yasuhiro Oikawa and Tatsuya Mori},
  doi          = {10.1109/TETC.2019.2953041},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {2004-2018},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Audio hotspot attack: An attack on voice assistance systems using directional sound beams and its feasibility},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DICO: A graph-DB framework for community detection on big
scholarly data. <em>TETC</em>, <em>9</em>(4), 1987–2003. (<a
href="https://doi.org/10.1109/TETC.2019.2952765">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread use of online social networks has also involved the scientific field in which researchers interact each other by publishing or citing a given paper. The huge amount of information about scientific research documents has been described through the term Big Scholarly Data . In this article we propose a framework, namely Discovery Information using COmmunity detection (DICO), for identifying overlapped communities of authors from Big Scholarly Data by modeling authors’ interactions through a novel graph-based data model combining jointly document metadata with semantic information. In particular, DICO presents three distinctive characteristics: i) the coauthorship network has been built from publication records using a novel approach for estimating relationships weight between users; ii) a new community detection algorithm based on Node Location Analysis has been developed to identify overlapped communities; iii) some built-in queries are provided to browse the generated network, though any graph-traversal query can be implemented through the Cypher query language. The experimental evaluation has been carried out to evaluate the efficacy of the proposed community detection algorithm on benchmark networks. Finally, DICO has been tested on a real-world Big Scholarly Dataset to show its usefulness working on the DBLP+AMiner dataset, that contains 1.7M+ distinct authors, 3M+ papers, handling 25M+ citation relationships.},
  archive      = {J_TETC},
  author       = {Fabio Mercorio and Mario Mezzanzanica and Vincenzo Moscato and Antonio Picariello and Giancarlo Sperlí},
  doi          = {10.1109/TETC.2019.2952765},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {1987-2003},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {DICO: A graph-DB framework for community detection on big scholarly data},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Blockchain mutability: Challenges and proposed solutions.
<em>TETC</em>, <em>9</em>(4), 1972–1986. (<a
href="https://doi.org/10.1109/TETC.2019.2949510">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain&#39;s evolution during the past decade is astonishing: from bitcoin to over 2.000 altcoins, and from decentralised electronic payments to transactions programmable by smart contracts and complex tokens governed by decentralised organisations. While the new generation of blockchain applications is still evolving, blockchain&#39;s technical characteristics are also advancing. Yet, immutability, a hitherto indisputable and highly advertised property according to which blockchain data cannot be edited nor deleted, remains the cornerstone of blockchain&#39;s security. Nevertheless, blockchain&#39;s immutability is being called into question lately in the light of the new erasing requirements imposed by the GDPR&#39;s “ Right to be Forgotten (RtbF) ” provision. As the RtbF obliges blockchain data to be editable in order restricted content redactions, modifications or deletions to be applied when requested, blockchains compliance with the regulation is indeed challenging, if not impracticable. Towards resolving this contradiction, various methods and techniques for mutable blockchains have been proposed to satisfy regulatory erasing requirements while preserving blockchains’ security. To this end, this work aims to provide a comprehensive review on the state-of-the-art research approaches, technical workarounds and advanced cryptographic techniques that have been put forward to resolve this conflict and to discuss their potentials, constraints and limitations when applied in the wild to either permissioned or permissionless blockchains.},
  archive      = {J_TETC},
  author       = {Eugenia Politou and Fran Casino and Efthimios Alepis and Constantinos Patsakis},
  doi          = {10.1109/TETC.2019.2949510},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {1972-1986},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Blockchain mutability: Challenges and proposed solutions},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reduced precision redundancy for reliable processing of
data. <em>TETC</em>, <em>9</em>(4), 1960–1971. (<a
href="https://doi.org/10.1109/TETC.2019.2947617">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information is an integral part of the correct and reliable operation of today&#39;s computing systems. Data either stored or provided as input to computation processing modules must be tolerant to many externally and internally induced destructive phenomena such as soft errors and faults, often of a transient nature but also in large numbers, thus causing catastrophic system failures. Together with error tolerance, reliable operation must be provided by reducing the large overheads often encountered at system-level when employing redundancy. While information-based techniques can also be used in some of these schemes, the complexity and limited capabilities for implementing high order correction functions for decoding limit their application due to poor performance; therefore, N Modular Redundancy ( N MR) is often employed. In N MR the correct output is given by majority voting among the N input copies of data. Reduced Precision Redundancy (RPR) has been advocated to reduce the redundancy, mostly for the case of &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$N= 3$&lt;/tex-math&gt;&lt;/inline-formula&gt; ; in a 3RPR scheme, one full precision (FP) input is needed while two inputs require reduced precision (RP) (usually by truncating some of the least significant bits (LSBs) in the input data). However, its decision logic is more complex than a 3MR scheme. This paper proposes a novel N RPR scheme with a simple comparison-based approach; the realistic case of &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$N= 5$&lt;/tex-math&gt;&lt;/inline-formula&gt; is considered as an example to explain in detail such proposed scheme; different arrangements for the redundancy (with three or four FP data copies) are considered. In addition to the design of the decision circuit, a probabilistic analysis is also pursued to determine the conditions by which RPR data is provided as output; it is shown that its probability is very small. Different applications of the proposed N RPR system are presented; in these applications, data is used either as memory output and/or for computing the discrete cosine transform. In both cases, the proposed 5RPR scheme shows considerable advantages in terms of redundancy management and reliable image processing.},
  archive      = {J_TETC},
  author       = {SHANSHAN LIU and Ke Chen and Pedro Reviriego and Weiqiang Liu and AHMED LOURI and Fabrizio Lombardi},
  doi          = {10.1109/TETC.2019.2947617},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {1960-1971},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Reduced precision redundancy for reliable processing of data},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Performance and area trade-off of 3D-stacked DRAM based chip
multiprocessor with hybrid interconnect. <em>TETC</em>, <em>9</em>(4),
1945–1959. (<a href="https://doi.org/10.1109/TETC.2019.2946887">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, the number of cores on a chip multiprocessor is growing to increase system performance. However, inadequate on-chip interconnection and memory bandwidth have diminished the potential of these chip multiprocessors. High performance interconnects, 3D-stacked main memory, and large on-chip caches are the architectural parameters used to tackle this issue. For a fixed die size, high performance interconnects, and the 3D-stacked memory fosters the increasing rate of the number of cores on a chip multiprocessor whereas increasing the size of on-chip cache poses a restriction. In this work, we study the trade-off between the performance and overall chip area (evaluated using the number of cores, their types and cache size per core) of the chip multiprocessor for different combinations of the interconnection network, DRAM memory (off-chip or on-chip) and self-adaptive page mapping. Our experiments show that for the base-case (chip multiprocessor with the off-chip DRAM and without hybrid interconnect) architecture and without page mapping technique, to increase the core count for a fixed die size, merely shrinking the cache size degrades the performance. Whereas, reducing the cache size and increasing the chip multiprocessor core count along with our considered target architecture and page mapping technique scale up the performance.},
  archive      = {J_TETC},
  author       = {Rakesh Pandey and Aryabartta Sahu},
  doi          = {10.1109/TETC.2019.2946887},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {1945-1959},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Performance and area trade-off of 3D-stacked DRAM based chip multiprocessor with hybrid interconnect},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Surrogate-assisted evolutionary framework with adaptive
knowledge transfer for multi-task optimization. <em>TETC</em>,
<em>9</em>(4), 1930–1944. (<a
href="https://doi.org/10.1109/TETC.2019.2945775">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-task optimization is a hot research topic in the field of evolutionary computation. This paper proposes an efficient surrogate-assisted multi-task evolutionary framework (named SaEF-AKT) with adaptive knowledge transfer for multi-task optimization. In the proposed SaEF-AKT, several tasks which are computationally expensive are solved jointly in each generation. Surrogate models are built based on the historical search information of each task to reduce the number of fitness evaluations. To improve the search efficiency, a general similarity measure mechanism and an adaptive knowledge transfer mechanism are proposed, which can help knowledge transfer among the tasks to be solved. The proposed SaEF-AKT is tested on a number of benchmark problems in multi-task optimization scenario and real-world time series regression problems. The experimental results demonstrate that the proposed framework can outperform several state-of-the-art multi-task optimization algorithms.},
  archive      = {J_TETC},
  author       = {Shijia Huang and Jinghui Zhong and Wei-Jie Yu},
  doi          = {10.1109/TETC.2019.2945775},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {1930-1944},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Surrogate-assisted evolutionary framework with adaptive knowledge transfer for multi-task optimization},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evaluating reliability of SSD-based i/o caches in enterprise
storage systems. <em>TETC</em>, <em>9</em>(4), 1914–1929. (<a
href="https://doi.org/10.1109/TETC.2019.2945087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {I/O caching techniques are widely employed in enterprise storage systems in order to enhance performance of I/O intensive applications in large-scale data centers. Due to higher performance compared to Hard Disk Drives (HDDs) and lower price and non-volatility compared to Dynamic Random-Access Memories (DRAM), Flash-based Solid-State Drives (SSDs) are used as a main media in the caching layer of storage systems. Although SSDs are known as non-volatile devices but recent studies have reported large number of data failures due to power outage in SSDs. To overcome the reliability implications of SSD-based I/O caching schemes, RAID-1 (mirrored) configuration is commonly used to avoid data loss due to uncommitted write operations. Such configuration, however, may still experience data loss in the cache layer due to correlated failures in SSDs. To our knowledge, none of previous studies have investigated the reliability of SSD-based I/O caching schemes in enterprise storage systems. In this paper, we present a comprehensive analysis investigating the reliability of SSD-based I/O caching architectures used in enterprise storage systems under power failure and high-operating temperature. We explore variety of SSDs from top vendors and investigate the cache reliability in mirrored configuration. To this end, we first develop a physical fault injection and failure detection platform and then investigate the impact of workload dependent parameters on the reliability of I/O cache in the presence of two common failure types in data centers, power outage and high temperature faults. We implement an I/O cache scheme using an open-source I/O cache module in Linux operating system. The experimental results obtained by conducting more than twenty thousand of physical fault injections on the implemented I/O cache with different write policies reveal that the failure rate of the I/O cache is significantly affected by workload dependent parameters. Our results show that unlike workload requests access pattern, the other workload dependent parameters such as request size, Working Set Size (WSS), and sequence of the accesses have considerable impact on the I/O cache failure rate. We observe a significant growth in the failure rate in the workloads by decreasing the size of the requests (by more than 14X). Furthermore, we observe that in addition to writes, the read accesses to the I/O cache are subjected to failure in presence of sudden power outage (the failure mainly occurs during promoting data to the cache). In addition, we observe that I/O cache experiences no data failure upon high temperature faults.},
  archive      = {J_TETC},
  author       = {Saba Ahmadian and Farhad Taheri and Hossein Asadi},
  doi          = {10.1109/TETC.2019.2945087},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {1914-1929},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Evaluating reliability of SSD-based I/O caches in enterprise storage systems},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Enabling workforce optimization in constrained
attribute-based access control systems. <em>TETC</em>, <em>9</em>(4),
1901–1913. (<a href="https://doi.org/10.1109/TETC.2019.2944787">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective utilization of human capital is one of the key requirements for any successful business endeavor, with reorganization necessary if there are nonproductive employees or employees that are retiring. However, while reorganizing tasks for newer employees, it should be ensured that the employees have the requisite capabilities of handling the assigned tasks. Furthermore, security constraints forbid any arbitrary assignment of tasks to employees and also enforce major dependencies on other employees who have access to the same tasks. Since Attribute Based Access Control (ABAC) is poised to emerge as the de facto model for specifying access control policies in commercial information systems, we consider organizational policies and constraints to be modeled with ABAC. Given the increasing size and scale of organizations, both in terms of employees and resources that need to be managed, it is crucial that computational solutions are developed to automate the process of employee to task assignment. In this work, we define the Employee Replacement Problem (ERP) which answers the question of whether a given set of employees can be replaced by a smaller set of employees, while ensuring that the desired security constraints are not violated. We prove that the problem is NP-hard and use CNF-SAT to obtain a solution. An extensive experimental evaluation is carried out on diverse data sets to validate the efficiency of the proposed solution.},
  archive      = {J_TETC},
  author       = {Arindam Roy and Shamik Sural and Arun Kumar Majumdar and Jaideep Vaidya and Vijayalakshmi Atluri},
  doi          = {10.1109/TETC.2019.2944787},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {1901-1913},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Enabling workforce optimization in constrained attribute-based access control systems},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Secure data sequence query framework based on multiple fogs.
<em>TETC</em>, <em>9</em>(4), 1883–1900. (<a
href="https://doi.org/10.1109/TETC.2019.2943524">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fog computing is used to process a large amount of data produced by terminal devices where fog nodes are the closest acquirers to the terminal devices. In fog computing, the processed data may be tampered with or illegally captured by some malicious nodes while the data is transferred or stored. So, when some applications need to require data process with high security, fog computing must provide a security approach to secure and check the final results. In this paper, we propose a secure data sequence query framework based on multiple fog servers, where we use multiple fog servers to store and provide data hashing values to verify corresponding data sequence. In the proposed scheme, the cloud server needs to pre-designate some Merkle hashing tree topologies to the fog network, then the fog server directly acquires related data from leaf-nodes (fog nodes) according to one of the pre-designated Merkle hashing tree topologies; at the same time, an actual Merkle hashing tree is constructed according to the selected Merkle hashing tree topology in the fog network. In fog computing, the related fog nodes participate in computing and transferring the hashing values on data, then the corresponding root node uses the &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$(t,n)$&lt;/tex-math&gt;&lt;/inline-formula&gt; threshold secret sharing scheme to compute and distribute the sub-secrets of the root value to other fog servers. Therefore, when a user requests a data sequence from a fog server, the fog server may immediately respond to the request and the other fog servers can provide the sub-secrets of hashing root value to verify the corresponding data sequence. Our proposed framework can ensure that users may obtain required data fast, accurately and reliably. Additionally, based on the data query security requirements of fog computing, we analyze the security of our proposed scheme. Our proposed scheme not only guarantees the reliability of data but also effectively protects data against various attacks.},
  archive      = {J_TETC},
  author       = {Ke Gu and Na Wu and Bo Yin and Weijia Jia},
  doi          = {10.1109/TETC.2019.2943524},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {1883-1900},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Secure data sequence query framework based on multiple fogs},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ScanSAT: Unlocking static and dynamic scan obfuscation.
<em>TETC</em>, <em>9</em>(4), 1867–1882. (<a
href="https://doi.org/10.1109/TETC.2019.2940750">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While financially advantageous, outsourcing key steps, such as testing, to potentially untrusted Outsourced Assembly and Test (OSAT) companies may pose a risk of compromising on-chip assets. Obfuscation of scan chains is a technique that hides the actual scan data from the untrusted testers; logic inserted between the scan cells, driven by a secret key, hides the transformation functions that map the scan-in stimulus (scan-out response) and the delivered scan pattern (captured response). While static scan obfuscation utilizes the same secret key, and thus, the same secret transformation functions throughout the lifetime of the chip, dynamic scan obfuscation updates the key periodically. In this paper, we propose ScanSAT: an attack that transforms a scan obfuscated circuit to its logic-locked version and applies the Boolean satisfiability (SAT) based attack, thereby extracting the secret key. We implement our attack, apply on representative scan obfuscation techniques, and show that ScanSAT can break both static and dynamic scan obfuscation schemes with 100 percent success rate. Moreover, ScanSAT is effective even for large key sizes and in the presence of scan compression.},
  archive      = {J_TETC},
  author       = {Lilas Alrahis and Muhammad Yasin and Nimisha Limaye and Hani Saleh and Baker Mohammad and Mahmoud Al-Qutayri and Ozgur Sinanoglu},
  doi          = {10.1109/TETC.2019.2940750},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {1867-1882},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {ScanSAT: Unlocking static and dynamic scan obfuscation},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A flip-flop based arbiter physical unclonable function
(APUF) design with high entropy and uniqueness for FPGA implementation.
<em>TETC</em>, <em>9</em>(4), 1853–1866. (<a
href="https://doi.org/10.1109/TETC.2019.2935465">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A PUF is a physical security primitive that allows to extract intrinsic digital identifiers from electronic devices. It is a promising candidate to improve security in lightweight devices targeted at IoT applications due to its low cost nature. The Arbiter PUF or APUF has been widely studied in the technical literature. However it often suffers from disadvantages such as poor uniqueness and reliability, particularly when implemented on FPGAs due to physical layout restrictions. To address these problems, a new design known as FF-APUF has been proposed; it offers a compact architecture, combined with good uniqueness and reliability properties, and is well suited to FPGA implementation. Many PUF designs have been shown to be vulnerable to machine learning (ML) based modelling attacks. In this paper, initial tests show that to attack the FF-APUF design requires more effort for the adversary than a conventional APUF design. A comprehensive analysis of the experimental results for the FF-APUF design is presented to show this outcome. An improved APUF design with a balanced routing, and the proposed FF-APUF design are both implemented on an Xilinx Artix-7 FPGA at 28 nm technology. The empirical min-entropy of the FF-APUF design across different devices is shown to be more than twice that of the conventional APUF design.},
  archive      = {J_TETC},
  author       = {Chongyan Gu and Weiqiang Liu and Yijun Cui and Neil Hanley and MÁire O’Neill and Fabrizio Lombardi},
  doi          = {10.1109/TETC.2019.2935465},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {1853-1866},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {A flip-flop based arbiter physical unclonable function (APUF) design with high entropy and uniqueness for FPGA implementation},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploring research in blockchain for healthcare and a
roadmap for the future. <em>TETC</em>, <em>9</em>(4), 1835–1852. (<a
href="https://doi.org/10.1109/TETC.2019.2936881">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Healthcare is a data-intensive domain, once a considerable volume of data is daily to monitoring patients, managing clinical research, producing medical records, and processing medical insurance claims. While the focus of applications of blockchain in practice has been to build distributed ledgers involving virtual tokens, the impetus of this emerging technology has now extended to the medical domain. With the increased popularity, it is crucial to study how this technology accompanied with a system for smart contracts can support and challenge the healthcare domain for all interrelated actors (patients, physicians, insurance companies, regulators) and involved assets (e.g., patients’ data, physician’s data, equipment’s and drug’s supply chain, etc.). The contributions of this paper are the following: (i) report the results of a systematic literature review conducted to identify, extract, evaluate and synthesize the studies on the symbiosis of blockchain in healthcare; (ii) summarize and categorize existing benefits/challenges on incorporating blockchain in healthcare domain; (iii) provide a framework that will facilitate new research activities; and (iv) establish the state of evidence with in-depth assessment.},
  archive      = {J_TETC},
  author       = {Mohamad Kassab and Joanna DeFranco and Tarek Malas and Phillip Laplante and Giuseppe Destefanis and Valdemar Vicente Graciano Neto},
  doi          = {10.1109/TETC.2019.2936881},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {1835-1852},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Exploring research in blockchain for healthcare and a roadmap for the future},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A modern approach to IP protection and trojan prevention:
Split manufacturing for 3D ICs and obfuscation of vertical
interconnects. <em>TETC</em>, <em>9</em>(4), 1815–1834. (<a
href="https://doi.org/10.1109/TETC.2019.2933572">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Split manufacturing (SM) and layout camouflaging (LC) are two promising techniques to obscure integrated circuits (ICs) from malicious entities during and after manufacturing. While both techniques enable protecting the intellectual property (IP) of ICs, SM can further mitigate the insertion of hardware Trojans (HTs). In this paper, we strive for the “best of both worlds,” that is we seek to combine the individual strengths of SM and LC. By jointly extending SM and LC techniques toward 3D integration, an up-and-coming paradigm based on stacking and interconnecting of multiple chips, we establish a modern approach to hardware security. Toward that end, we develop a security-driven CAD and manufacturing flow for 3D ICs in two variations, one for IP protection and one for HT prevention. Essential concepts of that flow are (i) “3D splitting” of the netlist to protect, (ii) obfuscation of the vertical interconnects (i.e., the wiring between stacked chips), and (iii) for HT prevention, a security-driven synthesis stage. We conduct comprehensive experiments on DRC-clean layouts of multi-million-gate DARPA and OpenCores designs (and others). Strengthened by extensive security analysis for both IP protection and HT prevention, we argue that entering the third dimension is eminent for effective and efficient hardware security.},
  archive      = {J_TETC},
  author       = {Satwik Patnaik and Mohammed Ashraf and Ozgur Sinanoglu and Johann Knechtel},
  doi          = {10.1109/TETC.2019.2933572},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {1815-1834},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {A modern approach to IP protection and trojan prevention: Split manufacturing for 3D ICs and obfuscation of vertical interconnects},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Highly efficient privacy preserving location-based services
with enhanced one-round blind filter. <em>TETC</em>, <em>9</em>(4),
1803–1814. (<a href="https://doi.org/10.1109/TETC.2019.2926385">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To take advantages of location-based services (LBS) while protecting user privacy against untrusted LBS providers, privacy preserving LBS have attracted increasing attention. Considering that users in an LBS system are often equipped with resource-constrained mobile devices, most existing privacy preserving LBS methods are based on anonymization techniques. However, these existing schemes still have some privacy and efficiency limitations. In this paper, we propose a novel privacy preserving LBS scheme, which simultaneously achieves user privacy protection and high query efficiency. Specifically, we utilize the &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$k$&lt;/tex-math&gt;&lt;/inline-formula&gt; -anonymity technique and the pseudo random function to protect the location privacy and the query message privacy of users. We design an enhanced one-round blind filter protocol (ORBF &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$_e$&lt;/tex-math&gt;&lt;/inline-formula&gt; ) based on the Paillier cryptosystem to securely filter out redundant records generated by the &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$k$&lt;/tex-math&gt;&lt;/inline-formula&gt; -anonymity technique. Compared with existing solutions, our ORBF &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$_e$&lt;/tex-math&gt;&lt;/inline-formula&gt; protocol not only ensures that users receive exactly satisfying results but also incurs a low computation and communication cost on the server side. Through the theoretical analysis and extensive experiments, we demonstrate the security and efficiency of our proposed scheme.},
  archive      = {J_TETC},
  author       = {Xingxin Li and Youwen Zhu and Jian Wang},
  doi          = {10.1109/TETC.2019.2926385},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {1803-1814},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Highly efficient privacy preserving location-based services with enhanced one-round blind filter},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Detection of limited magnitude errors in emerging multilevel
cell memories by one-bit parity (OBP) or two-bit parity (TBP).
<em>TETC</em>, <em>9</em>(4), 1792–1802. (<a
href="https://doi.org/10.1109/TETC.2019.2922631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emerging memory technologies rely on Multilevel Cells (MLC) to achieve high density; the use of multiple levels per cell allows storage of multiple bits, but it also reduces the margins and makes it error prone. Error control codes (including error correction and detection codes) can be used to protect MLC memories from errors; however, most existing coding schemes have been designed for traditional binary memories (so storing a single bit). In MLC memories, errors cause a change from a level to an adjacent level or to the next one (depending on the employed technology), so they are often referred to as limited magnitude errors. For a binary coding of levels to bits, these limited magnitude errors can corrupt several bits making traditional coding schemes inefficient. In this paper, error detection of MLC memories is considered when a binary encoding of levels to bits is used and two new schemes are proposed: One-Bit Parity (OBP) and Two-Bit Parity (TBP). The first scheme targets errors of magnitude-1 for detection using a single parity bit that checks only one bit per cell. The second scheme detects both magnitude-1 and -2 errors using only two parity bits. Both schemes are compared to existing alternatives, namely Gray coding combined with a single parity bit (GP) for OBP and Interleaved Parity (IP) for TBP. The results show that OBP reduces the encoding and error detection circuitry complexity and delay, while TBP additionally reduces the number of parity bits for some configurations. Therefore, OBP and TBP can be efficient alternatives for detection of limited magnitude errors in MLC memories that use a binary encoding of levels to bits.},
  archive      = {J_TETC},
  author       = {Shanshan Liu and Pedro Reviriego and Fabrizio Lombardi},
  doi          = {10.1109/TETC.2019.2922631},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {1792-1802},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Detection of limited magnitude errors in emerging multilevel cell memories by one-bit parity (OBP) or two-bit parity (TBP)},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Design of anonymous endorsement system in hyperledger
fabric. <em>TETC</em>, <em>9</em>(4), 1780–1791. (<a
href="https://doi.org/10.1109/TETC.2019.2920719">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Permissioned Blockchain has become quite popular with enterprises forming consortium since it prioritizes trust over privacy. One of the popular platforms for distributed ledger solution, Hyperledger Fabric , requires a transaction to be endorsed or approved by a group of special members known as endorsers before undergoing validation. To endorse a transaction, an endorser mentions its identity along with the signature so that it can be verified later. However, for certain transactions, difference in opinion may exist among endorsers. Disclosing the identity of an endorser may lead to conflict within the consortium. In such cases, an endorsement policy which not only allows an endorser to support a transaction discreetly, but at the same time takes into account the decision of the majority is preferred. Thus we propose an Anonymous Endorsement System which uses a threshold endorsement policy in order to address the issue. To realize a t-out-of-n endorsement policy, using any of the existing threshold ring signature for our endorsement system would have violated the privacy of endorsers as either the identity or the secret key of the endorsers get revealed to the party who recombines the signature after collecting each signature share. All these factors motivated us to design a new ring signature scheme, called Fabric’s Constant-Sized Linkable Ring Signature (FCsLRS) with Transaction-Oriented linkability for hiding identity of the endorsers. We have implemented the signature scheme in Golang and analyzed its security and performance by varying the Rivest-Shamir-Adleman (RSA) modulus size. Feasibility of implementation is supported by experimental analysis. Signature and tag generation time is quite fast and remains constant irrespective of change in message length or endorsement set size for a given RSA modulus value, assuming all the endorsers generates their signature in parallel. Each verifier is required to count and check individual valid ring signature. If the aggregate is above the threshold value, stated by the endorsement policy, then it confirms that the transaction is valid. This increases the verification time depending on the threshold value, but has very little effect on the scalability since generally &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$t&amp;lt;\!\!\!&amp;lt;n$&lt;/tex-math&gt;&lt;/inline-formula&gt; . Lastly, we also discuss the integration of the scheme on v1.2 Hyperledger Fabric.},
  archive      = {J_TETC},
  author       = {Subhra Mazumdar and Sushmita Ruj},
  doi          = {10.1109/TETC.2019.2920719},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {1780-1791},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Design of anonymous endorsement system in hyperledger fabric},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distributing tourists among POIs with an adaptive trip
recommendation system. <em>TETC</em>, <em>9</em>(4), 1765–1779. (<a
href="https://doi.org/10.1109/TETC.2019.2920484">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traveling is part of many people leisure activities and an increasing fraction of the economy comes from the tourism. Given a destination, the information about the different attractions, or points of interest (POIs), can be found on many sources. Among these attractions, finding the ones that could be of interest for a specific user, who may have different constraints—such as the available time or budget—represents a challenging task. Travel recommendation systems deal with this type of problems. Despite the vast literature on this topic, most of the solution does not take into account the impact of the suggestions on the level of crowding of POIs. This paper considers the trip planning problem focusing on user balancing among the different POIs. To this aim, we consider the effects of the previous recommendations, as well as estimates based on historical data, while devising a new recommendation. The problem is formulated as a multi-objective optimization problem, and a recommendation engine has been designed and implemented for exploring the solution space in near real-time, through a distributed version of the Simulated Annealing approach. We test our solution using a real dataset of users visiting the POIs of a touristic city, and we show that we are able to provide high quality recommendations, yet maintaining the attractions not overcrowded.},
  archive      = {J_TETC},
  author       = {Sara Migliorini and Damiano Carra and Alberto Belussi},
  doi          = {10.1109/TETC.2019.2920484},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {1765-1779},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Distributing tourists among POIs with an adaptive trip recommendation system},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Lightweight searchable public-key encryption with forward
privacy over IIoT outsourced data. <em>TETC</em>, <em>9</em>(4),
1753–1764. (<a href="https://doi.org/10.1109/TETC.2019.2921113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As more data from Industrial Internet of Things (IIoT) devices are been outsourced to the cloud, the need to ensure/achieve data privacy will be increasingly pressing. Searchable public-key encryption is a promising tool to achieve data privacy without sacrificing data usability. However, most existing searchable public-key encryption schemes are either inefficient (e.g., expensive in terms of encryption and searching keywords) or lack the required (security) features such as forward privacy. To address these limitations, we propose a lightweight searchable public-key encryption with forward privacy. Specifically, the scheme allows us to achieve forward privacy in a public-key cryptography (i.e., asymmetric) setting, and has the same search performance as a number of practical searchable symmetric encryption schemes. The formal security analysis shows that the proposed scheme is chosen-keyword attack resilient and achieves forward privacy. Finally, the experimental results on a real-world dataset demonstrate that the proposed scheme is highly efficient and scalable in IIoT applications.},
  archive      = {J_TETC},
  author       = {Biwen Chen and Libing Wu and Neeraj Kumar and Kim-Kwang Raymond Choo and Debiao He},
  doi          = {10.1109/TETC.2019.2921113},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {1753-1764},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Lightweight searchable public-key encryption with forward privacy over IIoT outsourced data},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MTFC: A multi-GPU training framework for cube-CNN-based
hyperspectral image classification. <em>TETC</em>, <em>9</em>(4),
1738–1752. (<a href="https://doi.org/10.1109/TETC.2020.3016978">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral images (HSI) classification has been a research hotspot in the remote sensing field. Deep learning methods such as Cube-CNN have been applied to address the HSI classification problem. However, mainstream frameworks exist a performance gap to train Cube-CNN, since they are not designed for processing high dimensional data like HSI. To close this gap, we propose a Multi-GPU Training Framework (MTFC) for Cube-CNN-based HSI classification. We first design a Parallel Neighbor Pixel Extraction (PNPE) algorithm for efficiently generating 3-dimensional cube samples from raw data. Then, to fully exploit massive GPU parallelism and realize unique characteristics of HSI and Cube-CNN, we employ optimizations in MTFC such as task division, fine-grained mapping between tasks and GPU thread blocks, shared memory usage reduction, etc. Finally, to further improve training speed, we take advantage of CUDA streams and multiple GPUs to train a mini-batches of data samples simultaneously. An extensive set of experiments highlights that MTFC constantly outperforms the two baselines Caffe and Theano for all measured metrics across all system configurations, while offering the same level of classification accuracy. The speedup is up to &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$3.6x$&lt;/tex-math&gt;&lt;/inline-formula&gt; when using a single GPU and MTFC can achieve a rough linear scaling on multiple GPUs.},
  archive      = {J_TETC},
  author       = {Ye Lu and Kunpeng Xie and Guanbin Xu and Han Dong and Cheng Li and Tao Li},
  doi          = {10.1109/TETC.2020.3016978},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {1738-1752},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {MTFC: A multi-GPU training framework for cube-CNN-based hyperspectral image classification},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). StreamFlow: Cross-breeding cloud with HPC. <em>TETC</em>,
<em>9</em>(4), 1723–1737. (<a
href="https://doi.org/10.1109/TETC.2020.3019202">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Workflows are among the most commonly used tools in a variety of execution environments. Many of them target a specific environment; few of them make it possible to execute an entire workflow in different environments, e.g., Kubernetes and batch clusters. We present a novel approach to workflow execution, called StreamFlow, that complements the workflow graph with the declarative description of potentially complex execution environments, and that makes it possible the execution onto multiple sites not sharing a common data space. StreamFlow is then exemplified on a novel bioinformatics pipeline for single-cell transcriptomic data analysis workflow.},
  archive      = {J_TETC},
  author       = {Iacopo Colonnelli and Barbara Cantalupo and Ivan Merelli and Marco Aldinucci},
  doi          = {10.1109/TETC.2020.3019202},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {1723-1737},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {StreamFlow: Cross-breeding cloud with HPC},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel bio-inspired approach for high-performance
management in service-oriented networks. <em>TETC</em>, <em>9</em>(4),
1709–1722. (<a href="https://doi.org/10.1109/TETC.2020.3018312">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Service-continuity in distributed computing can be enhanced by designing self-organized systems, with a non-fixed structure, able to modify their structure and organization, as well as adaptively react to internal and external environment changes. In this paper, an architecture exploiting a bio-inspired management approach, i.e., the functioning of cell metabolism, for specialized computing environments in Service-Oriented Networks (SONs) is proposed. Similar to the processes acting in metabolic networks, the nodes communicate to each other by means of stimulation or suppression chains giving rise to emergent behaviors to defend against foreign invaders, attacks, and malfunctioning. The main contribution of this work is a novel bio-inspired methodology for SON analysis to improve the network reliability and robustness for maintaining service-continuity. To show the effectiveness of the proposed computational framework, an embedded Field-Programmable Gate Array (FPGA) prototyped SON for a relevant healthcare imaging application is also outlined. In particular, our case study extracts and analyzes the Cerebral Vascular Tree from Magnetic Resonance Angiography series via a Maximum Intensity Projection algorithm; the proposed solution addresses and implements some basic issues of an interesting diagnosis tool for cerebral aneurysm detection. The prototyped system was tested and evaluated in terms of execution time and used resource analysis, by achieving a 4× speed-up factor compared to the software counterpart.},
  archive      = {J_TETC},
  author       = {Vincenzo Conti and Carmelo Militello and Leonardo Rundo and Salvatore Vitabile},
  doi          = {10.1109/TETC.2020.3018312},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {1709-1722},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {A novel bio-inspired approach for high-performance management in service-oriented networks},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Comparing data staging techniques for large scale brain
images. <em>TETC</em>, <em>9</em>(4), 1697–1708. (<a
href="https://doi.org/10.1109/TETC.2020.3028744">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of Deep Learning methods is identified as a key opportunity for enabling processing of extreme-scale scientific datasets. Efficient processing of these datasets thus requires the ability to store petabytes of data as well as to access this data fast. Hierarchical storage architectures are a promising technology to allow faster access to frequently used data, while providing high capacity. However, the efficient use of faster storage layers is hard, as they usually provide a lower capacity and store data only temporally. IO problems, which are caused by random access patterns, may not be solved by simply coping data to a faster layer. One way to overcome this bottleneck is staging. This means that frequently used data is temporarily stored in a faster memory or storage layer, so the processes can access it faster. In this work, we evaluate four different staging techniques for two Deep Learning usecases working on large scale brain images. These applications are very challenging for the underlying IO system, due to very high bandwidth requirements and random, fine granular access patterns. We analyse and evaluate these different methods on three different staging layers: local SSDs, the same local SSDs but clustered in a parallel file system, and a dedicated storage server. We also evaluate the performance of staging data in DRAM. As expected, the best performance is reached with DRAM staging or by using a usecase specific staging technique. However, since these methods cannot always be used, we developed a technique called split staging , which always can be used. With split staging, the performance, compared to the non-staged usecases can be improved up to the factor of four on our test machines and has comparable performance than specialized solutions of two storage layers. Our results also show that the performance often depends more on the data layout and thus the used transformations than on the bandwidth of the storage layer.},
  archive      = {J_TETC},
  author       = {Lena Oden},
  doi          = {10.1109/TETC.2020.3028744},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {1697-1708},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Comparing data staging techniques for large scale brain images},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Parallel computing for multi-objective train rescheduling.
<em>TETC</em>, <em>9</em>(4), 1683–1696. (<a
href="https://doi.org/10.1109/TETC.2020.3030984">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In railway traffic systems, it is essential to achieve a high punctuality to satisfy the goals of the involved stakeholders. Thus, whenever disturbances occur, it is important to effectively reschedule trains while considering the perspectives of various stakeholders. This typically involves solving a multi-objective train rescheduling problem, which is much more complex than its single-objective counterpart. Solving such a problem in real time for practically relevant problem sizes is computationally challenging. The reason is that the rescheduling solution(s) of interest are dispersed across a large search tree. The tree needs to be navigated fast while pruning off branches leading to undesirable solutions and exploring branches leading to potentially desirable solutions. The use of parallel computing enables such a fast navigation of the tree. This article presents a heuristic parallel algorithm to solve the multi-objective train rescheduling problem. The parallel algorithm combines a depth-first search with simultaneous breadth-wise tree exploration while searching the tree for solutions. An existing parallel algorithm for single-objective train rescheduling has been redesigned, primarily, by (i) pruning based on multiple metrics, and (ii) maintaining a set of upper bounds. The redesign improved the quality of the obtained rescheduling solutions and showed better speedups for several disturbance scenarios.},
  archive      = {J_TETC},
  author       = {Sai Prashanth Josyula and Johanna Törnquist Krasemann and Lars Lundberg},
  doi          = {10.1109/TETC.2020.3030984},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {1683-1696},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Parallel computing for multi-objective train rescheduling},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A computing system for discovering causal relationships
among human genes to improve drug repositioning. <em>TETC</em>,
<em>9</em>(4), 1667–1682. (<a
href="https://doi.org/10.1109/TETC.2020.3031024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The automatic discovery of causal relationships among human genes can shed light on gene regulatory processes and guide drug repositioning. To this end, a computationally-heavy method for causal discovery is distributed on a volunteer computing grid and, taking advantage of variable subsetting and stratification, proves to be useful for expanding local gene regulatory networks. The input data are purely observational measures of transcripts expression in human tissues and cell lines collected within the FANTOM project. The system relies on the BOINC platform and on optimized client code. The functional relevance of results, measured by analyzing the annotations of the identified interactions, increases significantly over the simple Pearson correlation between the transcripts. Additionally, in 82 percent of cases networks significantly overlap with known protein-protein interactions annotated in biological databases. In the two case studies presented, this approach has been used to expand the networks of genes associated with two severe human pathologies: prostate cancer and coronary artery disease. The method identified respectively 22 and 36 genes to be evaluated as novel targets for already approved drugs, demonstrating the effective applicability of the approach in pipelines aimed to drug repositioning.},
  archive      = {J_TETC},
  author       = {Enrico Blanzieri and Toma Tebaldi and Valter Cavecchia and Francesco Asnicar and Luca Masera and Gabriele TomÈ and Eleonora Nigro and Enrica Colasurdo and Matteo Ciciani and Chiara Mazzoni and Stefania Pilati},
  doi          = {10.1109/TETC.2020.3031024},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {1667-1682},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {A computing system for discovering causal relationships among human genes to improve drug repositioning},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Real-time personalized atrial fibrillation prediction on
multi-core wearable sensors. <em>TETC</em>, <em>9</em>(4), 1654–1666.
(<a href="https://doi.org/10.1109/TETC.2020.3014847">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the recent Internet-of-Things (IoT) era where biomedical applications require continuous monitoring of relevant data, edge computing keeps gaining more and more importance. These new architectures for edge computing include multi-core and parallel computing capabilities that can enable prevention diagnosis and treatment of diseases in ambulatory or home-based setups. In this article, we explore the benefits of the parallelization capabilities and computing heterogeneity of new wearable sensors in the context of a personalized online atrial fibrillation (AF) prediction method for daily monitoring. First, we apply optimizations to a single-core design to reduce energy, based on patient-specific training models. Second, we explore multi-core and memory banks configuration changes to adapt the computation and storage requirements to the characteristics of each patient. We evaluate our methodology on the Physionet Prediction Challenge (2001) publicly available database, and assess the energy consumption of single-core (ARM Cortex-M3 based) and new ultra-low power multi-core architectures (open-source RISC-V based) for next-generation of wearable platforms. Overall, our exploration at the application level highlights that a parallelization approach for personalized AF in multi-core wearable sensors enables energy savings up to 24% with respect to single-core sensors. Moreover, including the adaptation of the memory subsystem (size and number of memory banks), in combination with deep sleep energy saving modes, can overall provide total energy savings up to 34%, depending on the specific patient.},
  archive      = {J_TETC},
  author       = {Elisabetta De Giovanni and Adriana Arza ValdÉs and Miguel PeÓn-QuirÓs and Amir Aminifar and David Atienza},
  doi          = {10.1109/TETC.2020.3014847},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {1654-1666},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Real-time personalized atrial fibrillation prediction on multi-core wearable sensors},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Applying machine learning and parallel data processing for
attack detection in IoT. <em>TETC</em>, <em>9</em>(4), 1642–1653. (<a
href="https://doi.org/10.1109/TETC.2020.3006351">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Things (IoT) networks are kind of computer networks for which the problem of information security and, in particular, computer attack detection is acute. For solving this task the paper proposes a joint application of methods of machine learning and parallel data processing. The structure of basic classifiers is determined, which are designed for detecting the attacks in IoT networks, and a new approach to their combining is proposed. The statement of classification problem is formed in which the integral indicator of effectiveness is the ratio of accuracy to time of training and testing. For enhancing the speed of training and testing we propose the usage of the distributed data processing system Spark and multi-threaded mode. Moreover, a dataset pre-processing procedure is suggested, which leads to a significant reduction of the training sample volume. An experimental assessment of the proposed approach shows that the attack detection accuracy in IoT networks approaches 100 percent, and the speed of dataset processing increases in proportion to the number of parallel threads.},
  archive      = {J_TETC},
  author       = {Alexander Branitskiy and Igor Kotenko and Igor Saenko},
  doi          = {10.1109/TETC.2020.3006351},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {1642-1653},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Applying machine learning and parallel data processing for attack detection in IoT},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Guest editorial: Special section on new trends in parallel
and distributed computing for human sensible applications.
<em>TETC</em>, <em>9</em>(4), 1640–1641. (<a
href="https://doi.org/10.1109/TETC.2021.3113485">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The papers in this special section focus on collecting high-quality scientific contributions from the research community working in the fields of parallel and distributed computing, data analytics algorithms and big data frameworks, application specific processing. Specifically, the main focus is on emerging new computing trends that affect the concrete human life, the so-called “Human Sensible Applications”. Problems in parallel computing related to implement precision medicine and novel therapeutical targets, real-time architectures for biomedical IoT, computational biology and chemical compounds simulations, realistic modelling of human body organs, bioimaging processing, but even emerging computing systems for Human Sustainability, including weather and climate changes monitoring/prediction, resources management, safety, disaster prediction and prevention, belong to this scenario.},
  archive      = {J_TETC},
  author       = {Daniele D&#39;Agostino and Francesco Leporati and Massimo Torquati and Jingling Xue},
  doi          = {10.1109/TETC.2021.3113485},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {10},
  number       = {4},
  pages        = {1640-1641},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Guest editorial: Special section on new trends in parallel and distributed computing for human sensible applications},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Low-overhead adaptive brightness scaling for energy
reduction in OLED displays. <em>TETC</em>, <em>9</em>(3), 1625–1636. (<a
href="https://doi.org/10.1109/TETC.2019.2908257">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Organic Light Emitting Diode (OLED) is rapidly emerging as the mainstream mobile display technology. This is posing new challenges on the design of energy-saving solutions for OLED displays, specifically intended for interactive devices such as smartphones, smartwatches and tablets. To this date, the standard solution is brightness scaling. However, the amount of the scaling is typically set statically (either by the user, through a setting knob, or by the system in response to predefined events such as low-battery status) and independently of the displayed image. In this work we describe a smart computing technique called Low-Overhead Adaptive Brightness Scaling (LABS), that overcomes these limitations. In LABS, the optimal content-dependent brightness scaling factor is determined automatically for each displayed image, on a frame-by-frame basis, with a low computational cost that allows real-time usage. The basic form of LABS achieves more than 35 percent power reduction on average, when applied to different image datasets, while maintaining the Mean Structural Similarity Index (MSSIM) between the original and transformed images above 97 percent.},
  archive      = {J_TETC},
  author       = {Daniele Jahier Pagliari and Santa Di Cataldo and Edoardo Patti and Alberto Macii and Enrico Macii and Massimo Poncino},
  doi          = {10.1109/TETC.2019.2908257},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1625-1636},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Low-overhead adaptive brightness scaling for energy reduction in OLED displays},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Design and analysis of majority logic-based approximate
adders and multipliers. <em>TETC</em>, <em>9</em>(3), 1609–1624. (<a
href="https://doi.org/10.1109/TETC.2019.2929100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a new paradigm for nanoscale technologies, approximate computing deals with error tolerance in the computational process to improve performance and reduce power consumption. Majority logic (ML) is applicable to many emerging nanotechnologies; its basic building block (the 3-input majority voter, MV) has been extensively used for digital circuit design. In this paper, designs of approximate adders and multipliers based on ML are proposed; the proposed multipliers utilize approximate compressors and a reduction circuitry with so-called complement bits. An influence factor is defined and analyzed to assess the importance of different complement bits depending on the size of the multiplier; a scheme for selection of the complement bits is also presented. The proposed designs are evaluated using hardware metrics (such delay and gate complexity) as well as error metrics. Compared with other ML-based designs found in the technical literature, the proposed designs are found to offer superior performance. Case studies of error-resilient applications are also presented to show the validity of the proposed designs.},
  archive      = {J_TETC},
  author       = {Weiqiang Liu and Tingting Zhang and Emma McLarnon and Maire O’Neill and Paolo Montuschi and Fabrizio Lombardi},
  doi          = {10.1109/TETC.2019.2929100},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1609-1624},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Design and analysis of majority logic-based approximate adders and multipliers},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reconfigurable and dense analog circuit design using two
terminal resistive memory. <em>TETC</em>, <em>9</em>(3), 1596–1608. (<a
href="https://doi.org/10.1109/TETC.2019.2938440">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metal-oxide based bipolar Resistive RAM (RRAM) is one of the most promising candidates for the future non-volatile data storage. Due to unique properties e.g., small footprint, ability to modulate resistance states in wide ranges dynamically, hysteresis and CMOS compatibility, RRAM can be a fruitful candidate for analog circuit design. However, the recent literature only scratches the surface of this interesting prospect. In this paper, a single RRAM behavior is studied under temperature, voltage and process variations from an analog design standpoint. A comparative study is performed between two analog circuits namely, Common Source (CS) amplifier and differential amplifier with traditional passive resistors and with passive resistors replaced by RRAM along with two other design examples, namely constant &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$g_m$&lt;/tex-math&gt;&lt;/inline-formula&gt; biasing circuit and active low-pass filter, where RRAM can be integrated into analog circuits. Our study shows that blind swapping of passive resistors with RRAM in analog circuits can actually degrade the performance metrics. We propose techniques such as usage of RRAM Low Resistance State (LRS) to recover the loss. We also note that hyperbolic I-V characteristics of RRAM can inherently improve the linearity of RRAM based analog designs. Simulation results indicate that RRAM based amplifiers can achieve 2X area reduction, about 1.5X higher bandwidth with only &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\approx 9\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; reduction in gain. The resistance modulation property of RRAM is applied to realize a source degenerated amplifier with reconfigurable linearity, to a constant transconductance bias circuit to avoid resistance trimming and to design a programmable active low pass filter.},
  archive      = {J_TETC},
  author       = {Abdullah Ash-Saki and Mohammad Nasim Imtiaz Khan and Swaroop Ghosh},
  doi          = {10.1109/TETC.2019.2938440},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1596-1608},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Reconfigurable and dense analog circuit design using two terminal resistive memory},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Holo-BLSD – a holographic tool for self-training and
self-evaluation of emergency response skills. <em>TETC</em>,
<em>9</em>(3), 1581–1595. (<a
href="https://doi.org/10.1109/TETC.2019.2925777">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In case of cardiac arrest, prompt intervention of bystanders can be vital in saving lives. Basic Life Support and Defibrillation (BLSD) is a procedure designed to deliver a proficient emergency first response. Developing skills in BLSD in a large part of the population is a primary educational goal of resuscitation medicine. In this context, novel computer science technologies like Augmented Reality (AR) and Virtual Reality (VR) can alleviate some of the drawbacks of traditional instructor-led courses, especially concerning time and cost constraints. This paper presents Holo-BLSD, an AR system that allows users to learn and train the different operations involved in BLSD and receive an automatic assessment. The system uses a standard manikin which is “augmented” by an interactive virtual environment that reproduces realistic emergency scenarios. The proposed approach has been validated through a user study. Subjective results confirmed the usability of the devised tool and its capability to stimulate learners’ attention. Objective results indicated no statistical significance in the differences between the examiners’ evaluation of users who underwent traditional and AR training; they also showed a close agreement between expert and automatic assessments, suggesting that Holo-BLSD can be regarded as an effective self-learning method and a reliable self-evaluation tool.},
  archive      = {J_TETC},
  author       = {Francesco Strada and Andrea Bottino and Fabrizio Lamberti and Giulia Mormando and Pier Luigi Ingrassia},
  doi          = {10.1109/TETC.2019.2925777},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1581-1595},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Holo-BLSD – a holographic tool for self-training and self-evaluation of emergency response skills},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DNA molecular storage system: Transferring digitally encoded
information through bacterial nanonetworks. <em>TETC</em>,
<em>9</em>(3), 1566–1580. (<a
href="https://doi.org/10.1109/TETC.2019.2932685">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the birth of computer and networks, fueled by pervasive computing, Internet of Things and ubiquitous connectivity, the amount of data stored and transmitted has exponentially grown through the years. Due to this demand, new storage solutions are needed. One promising media is the DNA as it provides numerous advantages, which includes the ability to store dense information while achieving long-term reliability. However, the question as to how the data can be retrieved from a DNA-based archive, still remains. In this paper, we aim to address this question by proposing a new storage solution that relies on bacterial nanonetworks properties. Our solution allows digitally-encoded DNA to be stored into motility-restricted bacteria, which compose an archival architecture of clusters, and to be later retrieved by engineered motile bacteria, whenever reading operations are needed. We conducted extensive simulations, in order to determine the reliability of data retrieval from motility-restricted storage clusters, placed spatially at different locations. Aiming to assess the feasibility of our solution, we have also conducted wet lab experiments that show how bacteria nanonetworks can effectively retrieve a simple message, such as “ Hello World, ” by conjugation with motility-restricted bacteria, and finally mobilize towards a target point for delivery.},
  archive      = {J_TETC},
  author       = {Federico Tavella and Alberto Giaretta and Triona Marie Dooley-Cullinane and Mauro Conti and Lee Coffey and Sasitharan Balasubramaniam},
  doi          = {10.1109/TETC.2019.2932685},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1566-1580},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {DNA molecular storage system: Transferring digitally encoded information through bacterial nanonetworks},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An intelligent route computation approach based on real-time
deep learning strategy for software defined communication systems.
<em>TETC</em>, <em>9</em>(3), 1554–1565. (<a
href="https://doi.org/10.1109/TETC.2019.2899407">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software Defined Networking (SDN) is regarded as the next generation paradigm as it simplifies the structure of the data plane and improves the resource utilization. However, in current Software Defined Communication Systems (SDCSs), the maximum or minimum metric value based routing strategies come from traditional networks, which lack the ability of self-adaptation and do not efficiently utilize the computation resource in the controllers. To solve these problems, in this paper, we utilize the deep learning technique to conduct the routing computation for the SDCSs. Specifically, in our proposal, the considered Convolutional Neural Networks (CNNs) are adopted to intelligently compute the paths according to the input real-time traffic traces. To reduce the computation overhead of the central controller and improve the adaptation of CNNs to the changing traffic pattern, we consider an online training manner. Analysis shows that the computation complexity can be significantly reduced through the online training manner. Moreover, the simulation results demonstrate that our proposed CNNs are able to compute the appropriate paths combinations with high accuracy. Furthermore, the adopted periodical retraining enables the deep learning structures to adapt to the traffic changes.},
  archive      = {J_TETC},
  author       = {Bomin Mao and FengXiao Tang and Zubair Md. Fadlullah and Nei Kato},
  doi          = {10.1109/TETC.2019.2899407},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1554-1565},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {An intelligent route computation approach based on real-time deep learning strategy for software defined communication systems},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A comparative study of virtual reality methods of
interaction and locomotion based on presence, cybersickness, and
usability. <em>TETC</em>, <em>9</em>(3), 1542–1553. (<a
href="https://doi.org/10.1109/TETC.2019.2915287">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, virtual reality has experienced notorious technological advances in a quite short time. In an attempt to quickly response to this technical developments, some designs and developments of inmersive environments have caused different symptoms such as dizziness or disorientation. This work aims to analyze different methods of interaction and locomotion used in inmersive environments (Point of Interest, Gamepad, Teleport, and Room-Scale) in three different aspects: presence, cybersickness, and usability. We have designed and developed an experimental environment to carry out an empirical analysis with 48 subjects comparing the results obtained in different perceptual experiments. As a result, we provide a guideline for the use of these methods of interaction and locomotion in virtual reality.},
  archive      = {J_TETC},
  author       = {Jesus Mayor and Laura Raya and Alberto Sanchez},
  doi          = {10.1109/TETC.2019.2915287},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1542-1553},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {A comparative study of virtual reality methods of interaction and locomotion based on presence, cybersickness, and usability},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Smart resource allocation for mobile edge computing: A deep
reinforcement learning approach. <em>TETC</em>, <em>9</em>(3),
1529–1541. (<a href="https://doi.org/10.1109/TETC.2019.2902661">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of mobile devices with improving communication and perceptual capabilities has brought about a proliferation of numerous complex and computation-intensive mobile applications. Mobile devices with limited resources face more severe capacity constraints than ever before. As a new concept of network architecture and an extension of cloud computing, Mobile Edge Computing (MEC) seems to be a promising solution to meet this emerging challenge. However, MEC also has some limitations, such as the high cost of infrastructure deployment and maintenance, as well as the severe pressure that the complex and mutative edge computing environment brings to MEC servers. At this point, how to allocate computing resources and network resources rationally to satisfy the requirements of mobile devices under the changeable MEC conditions has become a great aporia. To combat this issue, we propose a smart, Deep Reinforcement Learning based Resource Allocation (DRLRA) scheme, which can allocate computing and network resources adaptively, reduce the average service time and balance the use of resources under varying MEC environment. Experimental results show that the proposed DRLRA performs better than the traditional OSPF algorithm in the mutative MEC conditions.},
  archive      = {J_TETC},
  author       = {Jiadai Wang and Lei Zhao and Jiajia Liu and Nei Kato},
  doi          = {10.1109/TETC.2019.2902661},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1529-1541},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Smart resource allocation for mobile edge computing: A deep reinforcement learning approach},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Proposal and performance evaluation of information diffusion
technique with novel virtual-cell-based wi-fi direct. <em>TETC</em>,
<em>9</em>(3), 1519–1528. (<a
href="https://doi.org/10.1109/TETC.2019.2891713">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wi-Fi Direct (WFD) has attracted much attention in recent years as a device-to-device communication technology that enables the sharing and diffusion of information in disaster areas that lack existing communication infrastructures. In WFD, mobile devices such as smartphones and tablets establish communication groups (a wireless local area network (WLAN)), and transmit and/or receive data by Wi-Fi among devices autonomously. However, WFD is not effective for spreading data throughout a wide range because it randomly selects communication partners and needs to wait uselessly for random lengths of time to maintain access control. Thus, we propose a novel and efficient information diffusion method exploiting WFD and delay-tolerant networking (DTN). This method involves a unique virtual cell design based on device locations and enables efficient information diffusion without interference by assigning communication times to the virtual cells. As there is no deterministic means of evaluating multihop communication exploiting WFD and a mathematical model is needed to quantitatively indicate the performance of our method, we further construct a performance evaluation model using the reaction–diffusion model, which is a partial differential equation used to mathematically describe the spread of epidemic diseases. The effectiveness of this proposed diffusion method is evaluated exploiting the constructed model.},
  archive      = {J_TETC},
  author       = {Tohn Furutani and Yuichi Kawamoto and Hiroki Nishiyama and Nei Kato},
  doi          = {10.1109/TETC.2019.2891713},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1519-1528},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Proposal and performance evaluation of information diffusion technique with novel virtual-cell-based wi-fi direct},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient word size modular arithmetic. <em>TETC</em>,
<em>9</em>(3), 1506–1518. (<a
href="https://doi.org/10.1109/TETC.2021.3073475">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modular multiplication is used in a wide range of applications. Most of the existing modular multiplication algorithms in the literature often focus on large size moduli. However, those large moduli oriented modular multiplication solutions are also used to implement modular arithmetic for applications requiring modular arithmetic on moduli of size inferior to a word size i.e., 32/64bits. As it happens, a large majority of applications are using word size modular arithmetic. In this work, we propose a new modular multiplication designed to be computed on one word size only. For word size moduli, in a large majority of instances, our solution outperforms other existing solutions including generalist solutions like Montgomery&#39;s and Barrett&#39;s modular multiplication as well as classes of moduli like Mersenne, Pseudo-Mersenne, Montgomery-Friendly and Generalized Mersenne.},
  archive      = {J_TETC},
  author       = {Thomas Plantard},
  doi          = {10.1109/TETC.2021.3073475},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1506-1518},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Efficient word size modular arithmetic},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). XpulpNN: Enabling energy efficient and flexible inference of
quantized neural networks on RISC-v based IoT end nodes. <em>TETC</em>,
<em>9</em>(3), 1489–1505. (<a
href="https://doi.org/10.1109/TETC.2021.3072337">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heavily quantized fixed-point arithmetic is becoming a common approach to deploy Convolutional Neural Networks (CNNs) on limited-memory low-power IoT end-nodes. However, this trend is narrowed by the lack of support for low-bitwidth in the arithmetic units of state-of-the-art embedded Microcontrollers (MCUs). This work proposes a multi-precision arithmetic unit fully integrated into a RISC-V processor at the micro-architectural and ISA level to boost the efficiency of heavily Quantized Neural Network (QNN) inference on microcontroller-class cores. By extending the ISA with nibble (4-bit) and crumb (2-bit) SIMD instructions, we show near-linear speedup with respect to higher precision integer computation on the key kernels for QNN computation. Also, we propose a custom execution paradigm for SIMD sum-of-dot-product operations, which consists of fusing a dot product with a load operation, with an up to 1.64 × peak MAC/cycle improvement compared to a standard execution scenario. To further push the efficiency, we integrate the RISC-V extended core in a parallel cluster of 8 processors, with near-linear improvement with respect to a single core architecture. To evaluate the proposed extensions, we fully implement the cluster of processors in GF22FDX technology. QNN convolution kernels on a parallel cluster implementing the proposed extension run 6 × and 8 × faster when considering 4- and 2-bit data operands, respectively, compared to a baseline processing cluster only supporting 8-bit SIMD instructions. With a peak of 2.22 TOPs/s/W, the proposed solution achieves efficiency levels comparable with dedicated DNN inference accelerators and up to three orders of magnitude better than state-of-the-art ARM Cortex-M based microcontroller systems such as the low-end STM32L4 MCU and the high-end STM32H7 MCU.},
  archive      = {J_TETC},
  author       = {Angelo Garofalo and Giuseppe Tagliavini and Francesco Conti and Luca Benini and Davide Rossi},
  doi          = {10.1109/TETC.2021.3072337},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1489-1505},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {XpulpNN: Enabling energy efficient and flexible inference of quantized neural networks on RISC-V based IoT end nodes},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sum propagate adders. <em>TETC</em>, <em>9</em>(3),
1479–1488. (<a href="https://doi.org/10.1109/TETC.2021.3068729">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Binary adders are present in every digital computer system. Even if their structure has evolved significantly over the last decades following the progress in logic and circuit design, the scaling of implementation technologies, and the improvement of logic synthesis tools, the fundamental carry-propagation algorithm that guides their operation remains unchanged. This work takes a different path and explores the possibility of performing addition by propagating directly the sum bits of previous bit positions instead of carries. The transformation of binary carry-propagate addition to an equivalent sum propagate addition opens up a whole new design space that spans from ripple-sum to sum-lookahead adders. New parallel-prefix structures that follow the sum-propagation paradigm are presented using a newly introduced associative prefix operator. Sum-propagate and carry-propagate adders have asymptotically the same area and delay complexity. In practice, however, carry propagate adders exhibit better characteristics when implemented in currently established implementation technologies. This gap is expected to reduce in the future using multiple-independent-gate transistors that are promising functionality-enhanced beyond CMOS device technologies, and allow the cost-efficient implementation of AND-XOR operations involved in sum-propagate adders.},
  archive      = {J_TETC},
  author       = {Giorgos Dimitrakopoulos and Kleanthis Papachatzopoulos and Vassilis Paliouras},
  doi          = {10.1109/TETC.2021.3068729},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1479-1488},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Sum propagate adders},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A study of the effects and benefits of custom-precision
mathematical libraries for HPC codes. <em>TETC</em>, <em>9</em>(3),
1467–1478. (<a href="https://doi.org/10.1109/TETC.2021.3070422">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mathematical libraries are typically developed for use with the fixed-width data-paths on processors and target common floating-point formats such as IEEE binary32 and binary64 . To address the increasing energy consumption and throughput requirements of HPC, scientific computing and AI applications, libraries and hardware implementations now provide new floating-point formats, allowing mathematical function evaluations with different performance and accuracy trade-offs. In this article we present a methodology and its associated proof-of-concept tool to evaluate the benefits of custom accuracy of mathematical library calls in HPC and scientific computations. First, our tool collects for each call-site of a mathematical function the input- and output-data profile. Then, using a heuristic exploration algorithm, we estimate the minimal required accuracy by rounding the result to lower precisions. The data profile and accuracy measurement per call-site is used to speculatively select the mathematical function implementation with the most appropriate accuracy for a given scenario. We have tested the methodology with the Intel MKL Vector Math ( VM ) library, leveraging the predefined accuracy levels. We demonstrate the benefits of our approach on two real-world applications: SGP4 , a satellite tracking application, and PATMOS , a Monte Carlo neutron transport code. The robustness of the methodology is estimated by measuring the numerical accuracy of the resulting optimized code, against user-defined criteria. We experiment and discuss generalization across data-sets and finally propose a speculative runtime implementation for PATMOS . The experiment provides an insight into the performance improvements achievable by leveraging the control of per-function call-site accuracy-mode execution of the Intel compiler SVML library. We show benefits from 13 to 55 percent in time reduction for the PATMOS use case.},
  archive      = {J_TETC},
  author       = {Emeric Brun and David Defour and Pablo de Oliveira Castro and Matei Iştoan and Davide Mancusi and Eric Petit and Alan Vaquet},
  doi          = {10.1109/TETC.2021.3070422},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1467-1478},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {A study of the effects and benefits of custom-precision mathematical libraries for HPC codes},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Algorithms for stochastically rounded elementary arithmetic
operations in IEEE 754 floating-point arithmetic. <em>TETC</em>,
<em>9</em>(3), 1451–1466. (<a
href="https://doi.org/10.1109/TETC.2021.3069165">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present algorithms for performing the five elementary arithmetic operations ( &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$+$&lt;/tex-math&gt;&lt;/inline-formula&gt; , &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$-$&lt;/tex-math&gt;&lt;/inline-formula&gt; , ×, &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\div$&lt;/tex-math&gt;&lt;/inline-formula&gt; , and &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\sqrt{\phantom{x}}$&lt;/tex-math&gt;&lt;/inline-formula&gt; ) in floating point arithmetic with stochastic rounding, and demonstrate the value of these algorithms by discussing various applications where stochastic rounding is beneficial. The algorithms require that the hardware be compliant with the IEEE 754 floating-point standard and that a floating-point pseudorandom number generator be available. The goal of these techniques is to emulate stochastic rounding when the underlying hardware does not support this rounding mode, as is the case for most existing CPUs and GPUs. By simulating stochastic rounding in software, one has the possibility to explore the behavior of this rounding mode and develop new algorithms even without having access to hardware implementing stochastic rounding—once such hardware becomes available, it suffices to replace the proposed algorithms by calls to the corresponding hardware routines. When stochastically rounding double precision operations, the algorithms we propose are between 7.3 and 19 times faster than the implementations that use the GNU MPFR library to simulate extended precision. We test our algorithms on various tasks, including summation algorithms and solvers for ordinary differential equations, where stochastic rounding is expected to bring advantages.},
  archive      = {J_TETC},
  author       = {Massimiliano Fasi and Mantas Mikaitis},
  doi          = {10.1109/TETC.2021.3069165},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1451-1466},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Algorithms for stochastically rounded elementary arithmetic operations in IEEE 754 floating-point arithmetic},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Special section on “emerging and impacting trends on
computer arithmetic.” <em>TETC</em>, <em>9</em>(3), 1449–1450. (<a
href="https://doi.org/10.1109/TETC.2021.3096698">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The papers in this special section focus on emerging and impacting trends on computer arithmetic. The computer arithmetic. field encompasses the definition and standardization of arithmetic systems for computers. It also deals with issues pertaining to hardware and software implementations, testing, and verification. Researchers and practitioners of this field also work on challenges associated with using Computer Arithmetic to perform scientific and engineering calculations. As such, Computer Arithmetic can be regarded as a truly multi-disciplinary field, which builds upon mathematics, computer science and electrical engineering. Thus, the range of topics addressed by Computer Arithmetic is generally very broad, spanning from highly theoretical to extremely practical contributions. Computer Arithmetic has been an active research field since the advent of computers, and it is progressively evolving following continuously advancements in technology.},
  archive      = {J_TETC},
  author       = {Mioara Joldes and Fabrizio Lamberti and Alberto Nannarelli},
  doi          = {10.1109/TETC.2021.3096698},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1449-1450},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Special section on “Emerging and impacting trends on computer arithmetic”},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). GasChecker: Scalable analysis for discovering
gas-inefficient smart contracts. <em>TETC</em>, <em>9</em>(3),
1433–1448. (<a href="https://doi.org/10.1109/TETC.2020.2979019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ethereum, the largest blockchain for running smart contracts, charges the people who send transactions to deploy or invoke smart contracts for thwarting resource abuse. The amount of transaction fee depends on the size of that contract and the operations executed by that contract. Consequently, smart contracts with inefficient code will waste money. In this article, we propose and develop the first tool, named GasChecker , for automatically identifying gas-inefficient code in smart contracts, and conduct the first empirical study on the prevalence of gas-inefficient code in the deployed smart contracts. More precisely, we first summarize ten gas-inefficient programming patterns and propose a new approach based on symbolic execution (SE) to detect them in the bytecode of smart contracts. To make our approach scalable to analyze millions of smart contracts, we parallelize SE by tailoring it to the MapReduce programming model, and propose a new feedback-based load balancing strategy to effectively utilize cloud resources. Extensive experiments show that GasChecker scales well with the increase of workers. The empirical study demonstrates that lots of real smart contracts contain various inefficient code. Manual investigation demonstrates that only 2.5 percent of discovered gas-inefficient instances are false positives.},
  archive      = {J_TETC},
  author       = {Ting Chen and Youzheng Feng and Zihao Li and Hao Zhou and Xiaopu Luo and Xiaoqi Li and Xiuzhuo Xiao and Jiachi Chen and Xiaosong Zhang},
  doi          = {10.1109/TETC.2020.2979019},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1433-1448},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {GasChecker: Scalable analysis for discovering gas-inefficient smart contracts},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A blockchain-enabled deduplicatable data auditing mechanism
for network storage services. <em>TETC</em>, <em>9</em>(3), 1421–1432.
(<a href="https://doi.org/10.1109/TETC.2020.3005610">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since network storage services achieve widespread adoption, security and performance issues are becoming primary concerns, affecting the scalability of storage systems. Countermeasures like data auditing mechanisms and deduplication techniques are widely studied. However, the existing data auditing mechanism with deduplication cannot solve the problems such as high cost and reliance on trusted third parties in traditional approaches, and it also faces the problem of repeated auditing of data shared by multiple-tenant. This article proposes a blockchain-based deduplicatable data auditing mechanism. We first design a client-side data deduplication scheme based on bilinear-pair techniques to reduce the burden on users and service providers. On this basis, we achieve a trustworthy and efficient data auditing mechanism that helps to check data integrity by using both the blockchain technique and bilinear pairing cryptosystem. The blockchain system is used to record the behaviors of entities in both data outsourcing and auditing processes so that the corresponding immutable records can be used to not only ensure the credibility of audit results but also help to monitor unreliable third-party auditors. Finally, theoretical analysis and experiments reveal the effectiveness and performance of our scheme.},
  archive      = {J_TETC},
  author       = {Yang Xu and Cheng Zhang and Guojun Wang and Zheng Qin and Quanrun Zeng},
  doi          = {10.1109/TETC.2020.3005610},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1421-1432},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {A blockchain-enabled deduplicatable data auditing mechanism for network storage services},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Circuit copyright blockchain: Blockchain-based homomorphic
encryption for IP circuit protection. <em>TETC</em>, <em>9</em>(3),
1410–1420. (<a href="https://doi.org/10.1109/TETC.2020.2993032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fast development of Blockchain technology makes it widely applied in several fields of digital transactions, like e-government affairs and the protection of financial transactions. In this article, we propose a homomorphic encryption-based Blockchain for circuit copyright protection that effectively addresses the issues in the protection of circuit copyright transactions, such as low security of private data, low efficiency in transaction data storage, cooperation and supervision. First, we establish a homomorphic encryption-based mathematical model by utilizing Blockchain and intelligent contract, and next, the algorithms that include Blockchain generation, homomorphic chain encryption/decryption, and intelligent contract are designed. As the intelligent contract is correctly executed in Blockchain, a fully homomorphic encryption-based identity authentication protocol is tackled for Blockchain, given that it ensures the change operation of any third-party in Blockchain and realizes real-time verification. The system is apposite for circuit copyright protection in a blockchain network, due to the use of distributed identity authentication and real-time extensible storage improves the security and extensibility of blockchain-based circuit copyright protection. The experimental results show that the proposed algorithm has reduced the transmission cost and improved the efficiency of data storage and supervision. In addition, it is resilient to several common attacks (e.g., double-spending attacks), yet incurs low cost/overhead and has a higher level of security when compared to three other competing algorithms.},
  archive      = {J_TETC},
  author       = {Wei Liang and Dafang Zhang and Xia Lei and Mingdong Tang and Kuan-Ching Li and Albert Y. Zomaya},
  doi          = {10.1109/TETC.2020.2993032},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1410-1420},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Circuit copyright blockchain: Blockchain-based homomorphic encryption for IP circuit protection},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Blockchain-based trust management for internet of vehicles.
<em>TETC</em>, <em>9</em>(3), 1397–1409. (<a
href="https://doi.org/10.1109/TETC.2020.3033532">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Vehicles (IoV) greatly improves the traffic environment and life efficiency using messages shared between vehicles. However, due to its complex network structure and high mobility, the messages shared between vehicles are not always reliable. To this, we propose a trust management system of IoV based on blockchain, which formalizes a complete vehicle reputation value calculation scheme to deal with the problem of calculating the credibility of messages. The proposed scheme can detect vehicles that send malicious messages and reduce their reputation values for punishing according to the rating mechanism. In addition, we design a blockchain-based data storage system that can prevent attackers from tampering with the reputation values stored in roadside units (RSUs). In view of the lack of calculation basis when roadside units verify the block, we also store the rating list it. Finally, we use the consensus mechanism that combines PoW and PoS to ensure that vehicles with a large change in reputation can be updated to the blockchain first. The simulation results show that the proposed scheme has an obvious limitation on malicious vehicles, and improves the accuracy of the vehicles’ judgment of events based on the received messages.},
  archive      = {J_TETC},
  author       = {Haibin Zhang and Jiajia Liu and Huanlei Zhao and Peng Wang and Nei Kato},
  doi          = {10.1109/TETC.2020.3033532},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1397-1409},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Blockchain-based trust management for internet of vehicles},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). B-TSCA: Blockchain assisted trustworthiness scalable
computation for V2I authentication in VANETs. <em>TETC</em>,
<em>9</em>(3), 1386–1396. (<a
href="https://doi.org/10.1109/TETC.2020.2978866">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of 5G networks has made smart driving possible. The vehicular ad-hoc networks (VANETs) are the main environment for smart driving, providing road information, instant communication between vehicle and vehicle (V2V) or vehicle and infrastructure (V2I). The information interaction security of VANETs is critical to the proper functioning of the traffic. Much research in recent years has focused on secure communication in VANETs, especially the secure V2V or V2I communications. However, current security schemes often require complex identity re-authentication when vehicles enter a new infrastructure coverage, which greatly reduces the efficiency of the entire network. In addition, the emergence of blockchain has created opportunities to overcome the challenges in VANETs mentioned above. In this article, blockchain is utilized to enhance the scalability of the trustworthiness scalable computation. The proposed blockchain assisted trustworthiness scalable computation based V2I authentication (B-TSCA) scheme achieves rapid re-authentication of vehicles through secure ownership transfer between infrastructures. Note that, trustworthiness scalable computation assisted by blockchian technology ensures the decentralization and non tamperability of the scalable computation result. The security analysis indicates that B-TSCA scheme is a CDH-secure scheme. The time cost of the novel handover authentication phase is half of that of the initial one as is presented in the simulation.},
  archive      = {J_TETC},
  author       = {Chen Wang and Jian Shen and Jin-Feng Lai and Jianwei Liu},
  doi          = {10.1109/TETC.2020.2978866},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1386-1396},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {B-TSCA: Blockchain assisted trustworthiness scalable computation for V2I authentication in VANETs},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Blockchain-based on-demand computing resource trading in
IoV-assisted smart city. <em>TETC</em>, <em>9</em>(3), 1373–1385. (<a
href="https://doi.org/10.1109/TETC.2020.2971831">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a smart city, Mobile Edge Computing (MEC) are generally deployed in static fashion in base stations (BSs). While moving vehicles with advanced on-board equipment can be regarded as dynamic computing resource transporters ignoring geographical limitations. Thus Internet of Vehicle (IoV) could assist the smart city to achieve flexible computing resource demand response (DR) via paid sharing the idle vehicle computing resources. Motivated by this, we propose a Peer-to-Peer (P2P) computing resource trading system to balance computing resource spatio-temporal dynamic demands in IoV-assisted smart city. On one hand, to guarantee transaction security and privacy-preserving in our system, we employ a consortium blockchain approach and demonstrate the process of secure computing resource trading without involving a centralized trusted third-party. On the other hand, to encourage individual smart vehicles to participate in our system, we construct a two-stage Stackelberg game jointly optimizing the utilities of buyers and sellers. And we also derive the optimal computing pricing and trading amount strategies in this proposed game. Finally, security analysis shows the security performance of our system and numerical simulations show that our strategies can encourage the collaboration between the buyer and smart vehicles.},
  archive      = {J_TETC},
  author       = {Xi Lin and Jun Wu and Shahid Mumtaz and Sahil Garg and Jianhua Li and Mohsen Guizani},
  doi          = {10.1109/TETC.2020.2971831},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1373-1385},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Blockchain-based on-demand computing resource trading in IoV-assisted smart city},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Special section on scalable computing for blockchain
systems. <em>TETC</em>, <em>9</em>(3), 1372. (<a
href="https://doi.org/10.1109/TETC.2021.3106180">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The papers in this special section focus scalable computing for blockchain systems.},
  archive      = {J_TETC},
  author       = {Hong-Ning Dai Senior and Zibin Zheng and Yan Zhang and Michael Rung Tsong Lyu and Alberto Nannarelli},
  doi          = {10.1109/TETC.2021.3106180},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1372},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Special section on scalable computing for blockchain systems},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bitcoin transaction forecasting with deep network
representation learning. <em>TETC</em>, <em>9</em>(3), 1359–1371. (<a
href="https://doi.org/10.1109/TETC.2020.3010464">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bitcoin and its decentralized computing paradigm for digital currency trading are one of the most disruptive technology in the 21st century. This article presents a novel approach to developing a Bitcoin transaction forecast model, DLForecast, by leveraging deep neural networks for learning Bitcoin transaction network representations. DLForecast makes three original contributions. First, we explore three interesting properties between Bitcoin transaction accounts: topological connectivity pattern of Bitcoin accounts, transaction amount pattern, and transaction dynamics. Second, we construct a time-decaying reachability graph and a time-decaying transaction pattern graph, aiming at capturing different types of spatial-temporal Bitcoin transaction patterns. Third, we employ node embedding on both graphs and develop a Bitcoin transaction forecasting system between user accounts based on historical transactions with built-in time-decaying factor. To maintain an effective transaction forecasting performance, we leverage the multiplicative model update (MMU) ensemble to combine prediction models built on different transaction features extracted from each corresponding Bitcoin transaction graph. Evaluated on real-world Bitcoin transaction data, we show that our spatial-temporal forecasting model is efficient with fast runtime and effective with forecasting accuracy over 60 percent and improves the prediction performance by 50 percent when compared to forecasting model built on the static graph baseline.},
  archive      = {J_TETC},
  author       = {Wenqi Wei and Qi Zhang and Ling Liu},
  doi          = {10.1109/TETC.2020.3010464},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1359-1371},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Bitcoin transaction forecasting with deep network representation learning},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SDLSC-TA: Subarea division learning based task allocation in
sparse mobile crowdsensing. <em>TETC</em>, <em>9</em>(3), 1344–1358. (<a
href="https://doi.org/10.1109/TETC.2020.3045463">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse mobile crowdsensing (Sparse MCS), a new paradigm for large-scale fine-grained urban monitoring applications, collects sensing data from relatively few areas and infers data for uncovered areas. In Sparse MCS, the task allocation problem is simplified to the area selection problem since it is typically assumed that there were enough participants across the target sensing area. However, in many real scenarios, there is no guarantee the platform can find participants to execute tasks in vital areas. In this case, additional moving costs are incurred, which is not beneficial for the MCS platform as organizers are cost-sensitive. To address this problem, we propose a novel Subarea Division Learning based Task Allocation framework in Sparse mobile Crowdsensing (SDLSC-TA) that integrates subarea division learning, task allocation, and sensing map reconstruction. Different from existing research, we design the subarea division learning module to provide guidance for a more reasonable task allocation scheme. Specifically, subarea division learning utilizes the Iterative Self-organizing Data Analysis Techniques Algorithm (ISODATA) to perform uneven subarea division considering historical data and spatio-temporal correlations. Based on subarea division learning results, task allocation iteratively selects the most suitable cell and participant combining sensing levels, sensing, and moving costs. Finally, sensing map reconstruction utilizes Bayesian compressive sensing (BCS) to infer missing data while ensuring high quality. Using four typical urban sensing datasets, SDLSC-TA outperforms state-of-the-art sparse MCS frameworks by 15 percent lower total costs on average and 40 percent lower average sensing map error rate.},
  archive      = {J_TETC},
  author       = {Xiaohui Wei and Zijian Li and Yuanyuan Liu and Shang Gao and Hengshan Yue},
  doi          = {10.1109/TETC.2020.3045463},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1344-1358},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {SDLSC-TA: Subarea division learning based task allocation in sparse mobile crowdsensing},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards the AlexNet moment for homomorphic encryption: HCNN,
the first homomorphic CNN on encrypted data with GPUs. <em>TETC</em>,
<em>9</em>(3), 1330–1343. (<a
href="https://doi.org/10.1109/TETC.2020.3014636">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Learning as a Service (DLaaS) stands as a promising solution for cloud-based inference applications. In this setting, the cloud has a pre-learned model whereas the user has samples on which she wants to run the model. The biggest concern with DLaaS is the user privacy if the input samples are sensitive data. We provide here an efficient privacy-preserving system by employing high-end technologies such as Fully Homomorphic Encryption (FHE), Convolutional Neural Networks (CNNs) and Graphics Processing Units (GPUs). FHE, with its widely-known feature of computing on encrypted data, empowers a wide range of privacy-concerned applications. This comes at high cost as it requires enormous computing power. In this article, we show how to accelerate the performance of running CNNs on encrypted data with GPUs. We evaluated two CNNs to classify homomorphically the MNIST and CIFAR-10 datasets. Our solution achieved sufficient security level ( &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$&amp;gt; 80$&lt;/tex-math&gt;&lt;/inline-formula&gt; bit) and reasonable classification accuracy (99) and (77.55 percent) for MNIST and CIFAR-10, respectively. In terms of latency, we could classify an image in 5.16 seconds and 304.43 seconds for MNIST and CIFAR-10, respectively. Our system can also classify a batch of images ( &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$&amp;gt;$&lt;/tex-math&gt;&lt;/inline-formula&gt; 8,000) without extra overhead.},
  archive      = {J_TETC},
  author       = {Ahmad Al Badawi and Chao Jin and Jie Lin and Chan Fook Mun and Sim Jun Jie and Benjamin Hong Meng Tan and Xiao Nan and Khin Mi Mi Aung and Vijay Ramaseshan Chandrasekhar},
  doi          = {10.1109/TETC.2020.3014636},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1330-1343},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Towards the AlexNet moment for homomorphic encryption: HCNN, the first homomorphic CNN on encrypted data with GPUs},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Guest editors’ introduction to the joint special section on
secure and emerging collaborative computing and intelligent systems.
<em>TETC</em>, <em>9</em>(3), 1328–1329. (<a
href="https://doi.org/10.1109/TETC.2021.3076338">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This joint special section of IEEE Transactions on Emerging Topics in Computing (TETC) and IEEE Transactions on Dependable and Secure Computing (TDSC) focuses on the security, privacy and trust of the emerging collaborative computing and intelligent systems. The Internet coupled with recent advances in computing and information technologies, such as IoT, mobile edge/cloud computing, cyber-physical-social systems, and artificial intelligence/machine learning/deep learning, have paved the way for creating next-generation smart and intelligent systems and applications that can have transformative impact in our society while accelerating rapid scientific discoveries and innovations.},
  archive      = {J_TETC},
  author       = {Yuan Hong and Valerie Issarny and Surya Nepal and Mudhakar Srivatsa},
  doi          = {10.1109/TETC.2021.3076338},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1328-1329},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Guest editors’ introduction to the joint special section on secure and emerging collaborative computing and intelligent systems},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sparse logistic maximum likelihood estimation for optimal
well-being determinants. <em>TETC</em>, <em>9</em>(3), 1316–1327. (<a
href="https://doi.org/10.1109/TETC.2020.3009295">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal well-being is a new multi-dimensional construct, which incorporates the well-known preexisting notions of subjective and psychological well-being. Classical models for describing the predictors of optimal well-being binary response variable are generalized linear models (GLM), such as logistic regression model. Since the number of predictors might be relatively large in these models, we devise a sparse optimization method for the regression problem based on subsequent iterations of a suitable sparse quadratic approximant problem, so that the resulting parameter vector estimate is sparse and indicates few significant predictors. We conduct empirical assessments using data of the European Social Survey (ESS), in order to identify the set of determinants which better predict optimal well-being by means of the proposed sparse regression method. ESS data analysis confirms that few selected predictors provide good data interpretation and no loss of information in the frequency of correct classification for people meeting the criteria of optimal well-being. Moreover, simulations with different structural parameter values indicate that sparse logistic model performs better in terms of the estimation of the true vector of parameters in a more parsimonious setting compared to classical logistic regression. The benefits increase as the structural sparsity of the optimization problem becomes stronger.},
  archive      = {J_TETC},
  author       = {Jianyi Lin and Emiliano Sironi},
  doi          = {10.1109/TETC.2020.3009295},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1316-1327},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Sparse logistic maximum likelihood estimation for optimal well-being determinants},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Virtual reality simulation of a quadrotor to monitor
dependent people at home. <em>TETC</em>, <em>9</em>(3), 1301–1315. (<a
href="https://doi.org/10.1109/TETC.2020.3000352">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicles (UAVs) represent an assistance solution for home care of dependent persons. These aircraft can cover the home, accompany the person, and position themselves to take photographs that can be analyzed to determine the person’s mood and the assistance needed. In this context, this work principally aims to design a tool to aid in the development and validation of the navigation algorithms of an autonomous vision-based UAV for monitoring dependent people. For that, a distributed architecture has been proposed based on the real-time communication of two modules, one of them in charge of the dynamics of the UAV, the trajectory planning and the control algorithms, and the other devoted to visualizing the simulation in an immersive virtual environment. Thus, a system has been developed that allows the evaluation of the behavior of the assistant UAV from a technological point of view, as well as to carry out studies from the assisted person’s viewpoint. An initial validation of a quadrotor model monitoring a virtual character demonstrates the advantages of the proposed system, which is an effective, safe and adaptable tool for the development of vision-based UAVs to help dependents at home.},
  archive      = {J_TETC},
  author       = {Lidia M. Belmonte and Arturo S. García and Eva Segura and Paulo Novais and Rafael Morales and Antonio Fernández-Caballero},
  doi          = {10.1109/TETC.2020.3000352},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1301-1315},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Virtual reality simulation of a quadrotor to monitor dependent people at home},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new application for the motor rehabilitation at home:
Structure and usability of bal-app. <em>TETC</em>, <em>9</em>(3),
1290–1300. (<a href="https://doi.org/10.1109/TETC.2020.3037962">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this paper is to present an innovative tablet-based application with 360° videos for the motor rehabilitation of frail elderly, Bal-App. This app was developed for iPad and exploits the potentiality of 360° videos to improve balance in frail patients through several exercises with an increasing level of difficulty. The app includes 10 sessions to be played 3 times a week for 3 weeks. The results of the usability study are very encouraging, and patients are very interested in trying this app at home like a guide for the motor rehabilitation. Only few non-substantial adjustments before the clinical trial are planned.},
  archive      = {J_TETC},
  author       = {Elisa Pedroli and Pietro Cipresso and Luca Greci and Sara Arlati and Atieh Mahroo and Valentina Mancuso and Lorenzo Boilini and Monica Rossi and Laura Stefanelli and Karine Goulene and Marco Sacco and Marco Stramba-Badiale and Giuseppe Riva and Andrea Gaggioli},
  doi          = {10.1109/TETC.2020.3037962},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1290-1300},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {A new application for the motor rehabilitation at home: Structure and usability of bal-app},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Online fall detection using recurrent neural networks on
smart wearable devices. <em>TETC</em>, <em>9</em>(3), 1276–1289. (<a
href="https://doi.org/10.1109/TETC.2020.3027454">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unintentional falls can cause severe injuries and even death, especially if no immediate assistance is given. A fall detection system aims to detect a fall as soon as it occurs, therefore issuing an automatic assistance request. Wearable embedded sensors are emerging as the most viable solution for continuous monitoring since they are more effective, less intrusive and less expensive than other systems. Tailoring a deep learning method to the requirements of microcontrollers entails matching very stringent constraints in terms of both memory and computational power. In addition, datasets acquired with wearable devices are relatively scarce and not necessarily devised for supervised learning. In this work, we discuss the design of a software architecture based on recurrent neural networks which can be effective for fall detection while running entirely onboard a wearable device. The well-known and publicly-available SisFall dataset was adopted and extended with fine-grained temporal annotations to cope with the supervised training of recurrent neural networks. We then show that an appropriate process of architectural minimization together with accurate hyperparameters selection leads to a workable model which compares favorably with other detection techniques. The embedding of the resulting architecture has been validated using a state-of-art hardware device.},
  archive      = {J_TETC},
  author       = {Mirto Musci and Daniele De Martini and Nicola Blago and Tullio Facchinetti and Marco Piastra},
  doi          = {10.1109/TETC.2020.3027454},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1276-1289},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Online fall detection using recurrent neural networks on smart wearable devices},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bag of models based embeddings for assessment of
neurological disorders using speech intelligibility. <em>TETC</em>,
<em>9</em>(3), 1265–1275. (<a
href="https://doi.org/10.1109/TETC.2020.3003085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligibility assessment of impaired speech is a tedious task because of the slow speaking rate, slurry speech, distorted vowels, and consonants. Hence, learning discriminative and compact embeddings to assess speech quality is essential. We propose a bag of models (BoM)-based framework that utilizes adapted Gaussian mixture models (AGMMs)-based embeddings. As opposed to AGMMs-based i-vector and supervector representations which use a universal background model (UBM) as a basic model and the model parameters of AGMMs for representations, we propose to use GMMs built for each intelligibility level as base-class GMMs to build a bag of models. The performance of the proposed approach is evaluated using two datasets namely 10-digits and 100-common words of UA-Speech database belonging to four intelligibility levels namely very low, low, mid, and high. The proposed BoM-based approach performs significantly better than the supervector, hybrid GMM/SVM, i-vector, and x-vector-based approaches for both datasets. In the case of prediction of intelligibility scores, the prediction error is reduced to 0.0726 and 0.1054 for 10-digits and 100-common words datasets, respectively. The discriminative power and the compactness of the proposed BoM-based embeddings lead to the best accuracy for both assessment of intelligibility levels and prediction of intelligibility scores.},
  archive      = {J_TETC},
  author       = {S. Chandrakala and S. Malini and S. L. Jayalakshmi},
  doi          = {10.1109/TETC.2020.3003085},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1265-1275},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Bag of models based embeddings for assessment of neurological disorders using speech intelligibility},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Live wire – a low-complexity body channel communication
system for landmark identification. <em>TETC</em>, <em>9</em>(3),
1248–1264. (<a href="https://doi.org/10.1109/TETC.2020.2996280">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a robust simplex Body Channel Communication (BCC) system aimed at providing an interactive infrastructure solution for visually impaired people. Compared to existing BCC solutions, it provides high versatility, wearability and installability in an environment in a low complexity hardware-software solution. It operates with a ground referred–transmitter (TX) and it is based on an asynchronous threshold receiver (RX) architecture. Synchronization, demodulation and packetizing and threshold control are completely software defined and implemented using MicroPython. The RX includes Bluetooth® (BT) radio connectivity and a cell-phone application provides push text-to-speech notifications to a smartphone. The hardware achieves a Packet Error Rate (PER) of &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\sim$&lt;/tex-math&gt;&lt;/inline-formula&gt; 0.1 at 550 kHz pulse center frequency, Synchronized-On Off Keying (S-OOK) modulation and 1 kbps data rate, for an average current consumption of 44 mA.},
  archive      = {J_TETC},
  author       = {Marco Crepaldi and Alessandro Barcellona and Giorgio Zini and Alberto Ansaldo and Paolo Motto Ros and Alessandro Sanginario and Claudia Cuccu and Danilo Demarchi and Luca Brayda},
  doi          = {10.1109/TETC.2020.2996280},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1248-1264},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Live wire – a low-complexity body channel communication system for landmark identification},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A machine-learning model for automatic detection of movement
compensations in stroke patients. <em>TETC</em>, <em>9</em>(3),
1234–1247. (<a href="https://doi.org/10.1109/TETC.2020.2988945">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the process of rehabilitation after stroke, it is important that patients know how well they perform their exercise, so they can improve their performance in future repetitions. Standard clinical rating conducted by human observation is the prevailing way today to monitor motor recovery of the patient. Therefore, patients cannot know whether they are performing a movement properly while exercising by themselves. Adhering to the exercise regime makes the rehabilitation process more effective and efficient, and thus a system that can give the patients feedback on their performance is of great value. Here, we built a machine-learning-based automated model that gives patients accurate information on the compensatory (undesirable) movements that they make. To construct the model, we recorded movements from 30 stroke patients, who each performed 18 movements, used to identify the presence of six types of compensatory movements in stroke patients’ movement trajectories. We used the random-forest algorithm for training this multi-label classification model. We achieved 85 percent average precision across the six movement compensations. This is the first study to automatically identify movement compensations based on stroke patients’ data. This model can be adapted for use in in-clinic and at-home exercise programs for patients after stroke.},
  archive      = {J_TETC},
  author       = {Shir Kashi and Ronit Feingold Polak and Boaz Lerner and Lior Rokach and Shelly Levy-Tzedek},
  doi          = {10.1109/TETC.2020.2988945},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1234-1247},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {A machine-learning model for automatic detection of movement compensations in stroke patients},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Guest editorial assistive computing technologies for human
well-being. <em>TETC</em>, <em>9</em>(3), 1231–1233. (<a
href="https://doi.org/10.1109/TETC.2021.3061315">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Well-being is a complex concept, that can be affected by long-term or temporary disabilities, as well as the natural process of aging. Nowadays, while meaningful computing methodologies have reached maturity, and a full awareness of the problem dimension has been reached, we are facing the objective of designing ad hoc technologies with the real potential of improving the quality of life of fragile individuals. Technology may contribute in different directions: by providing health-care providers with well-being assessment tools, by designing computer-assisted monitoring and rehabilitation methods that help maintaining independence, or by proposing assistive aids to compensate disabilities. The aim of this special issue is to promote a dialogue between healthcare and technology researchers in order to conceive effective solutions that tackle real needs of fragile people thus improving their well-being.},
  archive      = {J_TETC},
  author       = {Francesca Odone and Giuliano Grossi and Raffaella Lanzarotti and Henry Medeiros and Nicoletta Noceti},
  doi          = {10.1109/TETC.2021.3061315},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1231-1233},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Guest editorial assistive computing technologies for human well-being},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Privacy-preserving deep learning NLP models for cancer
registries. <em>TETC</em>, <em>9</em>(3), 1219–1230. (<a
href="https://doi.org/10.1109/TETC.2020.2983404">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Population cancer registries can benefit from Deep Learning (DL) to automatically extract cancer characteristics from the high volume of unstructured pathology text reports they process annually. The success of DL to tackle this and other real-world problems is proportional to the availability of large labeled datasets for model training. Although collaboration among cancer registries is essential to fully exploit the promise of DL, privacy and confidentiality concerns are main obstacles for data sharing across cancer registries. Moreover, DL for natural language processing (NLP) requires sharing a vocabulary dictionary for the embedding layer which may contain patient identifiers. Thus, even distributing the trained models across cancer registries causes a privacy violation issue. In this article, we propose DL NLP model distribution via privacy-preserving transfer learning approaches without sharing sensitive data. These approaches are used to distribute a multitask convolutional neural network (MT-CNN) NLP model among cancer registries. The model is trained to extract six key cancer characteristics – tumor site, subsite, laterality, behavior, histology, and grade – from cancer pathology reports. Using 410,064 pathology documents from two cancer registries, we compare our proposed approach to conventional transfer learning without privacy-preserving, single-registry models, and a model trained on centrally hosted data. The results show that transfer learning approaches including data sharing and model distribution outperform significantly the single-registry model. In addition, the best performing privacy-preserving model distribution approach achieves statistically indistinguishable average micro- and macro-F1 scores across all extraction tasks (0.823,0.580) as compared to the centralized model (0.827,0.585).},
  archive      = {J_TETC},
  author       = {Mohammed Alawad and Hong-Jun Yoon and Shang Gao and Brent Mumphrey and Xiao-Cheng Wu and Eric B. Durbin and Jong Cheol Jeong and Isaac Hands and David Rust and Linda Coyle and Lynne Penberthy and Georgia Tourassi},
  doi          = {10.1109/TETC.2020.2983404},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1219-1230},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Privacy-preserving deep learning NLP models for cancer registries},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). IoTility: Architectural requirements for enabling health IoT
ecosystems. <em>TETC</em>, <em>9</em>(3), 1206–1218. (<a
href="https://doi.org/10.1109/TETC.2019.2957241">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing ubiquity of the Internet of Things (IoT) has the potential to drastically alter the way healthcare systems are utilized at home or in a care environment. Smart things offer new ways to assist in general patient wellness, such as promoting an active and healthy lifestyle and simplifying treatment management. We believe smart health things bring new requirements not typically addressed in traditional IoT systems, and that an architecture targeting these devices must address such requirements to fully utilize their potential and safe usage. We believe such an architecture will help improve adoption and efficacy, closing gaps between the variety of emerging health IoT systems. In this paper, we present a number of requirements we consider integral to the continued expansion of the digital health IoT ecosystem (Health IoT). We consider the current landscape of IoT in relation to these requirements and present solutions that address two pressing requirements: 1) democratizing mobile health apps (giving users control and ownership over their app and data), and 2) making mobile apps act and behave like any other thing in an IoT. We present an implementation and evaluation of these Health IoT requirements to show how health-specific solutions can drive and influence the design of more generalized IoT architectures.},
  archive      = {J_TETC},
  author       = {Wyatt Lindquist and Sumi Helal and Ahmed Khaled and Wesley Hutchinson},
  doi          = {10.1109/TETC.2019.2957241},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1206-1218},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {IoTility: Architectural requirements for enabling health IoT ecosystems},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Collaborative trajectory mining in smart-homes to support
early diagnosis of cognitive decline. <em>TETC</em>, <em>9</em>(3),
1194–1205. (<a href="https://doi.org/10.1109/TETC.2020.2975071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our ageing world population claims for innovative tools to support healthcare and independent living. In this article, we address this challenge by introducing a novel system to recognize symptoms of cognitive decline by exploiting modern smart-home sensors. Since several studies indicate that cognitive issues are frequently associated to locomotion anomalies, our work relies on clinical models of wandering behavior. Previous works tried to recognize wandering of elderly people in outdoor environments, using GPS data and location trace analysis. However, the recognition of wandering indoors poses additional challenges. On the one hand, when moving in a restricted indoor environment, a system for wandering recognition may produce a large number of false positive, since a person&#39;s movements are frequently more intricate indoors than outdoors. On the other hand, several indoor movements resembling wandering may be actually due to the normal execution of daily living activities, or to the particular shape of the home. To address these challenges, we adopt a collaborative learning approach, using a training set of trajectories shared by individuals living in smart-homes. New wandering episodes are classified using a personalized model, built considering the homes’ shape and the individuals’ profiles. We apply a long-term analysis of classified wandering episodes to provide a hypothesis of diagnosis to be communicated to a medical center for further inspection. We implemented our algorithms and evaluated the system with a large dataset of real-world subjects, including people with dementia, MCI persons, and cognitively healthy people. The results indicate the potential utility of this system to support the early diagnosis of cognitive impairment.},
  archive      = {J_TETC},
  author       = {Elham Khodabandehloo and Daniele Riboni},
  doi          = {10.1109/TETC.2020.2975071},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1194-1205},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Collaborative trajectory mining in smart-homes to support early diagnosis of cognitive decline},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Recommending activities for mental health and well-being:
Insights from two user studies. <em>TETC</em>, <em>9</em>(3), 1183–1193.
(<a href="https://doi.org/10.1109/TETC.2020.2972007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Engaging in daily activities that engender positive affect (e.g., exercise and socializing) is critical for emotional well-being and is effective in reducing clinical depression. However, current digital mental health interventions have not exploited recommender approaches to encourage such healthy behaviors. This paper tests the feasibility of recommending personalized, healthy activities to users. Using two mobile applications, we collected high-quality data about specific healthy activities from two populations: a clinical sample diagnosed with a mood disorder (n = 318 activities/user) and a non-clinical sample (n = 59 activities/user). Activities were labeled with a type (e.g., social, leisure, work) and rated for their impact on mood. We used a probabilistic Naive Bayes (NB) Classifier and a Support Vector Machine (SVM) to model the activities as a bag-of-words to predict mood outcomes. We separate the analysis into a generalized model where we pooled all participants, comparing it with a personalized model. In both the clinical and non-clinical samples, there was a significant difference between the models. Both NB and SVM favored the personalized model after collecting 58.92 (SD = 20.96) activities. This research sheds light on recommendations for mental health, showing that personalization is key for recommending the right activity to each user.},
  archive      = {J_TETC},
  author       = {Darius A. Rohani and Aaron Springer and Victoria Hollis and Jakob E. Bardram and Steve Whittaker},
  doi          = {10.1109/TETC.2020.2972007},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1183-1193},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Recommending activities for mental health and well-being: Insights from two user studies},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A mental health chatbot for regulating emotions (SERMO) -
concept and usability test. <em>TETC</em>, <em>9</em>(3), 1170–1182. (<a
href="https://doi.org/10.1109/TETC.2020.2974478">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mental disorders are widespread in countries all over the world. Nevertheless, there is a global shortage in human resources delivering mental health services. Leaving people with mental disorders untreated may increase suicide attempts and mortality. To address this matter of limited resources, conversational agents have gained momentum in the last years. In this work, we introduce SERMO, a mobile application with integrated chatbot that implements methods from cognitive behaviour therapy (CBT) to support mentally ill people in regulating emotions and dealing with thoughts and feelings. SERMO asks the user on a daily basis on events that occurred and on emotions. It determines automatically the basic emotion of a user from the natural language input using natural language processing and a lexicon-based approach. Depending on the emotion, an appropriate measurement such as activities or mindfulness exercises are suggested by SERMO. Additional functionalities are an emotion diary, a list of pleasant activities, mindfulness exercises and information on emotions and CBT in general. User experience was studied with 21 participants using the User Experience Questionnaire (UEQ). Findings show that efficiency, perspicuity and attractiveness are considered as good. The scales describing hedonic quality (stimulation and novelty), i.e., fun of use, show neutral evaluations.},
  archive      = {J_TETC},
  author       = {Kerstin Denecke and Sayan Vaaheesan and Aaganya Arulnathan},
  doi          = {10.1109/TETC.2020.2974478},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1170-1182},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {A mental health chatbot for regulating emotions (SERMO) - concept and usability test},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). FarSight: Long-term disease prediction using unstructured
clinical nursing notes. <em>TETC</em>, <em>9</em>(3), 1151–1169. (<a
href="https://doi.org/10.1109/TETC.2020.2975251">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate risk stratification using patient data is a vital task in channeling prioritized care. Most state-of-the-art models are predominantly reliant on digitized data in the form of structured Electronic Health Records (EHRs). Those models overlook the valuable patient-specific information embedded in unstructured clinical notes, which is the prevalent medium employed by caregivers to record patients’ disease timeline. The availability of such patient-specific data presents an unprecedented opportunity to build intelligent systems that provide exclusive insights into patients’ disease physiology. Moreover, very few works have attempted to benchmark the performance of deep neural architectures against the state-of-the-art models on publicly available datasets. This article presents significant observations from our benchmarking experiments on the applicability of deep learning models for the clinical task of ICD-9 code group prediction. We present FarSight , a long-term aggregation mechanism intended to recognize the onset of the disease with the earliest detected symptoms. Vector space and topic modeling approaches are utilized to capture the semantic information in the patient representations. Experiments on MIMIC-III database underscored the superior performance of the proposed models built on unstructured data when compared to structured EHR based state-of-the-art model, achieving an improvement of 19.34 percent in AUPRC and 5.41 percent in AUROC.},
  archive      = {J_TETC},
  author       = {Tushaar Gangavarapu and Gokul S Krishnan and Sowmya Kamath S and Jayakumar Jeganathan},
  doi          = {10.1109/TETC.2020.2975251},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1151-1169},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {FarSight: Long-term disease prediction using unstructured clinical nursing notes},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DiabDeep: Pervasive diabetes diagnosis based on wearable
medical sensors and efficient neural networks. <em>TETC</em>,
<em>9</em>(3), 1139–1150. (<a
href="https://doi.org/10.1109/TETC.2019.2958946">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetes impacts the quality of life of millions of people around the globe. However, diabetes diagnosis is still an arduous process, given that this disease develops and gets treated outside the clinic. The emergence of wearable medical sensors (WMSs) and machine learning points to a potential way forward to address this challenge. WMSs enable a continuous, yet user-transparent, mechanism to collect and analyze physiological signals. However, disease diagnosis based on WMS data and its effective deployment on resource-constrained edge devices remain challenging due to inefficient feature extraction and vast computation cost. To address these problems, we propose a framework called DiabDeep that combines efficient neural networks (called DiabNNs) with off-the-shelf WMSs for pervasive diabetes diagnosis. DiabDeep bypasses the feature extraction stage and acts directly on WMS data. It enables both an (i) accurate inference on the server, e.g., a desktop, and (ii) efficient inference on an edge device, e.g., a smartphone, to obtain a balance between accuracy and efficiency based on varying resource budgets and design goals. On the resource-rich server, we stack sparsely connected layers to deliver high accuracy. On the resource-scarce edge device, we use a hidden-layer long short-term memory based recurrent layer to substantially cut down on computation and storage costs while incurring only a minor accuracy loss. At the core of our system lies a grow-and-prune training flow: it leverages gradient-based growth and magnitude-based pruning algorithms to enable DiabNNs to learn both weights and connections, while improving accuracy and efficiency. We demonstrate the effectiveness of DiabDeep through a detailed analysis of data collected from 52 participants. For server (edge) side inference, we achieve a 96.3 percent (95.3 percent) accuracy in classifying diabetics against healthy individuals, and a 95.7 percent (94.6 percent) accuracy in distinguishing among type-1 diabetic, type-2 diabetic, and healthy individuals. Against conventional baselines, such as support vector machines with linear and radial basis function kernels, k-nearest neighbor, random forest, and linear ridge classifiers, DiabNNs achieve higher accuracy, while reducing the model size (floating-point operations) by up to 454.5× (8.9×). Therefore, the system can be viewed as pervasive and efficient, yet very accurate.},
  archive      = {J_TETC},
  author       = {Hongxu Yin and Bilal Mukadam and Xiaoliang Dai and Niraj K. Jha},
  doi          = {10.1109/TETC.2019.2958946},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1139-1150},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {DiabDeep: Pervasive diabetes diagnosis based on wearable medical sensors and efficient neural networks},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Access control for implantable medical devices.
<em>TETC</em>, <em>9</em>(3), 1126–1138. (<a
href="https://doi.org/10.1109/TETC.2020.2982461">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The telemetry incorporate in the new generation of Implantable Medical Devices (IMDs) allows remote access and re-programming without interfering with the daily routine of their holders. Despite the benefits of this new feature, such remote access raises new threats related to the access of unauthorized entities to IMDs. Cardiac implants represent the most deployed types of IMD nowadays. Current solutions, to control their remote access, usually use a single feature for authentication. However, this feature is easily replicable, making these authentication schemes vulnerable to attacks. To overcome this limitation, we propose in this article a distance bounding protocol to manage access control of IMDs: ACIMD. ACIMD combines two security mechanisms, namely, identity verification (authentication) and proximity verification (distance checking). The authentication mechanism, formally and informally verified, conforms to the ISO/IEC 9798-2 standard. The distance checking is performed using the whole Electrocardiogram (ECG) signal and relies on the correlation coefficient (comparing an external versus an internal ECG signal) in the Hadamard domain. We evaluate the accuracy and security of ACIMD access control using ECG signals of 199 individuals recorded over 24 hours while considering three adversary strategies. Our results show that ACIMD is 92.92 percent accurate.},
  archive      = {J_TETC},
  author       = {Carmen Camara and Pedro Peris-Lopez and Jose Maria de Fuentes and Samuel Marchal},
  doi          = {10.1109/TETC.2020.2982461},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1126-1138},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Access control for implantable medical devices},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Differential privacy-based genetic matching in personalized
medicine. <em>TETC</em>, <em>9</em>(3), 1109–1125. (<a
href="https://doi.org/10.1109/TETC.2020.2970094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Genetic matching in personalized medicine is becoming more popular in cloud computing, whereby a cloud server performs genetic matching from the genetic data outsourced by a gene provider (e.g., a genetic lab) and an authorized party (e.g., a doctor) for diagnosing the patients’ diseases. Due to sensitive privacy, we should protect genetic data before outsourcing it to the untrusted cloud. However, traditional differential privacy schemes do not support genetic matching and ciphertext methods hinder data availability. In this article, we propose a differential privacy-based genetic matching (DPGM) scheme to achieve effective genetic matching and protect genetic privacy. Specifically, DPGM first uses a DP-based EIGENSTRAT (DPE) algorithm to construct a published sequence that contains significantly noisy single-nucleotide polymorphisms (SNPs) associated with diseases, thereby ensuring outsourced genetic data privacy. Second, DPGM adopts a DP-based N-order Markov (DPNM) algorithm to generate a noisy query sequence, which considers query privacy and the similarity between the noisy query and the actual query. Finally, DPGM calculates the longest common subsequence (LCS) based on a dynamic programming algorithm, which achieves effective matching results. Detailed theoretical analysis proves that our DPGM scheme achieves &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\epsilon$&lt;/tex-math&gt;&lt;/inline-formula&gt; -differential privacy. Extensive experiments over actual genetic datasets demonstrate that our scheme achieves high efficiency and data utility.},
  archive      = {J_TETC},
  author       = {Jianhao Wei and Yaping Lin and Xin Yao and Jin Zhang and Xinbo Liu},
  doi          = {10.1109/TETC.2020.2970094},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1109-1125},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Differential privacy-based genetic matching in personalized medicine},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Guest editorial: Special section on new frontiers in
computing for next-generation healthcare systems. <em>TETC</em>,
<em>9</em>(3), 1106–1108. (<a
href="https://doi.org/10.1109/TETC.2021.3097673">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The papers in this special section focus on new applications for computing for next generation healthcare systems and medical services. Advances in information and communication technology (ICT) are driving a profound transformation in the healthcare sector. The traditional healthcare has evolved to smart healthcare. The prominent role played by technology in the fight against the novel Coronavirus disease 2019 (COVID-19) pandemic, from artificial intelligence to telehealth services, from contact tracing to 3D printing, is a driving force towards increased digitalization of healthcare services. This Special Section aims at providing a comprehensive picture of the technological advancements in computing that are underpinning the current revolution in healthcare. It is dedicated to emerging technological trends and their potential implications for improving healthcare interventions and tackling the challenges of an increasingly aging population.},
  archive      = {J_TETC},
  author       = {Lia Morra and Valentina Gatteschi and Saraju P. Mohanty and Yuan-Hao Chang},
  doi          = {10.1109/TETC.2021.3097673},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {7},
  number       = {3},
  pages        = {1106-1108},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Guest editorial: Special section on new frontiers in computing for next-generation healthcare systems},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new PUF based lock and key solution for secure in-field
testing of cryptographic chips. <em>TETC</em>, <em>9</em>(2), 1095–1105.
(<a href="https://doi.org/10.1109/TETC.2019.2903387">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scan-based side-channel attacks have become a new threat to cryptographic chips. Existing countermeasures require a secret test key to unlock the scan chain before in-field testing is allowed. However, test key disclosure poses tremendous risks to multiple crypto chips that share a common test key. We address this open problem of in-field testing by leveraging physical unclonable function (PUF) to make the derived test key unique to each chip. The PUF&#39;s response is invoked only once and hardened into a one-time programmable pad. The PUF response required by the designer to derive a test key of each crypto chip can only be recovered at the time of locking the scan chains without directly reading it out. The manufacturer can test the chip normally with no test time penalty before the passed chips are locked. The proposed solution is analyzed to be secure against all known scan-based side-channel attacks and the overhead incurred for the added security is negligibly small.},
  archive      = {J_TETC},
  author       = {AIJIAO CUI and CHIP-HONG CHANG and WEI ZHOU and YUE ZHENG},
  doi          = {10.1109/TETC.2019.2903387},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {1095-1105},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {A new PUF based lock and key solution for secure in-field testing of cryptographic chips},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient single image enhancement approach using
luminance perception transformation. <em>TETC</em>, <em>9</em>(2),
1083–1094. (<a href="https://doi.org/10.1109/TETC.2019.2943231">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sufficient illumination enables the observer to identify the true colors of an object captured by an imaging sensor, whereas dim illumination restricts proper observation. This paper proposes a single image enhancement algorithm based on human visual system. First, the image is transformed by the proposed Luminance Perception procedure from the spatial domain into the proposed Brightness Domain, where the image can be assessed as to whether or not it has sufficient illumination. Further, if the image is determined to have insufficient illumination, the assessed range of insufficient illumination and sharpness is used to restore the image&#39;s true illumination and textures to best fulfill the requirements for human visual perception. Our experiments show that the enhanced images generated by the proposed algorithm exhibit more brightness and appreciably better contrast than those generated by other state-of-the-art image enhancement algorithms that use images captured under various illuminant levels in various kinds of natural scenes.},
  archive      = {J_TETC},
  author       = {Shih-Chia Huang and Da-Wei Jaw and Bo-Hao Chen and Sy-Yen Kuo},
  doi          = {10.1109/TETC.2019.2943231},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {1083-1094},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {An efficient single image enhancement approach using luminance perception transformation},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Leveraging communicating UAVs for emergency vehicle guidance
in urban areas. <em>TETC</em>, <em>9</em>(2), 1070–1082. (<a
href="https://doi.org/10.1109/TETC.2019.2930124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The response time to emergency situations in urban areas is considered as a crucial key in limiting material damage or even saving human lives. Thanks to their “bird&#39;s eye view” and their flexible mobility, Unmanned Aerial Vehicles (UAVs) can be a promising candidate for several vital applications. Under these perspectives, we investigate the use of communicating UAVs to detect any incident on the road, provide rescue teams with their exact locations, and plot the fastest path to intervene, while considering the constraints of the roads. To efficiently inform the rescue services, a robust routing scheme is introduced to ensure a high level of communication stability based on an efficient backbone, while considering both the high mobility and the restricted energy capacity of UAVs. This allows both predicting any routing path breakage prior to its occurrence, and carrying out a balanced energy consumption among UAVs. To ensure a rapid intervention by rescue teams, UAVs communicate in an ad hoc fashion with existing vehicles on the ground to estimate the fluidity of the roads. Our system is implemented and evaluated through a series of experiments. The reported results show that each part of the system reliably succeeds in achieving its planned objective.},
  archive      = {J_TETC},
  author       = {Omar Sami Oubbati and Abderrahmane Lakas and Pascal Lorenz and Mohammed Atiquzzaman and Abbas Jamalipour},
  doi          = {10.1109/TETC.2019.2930124},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {1070-1082},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Leveraging communicating UAVs for emergency vehicle guidance in urban areas},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Windows malware detector using convolutional neural network
based on visualization images. <em>TETC</em>, <em>9</em>(2), 1057–1069.
(<a href="https://doi.org/10.1109/TETC.2019.2910086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evolution of malware is continuing at an alarming rate, despite the efforts made towards detecting and mitigating them. Malware analysis is needed to defend against its sophisticated behaviour. However, the manual heuristic inspection is no longer effective or efficient. To cope with these critical issues, behaviour-based malware detection approaches with machine learning techniques have been widely adopted as a solution. It involves supervised classifiers to appraise their predictive performance on gaining the most relevant features from the original features&#39; set and the trade-off between high detection rate and low computation overhead. Though machine learning-based malware detection techniques have exhibited success in detecting malware, their shallow learning architecture is still deficient in identifying sophisticated malware. Therefore, in this paper, a Convolutional Neural Network (CNN) based Windows malware detector has been proposed that uses the execution time behavioural features of the Portable Executable (PE) files to detect and classify obscure malware. The 10-fold cross-validation tests were conducted to assess the proficiency of the proposed approach. The experimental results showed that the proposed approach was effective in uncovering malware PE files by utilizing significant behavioural features suggested by the Relief Feature Selection Technique. It attained detection accuracy of 97.968 percent.},
  archive      = {J_TETC},
  author       = {Shiva Darshan S.L and Jaidhar C.D},
  doi          = {10.1109/TETC.2019.2910086},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {1057-1069},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Windows malware detector using convolutional neural network based on visualization images},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Quantum circuit designs of integer division optimizing
t-count and t-depth. <em>TETC</em>, <em>9</em>(2), 1045–1056. (<a
href="https://doi.org/10.1109/TETC.2019.2910870">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum circuits for mathematical functions such as division are necessary to use quantum computers for scientific computing. Quantum circuits based on Clifford+T gates can easily be made fault-tolerant but the T gate is very costly to implement. The small number of qubits available in existing quantum computers adds another constraint on quantum circuits. As a result, reducing T-count and qubit cost have become important optimization goals. The design of quantum circuits for integer division has caught the attention of researchers and designs have been proposed in the literature. However, these designs suffer from excessive T gate and qubit costs. Many of these designs also produce significant garbage output resulting in additional qubit and T gate costs to eliminate these outputs. In this work, we propose two quantum integer division circuits. The first proposed quantum integer division circuit is based on the restoring division algorithm and the second proposed design implements the non-restoring division algorithm. Both proposed designs are optimized in terms of T-count, T-depth and qubits. Both proposed quantum circuit designs are based on (i) a quantum subtractor, (ii) a quantum adder-subtractor circuit, and (iii) a novel quantum conditional addition circuit. Our proposed restoring division circuit achieves average T-count savings from 79.03 to 91.69 percent compared to the existing works. Our proposed non-restoring division circuit achieves average T-count savings from 49.22 to 90.03 percent compared to the existing works. Further, both our proposed designs have linear T-depth. We also illustrate the application of the proposed quantum division circuits in quantum image processing with a case study of quantum bilinear interpolation.},
  archive      = {J_TETC},
  author       = {Himanshu Thapliyal and Edgard MuÑoz-Coreas and T. S. S. Varun and Travis S. Humble},
  doi          = {10.1109/TETC.2019.2910870},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {1045-1056},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Quantum circuit designs of integer division optimizing T-count and T-depth},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel quantum-inspired fuzzy based neural network for data
classification. <em>TETC</em>, <em>9</em>(2), 1031–1044. (<a
href="https://doi.org/10.1109/TETC.2019.2901272">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of the neural network (NN) depends on the various parameters such as structure, initial weight, number of hidden layer neurons, and learning rate. The improvement in classification performance of NN without changing its structure is a challenging issue. This paper proposes a novel learning model called Quantum-inspired Fuzzy Based Neural Network (Q-FNN) to solve two-class classification problems. In the proposed model, NN architecture is formed constructively by adding neurons in the hidden layer and learning is performed using the concept of Fuzzy c-Means (FCM) clustering, where the fuzziness parameter ( m ) is evolved using the quantum computing concept. The quantum computing concept provides a large search space for a selection of m , which helps in finding the optimal weights and also optimizes the network architecture. This paper also proposes a modified step activation function for the formation of hidden layer neurons, which handles the overlapping samples belong to different class regions. The performance of the proposed Q-FNN model is superior and competitive with the state-of-the-art methods in terms of accuracy, sensitivity, and specificity on 15 real-world benchmark datasets.},
  archive      = {J_TETC},
  author       = {Om Prakash Patel and Neha Bharill and Aruna Tiwari and Mukesh Prasad},
  doi          = {10.1109/TETC.2019.2901272},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {1031-1044},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {A novel quantum-inspired fuzzy based neural network for data classification},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SwMR: A framework for accelerating MapReduce applications on
sunway taihulight. <em>TETC</em>, <em>9</em>(2), 1020–1030. (<a
href="https://doi.org/10.1109/TETC.2018.2881265">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {MapReduce has already been an indispensable framework for the programmers to develop big data applications at scale without concerning the underlying complex system details. However, such an important framework is missing on the Sunway many-core processor that powers the world-leading supercomputer Sunway Taihulight. This paper fills the gap by implementing an efficient MapReduce framework on Sunway many-core processor which takes full advantage of the architecture features such as local device memory and register communication. Specifically, we propose three different schemes that adopt different methods to partition the computation of map and reduce across the MPE and CPEs of Sunway processor. Especially in CPE-accelerated Dynamic Partitioning Scheme (CDPS), the processing role of the CPEs within each CPE pair can be transformed dynamically between map and reduce, which is effective to improve the load balance during runtime. In addition, we adopt the local device memory as well as register communication on each CPE to improve the efficiency of data access and communication. The experiment results demonstrate our MapReduce framework based on CDPS achieves 36.9× performance speedup on average across representative benchmarks.},
  archive      = {J_TETC},
  author       = {Xiaogang Zhong and Mingzhen Li and Hailong Yang and Yi Liu and Depei Qian},
  doi          = {10.1109/TETC.2018.2881265},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {1020-1030},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {SwMR: A framework for accelerating MapReduce applications on sunway taihulight},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient monte carlo-based probabilistic time-dependent
routing calculation targeting a server-side car navigation system.
<em>TETC</em>, <em>9</em>(2), 1006–1019. (<a
href="https://doi.org/10.1109/TETC.2019.2919801">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incorporating speed probability distribution to the computation of the route planning in car navigation systems guarantees more accurate and precise responses. In this paper, we propose a novel approach for selecting dynamically the number of samples used for the Monte Carlo simulation to solve the Probabilistic Time-Dependent Routing (PTDR) problem, thus improving the computation efficiency. The proposed method is used to determine in a proactive manner the number of simulations to be done to extract the travel-time estimation for each specific request, while respecting an error threshold as output quality level. The methodology requires a reduced effort on the application development side. We adopted an aspect-oriented programming language (LARA) together with a flexible dynamic autotuning library (mARGOt) respectively to instrument the code and to make decisions on tuning the number of samples to improve the execution efficiency. Experimental results demonstrate that the proposed adaptive approach saves a large fraction of simulations (between 36 and 81 percent) with respect to a static approach, while considering different traffic situations, paths and error requirements. Given the negligible runtime overhead of the proposed approach, the execution-time speedup is between 1.5x and 5.1x. This speedup is reflected at the infrastructure-level in terms of a reduction of 36 percent of the computing resources needed to support the whole navigation pipeline.},
  archive      = {J_TETC},
  author       = {Emanuele Vitali and Davide Gadioli and Gianluca Palermo and Martin Golasowski and JoÃo Bispo and Pedro Pinto and Jan MartinoviČ and KateŘina SlaninovÁ and JoÃo M. P. Cardoso and Cristina Silvano},
  doi          = {10.1109/TETC.2019.2919801},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {1006-1019},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {An efficient monte carlo-based probabilistic time-dependent routing calculation targeting a server-side car navigation system},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). STPR: A personalized next point-of-interest recommendation
model with spatio-temporal effects based on purpose ranking.
<em>TETC</em>, <em>9</em>(2), 994–1005. (<a
href="https://doi.org/10.1109/TETC.2019.2912839">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of personalized next point-of-interest (POI) recommendation is significant and of practical value in location-based social networks (LBSNs). Due to the sparsity of data in regard to check-ins, POI recommendations remain a challenging problem. Previous work developed recommendation models by taking into consideration the properties of user&#39;s mobility, for example, spatio-temporal information and the similarity of movement rules. However, they ignore the influence of trip-purpose on user&#39;s mobility, and the memory effect of historical check-in behavior at the same location. To cope with this problem, a POI recommendation model with Spatio-Temporal effects based on Purpose Ranking (STPR) is proposed. STPR contains two important phases: (1) Purpose prediction: classifying the POIs in the spatio-temporal database into four categories. Each category corresponds to a purpose. Then, a purpose ranking model is constructed to model the selection of user&#39;s intended purpose for the trip. (2) The scoring of each candidate POI: the properties of spatial and temporal information are taken into consideration when calculating the score. For the spatial property, the kernel density estimation is used to estimate the visiting probability of a certain POI. For the temporal property, we focus on the time interval and the POI exploration mechanism. We find that POI exploration mechanism can reflect a user&#39;s mobility of visiting new POIs. Furthermore, a method based on Bayesian personalized ranking, called BPR, is proposed to estimate the time interval for unvisited POIs. Extensive experiments were conducted on two real datasets, and the experimental results demonstrate that the recommendation accuracy of the STPR model outperforms the state-of-the-art POI recommendation models with good runtime performance.},
  archive      = {J_TETC},
  author       = {Feihu Huang and Shaojie Qiao and Jian Peng and Bing Guo and Nan Han},
  doi          = {10.1109/TETC.2019.2912839},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {994-1005},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {STPR: A personalized next point-of-interest recommendation model with spatio-temporal effects based on purpose ranking},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Extended file hierarchy access control scheme with
attribute-based encryption in cloud computing. <em>TETC</em>,
<em>9</em>(2), 983–993. (<a
href="https://doi.org/10.1109/TETC.2019.2904637">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In cloud computing, attribute based encryption (ABE) is often used to solve the challenging issue in secure data storage. In order to lighten the burden of authority center, hierarchical ABE schemes is a very effective way. File hierarchy attribute based encryption (FH-CP-ABE) is a scheme, which both saves storage space of ciphertext and reduces the computation overhead of encryption. However, it&#39;s impossible to encrypt multiple files on the same access level in existing FH-CP-ABE scheme. The scheme is obviously not practical. In this paper, an efficient extended file hierarchy CP-ABE scheme (EFH-CP-ABE) is proposed, which can encrypt multiple files on the same access level. Our scheme is very practical especially for those big institutions or companies which have many hierarchical sectors, since it greatly saves storage space and computation cost for them on the cloud servers. Furthermore, our solution also achieves secure and flexible access control for users in cloud storage. We formally prove the security for our new scheme under the standard model. Finally, we implement the corresponding experiment for EFH-CP-ABE scheme and achieve desirable experimental results.},
  archive      = {J_TETC},
  author       = {JIGUO LI and NINGYU CHEN and YICHEN ZHANG},
  doi          = {10.1109/TETC.2019.2904637},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {983-993},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Extended file hierarchy access control scheme with attribute-based encryption in cloud computing},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An experience replay method based on tree structure for
reinforcement learning. <em>TETC</em>, <em>9</em>(2), 972–982. (<a
href="https://doi.org/10.1109/TETC.2018.2890682">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Q-Learning, which is a well-known model-free reinforcement learning algorithm, a learning agent explores an environment to update a state-action function. In reinforcement learning, the agent does not require information about the environment in advance, so an interaction between the agent and the environment is for collecting the real experiences that is also an expensive and time-consuming process. Therefore, to reduce the burden of the interaction, sample efficiency becomes an important role in reinforcement learning. This study proposes an adaptive tree structure integrating with experience replay for Q-Learning, called ERTS-Q. In ERTS-Q method, Q-Learning is used for policy learning, a tree structure establishes a virtual model which perceives two different continuous states after each state transaction, and then the variations of the continuous state are calculated. After each state transition, all states with highly similar variation are aggregated into the same leaf nodes. Otherwise, new leaf nodes will be produced. For experience replay, the tree structure predicts the next state and reward based on the statistical information that is stored in tree nodes. The virtual experiences produced by the tree structure are used for achieving extra learning. Simulations of the mountain car and a maze environment are performed to verify the validity of the proposed modeling learning approach.},
  archive      = {J_TETC},
  author       = {WEI-CHENG JIANG and KAO-SHING HWANG and JIN-LING LIN},
  doi          = {10.1109/TETC.2018.2890682},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {972-982},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {An experience replay method based on tree structure for reinforcement learning},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PESKEA: Anomaly detection framework for profiling kernel
event attributes in embedded systems. <em>TETC</em>, <em>9</em>(2),
957–971. (<a href="https://doi.org/10.1109/TETC.2020.2971251">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the software development life cycle, we use the execution traces of a given application to examine the behavior of the software when an error occurs or to monitor the software performance and compliance. However, this type of application trace analysis focuses on checking the performance of the software against its design goals. Conversely, the operating system (OS) sits between the application and the hardware, and traces logged from this layer capture the behavior of the embedded system and not just the application. Hence, an analysis of the kernel events captures the system-wide performance of the embedded system. Consequently, we present a feature-based anomaly detection framework called PESKEA, which exploits the statistical variance of the features in the execution traces of an embedded OS to perform trace classification, and subsequently, anomaly detection. We test PESKEA with two public datasets we refer to as Dataset I and Dataset II. On Dataset I, PESKEA results show a 3 to 6 percent improvement in the true positive rate (TPR) of Dataset I compared to the previous work tested on this dataset, and scores between 88.37 to 100 percent in Dataset II. We hope to test PESKEA on non-UAV embedded control application datasets in future work.},
  archive      = {J_TETC},
  author       = {Okwudili M. Ezeme and Akramul Azim and Qusay H. Mahmoud},
  doi          = {10.1109/TETC.2020.2971251},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {957-971},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {PESKEA: Anomaly detection framework for profiling kernel event attributes in embedded systems},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Implementation and performance evaluation of RNS variants of
the BFV homomorphic encryption scheme. <em>TETC</em>, <em>9</em>(2),
941–956. (<a href="https://doi.org/10.1109/TETC.2019.2902799">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Homomorphic encryption is an emerging form of encryption that provides the ability to compute on encrypted data without ever decrypting them. Potential applications include aggregating sensitive encrypted data on a cloud environment and computing on the data in the cloud without compromising data privacy. There have been several recent advances resulting in new homomorphic encryption schemes and optimized variants. We implement and evaluate the performance of two optimized variants, namely Bajard-Eynard-Hasan-Zucca (BEHZ) and Halevi-Polyakov-Shoup (HPS), of the most promising homomorphic encryption scheme in CPU and GPU. The most interesting (and also unexpected) result of our performance evaluation is that the HPS variant in practice scales significantly better (typically by 15-30 percent) with increase in multiplicative depth of the computation circuit than BEHZ, implying that the HPS variant will always outperform BEHZ for most practical applications. For the multiplicative depth of 98, our fastest GPU implementation performs homomorphic multiplication in 51 ms for 128-bit security settings, which is faster by two orders of magnitude than prior results and already practical for cloud environments supporting GPU computations. Large multiplicative depths supported by our implementations are required for applications involving deep neural networks, logistic regression learning, and other important machine learning problems.},
  archive      = {J_TETC},
  author       = {Ahmad Al Badawi and Yuriy Polyakov and Khin Mi Mi Aung and Bharadwaj Veeravalli and Kurt Rohloff},
  doi          = {10.1109/TETC.2019.2902799},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {941-956},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Implementation and performance evaluation of RNS variants of the BFV homomorphic encryption scheme},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Low-energy acceleration of binarized convolutional neural
networks using a spin hall effect based logic-in-memory architecture.
<em>TETC</em>, <em>9</em>(2), 928–940. (<a
href="https://doi.org/10.1109/TETC.2019.2915589">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Learning (DL) offers the advantages of high accuracy performance at tasks such as image recognition, learning of complex intelligent behaviors, and large-scale information retrieval problems such as intelligent web search. To attain the benefits of DL, the high computational and energy-consumption demands imposed by the underlying processing, interconnect, and memory devices on which software-based DL executes can benefit substantially from innovative hardware implementations. Logic-in-Memory (LIM) architectures offer potential approaches to attaining such throughput goals within area and energy constraints starting with the lowest layers of the hardware stack. In this paper, we develop a Spintronic Logic-in-Memory (S-LIM) XNOR neural network (S-LIM XNN) which can perform binary convolution with reconfigurable in-memory logic without supplementing distinct logic circuits for computation within the memory module itself. Results indicate that the proposed S-LIM XNN designs achieve 1.2-fold energy reduction, 1.26-fold throughput increase, and 1.4-fold accuracy improvement compared to the state-of-the-art binarized convolutional neural network hardware. Design considerations, architectural approaches, and the impact of process variation on the proposed hybrid spin-CMOS design are identified and assessed, including comparisons and recommendations for future directions with respect to LIM approaches for neuromorphic computing.},
  archive      = {J_TETC},
  author       = {Ashkan Samiee and Payal Borulkar and Ronald F. DeMara and Peiyi Zhao and Yu Bai},
  doi          = {10.1109/TETC.2019.2915589},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {928-940},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Low-energy acceleration of binarized convolutional neural networks using a spin hall effect based logic-in-memory architecture},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Flexible on-line reconfiguration of multi-core neuromorphic
platforms. <em>TETC</em>, <em>9</em>(2), 915–927. (<a
href="https://doi.org/10.1109/TETC.2019.2908079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neuromorphic architectures are emerging not only for real-time simulation of brain-scale biological neural networks but also to support innovative brain-inspired computational paradigms. In both domains there is an increasing demand for flexibility in terms of network configuration and runtime redesign of network parameters and simulated neurons models. Due to the intrinsically high parallelism of these architectures and complexity of the interconnect, broadcasting updates to the cores is time consuming. Hence, static solutions where the network is reloaded from an external host instead of being reconfigured are highly inefficient. To address these requirements, we designed an Application Command Protocol (ACP). The proposed protocol provides a mechanism to remotely trigger the execution of high-level op-codes by the cores and manage their application memory, and supports a more flexible computational model and memory management. We worked on SpiNNaker, a multi-core globally-asynchronous locally-synchronous platform running Spiking Neural Networks (SNNs) simulations. We demonstrated ACP in two SNN applications: i) SNN configuration, where simulation data are efficiently generated through ACP in the memory of computing nodes and ii) SNN reconfiguration, where ACP is used to change SNN network parameters at runtime and to easily switch from learning to test phase in a SNN classification application.},
  archive      = {J_TETC},
  author       = {Francesco Barchi and Gianvito Urgese and Alessandro Siino and Santa Di Cataldo and Enrico Macii and Andrea Acquaviva},
  doi          = {10.1109/TETC.2019.2908079},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {915-927},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Flexible on-line reconfiguration of multi-core neuromorphic platforms},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). RDAM: A reinforcement learning based dynamic attribute
matrix representation for virtual network embedding. <em>TETC</em>,
<em>9</em>(2), 901–914. (<a
href="https://doi.org/10.1109/TETC.2018.2871549">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network virtualization makes it possible to manage multiple virtual networks simultaneously on substrate physical networks. Virtual network embedding (VNE) is the critical step of network virtualization that maps virtual network requests to substrate physical networks. The majority of current virtual network embedding algorithms utilize heuristic algorithm, and manually customize a series of rules and assumptions. Therefore, these experimental results are not particularly convincing. This paper proposes a reinforcement learning based dynamic attribute matrix representation (RDAM) algorithm for virtual network embedding. The RDAM algorithm decomposes the process of node mapping into the following three steps: (1) static representation of substrate physical network. (2) dynamic update of substrate physical network. (3) Reinforcement-Learning-Based algorithm. To our best knowledge, RDAM algorithm is the first algorithm to apply spectral analysis and perturbation theory to virtual network embedding. Meanwhile, the method training virtual network embedding algorithm by reinforcement learning is also non-trivial. Furthermore, we compare RDAM algorithm with three other virtual network embedding algorithms. The results show that RDAM algorithm outperforms the other three algorithms in terms of several evaluation metrics, such as long-term average revenue, long-term revenue consumption ratio, and acceptance ratio.},
  archive      = {J_TETC},
  author       = {Haipeng Yao and Bo Zhang and Peiying Zhang and Sheng Wu and Chunxiao Jiang and Song Guo},
  doi          = {10.1109/TETC.2018.2871549},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {901-914},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {RDAM: A reinforcement learning based dynamic attribute matrix representation for virtual network embedding},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). FunkR-pDAE: Personalized project recommendation using deep
learning. <em>TETC</em>, <em>9</em>(2), 886–900. (<a
href="https://doi.org/10.1109/TETC.2018.2870734">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In open source communities, developers always need to spend plenty of time and energy on discovering specific projects from massive open source projects. Consequently, the study of personalized project recommendation for developers has important theoretical and practical significance. However, existing recommendation approaches have clear limitations, such as ignoring developers&#39; operating behavior, social relationships and practical skills, and are very inefficient for large amounts of data. To address these limitations, this paper proposes FunkR-pDAE (Funk singular value decomposition Recommendation using pearson correlation coefficient and Deep Auto-Encoders), a novel personalized project recommendation approach using a deep learning model. FunkR-pDAE first extracts data related to developers and open source projects from open source communities, which build a developer-open source project relevance matrix and a developer-developer relevance matrix. Meanwhile, Pearson Correlation Coefficient is utilized to calculate developer similarity using the developer-developer relevance matrix. Second, deep auto-encoders are used to learn the factor vectors that represent developers and open source projects. Finally, a sorting method is defined to provide personalized project recommendations. Experimental results on real-world GitHub data sets show that FunkR-pDAE has a precision rate of 75.46 percent and a recall rate of 40.32 percent, which provides more effective recommendation compared with state-of-the-art approaches.},
  archive      = {J_TETC},
  author       = {Pengcheng Zhang and Fang Xiong and Hareton Leung and Wei Song},
  doi          = {10.1109/TETC.2018.2870734},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {886-900},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {FunkR-pDAE: Personalized project recommendation using deep learning},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Resonant-tunnelling diodes as PUF building blocks.
<em>TETC</em>, <em>9</em>(2), 878–885. (<a
href="https://doi.org/10.1109/TETC.2019.2893040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Resonant-Tunnelling Diodes (RTDs) have been proposed as building blocks for Physical Unclonable Functions (PUFs). In this paper we show how the unique RTD current-voltage (I-V) spectrum can be translated into a robust digital representation. We analyse 130 devices and show that RTDs are a viable PUF building block.},
  archive      = {J_TETC},
  author       = {Ibrahim Ethem Bagci and Thomas McGrath and Christine Barthelmes and Scott Dean and RamÓn Bernardo Gavito and Robert James Young and Utz Roedig},
  doi          = {10.1109/TETC.2019.2893040},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {878-885},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Resonant-tunnelling diodes as PUF building blocks},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deployment of robust security scheme in SDN based 5G network
over NFV enabled cloud environment. <em>TETC</em>, <em>9</em>(2),
866–877. (<a href="https://doi.org/10.1109/TETC.2018.2879714">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this Modern era, Software Defined Network (SDN), Network Function Virtualization (NFV), and cloud computing participating of Fifth Generation (5G) network emergence. This paper presents a robust security scheme to provide fortification against major threats along with user privacy in 5G network, two additional entities are introduced. For mobile users, initial authentication is provided at access points by an inventive Highly Secured Authentication and Handover Mechanism (HS-AOHM) scheme which minimizes handover latency without loss of user privacy. Then the authorized user packets are arrived at dispatcher in which a novel Tree Based Switch Assignment (TBSA) algorithm is incorporated. TBSA mitigates the flow table overloading attack by assigning packets to underloaded switches. In controller, DDoS attack is detected with the assist of entropy analysis. Then the suspicious packets are redirected to scrubbing Virtual Network Function (sVNF) in cloud. In sVNF, suspicious packets are classified into normal packets and malicious packets by using Hybrid Fuzzy with Artificial Neural Network (HF-ANN) classifier based on packet features. Normal packets are allowed to access applications whereas malicious packets are dropped at sVNF. Extensive simulation shows security improvement in 5G network in terms of handover latency, holding time, switch failure rate, detection accuracy, and delay.},
  archive      = {J_TETC},
  author       = {Ihsan H. Abdulqadder and Deqing Zou and Israa T. Aziz and Bin Yuan and Weiqi Dai},
  doi          = {10.1109/TETC.2018.2879714},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {866-877},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Deployment of robust security scheme in SDN based 5G network over NFV enabled cloud environment},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Quantifying the impact of monolithic 3D (M3D) integration on
l1 caches. <em>TETC</em>, <em>9</em>(2), 854–865. (<a
href="https://doi.org/10.1109/TETC.2019.2894982">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monolithic 3D (M3D) integration has been recently introduced as a viable solution for fine-grained 3D integration. Since the conventional 3D integration uses relatively large micro-scale through-silicon-vias (TSVs), which causes large TSV area overhead, it is not cost-effective for small micro architectural blocks such as L1 caches. On the contrary, the M3D integration offers nano-scale monolithic inter-tier vias (MIVs) which are much smaller than TSVs. Thus, the M3D integration is known to be even feasible for 3D stacking of small micro architectural blocks, which reduces wire length of the blocks, leading to better performance and energy-efficiency. In this paper, we quantify the architectural impact (in terms of performance, power, temperature, and area) of the M3D integration for L1 caches. In our evaluation, the 8-layer stacked M3D L1 caches show 34.1~43.2 percent shorter access time than the 2D L1 cache. As a result, the M3D L1 caches improve the performance of SPEC CPU 2006 applications by 9.9 percent (up to 43.7 percent), on average, compared to the conventional 2D L1 caches. Additionally, the 8-layer stacked M3D L1 caches reduce dynamic energy and leakage power by 58.9 percent ~60.8 percent and 57.9~59.1 percent, respectively, compared to the 2D L1 cache. Additionally, though 3D stacking inevitably causes higher temperature than 2D baseline, since the M3D integration provides better heat dissipation as well as lower power consumption than the conventional TSV-3D, it reduces peak L1 cache temperature by up to 7.6°C, compared to the TSV-3D.},
  archive      = {J_TETC},
  author       = {YOUNG-HO GONG and JOONHO KONG and SUNG WOO CHUNG},
  doi          = {10.1109/TETC.2019.2894982},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {854-865},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Quantifying the impact of monolithic 3D (M3D) integration on l1 caches},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimized fuzzy commitment based key agreement protocol for
wireless body area network. <em>TETC</em>, <em>9</em>(2), 839–853. (<a
href="https://doi.org/10.1109/TETC.2019.2949137">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless body area networks composed of wearable devices have increasingly become an integral part of personal health monitoring and medical assistance. A series of key agreement schemes using heartbeats as a source of trust have been proposed to protect health data transferred among devices carried by a person from leakage. However, because of the unrealistic assumption in their threat model and the use of fixed parameters, previous schemes have unstable performance for different individuals and even have the risk of security degradation such that the schemes can be compromised by attackers. In this paper, we present an optimal key agreement scheme based on heartbeat, to ensure secure communication between legitimate devices. The proposed key agreement scheme employs fuzzy commitment with low latency in feature extraction. Moreover, the physiological-distribution-based parameter optimization (PDPO) algorithm is proposed to adaptively determine the optimal protocol parameters for individuals, which not only ensures outstanding and stable performance but also guarantee the security of the scheme. Finally, we prototype our protocol and conduct experiments with multiple subjects to evaluate its security and performance. Our results demonstrate that the proposed protocol negotiates the key securely and quickly, has low energy overhead, and is suitable for practical applications.},
  archive      = {J_TETC},
  author       = {Qi Jiang and Zhiren Chen and Jianfeng Ma and Xindi Ma and Jian Shen and Dapeng Wu},
  doi          = {10.1109/TETC.2019.2949137},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {839-853},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Optimized fuzzy commitment based key agreement protocol for wireless body area network},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Value of information based sensor ranking for efficient
sensor service allocation in service oriented wireless sensor networks.
<em>TETC</em>, <em>9</em>(2), 823–838. (<a
href="https://doi.org/10.1109/TETC.2019.2891716">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sensor service ranking for effective resource allocation is a well studied problem in service oriented wireless sensor networks. Existing sensor service ranking mechanisms fail to maintain a trade-off between meeting application requirements and minimizing the scarce network resource consumption. Moreover, a common usage context of the sensor data is considered while ranking the sensor services for different application queries. This results in a large number of applications not able to meet their specific quality of service requirements. This paper proposes an energy-aware value of information based sensor service ranking mechanism that models the rank of a sensor service as a value of information attribute while taking into account its usage context in the corresponding application. Integration of the proposed ranking mechanism with existing gateway service suggests its efficiency in maintaining a trade-off between application specific quality of service requirements and overall energy consumption in the network. Simulation results show that the proposed mechanism outperforms existing sensor service ranking mechanisms in terms of meeting applications&#39; quality of service requirements. In addition to this, the proposed mechanism shows an impressive 13 percent improvement in network lifetime.},
  archive      = {J_TETC},
  author       = {Sourabh Bharti and K. K. Pattanaik and Paolo Bellavista},
  doi          = {10.1109/TETC.2019.2891716},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {823-838},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Value of information based sensor ranking for efficient sensor service allocation in service oriented wireless sensor networks},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A lightweight robust logic locking technique to thwart
sensitization and cone-based attacks. <em>TETC</em>, <em>9</em>(2),
811–822. (<a href="https://doi.org/10.1109/TETC.2019.2935250">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Logic locking is a new technique to prevent an integrated circuit from hardware Trojan, piracy, overbuilding, etc. Most of the well-known logic locking techniques are vulnerable to sensitization and cone based attacks. Though the existing techniques try to thwart these attacks, they are highly circuit topology dependent and require significant overhead. Therefore, this paper presents a new lightweight logic locking technique that effectively neutralizes the sensitization and cone based attacks. We further propose new multi key-input gates and a new replacement-based logic locking algorithm. The replacement of design gates with our multi key-input gates not only effectively prevents the key-sensitization and signal probability skew based removal attacks but also removes rare nets from design. On the other hand, our logic locking algorithm significantly increases the brute-force attempts against cone-based attack with minimum replacements by replacing the nodes which have the maximum number of fan-outs and paths to output nodes. We evaluate our technique using ISCAS benchmarks, and the results demonstrate that the proposed key-gates on average reduce 32 percent area-overhead over the XOR/MUX key-gates, whereas our algorithm on average doubles the effective key size while reducing 50 percent area overhead over the best-known technique.},
  archive      = {J_TETC},
  author       = {Vijaypal Singh Rathor and G. K. Sharma},
  doi          = {10.1109/TETC.2019.2935250},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {811-822},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {A lightweight robust logic locking technique to thwart sensitization and cone-based attacks},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). FTxAC: Leveraging the approximate computing paradigm in the
design of fault-tolerant embedded systems to reduce overheads.
<em>TETC</em>, <em>9</em>(2), 797–810. (<a
href="https://doi.org/10.1109/TETC.2020.2986235">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The technological scaling has made electronic devices more susceptible to radiation-induced faults. To mitigate these faults, researchers have proposed different techniques at the software, hardware, and hybrid levels. Although some of these techniques are very effective, most of them are based on redundancy, which causes non-negligible computational overheads in terms of area, performance, and power consumption. In this paper, we propose FTxAC, which consists in using approximate computing techniques in conjunction with radiation-induced mitigation strategies for the design of fault-tolerant systems with minimal overheads. Given the nature of the approximate computing paradigm, FTxAC is suitable for error resilient applications. To show the applicability of the proposal, we carry out several case studies with the TI MSP430 microcontroller, in which a set of software-based fault tolerance techniques are used jointly with approximate computing methods to reduce overheads. The experimental results are analyzed in terms of fault coverage, accuracy of the results, and overheads of the several levels of redundancy. Results show that, depending on the level of approximation, the evaluated application, and the fault tolerance strategy employed, the performance of the system can be improved, even counteracting completely the implicit overheads of the redundancy.},
  archive      = {J_TETC},
  author       = {Alexander Aponte-Moreno and Felipe Restrepo-Calle and Cesar Pedraza},
  doi          = {10.1109/TETC.2020.2986235},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {797-810},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {FTxAC: Leveraging the approximate computing paradigm in the design of fault-tolerant embedded systems to reduce overheads},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Design and analysis of secure emerging crypto-hardware using
HyperFET devices. <em>TETC</em>, <em>9</em>(2), 787–796. (<a
href="https://doi.org/10.1109/TETC.2020.2977735">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of new devices to be used in low-power applications are expected to reach impressive performance compared to those obtained by equivalent CMOS counterparts. However, when used in lightweight security applications, these emerging paradigms are required to be reliable and safe enough during the task of protecting important and valuable data. In this work, the usage of HyperFET devices for security applications has been analyzed and new paradigms for enhancing security against Power Analysis attacks have been developed for the first time. To perform this analysis, classical dual-precharge logic primitives implemented with 14nm FinFET have been upgraded to incorporate HyperFET devices. The proposed primitives incorporating HyperFETs, as well as a 4-bit Substitution box of PRIDE algorithm as demonstrative example, have been designed and simulated using predictive models. Simulation-based Differential Power Analysis attacks demonstrate high improvements in security levels in a x25 factor at least, with negligible degradation in performance. This first approach could be easily extensible to other ciphers or crypto-circuits, where the incorporation of HyperFET devices will enhance security for most future applications.},
  archive      = {J_TETC},
  author       = {Ignacio M. Delgado-Lozano and Erica Tena-SÁnchez and Juan NÚÑez and Antonio J. Acosta},
  doi          = {10.1109/TETC.2020.2977735},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {787-796},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Design and analysis of secure emerging crypto-hardware using HyperFET devices},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). 3D ring oscillator based test structures to detect a trojan
die in a 3D die stack in the presence of process variations.
<em>TETC</em>, <em>9</em>(2), 774–786. (<a
href="https://doi.org/10.1109/TETC.2020.2984162">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D integrated circuits introduce both advantages and disadvantages for security. Among the disadvantages unique to 3D is the potential insertion of a Trojan die into the stack between two legitimate dies. Such a die could be used to snoop information traveling between dies, alter the data, or otherwise interfere with stack operation. In this article, we explore the use of in-stack circuitry and various testing procedures to detect an extra die through delay analysis even in the presence of process variations. Then, we explore the performance of these techniques when the attacker modifies some of the TSVs&#39; characteristics to avoid detection. Our simulation results show that the proposed techniques can detect the Trojan die in a 3D stack, especially when the test structure that incorporates multiple TSVs between two dies is used.},
  archive      = {J_TETC},
  author       = {Soha Alhelaly and Jennifer Dworak and Kundan Nepal and Theodore Manikas and Ping Gui and Alfred L. Crouch},
  doi          = {10.1109/TETC.2020.2984162},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {774-786},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {3D ring oscillator based test structures to detect a trojan die in a 3D die stack in the presence of process variations},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A statistical gate sizing method for timing yield and
lifetime reliability optimization of integrated circuits. <em>TETC</em>,
<em>9</em>(2), 759–773. (<a
href="https://doi.org/10.1109/TETC.2020.2987946">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As CMOS devices become smaller, process and aging variations become a major issue for circuit reliability and yield. In this paper, we propose a new two-phase gate sizing approach in order to improve the reliability of the circuit considering the joint effect of process variation and transistor aging. In the first stage, the initial delay of the circuit is optimized to improve the timing yield of the circuit. Then, in the second stage, we reduce the delay degradation induced by aging and process variations. To this end, two novel concepts called aging probability and delay degradation-aware gate criticality are introduced which enable us to perform gate sizing efficiently using an adaptive multi-objective ranking approach. Experimental results based on ISCAS&#39;85 and EPFL benchmark circuits show that, the proposed method achieves the 95 percent timing yield constraint and the 10 percent timing guard-band as the lifetime reliability constraint at the expense of 13.72 percent area overhead, on average. In comparison with the state-of-the-art methods, the proposed approach imposes lower area overhead with acceptable runtime.},
  archive      = {J_TETC},
  author       = {S. M. Ebrahimipour and Behnam Ghavami and Mohsen Raji},
  doi          = {10.1109/TETC.2020.2987946},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {759-773},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {A statistical gate sizing method for timing yield and lifetime reliability optimization of integrated circuits},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Defect analysis and parallel testing for 3D hybrid
CMOS-memristor memory. <em>TETC</em>, <em>9</em>(2), 745–758. (<a
href="https://doi.org/10.1109/TETC.2020.2982830">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {CMOS Molecular (CMOL) architecture, which can alleviate the sneak path problem of one memristor (1R) crossbars and limit its power consumption, can be used in a large-scale memory system. In this article, we analyze the electrical defects in a CMOL circuit including open and bridge. A parallel March-like test algorithm is presented for the CMOL architecture, which covers the faults caused by the open and bridge defects and parametric variations during its fabrication. Analysis results show that the test time of the proposed test algorithm is reduced significantly compared with the enhanced methods of March-MOM and March C* for CMOL architectures. The write time is reduced approximately 5 n /4× and n ×, respectively, where n is the number of memristors attached to a nanowire segment. The read time is also reduced drastically. Finally, a design for testability (DFT) architecture is proposed to adapt the parallel March-like test algorithm. In compare with the short write time testing scheme, the proposed DFT can achieve 35.4 percent of reduction in area overhead, with 14.52 percent more power overhead kept the same delay in a CMOL circuit with 64 memory cells.},
  archive      = {J_TETC},
  author       = {Peng Liu and Zhiqiang You and Jigang Wu and Michael Elimu and Weizheng Wang and Shuo Cai and Yinhe Han},
  doi          = {10.1109/TETC.2020.2982830},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {745-758},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Defect analysis and parallel testing for 3D hybrid CMOS-memristor memory},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Online safety checking for delay locked loops via embedded
phase error monitor. <em>TETC</em>, <em>9</em>(2), 735–744. (<a
href="https://doi.org/10.1109/TETC.2019.2956971">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today&#39;s automotive ICs, online safety checking is often required in order to achieve a high Automotive Safety Integrity Level (ASIL). For a Delay-Locked Loop (DLL), the most important safety (or health) indicator is the “phase error between the input clock signal and the output clock signal”. In this paper, we present a phase error monitoring scheme for DLLs, using circuits made of only standard cells. The proposed scheme can monitor the phase error continuously to record its worst-case values during a designated monitoring session. As a result, hazardous phase error glitches can be exposed and an alarm can be raised. We have implemented this monitoring scheme for a Delay Lock Loop in a 90 nm CMOS process and post-layout simulation is conducted to verify its effectiveness. Experimental results show that it can help expose hazards induced by dynamic power glitches that occurs within 1ns.},
  archive      = {J_TETC},
  author       = {Wei Chu and Shi-Yu Huang},
  doi          = {10.1109/TETC.2019.2956971},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {735-744},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Online safety checking for delay locked loops via embedded phase error monitor},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel TDMA-based fault tolerance technique for the TSVs in
3D-ICs using honeycomb topology. <em>TETC</em>, <em>9</em>(2), 724–734.
(<a href="https://doi.org/10.1109/TETC.2020.2969237">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Through-silicon-vias (TSVs) are prone to defects during the manufacturing process, which pose yield challenges for three dimensional integrated circuits (3D-ICs). The area per TSV is too great to be ignored, and in order to not use any redundant TSVs, a chain-type time division multiplexing access (TDMA)-based fault tolerance technique is proposed. However, a double-TSV structure is used per group, resulting in a significant TSV hardware overhead under a given large-scaled circuit design. Furthermore, it is impossible for the chain-TDMA scheme to plan the rerouting path for the right-hand-most TSV per group, resulting in a decrease in the repair rate per TSV group as well as in the whole TSV yield. In the proposed technique, we bundle six TSVs per group in a honeycomb pattern and the TSVs on the edges are connected to each other, enhancing the repair rate per group as well as the whole TSV yield. Subsequently, an architecture based on the proposed technique is designed, evaluated, and validated on logic-on-logic 3D IWLS&#39;05 benchmark circuits using 45 nm TSMC technology. The proposed technique is found to reduce the area overhead by 87.95-90.42 percent, compared to the chain-TDMA scheme, which results in a yield of 96.90-99.09 percent.},
  archive      = {J_TETC},
  author       = {Tianming Ni and Zhao Yang and Hao Chang and Xiaoqiang Zhang and Lin Lu and Aibin Yan and Zhengfeng Huang and Xiaoqing Wen},
  doi          = {10.1109/TETC.2020.2969237},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {724-734},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {A novel TDMA-based fault tolerance technique for the TSVs in 3D-ICs using honeycomb topology},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Defect and fault modeling framework for STT-MRAM testing.
<em>TETC</em>, <em>9</em>(2), 707–723. (<a
href="https://doi.org/10.1109/TETC.2019.2960375">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {STT-MRAM mass production is around the corner as major foundries worldwide invest heavily on its commercialization. To ensure high-quality STT-MRAM products, effective yet cost-efficient test solutions are of great importance. This article presents a systematic device-aware defect and fault modeling framework for STT-MRAM to derive accurate fault models which reflect the physical defects appropriately, and thereafter optimal and high-quality test solutions. An overview and classification of manufacturing defects in STT-MRAMs are provided with an emphasis on those related to the fabrication of magnetic tunnel junction (MTJ) devices, i.e., the data-storing elements. Defects in MTJ devices need to be modeled by adjusting the affected technology parameters and subsequent electrical parameters to fully capture the defect impact on both the device&#39;s electrical and magnetic properties, whereas defects in interconnects can be modeled as linear resistors. In addition, a complete single-cell fault space and nomenclature are defined, and a systematic fault analysis methodology is proposed. To demonstrate the use of the proposed framework, resistive defects in interconnect and pinhole defects in MTJ devices are analyzed for a single 1T-1MTJ memory cell. Test solutions for detecting these defects are also discussed.},
  archive      = {J_TETC},
  author       = {Lizhou Wu and Siddharth Rao and Mottaqiallah Taouil and Guilherme Cardoso Medeiros and Moritz Fieback and Erik Jan Marinissen and Gouri Sankar Kar and Said Hamdioui},
  doi          = {10.1109/TETC.2019.2960375},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {707-723},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Defect and fault modeling framework for STT-MRAM testing},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Attacks toward wireless network-on-chip and countermeasures.
<em>TETC</em>, <em>9</em>(2), 692–706. (<a
href="https://doi.org/10.1109/TETC.2020.2973427">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Wireless Network-on-Chip (WiNoC) offers a promising solution to reduce broadcast and long distance communication bottlenecks of conventional architectures by augmenting them with single hop wireless links. In this article, we discuss new security vulnerabilities and countermeasures to protect against them in a WiNoC based system. In particular, we describe Malicious Threshold Configuration (MTC) Attack, Disruptive Token Passing (DTP) Attack, Data Stealing by Broadcast (DSB) Attack and Hybrid Attack against the WiNoC. Our proposed countermeasure against MTC-OU (over-utilization) attack i.e., Source Destination checking mechanism decreases wireless hub utilization by 49% and network latency by many orders of magnitude compared to without countermeasure, causing system performance improvement. Another proposed countermeasure against DTP attacks i.e., detour mechanism improves the network throughout by 1.21x and 23x under DTP-AHT and DTP-DOS attacks respectively.},
  archive      = {J_TETC},
  author       = {Arnab Kumar Biswas and Navonil Chatterjee and Hemanta Kumar Mondal and Guy Gogniat and Jean-Philippe Diguet},
  doi          = {10.1109/TETC.2020.2973427},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {692-706},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Attacks toward wireless network-on-chip and countermeasures},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Autonomous scan patterns for laser voltage imaging.
<em>TETC</em>, <em>9</em>(2), 680–691. (<a
href="https://doi.org/10.1109/TETC.2019.2944590">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The semiconductor industry ramping up design capabilities for emerging technologies is facing new test quality and yield management challenges. To facilitate debugging of the first silicon, diagnosis of yield issues, and to enable repair processes, an accurate defect isolation is needed with support of advanced test, diagnostic, and yield analysis tools. Laser voltage imaging (LVI), laser voltage probing (LVP), and electron-beam testing are popular diagnostic techniques for scan chain failures. As scan remains instrumental in developing more advanced DFT technologies, its reliable operations are essential for test pattern bring-up, failure analysis, and yield learning. Running LVI tests at early stages of a design process involves a sophisticated infrastructure to offer a nanometer diagnostic resolution with a non-destructive failure isolation. However, as the use of external testers may not be feasible besides providing power and clock signals, the paper demonstrates how to reuse on-chip EDT compression environment to generate and apply LVI-aware scan patterns for advanced contactless test procedures. The presented approach avoids the repetitive loading of scan chains, requires no seed patterns to encode LVI tests, has virtually no area overhead, and offers a flexible selection of non-toggling scan chains in a low power test mode. Furthermore, there are no constraints or requirements imposed by designs that could limit the applicability of the scheme. The proposed solution does not compromise the test compression performance, marked by test data reduction ratios, test coverage, and test time. Hence, there are no modifications needed in existing flows and tools to implement the method besides the use of recommended polynomials.},
  archive      = {J_TETC},
  author       = {Wu-Tung Cheng and Sylwester Milewski and Grzegorz Mrugalski and Janusz Rajski and Maciej Trawka and Jerzy Tyszer},
  doi          = {10.1109/TETC.2019.2944590},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {680-691},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Autonomous scan patterns for laser voltage imaging},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Detection, location and concealment of defective pixels in
image sensors. <em>TETC</em>, <em>9</em>(2), 664–679. (<a
href="https://doi.org/10.1109/TETC.2020.2976807">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the construction process of defective pixel detection and concealment methods, for image sensor online diagnosis and self-healing. The proposed process is based on pixel neighborhood analysis using only simple arithmetic operations on the image files. This leads to an optimization of the processing speed of the produced image. A first step in the process is to identify and locate the defective pixels on the image. Three defective pixel detection algorithms are proposed. The first one uses the distance between the pixel under test and its neighboring pixels. The second method is based on the median value of the pixel block around each pixel. The third method uses an evaluation and analysis of the local dispersion parameters in the image. The concealment of detected defective pixels is the second step of the self-healing process of image sensor. It consists of substituting the defective value by the median value of the neighborhood pixel block. In the study and learning phase, distorted images obtained by injecting random disturbances into healthy reference images are used to evaluate the defective pixel detection and concealment methods. The set of $1 176$ distorted images is constructed using 196 reference images with six types of defects, based on typical failure mechanism of image sensors. The proposed methods are compared to different state-of-the-art defective pixel detection and correction methods, in both software and FPGA implementations. The experimental results undoubtedly demonstrate that the new methods proposed in this paper perform the best results compared to the state-of-the-art.},
  archive      = {J_TETC},
  author       = {Ghislain Takam Tchendjou and Emmanuel Simeu},
  doi          = {10.1109/TETC.2020.2976807},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {664-679},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Detection, location and concealment of defective pixels in image sensors},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Protecting memories against soft errors: The case for
customizable error correction codes. <em>TETC</em>, <em>9</em>(2),
651–663. (<a href="https://doi.org/10.1109/TETC.2019.2953139">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As technology scales, radiation induced soft errors create more complex error patterns in memories with a single particle corrupting several bits. This poses a challenge to the Error Correction Codes (ECCs) traditionally used to protect memories that can correct only single bit errors. During the last decade, a number of codes have been developed to correct the emerging error patterns, focusing initially on double adjacent errors and later on three bit burst errors. However, as the memory cells get smaller and smaller, the error patterns created by radiation will continue to change and thus new codes will be needed. In addition, the memory layout and the technology used may also make some patterns more likely than others. For example, in some memories, there maybe elements that separate blocks of bits in a word, making errors that affect two blocks less likely. Finally, for a given memory, depending on the data stored, some error patterns may be more critical than others. For example, if numbers are stored in the memory, in most cases, errors on the more significant bits have a larger impact. Therefore, for a given memory and application, to achieve optimal protection, we would like to have a code that corrects a given set of patterns. This is not possible today as there is a limited number of code choices available in terms of correctable error patterns and word lengths. However, most of the codes used to protect memories are linear block codes that have a regular structure and which design can be automated. In this paper, we propose the automation of error correction code design for memory protection. To that end, we introduce a software tool that given a word length and the error patterns that need to be corrected, produces a linear block code described by its parity check matrix and also the bit placement. The benefits of this automated design approach are illustrated with several case studies. Finally, the tool is made available so that designers can easily produce custom error correction codes for their specific needs.},
  archive      = {J_TETC},
  author       = {Jiaqiang Li and Pedro Reviriego and Liyi Xiao and Haotian Wu},
  doi          = {10.1109/TETC.2019.2953139},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {651-663},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Protecting memories against soft errors: The case for customizable error correction codes},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Guest editorial: Special section on emerging trends and
computing paradigms for testing, reliability and security in future VLSI
systems. <em>TETC</em>, <em>9</em>(2), 649–650. (<a
href="https://doi.org/10.1109/TETC.2021.3070450">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The papers in this special section focus on emerging trends and computing paradigms for testing, reliability and security in future VLSI systems. With the rapid advancement of computing technologies in all domains (i.e., handheld devices, autonomous vehicles, medical devices, and massive supercomputers), testability, reliability, and security of electronic systems are crucial challenges for the safety of human life. Emerging technologies coupled with new computing paradigms (e.g., approximate computing, neuromorphic computing, in-memory computing) are together exacerbating these problems posing significant challenges to researchers and designers. To address this increased complexity in the hardware testing, reliability, and security domains, engineers must employ design and analysis methods working at all levels of abstraction, starting from the system level down to the gate and transistor level.},
  archive      = {J_TETC},
  author       = {Stefano Di Carlo and Peilin Song and Alessandro Savino},
  doi          = {10.1109/TETC.2021.3070450},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {649-650},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Guest editorial: Special section on emerging trends and computing paradigms for testing, reliability and security in future VLSI systems},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Public service models: A systematic literature review and
synthesis. <em>TETC</em>, <em>9</em>(2), 637–648. (<a
href="https://doi.org/10.1109/TETC.2019.2939485">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the last decades, public authorities worldwide have invested heavily in electronic public services (PSs). This includes efforts for publishing information about PSs and for providing online PSs. Each of these efforts is based on an underlying PS Model, i.e., a data model developed for describing and/or developing PSs. Although many PS models exist, none has been universally accepted. This resulted in a fragmented landscape where resources are wasted, economies of scale cannot be achieved, and interoperability is hampered. Recently, the European Union (EU) launched the Core Public Service Vocabulary-Application Profile (CPSV-AP) as a reference PS model. However, CPSV-AP has not been thoroughly evaluated yet for comprehensiveness and compliance with EU policies. The aim of this work is to identify and analyze in a systematic way existing PS models and compare them with CPSV-AP. We conclude that CPSV-AP is comprehensive but can be further enriched with concepts from other PS models. We also provide evidence that the proposed enriched CPSV-AP better supports EU policies. Finally, we present a proof-of-concept pilot of the enriched model using linked data to demonstrate its technical feasibility and added value. Researchers, policy makers and practitioners could use the enriched model for conceptualizing and implementing electronic PSs.},
  archive      = {J_TETC},
  author       = {ALEXANDROS GERONTAS and VASSILIOS PERISTERAS and EFTHIMIOS TAMBOURIS and ELENI KALIVA and IOANNIS MAGNISALIS and KONSTANINOS TARABANIS},
  doi          = {10.1109/TETC.2019.2939485},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {637-648},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Public service models: A systematic literature review and synthesis},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Iterated watersheds, a connected variation of k-means for
clustering GIS data. <em>TETC</em>, <em>9</em>(2), 626–636. (<a
href="https://doi.org/10.1109/TETC.2019.2910147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose a novel algorithm to obtain a solution to the clustering problem with an additional constraint of connectivity. This is achieved by suitably modifying K-Means algorithm to include connectivity constraints. The modified algorithm involves repeated application of watershed transform, and hence is referred to as iterated watersheds. Detailed analysis of the algorithm is performed using toy examples. Iterated watersheds is compared with several image segmentation algorithms. It has been shown that iterated watersheds performs better than methods such as spectral clustering, isoperimetric partitioning, and K-Means on various measures. To illustrate the applicability of iterated watersheds - a simple problem of placing emergency stations and suitable cost function is considered. Using real world road networks of various cities, iterated watersheds is compared with K-Means and greedy K-center methods. It is observed that iterated watersheds result in 4 - 66 percent improvement over K-Means and in 31 - 72 percent improvement over Greedy K-Centers in experiments on road networks of various cities.},
  archive      = {J_TETC},
  author       = {Sampriti Soor and Aditya Challa and Sravan Danda and B. S. Daya Sagar and Laurent Najman},
  doi          = {10.1109/TETC.2019.2910147},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {626-636},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Iterated watersheds, a connected variation of K-means for clustering GIS data},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Polynomial vault: A secure and robust fingerprint based
authentication. <em>TETC</em>, <em>9</em>(2), 612–625. (<a
href="https://doi.org/10.1109/TETC.2019.2915288">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fingerprint matching is one of the extensively used tools to authenticate users. It has been accepted by governments of various countries to authenticate their citizens. The common practice in a fingerprint based system is to store minutiae points of fingerprints as the user template. The minutiae points information can be accessed through an attack by an adversary and the original fingerprint of users can be obtained using this information. Unlike passwords, a compromised fingerprint is irreparable and there is a necessity to protect user data. In this paper, a technique called Polynomial Vault is proposed to secure fingerprint information. The fingerprint features and a unique user key-set are used to generate a secure template for a user by using a non-invertible transformation. This obtained template is used to authenticate the user. In case a user template is compromised, the proposed technique provides a way to construct a new template by changing the user key-set values. To demonstrate the efficiency and the robustness of the proposed technique, a thorough experimental analysis is being conducted using IIT Kanpur, FVC2004 (DB1 and DB2), FVC2002 (DB1, DB2, DB3, and DB4), and FVC2000 (DB1 and DB2) databases.},
  archive      = {J_TETC},
  author       = {Syed Sadaf Ali and Iyyakutti Iyappan Ganapathi and Sajid Mahyo and Surya Prakash},
  doi          = {10.1109/TETC.2019.2915288},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {612-625},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Polynomial vault: A secure and robust fingerprint based authentication},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The e-LocGov model for introducing e-governance into local
governments: An estonian case study. <em>TETC</em>, <em>9</em>(2),
597–611. (<a href="https://doi.org/10.1109/TETC.2019.2910199">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We report on the results of an ongoing, long-term, large-scale, cross-organizational, and canonical action research project that we started in Estonia in 2003 to develop a reusable model (e-LocGov model) for the systematic introduction of e-governance into local governments. The project was conducted in cooperation with 126 local governments, which constitute more than half of Estonia&#39;s local governments. Given the complexity of the task, the endeavors in this project are necessarily highly interdisciplinary and cover the legal, the managerial, and the technological spheres. Consequentially, the e-LocGov model consists of major building blocks, each of which meets with a major challenge in the introduction of e-Governance: (i) state readiness, (ii) local government readiness, (iii) transition/implementation, and (iv) analysis and assessment. We provide a comprehensive explanation of the e-LocGov model and its building blocks. Also, we report on the research methodology and the theoretical background of this project.},
  archive      = {J_TETC},
  author       = {Ingrid Pappel and Valentyna Tsap and Dirk Draheim},
  doi          = {10.1109/TETC.2019.2910199},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {597-611},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {The e-LocGov model for introducing e-governance into local governments: An estonian case study},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An empirical investigation of the relationship between local
government budgets, IT expenditures, and cyber losses. <em>TETC</em>,
<em>9</em>(2), 582–596. (<a
href="https://doi.org/10.1109/TETC.2019.2915098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information technology (IT) is the key component of e-government infrastructures, but at the same time, it makes governments more exposed to the cyber risk. In this study, we take an empirical approach to investigate the cyber risk in the public sector. We describe the most common cyber threats facing local governments and build linear models to explain the relationships between cyber losses, local government budgets, and IT expenditures. We find that local governments are affected by cyber incidents more frequently, and disruption incidents that lead to the malfunction of e-government services are on the rise. In addition, the magnitude of cyber losses used to have a strong positive relationship with the affected governments’ budget size. However, in recent years, this relationship is weakening, and small local governments are more heavily impacted by cyber incidents than before. Our findings further suggest that investing in information technology is becoming more effective in terms of lowering the loss-to-budget ratio. However, this also means local governments with small budgets do not benefit from this change as much as the large ones do.},
  archive      = {J_TETC},
  author       = {Jay P. Kesan and Linfeng Zhang},
  doi          = {10.1109/TETC.2019.2915098},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {582-596},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {An empirical investigation of the relationship between local government budgets, IT expenditures, and cyber losses},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Open data categorization based on formal concept analysis.
<em>TETC</em>, <em>9</em>(2), 571–581. (<a
href="https://doi.org/10.1109/TETC.2019.2919330">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Government institutions have released a large number of datasets on their open data portals, which are in line with the data transparency and open government initiatives. With the purpose of making it more accessible and visible, these portals categorize datasets based on different criteria like publishers, categories, formats, and descriptions. However, some of this information is often missing, making it impossible to find datasets in all of these ways. As a result, with the number of datasets growing further on the portals, it is getting harder to obtain the desired information. This paper addresses this issue by introducing EODClassifier framework that suggests the best match for the category where a dataset should belong to. It relies on formal concept analysis as a means to generate a data structure that will reveal shared conceptualization originating from tags&#39; usage and utilize it as a knowledge base to categorize uncategorized open datasets.},
  archive      = {J_TETC},
  author       = {Milena FrtuniĆ GligorijeviĆ and MiloŠ BogdanoviĆ and NataŠa VeljkoviĆ and Leonid Stoimenov},
  doi          = {10.1109/TETC.2019.2919330},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {571-581},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Open data categorization based on formal concept analysis},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Guest editorial: Special section on eGovernment research,
management and innovation (SIEGRMI). <em>TETC</em>, <em>9</em>(2),
569–570. (<a href="https://doi.org/10.1109/TETC.2021.3077158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The papers in this special section on e-government research, management, and innovation (SIEGRMI). An information and knowledge society creates value by gathering, processing, evaluating, and sharing digital products and services. However, no citizens can be left behind in introducing Web-based technologies to the ad- ministration, creating a digital divide. Representatives of the governments, international organizations, and universities should develop a vision for eGovernment, management, and innovation. The term eGovernment covers information and communication processes between governmental institutions, pri- vate companies, and citizens. Besides, its focus should be on developing electronic services for taxation, social security, health care, enrollment in education, and job search, among others. Governmental institutions offer their electronic ser- vices not only to citizens but also to companies and orga- nizations. Also, the government uses Internet technologies to unify and improve the processes within its respective organizations.},
  archive      = {J_TETC},
  author       = {Andreas Meier and Luis Terán},
  doi          = {10.1109/TETC.2021.3077158},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {4},
  number       = {2},
  pages        = {569-570},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Guest editorial: Special section on eGovernment research, management and innovation (SIEGRMI)},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automatic signature verification in the mobile cloud
scenario: Survey and way ahead. <em>TETC</em>, <em>9</em>(1), 554–568.
(<a href="https://doi.org/10.1109/TETC.2018.2865345">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {On-line signature verification is typically carried out with the use of digitizing tablets specifically designed for the aim. So far, stand-alone systems have been mainly inspected, but the current distributed/cloud scenario and the amount of mobile devices in everyday life is calling for a new challenge. Within this scenario, signatures are acquired around the world with different kinds of devices and processed on multiple platforms in order to be verified. Through the paper, the different phases of the signature verification process in the new scenario are presented and the most valuable results are discussed considering the following aspects: accessibility and usability, interoperability, security and performance. Achievements as well as weakness are focused to highlight promising directions for further research and technology development.},
  archive      = {J_TETC},
  author       = {Donato Impedovo and Giuseppe Pirlo},
  doi          = {10.1109/TETC.2018.2865345},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {554-568},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Automatic signature verification in the mobile cloud scenario: Survey and way ahead},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Negative capacitance clock distribution. <em>TETC</em>,
<em>9</em>(1), 547–553. (<a
href="https://doi.org/10.1109/TETC.2018.2872000">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the ever-increasing power issue that is poised to jeopardize the performance and robustness of future low-power microprocessor design. We have observed a tremendous amount of research in low-power clock network design to bolster energy-efficient computing, without, however, any substantial improvement in overall microprocessor clock power and performance. In this work, we used the emerging ferroelectric negative capacitance field-effect transistor (NCFET) to reduce clock network effective capacitance and active elements, which enables low-power clocking. According to accurate HSPICE simulation, the proposed NCFET-based clocking can save up to 70 and 73 percent average power compared to the industry standard clocking schemes on industrial ISPD 2009 and ISPD 2010 benchmarks, respectively. In addition, the proposed methodology uses up to 20 percent fewer clock buffers compared to the existing synthesized clocking scheme and exhibits 49 percent lower crosstalk-induced delay variation compared to the traditional CMOS-based design.},
  archive      = {J_TETC},
  author       = {Riadul Islam},
  doi          = {10.1109/TETC.2018.2872000},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {547-553},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Negative capacitance clock distribution},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Enabling authorized encrypted search for multi-authority
medical databases. <em>TETC</em>, <em>9</em>(1), 534–546. (<a
href="https://doi.org/10.1109/TETC.2019.2905572">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {E-medical records are sensitive and should be stored in a medical database in encrypted form. However, simply encrypting these records will eliminate data utility and interoperability of the existing medical database system because encrypted records are no longer searchable. Moreover, multiple authorities could be involved in controlling and sharing the private medical records of clients. However, authorizing different clients to search and access records originating from multiple authorities in a secure and scalable manner is a nontrivial matter. To address the above issues, we propose an authorized searchable encryption scheme under a multi-authority setting. Specifically, our proposed scheme leverages the RSA function to enable each authority to limit the search capability of different clients based on clients&#39; privileges. To improve scalability, we utilize multi-authority attribute-based encryption to allow the authorization process to be performed only once even over policies from multiple authorities. We conduct rigorous security and cost analysis, and perform experimental evaluations to demonstrate that the proposed scheme introduces moderate overhead to existing searchable encryption schemes.},
  archive      = {J_TETC},
  author       = {Lei Xu and Shifeng Sun and Xingliang Yuan and Joseph K. Liu and Cong Zuo and Chungen Xu},
  doi          = {10.1109/TETC.2019.2905572},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {534-546},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Enabling authorized encrypted search for multi-authority medical databases},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Novel low cost, double-and-triple-node-upset-tolerant latch
designs for nano-scale CMOS. <em>TETC</em>, <em>9</em>(1), 520–533. (<a
href="https://doi.org/10.1109/TETC.2018.2871861">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents two novel low cost, double-and-triple-node-upset tolerant latch designs. First, a novel low cost and double-node-upset (DNU) completely tolerant (LCDNUT) latch design is proposed. The latch mainly comprises a storage module (SM) feeding back to a 3-input C-element. The SM mainly consists of eight input-split inverters. Since the inputs of the C-element cannot be simultaneously flipped, the latch tolerates any DNU in the SM. When a single node in the SM and the output node are affected, the latch can self-recover from the DNU. Second, to completely tolerate any triple-node-upset (TNU), by replacing the C-element in the LCDNUT latch with a two-level error-interceptive module constructed from triple C-elements, a novel low cost and TNU completely tolerant (LCTNUT) latch design is proposed. Simulation results demonstrate the robustness of the proposed latches. Furthermore, due to the use of a high-speed transmission path, the clock-gating technology and fewer transistors, the proposed LCTNUT latch reduces the delay-power-area product by approximately 99.39 percent and has a low sensitivity to the process-voltage-and-temperature variation effects, compared with currently the only TNU completely tolerant latch design.},
  archive      = {J_TETC},
  author       = {AIBIN YAN and CHAOPING LAI and YINLEI ZHANG and Jie Cui and Zhengfeng Huang and JIE SONG and Jing Guo and Xiaoqing Wen},
  doi          = {10.1109/TETC.2018.2871861},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {520-533},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Novel low cost, double-and-triple-node-upset-tolerant latch designs for nano-scale CMOS},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient parallel binary operations on homomorphic
encrypted real numbers. <em>TETC</em>, <em>9</em>(1), 507–519. (<a
href="https://doi.org/10.1109/TETC.2019.2906047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A number of homomorphic encryption application areas could be better enabled if there existed a general solution for combining sufficiently expressive logical and numerical circuit primitives. This paper examines accelerating binary operations on real numbers suitable for somewhat homomorphic encryption. A parallel solution based on Single Instruction Multiple Data (SIMD) can be used to efficiently perform combined addition, subtraction and comparison-based operations on packed binary operands in a single step. The result maximises computational efficiency, memory space usage and minimises multiplicative circuit depth. General application and performance of these accelerated binary primitives are demonstrated in a number of case studies, including min-max and sorting operations.},
  archive      = {J_TETC},
  author       = {Jim Basilakis and Bahman Javadi},
  doi          = {10.1109/TETC.2019.2906047},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {507-519},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Efficient parallel binary operations on homomorphic encrypted real numbers},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Trading computation for communication: A taxonomy of data
recomputation techniques. <em>TETC</em>, <em>9</em>(1), 496–506. (<a
href="https://doi.org/10.1109/TETC.2018.2883286">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A critical challenge for modern system design is meeting the overwhelming performance, storage, and communication bandwidth demand of emerging applications within a tightly bound power budget. As both the time and power, hence the energy, spent in data communication by far exceeds the energy spent in actual data generation (i.e., computation), (re)computing data can easily become cheaper than storing and retrieving (pre)computed data. Therefore, trading computation for communication can improve energy efficiency by minimizing the energy overhead incurred by data storage, retrieval, and communication. This paper provides a taxonomy for the computation versus communication trade-off accompanied by a quantitative characterization.},
  archive      = {J_TETC},
  author       = {Ismail Akturk and Ulya R. Karpuzcu},
  doi          = {10.1109/TETC.2018.2883286},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {496-506},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Trading computation for communication: A taxonomy of data recomputation techniques},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal sprinting pattern in thermal constrained CMPs.
<em>TETC</em>, <em>9</em>(1), 484–495. (<a
href="https://doi.org/10.1109/TETC.2019.2890867">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As studied in literatures, Computational Sprinting (CS) is a promising technique to tackle the thermal challenge for Chip Multi-Processors (CMPs) in dark silicon era. Sprinting pattern, the boosted chip and voltage during the sprinting time, greatly impacts the CMP performance. In the paper, we address how to find out the optimal sprinting pattern which maximizes the performance of CMPs within thermal limitation. First, we conduce a mathematical proof to show that any thermal-constrained CMP, when it executes an application, has a specialized, sustainable configuration &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$(v_o, f_o)$&lt;/tex-math&gt;&lt;/inline-formula&gt; , under which the CMP can keep sprinting without resting and meanwhile its performance is maximized. Then, we design a self-adaptive algorithm automatically altering the chip frequency with adjustable step size and voltage in runtime to reach the optimal value. Finally, our extensive experimental results reveal that our Optimal Sprinting Pattern (OSP) outperforms state-of-the-art sprinting techniques, Full Sprinting Policy (FSP) and Adaptive Sprinting Pacing (ASP). Specifically, our OSP improves the computational efficiency in MIPS by up to 59 percent against FSP and 40 percent against ASP. It also achieves higher energy efficiency in MIPJ, by up to 41 and 25 percent over FSP and ASP, respectively. Moreover, we demonstrate that our method is effective for various CMPs with different scales, CPU architectures and chip nano-technologies.},
  archive      = {J_TETC},
  author       = {Jian Wang and Zhe Chen and Shize Guo and Yubai Li and Zhonghai Lu},
  doi          = {10.1109/TETC.2019.2890867},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {484-495},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Optimal sprinting pattern in thermal constrained CMPs},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Time-bounded activity recognition for ambient assisted
living. <em>TETC</em>, <em>9</em>(1), 471–483. (<a
href="https://doi.org/10.1109/TETC.2018.2870047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust activity recognition in near real-time is a prerequisite for delivering the smartness intrinsic to the pragmatic realisation of smart homes, environments and so forth. Many of the physical devices necessary for equipping a smart home are already available as consumer electronic devices and certified for use by the public. Yet activity recognition remains the preserve of the research community, despite the array of machine learning and other AI techniques currently available. To-date, research has been dominated by the use of pre-segmented data, resulting in the recognition of an arbitrary activity subsequent to its completion. For assistive paradigms dependent on smart technologies, for example Ambient Assisted Living, such approaches are insufficient. The overall objective must be the identification of an activity within an appropriative confidence level as soon as possible after activity commencement. This paper presents a novel approach, Cumulatively Overlapping windowing approach for AmBient Recognition of Activities (COBRA), for near real-time activity recognition, specifically within 10, 30, 60 or 120 seconds of the commencement of an activity. COBRA utilizes an innovative combination of sliding windows augmented with a logistic regression model. The approach is evaluated using the well-established, open, CASAS dataset.},
  archive      = {J_TETC},
  author       = {Jie Wan and MingSong Li and Michael J. O&#39;Grady and Xiang Gu and Munassar A.A.H Alawlaqi and Gregory M.P. O&#39;Hare},
  doi          = {10.1109/TETC.2018.2870047},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {471-483},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Time-bounded activity recognition for ambient assisted living},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Privacy-preserving reinforcement learning design for
patient-centric dynamic treatment regimes. <em>TETC</em>, <em>9</em>(1),
456–470. (<a href="https://doi.org/10.1109/TETC.2019.2896325">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a privacy-preserving reinforcement learning framework for a patient-centric dynamic treatment regime, which we refer to as Preyer. Using Preyer, a patient-centric treatment strategy can be made spontaneously while preserving the privacy of the patient&#39;s current health state and the treatment decision. Specifically, we first design a new storage and computation method to support noninteger processing for multiple encrypted domains. A new secure plaintext length control protocol is also proposed to avoid plaintext overflow after executing secure computation repeatedly. Moreover, we design a new privacy-preserving reinforcement learning framework with experience replay to build the model for secure dynamic treatment policymaking. Furthermore, we prove that Preyer facilitates patient dynamic treatment policymaking without leaking sensitive information to unauthorized parties. We also demonstrate the utility and efficiency of Preyer using simulations and analysis.},
  archive      = {J_TETC},
  author       = {Ximeng Liu and Robert H. Deng and Kim-Kwang Raymond Choo and Yang Yang},
  doi          = {10.1109/TETC.2019.2896325},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {456-470},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Privacy-preserving reinforcement learning design for patient-centric dynamic treatment regimes},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). High-performance predictable NVM-based instruction memory
for real-time embedded systems. <em>TETC</em>, <em>9</em>(1), 441–455.
(<a href="https://doi.org/10.1109/TETC.2018.2858020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Worst case execution time and energy consumption are two of the most important design constraints of real-time embedded systems and memory subsystem has a major impact on both of them. Therefore, many recent studies have tried to improve the memory subsystem of embedded systems by using emerging non-volatile memories instead of conventional memories such as SRAM and DRAM. Indeed, the low leakage power dissipation and improved density of emerging non-volatile memories make them prime candidates for replacing the conventional memories. However, accessing these memories imposes performance and energy overhead and using them as the instruction memory could increase the worst case execution time, which would have a negative impact on the system. Furthermore, most previous studies that have tried to address such problems have focused on the data memory and therefore their solutions are not suitable for the instruction memory. In this paper, a new instruction memory architecture for non-volatile memories is proposed which reduces the effective memory access latency by employing memory access interleaving technique. Unlike common instruction access latency improvement techniques such as prefetching which usually increase the worst case execution time of the system, the proposed architecture is predictable and does not increase the worst case execution time of the system. Furthermore, it improves both average case execution time and energy consumption of the system and requires no changes to the application code. The proposed architecture has been evaluated using different applications from MiBench and Mälardalen benchmark suites and the results show that compared to previous studies, the proposed architecture can improve the memory energy consumption, the average case execution time, and the worst case execution time of the system by 73, 61, and 27 percent respectively.},
  archive      = {J_TETC},
  author       = {Mostafa Bazzaz and Ali Hoseinghorban and Farimah Poursafaei and Alireza Ejlali},
  doi          = {10.1109/TETC.2018.2858020},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {441-455},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {High-performance predictable NVM-based instruction memory for real-time embedded systems},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cyber security framework for vehicular network based on a
hierarchical game. <em>TETC</em>, <em>9</em>(1), 429–440. (<a
href="https://doi.org/10.1109/TETC.2018.2890476">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growth of electronic devices in connected vehicles and their connections to the untrusted network, present unprecedented exposure to attacks. Therefore, a reliable and efficient cyber security framework is mandatory to protect vehicular networks against the cyber attackers. Thereby, we propose a cyber defense framework based on a hierarchical cooperative game to secure legitimate vehicles from attacks. In the proposed hierarchical game, there are two kinds of players, the head agent and secondary agents that cooperate between each other to detect, predict and react efficiently against suspected attacks. The Intrusion Detection System (IDS), Intrusion Prediction System (IPS), and Intrusion Reaction System (IRS) represent the secondary players, where their strategies are to carry out the detection, prediction and reaction actions, respectively. The Intrusion Decision Agent (IDA) is the head player and is responsible for making decisions in launching the strategies of IDS, IPS and IRS players. The secondary and head agents are to collaborate in order to decrease the false positive and false negative rates, while minimizing the processing delay and overhead. Numerical results show that, our cyber defense game requires low communications overhead and low delay to achieve low false positive and false negative rates as compared to the current intrusion detection and prediction frameworks.},
  archive      = {J_TETC},
  author       = {Hichem Sedjelmaci and Imane Horiya Brahmi and Nirwan Ansari and Mubashir Husain Rehmani},
  doi          = {10.1109/TETC.2018.2890476},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {429-440},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Cyber security framework for vehicular network based on a hierarchical game},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SEMKC: Secure and efficient computation over outsourced data
encrypted under multiple keys. <em>TETC</em>, <em>9</em>(1), 414–428.
(<a href="https://doi.org/10.1109/TETC.2018.2859051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing is a popular paradigm to facilitate massive data computation and storage. The issue is challenging as data owners outsource their data after encryption to preserve privacy. In this work, we propose two efficient techniques namely SEMKC + and SEMKC* to compute remotely over encrypted data. SEMKC* can be used for execution which has more number of multiplications and fewer additions, while SEMKC + would be used for the process with more number of additions and fewer multiplications. Both the schemes facilitate to compute over the data from multiple owners encrypted with different keys, without leaking the privacy. Further, the scheme is proved to be secure on “Real world-Ideal world” paradigm. The performance comparison has been made with existing schemes and observed that our scheme requires less computation and communication in comparison to the other popular existing schemes.},
  archive      = {J_TETC},
  author       = {Sanjeet Kumar Nayak and Somanath Tripathy},
  doi          = {10.1109/TETC.2018.2859051},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {414-428},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {SEMKC: Secure and efficient computation over outsourced data encrypted under multiple keys},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive MRAM write and read with MTJ variation monitor.
<em>TETC</em>, <em>9</em>(1), 402–413. (<a
href="https://doi.org/10.1109/TETC.2018.2866289">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temperature and wafer-level process variations significantly degrade operation efficiency of Spin-transfer torque random access memory (STT-MRAM) and magnetoelectric random access memory (MeRAM), where the write and read reliability issues are exacerbated by the variations. We propose adaptive write and read schemes for highly efficient STT-MRAM and MeRAM programming and sensing that optimally selects write and read pulses to overcome process and temperature variation. With adaptive write, the write latency of STT-MRAM and MeRAM cache are reduced by up to 17 and 59 percent respectively, and application run time is improved by up to 41 percent. With adaptive read, the sensing margin is dramatically improved by 1.4X while maintaining read disturbance correctable by error-correcting-code (ECC) correction. To further mitigate read disturbance impact on memory system, additional adaptive read scheme can dynamically lower read voltage according to the proposed monitor result. It can extend memory service time by haft to one year, and reduce read disturbance induced memory failure by 59 to 84 percent. To better support these schemes, we also propose, design, and evaluate low-cost MTJ-based variation monitor, which precisely senses process and temperature variation. The monitor is over 10X faster, 5X more energy-efficient, and 20X smaller compared with conventional thermal monitors of similar accuracy.},
  archive      = {J_TETC},
  author       = {Shaodi Wang and HOCHUL LEE and Cecile Grezes and Pedram Khalili Amiri and Kang L. Wang and Puneet Gupta},
  doi          = {10.1109/TETC.2018.2866289},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {402-413},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Adaptive MRAM write and read with MTJ variation monitor},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sway: Traffic-aware QoS routing in software-defined IoT.
<em>TETC</em>, <em>9</em>(1), 390–401. (<a
href="https://doi.org/10.1109/TETC.2018.2847296">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a traffic-aware quality-of-service (QoS) routing scheme in software-defined internet of things (SDIoT) network. The proposed scheme exploits the unique features of software-defined networking (SDN), such as flow-based nature, and network flexibility, in order to fulfill QoS requirements of each flow in the network. We consider two types of QoS routing strategies-delay-sensitive and loss-sensitive-for incoming packets from end-devices in the network. The former is devised to deal with delay-sensitive flows, and the latter deals with loss-sensitive flows, in order to maximize the overall network performance. We propose a greedy approach based on Yen&#39;s K-shortest paths algorithm to compute the optimal forwarding path, while considering the QoS requirements of each packet. Consequently, the SDN controller deploys adequate flow-rules at the forwarding devices in the network. Extensive simulation results show that the proposed scheme significantly reduces the end-to-end delay and the percentage of flows which violate QoS constraints compared to the benchmarks considered in the study. It is also observed that the proposed scheme adequately satisfies the QoS requirements for both type of flows in contrast to the existing schemes. In particular, with 2000 flows in the network, the proposed scheme achieves 13%, 14% and 15% (with AttMpls topology) and 38%, 37% and 39% (with Goodnet topology) reduction in QoS violated flows as compared to the existing LARAC, SPD, and MRC schemes, respectively.},
  archive      = {J_TETC},
  author       = {Niloy Saha and SAMARESH BERA and Sudip Misra},
  doi          = {10.1109/TETC.2018.2847296},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {390-401},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Sway: Traffic-aware QoS routing in software-defined IoT},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-rate programmable equalizer for m-PHY serial
interface. <em>TETC</em>, <em>9</em>(1), 379–389. (<a
href="https://doi.org/10.1109/TETC.2019.2893735">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A programmable continuous-time linear equalizer (CTLE) for multi-rate high speed serial interfaces (HSSI) is proposed in this paper. Our solution is compliant with the multi-data rates of 1.45, 2.9, 5.8 and 11.6 Gbps specified by the M-PHY rev.4 HSSI standard for mobile applications. The specifications of the input short-term total jitter STTJ are analyzed demystifying the M-PHY standard. A STTJ generator which is implemented using the behavioral description language cadence verilog-A, is also proposed in order to optimize the CTLE operation and to improve the simulation time for jitter tolerance testing. The transfer function and the power consumption are programmable according to the data-rate and to the frequency band of the STDJ. The CTLE topology was designed and simulated in TSMC CMOS 65 nm process with 1.2 V supply voltage and dissipates 12.5 mA for 11.66 Gbps and the FoM is 0.12 pJ/bit/dB. The output deterministic jitter is around 2.5 ps for 11.66 Gbps.},
  archive      = {J_TETC},
  author       = {ANDREAS TSIMPOS and ANDREAS CHRISTOS DEMARTINOS and Spyridon Vlassis and George Souliotis},
  doi          = {10.1109/TETC.2019.2893735},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {379-389},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Multi-rate programmable equalizer for M-PHY serial interface},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Understanding the inter-domain presence of research topics
in the computing discipline. <em>TETC</em>, <em>9</em>(1), 366–378. (<a
href="https://doi.org/10.1109/TETC.2018.2869556">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The very nature of scientific inquiry encourages the flow of ideas across research domains in a discipline. Research topics with higher inter-domain presence tend to attract higher attention at individual and organizational levels. This is more pronounced in a discipline like computing, with its deeply intertwined ideas and strong connections with technology. In this paper, we study corpora of research publications across four domains of the computing discipline - covering more than 150,000 papers, involving more than 200,000 authors over 55 years and 175 publication venues - to examine the influences on inter-domain presence of research topics. We find statistically significant evidence that higher collective eminence of researchers publishing on a topic is related to lower inter-domain presence of that topic, fewer authors publishing on a topic relate to the topic being likely to have higher inter-domain presence, while topics belonging to more close-knit clusters of topics are likely to have lower inter-domain presence. Our results can inform decisions around defining and sustaining research agendas and offer insights on the progression of the computing discipline.},
  archive      = {J_TETC},
  author       = {Subhajit Datta and Rumana Lakdawala and Santonu Sarkar},
  doi          = {10.1109/TETC.2018.2869556},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {366-378},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Understanding the inter-domain presence of research topics in the computing discipline},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distributed relationship mining over big scholar data.
<em>TETC</em>, <em>9</em>(1), 354–365. (<a
href="https://doi.org/10.1109/TETC.2018.2829772">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a system infrastructure to construct the big scholar data as a large knowledge graph, discover the meta paths between the entities and calculate the relevancy between entities in the graph. The core infrastructure is established on the secured and private Amazon Elastic Compute Cloud(Amazon EC2) platform. The infrastructure maintains the data evenly across the repositories, processes the data parallel by utilizing open source Spark framework, manages computing resources optimally by utilizing YARN and Hadoop HDFS, and discovers the relationship distributedly between different types of entities. We incorporate four relationship discovery tasks including citation recommendation, potential collaborator discovery, similar venue measurement and paper to venue recommendation on top of this infrastructure. For relationship mining tasks, we propose a mixed and weighted meta path (MWMP) method to explore the potential relationship between different types of entities. To verify the accuracy and measure parallelization speedup of our algorithm, we set up clusters through Amazon EC2 platform.},
  archive      = {J_TETC},
  author       = {Da Zhang and Mansur R. Kabuka},
  doi          = {10.1109/TETC.2018.2829772},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {354-365},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Distributed relationship mining over big scholar data},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SARVE-2: Exploiting social venue recommendation in the
context of smart conferences. <em>TETC</em>, <em>9</em>(1), 342–353. (<a
href="https://doi.org/10.1109/TETC.2018.2854718">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Globally, the superfluity of scholarly research conferences in varying disciplines has introduced the issue of scholarly big data and information overload related to both research papers and conference proceedings/sessions. This evident scholarly expansion in different disciplines has increased the collaborative importance of conferences. Consequently, the problem regarding attendees selecting the right conference session(s) to attend in academic conferences requires further and urgent attention. Using a smart conference scenario, this paper aims to address the problem above by proposing an improved venue recommender algorithm called Socially-Aware Recommendation of Venues and Environments-2 (SARVE-2). Using a closeness centrality approach, SARVE-2 initially employs Breadth First Search (BFS) and Depth First Search (DFS) strategies to search for relevant presenters for a target attendee. Then, the tie strength of the (searched) presenter and target attendee is computed to generate reliable social (conference session) recommendations for the target attendee. Through the utilization of a relevant (real-world) dataset, our benchmark experiments reveal that, in comparison with other contemporary methods, SARVE-2 exhibits better performance in terms of effective social recommendation search, as well as social recommendation quality, coverage and accuracy.},
  archive      = {J_TETC},
  author       = {Nana Yaw Asabere and Bo Xu and Amevi Acakpovi and Nakema Deonauth},
  doi          = {10.1109/TETC.2018.2854718},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {342-353},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {SARVE-2: Exploiting social venue recommendation in the context of smart conferences},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Additional reviewer assignment by means of weighted
association rules. <em>TETC</em>, <em>9</em>(1), 329–341. (<a
href="https://doi.org/10.1109/TETC.2018.2861214">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The assessment of the academic papers submitted to scientific journals and conferences is mostly based on peer reviewing. The reviewers assigned to each paper are usually shortlisted from a program committee by matching paper topics with reviewers&#39; expertise. However, reviewer assignments often need to be reconsidered at a later time, because reviewers can be temporarily unavailable or some of the assignments turn out to be critical due to the presence of conflicts. Therefore, there is a need for automated tools that support experts in seeking additional reviewers external to the program committee. In this paper, we propose an association rule-based methodology to recommend additional external reviewers. Weighted Association Rules (WARs), which represent strong associations between paper co-authors, are first extracted from a benchmark publication dataset. Then, they are exploited to discover potential conflicts of interest between co-reviewers as well as between reviewers and authors. Finally, reviewer assignments for papers with conflicts or with low-quality assignments are reconsidered. To tackle this issue, a subset of selected WARs provide promptly usable additional reviewer recommendations, as they highlight external experts who have profitably collaborated with the shortlisted reviewers. The effectiveness of the proposed methodology were validated on both journal and conference datasets.},
  archive      = {J_TETC},
  author       = {Luca Cagliero and Paolo Garza and Andrea Pasini and Elena Baralis},
  doi          = {10.1109/TETC.2018.2861214},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {329-341},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Additional reviewer assignment by means of weighted association rules},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). BD2K training coordinating center’s ERuDIte: The educational
resource discovery index for data science. <em>TETC</em>, <em>9</em>(1),
316–328. (<a href="https://doi.org/10.1109/TETC.2019.2903466">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data science is a field that has developed to enable efficient integration and analysis of increasingly large data sets in many domains. In particular, big data in genetics, neuroimaging, mobile health, and other subfields of biomedical science, promises new insights, but also poses challenges. To address these challenges, the National Institutes of Health launched the Big Data to Knowledge (BD2K) initiative, including a Training Coordinating Center (TCC) tasked with developing a resource for personalized data science training for biomedical researchers. The BD2K TCC web portal is powered by ERuDIte, the Educational Resource Discovery Index, which collects training resources for data science, including online courses, videos of tutorials and research talks, textbooks, and other web-based materials. While the availability of so many potential learning resources is exciting, they are highly heterogeneous in quality, difficulty, format, and topic, making the field intimidating to enter and difficult to navigate. Moreover, data science is rapidly evolving, so there is a constant influx of new materials and concepts. We leverage data science techniques to build ERuDIte itself, using data extraction, data integration, machine learning, information retrieval, and natural language processing to automatically collect, integrate, describe, and organize existing online resources for learning data science.},
  archive      = {J_TETC},
  author       = {JosÉ Luis Ambite and Lily Fierro and Jonathan Gordon and Gully A. P. C. Burns and Florian Geigl and Kristina Lerman and John D. Van Horn},
  doi          = {10.1109/TETC.2019.2903466},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {316-328},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {BD2K training coordinating center&#39;s ERuDIte: The educational resource discovery index for data science},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). FacetsBase: A key-value store optimized for querying on
scholarly data. <em>TETC</em>, <em>9</em>(1), 302–315. (<a
href="https://doi.org/10.1109/TETC.2018.2844313">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an emerging topic, scholarly big data is the vast quantity of research output that requires sophisticated platforms and tools for creating applications that can benefit the research community. This paper addresses the applied research in storing, indexing, and querying scholarly big data. The relational databases, which employ a pre-defined and well-partitioned data model are not flexible, while the NoSQL databases lack sophisticated index and partition mechanisms. The proposed FacetsBase, which is a Hadoop-based key-value data store, combines the performance advantages of a relational database, the flexibility of a NoSQL database and the parallelism of a distributed file system. It partitions and indexes the publication information using the concept of facets, it stores facetsin a multi-dimensional logical data model and lower-cost file format, and it provides the attribute-specified query and attribute-unspecific query. In experiments, FacetsBase was compared with Hive, HBase, MongoDB, and Cassandra in terms of query performance. The results indicate that FacetsBase performs 1.4x, 3.8x, 1.4x, and 2.9x faster on average, respectively.},
  archive      = {J_TETC},
  author       = {Jie Song and Yuanguo Bi and Guangjie Han and Tiantian Li},
  doi          = {10.1109/TETC.2018.2844313},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {302-315},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {FacetsBase: A key-value store optimized for querying on scholarly data},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fitness and research complexity among research-active
universities in the world. <em>TETC</em>, <em>9</em>(1), 293–301. (<a
href="https://doi.org/10.1109/TETC.2018.2854266">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In addition to knowledge transfer through higher education, universities play an important role in exploring new concepts and innovation by research. While most research-active universities cover a wide range of academic disciplines, strategic research prioritisation becomes an important task of senior management and research leaders. This paper investigates research-active institutes in the world according to the Academic Ranking of World Universities. Revealed symmetric comparative advantage analysis is applied on the research publications extracted from the Microsoft Academic Graph data set, and the correlations between research institutes and research fields are analysed. This paper also investigates the fitness of research institutes and analyses the nicheness of research disciplines. The relationship between opportunity value, research complexity index and the fitness level are explored.},
  archive      = {J_TETC},
  author       = {Ivan Lee and Yun Tie},
  doi          = {10.1109/TETC.2018.2854266},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {293-301},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Fitness and research complexity among research-active universities in the world},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multilevel graph-based decision making in big scholarly
data: An approach to identify expert reviewer, finding quality impact
factor, ranking journals and researchers. <em>TETC</em>, <em>9</em>(1),
280–292. (<a href="https://doi.org/10.1109/TETC.2018.2869458">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital libraries, such as conference papers, journal documents, books and thesis, research patents, and experiments generate a vast amount of data, named as, Scholarly Big Data. It covers scholarly related information for both researcher&#39;s perspective as well as publisher&#39;s perspective, such as academic activities, author&#39;s demography, academic social networks, etc. The relationships among Big Scholarly Data can be worthy of solving researcher as well as journal related concerns, if they are prudently treated to extract knowledge. The best approach to efficiently process these relationships is the graph. However, with the rapid growth in the number of digital articles by various libraries, the relationships raise exponentially, generating large graphs, which have become increasingly challenging to be handled in order to analyze scholarly information. On the other hand, many researchers and publishers/journals have severe concerns about the ranking control mechanisms and the consideration of quantity rather than quality. Therefore, in this paper, we proposed graph-based mechanisms to perform four critical decisions that are the need of the today&#39;s scholarly community. To improve the quality of the article, we proposed a mechanism for selecting and recommending suitable reviewers for a submitted paper based on researchers&#39; expertise and their popularity in that particular field while avoiding conflict of interest. Also, due to shortcomings in the existing journal ranking approaches, we also designed a journal ranking mechanism including its new impact factor and relative ranking by using a modified version of traditional page ranking algorithm and excluding self-authors citations as well as self-journal citations. Similarly, researchers ranking is also important for various motives that is calculated based on the expert&#39;s field, citation count, and a number of publications while avoiding any loophole to increase the ranking such as, self-citations and wrong citations. Also, to efficiently process big graphs generated by a massive number of scholarly related relationships, we proposed an architecture that uses the parallel processing mechanism of the Hadoop ecosystem over the real-time analysis approach of Apache Spark with GraphX. Finally, the efficiency of the proposed system is evaluated in terms of processing time and throughput while implementing the designed decision mechanisms.},
  archive      = {J_TETC},
  author       = {Muhammad Mazhar Ullah Rathore and Malik Junaid Jami Gul and Anand Paul and Ashraf Ali Khan and Raja Wasim Ahmad and Joel J. P. C. Rodrigues and Spiridon Bakiras},
  doi          = {10.1109/TETC.2018.2869458},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {280-292},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Multilevel graph-based decision making in big scholarly data: An approach to identify expert reviewer, finding quality impact factor, ranking journals and researchers},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the expressive power of scientific manuscripts.
<em>TETC</em>, <em>9</em>(1), 269–279. (<a
href="https://doi.org/10.1109/TETC.2018.2870179">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Every research manuscript is appreciated in the form of citations. Citations are expected to carry the essence of the underlying base paper by some rhetorical means. However, this is not true in reality. Citation manipulations are equally possible which shall be identified using research semantics. This paper discusses machine learning based approaches for analyzing research citations with the aim of finding quality research citations. On analyzing the semantics of the research manuscript and the respective citations, this paper proposes various metrics for citation quality analysis including deep cite, raw expressive power, expressive power and normalized expressive power.},
  archive      = {J_TETC},
  author       = {G. S. MAHALAKSHMI and R. SIVA and S. SENDHILKUMAR},
  doi          = {10.1109/TETC.2018.2870179},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {269-279},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {On the expressive power of scientific manuscripts},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A population model for academia: Case study of the computer
science community using DBLP bibliography 1960-2016. <em>TETC</em>,
<em>9</em>(1), 258–268. (<a
href="https://doi.org/10.1109/TETC.2018.2855156">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The academic community has seen a tremendous growth in number of authors and publications in recent times. Most previous studies of the academic community, whether on individual activity, productivity and influence, or collaboration patterns and their implications, have been based on a flat and static view of the system. However, the academic community resembles a dynamic growing population, with entry and exit of authors. In this paper, we study this systemic inflation by proposing a population model for academia. We use a generalized branching process as an overarching framework, which enables us to describe the research community from an evolutionary and structural perspective. Further, the observed patterns allow us to shed light on researchers&#39; life-cycle encompassing their arrival, academic life expectancy, activity, productivity and offspring distribution in the community. In our study, we used data from DBLP for a case study in the computer science community, although our methodology can be adopted in a systematic manner to any other research domain with sufficient publication records. We believe that the results can help academics and policy makers alike to better understand and evaluate the development and evolution of their respective academic communities.},
  archive      = {J_TETC},
  author       = {Yan Wu and Srinivasan Venkatramanan and Dah Ming Chiu},
  doi          = {10.1109/TETC.2018.2855156},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {258-268},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {A population model for academia: Case study of the computer science community using DBLP bibliography 1960-2016},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Academic influence aware and multidimensional network
analysis for research collaboration navigation based on scholarly big
data. <em>TETC</em>, <em>9</em>(1), 246–257. (<a
href="https://doi.org/10.1109/TETC.2018.2860051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scholarly big data, which is a large-scale collection of academic information, technical data, and collaboration relationships, has attracted increasing attentions, ranging from industries to academic communities. The widespread adoption of social computing paradigm has made it easier for researchers to join collaborative research activities and share academic data more extensively than ever before across the highly interlaced academic networks. In this study, we focus on the academic influence aware and multidimensional network analysis based on the integration of multi-source scholarly big data. Following three basic relations: Researcher-Researcher, Researcher-Article, and Article-Article, a set of measures is introduced and defined to quantify correlations in terms of activity-based collaboration relationship, specialty-aware connection, and topic-aware citation fitness among a series of academic entities (e.g., researchers and articles) within a constructed multidimensional network model. An improved Random Walk with Restart (RWR) based algorithm is developed, in which the time-varying academic influence is newly defined and measured in a certain social context, to provide researchers with research collaboration navigation for their future works. Experiments and evaluations are conducted to demonstrate the practicability and usefulness of our proposed method in scholarly big data analysis using DBLP and ResearchGate data.},
  archive      = {J_TETC},
  author       = {Xiaokang Zhou and Wei Liang and Kevin I-Kai Wang and Runhe Huang and Qun Jin},
  doi          = {10.1109/TETC.2018.2860051},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {246-257},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Academic influence aware and multidimensional network analysis for research collaboration navigation based on scholarly big data},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Will your paper get promoted by a citation? A case study of
citation promoter in computer science discipline. <em>TETC</em>,
<em>9</em>(1), 238–245. (<a
href="https://doi.org/10.1109/TETC.2018.2861321">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reseachers have investigated numerous factors influencing citation counts of cited papers. One factor investigated has been the number of gained citations, as this could increase the visibility of cited papers and subsequently induce further citations. In this paper, aiming to identify a particular kind of citation that could trigger a rapid growth in the citation counts of cited papers, a concept of “citation promoter” was proposed. We defined citation promoters based on the annual citation rates of the cited papers and the co-citation counts received by the pair of cited and citing papers. The comparative results showed that papers would obtain a sharp rise in citation counts shortly after they were cited by citation promoters. Papers that received citation promoters at an early age outperformed other papers in long-term citation counts. In addition, we developed a classification model for predicting whether a citing paper would be a citation promoter for its cited paper. Since it was a class imbalanced problem (4 percent positive instances), and there was a lack of content and author features in our dataset, our preliminary models achieved moderate performance with an F 1 score slightly higher than 0.5, while the F 1 score obtained by random guessing was 0.07.},
  archive      = {J_TETC},
  author       = {Feiheng Luo and Aixin Sun and Aravind Sesagiri Raamkumar and Mojisola Erdt and Yin-Leng Theng},
  doi          = {10.1109/TETC.2018.2861321},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {238-245},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Will your paper get promoted by a citation? a case study of citation promoter in computer science discipline},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). VOPRec: Vector representation learning of papers with text
information and structural identity for recommendation. <em>TETC</em>,
<em>9</em>(1), 226–237. (<a
href="https://doi.org/10.1109/TETC.2018.2830698">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding relevant papers is a non-trivial problem for scholars due to the tremendous amount of academic information in the era of scholarly big data. Scientific paper recommendation systems have been developed to solve such problem by recommending relevant papers to scholars. However, previous paper recommendations calculate paper similarity based on hand-engineered features which are inflexible. To address this problem, we develop a scientific paper recommendation system, namely VOPRec, by vector representation learning of paper in citation networks. VOPRec takes advantages of recent research in both text and network representation learning for unsupervised feature design. In VOPRec, the text information is represented with word embedding to find papers of similar research interest. Then, the structural identity is converted into vectors to find papers of similar network topology. After bridging text information and structural identity with the citation network, vector representation of paper can be learned with network embedding. Finally, top- &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$Q$&lt;/tex-math&gt;&lt;/inline-formula&gt; recommendation list is generated based on the similarity calculated with paper vectors. Through the APS data set, we show that VOPRec outperforms state-of-the-art paper recommendation baselines measured by precision, recall, F1, and NDCG.},
  archive      = {J_TETC},
  author       = {Xiangjie Kong and Mengyi Mao and Wei Wang and Jiaying Liu and Bo Xu},
  doi          = {10.1109/TETC.2018.2830698},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {226-237},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {VOPRec: Vector representation learning of papers with text information and structural identity for recommendation},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A searchable and verifiable data protection scheme for
scholarly big data. <em>TETC</em>, <em>9</em>(1), 216–225. (<a
href="https://doi.org/10.1109/TETC.2018.2830368">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scientific research achievements play a positive role in the promotion of social development. Scholarly big data include scholars&#39; scientific research, experimental data, and their own identity information. The security of scholarly big data relates to the authors&#39; reputation and the copyright of their works. This paper proposes a trusted third-party-aided searchable and verifiable data protection scheme that utilizes cloud computing technology. For a better description of the the protocol, we first present a user-differentiated system model and a cube data storage structure. On the basis of the novel system model and data structure, the scheme helps the users review the integrity of their uploaded or downloaded data at any time and search the online scholarly data with encrypted keywords. The security analysis and performance simulation demonstrate that the novel scheme is a secure and efficient scheme for scholarly big data applications.},
  archive      = {J_TETC},
  author       = {Jian Shen and Chen Wang and Anxi Wang and Sai Ji and Yan Zhang},
  doi          = {10.1109/TETC.2018.2830368},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {216-225},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {A searchable and verifiable data protection scheme for scholarly big data},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Forming dream teams: A chemistry-oriented approach in social
networks. <em>TETC</em>, <em>9</em>(1), 204–215. (<a
href="https://doi.org/10.1109/TETC.2018.2869377">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scientific collaboration networks are social networks in which vertices represent scientists and edges typically represent co-authorship. Such networks not only permit research into understanding the characteristics of scientific collaboration, but can also provide a basis for building collaborative research platforms to support research groups with functionality such as, information sharing, data repositories, and communication. Collaboration networks are highly clustered, mapping closely to the real world relationships of individual researchers. However, just as big data constitute a well recognised disruptive change to the way basic research is carried out in many fields, there is an equivalent and largely unexplored change in the collaborative relationships between researchers - which are becoming not only larger in scale, but also more distributed and interdisciplinary. One element in this, which we suggest will play a pivotal role in the future, is the formation of teams for big data projects. This paper presents an innovative algorithm for expert team formation called Chemistry Oriented Team Formation (ChemoTF) based on two new metrics; Chemistry Level and Expertise Level. Chemistry Level measures scale of communication required by the task, while Expertise Level measures the overall expertise among potential teams filtered by Chemistry Level. This approach is tested using a large scholarly corpus containing 472,365 individual authors. The ChemoTF algorithm is able to build teams for median average 90 percent of the expected cost, achieving a 99 percent fit while remaining tractable for teams up to 16 individuals - resulting in the formation of more communicative and cost effective teams with higher expertise level.},
  archive      = {J_TETC},
  author       = {Yashar Najaflou and Kris Bubendorfer},
  doi          = {10.1109/TETC.2018.2869377},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {204-215},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Forming dream teams: A chemistry-oriented approach in social networks},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Guest editorial: Scholarly big data. <em>TETC</em>,
<em>9</em>(1), 200–203. (<a
href="https://doi.org/10.1109/TETC.2021.3059329">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The papers in this special section focus on Big Data as it applies to scholarly information - or scholarly Big Data. This represents the vast quantity of research output, which can be acquired from digital libraries, such as journal articles, conference proceedings, theses, books, patents, experimental data, etc. It also encompasses various scholarly related data, such as author demography, academic social networks, and academic activities. The abundance of scholarly data enables the study of the academic society from a big data perspective. The dynamic and diverse nature of scholarly big data requires different data management techniques and advanced data analysis methods. Therefore, emerging topics such as scholarly big data acquisition, storage, management and processing are important issues for the research community.},
  archive      = {J_TETC},
  author       = {Feng Xia and C. Lee Giles and Huan Liu and Kuansan Wang},
  doi          = {10.1109/TETC.2021.3059329},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {200-203},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Guest editorial: Scholarly big data},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An eParticipation acceptance model. <em>TETC</em>,
<em>9</em>(1), 188–199. (<a
href="https://doi.org/10.1109/TETC.2018.2861426">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the factors influencing user acceptance of eParticipation systems drawing experience not only from previous eParticipation research but also from the Information Systems domain. Subsequently, a model for eParticipation acceptance is constructed by integrating the concepts from TAM literature and eParticipation evaluation literature. The model is validated through statistical analysis and hypothesis testing based on the findings of a multi-national user survey (gathering 299 reliable responses through a structured online questionnaire) and findings are discussed. Finally, a revised model is proposed called ePAM, including TAM&#39;s main concepts of Perceived Usefulness, Perceived Ease of Use, and Behavioural Intention to Use, and the four additional concepts of Technological Confidence, Integration to Governmental Processes, Perceived Facilitating Conditions and Social Influences.},
  archive      = {J_TETC},
  author       = {Eleni Panopoulou and Efthimios Tambouris and Konstantinos Tarabanis},
  doi          = {10.1109/TETC.2018.2861426},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {188-199},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {An eParticipation acceptance model},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Combining technocrats’ expertise with public opinion through
an innovative e-participation platform. <em>TETC</em>, <em>9</em>(1),
174–187. (<a href="https://doi.org/10.1109/TETC.2018.2824022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous political sciences research has revealed that democracy (democratic institutions, consultations with citizens) and technocracy (specialized knowledge of experts) are the main foundations for the development of effective and socially acceptable public policies, and that there should be balance as well as interaction and exchange of knowledge between them. However, there is a lack of e-participation platforms supporting this required `duality&#39;: the collection of policy related information, knowledge and opinions from both citizens and experts, as well as the communication and interaction between them. This paper contributes to filling this critical research gap. It describes the development of an innovative e-participation platform, which supports on one hand structured consultation and argumentation between experts/technocrats concerning important social problems and public policies for addressing them, and on the other hand the collection and interrelation of relevant citizens-generated textual content from numerous external social media. This platform enables the meaningful combination of technocrats&#39; expertise with public opinion, allowing the technocrats participating in policy related structured consultations to retrieve, understand and get insights from citizens&#39; perceptions. Evaluation results show that users appreciate the potential of exploiting the synergy of machine and human reasoning enabled by the proposed platform through a combination of data mining and structured consultation/argumentation - collaborative decision-making services.},
  archive      = {J_TETC},
  author       = {Aggeliki S. Androutsopoulou and Nikos I. Karacapilidis and Euripidis N. Loukis and Yannis K. Charalabidis},
  doi          = {10.1109/TETC.2018.2824022},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {174-187},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Combining technocrats’ expertise with public opinion through an innovative e-participation platform},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). E-voting system evaluation based on the council of europe
recommendations: Helios voting. <em>TETC</em>, <em>9</em>(1), 161–173.
(<a href="https://doi.org/10.1109/TETC.2018.2881891">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the claimed benefits of e-voting initiatives, wider adoption of e-voting mechanisms and implementation processes is slower than expected. Several technical, social, and cultural challenges hinder generability and applicability of e-voting. Amongst them, the evaluation and harmonization of e-voting systems, given different legal and statutory frameworks, is still an important challenge to overcome. Yet, only a few works have addressed this topic in the field. This article aims to contribute to further understanding this unexplored topic by applying a practical evaluation framework to Helios Voting, one of the most widely used e-voting tools to date. Our framework, strongly based on the technical and security requirements issued by the Council of Europe in 2017, is a valuable source of information for election officials, researchers and voters to understand the strengths and weaknesses of Helios Voting and, as a result, to improve decision-making processes regarding the type and size of elections that can be securely handled by Helios Voting. The ultimate goal of our paper is to conceptually and practically support the gradual, secure and protocolized expansion of e-voting.},
  archive      = {J_TETC},
  author       = {LUIS PANIZO ALONSO and MILA GASCÓ and DAVID Y. MARCOS del BLANCO and José Á. Hermida Alonso and Jordi Barrat and Héctor Aláiz Moreton},
  doi          = {10.1109/TETC.2018.2881891},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {161-173},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {E-voting system evaluation based on the council of europe recommendations: Helios voting},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Documenting context-based quality assessment of controlled
vocabularies. <em>TETC</em>, <em>9</em>(1), 144–160. (<a
href="https://doi.org/10.1109/TETC.2018.2865094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Access to e-Government data is challenging due to the heterogeneity and complexity of the public information ecosystem. Controlled Vocabularies (CVs) provide a key to disclosing the potential of Open Government data, by supplying common terms for marking up metadata and data in a consistent and coherent way. However, quality information is needed to help public institutions decide whether to adopt an existing or newly created CV. The paper discusses how to evaluate and document CV quality thus facilitating a comparison of different controlled vocabularies based on contextual information. The Analytical Hierarchy Process (AHP) is adopted to assess the overall quality and rank of a controlled vocabulary, by integrating various quality dimensions according to the decision maker&#39;s needs. A set of e-Government controlled vocabularies that facilitate the semantic interoperability of e-Government data are selected as a testbed, and updated quality values are made available as Linked Data. Multi-step guidelines are also defined promoting and complementing the adoption of W3C recommendations to provide machine-readable quality metadata. This fosters reliability and re-usability by providing consumers with information on the assessment process carried out and the outcomes achieved. We illustrate the application of these guidelines by focusing on provenance and quality documentation.},
  archive      = {J_TETC},
  author       = {Riccardo Albertoni and Monica De Martino and Alfonso Quarati},
  doi          = {10.1109/TETC.2018.2865094},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {144-160},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Documenting context-based quality assessment of controlled vocabularies},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Framework for prioritization of open data publication: An
application to smart cities. <em>TETC</em>, <em>9</em>(1), 131–143. (<a
href="https://doi.org/10.1109/TETC.2019.2893016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Public Sector Information is considered to play a fundamental role in the growth of the knowledge economy and improvements in society. Given the difficulty in publishing and maintaining all available data, due to budget constraints, institutions need to select which data to publish, giving priority to data most likely to generate social and economic impact. Priority of publication could become an even more significant problem in Smart Cities: as huge amounts of information are generated from different domains, the way data is prioritized and thus reused, could be a determining factor in promoting, among others, new and sustainable business opportunities for local entrepreneurs, and to improve citizen quality of life. However, people in charge of prioritizing which data to publish through open data portals (such as Chief Data Officers, or CDOs) do not have available any specific support in their decision-making process. In this work, a proposal of a framework for prioritization of open data publication as well as its application to Smart Cities is presented. This specific application of the framework relies on OSS (Open Source Software) indicators to help making decisions on the most relevant data to publish focused on developers and businesses operating within the Smart City context.},
  archive      = {J_TETC},
  author       = {ALVARO E. PRIETO and Jose-Norberto Mazón and Adolfo Lozano-Tello},
  doi          = {10.1109/TETC.2019.2893016},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {131-143},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Framework for prioritization of open data publication: An application to smart cities},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Comparative analysis of metadata models on e-government open
data platforms. <em>TETC</em>, <em>9</em>(1), 119–130. (<a
href="https://doi.org/10.1109/TETC.2018.2815591">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {E-government open data platforms use metadata to provide an adequate environment for the consumption of data released on these platforms. Metadata enable the machine processing of information in a structured manner. Given that it reveals details and context about data, metadata allow interpretation in unique way and offer semantics for open government data. This paper presents an overview and analysis of four metadata models used in contemporary e-government open data platforms. We illustrate the strengths and limitations of these models through aspects and principles of open data defined in the paper by proposing metadata quality assessment model. Moreover, we examine how metadata structure is oriented toward the provision of valuable information assets needed for the utilization of open government data. Finally, we give an overview of available API support on the selected open data platforms for the provision and reuse of open data. The research results indicate that more attention should be paid to metadata to uncover relationships between datasets.},
  archive      = {J_TETC},
  author       = {Petar MiliĆ and NataŠa VeljkoviĆ and Leonid Stoimenov},
  doi          = {10.1109/TETC.2018.2815591},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {119-130},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Comparative analysis of metadata models on e-government open data platforms},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Guest editorial: Special issue on eGovernment development
and applications (SIEGDA). <em>TETC</em>, <em>9</em>(1), 117–118. (<a
href="https://doi.org/10.1109/TETC.2021.3057776">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The articles in this special section focus on electronic government development and applications. An information and knowledge society creates its value by gathering, processing, evaluating, and sharing digital products and services. However, no citizens can be left behind in introducing Web-based technologies to the administration, as this creates a digital divide. Representatives of the governments, international organizations, and universities should develop a vision for eDemocracy and eGovernment. eDemocracy defines the support and enhancement of civil rights and duties in the information and knowledge society. Options for participation allow citizens to strengthen an open society. One option involves the inclusion of the citizens even in the early stages of the planning; improved information and discussion forums; barrier-free Web access in electronic votes and elections; and communities’ formation in different public sectors.},
  archive      = {J_TETC},
  author       = {Andreas Meier and Luis Terán},
  doi          = {10.1109/TETC.2021.3057776},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {117-118},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Guest editorial: Special issue on eGovernment development and applications (SIEGDA)},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Surrogate applications for early design stage multicore
contention modeling. <em>TETC</em>, <em>9</em>(1), 109–116. (<a
href="https://doi.org/10.1109/TETC.2018.2852760">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Properly allocating time budgets to applications during system&#39;s early design phases (EDP) prevents costly-to-handle time overruns in late design phases (LDP). Applications running in a multicore affect each other&#39;s behavior, which complicates reaching this goal. Further, in multi-provider software developments, software providers are reluctant to share their applications for IP reasons. Both factors prevent deriving tight bounds until LDP when applications are actually integrated. In this paper we propose a modeling approach, which we tailor for a processor in the space domain, that simplifies time budgeting in EDP by developing surrogate applications (SurApps) and an automatic framework to generate them. A SurApp copies the non-functional behavior of a given target application automatically. Each software provider generates, for an application AppA, a surrogate application SurAppA and gives it to other providers without the risk of revealing any IP. By running their applications against the SurAppA, other providers obtain a tight estimate of the slowdown their applications will suffer when run against AppA.},
  archive      = {J_TETC},
  author       = {Gabriel Fernandez and Jaume Abella and Guillem Bernat and Francisco J. Cazorla},
  doi          = {10.1109/TETC.2018.2852760},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {109-116},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Surrogate applications for early design stage multicore contention modeling},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). First tests of a new facility for device-level, board-level
and system-level neutron irradiation of microelectronics. <em>TETC</em>,
<em>9</em>(1), 104–108. (<a
href="https://doi.org/10.1109/TETC.2018.2879027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The very limited availability of fast neutron facilities, particularly in Europe, for testing of microelectronics has motivated the construction of ChipIr, a new beamline at the ISIS neutron and muon source in the UK. ChipIr has been designed for Single Event Effect testing at the device-level, board-level and system-level which requires a beam of uniform intensity over a selectable area in the order of hundreds of cm 2 . Measurements of the beam uniformity are presented in this paper. A memory chip of interest for space applications, based on SRAMs and developed by ESA for monitoring of radiation fields, has been used for a comparative characterization of the beam. Consistent results have been found, giving confidence on the intensity and shape of the fast neutron spectrum of ChipIr.},
  archive      = {J_TETC},
  author       = {Carlo Cazzaniga and Marta Bagatin and Simone Gerardin and ALESSANDRA COSTANTINO and CHRISTOPHER D. FROST},
  doi          = {10.1109/TETC.2018.2879027},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {104-108},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {First tests of a new facility for device-level, board-level and system-level neutron irradiation of microelectronics},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A 3.3 gbps CCSDS 123.0-b-1 multispectral &amp; hyperspectral
image compression hardware accelerator on a space-grade SRAM FPGA.
<em>TETC</em>, <em>9</em>(1), 90–103. (<a
href="https://doi.org/10.1109/TETC.2018.2854412">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The explosive growth of data volume from next generation high-resolution and high-speed hyperspectral remote sensing systems will compete with the limited on-board storage resources and bandwidth available for the transmission of data to ground stations making hyperspectral image compression a mission critical and challenging on-board payload data processing task. The Consultative Committee for Space Data Systems (CCSDS) has issued recommended standard CCSDS-123.0-B-1 for lossless multispectral and hyperspectral image compression. In this paper, a very high data-rate performance hardware accelerator is presented implementing the CCSDS-123.0-B-1 algorithm as an IP core targeting a space-grade FPGA. For the first time, the introduced architecture based on the principles of C-slow retiming, exploits the inherent task-level parallelism of the algorithm under BIP ordering and implements a reconfigurable fine-grained pipeline in critical feedback loops, achieving high throughput performance. The CCSDS-123.0-B-1 IP core achieves beyond the current state-of-the-art data-rate performance with a maximum throughput of 213 MSamples/s (3.3 Gbps @ 16-bits) using 11 percent of LUTs and 27 percent of BRAMs of the Virtex-5QV FPGA resources for a typical hyperspectral image, leveraging the full throughput of a single SpaceFibre lane. To the bes t of our knowledge, it is the fastest implementation of CCSDS-123.0-B-1 targeting a space-grade FPGA to date.},
  archive      = {J_TETC},
  author       = {Antonis Tsigkanos and Nektarios Kranitis and George Theodorou and Antonis Paschalis},
  doi          = {10.1109/TETC.2018.2854412},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {90-103},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {A 3.3 gbps CCSDS 123.0-B-1 multispectral &amp; hyperspectral image compression hardware accelerator on a space-grade SRAM FPGA},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A platform-aware model-driven embedded software engineering
process based on annotated analysis models. <em>TETC</em>,
<em>9</em>(1), 78–89. (<a
href="https://doi.org/10.1109/TETC.2018.2866024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work a platform-aware model-driven engineering process for building component-based embedded software systems using annotated analysis models is described. The process is supported by a framework, called MICOBS, that allows working with different component technologies and integrating different tools that, independently of the component technology, enable the analysis of non-functional properties based on the principles of composability and compositionality. An actor, called Framework Architect, is responsible for this integration. Three other actors take a relevant part in the analysis process. The Component Provider supplies the components, while the Component Tester is in charge of their validation. The latter also feeds MICOBS with the annotated analysis models that characterize the extra-functional properties of the components for the different platforms on which they can be deployed. The Application Architect uses these components to build new systems, performing the trade-off between different alternatives. At this stage, and in order to verify that the final system meets the extra-functional requirements, the Application Architect uses the reports generated by the integrated analysis tools. This process has been used to support the validation and verification of the on-board application software for the Instrument Control Unit of the Energetic Particle Detector of the Solar Orbiter mission.},
  archive      = {J_TETC},
  author       = {Pablo Parra and Óscar R. Polo and Javier FernÁndez and Antonio Da Silva and Sebastián Sánchez and Agustín Martínez},
  doi          = {10.1109/TETC.2018.2866024},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {78-89},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {A platform-aware model-driven embedded software engineering process based on annotated analysis models},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). CAN implementation and performance for raman laser
spectrometer (RLS) instrument on exomars 2020 mission. <em>TETC</em>,
<em>9</em>(1), 67–77. (<a
href="https://doi.org/10.1109/TETC.2018.2874643">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of CAN bus in space applications has increased during the last fifteen years. The need of standardizing not only the physical and link layers but also the higher layers protocol to meet spacecraft specific constraints or requirements, such as bus redundancy management, node monitoring and synchronization, has aroused. Therefore, a Working Group on CAN bus was stablished by ESA in collaboration with European Industry and Space Agencies, whose effort gave as result the publication of ECSS-E-ST-50-15C in 2015. This standard defines CAN protocol extensions for space use and specifies the optional use of the CANopen standard as higher layer to be used over CAN bus. The ExoMars Mission was chosen as spreadhead for the application of this standard. The present paper provides an experience report on this novel standardized use of CAN/CANopen in Space, in particular in the Raman Laser Spectrometer (RLS) that will be boarded into the Rover of ExoMars 2020. Even though RLS makes use of considerably long science telemetries (up to around 2Mbytes) CAN has been designated as its only data interface. We report on software, hardware and data transmission performances, as well as brief description on redundancy and synchronisation of this CAN implementation.},
  archive      = {J_TETC},
  author       = {Laura Seoane and Carlos Díaz and Jesús Zafra and Sergio Ibarmia and César Quintana and Carlos Pérez Canora and Andoni G. Moral and A. Araujo},
  doi          = {10.1109/TETC.2018.2874643},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {67-77},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {CAN implementation and performance for raman laser spectrometer (RLS) instrument on exomars 2020 mission},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Guest editorial: IEEE transactions on emerging topics in
computing special issue on advanced command, control and on-board data
processing for space avionic systems. <em>TETC</em>, <em>9</em>(1),
65–66. (<a href="https://doi.org/10.1109/TETC.2021.3053795">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The papers in this special issue focus on advanced command, control and on-board data processing for space avionic systems. The domain of space avionic systems is changing extremely rapidly, compared to other technical domains in the spacefaring industry, under the pressure of intense competition, the continuous emergence of new markets and players, the need for cost reduction, as well as an increased obsolescence rate of components and processes due to the relative reduction of hi-rel parts market share with respect to booming volumes of consumer electronics. The emergence of “new space” paradigm, with new (mostly private) players taking the risk of compromising with system’s dependability in favour of stripped down cost further contributes to this rapidly changing landscape: new opportunities are opening for the space avionic systems.},
  archive      = {J_TETC},
  author       = {Gianluca Furano and Marco Ottavi},
  doi          = {10.1109/TETC.2021.3053795},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {65-66},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Guest editorial: IEEE transactions on emerging topics in computing special issue on advanced command, control and on-board data processing for space avionic systems},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Trade-off between hit rate and hit latency for optimizing
DRAM cache. <em>TETC</em>, <em>9</em>(1), 55–64. (<a
href="https://doi.org/10.1109/TETC.2018.2800721">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the large storage capacity, high bandwidth and low latency, 3D DRAM is proposed to be the last level cache, referred to as DRAM cache. The hit rate and hit latency are two conflicting optimization goals for DRAM cache. To address this issue, we design a new DRAM organization that trades the lower hit rate for shorter hit latency by way-locator cache and novel cache set layout. We have designed a novel DRAM cache organization to simultaneously achieve a good hit rate and shorter latency, referred to as SODA-cache. The SODA-cache adapts 2-way set associate cache motivated by the observation that 2-way set associative cache provides the most hit rate improvement from the direct-mapped cache to highly associative cache. The proposed way-locator cache and a novel set layout effectively reduce the cache-hit latency. We use SPEC 2006 CPU benchmark to evaluate our design and two stat-of-art DRAM cache designs. Experimental results show that SODA-cache can improve hit rate by 8.1 percent compared with Alloy-cache and reduce average access latency by 23.1, 13.2 and 8.6 percent compared with LH-cache, Alloy-cache and ATCache respectively on average. Accordingly, SODA-cache outperforms over LH-cache, Alloy-cache and ATCache by on average 17, 12.8 and 8.4 percent respectively in term of weighted speedup.},
  archive      = {J_TETC},
  author       = {Pai Chen and Jianhui Yue and Xiaofei Liao and Hai Jin},
  doi          = {10.1109/TETC.2018.2800721},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {55-64},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Trade-off between hit rate and hit latency for optimizing DRAM cache},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Concurrency analysis in dynamic dataflow graphs.
<em>TETC</em>, <em>9</em>(1), 44–54. (<a
href="https://doi.org/10.1109/TETC.2018.2799078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic dataflow scheduling enables effective exploitation of concurrency while making parallel programming easier. To this end, analyzing the inherent degree of concurrency available in dataflow graphs is an important task, since it may aid compilers or programmers to assess the potential performance a program can achieve via parallel execution. However, traditional concurrency analysis techniques only work for DAGs (directed acyclic graphs), hence the need for new techniques that contemplate graphs with cycles. In this paper we present techniques to perform concurrency analysis on generic dynamic dataflow graphs, even in the presence of cycles. In a dataflow graph, nodes represent instructions and edges describe dependencies. The novelty of our approach is that we allow concurrency between different iterations of the loops. Consequently, a set of concurrent nodes may contain instructions from different loops that can be proven independent. In this work, we provide a set of theoretical tools for obtaining bounds and illustrate implementation of parallel dataflow runtime on a set of representative graphs for important classes of benchmarks to compare measured performance against derived bounds.},
  archive      = {J_TETC},
  author       = {Tiago A. O. Alves and Leandro A. J. Marzulo and Sandip Kundu and Felipe M. G. França},
  doi          = {10.1109/TETC.2018.2799078},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {44-54},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Concurrency analysis in dynamic dataflow graphs},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cluster-based heuristic for high level synthesis design
space exploration. <em>TETC</em>, <em>9</em>(1), 35–43. (<a
href="https://doi.org/10.1109/TETC.2018.2794068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High Level Synthesis (HLS) frameworks allow to describe hardware designs in a high-level language (C/C++), without burdening developers with the error-prone task of specifying their implementation in detail. The HLS process is usually controlled by user-specified directives, which influence the implementation area and latency. Nonetheless, the correlation between directives and performance is often difficult to foresee and to quantify. Addressing this challenge, we herein propose a heuristic that, by only exploring a subset of possible configurations for an HLS design, is able to retrieve a close approximation of its Pareto Frontier of non-dominated implementations. Our framework identifies regions of interest in the design space, and iteratively searches for new solutions within such regions, or in their combinations. Experimental evidence across multiple benchmarks showcases that our approach to HLS design space exploration reaches better Pareto approximations, and with less required synthesis runs, with respect to State of the Art alternatives.},
  archive      = {J_TETC},
  author       = {Lorenzo Ferretti and Giovanni Ansaloni and Laura Pozzi},
  doi          = {10.1109/TETC.2018.2794068},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {35-43},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Cluster-based heuristic for high level synthesis design space exploration},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the design of minimal-cost pipeline systems satisfying
hard/soft real-time constraints. <em>TETC</em>, <em>9</em>(1), 24–34.
(<a href="https://doi.org/10.1109/TETC.2017.2788800">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pipeline systems provide high throughput for applications by overlapping the executions of tasks. In the architectures with heterogeneity, two basic issues in the design of application-specific pipelines need to be studied: what type of functional unit to execute each task, and where to place buffers. Due to the increasing complexity of applications, pipeline designs face a bundle of problems. One of the most challenging problems is the uncertainty on the execution times, which makes the deterministic techniques inapplicable. In this paper, the execution times are modeled as random variables. Given an application, our objective is to construct the optimal pipeline, such that the total cost of the resultant pipeline can be minimized while satisfying the required timing constraints with the given guaranteed probability. We first prove the NP-hardness of the problem. Then, we present Mixed Integer Linear Programming (MILP) formulations to obtain the optimal solution. Due to the high time complexity of MILP, we devise an efficient (1+ε)-approximation algorithm, where the value of ε is less than 5 percent in practice. Experimental results show that our algorithms can achieve significant reductions in cost over the existing techniques, reaching up to 31.93 percent on average.},
  archive      = {J_TETC},
  author       = {Weiwen Jiang and Edwin Hsing-Mean Sha and Qingfeng Zhuge and Lei Yang and Hailiang Dong and Xianzhang Chen},
  doi          = {10.1109/TETC.2017.2788800},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {24-34},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {On the design of minimal-cost pipeline systems satisfying Hard/Soft real-time constraints},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). &lt;Inline-formula&gt;&lt;tex-math notation=“LaTeX”&gt;<span
class="math inline"><em>O</em>(<em>N</em>)</span>&lt;/tex-math&gt;&lt;mml:math
xmlns:mml=“http://www.w3.org/1998/math/MathML”&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;o&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;&lt;inline-graphic
xlink:href=“khodamoradi-ieq1-2788865.gif”
xmlns:xlink=“http://www.w3.org/1999/xlink”/&gt;&lt;/inline-formula&gt;-space
spatiotemporal filter for reducing noise in neuromorphic vision sensors.
<em>TETC</em>, <em>9</em>(1), 15–23. (<a
href="https://doi.org/10.1109/TETC.2017.2788865">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neuromorphic vision sensors are an emerging technology inspired by how retina processing images. A neuromorphic vision sensor only reports when a pixel value changes rather than continuously outputting the value every frame as is done in an “ordinary” Active Pixel Sensor (ASP). This move from a continuously sampled system to an asynchronous event driven one effectively allows for much faster sampling rates; it also fundamentally changes the sensor interface. In particular, these sensors are highly sensitive to noise, as any additional event reduces the bandwidth, and thus effectively lowers the sampling rate. In this work we introduce a novel spatiotemporal filter with O(N) memory complexity for reducing background activity noise in neuromorphic vision sensors. Our design consumes 10× less memory and has 100× reduction in error compared to previous designs. Our filter is also capable of recovering real events and can pass up to 180 percent more real events.},
  archive      = {J_TETC},
  author       = {Alireza Khodamoradi and Ryan Kastner},
  doi          = {10.1109/TETC.2017.2788865},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {15-23},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {&lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$O(N)$&lt;/tex-math&gt;&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;O&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href=&quot;khodamoradi-ieq1-2788865.gif&quot; xmlns:xlink=&quot;http://www.w3.org/1999/xlink&quot;/&gt;&lt;/inline-formula&gt;-space spatiotemporal filter for reducing noise in neuromorphic vision sensors},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). High quality down-sampling for deterministic approaches to
stochastic computing. <em>TETC</em>, <em>9</em>(1), 7–14. (<a
href="https://doi.org/10.1109/TETC.2017.2789243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deterministic approaches to stochastic computing (SC) have been recently proposed to remove the random fluctuation and correlation problems of SC and so produce completely accurate results with stochastic logic. For many applications of SC, such as image processing and neural networks, completely accurate computation is not required for all input data. Decision-making on some input data can be done in a much shorter time using only a good approximation of the input values. While the deterministic approaches to SC are appealing by generating completely accurate results, the cost of precise results makes them energy inefficient for the cases when slight inaccuracy is acceptable. In this work, we propose a high quality down-sampling method for previously proposed deterministic approaches to SC by generating pseudo-random-but accurate-stochastic bit-stream. The result is a much better accuracy for a given number of input bits. Experimental results show that the processing time and the energy consumption of these deterministic methods are improved up to 61 and 41 percent, respectively, while allowing a mean absolute error (MAE) of 0.1 percent, and up to 500X and 334X improvement, respectively, for an MAE of 3.0 percent. The accuracy and the energy consumption are also improved compared to conventional random stream-based stochastic implementations.},
  archive      = {J_TETC},
  author       = {M. Hassan Najafi and David J. Lilja},
  doi          = {10.1109/TETC.2017.2789243},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {7-14},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {High quality down-sampling for deterministic approaches to stochastic computing},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Guest editorial: Special issue on emerging technologies in
computer design. <em>TETC</em>, <em>9</em>(1), 5–6. (<a
href="https://doi.org/10.1109/TETC.2020.3046058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The papers in this special issue focus on emerging technologies in computer design. These papers describe original work on practical and theoretical work covering system and computer architecture, test, verification and security, design and technology, and tools and methodologies.},
  archive      = {J_TETC},
  author       = {Ozgur Sinanoglu and Umit Ogras},
  doi          = {10.1109/TETC.2020.3046058},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {5-6},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Guest editorial: Special issue on emerging technologies in computer design},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Editorial from the new editor in chief. <em>TETC</em>,
<em>9</em>(1), 4. (<a
href="https://doi.org/10.1109/TETC.2021.3057410">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Presents the editorial from the new Editor-in-Chief.},
  archive      = {J_TETC},
  author       = {Paolo Montuschi},
  doi          = {10.1109/TETC.2021.3057410},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1},
  number       = {1},
  pages        = {4},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Editorial from the new editor in chief},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
