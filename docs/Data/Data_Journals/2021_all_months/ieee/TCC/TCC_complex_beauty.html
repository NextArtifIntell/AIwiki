<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TCC_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tcc---124">TCC - 124</h2>
<ul>
<li><details>
<summary>
(2021). Comment on “achieving secure, universal, and fine-grained
query results verification for secure search scheme over encrypted cloud
data.” <em>TCC</em>, <em>9</em>(4), 1675–1677. (<a
href="https://doi.org/10.1109/TCC.2020.3000513">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently in IEEE Transactions on Cloud Computing (TCC), Yin et al. [5] designed a fine-grained query verification mechanism where a novel certificateless short signature scheme is proposed for validating the data of encrypted query results. Despite the authors alleged that their scheme achieves the existential unforgeability to ensure the authenticity of verification objects, we found that this scheme fails to resist the forgery attack. Specifically, through launching the concrete attacks, a malicious adversary can forge a signature on any verification object without being detected.},
  archive      = {J_TCC},
  author       = {Zhiguang Qin and Yan Wu and Hu Xiong},
  doi          = {10.1109/TCC.2020.3000513},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1675-1677},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Comment on “Achieving secure, universal, and fine-grained query results verification for secure search scheme over encrypted cloud data”},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ViePEP-c: A container-based elastic process platform.
<em>TCC</em>, <em>9</em>(4), 1657–1674. (<a
href="https://doi.org/10.1109/TCC.2019.2912613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Business Process Management Systems (BPMS) need to be able to take into account the fluctuating demand for computational resources during the execution of business process activities. Today, BPMS rely on the leasing and releasing of virtual machines (VMs) on cloud resources, which leads to a rather coarse-grained allocation of computational resources. This may result in an increase in the execution cost, flexibility restrictions, and a negative impact on the Quality of Service. In order to overcome these drawbacks, we introduce the Vienna Platform for Elastic Processes on Containers (ViePEP-C). ViePEP-C is an elastic BPMS that uses containers instead of VMs for the execution of business process activities on cloud resources, leading to a more fine-grained execution environment. To achieve this, ViePEP-C offers cloud controller, monitoring and business process execution functionalities and provides a platform for different resource and task scheduling algorithms. To evaluate the benefits of ViePEP-C, we further present a resource and task scheduling algorithm and show that, by using containers as execution environment, the execution cost can be decreased by over 20 percent (compared to a state-of-the-art VM-based scheduling algorithm) while considering a high service level.},
  archive      = {J_TCC},
  author       = {Philipp Waibel and Christoph Hochreiner and Stefan Schulte and Agnes Koschmider and Jan Mendling},
  doi          = {10.1109/TCC.2019.2912613},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1657-1674},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {ViePEP-C: A container-based elastic process platform},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Two-server delegation of computation on label-encrypted
data. <em>TCC</em>, <em>9</em>(4), 1645–1656. (<a
href="https://doi.org/10.1109/TCC.2019.2913375">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Catalano and Fiore propose a scheme to transform a linearly-homomorphic encryption into a homomorphic encryption scheme capable of evaluating quadratic computations on ciphertexts. Their scheme is based on the linearly-homomorphic encryption (such as Goldwasser-Micali, Paillier and ElGamal) and need to perform large integer operation on servers. Then, their scheme have numerous computations on the servers. At the same time, their scheme cannot verify the computations and cannot evaluate more than degree-4 computations. To solve these problems, we no longer use linearly-homomorphic encryption which based on number theory assumptions. We use label and pseudorandom function to encrypt message, which significantly reduce the computations on the servers and enable us to use homomorphic MACs technology to realize verifiable computations naturally. We also extend the method to construct $d$ -server schemes, which allow the client to delegate degree- $d$ computations on outsourced data.},
  archive      = {J_TCC},
  author       = {Xin Chen and Liang Feng Zhang},
  doi          = {10.1109/TCC.2019.2913375},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1645-1656},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Two-server delegation of computation on label-encrypted data},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). TOFFEE: Task offloading and frequency scaling for energy
efficiency of mobile devices in mobile edge computing. <em>TCC</em>,
<em>9</em>(4), 1634–1644. (<a
href="https://doi.org/10.1109/TCC.2019.2923692">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an emerging computing paradigm, mobile edge computing (MEC) can improve users’ service experience by provisioning the cloud resources close to the mobile devices. With MEC, computation-intensive tasks can be processed on the MEC servers, which can greatly decrease the mobile devices’ energy consumption and prolong their battery lifetime. However, the highly dynamic task arrival and wireless channel states pose great challenges on the computation task allocation in MEC. This paper jointly investigates the task allocation and CPU-cycle frequency, to achieve the minimum energy consumption while guaranteeing that the queue length is upper bounded. We formulate it as a stochastic optimization problem, and with the aid of stochastic optimization methods, we decouple the original problem into two deterministic optimization subproblems. An online Task Offloading and Frequency Scaling for Energy Efficiency (TOFFEE) algorithm is proposed to obtain the optimal solutions of these subproblems concurrently. TOFFEE can obtain the close-to-optimal energy consumption while bounding the applications’ queue length. Performance evaluation is conducted which verifies TOFFEE’s effectiveness. Experiment results indicate that TOFFEE can decrease the energy consumption by about 15 percent compared with the RLE algorithm, and by about 38 percent compared with the RME algorithm.},
  archive      = {J_TCC},
  author       = {Ying Chen and Ning Zhang and Yongchao Zhang and Xin Chen and Wen Wu and Xuemin Sherman Shen},
  doi          = {10.1109/TCC.2019.2923692},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1634-1644},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {TOFFEE: Task offloading and frequency scaling for energy efficiency of mobile devices in mobile edge computing},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Survivable IaaS management with SDN. <em>TCC</em>,
<em>9</em>(4), 1619–1633. (<a
href="https://doi.org/10.1109/TCC.2019.2910111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault-tolerance, survivability and resiliency in wide area networks have long been prominent research topics. With the popularity of the cloud service model and the novel software defined networking (SDN) paradigm, there is renewed interest in failure protection and restoration in network service provisioning. In this work, we propose a novel protection and restoration based virtual network management scheme to enhance fault tolerance in infrastructure-as-a-service, deployed over networked cloud infrastructure. The networked cloud infrastructure is composed of multiple geographically distributed datacenters that are interconnected with SDN. Both compute and network resources are allocated by formulating the virtual network embedding problem as an integer linear program. A shared backup virtual link protection mechanism and a reactive traffic engineering network failure restoration algorithm are proposed and integrated with the framework to provide recovery from unexpected link failures. We implemented the framework on an emulated SDN testbed and evaluated the performances of the algorithms during single and multiple link failures. Experimental results demonstrate trade-offs of the proposed approaches and their applicability in different application scenarios.},
  archive      = {J_TCC},
  author       = {Heli Amarasinghe and Abdallah Jarray and Ahmed Karmouch},
  doi          = {10.1109/TCC.2019.2910111},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1619-1633},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Survivable IaaS management with SDN},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Secure data group sharing and conditional dissemination with
multi-owner in cloud computing. <em>TCC</em>, <em>9</em>(4), 1607–1618.
(<a href="https://doi.org/10.1109/TCC.2019.2908163">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of cloud services, huge volume of data is shared via cloud computing. Although cryptographic techniques have been utilized to provide data confidentiality in cloud computing, current mechanisms cannot enforce privacy concerns over ciphertext associated with multiple owners, which makes co-owners unable to appropriately control whether data disseminators can actually disseminate their data. In this paper, we propose a secure data group sharing and conditional dissemination scheme with multi-owner in cloud computing, in which data owner can share private data with a group of users via the cloud in a secure way, and data disseminator can disseminate the data to a new group of users if the attributes satisfy the access policies in the ciphertext. We further present a multiparty access control mechanism over the disseminated ciphertext, in which the data co-owners can append new access policies to the ciphertext due to their privacy preferences. Moreover, three policy aggregation strategies, including full permit, owner priority and majority permit, are provided to solve the privacy conflicts problem caused by different access policies. The security analysis and experimental results show our scheme is practical and efficient for secure data sharing with multi-owner in cloud computing.},
  archive      = {J_TCC},
  author       = {Qinlong Huang and Yixian Yang and Wei Yue and Yue He},
  doi          = {10.1109/TCC.2019.2908163},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1607-1618},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Secure data group sharing and conditional dissemination with multi-owner in cloud computing},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Rerouting strategies for highly available virtual network
functions. <em>TCC</em>, <em>9</em>(4), 1592–1606. (<a
href="https://doi.org/10.1109/TCC.2019.2925110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of Virtual Network Functions (VNFs) migrates network functions from dedicated hardware to groups of commodity servers called network points of presence (N-PoPs). In this way, network services are redefined as interconnected VNFs called Service Function Chains (SFCs). The emerging of SFCs significantly reduces the cost of network services and improves scalability. However, the availability of SFCs brings new challenges since a failure of any N-PoP along an SFC affects its availability. In this paper, we propose two rerouting strategies to improve the availability of SFCs. First, we propose a local rerouting strategy to bypass the failed N-PoPs on SFCs using locally rerouted paths (LRPs). In the strategy, we formulate an optimization model to minimize the maximum load on links while deploying SFCs and LRPs to reduce the risk of congested links caused by local rerouting. We then propose an approximation algorithm to solve the optimization problem, preserving an approximation ratio of $\mathcal {O}(\log (|V|))$ , where $|V|$ is the number of N-PoPs in the network. We also propose an alternative heuristic algorithm to improve efficiency. Second, we propose a supplementary rerouting strategy with an online algorithm to provide supplementary rerouted paths when original SFCs and corresponding LRPs fail at the same time in the local rerouting strategy. The online algorithm is proved to have an $\mathcal {O}(\log (|V|))$ competitive ratio to the offline optimum. Finally, our extensive simulation results show that the proposed algorithms can provide highly available SFCs with less congested links.},
  archive      = {J_TCC},
  author       = {Xiaojun Shang and Zhenhua Li and Yuanyuan Yang},
  doi          = {10.1109/TCC.2019.2925110},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1592-1606},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Rerouting strategies for highly available virtual network functions},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Repair strategies for mobile storage systems. <em>TCC</em>,
<em>9</em>(4), 1575–1591. (<a
href="https://doi.org/10.1109/TCC.2019.2914436">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the data reliability problem for devices forming a dynamic distributed storage system. Such systems are commonplace in traditional cloud storage applications where storage node failures and updates are frequent. We consider the application of regenerating codes for file maintenance. Such codes require lower bandwidth to regenerate lost data fragments compared to file replication or reconstruction. We investigate threshold-based repair strategies where data repair is initiated after a threshold number of data fragments have been lost. We show that at a low departure-to-repair rate regime, in which repairs are initiated after several nodes have left the system outperforms if repairs are initiated after a single node departure. This optimality is reversed when the node turnover is high. We further compare distributed and centralized repair strategies and derive the optimal repair threshold for minimizing the average repair cost per unit of time. In addition, we examine cooperative repair strategies and show performance improvements. We investigate several models for the time needed for node repair including a simple fixed time model and a more realistic model that takes into account the number of repaired nodes. Finally, an extended model where additional failures are allowed during the repair process is investigated.},
  archive      = {J_TCC},
  author       = {Gokhan Calis and Swetha Shivaramaiah and O. Ozan Koyluoglu and Loukas Lazos},
  doi          = {10.1109/TCC.2019.2914436},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1575-1591},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Repair strategies for mobile storage systems},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Profit maximization of big data jobs in cloud using
stochastic optimization. <em>TCC</em>, <em>9</em>(4), 1563–1574. (<a
href="https://doi.org/10.1109/TCC.2019.2926254">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reserved instances offered by cloud providers make it possible to reserve resources and computing capacity for a specific period of time. One should pay for all the hours of that time interval; in exchange, the hourly rate is significantly lower than on-demand instances. Reserved Instances can significantly reduce the monetary cost of resources needed to process big data applications in cloud. However, purchases of these instances are non-refundable, and hence, one should be able to estimate the required resources prior to purchase to avoid over-payment. It becomes important especially when the results obtained by big data job has monetary value, such as business intelligence applications. But, estimating the resource demand of big data processing jobs is hard because of numerous factors that affect them such as data locality, data skew, stragglers, internal settings of big data processing framework, interference among instances, instances availability, etc. To maximize the profit of processing such big data jobs in cloud considering fluctuating nature of their resource demand, as well as reserved instances limitations, we propose Reserved Instances Stochastic Allocation (RISA) approach. Using historical traces of resource demand of big data jobs submitted by user, RISA leverages stochastic optimization to determine the amount of resources needed to be reserved for that user to maximize the profit. Our evaluation using real-world traces shows that RISA can increase the net profit by up to 10x, compared to previous approaches. RISA can also find solutions as close as 2 percent to the best possible solution.},
  archive      = {J_TCC},
  author       = {Seyed Morteza Nabavinejad and Maziar Goudarzi},
  doi          = {10.1109/TCC.2019.2926254},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1563-1574},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Profit maximization of big data jobs in cloud using stochastic optimization},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Model-driven elasticity management with OCCI. <em>TCC</em>,
<em>9</em>(4), 1549–1562. (<a
href="https://doi.org/10.1109/TCC.2019.2923686">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Elasticity is considered as a fundamental feature of cloud computing where the system capacity can adjust to the current application workloads by provisioning or de-provisioning computing resources automatically and timely. Many studies have been already conducted to elasticity management systems, however, almost all lack to offer a complete modular solution. In this article, we propose MoDEMO , a new elasticity management system powering both vertical and horizontal elasticities, both VM and Container virtualization technologies, multiple cloud providers simultaneously, and various elasticity policies. MoDEMO is characterized by the following features: it represents ( i ) the first system that manages elasticity using Open Cloud Computing Interface (OCCI) model with respect to the OCCI standard specifications, ( ii ) the first unified system which combines the functionalities of the worldwide cloud providers: Amazon Web Services (AWS), Microsoft Azure and Google Cloud Platform (GCP), and ( iii ) allows a dynamic configuration at runtime during the execution of the application. MoDEMO permits to timely adapt resource capacity according to the workload intensity and increase application performance without introducing a significant overhead.},
  archive      = {J_TCC},
  author       = {Yahya Al-Dhuraibi and Faiez Zalila and Nabil Djarallah and Philippe Merle},
  doi          = {10.1109/TCC.2019.2923686},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1549-1562},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Model-driven elasticity management with OCCI},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Maximizing throughput of delay-sensitive NFV-enabled request
admissions via virtualized network function placement. <em>TCC</em>,
<em>9</em>(4), 1535–1548. (<a
href="https://doi.org/10.1109/TCC.2019.2915835">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network Function Virtualization (NFV) has attracted significant attention from both industry and academia as an important paradigm change in network service provisioning. Most existing studies on admissions of NFV-enabled requests focused on deploying dedicated Virtualized Network Function (VNF) instances to serve each individual request without exploring the sharing of VNF instances among multiple user requests. However, with ever-growing demands of user services, exclusive usages of VNF instances in most networks drastically degrade the network performance and largely under-utilize the VNF instance resources. In this paper, we jointly explore two different VNF instance scaling techniques, horizontal scaling and vertical scaling techniques, to improve the network throughput while minimizing the operational cost of the network, where horizontal scaling that migrates some existing VNF instances from their current locations to new locations to allow the VNF instances to be shared by multiple requests to reduce the resource consumption and operational cost of the network, and vertical scaling that instantiates new VNF instances to meet the demands of new request admissions if existing VNF instances sharing becomes more expensive or the end-to-end delay requirements of currently executing requests will be violated. We first propose a unified framework of maximizing the network throughput, by admitting as many as NFV-enabled requests while meeting the end-to-end delay requirements of the admitted requests. We then provide an Integer Linear Programming (ILP) solution for the problem when the problem size is small. Otherwise, we devise an efficient algorithm through a non-trivial reduction that reduces the problem to the minimum-weight feedback arc set problem and the generalized assignment problem (GAP). We finally conduct experiments to evaluate the performance of the proposed algorithm. Experimental results demonstrate that the proposed algorithm outperforms a baseline algorithm and achieves a performance on a par with its optimal ILP solution.},
  archive      = {J_TCC},
  author       = {Meitian Huang and Weifa Liang and Yu Ma and Song Guo},
  doi          = {10.1109/TCC.2019.2915835},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1535-1548},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Maximizing throughput of delay-sensitive NFV-enabled request admissions via virtualized network function placement},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Low latency big data processing without prior information.
<em>TCC</em>, <em>9</em>(4), 1521–1534. (<a
href="https://doi.org/10.1109/TCC.2019.2910251">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Job scheduling plays an important role in improving the overall system performance in big data processing frameworks. Simple job scheduling policies, such as Fair and FIFO scheduling, do not consider job sizes and may degrade the performance when jobs of varying sizes arrive. More elaborate job scheduling policies make the convenient assumption that jobs are recurring, and complete information about their sizes is available from their prior runs. In this paper, we design and implement an efficient and practical job scheduler for big data processing systems to achieve better performance even without prior information about job sizes. The superior performance of our job scheduler originates from the design of multiple level priority queues, where jobs are demoted to lower priority queues if the amount of service consumed so far reaches a certain threshold. In this case, jobs in need of a small amount of service can finish in the topmost several levels of queues, while jobs that need a large amount of service to complete are moved to lower priority queues to avoid head-of-line blocking. Our new job scheduler can effectively mimic the shortest job first scheduling policy without knowing the job sizes in advance. To demonstrate its performance, we have implemented our new job scheduler in YARN, a popular resource manager used by Hadoop/Spark, and validated its performance with experiments in both real testbeds including Amazon EC2 and large-scale trace-driven simulations. Our experimental and simulation results have strongly confirmed the effectiveness of our design: our new job scheduler can reduce the average job response time of the Fair scheduler by up to 45 percent and achieve better fairness at the same time.},
  archive      = {J_TCC},
  author       = {Zhiming Hu and Baochun Li and Zheng Qin and Rick Siow Mong Goh},
  doi          = {10.1109/TCC.2019.2910251},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1521-1534},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Low latency big data processing without prior information},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Joint management of wireless and computing resources for
computation offloading in mobile edge clouds. <em>TCC</em>,
<em>9</em>(4), 1507–1520. (<a
href="https://doi.org/10.1109/TCC.2019.2923768">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the computation offloading problem in an edge computing system in which an operator jointly manages wireless and computing resources across devices that make their offloading decisions autonomously with the objective to minimize their own completion times. We develop a game theoretical model of the interaction between the devices and an operator that can implement one of two resource allocation policies, a cost minimizing or a time fair resource allocation policy. We express the optimal cost minimizing resource allocation policy in closed form and prove the existence of Stackelberg equilibria for both resource allocation policies. We propose two efficient decentralized algorithms that devices can use for computing equilibria of offloading decisions under the cost minimizing and the time fair resource allocation policies. We establish bounds on the price of anarchy of the games played by the devices and by doing so we show that the proposed algorithms have bounded approximation ratios. Our simulation results show that the cost minimizing resource allocation policy can achieve significantly lower completion times than the time fair allocation policy. At the same time, the convergence time of the proposed algorithms is approximately linear in the number of devices, and thus they could be effectively implemented for edge computing resource management.},
  archive      = {J_TCC},
  author       = {Slađana Jošilo and György Dán},
  doi          = {10.1109/TCC.2019.2923768},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1507-1520},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Joint management of wireless and computing resources for computation offloading in mobile edge clouds},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Incentive facilitation for peer data exchange in
crowdsensing. <em>TCC</em>, <em>9</em>(4), 1493–1506. (<a
href="https://doi.org/10.1109/TCC.2019.2926973">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With mobile devices extensively used in daily life, there are ample opportunities to exchange sensing data through them, even without centralized management. In this paper, we design a peer based data exchanging model, where relay nodes move to certain locations to connect data providers and consumers to facilitate data delivery. Consumers are willing to pay for the data and these rewards are given to both relays and data providers. We first prove the NP-hardness of the problem on how to assign relay nodes to proper locations, and present a centralized optimal method with an approximation ratio. Then we define an autonomous compensation game for relays to make their individual decisions without any central authority. The sufficient and necessary condition for the existence of Nash equilibrium is derived, and an efficient reinforcement learning solver is designed to find the exact forms of equilibria. We analyze and compare this distributed game to the centralized social optimal solution, showing that the game incurs small bounded social costs, and is efficient under various network sizes, number of providers, number of consumers and device mobility.},
  archive      = {J_TCC},
  author       = {Xiang Yan and Fan Ye and Yuanyuan Yang and Dongge Wang and Xiaotie Deng},
  doi          = {10.1109/TCC.2019.2926973},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1493-1506},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Incentive facilitation for peer data exchange in crowdsensing},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Impact of processing-resource sharing on the placement of
chained virtual network functions. <em>TCC</em>, <em>9</em>(4),
1479–1492. (<a href="https://doi.org/10.1109/TCC.2019.2914387">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network Function Virtualization (NFV) provides higher flexibility for network operators and reduces the complexity in network service deployment. Using NFV, Virtual Network Functions (VNF) can be located in various network nodes and chained together in a Service Function Chain (SFC) to provide a specific service. Consolidating multiple VNFs in a smaller number of locations would allow decreasing capital expenditures. However, excessive consolidation of VNFs might cause additional latency penalties due to processing-resource sharing, and this is undesirable, as SFCs are bounded by service-specific latency requirements. In this paper, we identify two different types of penalties (referred as “costs”) related to the processing-resource sharing among multiple VNFs: the context switching costs and the upscaling costs . Context switching costs arise when multiple CPU processes (e.g., supporting different VNFs) share the same CPU and thus repeated loading/saving of their context is required. Upscaling costs are incurred by VNFs requiring multi-core implementations, since they suffer a penalty due to the load-balancing needs among CPU cores. These costs affect how the chained VNFs are placed in the network to meet the performance requirement of the SFCs. We evaluate their impact while considering SFCs with different bandwidth and latency requirements in a scenario of VNF consolidation.},
  archive      = {J_TCC},
  author       = {Marco Savi and Massimo Tornatore and Giacomo Verticale},
  doi          = {10.1109/TCC.2019.2914387},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1479-1492},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Impact of processing-resource sharing on the placement of chained virtual network functions},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). FCTcon: Dynamic control of flow completion time in data
center networks for power efficiency. <em>TCC</em>, <em>9</em>(4),
1467–1478. (<a href="https://doi.org/10.1109/TCC.2019.2912969">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of cloud computing, data center network (DCN) can consume a significant amount of power (e.g., 10 to 20 percent) in large-scale data centers. To reduce the power consumption of DCN, traffic consolidation has been recently proposed as an effective approach to reduce the number of DCN devices in use. However, existing consolidation approaches do not sufficiently consider the flow completion time (FCT) requirement. On one hand, missing the FCT deadlines can cause serious violation of service-level agreement, especially for delay-sensitive networking services, such as web search and E-commerce. On the other hand, keeping all the devices on to make FCTs much shorter than the desired requirements is unnecessary because 1) users may not be able to perceive the difference, and 2) such a greedy strategy can lead to unnecessarily high DCN power consumption and thus more electricity costs. In this paper, we propose FCTcon, a dynamic FCT control strategy for DCN power optimization. FCTcon is designed rigorously based on control theory to dynamically control the FCT of delay-sensitive traffic flows exactly to the requirements, such that the desired FCT performance is guaranteed while the maximum amount of DCN power savings can be achieved. Results from both hardware experiments and simulation evaluation demonstrate that, compared to the state-of-the-art DCN power optimization schemes, FCTcon can improve the DCN FCT performance, while achieving nearly the same or even more power savings. Consequently, FCTcon can result in more than 22.0 to 62.2 percent extra net profits for a data center with 50K servers. In addition, we further propose two extended designs of FCTcon to handle the coflow abstraction recently proposed for DCN, which successfully reduce the coflow deadline miss ratio by 12 to 15 percent.},
  archive      = {J_TCC},
  author       = {Kuangyu Zheng and Yunhao Bai and Xiaorui Wang},
  doi          = {10.1109/TCC.2019.2912969},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1467-1478},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {FCTcon: Dynamic control of flow completion time in data center networks for power efficiency},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). FastTrack: Minimizing stalls for CDN-based over-the-top
video streaming systems. <em>TCC</em>, <em>9</em>(4), 1453–1466. (<a
href="https://doi.org/10.1109/TCC.2019.2920979">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic for internet video streaming has been rapidly increasing and is further expected to increase with the higher definition videos and IoT applications, such as 360 degree videos and augmented virtual reality applications. While efficient management of heterogeneous cloud resources to optimize the quality of experience is important, existing work in this problem space often left out important factors. In this paper, we present a model for describing a today’s representative system architecture for video streaming applications, typically composed of a centralized origin server and several CDN sites. Our model comprehensively considers the following factors: limited caching spaces at the CDN sites, allocation of CDN for a video request, choice of different ports from the CDN, and the central storage and bandwidth allocation. With the model, we focus on minimizing a performance metric, stall duration tail probability (SDTP), and present a novel, yet efficient, algorithm to solve the formulated optimization problem. The theoretical bounds with respect to the SDTP metric are also analyzed and presented. Our extensive simulation results demonstrate that the proposed algorithms can significantly improve the SDTP metric, compared to the baseline strategies. Small-scale video streaming system implementation in a real cloud environment further validates our results.},
  archive      = {J_TCC},
  author       = {Abubakr O. Al-Abbasi and Vaneet Aggarwal and Tian Lan and Yu Xiang and Moo-Ryong Ra and Yih-Farn Chen},
  doi          = {10.1109/TCC.2019.2920979},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1453-1466},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {FastTrack: Minimizing stalls for CDN-based over-the-top video streaming systems},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic demand prediction and allocation in cloud service
brokerage. <em>TCC</em>, <em>9</em>(4), 1439–1452. (<a
href="https://doi.org/10.1109/TCC.2019.2913419">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To maximize its own profit, cloud service brokerage (CSB) aims to distribute tenant demands to reserved servers such that the total reservation cost is minimized with the tenants’ service level agreement (SLA) being satisfied. The demand allocation problem for CSB is non-trivial to solve due to uncertainty of tenants’ behavior. To avoid possible violations among demands, existing schemes allocate additional padding resources on the predicted demands, which leads to under-utilization of reserved resources. Accordingly, we propose a Probabilistic Demand Allocation (PDA) system to address the demand allocation problem for CSB. In PDA, we not only predict tenants’ demands based on their historical records, but also estimate the probability distribution of prediction errors. As over- and under-estimation are equally likely to happen with our prediction method, when allocating demands to a single server, their errors are possibly offset. Hence, it is unnecessary to allocate additional resource to each demand for violation prevention. Given the predication results, we formulate the demand allocation problem by probabilistic optimization, of which the objective is to minimize the overall cost from reserved servers while satisfying tenants’ SLA with high probability. Both simulation and real-world experimental results demonstrate the superiority of PDA in reducing servers’ reservation cost.},
  archive      = {J_TCC},
  author       = {Chenxi Qiu and Haiying Shen},
  doi          = {10.1109/TCC.2019.2913419},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1439-1452},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Dynamic demand prediction and allocation in cloud service brokerage},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Delay and cost optimization in computational offloading
systems with unknown task processing times. <em>TCC</em>, <em>9</em>(4),
1422–1438. (<a href="https://doi.org/10.1109/TCC.2019.2924634">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational offloading systems, where computational tasks can be processed locally or offloaded to a remote cloud, have become prevalent since the advent of cloud computing. The task scheduler in a computational offloading system decides both the selection of tasks to be offloaded to the remote cloud and the scheduling of tasks on the local processors. In this work, we consider the problem of minimizing a weighted sum of the makespan of the tasks and the offloading cost at the remote cloud. In contrast to prior works, we do not assume that the task processing times are known a priori. We show that the original problem can be solved by algorithms designed toward minimizing the maximum between the makespan and the weighted offloading cost, only with doubling of the competitive ratio. Furthermore, when the remote cloud is much faster than the local processors, the latter problem can be equivalently transformed into a makespan minimization problem with unrelated processors. For this case, we propose a Greedy-One-Restart (GOR) algorithm based on online estimation of the unknown processing times, and one-time cancellation and rescheduling of tasks that turn out to require long processing times. Given $m$ local processors, we show that GOR has $O(\sqrt{m})$ competitive ratio, which is a substantial improvement over the best known algorithms in the literature. For the general case of arbitrary speed at the remote cloud, we extend GOR to a Greedy-Two-Restart (GTR) algorithm and show that it is $O(\sqrt{m})$ -competitive. Furthermore, where tasks arrive dynamically with unknown arrival times, we extend GOR and GTR to Dynamic-GOR (DGOR) and Dynamic-GTR (DGTR), respectively, and find their competitive ratios. Finally, we discuss how GOR can be extended to accommodate multiple remote processors. In addition to performance bounding by competitive ratios, our simulation results demonstrate that the proposed algorithms are favorable also in terms of average performance, in comparison with the well-known list scheduling algorithm and other alternatives.},
  archive      = {J_TCC},
  author       = {Jaya Prakash Champati and Ben Liang},
  doi          = {10.1109/TCC.2019.2924634},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1422-1438},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Delay and cost optimization in computational offloading systems with unknown task processing times},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Data integrity auditing without private key storage for
secure cloud storage. <em>TCC</em>, <em>9</em>(4), 1408–1421. (<a
href="https://doi.org/10.1109/TCC.2019.2921553">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using cloud storage services, users can store their data in the cloud to avoid the expenditure of local data storage and maintenance. To ensure the integrity of the data stored in the cloud, many data integrity auditing schemes have been proposed. In most, if not all, of the existing schemes, a user needs to employ his private key to generate the data authenticators for realizing the data integrity auditing. Thus, the user has to possess a hardware token (e.g., USB token, smart card) to store his private key and memorize a password to activate this private key. If this hardware token is lost or this password is forgotten, most of the current data integrity auditing schemes would be unable to work. In order to overcome this problem, we propose a new paradigm called data integrity auditing without private key storage and design such a scheme. In this scheme, we use biometric data (e.g., iris scan, fingerprint) as the user’s fuzzy private key to avoid using the hardware token. Meanwhile, the scheme can still effectively complete the data integrity auditing. We utilize a linear sketch with coding and error correction processes to confirm the identity of the user. In addition, we design a new signature scheme which not only supports blockless verifiability, but also is compatible with the linear sketch. The security proof and the performance analysis show that our proposed scheme achieves desirable security and efficiency.},
  archive      = {J_TCC},
  author       = {Wenting Shen and Jing Qin and Jia Yu and Rong Hao and Jiankun Hu and Jixin Ma},
  doi          = {10.1109/TCC.2019.2921553},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1408-1421},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Data integrity auditing without private key storage for secure cloud storage},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cost-effective sharing of streaming dataflows for IoT
applications. <em>TCC</em>, <em>9</em>(4), 1391–1407. (<a
href="https://doi.org/10.1109/TCC.2019.2921371">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Things (IoT) applications are often designed as dataflows that analyze sensor data in real-time to make decisions. Stream processing systems like Apache Storm execute these on Cloud infrastructure. As IoT applications within shared data environments like smart cities grow, they will duplicate tasks like pre-processing and analytics. This offers the opportunity to collaboratively reuse the outputs of overlapping dataflows, improving the resource efficiency on Clouds. We propose dataflow reuse algorithms that when given a submitted dataflow, identify the intersection of reusable tasks and streams from existing dataflows to form a merged dataflow , with guaranteed equivalence of their output streams. Algorithms to unmerge dataflows when they are removed, and defragment partially reused dataflows are also proposed. We implement these algorithms for the Storm fast-data platform, and validate their performance and resource savings using 86 real and synthetic dataflows from eScience and IoT domains. Our reuse strategies reduce the number of running tasks by 34–45 percent and the cumulative CPU usage by 29–63 percent. Including defragmentation of incremental dataflows achieves a monetary savings on Cloud resources of 36–44 percent compared to dataflows without reuse, and has limited redeployment overheads.},
  archive      = {J_TCC},
  author       = {Shilpa Chaturvedi and Sahil Tyagi and Yogesh Simmhan},
  doi          = {10.1109/TCC.2019.2921371},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1391-1407},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Cost-effective sharing of streaming dataflows for IoT applications},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Classification-based and energy-efficient dynamic task
scheduling scheme for virtualized cloud data center. <em>TCC</em>,
<em>9</em>(4), 1376–1390. (<a
href="https://doi.org/10.1109/TCC.2019.2918226">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The size and number of cloud data centers (CDCs) have grown rapidly with the increasing popularity of cloud computing and high-performance computing. This has the unintended consequences of creating new challenges due to inefficient use of resources and high energy consumption. Hence, this necessitates the need to maximize resource utilization and ensure energy efficiency in CDCs. One viable approach to achieve energy efficiency and resource utilization in CDC is task scheduling. While several task scheduling approaches have been proposed in the literature, there appears to be a lack of classification-based merging concept for real-time tasks in these existing approaches. Thus, an energy-efficient dynamic scheduling scheme (EDS) of real-time tasks for virtualized CDC is presented in this paper. In the scheduling scheme, the heterogeneous tasks and virtual machines are first classified based on a historical scheduling record. Then, similar type of tasks are merged and scheduled to maximally utilize an operational state of the host. In addition, energy efficiencies and optimal operating frequencies of heterogeneous physical hosts are employed to attain energy preservation while creating and deleting the virtual machines. Experimental results show that, in comparison with existing techniques, EDS significantly improves overall scheduling performance, achieves a higher CDC resource utilization, increases task guarantee ratio, minimizes the mean response time, and reduces energy consumption.},
  archive      = {J_TCC},
  author       = {Avinab Marahatta and Sandeep Pirbhulal and Fa Zhang and Reza M. Parizi and Kim-Kwang Raymond Choo and Zhiyong Liu},
  doi          = {10.1109/TCC.2019.2918226},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1376-1390},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Classification-based and energy-efficient dynamic task scheduling scheme for virtualized cloud data center},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). CIPPPA: Conditional identity privacy-preserving public
auditing for cloud-based WBANs against malicious auditors. <em>TCC</em>,
<em>9</em>(4), 1362–1375. (<a
href="https://doi.org/10.1109/TCC.2019.2927219">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless body area networks (WBANs) rely on powerful cloud storage services to manage massive medical data. As precise medical diagnosis analysis is heavily based on these medical data, any altered medical data may cause severe consequences, the integrity of outsourced medical data has become the most concerning security issue. Up to date, most existing public auditing mechanisms have been proposed to check the data integrity, but they could not achieve conditional identity privacy, any patient would not like others to know his/her real identity corresponding to certain serious disease, and some malicious patients should be revoked timely due to misbehaviors. Additionally, they are vulnerable to malicious auditors, by colluding with the cloud server to cheat patients. In this paper, we propose a conditional identity privacy-preserving public auditing (CIPPPA) mechanism for cloud-based WBANs. CIPPPA is the first public auditing mechanism achieving conditional identity privacy of patients in WBANs, the real identity of a patient is unknown to anyone in cloud-based WBANs other than the private key generator (PKG). We attempt to integrate Ethereum blockchain into CIPPPA, which gives assistance to patients for validating malicious auditing behaviors. Formal security analysis and performance evaluation demonstrate that CIPPPA is practical for cloud-based WBANs.},
  archive      = {J_TCC},
  author       = {Xiaojun Zhang and Jie Zhao and Chunxiang Xu and Hongwei Li and Huaxiong Wang and Yuan Zhang},
  doi          = {10.1109/TCC.2019.2927219},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1362-1375},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {CIPPPA: Conditional identity privacy-preserving public auditing for cloud-based WBANs against malicious auditors},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Charon: A secure cloud-of-clouds system for storing and
sharing big data. <em>TCC</em>, <em>9</em>(4), 1349–1361. (<a
href="https://doi.org/10.1109/TCC.2019.2916856">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present Charon , a cloud-backed storage system capable of storing and sharing big data in a secure, reliable, and efficient way using multiple cloud providers and storage repositories to comply with the legal requirements of sensitive personal data. Charon implements three distinguishing features: (1) it does not require trust on any single entity, (2) it does not require any client-managed server, and (3) it efficiently deals with large files over a set of geo-dispersed storage services. Besides that, we developed a novel Byzantine-resilient data-centric leasing protocol to avoid write-write conflicts between clients accessing shared repositories. We evaluate Charon using micro and application-based benchmarks simulating representative workflows from bioinformatics, a prominent big data domain. The results show that our unique design is not only feasible but also presents an end-to-end performance of up to $2.5\times$ better than other cloud-backed solutions.},
  archive      = {J_TCC},
  author       = {Ricardo Mendes and Tiago Oliveira and Vinicius Cogo and Nuno Neves and Alysson Bessani},
  doi          = {10.1109/TCC.2019.2916856},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1349-1361},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Charon: A secure cloud-of-clouds system for storing and sharing big data},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Blockchain-assisted public-key encryption with keyword
search against keyword guessing attacks for cloud storage. <em>TCC</em>,
<em>9</em>(4), 1335–1348. (<a
href="https://doi.org/10.1109/TCC.2019.2923222">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud storage enables users to outsource data to storage servers and retrieve target data efficiently. Some of the outsourced data are very sensitive and should be prevented for any leakage. Generally, if users conventionally encrypt the data, searching is impeded. Public-key encryption with keyword search (PEKS) resolves this tension. Whereas, it is vulnerable to keyword guessing attacks (KGA), since keywords are low-entropy. In this paper, we present a secure PEKS scheme called SEPSE against KGA, where users encrypt keywords with the aid of dedicated key servers via a threshold and oblivious way. SEPSE supports key renewal to periodically replace an existing key with a new one on each key server to thwart the key compromise. Furthermore, SEPSE can efficiently resist online KGA, where each keyword request made by a user is integrated into a transaction on a public blockchain (e.g., Ethereum), which allows key servers to learn the number of keyword requests made by the user without requiring a synchronization between them for per-user rate limiting. Security analysis and performance evaluation demonstrate that SEPSE provides a stronger security guarantee compared with existing schemes, at the expense of acceptable computational costs.},
  archive      = {J_TCC},
  author       = {Yuan Zhang and Chunxiang Xu and Jianbing Ni and Hongwei Li and Xuemin Sherman Shen},
  doi          = {10.1109/TCC.2019.2923222},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1335-1348},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Blockchain-assisted public-key encryption with keyword search against keyword guessing attacks for cloud storage},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Big-sensor-cloud infrastructure: A holistic prototype for
provisioning sensors-as-a-service. <em>TCC</em>, <em>9</em>(4),
1323–1334. (<a href="https://doi.org/10.1109/TCC.2019.2908820">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proposed work relates to the development of Big-Sensor-Cloud Infrastructure ( BSCI ) that immensely enhances the usability and management of the physical sensor devices. Traditional Wireless Sensor Networks (WSNs) are manufactured in a proprietary, vendor-specific design. Thus, the renderability of WSNs is almost infeasible to people/organizations that do not own a network of their own. Thus, in the existing system, WSN-based applications are inaccessible to the naive-users or common people who do not own physical sensor devices. Recently, sensor-cloud infrastructure has been viewed as a substitute for traditional WSNs. However, with the increasing growth in the velocity, variety, and variability of data, the management becomes a serious concern and difficulty. Thus, existing systems are not able to capture, analyze, and control the present data efficiently, in real-time. BSCI is a distributed framework for “Big” sensor-data storage, processing, virtualization, leveraging, and efficient remote management. The methods of the proposed BSCI are persuasive as they are equipped with the ability to handle “Big” data with enormous heterogeneous data volumes (in zettabyte) generated with tremendous velocity. The framework interfaces between the physical and cyber worlds, thereby acquiring real-time data from the physical WSNs into the cloud platform. This data are processed and delivered to the end-users as a simple service – Sensors-as-a-Service (Se-aaS). BSCI completely maintains and manages the data and the metadata internally within its database. Multiple organizations with heterogeneous demand can be successfully served with Se-aaS through BSCI. From a user-perspective, BSCI is highly convenient as the users are completely abstracted from the underlying complex processing logic. This allows the naive users to envision the typical hardware sensor devices as simple accessible services like electricity, and water.},
  archive      = {J_TCC},
  author       = {Subarna Chatterjee and Arijit Roy and Sanku Kumar Roy and Sudip Misra and Manmeet Singh Bhogal and Rachit Daga},
  doi          = {10.1109/TCC.2019.2908820},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1323-1334},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Big-sensor-cloud infrastructure: A holistic prototype for provisioning sensors-as-a-service},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An energy and performance aware consolidation technique for
containerized datacenters. <em>TCC</em>, <em>9</em>(4), 1305–1322. (<a
href="https://doi.org/10.1109/TCC.2019.2920914">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud datacenters have become a backbone for today’s business and economy, which are the fastest-growing electricity consumers, globally. Numerous studies suggest that $\sim$ 30\% of the US datacenters are comatose and the others are grossly less-utilized, which make it possible to save energy through resource consolidation techniques. However, consolidation comprises migrations that are expensive in terms of energy consumption and performance degradation, which is mostly not accounted for in many existing models, and, possibly, it could be more energy and performance efficient not to consolidate. In this paper, we investigate how migration decisions should be taken so that the migration cost is recovered, as only when migration cost has been recovered and performance is guaranteed, will energy start to be saved. We demonstrate through several experiments, using the Google workload data for 12,583 hosts and approximately one million tasks that belong to three different kinds of workload, how different allocation policies, combined with various migration approaches, will impact on datacenter’s energy and performance efficiencies. Using several plausible assumptions for containerised datacenter set-up, we suggest, that a combination of the proposed energy-performance-aware allocation ( Epc-Fu ) and migration ( Cper ) techniques, and migrating relatively long-running containers only, offers for ideal energy and performance efficiencies.},
  archive      = {J_TCC},
  author       = {Ayaz Ali Khan and Muhammad Zakarya and Rajkumar Buyya and Rahim Khan and Mukhtaj Khan and Omer Rana},
  doi          = {10.1109/TCC.2019.2920914},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1305-1322},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {An energy and performance aware consolidation technique for containerized datacenters},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A user-centric data protection method for cloud storage
based on invertible DWT. <em>TCC</em>, <em>9</em>(4), 1293–1304. (<a
href="https://doi.org/10.1109/TCC.2019.2911679">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Protection on end users’ data stored in Cloud servers becomes an important issue in today’s Cloud environments. In this paper, we present a novel data protection method combining Selective Encryption (SE) concept with fragmentation and dispersion on storage. Our method is based on the invertible Discrete Wavelet Transform (DWT) to divide agnostic data into three fragments with three different levels of protection. Then, these three fragments can be dispersed over different storage areas with different levels of trustworthiness to protect end users’ data by resisting possible leaks in Clouds. Thus, our method optimizes the storage cost by saving expensive, private, and secure storage spaces and utilizing cheap but low trustworthy storage space. We have intensive security analysis performed to verify the high protection level of our method. Additionally, the efficiency is proved by implementation of deploying tasks between CPU and General Purpose Graphic Processing Unit (GPGPU) in an optimized manner.},
  archive      = {J_TCC},
  author       = {Han Qiu and Hassan Noura and Meikang Qiu and Zhong Ming and Gerard Memmi},
  doi          = {10.1109/TCC.2019.2911679},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1293-1304},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {A user-centric data protection method for cloud storage based on invertible DWT},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A trust-aware mechanism for cloud federation formation.
<em>TCC</em>, <em>9</em>(4), 1278–1292. (<a
href="https://doi.org/10.1109/TCC.2019.2911831">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud providers can form cloud federations by pooling their resources together to balance their loads, reduce their costs, and manage demand spikes. However, forming cloud federations is a challenging problem, especially when considering the incentives of the cloud providers making their own decisions to participate in cloud federations. In this paper, we model the formation of cloud federations necessary to provide resources to execute Map-heavy/Reduce-heavy programs while considering the trust and reputation among the participating cloud providers. The objective is to form cloud federations with highly reputable cloud providers that achieve maximum profit for their participation. This is an NP-hard bicriteria optimization problem. We introduce a coalitional graph game, called trust-aware cloud federation formation game, to model the cooperation among cloud providers. We design a mechanism for cloud federation formation that enables the cloud providers with high reputation to organize into federations reducing their costs. Our proposed mechanism guarantees the highest profits for the participating cloud providers in the federations, and ensures high reliability of the formed federations in executing the applications. We perform extensive experiments to characterize the properties of the proposed mechanism. The results show that our proposed mechanism produces Pareto optimal and stable cloud federations that not only guarantee that the participating cloud providers have high reputation, but also high individual profits.},
  archive      = {J_TCC},
  author       = {Lena Mashayekhy and Mark M. Nejad and Daniel Grosu},
  doi          = {10.1109/TCC.2019.2911831},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1278-1292},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {A trust-aware mechanism for cloud federation formation},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A power consumption model for cloud servers based on elman
neural network. <em>TCC</em>, <em>9</em>(4), 1268–1277. (<a
href="https://doi.org/10.1109/TCC.2019.2922379">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Leveraging power consumption models in software systems can achieve easy deployment of low-cost, high-availability power monitoring in cloud datacenters that are usually large-scale, heterogeneous and frequently scaling up. However, traditional regression-based power consumption models generally have two drawbacks. First, their mathematical forms are usually fixed and determined a priori. This may cause unacceptable increase of error or over-fitting as the power signatures of cloud servers are usually uncertain. Second, the characteristic of workload dispatched to cloud servers is constantly changing while regression-based models can hardly generalize to a wide range of servers and workload types. As a novel solution, we in this paper propose a server power consumption model based on Elman Neural Network (PCM-ENN), aiming to allow accurate and flexible power estimation. PCM-ENN is an end-to-end black box model capable of learning the temporal relation between samples in a time series of power consumption. We trained and evaluated PCM-ENN on two power sequence datasets collected from heterogeneous hardware and operating systems running quasi-production benchmarks like CloudSuite. Experimental result shows that PCM-ENN generated accurate estimates on server power consumption with only small errors, outperforming widely-used linear regression model and NARX model in terms of accuracy.},
  archive      = {J_TCC},
  author       = {Wentai Wu and Weiwei Lin and Ligang He and Guangxin Wu and Ching-Hsien Hsu},
  doi          = {10.1109/TCC.2019.2922379},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {4},
  pages        = {1268-1277},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {A power consumption model for cloud servers based on elman neural network},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). VFTree: A versatile network architecture for data centers.
<em>TCC</em>, <em>9</em>(3), 1254–1267. (<a
href="https://doi.org/10.1109/TCC.2019.2901462">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a versatile network architecture, named VFTree, for data centers. VFTree provisions unique versatility in the sense that its topology and performance can be tailored with great freedom. The wide dynamic range and fine granularity of its configurations allow this architecture to closely follow the demands of the running traffic. Also, this versatility facilitates the reuse of network devices, so that upgrades could be achieved by rearranging existing devices, avoiding the expenditure on new generations of hardware in each upgrade cycle. Furthermore, this versatility allows VFTree to be elaborately tuned into cost efficient zones. This way, compared to widely adopted industrial solutions including fat-tree, VFTree can provide even higher aggregate bandwidth and richer path availability at the same cost. In this paper, we first design the network topology of VFTree. We parameterize the topology so that it is flexible and generalized. For example, we can configure the numbers of upward and downward ports for the switches, which are fixed in the classic fat-tree. Based on that, we propose routing algorithms, implement the abstraction from packet level to the flow level, and handle the flow collisions. We also analyze VFTree’s performance, demonstrate its aforementioned features, and compare it with its predecessors. VFTree can be seen as a generalization of, and is backward-compatible to fat-tree. We believe it is ready to be deployed in industry, as a perfect replacement of the fat-tree DCNs.},
  archive      = {J_TCC},
  author       = {Jun Duan and Yuanyuan Yang},
  doi          = {10.1109/TCC.2019.2901462},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {1254-1267},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {VFTree: A versatile network architecture for data centers},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SLA-based profit optimization resource scheduling for big
data analytics-as-a-service platforms in cloud computing environments.
<em>TCC</em>, <em>9</em>(3), 1236–1253. (<a
href="https://doi.org/10.1109/TCC.2018.2889956">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The value that can be extracted from big data greatly motivates users to explore data analytics technologies for better decision making and problem solving in various application domains. Analytical solutions can be expensive due to the demand for large-scale and high-performance computing resources. To provision online big data Analytics-as-a-Service (AaaS) to users in various domains, a general purpose AaaS platform is required to deliver on-demand services at low cost and in an easy to use manner. Our research focuses on proposing efficient and automatic admission control and resource scheduling algorithms for AaaS platforms in cloud environments. In this paper, we propose scalable and automatic admission control and profit optimization resource scheduling algorithms, which effectively admit data analytics requests, dynamically provision resources, and maximize profit for AaaS providers, while satisfying QoS requirements of queries with Service Level Agreement (SLA) guarantees. Moreover, the proposed algorithms enable users to trade-off accuracy for faster response times and less resource costs for query processing on large datasets. We evaluate the algorithm performance by adopting a data splitting method to process smaller data samples as representatives of the original big datasets. We conduct extensive experiments to evaluate the proposed admission control and profit optimization scheduling algorithms. Experimental evaluation shows the algorithms perform significantly better compared to the state-of-the-art algorithms in enhancing profits, reducing resource costs, increasing query admission rates, and decreasing query response times.},
  archive      = {J_TCC},
  author       = {Yali Zhao and Rodrigo N. Calheiros and Graeme Gange and James Bailey and Richard O. Sinnott},
  doi          = {10.1109/TCC.2018.2889956},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {1236-1253},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {SLA-based profit optimization resource scheduling for big data analytics-as-a-service platforms in cloud computing environments},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Scheduling of low latency services in softwarized networks.
<em>TCC</em>, <em>9</em>(3), 1220–1235. (<a
href="https://doi.org/10.1109/TCC.2019.2907949">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fifth generation (5G) networks are expected to support diverse business verticals (i.e., manufacturing, health care, etc.) with varying quality of service requirements. While today’s mobile networks are a one size fits all architecture, tomorrow’s 5G mobile networks are envisioned to encourage agility, programmability and elasticity through enabling a software-based architecture promoted by network slicing. Network slicing is a new paradigm consisting of partitioning the underlying network infrastructure into different logical network slices, each dedicated to address the requirements (i.e., ultra-low latency, ultra-reliability, etc.) of a group of services. Network Function Virtualization (NFV) and Software Defined Networking (SDN) technologies have been identified as main enablers of network slicing, facilitating the fulfillment of the aforementioned services’ requirements. In this paper, we study the Latency-Aware service scheduling (LASS) problem to solve the network function mapping, the traffic routing and the network service scheduling in the context of an ultra-low latency network slice to consider services with stringent deadlines. We propose the LASS-Game, a novel game-theoretic approach presenting a scalable solution for the LASS problem that accounts for the centralized aspect of the problem while leveraging a decentralized mapping, routing and scheduling decisions.},
  archive      = {J_TCC},
  author       = {Hyame Assem Alameddine and Mosaddek Hossain Kamal Tushar and Chadi Assi},
  doi          = {10.1109/TCC.2019.2907949},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {1220-1235},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Scheduling of low latency services in softwarized networks},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Quantitative analysis of opacity in cloud computing systems.
<em>TCC</em>, <em>9</em>(3), 1210–1219. (<a
href="https://doi.org/10.1109/TCC.2019.2894768">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated cloud systems increase the reliability and reduce the cost of the computational support. The resulting combination of secure private clouds and less secure public clouds, together with the fact that resources need to be located within different clouds, strongly affects the information flow security of the entire system. In this paper, the clouds as well as entities of a federated cloud system are assigned security levels, and a probabilistic flow sensitive security model for a federated cloud system is proposed. Then the notion of opacity—a notion capturing the security of information flow—of a cloud computing systems is introduced, and different variants of quantitative analysis of opacity are presented. As a result, one can track the information flow in a cloud system, and analyze the impact of different resource allocation strategies by quantifying the corresponding opacity characteristics.},
  archive      = {J_TCC},
  author       = {Wen Zeng and Maciej Koutny},
  doi          = {10.1109/TCC.2019.2894768},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {1210-1219},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Quantitative analysis of opacity in cloud computing systems},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Outsourced decentralized multi-authority attribute based
signature and its application in IoT. <em>TCC</em>, <em>9</em>(3),
1195–1209. (<a href="https://doi.org/10.1109/TCC.2019.2902380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IoT (Internet of things) devices often collect data and store the data in the cloud for sharing and further processing; This collection, sharing, and processing will inevitably encounter secure access and authentication issues. Attribute based signature (ABS), which utilizes the signer’s attributes to generate private keys, plays a competent role in data authentication and identity privacy preservation. In ABS, there are multiple authorities that issue different private keys for signers based on their various attributes, and a central authority is usually established to manage all these attribute authorities. However, one security concern is that if the central authority is compromised, the whole system will be broken. In this paper, we present an outsourced decentralized multi-authority attribute based signature (ODMA-ABS) scheme. The proposed ODMA-ABS achieves attribute privacy and stronger authority-corruption resistance than existing multi-authority attribute based signature schemes can achieve. In addition, the overhead to generate a signature is further reduced by outsourcing expensive computation to a signing cloud server. We present extensive security analysis and experimental simulation of the proposed scheme. We also propose an access control scheme that is based on ODMA-ABS.},
  archive      = {J_TCC},
  author       = {Jiameng Sun and Ye Su and Jing Qin and Jiankun Hu and Jixin Ma},
  doi          = {10.1109/TCC.2019.2902380},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {1195-1209},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Outsourced decentralized multi-authority attribute based signature and its application in IoT},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Online multi-workflow scheduling under uncertain task
execution time in IaaS clouds. <em>TCC</em>, <em>9</em>(3), 1180–1194.
(<a href="https://doi.org/10.1109/TCC.2019.2906300">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud has become an important platform for executing numerous deadline-constrained scientific applications generally represented by workflow models. It provides scientists a simple and cost-efficient method of running workflows on their rental Virtual Machines (VMs) anytime and anywhere. Since pay-as-you-go is a dominating pricing solution in clouds, extensive research efforts have been devoted to minimizing the monetary cost of executing workflows by designing tailored VM allocation mechanisms. However, most of them assume that the task execution time in clouds is static and can be estimated in advance, which is impractical in real scenarios due to performance fluctuation of VMs. In this paper, we propose an onli N e multi-workfl O w S cheduling F ramework, named NOSF, to schedule deadline-constrained workflows with random arrivals and uncertain task execution time. In NOSF, workflow scheduling process consists of three phases, including workflow preprocessing, VM allocation and feedback process. Built upon the new framework, a deadline-aware heuristic algorithm is then developed to elastically provision suitable VMs for workflow execution, with the objective of minimizing the rental cost and improving resource utilization. Simulation results demonstrate that the proposed algorithm significantly outperforms two state-of-the-art algorithms in terms of reducing VM rental costs and deadline violation probability, as well as improving the resource utilization efficiency.},
  archive      = {J_TCC},
  author       = {Jiagang Liu and Ju Ren and Wei Dai and Deyu Zhang and Pude Zhou and Yaoxue Zhang and Geyong Min and Noushin Najjari},
  doi          = {10.1109/TCC.2019.2906300},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {1180-1194},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Online multi-workflow scheduling under uncertain task execution time in IaaS clouds},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On bayesian epistemology of myerson auction. <em>TCC</em>,
<em>9</em>(3), 1172–1179. (<a
href="https://doi.org/10.1109/TCC.2019.2896225">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian Epistemology bases its analysis of the objects under study on a prior, a (jointly known) probability distribution, which is in turn the subject matter in statistical learning, and that of machine learning at least implicitly. Our interests are in data related to bidder behavior in a game theoretical setting where the learner and the owners of data to be learned are affected by each other’s strategies of data reporting and data utilization. More specifically, the learner takes actions according to the probability governing the data distributions. The owners of data may reveal false probability distributions of their private data for their better utilities. We focus on the Myerson auction for such an issue of learning and optimization of the seller who wants to gain information on bidders’ value distributions to achieve the maximum revenue. We study bidders’ best responses against each other. We make a special effort to understand the possibility of truthful reporting of agent value distributions. For cases this is not possible, we study the dynamic properties of bidder value distribution reporting and the convergence toward a local Nash equilibria.},
  archive      = {J_TCC},
  author       = {Xiaotie Deng and Keyu Zhu},
  doi          = {10.1109/TCC.2019.2896225},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {1172-1179},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {On bayesian epistemology of myerson auction},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). New scheduling algorithms for improving performance and
resource utilization in hadoop YARN clusters. <em>TCC</em>,
<em>9</em>(3), 1158–1171. (<a
href="https://doi.org/10.1109/TCC.2019.2894779">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The MapReduce framework has become the defacto scheme for scalable semi-structured and un-structured data processing in recent years. The Hadoop ecosystem has evolved into its second generation, Hadoop YARN, which adopts fine-grained resource management schemes for job scheduling. Nowadays, fairness and efficiency are two main concerns in YARN resource management because resources in YARN are shared and contended by multiple applications. However, the current scheduling in YARN does not yield the optimal resource arrangement, unnecessarily causing idle resources and inefficient scheduling. It omits the dependency between tasks which is extremely crucial for the efficiency of resource utilization as well as heterogeneous job features in real application environments. We thus propose a new YARN scheduler which can effectively reduce the makespan (i.e., the total execution time) of a batch of MapReduce jobs in Hadoop YARN clusters by leveraging the information of requested resources, resource capacities and dependency between tasks. For accommodating heterogeneity in MapReduce jobs, we also extend our scheduler by further considering the job iteration information in the scheduling decisions. We implemented the new scheduling algorithm as a pluggable scheduler in YARN and evaluated it with a set of classic MapReduce benchmarks. The experimental results demonstrate that our YARN scheduler effectively reduces the makespans and improves resource utilizations.},
  archive      = {J_TCC},
  author       = {Yi Yao and Han Gao and Jiayin Wang and Bo Sheng and Ningfang Mi},
  doi          = {10.1109/TCC.2019.2894779},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {1158-1171},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {New scheduling algorithms for improving performance and resource utilization in hadoop YARN clusters},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mobility and dependence-aware QoS monitoring in mobile edge
computing. <em>TCC</em>, <em>9</em>(3), 1143–1157. (<a
href="https://doi.org/10.1109/TCC.2021.3063050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile edge computing is a new computing paradigm that performs computing on the edge of a network. It provides services to users by deploying edge servers near mobile devices. Services may be unavailable or do not satisfy the needs of users due to changing edge environments. Quality of service (QoS) is commonly employed as a critical means to indicate qualitative status of services. It is particularly important to monitor QoS of services timely and effectively in the mobile edge environment. However, user mobility and dependencies among QoS values often cause the monitoring results to deviate from the real results in the mobile edge environment. Existing QoS monitoring approaches have not taken into account these problems. To address the problems, this article proposes ghBSRM-MEC ( G aussian h idden B aye S ian R untime M onitoring for M obile E dge C omputing), a novel mobility and dependence-aware QoS monitoring approach for the mobile edge environment. This approach assumes that the QoS attribute values of edge servers obey Gaussian distribution. It constructs a parent property for each property, thus reducing the dependence between properties. During the training stage, a Gaussian Hidden Bayesian classifier is constructed for each edge server. During the monitoring stage, combining with a KNN algorithm, the classifier is changed dynamically based on user mobility to realize QoS monitoring in the mobile edge environment. The experimental results validate the feasibility, effectiveness, and efficiency of ghBSRM-MEC.},
  archive      = {J_TCC},
  author       = {Pengcheng Zhang and Yaling Zhang and Hai Dong and Huiying Jin},
  doi          = {10.1109/TCC.2021.3063050},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {1143-1157},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Mobility and dependence-aware QoS monitoring in mobile edge computing},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Low latency and high throughput write-ahead logging using
CAPI-flash. <em>TCC</em>, <em>9</em>(3), 1129–1142. (<a
href="https://doi.org/10.1109/TCC.2019.2906613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-velocity data imposes high durability overheads on Big Data technology components such as NoSQL data stores. In Apache Cassandra and MongoDB, widely used NoSQL solutions with high scalability and availability, write-ahead logging is used to provide durability. However, current write-ahead logging techniques are limited by the excessive overhead in the I/O subsystem. To address this performance gap, we have designed a novel CAPI-Flash based high performance durable logging mechanism for Apache Cassandra and MongoDB. We take advantage of the high throughput, low latency path to flash storage provided by the Coherent Accelerator Processor Interface (CAPI) on IBM POWER8 Systems. Our experimental results show that for insert-only workloads, CAPI-Flash logging provides up to 70 and 514 percent improvement in throughput compared to Cassandra and MongoDB’s durable alternatives, respectively. It also provides average of 45 percent increase in throughput with Cassandra and average of 115 percent increase in throughput with MongoDB for update-mostly and update-only workloads.},
  archive      = {J_TCC},
  author       = {Bedri Sendir and Madhusudhan Govindaraju and Rei Odaira and Peter Hofstee},
  doi          = {10.1109/TCC.2019.2906613},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {1129-1142},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Low latency and high throughput write-ahead logging using CAPI-flash},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Key management scheme for secure channel establishment in
fog computing. <em>TCC</em>, <em>9</em>(3), 1117–1128. (<a
href="https://doi.org/10.1109/TCC.2019.2903254">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fog computing is a promising extension of cloud computing, and enables computing directly at the edge of the network. Due to the decentralized and distributed nature of fog nodes, secure communication channels have to be supported in fog computing, which are generally realized through secure keys. Key management schemes are usually employed to generate, distribute and maintain the secret keys. In this paper, we propose a key management scheme called dynamic contributory broadcast encryption (DConBE) for secure channel establishment in fog computing. It allows a group of fog nodes that want to establish a fog system to negotiate a public encryption key and each node’s decryption key in one round without a trusted dealer. Any end user may encrypt messages under the public encryption key with short ciphertexts to any subset of the fog nodes in the system. Only selected fog nodes in the system can decrypt the encrypted messages using their respective decryption key. Our new key management scheme also achieves the properties of fog node dynamics, fully collusion-resistant and stateless.},
  archive      = {J_TCC},
  author       = {Lei Zhang},
  doi          = {10.1109/TCC.2019.2903254},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {1117-1128},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Key management scheme for secure channel establishment in fog computing},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Investigating machine learning algorithms for modeling SSD
i/o performance for container-based virtualization. <em>TCC</em>,
<em>9</em>(3), 1103–1116. (<a
href="https://doi.org/10.1109/TCC.2019.2898192">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the cornerstones of the cloud provider business is to reduce hardware resources cost by maximizing their utilization. This is done through smartly sharing processor, memory, network and storage, while fully satisfying SLOs negotiated with customers. For the storage part, while SSDs are increasingly deployed in data centers mainly for their performance and energy efficiency, their internal mechanisms may cause a dramatic SLO violation. In effect, we measured that I/O interference may induce a 10x performance drop. We are building a framework based on autonomic computing which aims to achieve intelligent container placement on storage systems by preventing bad I/O interference scenarios. One prerequisite to such a framework is to design SSD performance models that take into account interactions between running processes/containers, the operating system and the SSD. These interactions are complex. In this paper, we investigate the use of machine learning for building such models in a container based Cloud environment. We have investigated five popular machine learning algorithms along with six different I/O intensive applications and benchmarks. We analyzed the prediction accuracy, the learning curve, the feature importance and the training time of the tested algorithms on four different SSD models. Beyond describing modeling component of our framework, this paper aims to provide insights for cloud providers to implement SLO compliant container placement algorithms on SSDs. Our machine learning-based framework succeeded in modeling I/O interference with a median Normalized Root-Mean-Square Error (NRMSE) of 2.5 percent.},
  archive      = {J_TCC},
  author       = {Jean-Emile Dartois and Jalil Boukhobza and Anas Knefati and Olivier Barais},
  doi          = {10.1109/TCC.2019.2898192},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {1103-1116},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Investigating machine learning algorithms for modeling SSD I/O performance for container-based virtualization},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hybrid resource provisioning for cloud workflows with
malleable and rigid tasks. <em>TCC</em>, <em>9</em>(3), 1089–1102. (<a
href="https://doi.org/10.1109/TCC.2019.2894836">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In cloud computing, reserved and on-demand instances are generally provided by service providers. Hybridization of the two alternatives can considerably save costs when renting resources from the cloud. However, it is a big challenge to determine the appropriate amount of reserved and on-demand resources in terms of users’ requirements. In this paper, the workflow scheduling problem with both reserved and on-demand instances is considered. The objective is to minimize the total rental cost under deadline constrains. The considered problem is mathematically modeled. A multiple sequence-based earliest finish time method is proposed to construct schedules for the workflows. Four different rules are used to generate initial task allocation sequences. Types and quantities of resources are determined by a free time block-based schedule construction mechanism. New sequences are generated by a variable neighborhood search method. Experimental and statistical analyses and results demonstrate that the proposed algorithm algorithm generates considerable cost savings when compared to the algorithms with only on-demand or reserved instances.},
  archive      = {J_TCC},
  author       = {Long Chen and Xiaoping Li and Yucheng Guo and Rubén Ruiz},
  doi          = {10.1109/TCC.2019.2894836},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {1089-1102},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Hybrid resource provisioning for cloud workflows with malleable and rigid tasks},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evaluating distributed computing infrastructures: An
empirical study comparing hadoop deployments on cloud and local systems.
<em>TCC</em>, <em>9</em>(3), 1075–1088. (<a
href="https://doi.org/10.1109/TCC.2019.2902377">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The popularity of distributed computing platforms (e.g., Hadoop) is largely due to their ability to address scalability issues that arise from data storage and processing limitations of standard computing systems. However, the decision to dedicate organizational resources and capital for such systems needs a careful consideration of several factors including evaluation of cloud-based distributed computing options. We propose a framework of metrics which we used to conduct an in-depth performance and cost benefit analysis of two standard Hadoop infrastructural choices, i.e., a Platform as a Service ( PaaS ) on-demand cloud setup and a local organizational setup. We evaluated the framework by means of an exploratory data analysis use-case for a large-scale graph processing research problem. Our analysis considered highly granular aspects of distributed computing performance and studied how utilization rates and infrastructure amortization times affect break-even times. We identified that virtual memory management adversely affects the performance of a cloud cluster during the reduce phase with the magnitude of degradation dependent on the type of MapReduce operation. Our study is intended not only as an evaluation of infrastructural choices but also a development of a metric framework that can serve as a baseline for researchers examining distributed infrastructures.},
  archive      = {J_TCC},
  author       = {Devipsita Bhattacharya and Faiz Currim and Sudha Ram},
  doi          = {10.1109/TCC.2019.2902377},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {1075-1088},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Evaluating distributed computing infrastructures: An empirical study comparing hadoop deployments on cloud and local systems},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Enhancing reliability and availability through redundancy in
vehicular clouds. <em>TCC</em>, <em>9</em>(3), 1061–1074. (<a
href="https://doi.org/10.1109/TCC.2019.2905590">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The past eight years have seen the emergence of vehicular clouds as a topic of research in its own right. Vehicular clouds were inspired by the insight that present-day vehicles feature an impressive array of on-board compute, storage and sensing capabilities. These on-board capabilities are a vast untapped resource that, at the moment, is wasted. One of the defining ways in which vehicular clouds differ from conventional clouds is resource volatility. As vehicles enter and leave the cloud, new compute resources become available while others depart, creating a volatile environment where the tasks of enhancing reliability and availability become very challenging. It is intuitively clear that the longer and more predictable the vehicle residency times in the cloud are, the easier it is to ensure reliability and system availability. In this work we look at vehicular clouds with short and unpredictable vehicular residency times. We propose to enhance the reliability and availability of these types of vehicular clouds through a family of redundancy-based job assignment strategies that attempt to mitigate the effect of resource volatility. We offer a theoretical prediction of the Mean Time To Failure (MTTF) of these strategies. We also show how to fine-tune the granularity of the redundancy in order to meet QoS requirements specified in terms of a minimum MTTF for a given user job. Extensive simulations, using vehicle residency data derived from shopping mall statistics, have confirmed the accuracy of our analytical predictions.},
  archive      = {J_TCC},
  author       = {Ryan Florin and Aida Ghazizadeh and Puya Ghazizadeh and Stephan Olariu and Dan C. Marinescu},
  doi          = {10.1109/TCC.2019.2905590},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {1061-1074},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Enhancing reliability and availability through redundancy in vehicular clouds},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Energy efficient dynamic offloading in mobile edge
computing for internet of things. <em>TCC</em>, <em>9</em>(3),
1050–1060. (<a href="https://doi.org/10.1109/TCC.2019.2898657">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With proliferation of computation-intensive Internet of Things (IoT) applications, the limited capacity of end devices can deteriorate service performance. To address this issue, computation tasks can be offloaded to the Mobile Edge Computing (MEC) for processing. However, it consumes considerable energy to transmit and process these tasks. In this paper, we study the energy efficient task offloading in MEC. Specifically, we formulate it as a stochastic optimization problem, with the objective of minimizing the energy consumption of task offloading while guaranteeing the average queue length. Solving this offloading optimization problem faces many technical challenges due to the uncertainty and dynamics of wireless channel state and task arrival process, and the large scale of solution space. To tackle these challenges, we apply stochastic optimization techniques to transform the original stochastic problem into a deterministic optimization problem, and propose an energy efficient dynamic offloading algorithm called EEDOA. EEDOA can be implemented in an online manner to make the task offloading decisions with polynomial time complexity. Theoretical analysis is provided to demonstrate that EEDOA can approximate the minimal transmission energy consumption while still bounding the queue length. Experiment results are presented which show the EEDOA’s effectiveness.},
  archive      = {J_TCC},
  author       = {Ying Chen and Ning Zhang and Yongchao Zhang and Xin Chen and Wen Wu and Xuemin Shen},
  doi          = {10.1109/TCC.2019.2898657},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {1050-1060},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Energy efficient dynamic offloading in mobile edge computing for internet of things},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Empirical investigation of key factors for SaaS
architecture. <em>TCC</em>, <em>9</em>(3), 1037–1049. (<a
href="https://doi.org/10.1109/TCC.2019.2906299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software-as-a-Service (SaaS) has received significant attention from software providers and users as a software delivery model. Most of the existing companies are transferring their business into a SaaS model. This intensely competitive environment has imposed many challenges for SaaS developers and vendors. SaaS development is a very complex process and SaaS success depends on its architecture design and development. This paper provides a better understanding of SaaS applications architecture phase during the SaaS development process. It focuses mainly on an empirical investigation of key factors of SaaS Architecture phase identified from the systematic literature review. A quantitative survey was developed and conducted to identify key architecture factors for an improved and successful SaaS application. A developed survey was used to test the proposed hypothesis presented in this study. Empirical investigation&#39;s results provide evidence that vendors and developers must consider key architecture factors for SaaS development process to stand in the current competitive environment. These key factors include customization, scalability, MTA (Multi-Tenancy Architecture), security, integration, and fault tolerance and recovery management. The main contribution of this paper is to investigate empirically the influence of identified key factors of the architecture on SaaS applications success.},
  archive      = {J_TCC},
  author       = {Saiqa Aleem and Faheem Ahmed and Rabia Batool and Asad Khattak},
  doi          = {10.1109/TCC.2019.2906299},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {1037-1049},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Empirical investigation of key factors for SaaS architecture},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Elephant flow detection and load-balanced routing with
efficient sampling and classification. <em>TCC</em>, <em>9</em>(3),
1022–1036. (<a href="https://doi.org/10.1109/TCC.2019.2901669">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {SDN (Software defined networking) provides effective technical methods for optimal resource management. However, there are resource conflicts frequent and serious in current related schemes because they mix elephant and mice flows on shared transmission paths. So, controllers in SDN have to be smart enough to detect elephant flows with low cost and then reroute elephant and mice flows in a feature-aware way. However, existing elephant flow detection schemes suffer from high bandwidth consumption and long detection time; and little literature considers mice-flow scheduling. In this paper, we propose an Efficient Sampling and Classification Approach (ESCA). Our ESCA significantly reduces sampling overhead through estimating the arrival interval of elephant flows and filtering out redundant samples, and efficiently classifies samples with a new supervised classification algorithm based on correlations among data flows. Then, based on our low-cost ESCA, we propose a novel load-balanced routing approach LBRouting that sets up paths for elephant and mice flows with different mechanisms. The theoretical analysis proofs our ESCA outperforms related schemes. Extensive experiment results further demonstrate that our ESCA can provide accurate detection with less sampled packets and shorter detection time; and our routing approach LBRouting significantly outperforms related proposals.},
  archive      = {J_TCC},
  author       = {Feilong Tang and Heteng Zhang and Laurence T. Yang and Long Chen},
  doi          = {10.1109/TCC.2019.2901669},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {1022-1036},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Elephant flow detection and load-balanced routing with efficient sampling and classification},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient and green embedding of virtual data centers with
mixture of unicast and multicast services. <em>TCC</em>, <em>9</em>(3),
1008–1021. (<a href="https://doi.org/10.1109/TCC.2019.2897273">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The improved efficiency achieved by virtualizing data centers (DCs) has been well established. In this paper, we propose a mixed Virtual Data Center (VDC) capable of supporting both unicast and multicast services. We provide a new method to realize the embedding of these VDCs. We also provide a Mixed Integer Linear Programming (MILP) formulation and a scalable heuristic algorithm for efficiently embedding its demands. Numerical results show that mixed VDC embedding supporting both unicast and multicast services performs significantly better than existing embedding methods in terms of system cost, power consumption, link capacity utilization, and VDC acceptance ratio.},
  archive      = {J_TCC},
  author       = {Chao Guo and Kai Xu and Sanjay Kumar Bose and Moshe Zukerman and Gangxiang Shen},
  doi          = {10.1109/TCC.2019.2897273},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {1008-1021},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Efficient and green embedding of virtual data centers with mixture of unicast and multicast services},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic resource management to defend against advanced
persistent threats in fog computing: A game theoretic approach.
<em>TCC</em>, <em>9</em>(3), 995–1007. (<a
href="https://doi.org/10.1109/TCC.2019.2896632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fog computing has gained tremendous popularity due to its capability of addressing the surging demand on high-quality ubiquitous mobile services. Nevertheless, the highly virtualized environment in fog computing leads to vulnerability to cyber attacks such as advanced persistent threats. In this paper, we propose a novel game approach of cyber risk management for the fog computing platform. We adopt the cyber-insurance concept to transfer cyber risks from fog computing platform to a third party. The system model under consideration consists of three main entities, i.e., the fog computing provider, attacker, and cyber-insurer. The fog computing provider dynamically optimizes the allocation of its defense computing resources to improve the security of the fog computing platform which is composed of multiple fog nodes. Meanwhile, the attacker dynamically adjusts the allocation of its attack computing resources to increase the probability of successful attack. Additionally, to prevent from the potential loss due to the attacks, the provider also makes a dynamic decision on the subscription of cyber-insurance for each fog node. Thereafter, the cyber-insurer accordingly determines the premium of cyber-insurance for each fog node. To model this dynamic interactive decision making problem, we formulate a dynamic Stackelberg game. In the lower-level, we formulate an evolutionary subgame to analyze the provider&#39;s defense and cyber-insurance subscription strategies as well as the attacker&#39;s attack strategy. In the upper-level, the cyber-insurer optimizes its premium strategy, taking into account the evolutionary equilibrium at the lower-level evolutionary subgame. We analytically prove that the evolutionary equilibrium is unique and stable, and we investigate the Stackelberg equilibrium by capitalizing on tools from the optimal control theory. Moreover, we provide a series of insightful analytical and numerical results on the equilibrium of the dynamic Stackelberg game.},
  archive      = {J_TCC},
  author       = {Shaohan Feng and Zehui Xiong and Dusit Niyato and Ping Wang},
  doi          = {10.1109/TCC.2019.2896632},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {995-1007},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Dynamic resource management to defend against advanced persistent threats in fog computing: A game theoretic approach},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic cloud resource allocation considering demand
uncertainty. <em>TCC</em>, <em>9</em>(3), 981–994. (<a
href="https://doi.org/10.1109/TCC.2019.2897304">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing provisions scalable resources for high performance industrial applications. Cloud providers usually offer two types of usage plans: reserved and on-demand. Reserved plans offer cheaper resources for long-term contracts while on-demand plans are available for short or long periods but are more expensive. To satisfy incoming user demands with reasonable costs, cloud resources should be allocated efficiently. Most existing works focus on either cheaper solutions with reserved resources that may lead to under-provisioning or over-provisioning, or costly solutions with on-demand resources. Since inefficiency of allocating cloud resources can cause huge provisioning costs and fluctuation in cloud demand, resource allocation becomes a highly challenging problem. In this paper, we propose a hybrid method to allocate cloud resources according to the dynamic user demands. This method is developed as a two-phase algorithm that consists of reservation and dynamic provision phases. In this way, we minimize the total deployment cost by formulating each phase as an optimization problem while satisfying quality of service. Due to the uncertain nature of cloud demands, we develop a stochastic optimization approach by modeling user demands as random variables. Our algorithm is evaluated using different experiments and the results show its efficiency in dynamically allocating cloud resources.},
  archive      = {J_TCC},
  author       = {Seyedehmehrnaz Mireslami and Logan Rakai and Mea Wang and Behrouz Homayoun Far},
  doi          = {10.1109/TCC.2019.2897304},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {981-994},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Dynamic cloud resource allocation considering demand uncertainty},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cost-efficient resource provisioning for dynamic requests in
cloud assisted mobile edge computing. <em>TCC</em>, <em>9</em>(3),
968–980. (<a href="https://doi.org/10.1109/TCC.2019.2903240">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile edge computing is emerging as a new computing paradigm that provides enhanced experience to mobile users via low latency connections and augmented computation capacity. As the amount of user requests is time-varying, while the computation capacity of edge hosts is limited, Cloud Assisted Mobile Edge (CAME) computing framework is introduced to improve the scalability of the edge platform. By outsourcing mobile requests to clouds with various types of instances, the CAME framework can accommodate dynamic mobile requests with diverse quality of service requirements. In order to provide guaranteed services at minimal system cost, the edge resource provisioning and cloud outsourcing of the CAME framework should be carefully designed in a cost-efficient manner. Specifically, two fundamental issues should be answered: (1) what is the optimal edge computation capacity configuration? and (2) what types of cloud instances should be tenanted and what is the amount of each type? To solve these issues, we formulate the resource provisioning in CAME framework as an optimization problem. By exploiting the piecewise convex property of this problem, the Optimal Resource Provisioning (ORP) algorithms with different instances are proposed, so as to optimize the computation capacity of edge hosts and meanwhile dynamically adjust the cloud tenancy strategy. The proposed algorithms are proved to be with polynomial computational complexity. To evaluate the performance of the ORP algorithms, extensive simulations and experiments are conducted based on both the widely-used traffic models and the Google cluster usage tracelogs, respectively. It is shown that the proposed ORP algorithms outperform the local-first and cloud-first benchmark algorithms in system flexibility and cost-efficiency.},
  archive      = {J_TCC},
  author       = {Xiao Ma and Shangguang Wang and Shan Zhang and Peng Yang and Chuang Lin and Xuemin Shen},
  doi          = {10.1109/TCC.2019.2903240},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {968-980},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Cost-efficient resource provisioning for dynamic requests in cloud assisted mobile edge computing},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Computing-aware base station sleeping mechanism in
h-CRAN-cloud-edge networks. <em>TCC</em>, <em>9</em>(3), 958–967. (<a
href="https://doi.org/10.1109/TCC.2019.2893228">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a power minimization problem using base station sleeping is proposed for heterogeneous cloud radio access networks (H-CRANs) taking into account the computing delay constraints. In the proposed system, which is modeled using M/M/k queues, the edge device coexists with the small base station (SBS) to provide computing capabilities beside the central cloud. In general, the SBS sleeping is governed by the availability of resources provided the macro base station (MBS) which is in charge of accommodating offloaded users from sleeping SBSs. However, switching off lightly loaded SBSs can impose significant burdens on cloud servers. Here, the proposed sleeping scheme allows SBSs serving more computing tasks to remain active in order to fulfill the task completion deadlines requested by mobile users and to keep the cloud response time within a predefined limit. In other words, the proposed scheme aims to save power by undertaking a centralized selection of active and sleeping SBSs taking into account the delay constraints of both cloud and mobile devices. First, we consider a disjoint cloud-edge system, where computing services can be provided by either the cloud or the edge device, and aim to minimize the number of active SBSs. The problem is formulated as a 0-1 knapsack problem with SBS utilization considered as the weight while the ratio of computing tasks to all incoming tasks is considered as the value of that SBS. In this problem, which is solved using dynamic programming, SBSs processing less computing tasks are given higher values; and as a result, higher chance to sleep compared to others. Second, a shared computing system is proposed whereby active SBSs (edge devices) contribute to the total computing capability. Here, an exhaustive search approach is used to achieve the optimal power saving. We also proved that the shared computing system performs better in terms of response time compared to the disjoint system depending on the number of active SBSs.},
  archive      = {J_TCC},
  author       = {Ali Alnoman and Alagan Anpalagan},
  doi          = {10.1109/TCC.2019.2893228},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {958-967},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Computing-aware base station sleeping mechanism in H-CRAN-cloud-edge networks},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). CloudCFI: Context-sensitive and incremental CFI in the cloud
environment. <em>TCC</em>, <em>9</em>(3), 938–957. (<a
href="https://doi.org/10.1109/TCC.2019.2902384">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Control-Flow Integrity (CFI) is one of the most promising techniques against control-flow hijacking attacks. For Commercial Off-the-Shelf (COTS) binaries, a number of solutions provide coarse-grained CFI and thus are context-insensitive, while having the benefit of introducing a low runtime overhead. However, they can hardly defend against elaborately designed attacks due to the inaccuracy of the Control-Flow Graphs (CFGs). This paper presents CloudCFI , a context-sensitive and incremental CFI, which specifically makes full use of the characteristic of the cloud environment, where multiple instances of a software run on multiple virtual machines, and the control flow checking result from one software instance could be utilized to handle the control-hijacking occurred on other sibling instances. In CloudCFI , the accuracy of the control flow checking can be continuously increased to offer the incremental CFI, and a context-sensitive CFI policy is enforced to determine the validity of the control flow of the execution path through checking the entire execution path instead of the single edge or partial edges in the execution path. CloudCFI includes the static phase and the runtime phase respectively. Control-flow information and basic-block information is collected through emulation execution in the static phase, and the execution paths are tracked in runtime phase to collect process-tracking information. Next, it recovers the execution path by using basic-block information and process-tracking information, and checks the validity of the control flow by using the control-flow information. A prototype system is implemented and evaluated from several aspects using RIPE and SPEC benchmarks, as well as real-world cloud applications, Memcached and Redis. The evaluation results show that CloudCFI can defend against most common control-flow hijacking attacks. Meanwhile, it only introduces a low runtime performance overhead.},
  archive      = {J_TCC},
  author       = {Weizhong Qiang and Yingda Huang and Hai Jin and Laurence T. Yang and Deqing Zou},
  doi          = {10.1109/TCC.2019.2902384},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {938-957},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {CloudCFI: Context-sensitive and incremental CFI in the cloud environment},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Blockchain-based public integrity verification for cloud
storage against procrastinating auditors. <em>TCC</em>, <em>9</em>(3),
923–937. (<a href="https://doi.org/10.1109/TCC.2019.2908400">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The deployment of cloud storage services has significant benefits in managing data for users. However, it also causes many security concerns, and one of them is data integrity. Public verification techniques can enable a user to employ a third-party auditor to verify the data integrity on behalf of her/him, whereas existing public verification schemes are vulnerable to procrastinating auditors who may not perform verifications on time. Furthermore, most of public verification schemes are constructed on the public key infrastructure (PKI), and thereby suffer from certificate management problem. In this paper, we propose a c ertificateless p ublic v erification scheme against p rocrastinating a uditors (CPVPA) by using blockchain technology . The key idea is to require auditors to record each verification result into a transaction on a blockchain. Because transactions on the blockchain are time-sensitive, the verification can be time-stamped after the transaction is recorded into the blockchain, which enables users to check whether auditors perform the verifications at the prescribed time. Moreover, CPVPA is built on certificateless cryptography, and is free from the certificate management problem. We present rigorous security proofs to demonstrate the security of CPVPA, and conduct a comprehensive performance evaluation to show that CPVPA is efficient.},
  archive      = {J_TCC},
  author       = {Yuan Zhang and Chunxiang Xu and Xiaodong Lin and Xuemin Shen},
  doi          = {10.1109/TCC.2019.2908400},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {923-937},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Blockchain-based public integrity verification for cloud storage against procrastinating auditors},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Architectural protection of trusted system services for SGX
enclaves in cloud computing. <em>TCC</em>, <em>9</em>(3), 910–922. (<a
href="https://doi.org/10.1109/TCC.2019.2892449">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data security and privacy are of great concern for users of cloud computing. In order to provide such guarantees in public clouds, hardware manufacturers have designed trusted execution environments such as Intel’s Software Guard eXtensions (SGX). Intel SGX supports privacy-preserving, tamper-proof containments called enclaves. Regrettably, an SGX enclave has to rely on the untrusted operating system or hypervisor for underlying services, which contradicts the threat model of Intel SGX. Whereas much of the previous work concentrates on protecting trusted applications by means of modifying a hypervisor, we tackle the problem by reusing existing drivers and leveraging processor-enforced protection. We propose a novel approach, named SMK, to provide trusted system services for SGX enclaves. SMK leverages existing Intel architecture features, i.e., System Management Mode (SMM) and Uniform Extensible Firmware Interface (UEFI). Specifically, we retrofit UEFI firmware and design an isolated micro-kernel inside SMM to securely provision critical system services for enclaves. To highlight the effectiveness and extensibility of SMK, we implement two system services: trusted clock and trusted network. Furthermore, we harden two real-world security-sensitive applications, OpenSSL and OpenVPN, with SMK’s system services. Our evaluation indicates that SMK can supply trusted system services for enclaves with modest runtime overheads.},
  archive      = {J_TCC},
  author       = {Hongliang Liang and Mingyu Li and Yixiu Chen and Tianqi Yang and Zhuosi Xie and Lin Jiang},
  doi          = {10.1109/TCC.2019.2892449},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {910-922},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Architectural protection of trusted system services for SGX enclaves in cloud computing},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient approach based on ant colony optimization and
tabu search for a resource embedding across multiple cloud providers.
<em>TCC</em>, <em>9</em>(3), 896–909. (<a
href="https://doi.org/10.1109/TCC.2019.2904227">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In cloud computing, a fundamental management problem with the Infrastructure as a Service (IaaS) model lies in the efficient embedding of computational and networking resources onto distributed virtualized infrastructures owned by independent cloud providers (CPs). In such a context, this issue usually referred to as the Virtual Network Embedding (VNE) problem, adds more complexity since the entire embedding process requires two mayor phases of operation: the multicloud virtual network requests (VNRs) splitting, followed by the intracloud VNR segments mapping. This paper focuses on the splitting phase problem, by proposing a VNRs splitting strategy formalized as an Integer Linear Program (ILP) model, with the objective of improving the performance and QoS of resulting mapped VNR segments, while minimizing the resource provisioning expenditures. As the VNE is classified as an NP-hard problem, a hybrid metaheuristic approach based on the Ant Colony Optimization (ACO) combined with the Tabu Search (TS) as local search operator, is proposed in order to find good feasible solutions in reasonable time. The simulation results show the efficiency of the proposed approach, which generates, in a highly reduced computing time, solution costs very close to the exact solution, with an average cost gap ranging from 0 percent to a maximum of 3.42 percent.},
  archive      = {J_TCC},
  author       = {Marieme Diallo and Alejandro Quintero and Samuel Pierre},
  doi          = {10.1109/TCC.2019.2904227},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {896-909},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {An efficient approach based on ant colony optimization and tabu search for a resource embedding across multiple cloud providers},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A two-stage auction mechanism for cloud resource allocation.
<em>TCC</em>, <em>9</em>(3), 881–895. (<a
href="https://doi.org/10.1109/TCC.2019.2901785">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The contemporary literature on cloud resource allocation is mostly focused on studying the interactions between customers and cloud managers. Nevertheless, the recent growth in the customers’ demands and the emergence of private cloud providers (CPs) entice the cloud managers to rent extra resources from the CPs so as to handle their backlogged tasks and attract more customers. This also renders the interactions between the cloud managers and the CPs an important problem to study. In this paper, we investigate both interactions through a two-stage auction mechanism. For the interactions between customers and cloud managers, we adopt the options-based sequential auctions (OBSAs) to design the cloud resource allocation paradigm. As compared to existing works, our framework can handle customers with heterogeneous demands, provide truthfulness as the dominant strategy, enjoy a simple winner determination procedure, and preclude the delayed entrance issue. We also provide the performance analysis of the OBSAs, which is among the first in literature. Regarding the interactions between cloud managers and CPs, we propose two parallel markets for resource gathering, and capture the selfishness of the CPs by their offered prices . We conduct a comprehensive analysis of the two markets and identify the bidding strategies of the cloud managers.},
  archive      = {J_TCC},
  author       = {Seyyedali Hosseinalipour and Huaiyu Dai},
  doi          = {10.1109/TCC.2019.2901785},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {881-895},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {A two-stage auction mechanism for cloud resource allocation},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A streaming cloud platform for real-time video processing on
embedded devices. <em>TCC</em>, <em>9</em>(3), 868–880. (<a
href="https://doi.org/10.1109/TCC.2019.2894621">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time intelligent video processing on embedded devices with low power consumption can be useful for applications like drone surveillance, smart cars, and more. However, the limited resources of embedded devices is a challenging issue for effective embedded computing. Most of the existing work on this topic focuses on single device based solutions, without the use of cloud computing mechanisms for parallel processing to boost performance. In this paper, we propose a cloud platform for real-time video processing based on embedded devices. Eight NVIDIA Jetson TX1 and three Jetson TX2 GPUs are used to construct a streaming embedded cloud platform (SECP), on which Apache Storm is deployed as the cloud computing environment for deep learning algorithms (Convolutional Neural Networks - CNNs) to process video streams. Additionally, self-managing services are designed to ensure that this platform can run smoothly and stably, in the form of a metric sensor, a bottleneck detector and a scheduler. This platform is evaluated in terms of processing speed, power consumption, and network throughput by running various deep learning algorithms for object detection. The results show the proposed platform can run deep learning algorithms on embedded devices while meeting the high scalability and fault tolerance required for real-time video processing.},
  archive      = {J_TCC},
  author       = {Weishan Zhang and Haoyun Sun and Dehai Zhao and Liang Xu and Xin Liu and Huansheng Ning and Jiehan Zhou and Yi Guo and Su Yang},
  doi          = {10.1109/TCC.2019.2894621},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {868-880},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {A streaming cloud platform for real-time video processing on embedded devices},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A game-theoretic framework for the virtual machines
migration timing problem. <em>TCC</em>, <em>9</em>(3), 854–867. (<a
href="https://doi.org/10.1109/TCC.2019.2905605">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a multi-tenant cloud, a number of Virtual Machines (VMs) are collocated on the same physical machine to optimize performance, power consumption and maximize profit. This, however, increases the risk of a malicious VM performing side-channel attacks and leaking sensitive information from neighboring VMs. As such, this paper develops and analyzes a game-theoretic framework for the VM migration timing problem in which the cloud provider decides when to migrate a VM to a different physical machine to reduce the risk of being compromised by a collocated malicious VM. The adversary decides the rate at which she launches new VMs to collocate with the victim VMs. Our formulation captures a data leakage model in which the cost incurred by the cloud provider depends on the duration of collocation with malicious VMs. It also captures costs incurred by the adversary in launching new VMs and by the defender in migrating VMs. We establish sufficient conditions for the existence of Nash equilibria for general cost functions, as well as for specific instantiations, and characterize the best response for both players. Furthermore, we extend our model to characterize its impact on the attacker’s payoff when the cloud utilizes intrusion detection systems that detect side-channel attacks. Our theoretical findings are corroborated with extensive numerical results in various settings as well as a proof-of-concept implementation in a realistic cloud setting.},
  archive      = {J_TCC},
  author       = {Ahmed H. Anwar and George Atia and Mina Guirguis},
  doi          = {10.1109/TCC.2019.2905605},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {854-867},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {A game-theoretic framework for the virtual machines migration timing problem},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A game-based thermal-aware resource allocation strategy for
data centers. <em>TCC</em>, <em>9</em>(3), 845–853. (<a
href="https://doi.org/10.1109/TCC.2019.2899310">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data centers (DC) host a large number of servers, computing devices and computing infrastructure, which incur significant electricity / energy. This also results in huge amount of heat produced, which if not addressed can lead to overheating of computing devices in the DC. In addition, temperature mismanagement can lead to thermal imbalance within the DC environment, which may result in the creation of hotspots. The energy consumed during the life of a hotspot is greater than the energy saved during computation. Hence, the thermal imbalance impacts on the efficiency of the cooling mechanism installed inside the DC, which can result in high energy consumption. One popular strategy to minimize energy consumption is to optimize resource allocation within the DC. However, existing scheduling strategies do not consider the ambient effect of the surrounding nodes at the time of job allocation. Moreover, thermal-aware resource scheduling as an optimization problem is a topic that is relatively understudied in the literature. Therefore, in this research, we propose a novel Game-based Thermal-Aware Resource Allocation (GTARA) strategy to reduce the thermal imbalances within the DC. Specifically, we use cooperative game theory with a Nash-bargaining solution concept to model the resource allocation as an optimization problem, where the user jobs are assigned to the computing nodes based on their thermal profiles and their potential effect on the surrounding nodes. This allows us to improve the thermal balance and avoid the hotspots. We then demonstrate the effectiveness of GTARA, TACS, TASA, and FCFS, in terms of minimizing thermal imbalance and the hotspots.},
  archive      = {J_TCC},
  author       = {Saeed Akbar and Saif Ur Rehman Malik and Kim-Kwang Raymond Choo and Samee U. Khan and Naveed Ahmad and Adeel Anjum},
  doi          = {10.1109/TCC.2019.2899310},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {3},
  pages        = {845-853},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {A game-based thermal-aware resource allocation strategy for data centers},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Correction to “an efficient and secured framework for
mobile cloud computing.” <em>TCC</em>, <em>9</em>(2), 844. (<a
href="https://doi.org/10.1109/TCC.2021.3066023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Presents corrections to author affiliation information in the above named paper.},
  archive      = {J_TCC},
  author       = {Ibrahim A. Elgendy and Wei-Zhe Zhang and Chuan-Yi Liu and Ching-Hsien Hsu},
  doi          = {10.1109/TCC.2021.3066023},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {844},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Correction to “An efficient and secured framework for mobile cloud computing”},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Virtual network recognition and optimization in SDN-enabled
cloud environment. <em>TCC</em>, <em>9</em>(2), 834–843. (<a
href="https://doi.org/10.1109/TCC.2018.2871118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing is a scalable and efficient technology for providing different services. For better reconfigurability and other purposes, users build virtual networks in cloud environments. Since some applications bring heavy pressure to cloud datacenter networks, it is necessary to recognize and optimize virtual networks with different applications. In some cloud environments, cloud providers are not allowed to monitor user private information in cloud instances. Therefore, in this paper, we present a virtual network recognition and optimization method to improve quality-of-service (QoS) of cloud services. We first introduce a community detection method to recognize virtual networks from the cloud datacenter network. Then, we design a scheduling strategy by combining SDN-based network management and instance placement to improve the service-level agreements (SLA) fulfillment. Our experimental result shows that we can achieve a recognition accuracy as high as 80 percent to find out the virtual networks, and the scheduling strategy increases the number of SLA fulfilled virtual networks.},
  archive      = {J_TCC},
  author       = {He Li and Kaoru Ota and Mianxiong Dong},
  doi          = {10.1109/TCC.2018.2871118},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {834-843},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Virtual network recognition and optimization in SDN-enabled cloud environment},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). User association in cloud RANs with massive MIMO.
<em>TCC</em>, <em>9</em>(2), 821–833. (<a
href="https://doi.org/10.1109/TCC.2018.2867224">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies a resource allocation problem where a set of users within a specific region is served by cloud radio access network (C-RAN) structure consisting of a set of base-band units (BBUs) connected to a set of radio remote heads (RRHs) equipped with a large number of antennas via limited capacity front-haul links. User association to each RRH, BBU and front-haul link is essential to achieve high rates for cell-edge users under network limitations. We introduce two types of optimization variables to formulate this resource allocation problem: (i) C-RAN user association factor (UAF) including RRH, BBU and front-haul allocation for each user and (ii) power allocation vector. The formulated optimization problem is non-convex with high computational complexity. An efficient two-level iterative approach is proposed. The higher level consists of two steps where, in each step, one of these two optimization variables is fixed to derive the other. At the lower level, by applying different transformations and convexification techniques, the optimization problem in each step is broken down into a sequence of geometric programming (GP) problems to be solved by the successive convex approximation (SCA). Simulation results reveal the effectiveness of the proposed approach to increase the total throughput of network, specifically for cell-edge users. It outperforms the traditional user association approach, in which, each user is first assigned to the RRH with the largest average value of signal strength, and then, based on this fixed user association, front-haul link association and power allocation are optimized.},
  archive      = {J_TCC},
  author       = {Saeedeh Parsaeefard and Vikas Jumba and Atoosa Dalili Shoaei and Mahsa Derakhshani and Tho Le-Ngoc},
  doi          = {10.1109/TCC.2018.2867224},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {821-833},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {User association in cloud RANs with massive MIMO},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Two-aggregator topology optimization using single paths in
data center networks. <em>TCC</em>, <em>9</em>(2), 807–820. (<a
href="https://doi.org/10.1109/TCC.2018.2885053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the data aggregation problem to two aggregators in a data center network under the constraint that each source rack must use a single path to each aggregator. We derive bounds on the approximation ratios of two classes of aggregation algorithms- Restricted 1-Round (R1R) and Restricted 2-Round (R2R). We achieve tighter bounds for the problem with additional constraints on the inputs. We propose another strategy using the 2Chain topology for k = 2, where k denotes the maximum degree of each top-of-rack(ToR) switch (number of uplinks in a ToR switch) in the data center and show that the optimal 2Chain cannot have an aggregation time greater than that of the optimal R1R and R2R topologies. For k ≥ 4, we propose a 1-round aggregation algorithm (1R) that uses trees for aggregation. Experimental results illustrate that 1R, R2R and R1R reduce the aggregation time by up to 85, 67 and 67 percent respectively for k = 4 relative to the two-round aggregation algorithm proposed by Wang et al. Moreover, for k = 2, the 2Chain can reduce the aggregation time up to 42 and 24 percent respectively relative to R1R and R2R.},
  archive      = {J_TCC},
  author       = {Soham Das and Sartaj Sahni},
  doi          = {10.1109/TCC.2018.2885053},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {807-820},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Two-aggregator topology optimization using single paths in data center networks},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Threat-specific security risk evaluation in the cloud.
<em>TCC</em>, <em>9</em>(2), 793–806. (<a
href="https://doi.org/10.1109/TCC.2018.2883063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing security risk evaluation approaches (e.g., asset-based) do not consider specific security requirements of individual cloud computing clients in the security risk evaluation. In this paper, we propose a threat-specific risk evaluation approach that uses various security attributes of the cloud (e.g., vulnerability information, the probability of an attack, and the impact of each attack associated with the identified threat(s)) as well as the client-specific security requirements in the cloud. Our approach allows a security administrator of the cloud provider to make fine-grained decisions for selecting mitigation strategies in order to protect the outsourced computing assets of individual clients based on their specific security needs against specific threats. This is different from the existing asset-based approaches where they do not have the functionalities to provide the security evaluation of the cloud with respect to specific threats. On the other hand, the proposed approach enables security administrators to compute a range of more effective client-specific countermeasures with respect to the importance of security requirements and threats. The experimental evaluation results demonstrate that effective security solutions vary due to specific threats prioritized by different clients for an application in the cloud. Further, the proposed approach is not limited to only the cloud-based systems, but can easily be adopted to other networked systems. We have also developed a software tool to support the proposed approach.},
  archive      = {J_TCC},
  author       = {Armstrong Nhlabatsi and Jin B. Hong and Dong Seong Kim and Rachael Fernandez and Alaa Hussein and Noora Fetais and Khaled M. Khan},
  doi          = {10.1109/TCC.2018.2883063},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {793-806},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Threat-specific security risk evaluation in the cloud},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). QoS promotion in energy-efficient datacenters through peak
load scheduling. <em>TCC</em>, <em>9</em>(2), 777–792. (<a
href="https://doi.org/10.1109/TCC.2018.2886187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To build energy-efficient datacenters, one widely used way is to dynamically manipulate the quantity of available hardware resources on demand. However, when bursty workloads appear, additional time overhead is required for resource gearing, thus incurring a performance degradation. To explore this problem, we present an intelligible analysis on the request handing in a VM. From the analysis, we find that, when workloads are overloaded (i.e., peak loads appear), the number of QoS guaranteed requests can be greatly increased by deferring the scheduling of a few requests. Inspired by this finding, we propose a Peak Load Scheduling Control (PLSC) method to promote the Quality of Service (QoS) of peak loads for modern energy-efficient datacenters. However, peak loads are usually difficult to identify. To overcome this difficulty, PLSC tracks the number of requests residing in a VM by leveraging a two-tier request queue maintained by it. When the number exceeds the capability of the VM, it means that peak loads appear. In this case, PLSC adds some delay-tolerant requests to the secondary queue. The scheduling of requests in the secondary queue is controlled with a lower priority than that of requests in the primary queue. Sequentially, with critical requests maintained in the primary queue, PLSC shortens the response time of critical requests. In addition, PLSC expands the number of QoS-guaranteed requests. Comprehensive experiments are conducted to attest the effectiveness of PLSC, by simulating a typical energy-efficient datacenter. The experimental results show that PLSC significantly promotes the QoS of workloads with a negligible impact on energy saving.},
  archive      = {J_TCC},
  author       = {Cheng Hu and Yuhui Deng and Geyong Min and Ping Huang and Xiao Qin},
  doi          = {10.1109/TCC.2018.2886187},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {777-792},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {QoS promotion in energy-efficient datacenters through peak load scheduling},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Providing bandwidth guarantees, work conservation and low
latency simultaneously in the cloud. <em>TCC</em>, <em>9</em>(2),
763–776. (<a href="https://doi.org/10.1109/TCC.2018.2890252">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today&#39;s cloud is shared among multiple tenants running different applications, and a desirable multi-tenant datacenter network infrastructure should provide bandwidth guarantees for throughput-intensive applications, low latency for latency-sensitive short messages, as well as work conservation to fully utilize the network bandwidth. Despite significant efforts in recent years, none of them can achieve these three properties simultaneously. In this paper, we identify the key deficiency of prior solutions and use this insight to motivate our design of Trinity-a simple, practical yet effective solution that achieves bandwidth guarantees, work conservation and low latency simultaneously in the cloud. We implement Trinity using existing commodity hardwares and demonstrate its superior performance over prior solutions using testbed experiments.},
  archive      = {J_TCC},
  author       = {Shuihai Hu and Wei Bai and Kai Chen and Chen Tian and Ying Zhang and Haitao Wu},
  doi          = {10.1109/TCC.2018.2890252},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {763-776},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Providing bandwidth guarantees, work conservation and low latency simultaneously in the cloud},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Privacy preserving searchable encryption with fine-grained
access control. <em>TCC</em>, <em>9</em>(2), 753–762. (<a
href="https://doi.org/10.1109/TCC.2019.2892116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Searchable encryption facilitates cloud server to search over encrypted data without decrypting the data. Single keyword based searchable encryption enables a user to access a subset of documents, which contains the keyword of the user&#39;s interest. In this paper, we present a single keyword based searchable encryption scheme for the applications where multiple data owners upload their data and then multiple users can access the data. The scheme uses attribute based encryption that allows user to access the selective subset of data from cloud without revealing his/her access rights to the cloud server. The scheme is proven adaptively secure against chosen-keyword attack in the random oracle model. We have implemented the scheme on Google cloud instance and the performance of the scheme found practical in real-world applications.},
  archive      = {J_TCC},
  author       = {Payal Chaudhari and Manik Lal Das},
  doi          = {10.1109/TCC.2019.2892116},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {753-762},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Privacy preserving searchable encryption with fine-grained access control},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimizing quality-aware big data applications in the cloud.
<em>TCC</em>, <em>9</em>(2), 737–752. (<a
href="https://doi.org/10.1109/TCC.2018.2874944">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The last years witnessed a steep rise in data generation worldwide and, consequently, the widespread adoption of software solutions able to support data-intensive application. Competitiveness and innovation have strongly benefited from these new platforms and methodologies, and there is a great deal of interest around the new possibilities that Big Data analytics promise to make reality. Many companies currently engage in data-intensive processes as part of their core businesses; however, fully embracing the data-driven paradigm is still cumbersome, and establishing a production-ready, fine-tuned deployment is time-consuming, expensive, and resource-intensive. This situation calls for innovative models and techniques to streamline the process of deployment configuration for Big Data applications. In particular, the focus in this paper is on the rightsizing of Cloud deployed clusters, which represent a cost-effective alternative to installation on premises. This paper proposes a novel tool, integrated in a wider DevOps-inspired approach, implementing a parallel and distributed simulation-optimization technique that efficiently and effectively explores the space of alternative Cloud configurations, seeking the minimum cost deployment that satisfies quality of service constraints. The soundness of the proposed solution has been thoroughly validated in a vast experimental campaign encompassing different applications and Big Data platforms.},
  archive      = {J_TCC},
  author       = {Eugenio Gianniti and Michele Ciavotta and Danilo Ardagna},
  doi          = {10.1109/TCC.2018.2874944},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {737-752},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Optimizing quality-aware big data applications in the cloud},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the planning and design problem of fog computing
networks. <em>TCC</em>, <em>9</em>(2), 724–736. (<a
href="https://doi.org/10.1109/TCC.2018.2874484">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an exact model for the planning and design problem of fog networks. More precisely, a mathematical model is proposed to simultaneously determine the optimal location, the capacity and the number of fog node(s) as well as the interconnection between the installed fog nodes and the cloud. The goal of the model is to minimize the delay in the network and the amount of traffic sent to the cloud data center. To address this multi-objective optimization problem, three optimization techniques are used: the weighted sum, the hierarchical and the trade-off methods. The weighted sum method aggregates all the lone objective functions into a single objective by applying a weighted vector. The hierarchical method takes a sequential approach by tightly constraining the more important objective function. The trade-off method solves a single objective function and translates all other objective functions into constraints. These methods are then compared in terms of average delay, amount of traffic sent to the cloud and amount of CPU time required to find optimal solution(s). Since we are dealing with a multi-objective optimization problem and that multiple optimal solutions can be found, the fuzzy-based mechanism and the hypervolume indicator have been used. Computational results show that as the problem size increases, the delay and the traffic also increase in a linear form; whereas, the solution time increases in non-polynomial time. The weighted sum method was able to achieve the best trade-off results for the delay and the traffic, whereas the hierarchical method was able to return minimum delay but with worse traffic going to the cloud. As the model considers realistic edge device traffic parameters, constraints, and various topology aspects, it can be helpful for the planning and deployment of fog networks and how they operate within a cloud infrastructure.},
  archive      = {J_TCC},
  author       = {Faisal Haider and Decheng Zhang and Marc St-Hilaire and Christian Makaya},
  doi          = {10.1109/TCC.2018.2874484},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {724-736},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {On the planning and design problem of fog computing networks},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the fly orchestration of unikernels: Tuning and
performance evaluation of virtual infrastructure managers. <em>TCC</em>,
<em>9</em>(2), 710–723. (<a
href="https://doi.org/10.1109/TCC.2018.2882505">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network operators are facing significant challenges meeting the demand for more bandwidth, agile infrastructures, innovative services, while keeping costs low. Network Functions Virtualization (NFV) and Cloud Computing are emerging as key trends of 5G network architectures, providing flexibility, fast instantiation times, support of Commercial Off The Shelf hardware and significant cost savings. NFV leverages Cloud Computing principles to move the data-plane network functions from expensive, closed and proprietary hardware to the so-called Virtual Network Functions (VNFs). In this paper we deal with the management of virtual computing resources (Unikernels) for the execution of VNFs. This functionality is performed by the Virtual Infrastructure Manager (VIM) in the NFV MANagement and Orchestration (MANO) reference architecture. We discuss the instantiation process of virtual resources and propose a generic reference model, starting from the analysis of three open source VIMs, namely OpenStack, Nomad and OpenVIM. We improve the aforementioned VIMs introducing the support for special-purpose Unikernels and aiming at reducing the duration of the instantiation process. We evaluate some performance aspects of the VIMs, considering both stock and tuned versions. The VIM extensions and performance evaluation tools are available under a liberal open source licence.},
  archive      = {J_TCC},
  author       = {Pier Luigi Ventre and Paolo Lungaroni and Giuseppe Siracusano and Claudio Pisa and Florian Schmidt and Francesco Lombardo and Stefano Salsano},
  doi          = {10.1109/TCC.2018.2882505},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {710-723},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {On the fly orchestration of unikernels: Tuning and performance evaluation of virtual infrastructure managers},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). New YARN non-exclusive resource management scheme through
opportunistic idle resource assignment. <em>TCC</em>, <em>9</em>(2),
696–709. (<a href="https://doi.org/10.1109/TCC.2018.2867580">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficiently managing resources and improving throughput in a large-scale cluster has become a crucial problem with the explosion of data processing applications in recent years. Hadoop YARN and Mesos, as two universal resource management platforms, have been widely adopted in the commodity cluster for co-deploying multiple data processing frameworks, such as Hadoop MapReduce and Apache Spark. However, in the existing resource management, a certain amount of resources are exclusively allocated to a running task and can only be re-assigned after that task is completed. This exclusive mode unfortunately leads to a potential problem that may under-utilize the cluster resources and degrade system performance. To address this issue, we propose a novel opportunistic and efficient resource allocation scheme, named OpERA, which breaks the barriers among the encapsulated resource containers by leveraging the knowledge of actual runtime resource utilizations to re-assign opportunistic available resources to the pending tasks. OpERA avoids incurring severe performance interference to active tasks by further using two approaches to efficiently balances the starvations of reserved tasks and normal queued tasks. We implement and evaluate OpERA in Hadoop YARN v2.5. Our experimental results show that OpERA significantly reduces the average job execution time and increases the resource (CPU and memory) utilizations.},
  archive      = {J_TCC},
  author       = {Zhengyu Yang and Yi Yao and Han Gao and Jiayin Wang and Ningfang Mi and Bo Sheng},
  doi          = {10.1109/TCC.2018.2867580},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {696-709},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {New YARN non-exclusive resource management scheme through opportunistic idle resource assignment},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Maximizing cloud revenue using dynamic pricing of multiple
class virtual machines. <em>TCC</em>, <em>9</em>(2), 682–695. (<a
href="https://doi.org/10.1109/TCC.2018.2878023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Infrastructure as a Service (IaaS) cloud industry that relies on leasing virtual machines (VMs) has significant portion of business values of finding the dynamic equilibrium between two conflicting phenomena: underutilization and surging congestion. Spot instance has been proposed as an elegant solution to overcome these challenges, with the ultimate goal to achieve greater profits. However, previous studies on recent spot pricing schemes reveal artificial pricing policies that do not comply with the dynamic nature of these phenomena. Motivated by these facts, this paper investigates dynamic pricing of stagnant resources in order to maximize cloud revenue. Specifically, our proposed approach manages multiple classes of virtual machines in order to achieve the maximum expected revenue within a finite discrete time horizon. For this sake, the proposed approach leverages the Markov decision processes with a number of properties under optimum controlling conditions that characterize a model&#39;s behaviour. Further, this approach applies approximate stochastic dynamic programming using linear programming to create a practical model. Experimental results confirm that this approach of dynamic pricing can scale up or down the price efficiently and effectively, according to the stagnant resources and the load thresholds. These results provide significant insights to maximizing the IaaS cloud revenue.},
  archive      = {J_TCC},
  author       = {Fadi Alzhouri and Anjali Agarwal and Yan Liu},
  doi          = {10.1109/TCC.2018.2878023},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {682-695},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Maximizing cloud revenue using dynamic pricing of multiple class virtual machines},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). KeyD: Secure key-deduplication with identity-based broadcast
encryption. <em>TCC</em>, <em>9</em>(2), 670–681. (<a
href="https://doi.org/10.1109/TCC.2018.2869333">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deduplication, which can save storage cost by enabling us to store only one copy of identical data, becomes unprecedentedly significant with the dramatic increase in data stored in the cloud. For the purpose of ensuring data confidentiality, they are usually encrypted before outsourced. Traditional encryption will inevitably result in multiple different ciphertexts produced from the same plaintext by different users&#39; secret keys, which hinders data deduplication. Convergent encryption makes deduplication possible since it naturally encrypts the same plaintexts into the same ciphertexts. One attendant problem is how to reliably and effectively manage a huge number of convergent keys. Several deduplication schemes have been proposed to deal with the convergent key management problem. However, they either need to introduce key management servers or require interaction between data owners. In this paper, we design a novel client-side deduplication protocol named KeyD without such an independent key management server by utilizing the identity-based broadcast encryption (IBBE) technique. Users only interact with the cloud service provider (CSP) during the process of data upload and download. Security analysis demonstrates that KeyD ensures data confidentiality and convergent key security, and well protects the ownership privacy simultaneously. A thorough and detailed performance comparison shows that our scheme makes a better tradeoff among the storage cost, communication and computation overhead.},
  archive      = {J_TCC},
  author       = {Ling Liu and Yuqing Zhang and Xuejun Li},
  doi          = {10.1109/TCC.2018.2869333},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {670-681},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {KeyD: Secure key-deduplication with identity-based broadcast encryption},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hypertracing: Tracing through virtualization layers.
<em>TCC</em>, <em>9</em>(2), 654–669. (<a
href="https://doi.org/10.1109/TCC.2018.2874641">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing enables on-demand access to remote computing resources. It provides dynamic scalability and elasticity with a low upfront cost. As the adoption of this computing model is rapidly growing, this increases the system complexity, since virtual machines (VMs) running on multiple virtualization layers become very difficult to monitor without interfering with their performance. In this paper, we present hypertracing, a novel method for tracing VMs by using various paravirtualization techniques, enabling efficient monitoring across virtualization boundaries. Hypertracing is a monitoring infrastructure that facilitates seamless trace sharing among host and guests. Our toolchain can detect latencies and their root causes within VMs, even for boot-up and shutdown sequences, whereas existing tools fail to handle these cases. We propose a new hypervisor optimization, for handling efficient nested paravirtualization, which allows hypertracing to be enabled in any nested environment without triggering VM exit multiplication. This is a significant improvement over current monitoring tools, with their large I/O overhead associated with activating monitoring within each virtualization layer.},
  archive      = {J_TCC},
  author       = {Abderrahmane Benbachir and Michel Dagenais},
  doi          = {10.1109/TCC.2018.2874641},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {654-669},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Hypertracing: Tracing through virtualization layers},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hybrid evolutionary scheduling for energy-efficient
fog-enhanced internet of things. <em>TCC</em>, <em>9</em>(2), 641–653.
(<a href="https://doi.org/10.1109/TCC.2018.2889482">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the rapid development of the Internet of Things (IoT) has produced a large amount of data that needs to be processed in a timely manner. Traditional cloud computing systems can provide us with plentiful resources to process such data. However, the increasing requirements of IoT applications on data privacy, energy consumption savings and location-aware data processing pushes the emergence and the interplay of fog computing and cloud computing. This paper examines the resource scheduling issue under such a system to minimize makespan and energy consumption. A multi-objective estimation of distribution algorithm (EDA) as well as a partition operator is adopted to divide the graph and determine the task processing permutation and processor assignment. Single and multiple application simulation were both conducted. The comparative results show that the Pareto set produced by our proposed algorithm is able to dominate a large proportion of those solutions by the heuristic method and the simple EDA under single application simulation. When it comes to multi-application simulation, IoT devices can have a much longer lifetime with our proposed scheduling algorithm as well having similar performance to the other algorithms on fog node energy consumption and much better on makespan.},
  archive      = {J_TCC},
  author       = {Chu-ge Wu and Wei Li and Ling Wang and Albert Y. Zomaya},
  doi          = {10.1109/TCC.2018.2889482},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {641-653},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Hybrid evolutionary scheduling for energy-efficient fog-enhanced internet of things},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Guaranteed bang for the buck: Modeling VDI applications to
identify storage requirements. <em>TCC</em>, <em>9</em>(2), 627–640. (<a
href="https://doi.org/10.1109/TCC.2018.2889975">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the cloud environment, most services are provided by virtual machines (VMs). Identifying storage requirements of VMs is challenging, but it is essential for good user experiences while optimizing use of storage resources. Determining the storage configuration necessary to support and satisfy VMs first requires an accurate description of the VM configurations, and the problem is further exacerbated by the diversity and special characteristics of the VMs. In this paper, we study Virtual Desktop Infrastructure (VDI), a prevalent and complicated VM application, to identify and characterize storage requirements of VMs and determine how to meet such requirements with minimal storage resources and cost. We first create a model to describe the behavior of VDI, and we collect real VDI traces to populate this model. The model allows us to identify the storage requirements of VDI and determine the potential bottlenecks of a given storage configuration. Based on this information, we can tell what capacity and minimum capability a storage configuration needs in order to support and satisfy given VDI configurations. We show that our model can describe more fine-grained VM behavior varying with time and virtual disk types compared with the rules of thumb currently used in industry.},
  archive      = {J_TCC},
  author       = {Hao Wen and David H. C. Du and Milan Shetti and Doug Voigt and Shanshan Li},
  doi          = {10.1109/TCC.2018.2889975},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {627-640},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Guaranteed bang for the buck: Modeling VDI applications to identify storage requirements},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). FPGA resource pooling in cloud computing. <em>TCC</em>,
<em>9</em>(2), 610–626. (<a
href="https://doi.org/10.1109/TCC.2018.2874011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud providers have started to deploy various FPGA accelerators in their datacenters because the performance of many applications can be significantly improved by implementing their core routines in FPGAs. In conventional datacenters with FPGA accelerated servers, if a tenant wants to use FPGA accelerators, it requests for a VM instance residing in a server equipped with an FPGA accelerator. This paradigm to integrate FPGA into Cloud leads to poor resource sharing of the precious FPGA resources. In this paper, we propose FPGAPooling, an FPAG-enabled Cloud system where all FPGA accelerators are managed as a single resource pool and shared among all VMs. For a VM, instead of requesting the Cloud to run the VM on an FPGA accelerated server, at run time, when a VM needs to use FPGA acceleration, it requests an FPGA accelerator from the pool. After the VM finishes using the FPGA accelerator, it releases the FPGA accelerator back to the pool. We design a centralized scheduler to handle acceleration requests from VMs and assign each request to an idle FPGA accelerator at run time; We implemented a system prototype on IBM&#39;s OpenPower Cloud system. The key challenging of FPGAPooling is scheduling. We designed and implemented a group of scheduling algorithms for the FPGAPooling system. With extensive evaluations on both a small testbed and a large-scale simulation, we found that our algorithms can improve the average and tail job completion time by up to 7 and 4 times, respectively.},
  archive      = {J_TCC},
  author       = {Zhuangdi Zhu and Alex X. Liu and Fan Zhang and Fei Chen},
  doi          = {10.1109/TCC.2018.2874011},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {610-626},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {FPGA resource pooling in cloud computing},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient oblivious data structures for database services on
the cloud. <em>TCC</em>, <em>9</em>(2), 598–609. (<a
href="https://doi.org/10.1109/TCC.2018.2879104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Database-as-a-service (DBaaS) allows the client to store and manage structured data on the cloud remotely. Despite its merits, DBaaS also brings significant privacy issues. Existing encryption techniques (e.g., SQL-aware encryption) can mitigate privacy concerns, but they still leak information through access patterns, which are vulnerable to statistical inference attacks. Oblivious Random Access Machine (ORAM) can seal such leakages; however, the recent studies showed significant challenges on the integration of ORAM into databases. That is, the direct usage of ORAM on databases is not only costly but also permits very limited query functionalities. In this paper, we propose new oblivious data structures called Oblivious Matrix Structure (OMAT), which allow tree-based ORAM to be integrated into database systems in a more efficient manner with diverse query functionalities supported. OMAT provides special ORAM packaging strategies for table structures, which not only offers a significantly better performance but also enables a broad range of query types that may not be efficient in existing frameworks. On the other hand, OTREE allows oblivious conditional queries to be performed on tree-indexed databases more efficiently than existing techniques. We implemented our proposed techniques and evaluated their performance on a real cloud database with various metrics, compared with state-of-the-art counterparts.},
  archive      = {J_TCC},
  author       = {Thang Hoang and Ceyhun D. Ozkaptan and Gabriel Hackebeil and Attila Altay Yavuz},
  doi          = {10.1109/TCC.2018.2879104},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {598-609},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Efficient oblivious data structures for database services on the cloud},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient and secure outsourcing of large-scale linear
system of equations. <em>TCC</em>, <em>9</em>(2), 587–597. (<a
href="https://doi.org/10.1109/TCC.2018.2880181">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving the large-scale linear system of equations is one of the most fundamental problems both in theory and practice. However this problem requires too much computational resource for most users to solve it. With the rapid development of cloud services, many users tend to outsource the expensive computing to the cloud server, which is regarded as an efficient way of solving such problem. Nevertheless, the cloud server can not protect the data privacy well, especially when the user&#39;s linear system of equations contain private and sensitive data. There are many previous research works on secure outsourcing of systems of linear equations. In this paper we first analyze a privacy preserving CGM (conjugate gradient method) algorithm for secure outsourcing of large-scale systems of linear equations proposed in [1] . We find that the cloud server can recover the protected coefficient matrix of the linear system of equations from the message it receives, which makes the security method in this scheme fails. This is a serious problem, which makes the private and sensitive data of the user leak to the cloud server, and privacy preserving does not exist. To overcome this problem, we modified this algorithm to protect the message from leaking, which can protect the users&#39; privacy well. We also show the security of this new scheme and do experiments to show its efficiency.},
  archive      = {J_TCC},
  author       = {Qi Ding and Guobiao Weng and Guohui Zhao and Changhui Hu},
  doi          = {10.1109/TCC.2018.2880181},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {587-597},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Efficient and secure outsourcing of large-scale linear system of equations},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient and privacy-preserving online fingerprint
authentication scheme over outsourced data. <em>TCC</em>, <em>9</em>(2),
576–586. (<a href="https://doi.org/10.1109/TCC.2018.2866405">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the pervasiveness of mobile devices and the development of biometric technology, biometric identification, which can achieve individual authentication relies on personal biological or behavioral characteristics, has attracted widely considerable interest. However, privacy issues of biometric data bring out increasing concerns due to the highly sensitivity of biometric data. Aiming at this challenge, in this paper, we present a novel privacy-preserving online fingerprint authentication scheme, named e-Finga, over encrypted outsourced data. In the proposed e-Finga scheme, the user&#39;s fingerprint registered in trust authority can be outsourced to different servers with user&#39;s authorization, and secure, accurate and efficient authentication service can be provided without the leakage of fingerprint information. Specifically, an improved homomorphic encryption technology for secure euclidean distance calculation to achieve an efficient online fingerprint matching algorithm over encrypted FingerCode data in the outsourcing scenarios. Through detailed security analysis, we show that e-Finga can resist various security threats. In addition, we implement e-Finga over a workstation with a real fingerprint database, and extensive simulation results demonstrate that the proposed e-Finga scheme can serve efficient and accurate online fingerprint authentication.},
  archive      = {J_TCC},
  author       = {Hui Zhu and Qing Wei and Xiaopeng Yang and Rongxing Lu and Hui Li},
  doi          = {10.1109/TCC.2018.2866405},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {576-586},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Efficient and privacy-preserving online fingerprint authentication scheme over outsourced data},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). D-SRTF: Distributed shortest remaining time first scheduling
for data center networks. <em>TCC</em>, <em>9</em>(2), 562–575. (<a
href="https://doi.org/10.1109/TCC.2018.2879313">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many recent works utilize scheduling to minimize the Flow Completion Time (FCT) in Data Center Networks (DCN), like PIAS using Shortest Job First (SJF) scheduling and pFabric using Shortest Remaining Size First (SRSF) scheduling. However, they only consider the flow size information, without consideration of available bandwidth of the network, leading to inferior performance when the network is congested. Besides, information on flow size is hard to obtain in practice. Moreover, although a centralized scheduler may have optimal scheduling decisions, it suffers from high system overhead. Therefore, a new DCN scheme is expected which is deployment-friendly and implements SRTF scheduling in a distributed manner. In this paper, we propose D-SRTF, a light-weight yet effective DCN scheme to implement SRTF scheduling. D-SRTF determines the remaining time of each flow according to the estimated remaining flow size and the available bandwidth, in order to determine the priority of each flow. Switches perform Strict Priority (SP) scheduling according to the priority of each flow, in order to realize SRTF scheduling. Experiments show that D-SRTF performs better than the currently best implementable scheme, PIAS, and could perform better than pFabric if information on flow size is available.},
  archive      = {J_TCC},
  author       = {Chengxi Gao and Victor C.S. Lee and Keqin Li},
  doi          = {10.1109/TCC.2018.2879313},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {562-575},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {D-SRTF: Distributed shortest remaining time first scheduling for data center networks},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dependable data outsourcing scheme based on cloud-of-clouds
approach with fast recovery. <em>TCC</em>, <em>9</em>(2), 546–561. (<a
href="https://doi.org/10.1109/TCC.2018.2871181">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing is increasingly popular today. Cloud services such as data-outsourcing services provide a growing number of users access to cloud storage for large quantities of data, and enterprises are turning to cloud storage for cost-effective remote backup. In 2011, DEPSKY shows and overcomes four limitations hinder the effectiveness of cloud storage: loss of availability, loss and corruption of data, loss of privacy, and vendor lock-in. Unfortunately, DEPSKY lacks an error detection mechanism and comes with heavy computing costs. Therefore, we propose a new data-outsourcing scheme overcoming not only the four limitations, but also the shortcomings of DEPSKY. In this paper, we modify Nyberg&#39;s accumulator and apply it to our three proposed error-detection methods. Moreover, we specially design a fast recovery method that is faster than DEPSKY and alternative methods.},
  archive      = {J_TCC},
  author       = {Chun-I Fan and Jheng-Jia Huang and Shang-Wei Tseng and I-Te Chen},
  doi          = {10.1109/TCC.2018.2871181},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {546-561},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Dependable data outsourcing scheme based on cloud-of-clouds approach with fast recovery},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Demand-aware erasure coding for distributed storage systems.
<em>TCC</em>, <em>9</em>(2), 532–545. (<a
href="https://doi.org/10.1109/TCC.2018.2885306">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed storage systems provide cloud storage services by storing data on commodity storage servers. Conventionally, data are protected against failures of such commodity servers by replication. Erasure coding consumes less storage overhead than replication to tolerate the same number of failures and thus has been replacing replication in many distributed storage systems. However, with erasure coding, the overhead of reconstructing data from failures also increases significantly. Under the ever-changing workload where data accesses can be highly skewed, it is challenging to deploy erasure coding with appropriate values of parameters to achieve a well trade-off between storage overhead and reconstruction overhead. In this paper, we propose Zebra, a framework that encodes data by their demand into multiple tiers that deploy erasure codes with different values of parameters. Zebra automatically determines the number of such tiers and dynamically assigns erasure codes with optimal values of parameters into corresponding tiers. With Zebra, a flexible trade-off between storage overhead and reconstruction overhead is achieved with multiple tiers. When demand changes, Zebra adjusts itself with a marginal amount of network transfer. We demonstrate that Zebra can work with two representative families of erasure codes in distributed storage systems, Reed-Solomon codes and local reconstruction codes.},
  archive      = {J_TCC},
  author       = {Jun Li and Baochun Li},
  doi          = {10.1109/TCC.2018.2885306},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {532-545},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Demand-aware erasure coding for distributed storage systems},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Consolidating policy chains using one pass packet steering
in software defined data centers. <em>TCC</em>, <em>9</em>(2), 518–531.
(<a href="https://doi.org/10.1109/TCC.2018.2881963">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address the problem of service function chaining in a network and present a solution that tackles this problem in Software Defined Data Centers. Service function chaining can broadly be categorized into middlebox placement in a network and packet steering through middleboxes. We address packet steering in this paper. In particular, we present a One Pass Packet Steering (OPPS) approach for use in multi-subscriber environments. We show algorithms and proof of concept implementation using emulation. We examine how OPPS can benefit from Software Defined Data Center architecture to overcome challenges that occur in simple linear networks. Our results show how OPPS can utilize a lesser number of middleboxes and achieve the same hop counts as a reference model which has been described in previous work as ideal, without violating the subscriber&#39;s policy chain.},
  archive      = {J_TCC},
  author       = {Julian Chimaobi Chukwu and Ashraf Matrawy and Dimitrios Makrakis},
  doi          = {10.1109/TCC.2018.2881963},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {518-531},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Consolidating policy chains using one pass packet steering in software defined data centers},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cloud resource scaling for time-bounded and unbounded big
data streaming applications. <em>TCC</em>, <em>9</em>(2), 504–517. (<a
href="https://doi.org/10.1109/TCC.2018.2876242">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in technology have led to a deluge of big data streams that require real-time analysis with strict latency constraints. A major challenge, however, is determining the amount of resources required by applications processing these streams given their high volume, velocity and variety. The majority of research efforts on resource scaling in the cloud are investigated from the cloud provider&#39;s perspective with little consideration for multiple resource bottlenecks. We aim at analyzing the resource scaling problem from an application provider&#39;s point of view such that efficient scaling decisions can be made. This paper provides two contributions to the study of resource scaling for big data streaming applications in the cloud. First, we present a Layered Multi-dimensional Hidden Markov Model (LMD-HMM) for managing time-bounded streaming applications. Second, to cater to unbounded streaming applications, we propose a framework based on a Layered Multi-dimensional Hidden Semi-Markov Model (LMD-HSMM). The parameters in our models are evaluated using modified Forward and Backward algorithms. Our detailed experimental evaluation results show that LMD-HMM is very effective with respect to cloud resource prediction for bounded streaming applications running for shorter periods while the LMD-HSMM accurately predicts the resource usage for streaming applications running for longer periods.},
  archive      = {J_TCC},
  author       = {Olubisi Runsewe and Nancy Samaan},
  doi          = {10.1109/TCC.2018.2876242},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {504-517},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Cloud resource scaling for time-bounded and unbounded big data streaming applications},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Characterization and prediction of performance loss and MTTR
during fault recovery on scale-out storage using DOE &amp; RSM: A case
study with ceph. <em>TCC</em>, <em>9</em>(2), 492–503. (<a
href="https://doi.org/10.1109/TCC.2018.2874054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recognizing the impact from cluster recovery operations on performance and mean time to recovery (MTTR) is essential to maintain service and availability objectives. Testing the impact of recovery operation can reveal a cause-and-effect relationship between recovery parameters and responses of performance and MTTR during the recovery process. This study introduces a combination of systematic methodologies of design of experiments and response surface methodologies to effectively and efficiently find out main and factor-to-factor interaction effects toward the responses. Two Ceph clusters using different storage device technologies, HDD and SSD respectively, were used to characterize the impact of recovery operation on performance and MTTR. The combination of quadratic and linear effects from both Ceph clusters were determined and reported. With 28 tests, MTTR and performance models were developed for each Ceph cluster based on those quadratic and linear effects. These models demonstrate good prediction on performance and MTTR when recovery parameters are adjusted. Using design of experiment and response surface not only allow cause and effect analysis, but also provide the potential inefficient parameter that causes performance loss during recovery. This not only introduces a new method to study cause-and-effect in MTTR but serves as the indicator to areas for improvement for more efficient recovery operation.},
  archive      = {J_TCC},
  author       = {Lay Wai Kong and Orlando Moreno},
  doi          = {10.1109/TCC.2018.2874054},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {492-503},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Characterization and prediction of performance loss and MTTR during fault recovery on scale-out storage using DOE &amp; RSM: A case study with ceph},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An SLA-aware cloud coalition formation approach for
virtualized networks. <em>TCC</em>, <em>9</em>(2), 475–491. (<a
href="https://doi.org/10.1109/TCC.2018.2865737">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the main challenges faced by cloud providers is the uncertainty in their workload, resulting from the high variability and the dynamic nature of clients&#39; demands. The inability to meet those demands during peak times can lead to high service rejection rates, experienced delays, and consequently profit and reputation losses. The concept of cloud federation has been proposed as a way to address this challenge, by enabling a group of cloud providers to collaborate by dynamically combining their resources as needed, to satisfy received requests. Existing cloud federation approaches fail to consider clients&#39; SLA requirements during the coalition formation process or provide a self-healing mechanism to deal with unexpected resources&#39; shortage during operation. Furthermore, the state of the art approaches suffer from performance issues, such as high execution times, unstable performance, and lack of convergence to a solution in complex scenarios (e.g., requests with mixed, independent types of VMs). This paper proposes a novel social gaming based approach for coalition formation in the cloud that finds the best coalition of cloud providers to answer requests, while satisfying the clients&#39; SLA requirements. The proposed algorithm, dubbed SLA Aware Cloud Coalition Formation algorithm (S-ACCF), leverages Irving&#39;s roommate algorithm to form a stable coalition of cloud providers, with a rapid execution time. The S-ACCF algorithm is designed to maximize the coalition&#39;s profit, while minimizing the number of participants in the coalition as well as the penalty incurred by providers who fail to offer all or some of the promised resources using a self-healing process. The S-ACCF algorithm was extensively tested using a variety of scenarios, and its performance was compared to two state of the art approaches: 1) the Optimal Cloud Federation Mechanism (OCFM) that relies on an exhaustive search of all possible solutions to find the best coalition; and 2) the Cloud Federation Formation Mechanism (CFFM) that relies on an iterative split-and-merge approach to find the best coalition. While the optimal approach (OCFM) always finds the best coalition leading to the highest collective profit, it has an exponential time complexity, thus leading to very large execution times. On the other hand, the split-and-merge approach (CFFM), which relies on random selection of sub-groups for coalition formation, suffers from instability (different results in repeated runs), high and variable execution time, and a noticeable requests&#39; rejection rate that changes between runs. The test results show that the S-ACCF algorithm addresses the limitations of the OCFM and the CFFM algorithms, and outperforms the optimal and split-and-merge approaches in terms of execution time, individual provider payoff, and the number of providers per coalition. Furthermore, it yields higher stability and zero rejection rate, when compared to the split-and-merge approach. Indeed, our proposed approach yields an execution time that is 12 to 25 times faster than the optimal and split-and-merge approaches, which is a major advantage for real-time applications. Moreover, when compared to the two other approaches, our S-ACCF algorithm always finds the smallest coalition possible satisfying the client requirements, thus leading to the highest individual payoff for providers and lower administration overhead. Finally, unlike the split-and-merge approach, our algorithm shows a stable performance, and converges towards the optimal solution in simple and complex scenarios, thus making it suitable for production environments.},
  archive      = {J_TCC},
  author       = {Souad Hadjres and Nadjia Kara and May El Barachi and Fatna Belqasmi},
  doi          = {10.1109/TCC.2018.2865737},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {475-491},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {An SLA-aware cloud coalition formation approach for virtualized networks},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An intermediate data partition algorithm for skew mitigation
in spark computing environment. <em>TCC</em>, <em>9</em>(2), 461–474.
(<a href="https://doi.org/10.1109/TCC.2018.2878838">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the parallel computing framework of Hadoop/Spark, data skew is a common problem resulting in performance degradation, such as prolonging of the entire execution time and idle resources. What lies behind this issue is the partition imbalance, that causes significant differences in the amount of data processed by each reduce task. This paper proposes a key reassigning and splitting partition algorithm (SKRSP) to solve the partition skew from the source codes of Spark-core_2.11 project, which considers both the partition balance of the intermediate data and the partition balance after shuffle operators. First, we propose a step-based algorithm for sampling the input data to estimate the general key distribution of entire intermediate data. According to the types of the specific applications, we design two algorithms: hash based key reassigning algorithm (KRHP) and rang based key splitting algorithm (KSRP), which can generate appropriate strategy and implement the skew mitigation in shuffle phase. KKSRP generates the weighted bounds to split intermediate data for the type of sort-based applications while KRHP records these reassigned keys and the new reducers these keys belong to for other applications. Finally, we implement SKRSP in Spark 2.2.0 and evaluate its performance through four benchmarks exhibiting significant data skew: WordCount, Sort, Join, and PageRank. The experimental results verify that our algorithm not only can achieve a better partition balance but also reduce the execution time of reduce tasks effectively.},
  archive      = {J_TCC},
  author       = {Zhuo Tang and Wei Lv and Kenli Li and Keqin Li},
  doi          = {10.1109/TCC.2018.2878838},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {461-474},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {An intermediate data partition algorithm for skew mitigation in spark computing environment},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A robust optimization technique for energy cost minimization
of cloud data centers. <em>TCC</em>, <em>9</em>(2), 447–460. (<a
href="https://doi.org/10.1109/TCC.2018.2879948">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Power consumption cost constitutes significant portion of a data center&#39;s total operational cost. Variations in parameters, such as power demand, electricity price, and renewable power generation effects the data center&#39;s power consumption cost. Therefore, in this paper, a smart power management system based on a robust energy cost optimization algorithm is proposed for the data center. The designed robust optimization algorithm coordinates data center workload, battery bank, diesel generators, renewable power, and trade electricity price in real-time and day-ahead power market to reduce expected energy consumption cost. The uncertain parameters, such as data center workload and renewable power are computed using forecasting algorithms. The optimization algorithm is used to limit unbalance power purchase from real-time power market due to uncertainty of real-time electricity price. The algorithm formulation is obtained using mixed-integer linear programming. Moreover, a model to calculate prices to be used in service level agreements with data centers’ clients for on-demand cloud services is designed considering operational cost of the data center. Simulations are performed on actual data center workload, weather parameters, and electricity price. The results have shown that the proposed methodology is an effective tool to minimize data center operational cost.},
  archive      = {J_TCC},
  author       = {Muhammad Jawad and Muhammad B. Qureshi and Muhammad U. S. Khan and Sahibzada M. Ali and Arshad Mehmood and Bilal Khan and Xiaoyu Wang and Samee U. Khan},
  doi          = {10.1109/TCC.2018.2879948},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {447-460},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {A robust optimization technique for energy cost minimization of cloud data centers},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A robust generic multi-authority attributes management
system for cloud storage services. <em>TCC</em>, <em>9</em>(2), 435–446.
(<a href="https://doi.org/10.1109/TCC.2018.2867871">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute Based Encryption (ABE) schemes face number of essential challenges for achieving data privacy in Cloud Storage Services (CSS). One crucial challenge is the existence of a single authority for attributes management. The second challenge is the lack of an efficient attribute revocation mechanism that prohibits an unauthorized access instantaneously after an attribute revocation is requested. The third challenge is the avoidance of using attribute revocation scenario as a mechanism for user revocation. In this paper, a robust generic multi-authority attributes management system is presented to overcome these challenges for CSS. The proposed system can be implemented using either Ciphertext Policy ABE (CP-ABE) or Key Policy ABE (KP-ABE) technique that possesses a specific set of characteristics. In addition, the proposed system presents a novel structure for user digital identity that prohibits the collusion between system users. Moreover, the proposed system does not oblige cooperation between the participated attributes authorities to accomplish any of the proposed system tasks. Furthermore, the attributes authorities can join or leave the proposed system without mandating the proposed system re-initialization. Finally, the presented performance measures prove the proposed system validity to accomplish all the specified goals with acceptable performance.},
  archive      = {J_TCC},
  author       = {Ibrahim Mostafa Ibrahim and Mostafa G. M. Mostafa and Sherif H. Nour El-Din and Rania Elgohary and Hossam Faheem},
  doi          = {10.1109/TCC.2018.2867871},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {435-446},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {A robust generic multi-authority attributes management system for cloud storage services},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hierarchical receding horizon algorithm for QoS-driven
control of multi-IaaS applications. <em>TCC</em>, <em>9</em>(2),
418–434. (<a href="https://doi.org/10.1109/TCC.2018.2875443">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud Computing is emerging as a major trend in ICT industry. However, as with any new technology, new major challenges lie ahead, one of them concerning the resource provisioning. Indeed, modern Cloud applications deal with a dynamic context that requires a continuous adaptation process in order to meet satisfactory Quality of Service (QoS) but even the most titled Cloud platform provide just simple rule-based tools; the rudimentary autoscaling mechanisms that can be carried out may be unsuitable in many situations as they do not prevent SLA violations, but only react to them. In addition, these approaches are inherently static and cannot catch the dynamic behavior of the application and are unsuitable to manage multi-Cloud/data center deployments required for mission critical services. This situation calls for advanced solutions designed to provide Cloud resources in a predictive and dynamic way. This work presents capacity allocation algorithms, whose goal is to minimize the total execution cost while satisfying some constraints on the average response time of multi-Cloud based applications. This paper proposes a joint load balancing and receding horizon capacity allocation techniques, which can be employed to handle multiple classes of requests. An extensive evaluation of the proposed solution against an Oracle with perfect knowledge of the future and well-known heuristics proposed in the literature is provided. The analysis shows that our solution outperforms the heuristics producing results very close to the optimal ones, and reducing the number of QoS violations (in the worst case QoS constraints violation rate is 4.26 percent versus up to 17.25 percent of other approaches and can easily reduced by roughly a factor of four by exploiting the receding horizon approach). Furthermore, a sensitivity analysis over two different time scales indicates that finer grained time scales are more appropriate for spiky workloads. Analytical results are validated through simulation, which also analyzes the impact of Cloud environment random perturbations. Finally, experiments on a prototype environment demonstrate the effectiveness of the proposed approach under real workloads.},
  archive      = {J_TCC},
  author       = {Danilo Ardagna and Michele Ciavotta and Riccardo Lancellotti and Michele Guerriero},
  doi          = {10.1109/TCC.2018.2875443},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {418-434},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {A hierarchical receding horizon algorithm for QoS-driven control of multi-IaaS applications},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Editorial: State of the transactions on cloud computing.
<em>TCC</em>, <em>9</em>(2), 414–417. (<a
href="https://doi.org/10.1109/TCC.2021.3061840">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Presents an editorial analsis of the state of the IEEE Transactions on Cloud Computing.},
  archive      = {J_TCC},
  author       = {YuanYuan Yang},
  doi          = {10.1109/TCC.2021.3061840},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {2},
  pages        = {414-417},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Editorial: State of the transactions on cloud computing},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Virtual machine extrospection: A reverse information
retrieval in clouds. <em>TCC</em>, <em>9</em>(1), 401–413. (<a
href="https://doi.org/10.1109/TCC.2018.2855143">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a virtualized environment, it is not difficult to retrieve guest OS information from its hypervisor. However, it is very challenging to retrieve information in the reverse direction, i.e., retrieve the hypervisor information from within a guest OS, which remains an open problem and has not yet been comprehensively studied before. In this paper, we take the initiative and study this reverse information retrieval problem. In particular, we investigate how to determine the host OS kernel version from within a guest OS. We observe that modern commodity hypervisors introduce new features and bug fixes in almost every new release. Thus, by carefully analyzing the seven-year evolution of Linux KVM development (including 3,485 patches), we can identify 19 features and 20 bugs in the hypervisor detectable from within a guest OS. Building on our detection of these features and bugs, we present a novel framework called Hyperprobe that for the first time enables users in a guest OS to automatically detect the underlying host OS kernel version in a few minutes. We implement a prototype of Hyperprobe and evaluate its effectiveness in six real world clouds, including Google Compute Engine (a.k.a. Google Cloud), HP Helion Public Cloud, ElasticHosts, Joyent Cloud, CloudSigma, and VULTR, as well as in a controlled testbed environment, all yielding promising results.},
  archive      = {J_TCC},
  author       = {Jidong Xiao and Lei Lu and Hai Huang and Haining Wang},
  doi          = {10.1109/TCC.2018.2855143},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {401-413},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Virtual machine extrospection: A reverse information retrieval in clouds},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unequal failure protection coding technique for distributed
cloud storage systems. <em>TCC</em>, <em>9</em>(1), 386–400. (<a
href="https://doi.org/10.1109/TCC.2017.2785396">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, erasure codes have become the de facto standard for data protection in large scale distributed cloud storage systems at the cost of an affordable storage overhead. However, traditional erasure coding schemes, such as Reed-Solomon codes, suffer from high reconstruction cost and I/Os. The recent past has seen a plethora of efforts to optimize the tradeoff between the reconstruction cost, I/Os and storage overhead. Quiet different from all prior studies, in this paper, our erasure coding technique makes the first attempt to take advantage of the unequal failure rates across the disks/nodes to optimize the system reliability and reconstruction performance. Specifically, our proposed technique, the Unequal Failure Protection based Local Reconstruction Code (UFP-LRC) divides the data blocks into several unequal-sized groups with local parities, assigning the data blocks stored on more failure-prone disks/nodes into the smaller-sized group, so as to provide unequal failure protection for each group. In this way, by exploiting the nonuniform local parity degrees, the proposed UFP-LRC enables the data blocks that are stored on more failure-prone disks/nodes to tolerate a greater number of failures while suffering from less repair cost than others, leading to a substantial improvement of the overall reliability and repair performance for cloud storage systems. We perform numerical analysis and build a prototype storage system to verify our approach. The analytical results show that the UFP-LRC technique gradually outperforms LRC along the increase of failure rate ratio. Also, extensive experiments show that, when compared to LRC, UFP-LRC is able to achieve a 10 to 15 percent improvement in throughput, and an 8 to 12 percent reduction in decoding latency, while retaining a comparable overall reliability.},
  archive      = {J_TCC},
  author       = {Yupeng Hu and Yonghe Liu and Wenjia Li and Keqin Li and Kenli Li and Nong Xiao and Zheng Qin},
  doi          = {10.1109/TCC.2017.2785396},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {386-400},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Unequal failure protection coding technique for distributed cloud storage systems},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Trigger-based incremental data processing with unified sync
and async model. <em>TCC</em>, <em>9</em>(1), 372–385. (<a
href="https://doi.org/10.1109/TCC.2018.2830348">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, more and more applications in the cloud have needs to process large-scale on-line datasets, which evolve over time as new entries are added and existing entries are modified. Several programming frameworks, such as Percolator and Oolong, are proposed for such incremental data processing and can achieve efficient processing with an event-driven abstraction. However, these frameworks are inherently asynchronous, leaving the heavy burden of managing synchronization to applications&#39; developers, which further significantly restricts their usabilities. In this study, we propose a trigger-based incremental computing framework in the cloud, called Domino, with both synchronous and asynchronous mechanisms to coordinate parallel triggers. With this new framework, both synchronous and asynchronous applications can be seamlessly developed. Use cases and extensive evaluation results confirm that it can deliver sufficient performance, and also is easy to use for incremental applications in large-scale distributed computing.},
  archive      = {J_TCC},
  author       = {Dong Dai and Yong Chen and Dries Kimpe and Robert B. Ross},
  doi          = {10.1109/TCC.2018.2830348},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {372-385},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Trigger-based incremental data processing with unified sync and async model},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Speeding up VM startup by cooperative VM image caching.
<em>TCC</em>, <em>9</em>(1), 360–371. (<a
href="https://doi.org/10.1109/TCC.2018.2791509">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Virtual machine (VM) management is at the core of virtualized cloud data centers. Among others, how to reduce the startup delay of VMs is a key issue for improving user experience and resource utility. In this paper, we study this issue by jointly considering VM placement and VM image caching. We formulate the joint placement problem and design several joint algorithms, including both online and offline algorithms, to speed up VM startup. In our design, we adopt the cooperative caching approach, where image cache copies are shared among physical machines (PMs) so as to reduce image retrieval time. The key point of our algorithms lies in how to appropriately place VM image cache among PMs so as to speed up VM startup as much as possible. The proposed algorithms are evaluated by extensive simulations via SimGrid. The results show that our algorithms can achieve shorter startup delay in most cases, compared with existing ones.},
  archive      = {J_TCC},
  author       = {Yifan Zhang and Kai Niu and Weigang Wu and Keqin Li and Yu Zhou},
  doi          = {10.1109/TCC.2018.2791509},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {360-371},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Speeding up VM startup by cooperative VM image caching},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SeSPHR: A methodology for secure sharing of personal health
records in the cloud. <em>TCC</em>, <em>9</em>(1), 347–359. (<a
href="https://doi.org/10.1109/TCC.2018.2854790">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread acceptance of cloud based services in the healthcare sector has resulted in cost effective and convenient exchange of Personal Health Records (PHRs) among several participating entities of the e-Health systems. Nevertheless, storing the confidential health information to cloud servers is susceptible to revelation or theft and calls for the development of methodologies that ensure the privacy of the PHRs. Therefore, we propose a methodology called SeSPHR for secure sharing of the PHRs in the cloud. The SeSPHR scheme ensures patient-centric control on the PHRs and preserves the confidentiality of the PHRs. The patients store the encrypted PHRs on the un-trusted cloud servers and selectively grant access to different types of users on different portions of the PHRs. A semi-trusted proxy called Setup and Re-encryption Server (SRS) is introduced to set up the public/private key pairs and to produce the re-encryption keys. Moreover, the methodology is secure against insider threats and also enforces a forward and backward access control. Furthermore, we formally analyze and verify the working of SeSPHR methodology through the High Level Petri Nets (HLPN). Performance evaluation regarding time consumption indicates that the SeSPHR methodology has potential to be employed for securely shar-ing the PHRs in the cloud.},
  archive      = {J_TCC},
  author       = {Mazhar Ali and Assad Abbas and Muhammad Usman Shahid Khan and Samee U. Khan},
  doi          = {10.1109/TCC.2018.2854790},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {347-359},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {SeSPHR: A methodology for secure sharing of personal health records in the cloud},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Risk-averse caching policies for YouTube content in
femtocell networks using density forecasting. <em>TCC</em>,
<em>9</em>(1), 331–346. (<a
href="https://doi.org/10.1109/TCC.2018.2855160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper presents risk-neutral and risk-averse caching policies that can be deployed in a femtocell network with limited storage capacity to reduce the time delay of servicing content requests. The caching policies use a forecasting algorithm to estimate the cumulative distribution function of content requests based on the content features. Given the cumulative distribution function, a mixed-integer linear program is used to compute where to cache content in the femtocell network. The caching policies account for the uncertainty associated with estimating the content requests using the coherent Conditional Value-at-Risk (CVaR) measure. For a large number of content, a risk-neutral caching policy is constructed that accounts for both the content features and routing protocol that only requires the evaluation of a unimodular linear program. Using data from YouTube (comprising 25,000 videos) and the NS-3 simulator, the caching policies reduce the delay of retrieving content in femtocell networks compared with industry standard caching policies. Specifically, a 6 percent reduction in delay is achieved by accounting for the uncertainty, and a 60 percent reduction in delay is achieved if both the uncertainty and femtocell routing protocol are accounted for compared to the risk-neutral caching policy that neglects the routing protocol.},
  archive      = {J_TCC},
  author       = {William Hoiles and S M Shahrear Tanzil and Vikram Krishnamurthy},
  doi          = {10.1109/TCC.2018.2855160},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {331-346},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Risk-averse caching policies for YouTube content in femtocell networks using density forecasting},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Provably secure and lightweight identity-based authenticated
data sharing protocol for cyber-physical cloud environment.
<em>TCC</em>, <em>9</em>(1), 318–330. (<a
href="https://doi.org/10.1109/TCC.2018.2834405">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Secure and efficient file storage and sharing via authenticated physical devices remain challenging to achieve in a cyber-physical cloud environment, particularly due to the diversity of devices used to access the services and data. Thus in this paper, we present a lightweight identity-based authenticated data sharing protocol to provide secure data sharing among geographically dispersed physical devices and clients. The proposed protocol is demonstrated to resist chosen-ciphertext attack (CCA) under the hardness assumption of decisional-Strong Diffie-Hellman (SDH) problem. We also evaluate the performance of the proposed protocol with existing data sharing protocols in terms of computational overhead, communication overhead, and response time.},
  archive      = {J_TCC},
  author       = {Arijit Karati and Ruhul Amin and SK Hafizul Islam and Kim-Kwang Raymond Choo},
  doi          = {10.1109/TCC.2018.2834405},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {318-330},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Provably secure and lightweight identity-based authenticated data sharing protocol for cyber-physical cloud environment},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Price-based resource allocation for edge computing: A market
equilibrium approach. <em>TCC</em>, <em>9</em>(1), 302–317. (<a
href="https://doi.org/10.1109/TCC.2018.2844379">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emerging edge computing paradigm promises to deliver superior user experience and enable a wide range of Internet of Things (IoT) applications. In this paper, we propose a new market-based framework for efficiently allocating resources of heterogeneous capacity-limited edge nodes (EN) to multiple competing services at the network edge. By properly pricing the geographically distributed ENs, the proposed framework generates a market equilibrium (ME) solution that not only maximizes the edge computing resource utilization but also allocates optimal resource bundles to the services given their budget constraints. When the utility of a service is defined as the maximum revenue that the service can achieve from its resource allotment, the equilibrium can be computed centrally by solving the Eisenberg-Gale (EG) convex program. We further show that the equilibrium allocation is Pareto-optimal and satisfies desired fairness properties including sharing incentive, proportionality, and envy-freeness. Also, two distributed algorithms, which efficiently converge to an ME, are introduced. When each service aims to maximize its net profit (i.e., revenue minus cost) instead of the revenue, we derive a novel convex optimization problem and rigorously prove that its solution is exactly an ME. Extensive numerical results are presented to validate the effectiveness of the proposed techniques.},
  archive      = {J_TCC},
  author       = {Duong Tung Nguyen and Long Bao Le and Vijay Bhargava},
  doi          = {10.1109/TCC.2018.2844379},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {302-317},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Price-based resource allocation for edge computing: A market equilibrium approach},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Outsourcing proofs of retrievability. <em>TCC</em>,
<em>9</em>(1), 286–301. (<a
href="https://doi.org/10.1109/TCC.2018.2865554">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Proofs of Retrievability (POR) are cryptographic proofs that enable a cloud provider to prove that a user can retrieve his file in its entirety. POR need to be frequently executed by the user to ensure that their files stored in the cloud can be fully retrieved at any point in time. To conduct and verify POR, users need to be equipped with devices that have network access, and that can tolerate the (non-negligible) computational overhead incurred by the verification process. This clearly hinders the large-scale adoption of POR by cloud users, since many users increasingly rely on portable devices that have limited computational capacity, or might not always have network access. In this paper, we introduce the notion of outsourced proofs of retrievability (OPOR), in which users can task an external auditor to perform and verify POR with the cloud provider. We argue that the OPOR setting is subject to security risks that have not been covered by existing POR security models. To remedy that, we propose a formal framework and a security model for OPOR. We then propose a generic procedure for transforming a public POR into an OPOR and we show the security of the resulting OPOR in our proposed security model. We demonstrate the transformation on two different instantiations of public POR schemes due to Shacham and Waters (Asiacrypt&#39;08)-one based on BLS signatures and one using RSA signatures. A shortcoming of this transformation is that the generated OPOR inherits the high computational overhead from the underlying public key cryptography. Consequently, we propose afterwards an OPOR that is build from a private POR by Shacham and Waters. We implement a prototype based on our solutions, and evaluate their performance in a realistic cloud setting. Our evaluation results show that our proposals minimize user effort, and incur negligible overhead on the auditor.},
  archive      = {J_TCC},
  author       = {Frederik Armknecht and Jens-Matthias Bohli and Ghassan Karame and Wenting Li},
  doi          = {10.1109/TCC.2018.2865554},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {286-301},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Outsourcing proofs of retrievability},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the efficiency of cloud providers: A DEA approach
incorporating categorical variables. <em>TCC</em>, <em>9</em>(1),
272–285. (<a href="https://doi.org/10.1109/TCC.2018.2850889">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing is a growing industry and it has already dominated many IT markets segments. Cloud providers offer numerous equivalent IaaS services aiming to fulfill clients&#39; requirements. In addition, cloud clients need to choose solutions that minimize costs without compromising efficiency though. However, not only the confusion due to the large variety of cloud services but also the uncertainty about the efficiency specifications that their cloud services should have, can make cloud computing services selection a difficult task for the users. Into this context, this paper presents an approach to a multi-attribute decision-making problem that focuses on the calculation of efficiency of IaaS cloud services as a measurable driver for both clients and providers. A DEA input-oriented model is described, which estimates efficiency of cloud services based on functional and non-functional parameters. Furthermore, the contribution of functional and non-functional features to the overall performance is examined. This innovative model urges providers to optimize the efficiency of their services aiming to increase their market share and, at the same time, assists clients in choosing a cost-effective cloud solution.},
  archive      = {J_TCC},
  author       = {E. Filiopoulou and P. Mitropoulou and N. Lionis and C. Michalakelis},
  doi          = {10.1109/TCC.2018.2850889},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {272-285},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {On the efficiency of cloud providers: A DEA approach incorporating categorical variables},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Network and application-aware cloud service selection in
peer-assisted environments. <em>TCC</em>, <em>9</em>(1), 258–271. (<a
href="https://doi.org/10.1109/TCC.2018.2865560">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are a vast number of cloud service providers, which offer virtual machines (VMs) with different configurations. From the companies perspective, an appropriate selection of VMs is an important issue, as the proper service selection leads to improved productivity, higher efficiency, and lower cost. An effective service selection cannot be done without a systematic approach due to the modularity of requests, the conflicts between requirements, and the impact of network parameters. In this paper, we introduce an innovative framework, called PCA, to solve service selection problem in the hybrid environment of peer-assisted, public, and private clouds. PCA detects the conflicts between the requests and enterprises policies, finds proper services based on the requirements, and reduces VMs rent and end-to-end network costs. PCA selects the services from multiple clouds to utilize resources and reduce the total cost. Our proposed framework utilizes set theory, B+ tree, and greedy algorithms to meet its goals. The simulation results show that PCA can reduce up to 30 percent of cloud-related costs and can achieve answers at least seven times faster in comparison to recent studies.},
  archive      = {J_TCC},
  author       = {Sina Askarnejad and Marzieh Malekimajd and Ali Movaghar},
  doi          = {10.1109/TCC.2018.2865560},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {258-271},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Network and application-aware cloud service selection in peer-assisted environments},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-cloud performance and security driven federated
workflow management. <em>TCC</em>, <em>9</em>(1), 240–257. (<a
href="https://doi.org/10.1109/TCC.2018.2849699">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated multi-cloud resource allocation for data-intensive application workflows is generally performed based on performance or quality of service (i.e., QSpecs) considerations. At the same time, end-to-end security requirements of these workflows across multiple domains are considered as an afterthought due to lack of standardized formalization methods. Consequently, diverse/heterogenous domain resource and security policies cause inter-conflicts between application&#39;s security and performance requirements that lead to sub-optimal resource allocations. In this paper, we present a joint performance and security-driven federated resource allocation scheme for data-intensive scientific applications. In order to aid joint resource brokering among multi-cloud domains with diverse/heterogenous security postures, we first define and characterize a data-intensive application&#39;s security specifications (i.e., SSpecs). Then we describe an alignment technique inspired by Portunes Algebra to homogenize the various domain resource policies (i.e., RSpecs) along an application&#39;s workflow lifecycle stages. Using such formalization and alignment, we propose a near optimal cost-aware joint QSpecs-SSpecs-driven, RSpecs-compliant resource allocation algorithm for multi-cloud computing resource domain/location selection as well as network path selection. We implement our security formalization, alignment, and allocation scheme as a framework, viz., “OnTimeURB” and validate it in a multi-cloud environment with exemplar data-intensive application workflows involving distributed computing and remote instrumentation use cases with different performance and security requirements.},
  archive      = {J_TCC},
  author       = {Matthew Dickinson and Saptarshi Debroy and Prasad Calyam and Samaikya Valluripally and Yuanxun Zhang and Ronny Bazan Antequera and Trupti Joshi and Tommi White and Dong Xu},
  doi          = {10.1109/TCC.2018.2849699},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {240-257},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Multi-cloud performance and security driven federated workflow management},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Live migration in bare-metal clouds. <em>TCC</em>,
<em>9</em>(1), 226–239. (<a
href="https://doi.org/10.1109/TCC.2018.2848981">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Live migration allows a running operating system (OS) to be moved to another physical machine with negligible downtime. Unfortunately, live migration is not supported in bare-metal clouds, which lease physical machines rather than virtual machines to offer maximum hardware performance. Since bare-metal clouds have no virtualization software, implementing live migration is difficult. Previous studies have proposed OS-level live migration; however, to prevent user intervention and broaden OS choices, live migration should be OS-independent. In addition, the overhead of live migration mechanisms should be as low as possible. This paper introduces BLMVisor, a live migration scheme for bare-metal clouds. To achieve OS-independent and lightweight live migration, BLMVisor utilizes a very thin hypervisor that exposes physical hardware devices to the guest OS directly rather than virtualizing the devices. The hypervisor captures, transfers, and reconstructs physical device states by monitoring access from the guest OS and controlling the physical devices with effective techniques. To minimize performance degradation, the hypervisor is mostly idle after completing the live migration. A performance evaluation confirmed that the OS performance with BLMVisor is comparable to that of a bare-metal machine.},
  archive      = {J_TCC},
  author       = {Takaaki Fukai and Takahiro Shinagawa and Kazuhiko Kato},
  doi          = {10.1109/TCC.2018.2848981},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {226-239},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Live migration in bare-metal clouds},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Lightweight and privacy-preserving delegatable proofs of
storage with data dynamics in cloud storage. <em>TCC</em>,
<em>9</em>(1), 212–225. (<a
href="https://doi.org/10.1109/TCC.2018.2851256">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud storage has been in widespread use nowadays, which alleviates users&#39; burden of local data storage. Meanwhile, how to ensure the security and integrity of the outsourced data stored in a cloud storage server has also attracted enormous attention from researchers. Proofs of storage (POS) is the main technique introduced to address this problem. Publicly verifiable POS allowing a third party to verify the data integrity on behalf of the data owner significantly improves the scalability of cloud service. However, most of existing publicly verifiable POS schemes are extremely slow to compute authentication tags for all data blocks due to many expensive group exponentiation operations, even much slower than typical network uploading speed, and thus it becomes the bottleneck of the setup phase of the POS scheme. In this article, we propose a new variant formulation called “Delegatable Proofs of Storage (DPOS)”. Then, we construct a lightweight privacy-preserving DPOS scheme, which on one side is as efficient as private POS schemes, and on the other side can support third party auditor and can switch auditors at anytime, close to the functionalities of publicly verifiable POS schemes. Compared to traditional publicly verifiable POS schemes, we speed up the tag generation process by at least several hundred times, without sacrificing efficiency in any other aspect. In addition, we extend our scheme to support fully dynamic operations with high efficiency, reducing the computation of any data update to O(log n) and simultaneously only requiring constant communication costs. We prove that our scheme is sound and privacy preserving against auditor in the standard model. Experimental results verify the efficient performance of our scheme.},
  archive      = {J_TCC},
  author       = {Anjia Yang and Jia Xu and Jian Weng and Jianying Zhou and Duncan S. Wong},
  doi          = {10.1109/TCC.2018.2851256},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {212-225},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Lightweight and privacy-preserving delegatable proofs of storage with data dynamics in cloud storage},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Karma: Cost-effective geo-replicated cloud storage with
dynamic enforcement of causal consistency. <em>TCC</em>, <em>9</em>(1),
197–211. (<a href="https://doi.org/10.1109/TCC.2018.2842184">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal consistency has emerged as an attractive middle-ground to architecting cloud storage systems, as it allows for high availability and low latency, while supporting semantics stronger than eventual consistency. However, causally-consistent cloud storage systems have seen limited deployment in practice. A key factor is these systems employ full replication of all the data in all the data centers ( DCs ), incurring high cost. A simple extension of current causal systems to support partial replication by clustering DCs into rings incurs availability and latency problems. We propose Karma , the first system to enable causal consistency for partitioned data stores while achieving the cost advantages of partial replication without the availability and latency problems of the simple extension. Our evaluation with 64 servers emulating 8 geo-distributed DCs shows that Karma (i) incurs much lower cost than a fully-replicated causal store (obviously due to the lower replication factor); and (ii) offers higher availability and better performance than the above partial-replication extension at similar costs.},
  archive      = {J_TCC},
  author       = {Tariq Mahmood and Shankaranarayanan Puzhavakath Narayanan and Sanjay Rao and T. N. Vijaykumar and Mithuna Thottethodi},
  doi          = {10.1109/TCC.2018.2842184},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {197-211},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Karma: Cost-effective geo-replicated cloud storage with dynamic enforcement of causal consistency},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hedonic pricing of cloud computing services. <em>TCC</em>,
<em>9</em>(1), 182–196. (<a
href="https://doi.org/10.1109/TCC.2018.2858266">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud service providers (CSP) and cloud consumers often need to forecast the cloud price to optimize their business strategy. However, pricing of cloud services is a challenging task due to its services complexity and dynamic nature of the ever-changing environment. Moreover, the cloud pricing based on consumers&#39; willingness to pay (W2P) becomes even more challenging due to the subjectiveness of consumers&#39; experiences and implicit values of some non-marketable features, such as burstable CPU, dedicated server, and cloud data center global footprints. Unfortunately, many existing pricing models often cannot support value-based pricing. In this paper, we propose a novel solution based on value-based pricing, which does not only consider how much does the service cost (or intrinsic values) to a CSP but also how much a customer is willing to pay (or extrinsic values) for the service. We demonstrate that the cloud extrinsic values would not only become one of the competitive advantages for CSPs to lead the cloud market but also increase the profit margin. Our approach is often referred to as a hedonic pricing model. We show that our model can capture the value of non-marketable features. This value is about 43.4 percent on average above the baseline, which is often ignored by many traditional cloud pricing models. We also show that Average Annual Growth Rate (AAGR) of Amazon Web Services&#39; (AWS) is about -20.0 percent per annum between 2008 and 2017, ceteris paribus. In comparison with Moore&#39;s law (-50 percent per annum), it is at a far slower pace. We argue this value is Moore&#39;s law equivalent in the cloud. The primary goal of this research is to provide a less biased pricing model for cloud decision makers to develop their optimizing investment strategy.},
  archive      = {J_TCC},
  author       = {Caesar Wu and Adel Nadjaran Toosi and Rajkumar Buyya and Kotagiri Ramamohanarao},
  doi          = {10.1109/TCC.2018.2858266},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {182-196},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Hedonic pricing of cloud computing services},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Enhancing performance and energy efficiency for hybrid
workloads in virtualized cloud environment. <em>TCC</em>, <em>9</em>(1),
168–181. (<a href="https://doi.org/10.1109/TCC.2018.2837040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Virtualization has attained mainstream status in enterprise IT industry. Despite its widespread adoption, it is known that virtualization also introduces non-trivial overhead when tasks are executed on a virtual machine (VM). In particular, a combined effect from device virtualization overhead and CPU scheduling latency can cause performance degradation when computation intensive tasks and I/O intensive tasks are co-located on a VM. Such an interference also causes extra energy consumption. In this paper, we present Hylics, a novel solution that enables efficient data traverse paths for both I/O and computation intensive workloads. This is achieved with the provision of in-memory file system and network service at the hypervisor level. Several important design issues are pinpointed and addressed during our prototype implementation, including efficient intermediate data sharing, network service offloading, and QoS-aware memory usage management. Based on our real-world deployment on KVM, we show that Hylics can significantly improve computation and I/O performance for hybrid workloads. Moreover, this design also alleviates the existing virtualization overhead and naturally optimizes the overall energy efficiency.},
  archive      = {J_TCC},
  author       = {Chi Xu and Xiaoqiang Ma and Ryan Shea and Haiyang Wang and Jiangchuan Liu},
  doi          = {10.1109/TCC.2018.2837040},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {168-181},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Enhancing performance and energy efficiency for hybrid workloads in virtualized cloud environment},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient replica migration scheme for distributed cloud
storage systems. <em>TCC</em>, <em>9</em>(1), 155–167. (<a
href="https://doi.org/10.1109/TCC.2018.2858792">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the wide adoption of large-scale internet services and big data, the cloud has become the ideal environment to satisfy the ever-growing storage demand. In this context, data replication has been touted as the ultimate solution to improve data availability and reduce access time. However, replica management systems usually need to migrate and create a large number of data replicas over time between and within data centers, incurring a large overhead in terms of network load and availability. In this paper, we propose CRANE, an effiCient Replica migrAtion scheme for distributed cloud Storage systEms. CRANE complements any replica placement algorithm by efficiently managing replica creation in geo-distributed infrastructures in order to (1) minimize the time needed to copy the data to the new replica location, (2) avoid network congestion, and (3) ensure the minimum desired availability for the data. Through simulation and experimental results, we show that CRANE provides a sub-optimal solution for the replica migration problem with lower computational complexity than its integer linear program formulation. We also show that, compared to OpenStack Swift, CRANE is able to reduce by up to 60 percent the replica creation and migration time and by up to 50 percent the inter-data center network traffic while ensuring the minimum required data availability.},
  archive      = {J_TCC},
  author       = {Amina Mseddi and Mohammad A. Salahuddin and Mohamed Faten Zhani and Halima Elbiaze and Roch H. Glitho},
  doi          = {10.1109/TCC.2018.2858792},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {155-167},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Efficient replica migration scheme for distributed cloud storage systems},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient algorithm for secure outsourcing of modular
exponentiation with single server. <em>TCC</em>, <em>9</em>(1), 145–154.
(<a href="https://doi.org/10.1109/TCC.2018.2851245">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outsourcing computation allows an outsourcer with limited resource to delegate the computation load to a powerful server without the exposure of true inputs and outputs. It is well known that modular exponentiation is one of the most expensive operations in public key cryptosystems. Currently, most of outsourcing algorithms for modular exponentiation are based on two untrusted servers or have small checkability with single server. In this paper, we first propose an efficient outsourcing algorithm of modular exponentiation based on two untrusted servers, where the outsourcer can detect the error based on Euler theorem with a probability of 1 if one of the servers misbehaves. We then present an outsourcing algorithm of modular exponentiation with single server, and the outsourcer can also check the failure with a probability of 1. Therefore, the proposed algorithm with single server improves efficiency and checkability simultaneously compare with the previous ones. Finally, we provide the experimental evaluations to demonstrate that the proposed two algorithms are the most efficient ones in all of the outsourcing algorithms for an outsourcer.},
  archive      = {J_TCC},
  author       = {Yanli Ren and Min Dong and Zhenxing Qian and Xinpeng Zhang and Guorui Feng},
  doi          = {10.1109/TCC.2018.2851245},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {145-154},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Efficient algorithm for secure outsourcing of modular exponentiation with single server},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic VM scaling: Provisioning and pricing through an
online auction. <em>TCC</em>, <em>9</em>(1), 131–144. (<a
href="https://doi.org/10.1109/TCC.2018.2840999">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today&#39;s IaaS clouds allow dynamic scaling of VMs allocated to a user, according to real-time demand of the user. There are two types of scaling: horizontal scaling (scale-out) by allocating more VM instances to the user, and vertical scaling (scale-up) by boosting resources of VMs owned by the user. It has been a daunting issue how to efficiently allocate the resources on physical servers to meet the scaling demand of users on the go, which achieves the best server utilization and user utility. An accompanying critical challenge is how to effectively charge the incremental resources, such that the economic benefits of both the cloud provider and cloud users are guaranteed. There has been online auction design dealing with dynamic VM provisioning, where the resource bids are not related to each other, failing to handle VM scaling where later bids may rely on earlier bids of the same user. As the first in the literature, this paper designs an efficient, truthful online auction for resource provisioning and pricing in the practical cases of dynamic VM scaling, where: (i) users bid for customized VMs to use in future durations, and can bid again in the following time to increase resources, indicating both scale-up and scale-out options; (ii) the cloud provider packs the demanded VMs on heterogeneous servers for energy cost minimization on the go. We carefully design resource prices maintained for each type of resource on each server to achieve threshold-based online allocation and charging, as well as a novel competitive analysis technique based on submodularity of the offline objective, to show a good competitive ratio is achieved. The efficacy of the online auction is validated through solid theoretical analysis and trace-driven simulations.},
  archive      = {J_TCC},
  author       = {Xiaoxi Zhang and Zhiyi Huang and Chuan Wu and Zongpeng Li and Francis C. M. Lau},
  doi          = {10.1109/TCC.2018.2840999},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {131-144},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Dynamic VM scaling: Provisioning and pricing through an online auction},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cost optimal data center servers: A voltage scaling
approach. <em>TCC</em>, <em>9</em>(1), 118–130. (<a
href="https://doi.org/10.1109/TCC.2018.2844823">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data centers have experienced dramatic growth in recent years in order to meet the ever-increasing demand for computing. As a result, minimizing the electrical cost to operate data centers has become a crucial issue. In this paper, we observe that electricity prices change over time, and that we can take advantage of periods with low prices by scaling up processor speeds to perform more work, while scaling down speeds during high price periods to reduce cost. We apply this observation to several settings. First, we consider an offline setting which assumes future electricity prices are given, and propose an efficient algorithm for optimally scaling a processor&#39;s speed in order to minimize the total electrical cost for completing a task by a deadline. We then consider a more realistic stochastic setting in which future prices are not known, but vary according to a Markov model. We present another efficient algorithm for minimizing the expected cost to meet a deadline. We performed a number of experiments using real electricity price traces to test the performance of our algorithms. We show that our stochastic algorithm is light-weight and relies only on easily obtainable price data, but that it achieves excellent performance, with only a 1 percent cost difference on average from the optimal offline algorithm. In addition, the stochastic algorithm significantly reduced costs compared to several candidate algorithms.},
  archive      = {J_TCC},
  author       = {Wei Zhang and Yonggang Wen and Loi Lei Lai and Fang Liu and Rui Fan},
  doi          = {10.1109/TCC.2018.2844823},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {118-130},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Cost optimal data center servers: A voltage scaling approach},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cooperative set homomorphic proofs for data possession
checking in clouds. <em>TCC</em>, <em>9</em>(1), 102–117. (<a
href="https://doi.org/10.1109/TCC.2018.2865343">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outsourcing an increasing amount of data to a third party raises a number of security and privacy challenges, namely remote data integrity verification. Indeed, proofs for data possession checking address the verification that some previously outsourced data blocks across multiple storing nodes are correctly stored and fully available. In this paper, we propose a new set homomorphic proof of data possession, referred to as SHoPS, supporting several operations like aggregation of proofs. SHoPS is a deterministic Proof of Data Possession (PDP) scheme, based on an interactive proof protocol. Our approach has several advantages. First, it enables several proofs to be aggregated and a subset of data files&#39; proofs to be verified, while providing an attractive communication overhead. Second, it supports public verifiability where the verification process can be delegated to another entity, thus releasing the data owner from the cumbersome task of periodical verifications. Third, SHoPS is efficient and provably secure, as it is resistant to the fraudulence of the prover and the leakage of verified data. Finally, a theoretical performances&#39; analysis shows that SHoPS performs better in terms of functionality, communication and computation overhead compared to closely related works and experimental results point out the applicability of the proposed scheme in real world scenarios.},
  archive      = {J_TCC},
  author       = {Nesrine Kaaniche and Maryline Laurent and Sébastien Canard},
  doi          = {10.1109/TCC.2018.2865343},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {102-117},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Cooperative set homomorphic proofs for data possession checking in clouds},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An empirical study on data flow bugs in business processes.
<em>TCC</em>, <em>9</em>(1), 88–101. (<a
href="https://doi.org/10.1109/TCC.2018.2844247">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An increasing number of service-based business processes are being developed with the booming of BPaaS (Business Process as a Service) in cloud computing. The profits and performance of enterprises strongly depend on the soundness of their processes being bereft of control flow and data flow bugs. Although some work has focused on the detection of control flow bugs, few studies have comprehensively and empirically investigated data flow bugs in business processes. To this end, we report an empirical study on data flow bugs in business (BPEL) processes. Our analysis of 178 real-world BPEL processes reveals that data flow bugs are surprisingly common: 94 BPEL processes involve data flow bugs, among which redundant output is predominant. The distribution and common scenarios of data flow bugs provide a reference for BPEL process designers. We also investigate the correlation between process complexity metrics and data flow bugs. Based on the statistics of the process complexity metrics and data flow bugs in our empirical study, we present a method to select appropriate metrics as features of BPEL processes and utilize state-of-the-art supervised learning algorithms to predict data flow bugs in an unseen BPEL process. The prediction accuracies of the different classification algorithms exceed 90 percent on average when using our selected metrics.},
  archive      = {J_TCC},
  author       = {Wei Song and Chengzhen Zhang and Hans-Arno Jacobsen},
  doi          = {10.1109/TCC.2018.2844247},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {88-101},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {An empirical study on data flow bugs in business processes},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). An efficient and secured framework for mobile cloud
computing. <em>TCC</em>, <em>9</em>(1), 79–87. (<a
href="https://doi.org/10.1109/TCC.2018.2847347">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smartphone devices are widely used in our daily lives. However, these devices exhibit limitations, such as short battery lifetime, limited computation power, small memory size and unpredictable network connectivity. Therefore, numerous solutions have been proposed to mitigate these limitations and extend the battery lifetime with the use of the offloading technique. In this paper, a novel framework is proposed to offload intensive computation tasks from the mobile device to the cloud. This framework uses an optimization model to determine the offloading decision dynamically based on four main parameters, namely, energy consumption, CPU utilization, execution time, and memory usage. In addition, a new security layer is provided to protect the transferred data in the cloud from any attack. The experimental results showed that the framework can select a suitable offloading decision for different types of mobile application tasks while achieving significant performance improvement. Moreover, different from previous techniques, the framework can protect application data from any threat.},
  archive      = {J_TCC},
  author       = {Ibrahim A. Elgendy and Wei-Zhe Zhang and Chuan-Yi Liu and Ching-Hsien Hsu},
  doi          = {10.1109/TCC.2018.2847347},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {79-87},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {An efficient and secured framework for mobile cloud computing},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Aggregation-based colocation datacenter energy management in
wholesale markets. <em>TCC</em>, <em>9</em>(1), 66–78. (<a
href="https://doi.org/10.1109/TCC.2018.2836424">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study how colocation datacenter energy cost can be effectively reduced in the wholesale electricity market via cooperative power procurement. Intuitively, by aggregating workloads and renewables across a group of tenants in a colocation datacenter, the overall power demand uncertainty of the colocation datacenter can be reduced, resulting in less chance of being penalized when participating in the wholesale electricity market. We use cooperative game theory to model the cooperative electricity procurement process of tenants as a cooperative game, and show the cost saving benefits of aggregation. Then, a cost allocation scheme based on the marginal contribution of each tenant to the total expected cost is proposed to distribute the aggregation benefits among the participating tenants. Besides, we propose proportional cost allocation scheme to distribute the aggregation benefits among the participating tenants after realizations of power demand and market prices. Finally, numerical experiments based on real-world traces are conducted to illustrate the benefits of aggregation compared to noncooperative power procurement.},
  archive      = {J_TCC},
  author       = {Yuanxiong Guo and Miao Pan and Yanmin Gong},
  doi          = {10.1109/TCC.2018.2836424},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {66-78},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Aggregation-based colocation datacenter energy management in wholesale markets},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Applying buffer to SDN switches: Benefits analysis and
mechanism design. <em>TCC</em>, <em>9</em>(1), 54–65. (<a
href="https://doi.org/10.1109/TCC.2018.2846620">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software-Defined-Networking (SDN) is progressively dominating the dynamic management for timely network trouble shooting and fine grained traffic scheduling in data center networks. One critical issue in SDN is to reduce the communication overhead between the switches and the controller. Such overhead is mainly caused by handling miss-match packets, because for each miss-match packet, a switch will send a request to the controller asking for forwarding rule. Existing approaches to address this problem generally need to deploy intermediate proxy or authority switches to hold rule copies, so as to reduce the number of requests sent to the controller. In this paper, we argue that using the intrinsic buffer in a SDN switch can also greatly reduce the communication overhead without using additional devices. If a switch buffers each miss-match packet, only a few header fields instead of the entire packet are required to be sent to the controller. Experiment results show that this can reduce 78.7 percent control traffic and 37 percent controller overhead at the cost of increasing only 5.6 percent switch overhead on average. If the proposed flow-granularity buffer mechanism is adopted, only one request message needs to be sent to the controller for a new flow with many arrival packets. Thus the control traffic and controller overhead can be further reduced by 64 percent and 35.7 percent respectively on average without increasing the switch overhead.},
  archive      = {J_TCC},
  author       = {Fuliang Li and Jiannong Cao and Xingwei Wang and Yinchu Sun and Tian Pan and Xuefeng Liu},
  doi          = {10.1109/TCC.2018.2846620},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {54-65},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Applying buffer to SDN switches: Benefits analysis and mechanism design},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive resource management for analyzing video streams
from globally distributed network cameras. <em>TCC</em>, <em>9</em>(1),
40–53. (<a href="https://doi.org/10.1109/TCC.2018.2836907">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There has been tremendous growth in the amount of visual data available on the Internet in recent years. One type of visual data of particular interest is produced by network cameras providing real-time views. Millions of network cameras around the world continuously stream data to viewers connected to the Internet. This data may be used by a wide variety of applications such as enhancing public safety, urban planning, emergency response, and traffic management which are computationally intensive. Analyzing this data requires significant amounts of computational resources. Cloud computing can be a preferred solution for meeting the resource requirements for analyzing these data. There are many options when selecting cloud instances (amounts of memory, number of cores, locations, etc.). Inefficient provisioning of cloud resources may become costly in pay-per-use cloud computing. This paper presents a method to select cloud instances in order to meet the performance requirements for visual data analysis at a lower cost. We measure the frame rates when analyzing the data using different computer vision methods and model the relationships between frame rates and resource utilizations. We formulate the problem of managing cloud resources as a Variable Size Bin Packing Problem and use a heuristic solution. Experiments using Amazon EC2 validate the model and demonstrate that the proposed solution can reduce the cost up to 62 percent while meeting the performance requirements.},
  archive      = {J_TCC},
  author       = {Anup Mohan and Ahmed S. Kaseb and Yung-Hsiang Lu and Thomas J. Hacker},
  doi          = {10.1109/TCC.2018.2836907},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {40-53},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Adaptive resource management for analyzing video streams from globally distributed network cameras},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Achieving secure, universal, and fine-grained query results
verification for secure search scheme over encrypted cloud data.
<em>TCC</em>, <em>9</em>(1), 27–39. (<a
href="https://doi.org/10.1109/TCC.2017.2709318">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Secure search techniques over encrypted cloud data allow an authorized user to query data files of interest by submitting encrypted query keywords to the cloud server in a privacy-preserving manner. However, in practice, the returned query results may be incorrect or incomplete in the dishonest cloud environment. For example, the cloud server may intentionally omit some qualified results to save computational resources and communication overhead. Thus, a well-functioning secure query system should provide a query results verification mechanism that allows the data user to verify results. In this paper, we design a secure, easily integrated, and fine-grained query results verification mechanism, by which, given an encrypted query results set, the query user not only can verify the correctness of each data file in the set but also can further check how many or which qualified data files are not returned if the set is incomplete before decryption. The verification scheme is loose-coupling to concrete secure search techniques and can be very easily integrated into any secure query scheme. We achieve the goal by constructing secure verification object for encrypted cloud data. Furthermore, a short signature technique with extremely small storage cost is proposed to guarantee the authenticity of verification object and a verification object request technique is presented to allow the query user to securely obtain the desired verification object. Performance evaluation shows that the proposed schemes are practical and efficient.},
  archive      = {J_TCC},
  author       = {Hui Yin and Zheng Qin and JiXin Zhang and Lu Ou and Keqin Li},
  doi          = {10.1109/TCC.2017.2709318},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {27-39},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {Achieving secure, universal, and fine-grained query results verification for secure search scheme over encrypted cloud data},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new service mechanism for profit optimizations of a cloud
provider and its users. <em>TCC</em>, <em>9</em>(1), 14–26. (<a
href="https://doi.org/10.1109/TCC.2017.2701793">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we try to design a service mechanism for profit optimizations of both a cloud provider and its multiple users. We consider the problem from a game theoretic perspective and characterize the relationship between the cloud provider and its multiple users as a Stackelberg game, in which the strategies of all users are subject to that of the cloud provider. The cloud provider tries to select and provision appropriate servers and configure a proper request allocation strategy to reduce energy cost while satisfying its cloud users at the same time. We approximate its servers selection space by adding a controlling parameter and configure an optimal request allocation strategy. For each user, we design a utility function which combines the net profit with time efficiency and try to maximize its value under the strategy of the cloud provider. We formulate the competitions among all users as a generalized Nash equilibrium problem (GNEP). We solve the problem by employing variational inequality (VI) theory and prove that there exists a generalized Nash equilibrium solution set for the formulated GNEP. Finally, we propose an iterative algorithm (IA), which characterizes the whole process of our proposed service mechanism. We conduct some numerical calculations to verify our theoretical analyses. The experimental results show that our IA algorithm can benefit both of a cloud provider and its multiple users by configuring proper strategies.},
  archive      = {J_TCC},
  author       = {Chubo Liu and Kenli Li and Keqin Li and Rajkumar Buyya},
  doi          = {10.1109/TCC.2017.2701793},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {14-26},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {A new service mechanism for profit optimizations of a cloud provider and its users},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A game approach to multi-servers load balancing with
load-dependent server availability consideration. <em>TCC</em>,
<em>9</em>(1), 1–13. (<a
href="https://doi.org/10.1109/TCC.2018.2790404">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we focus on request migration strategies among multi-servers for load balancing. Different from the general load balancing problem, we consider it under a distributed, non-cooperative, and competitive environment. Due to the mentioned characteristics, we view our problem from a game theoretic perspective and formulate it into a non-cooperative game among the multiple servers, in which each server is informed with incomplete information of other servers. For each server, we define its expected response time as a disutility function and try to minimize its value. We also take into account server availability, which impacts the processing capacity of a server and thus its disutility. We solve the problem by employing variational inequality (VI) theory and prove that there exists a Nash equilibrium solution set for the formulated game. Then, we propose an iterative proximal algorithm (IPA) to compute a Nash equilibrium solution. The convergence of the IPA algorithm is also analyzed and we find that it converges to a Nash equilibrium. Finally, we conduct some numerical calculations to verify our theoretical analyses. The experimental results show that our proposed IPA algorithm converges to a Nash equilibrium very quickly and significantly decreases the disutilities of all servers by configuring a proper request migration strategy.},
  archive      = {J_TCC},
  author       = {Chubo Liu and Kenli Li and Keqin Li},
  doi          = {10.1109/TCC.2018.2790404},
  journal      = {IEEE Transactions on Cloud Computing},
  number       = {1},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Cloud Comput.},
  title        = {A game approach to multi-servers load balancing with load-dependent server availability consideration},
  volume       = {9},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
