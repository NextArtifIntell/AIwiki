<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TEVC_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tevc---90">TEVC - 90</h2>
<ul>
<li><details>
<summary>
(2021a). IEEE transactions on evolutionary computation society
information. <em>TEVC</em>, <em>25</em>(6), C3. (<a
href="https://doi.org/10.1109/TEVC.2021.3129004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Provides a listing of current committee members and society officers.},
  archive      = {J_TEVC},
  doi          = {10.1109/TEVC.2021.3129004},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {C3},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {IEEE transactions on evolutionary computation society information},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Introducing IEEE collabratec. <em>TEVC</em>,
<em>25</em>(6), 1179. (<a
href="https://doi.org/10.1109/TEVC.2021.3129126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advertisement, IEEE. IEEE Collabratec is a new, integrated online community where IEEE members, researchers, authors, and technology professionals with similar fields of interest can network and collaborate, as well as create and manage content. Featuring a suite of powerful online networking and collaboration tools, IEEE Collabratec allows you to connect according to geographic location, technical interests, or career pursuits. You can also create and share a professional identity that showcases key accomplishments and participate in groups focused around mutual interests, actively learning from and contributing to knowledgeable communities. All in one place! Learn about IEEE Collabratec at ieeecollabratec.org.},
  archive      = {J_TEVC},
  doi          = {10.1109/TEVC.2021.3129126},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1179},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Introducing IEEE collabratec},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Statistical models for the analysis of optimization
algorithms with benchmark functions. <em>TEVC</em>, <em>25</em>(6),
1163–1177. (<a href="https://doi.org/10.1109/TEVC.2021.3081167">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Frequentist statistical methods, such as hypothesis testing, are standard practices in studies that provide benchmark comparisons. Unfortunately, these methods have often been misused, e.g., without testing for their statistical test assumptions or without controlling for familywise errors in multiple group comparisons, among several other problems. Bayesian data analysis (BDA) addresses many of the previously mentioned shortcomings but its use is not widely spread in the analysis of empirical data in the evolutionary computing community. This article provides three main contributions. First, we motivate the need for utilizing BDA and provide an overview of this topic. Second, we discuss the practical aspects of BDA to ensure that our models are valid and the results are transparent. Finally, we provide five statistical models that can be used to answer multiple research questions. The online Appendix provides a step-by-step guide on how to perform the analysis of the models discussed in this article, including the code for the statistical models, the data transformations, and the discussed tables and figures.},
  archive      = {J_TEVC},
  author       = {David Issa Mattos and Jan Bosch and Helena Holmström Olsson},
  doi          = {10.1109/TEVC.2021.3081167},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1163-1177},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Statistical models for the analysis of optimization algorithms with benchmark functions},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). A divide-and-conquer genetic programming algorithm with
ensembles for image classification. <em>TEVC</em>, <em>25</em>(6),
1148–1162. (<a href="https://doi.org/10.1109/TEVC.2021.3082112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Genetic programming (GP) has been applied to feature learning in image classification and achieved promising results. However, one major limitation of existing GP-based methods is the high computational cost, which may limit their applications on large-scale image classification tasks. To address this, this article develops a divide-and-conquer GP algorithm with knowledge transfer (KT) and ensembles to achieve fast feature learning in image classification. In the new algorithm framework, a divide-and-conquer strategy is employed to split the training data and the population into small subsets or groups to reduce computational time. A new KT method is proposed to improve GP learning performance. A new fitness function based on log loss and a new ensemble formulation strategy are developed to build an effective ensemble for image classification. The performance of the proposed approach has been examined on 12 image classification datasets of varying difficulty. The results show that the new approach achieves better classification performance in significantly less computation time than the baseline GP-based algorithm. The comparisons with state-of-the-art algorithms show that the new approach achieves better or comparable performance in almost all the comparisons. Further analysis demonstrates the effectiveness of ensemble formulation and KT in the proposed approach.},
  archive      = {J_TEVC},
  author       = {Ying Bi and Bing Xue and Mengjie Zhang},
  doi          = {10.1109/TEVC.2021.3082112},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1148-1162},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A divide-and-conquer genetic programming algorithm with ensembles for image classification},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Set theory-based operator design in evolutionary algorithms
for solving knapsack problems. <em>TEVC</em>, <em>25</em>(6), 1133–1147.
(<a href="https://doi.org/10.1109/TEVC.2021.3080683">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knapsack problems (KPs) are famous combinatorial optimization problems that can be solved by evolutionary algorithms (EAs). In such methods, a key step is to produce new solutions for each generation. However, traditional EAs cannot guarantee the feasibility of the new solutions, causing ineffectiveness or inefficiency of the methods. Owing to the fact that directly generating a feasible solution is difficult, a practical way is to generate a potential solution and transform it to a feasible one if necessary; more ideally, transform it to the local-optimal solution. Essentially, this transforming process is to map an element of the solution set to an element of the feasible solution set, which can be analyzed and optimized from a new perspective, i.e., the set theory (ST). In this article, we provide new explanations for the transforming process of solutions based on ST and summarize the properties that the transforming process should satisfy. Furthermore, based on the proposed concepts and theories, we put forward the ideas for improving the transforming process. Consequently, some new operators for KPs are proposed. Experimental results demonstrate the superiority of the proposed operators.},
  archive      = {J_TEVC},
  author       = {Ran Wang and Zichao Zhang},
  doi          = {10.1109/TEVC.2021.3080683},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1133-1147},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Set theory-based operator design in evolutionary algorithms for solving knapsack problems},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evolutionary neural architecture search for high-dimensional
skip-connection structures on DenseNet style networks. <em>TEVC</em>,
<em>25</em>(6), 1118–1132. (<a
href="https://doi.org/10.1109/TEVC.2021.3083315">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks hold state-of-the-art results for image classification, and many neural architecture search algorithms have been proposed to discover high performance convolutional neural networks. However, the use of neural architecture search for the discovery of skip-connection structures, an important element in modern convolutional neural networks, is limited within the literature. Furthermore, while many neural architecture search algorithms utilize performance estimation techniques to reduce computation time, empirical evaluations of these performance estimation techniques remain limited. This work focuses on utilizing evolutionary neural architecture search to examine the search space of networks, which follow a fundamental DenseNet structure, but have no fixed skip connections. In particular, a genetic algorithm is designed, which searches the space consisting of all networks between a standard feedforward network and the corresponding DenseNet. To design the algorithm, lower fidelity performance estimation of this class of networks is examined and presented. The final algorithm finds networks that are more accurate than DenseNets on CIFAR10 and CIFAR100, and have fewer trainable parameters. The structures found by the algorithm are examined to shed light on the importance of different types of skip-connection structures in convolutional neural networks, including the discovery of a simple skip-connection removal, which improves DenseNet performance on CIFAR10.},
  archive      = {J_TEVC},
  author       = {Damien O’Neill and Bing Xue and Mengjie Zhang},
  doi          = {10.1109/TEVC.2021.3083315},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1118-1132},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolutionary neural architecture search for high-dimensional skip-connection structures on DenseNet style networks},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Partial evaluation strategies for expensive evolutionary
constrained optimization. <em>TEVC</em>, <em>25</em>(6), 1103–1117. (<a
href="https://doi.org/10.1109/TEVC.2021.3078486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained optimization problems (COPs) are frequently encountered in real-world design applications. For some COPs, the evaluation of the objective(s) and/or constraint(s) may involve significant computational/temporal/financial cost. Such problems are referred to as expensive COPs (ECOPs). Surrogate modeling has been widely used in conjunction with optimization methods for such problems, wherein the search is partially driven by an approximate function instead of true expensive evaluations. However, for any true evaluation, nearly all existing methods compute all objective and constraint values together as one batch. Such full evaluation approaches may be inefficient for cases where the objective/constraint(s) can be evaluated independently of each other. In this article, we propose and study a constraint handling strategy for ECOPs using partial evaluations. The constraints are evaluated in a sequence determined based on their likelihood of being violated; and the evaluation is aborted if a constraint violation is encountered. Modified ranking strategies are introduced to effectively rank the solutions using the limited information thus obtained, while saving on significant function evaluations. The proposed algorithm is compared with a number of its variants to establish the utility of its key components systematically. Numerical experiments and benchmarking are conducted on a range of mathematical and engineering design problems to demonstrate the efficacy of the approach compared to state-of-the-art evolutionary optimization approaches.},
  archive      = {J_TEVC},
  author       = {Kamrul Hasan Rahi and Hemant Kumar Singh and Tapabrata Ray},
  doi          = {10.1109/TEVC.2021.3078486},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1103-1117},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Partial evaluation strategies for expensive evolutionary constrained optimization},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Identifying influential spreaders in social networks through
discrete moth-flame optimization. <em>TEVC</em>, <em>25</em>(6),
1091–1102. (<a href="https://doi.org/10.1109/TEVC.2021.3081478">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Influence maximization in a social network refers to the selection of node sets that support the fastest and broadest propagation of information under a chosen transmission model. The efficient identification of such influence-maximizing groups is an active area of research with diverse practical relevance. Greedy-based methods can provide solutions of reliable accuracy, but the computational cost of the required Monte Carlo simulations renders them infeasible for large networks. Meanwhile, although network structure-based centrality methods can be efficient, they typically achieve poor recognition accuracy. Here, we establish an effective influence assessment model based both on the total valuation and variance in valuation of neighbor nodes, motivated by the possibility of unreliable communication channels. We then develop a discrete moth-flame optimization method to search for influence-maximizing node sets, using a local crossover and mutation evolution scheme atop the canonical moth position updates. To accelerate convergence, a search area selection scheme derived from a degree-based heuristic is used. The experimental results on five real-world social networks, comparing our proposed method against several alternatives in the current literature, indicates our approach to be effective and robust in tackling the influence maximization problem.},
  archive      = {J_TEVC},
  author       = {Lu Wang and Lei Ma and Chao Wang and Neng-Gang Xie and Jin Ming Koh and Kang Hao Cheong},
  doi          = {10.1109/TEVC.2021.3081478},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1091-1102},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Identifying influential spreaders in social networks through discrete moth-flame optimization},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Autoencoding with a classifier system. <em>TEVC</em>,
<em>25</em>(6), 1079–1090. (<a
href="https://doi.org/10.1109/TEVC.2021.3079320">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autoencoders are data-specific compression algorithms learned automatically from examples. The predominant approach has been to construct single large global models that cover the domain. However, training and evaluating models of increasing size comes at the price of additional time and computational cost. Conditional computation, sparsity, and model pruning techniques can reduce these costs while maintaining performance. Learning classifier systems (LCSs) are a framework for adaptively subdividing input spaces into an ensemble of simpler local approximations that together cover the domain. LCS perform conditional computation through the use of a population of individual gating/guarding components, each associated with a local approximation. This article explores the use of an LCS to adaptively decompose the input domain into a collection of small autoencoders, where local solutions of different complexity may emerge. In addition to the benefits in convergence time and computational cost, it is shown possible to reduce the code size as well as the resulting decoder computational cost when compared with the global model equivalent.},
  archive      = {J_TEVC},
  author       = {Richard J. Preen and Stewart W. Wilson and Larry Bull},
  doi          = {10.1109/TEVC.2021.3079320},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1079-1090},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Autoencoding with a classifier system},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Weighted indicator-based evolutionary algorithm for
multimodal multiobjective optimization. <em>TEVC</em>, <em>25</em>(6),
1064–1078. (<a href="https://doi.org/10.1109/TEVC.2021.3078441">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal multiobjective problems (MMOPs) arise frequently in the real world, in which multiple Pareto-optimal solution (PS) sets correspond to the same point on the Pareto front. Traditional multiobjective evolutionary algorithms (MOEAs) show poor performance in solving MMOPs due to a lack of diversity maintenance in the decision space. Thus, recently, many multimodal MOEAs (MMEAs) have been proposed. However, for most existing MMEAs, the convergence performance in the objective space does not meet expectations. In addition, many of them cannot always obtain all equivalent Pareto solution sets. To address these issues, this study proposes an MMEA based on a weighted indicator, termed MMEA-WI. The algorithm integrates the diversity information of solutions in the decision space into an objective space performance indicator to maintain the diversity in the decision space and introduces a convergence archive to ensure a more effective approximation of the Pareto-optimal front (PF). These strategies can readily be applied to other indicator-based MOEAs. The experimental results show that MMEA-WI outperforms some state-of-the-art MMEAs on the chosen benchmark problems in terms of the inverted generational distance (IGD) and IGD in the decision space (IGDX) metrics.},
  archive      = {J_TEVC},
  author       = {Wenhua Li and Tao Zhang and Rui Wang and Hisao Ishibuchi},
  doi          = {10.1109/TEVC.2021.3078441},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1064-1078},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Weighted indicator-based evolutionary algorithm for multimodal multiobjective optimization},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multitree genetic programming with new operators for
transfer learning in symbolic regression with incomplete data.
<em>TEVC</em>, <em>25</em>(6), 1049–1063. (<a
href="https://doi.org/10.1109/TEVC.2021.3079843">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lack of knowledge is a common consequence of data incompleteness when learning from real-world data. To deal with such a situation, this work utilizes transfer learning (TL) to reuse knowledge from different (yet related) but complete domains. Due to its powerful feature construction ability, genetic programming (GP) is used to construct feature-based transformations that map the feature space of the source domain to that of the target domain such that their differences are reduced. Particularly, this work proposes a new multitree GP-based feature construction approach to TL in symbolic regression with missing values. It transfers knowledge related to the importance of the features and instances in the source domain to the target domain to improve the learning performance. Moreover, new genetic operators are developed to encourage minimizing the distribution discrepancy between the transformed domain and the target domain. A new probabilistic crossover is developed to make the well-constructed trees in the individuals more likely to be mated than the other trees. A new mutation operator is designed to give more probability for the poorly constructed trees to be mutated. The experimental results show that the proposed method not only achieves better performance compared with different traditional learning methods but also advances two recent TL methods on real-world data sets with various incompleteness and learning scenarios.},
  archive      = {J_TEVC},
  author       = {Baligh Al-Helali and Qi Chen and Bing Xue and Mengjie Zhang},
  doi          = {10.1109/TEVC.2021.3079843},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1049-1063},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Multitree genetic programming with new operators for transfer learning in symbolic regression with incomplete data},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey of normalization methods in multiobjective
evolutionary algorithms. <em>TEVC</em>, <em>25</em>(6), 1028–1048. (<a
href="https://doi.org/10.1109/TEVC.2021.3076514">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A real-world multiobjective optimization problem (MOP) usually has differently scaled objectives. Objective space normalization has been widely used in multiobjective optimization evolutionary algorithms (MOEAs). Without objective space normalization, most of the MOEAs may fail to obtain uniformly distributed and well-converged solutions on MOPs with differently scaled objectives. Objective space normalization requires information on the Pareto front (PF) range, which can be acquired from the ideal and nadir points. Since the ideal and nadir points of a real-world MOP are usually not known a priori , many recently proposed MOEAs tend to estimate and update the two points adaptively during the evolutionary process. Different methods to estimate ideal and nadir points have been proposed in the literature. Due to inaccurate estimation of the two points (i.e., inaccurate estimation of the PF range), objective space normalization may deteriorate the performance of an MOEA. Different methods have also been proposed to alleviate the negative effects of inaccurate estimation. This article presents a comprehensive survey of objective space normalization methods, including ideal point estimation methods, nadir point estimation methods, and different methods based on the utilization of the estimated PF range.},
  archive      = {J_TEVC},
  author       = {Linjun He and Hisao Ishibuchi and Anupam Trivedi and Handing Wang and Yang Nan and Dipti Srinivasan},
  doi          = {10.1109/TEVC.2021.3076514},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1028-1048},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A survey of normalization methods in multiobjective evolutionary algorithms},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A kriging-assisted two-archive evolutionary algorithm for
expensive many-objective optimization. <em>TEVC</em>, <em>25</em>(6),
1013–1027. (<a href="https://doi.org/10.1109/TEVC.2021.3073648">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Only a small number of function evaluations can be afforded in many real-world multiobjective optimization problems (MOPs) where the function evaluations are economically/computationally expensive. Such problems pose great challenges to most existing multiobjective evolutionary algorithms (EAs), which require a large number of function evaluations for optimization. Surrogate-assisted EAs (SAEAs) have been employed to solve expensive MOPs. Specifically, a certain number of expensive function evaluations are used to build computationally cheap surrogate models for assisting the optimization process without conducting expensive function evaluations. The infill sampling criteria in most existing SAEAs take all requirements on convergence, diversity, and model uncertainty into account, which is, however, not the most efficient in exploiting the limited computational budget. Thus, this article proposes a Kriging-assisted two-archive EA for expensive many-objective optimization. The proposed algorithm uses one influential point-insensitive model to approximate each objective function. Moreover, an adaptive infill criterion that identifies the most important requirement on convergence, diversity, or uncertainty is proposed to determine an appropriate sampling strategy for reevaluations using the expensive objective functions. The experimental results on a set of expensive multi/many-objective test problems have demonstrated its superiority over five state-of-the-art SAEAs.},
  archive      = {J_TEVC},
  author       = {Zhenshou Song and Handing Wang and Cheng He and Yaochu Jin},
  doi          = {10.1109/TEVC.2021.3073648},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1013-1027},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A kriging-assisted two-archive evolutionary algorithm for expensive many-objective optimization},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). IEEE transactions on evolutionary computation society
information. <em>TEVC</em>, <em>25</em>(5), C3. (<a
href="https://doi.org/10.1109/TEVC.2021.3101532">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Provides a listing of current committee members and society officers.},
  archive      = {J_TEVC},
  doi          = {10.1109/TEVC.2021.3101532},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {C3},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {IEEE transactions on evolutionary computation society information},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Empirical comparison of search heuristics for genetic
improvement of software. <em>TEVC</em>, <em>25</em>(5), 1001–1011. (<a
href="https://doi.org/10.1109/TEVC.2021.3070271">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Genetic improvement (GI) uses automated search to improve existing software. It has been successfully used to optimize various program properties, such as runtime or energy consumption, as well as for the purpose of bug fixing. GI typically navigates a space of thousands of patches in search for the program mutation that best improves the desired software property. While genetic programming (GP) has been dominantly used as the search strategy, more recently other search strategies, such as local search, have been tried. It is, however, still unclear which strategy is the most effective and efficient. In this article, we conduct an in-depth empirical comparison of a total of 18 search processes using a set of eight improvement scenarios. Additionally, we also provide new GI benchmarks and we report on new software patches found. Our results show that, overall, local search approaches achieve better effectiveness and efficiency than GP approaches. Moreover, improvements were found in all scenarios (between 15\% and 68\%). A replication package can be found online: https://github.com/bloa/tevc_2020_artefact .},
  archive      = {J_TEVC},
  author       = {Aymeric Blot and Justyna Petke},
  doi          = {10.1109/TEVC.2021.3070271},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {1001-1011},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Empirical comparison of search heuristics for genetic improvement of software},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). CDE-GAN: Cooperative dual evolution-based generative
adversarial network. <em>TEVC</em>, <em>25</em>(5), 986–1000. (<a
href="https://doi.org/10.1109/TEVC.2021.3068842">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative adversarial networks (GANs) have been a popular deep generative model for real-world applications. Despite many recent efforts on GANs that have been contributed, mode collapse and instability of GANs are still open problems caused by their adversarial optimization difficulties. In this article, motivated by the cooperative co-evolutionary algorithm, we propose a cooperative dual evolution-based GAN (CDE-GAN) to circumvent these drawbacks. In essence, CDE-GAN incorporates dual evolution with respect to the generator(s) and discriminators into a unified evolutionary adversarial framework to conduct effective adversarial multiobjective optimization. Thus, it exploits the complementary properties and injects dual mutation diversity into the training, to steadily diversify the estimated density in capturing multimodes and improve generative performance. Specifically, CDE-GAN decomposes the complex adversarial optimization problem into two subproblems (generation and discrimination), and each subproblem is solved with a separated subpopulation ( E-Generators and E-Discriminators ), evolved by its own evolutionary algorithm. Additionally, we further propose a Soft Mechanism to balance the tradeoff between E-Generators and E-Discriminators to conduct steady training for CDE-GAN. Extensive experiments on one synthetic dataset and three real-world benchmark image datasets demonstrate that the proposed CDE-GAN achieves a competitive and superior performance in generating good quality and diverse samples over baselines. The code and more generated results are available at our project homepage https://shiming-chen.github.io/CDE-GAN-website/CDE-GAN.html .},
  archive      = {J_TEVC},
  author       = {Shiming Chen and Wenjie Wang and Beihao Xia and Xinge You and Qinmu Peng and Zehong Cao and Weiping Ding},
  doi          = {10.1109/TEVC.2021.3068842},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {986-1000},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {CDE-GAN: Cooperative dual evolution-based generative adversarial network},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Solving mixed pareto-lexicographic multiobjective
optimization problems: The case of priority levels. <em>TEVC</em>,
<em>25</em>(5), 971–985. (<a
href="https://doi.org/10.1109/TEVC.2021.3068816">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article concerns the study of mixed Pareto-lexicographic multiobjective optimization problems where the objectives must be partitioned in multiple priority levels (PLs). A PL is a group of objectives having the same importance in terms of optimization and subsequent decision making, while between PLs a lexicographic ordering exists. A naive approach would be to define a multilevel dominance relationship and apply a standard EMO/EMaO algorithm, but the concept does not conform to a stable optimization process as the resulting dominance relationship violates the transitive property needed to achieve consistent comparisons. To overcome this, we present a novel approach that merges a custom nondominance relation with the Grossone methodology, a mathematical framework to handle infinite and infinitesimal quantities. The proposed method is implemented on a popular multiobjective optimization algorithm (NSGA-II), deriving a generalization of it called by us PL-NSGA-II. We also demonstrate the usability of our strategy by quantitatively comparing the results obtained by PL-NSGA-II against other priority and nonpriority-based approaches. Among the test cases, we include two real-world applications: one 10-objective aircraft design problem and one 3-objective crash safety vehicle design task. The obtained results show that PL-NSGA-II is more suited to solve lexicographical many-objective problems than the general purpose EMaO algorithms.},
  archive      = {J_TEVC},
  author       = {Leonardo Lai and Lorenzo Fiaschi and Marco Cococcioni and Kalyanmoy Deb},
  doi          = {10.1109/TEVC.2021.3068816},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {971-985},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Solving mixed pareto-lexicographic multiobjective optimization problems: The case of priority levels},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fast immune system-inspired hypermutation operators for
combinatorial optimization. <em>TEVC</em>, <em>25</em>(5), 956–970. (<a
href="https://doi.org/10.1109/TEVC.2021.3068574">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various studies have shown that immune system-inspired hypermutation operators can allow artificial immune systems (AIS) to be very efficient at escaping local optima of multimodal optimization problems. However, this efficiency comes at the expense of considerably slower runtimes during the exploitation phase compared to the standard evolutionary algorithms. We propose modifications to the traditional hypermutations with mutation potential (HMP) that allow them to be efficient at exploitation, as well as maintaining their effective explorative characteristics. Rather than deterministically evaluating fitness after each bit-flip of a hypermutation, we sample the fitness function stochastically with a “parabolic” distribution. This allows the stop at the first constructive mutation (FCM) variant of HMP to reduce the linear amount of wasted function evaluations when no improvement is found to a constant. The stochastic distribution also allows the removal of the FCM mechanism altogether as originally desired in the design of the HMP operators. We rigorously prove the effectiveness of the proposed operators for all the benchmark functions, where the performance of HMP is rigorously understood in the literature. We validate the gained insights to show linear speed-ups for the identification of high-quality approximate solutions to classical NP-Hard problems from combinatorial optimization. We then show the superiority of the HMP operators to the traditional ones in an analysis of the complete standard Opt-IA AIS, where the stochastic evaluation scheme allows HMP and aging operators to work in harmony. Through a comparative performance study of other “fast mutation” operators from the literature, we conclude that a power-law distribution for the parabolic evaluation scheme is the best compromise in black-box scenarios, where little problem knowledge is available.},
  archive      = {J_TEVC},
  author       = {Dogan Corus and Pietro S. Oliveto and Donya Yazdani},
  doi          = {10.1109/TEVC.2021.3068574},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {956-970},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Fast immune system-inspired hypermutation operators for combinatorial optimization},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A fast kriging-assisted evolutionary algorithm based on
incremental learning. <em>TEVC</em>, <em>25</em>(5), 941–955. (<a
href="https://doi.org/10.1109/TEVC.2021.3067015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kriging models, also known as Gaussian process models, are widely used in surrogate-assisted evolutionary algorithms (SAEAs). However, the cubic time complexity of the standard Kriging models limits their usage in high-dimensional optimization. To tackle this problem, we propose an incremental Kriging model for high-dimensional surrogate-assisted evolutionary computation. The main idea is to update the Kriging model incrementally based on the equations of the previously trained model instead of building the model from scratch when new samples arrive, so that the time complexity of updating the Kriging models can be reduced to quadratic. The proposed incremental learning scheme is very suitable for online SAEAs since they evaluate new samples in each one or several generations. The proposed algorithm is able to achieve competitive optimization results on the test problems compared with the standard Kriging-assisted evolutionary algorithm and is significantly faster than the standard Kriging approach. The proposed algorithm also shows competitive or better performances compared with four fast Kriging-assisted evolutionary algorithms and four state-of-the-art SAEAs. This work provides a fast way of employing Kriging models in high-dimensional surrogate-assisted evolutionary computation.},
  archive      = {J_TEVC},
  author       = {Dawei Zhan and Huanlai Xing},
  doi          = {10.1109/TEVC.2021.3067015},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {941-955},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A fast kriging-assisted evolutionary algorithm based on incremental learning},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Two-stage evolutionary neural architecture search for
transfer learning. <em>TEVC</em>, <em>25</em>(5), 928–940. (<a
href="https://doi.org/10.1109/TEVC.2021.3097937">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) have achieved state-of-the-art performance in many image classification tasks. However, training a deep CNN requires a massive amount of training data, which can be expensive or unobtainable in practical applications, such as defect inspection and medical diagnosis. Transfer learning has been developed to address this issue by transferring knowledge learned from source domains to target domains. A common approach is fine-tuning, which adapts the parameters of a trained neural network for the new target task. Nevertheless, the network architecture remains designed for the source task rather than the target task. To optimize the network architecture in transfer learning, we propose a two-stage evolutionary neural architecture search for transfer learning (EvoNAS-TL), which searches for an efficient subnetwork of the source model for the target task. EvoNAS-TL features two search stages: 1) structure search and 2) local enhancement. The former conducts a coarse-grained global search for suitable neural architectures, while the latter acts as a fine-grained local search to refine the models obtained. In this study, neural architecture search (NAS) is formulated as a multiobjective optimization problem that concurrently minimizes the prediction error and model size. The knee-guided multiobjective evolutionary algorithm, a modern multiobjective optimization approach, is employed to solve the NAS problem. In this study, several experiments are conducted to examine the effectiveness of EvoNAS-TL. The results show that applying EvoNAS-TL on VGG-16 can reduce the model size by 52\%–85\% and simultaneously improve the testing accuracy by 0.7\%–6.9\% in transferring from ImageNet to CIFAR-10 and NEU surface detection datasets. In addition, EvoNAS-TL performs comparably to or better than state-of-the-art methods on the CIFAR-10, NEU, and Office-31 datasets.},
  archive      = {J_TEVC},
  author       = {Yu-Wei Wen and Sheng-Hsuan Peng and Chuan-Kang Ting},
  doi          = {10.1109/TEVC.2021.3097937},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {928-940},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Two-stage evolutionary neural architecture search for transfer learning},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive genetic algorithm-aided neural network with channel
state information tensor decomposition for indoor localization.
<em>TEVC</em>, <em>25</em>(5), 913–927. (<a
href="https://doi.org/10.1109/TEVC.2021.3085906">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Channel state information (CSI) can provide phase and amplitude of multichannel subcarrier to better describe signal propagation characteristics. Therefore, CSI has become one of the most commonly used features in indoor Wi-Fi localization. In addition, compared to the CSI geometric localization method, the CSI fingerprint localization method has the advantages of easy implementation and high accuracy. However, as the scale of the fingerprint database increases, the training cost and processing complexity of CSI fingerprints will also greatly increase. Based on this, this article proposes to combine backpropagation neural network (BPNN) and adaptive genetic algorithm (AGA) with CSI tensor decomposition for indoor Wi-Fi fingerprint localization. Specifically, the tensor decomposition algorithm based on the parallel factor (PARAFAC) analysis model and the alternate least squares (ALSs) iterative algorithm are combined to reduce the interference of the environment. Then, we use the tensor wavelet decomposition algorithm for feature extraction and obtain the CSI fingerprint. Finally, in order to find the optimal weights and thresholds and then obtain the estimated location coordinates, we introduce an AGA to optimize BPNN. The experimental results show that the proposed algorithm has high localization accuracy, while improving the data processing ability and fitting the nonlinear relationship between CSI location fingerprints and location coordinates.},
  archive      = {J_TEVC},
  author       = {Mu Zhou and Yuexin Long and Weiping Zhang and Qiaolin Pu and Yong Wang and Wei Nie and Wei He},
  doi          = {10.1109/TEVC.2021.3085906},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {913-927},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Adaptive genetic algorithm-aided neural network with channel state information tensor decomposition for indoor localization},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on evolutionary construction of deep neural
networks. <em>TEVC</em>, <em>25</em>(5), 894–912. (<a
href="https://doi.org/10.1109/TEVC.2021.3079985">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated construction of deep neural networks (DNNs) has become a research hot spot nowadays because DNN’s performance is heavily influenced by its architecture and parameters, which are highly task-dependent, but it is notoriously difficult to find the most appropriate DNN in terms of architecture and parameters to best solve a given task. In this work, we provide an insight into the automated DNN construction process by formulating it into a multilevel multiobjective large-scale optimization problem with constraints, where the nonconvex, nondifferentiable, and black-box nature of this problem make evolutionary algorithms (EAs) to stand out as a promising solver. Then, we give a systematical review of existing evolutionary DNN construction techniques from different aspects of this optimization problem and analyze the pros and cons of using EA-based methods in each aspect. This work aims to help DNN researchers to better understand why, where, and how to utilize EAs for automated DNN construction and meanwhile, help EA researchers to better understand the task of automated DNN construction so that they may focus more on EA-favored optimization scenarios to devise more effective techniques.},
  archive      = {J_TEVC},
  author       = {Xun Zhou and A. K. Qin and Maoguo Gong and Kay Chen Tan},
  doi          = {10.1109/TEVC.2021.3079985},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {894-912},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A survey on evolutionary construction of deep neural networks},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evolutionary deep fusion method and its application in
chemical structure recognition. <em>TEVC</em>, <em>25</em>(5), 883–893.
(<a href="https://doi.org/10.1109/TEVC.2021.3064943">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature extraction is a critical issue in many machine learning systems. A number of basic fusion operators have been proposed and studied. This article proposes an evolutionary algorithm, called evolutionary deep fusion method, for searching an optimal combination scheme of different basic fusion operators to fuse multiview features. We apply our proposed method to chemical structure recognition. Our proposed method can directly take images as inputs, and users do not need to transform images to other formats. The experimental results demonstrate that our proposed method can achieve a better performance than those designed by human experts on this real-life problem.},
  archive      = {J_TEVC},
  author       = {Xinyan Liang and Qian Guo and Yuhua Qian and Weiping Ding and Qingfu Zhang},
  doi          = {10.1109/TEVC.2021.3064943},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {883-893},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolutionary deep fusion method and its application in chemical structure recognition},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Convolutional neural networks-based lung nodule
classification: A surrogate-assisted evolutionary algorithm for
hyperparameter optimization. <em>TEVC</em>, <em>25</em>(5), 869–882. (<a
href="https://doi.org/10.1109/TEVC.2021.3060833">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates deep neural networks (DNNs)-based lung nodule classification with hyperparameter optimization. Hyperparameter optimization in DNNs is a computationally expensive problem, and a surrogate-assisted evolutionary algorithm has been recently introduced to automatically search for optimal hyperparameter configurations of DNNs, by applying computationally efficient surrogate models to approximate the validation error function of hyperparameter configurations. Different from existing surrogate models adopting stationary covariance functions (kernels) to measure the difference between hyperparameter points, this article proposes a nonstationary kernel that allows the surrogate model to adapt to functions whose smoothness varies with the spatial location of inputs. A multilevel convolutional neural network (ML-CNN) is built for lung nodule classification, and the hyperparameter configuration is optimized by the proposed nonstationary kernel-based Gaussian surrogate model. Our algorithm searches with a surrogate for optimal setting via a hyperparameter importance-based evolutionary strategy, and the experiments demonstrate our algorithm outperforms manual tuning and several well-established hyperparameter optimization methods, including random search, grid search, the tree-structured parzen estimator (TPE) approach, Gaussian processes (GP) with stationary kernels, and the recently proposed hyperparameter optimization via RBF and dynamic (HORD) coordinate search.},
  archive      = {J_TEVC},
  author       = {Miao Zhang and Huiqi Li and Shirui Pan and Juan Lyu and Steve Ling and Steven Su},
  doi          = {10.1109/TEVC.2021.3060833},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {869-882},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Convolutional neural networks-based lung nodule classification: A surrogate-assisted evolutionary algorithm for hyperparameter optimization},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust multimodal representation learning with evolutionary
adversarial attention networks. <em>TEVC</em>, <em>25</em>(5), 856–868.
(<a href="https://doi.org/10.1109/TEVC.2021.3066285">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal representation learning is beneficial for many multimedia-oriented applications, such as social image recognition and visual question answering. The different modalities of the same instance (e.g., a social image and its corresponding description) are usually correlational and complementary. Most existing approaches for multimodal representation learning are not effective to model the deep correlation between different modalities. Moreover, it is difficult for these approaches to deal with the noise within social images. In this article, we propose a deep learning-based approach named evolutionary adversarial attention networks (EAANs), which combines the attention mechanism with adversarial networks through evolutionary training, for robust multimodal representation learning. Specifically, a two-branch visual-textual attention model is proposed to correlate visual and textual content for joint representation. Then adversarial networks are employed to impose regularization upon the representation by matching its posterior distribution to the given priors. Finally, the attention model and adversarial networks are integrated into an evolutionary training framework for robust multimodal representation learning. Extensive experiments have been conducted on four real-world datasets, including PASCAL, MIR, CLEF, and NUS-WIDE. Substantial performance improvements on the tasks of image classification and tag recommendation demonstrate the superiority of the proposed approach.},
  archive      = {J_TEVC},
  author       = {Feiran Huang and Alireza Jolfaei and Ali Kashif Bashir},
  doi          = {10.1109/TEVC.2021.3066285},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {856-868},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Robust multimodal representation learning with evolutionary adversarial attention networks},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Task allocation on layered multiagent systems: When
evolutionary many-objective optimization meets deep q-learning.
<em>TEVC</em>, <em>25</em>(5), 842–855. (<a
href="https://doi.org/10.1109/TEVC.2021.3049131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article is concerned with the multitask multiagent allocation problem via many-objective optimization for multiagent systems (MASs). First, a novel layered MAS model is constructed to address the multitask multiagent allocation problem that includes both the original task simplification and the many-objective allocation. In the first layer of the model, the deep Q-learning method is introduced to simplify the prioritization of the original task set. In the second layer of the model, the modified shift-based density estimation (MSDE) method is put forward to improve the conventional strength Pareto evolutionary algorithm 2 (SPEA2) in order to achieve many-objective optimization on task assignments. Then, an MSDE-SPEA2-based method is proposed to tackle the many-objective optimization problem with objectives including task allocation, makespan, agent satisfaction, resource utilization, task completion, and task waiting time. As compared with the existing allocation methods, the developed method in this article exhibits an outstanding feature that the task assignment and the task scheduling are carried out simultaneously. Finally, extensive experiments are conducted to: 1) verify the validity of the proposed model and the effectiveness of two main algorithms and 2) illustrate the optimal solution for task allocation and efficient strategy for task scheduling under different scenarios.},
  archive      = {J_TEVC},
  author       = {Mincan Li and Zidong Wang and Kenli Li and Xiangke Liao and Kate Hone and Xiaohui Liu},
  doi          = {10.1109/TEVC.2021.3049131},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {842-855},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Task allocation on layered multiagent systems: When evolutionary many-objective optimization meets deep Q-learning},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AS-NAS: Adaptive scalable neural architecture search with
reinforced evolutionary algorithm for deep learning. <em>TEVC</em>,
<em>25</em>(5), 830–841. (<a
href="https://doi.org/10.1109/TEVC.2021.3061466">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural architecture search (NAS) is a challenging problem in the design of deep learning due to its nonconvexity. To address this problem, an adaptive scalable NAS method (AS-NAS) is proposed based on the reinforced I-Ching divination evolutionary algorithm (IDEA) and variable-architecture encoding strategy. First, unlike the typical reinforcement learning (RL)-based and evolutionary algorithm (EA)-based NAS methods, a simplified RL algorithm is developed and used as the reinforced operator controller to adaptively select the efficient operators of IDEA. Without the complex actor–critic parts, the reinforced IDEA based on simplified RL can enhance the search efficiency of the original EA with lower computational cost. Second, a variable-architecture encoding strategy is proposed to encode neural architecture as a fixed-length binary string. By simultaneously considering variable layers, channels, and connections between different convolution layers, the deep neural architecture can be scalable. Through the integration with the reinforced IDEA and variable-architecture encoding strategy, the design of the deep neural architecture can be adaptively scalable. Finally, the proposed AS-NAS are integrated with the ${L}_{1/2}$ regularization to increase the sparsity of the optimized neural architecture. Experiments and comparisons demonstrate the effectiveness and superiority of the proposed method.},
  archive      = {J_TEVC},
  author       = {Tong Zhang and Chunyu Lei and Zongyan Zhang and Xian-Bing Meng and C. L. Philip Chen},
  doi          = {10.1109/TEVC.2021.3061466},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {830-841},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {AS-NAS: Adaptive scalable neural architecture search with reinforced evolutionary algorithm for deep learning},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evolving deep convolutional variational autoencoders for
image classification. <em>TEVC</em>, <em>25</em>(5), 815–829. (<a
href="https://doi.org/10.1109/TEVC.2020.3047220">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variational autoencoders (VAEs) have demonstrated their superiority in unsupervised learning for image processing in recent years. The performance of the VAEs highly depends on their architectures, which are often handcrafted by the human expertise in deep neural networks (DNNs). However, such expertise is not necessarily available to each of the end users interested. In this article, we propose a novel method to automatically design optimal architectures of VAEs for image classification, called evolving deep convolutional VAE (EvoVAE), based on a genetic algorithm (GA). In the proposed EvoVAE algorithm, the traditional VAEs are first generalized to a more generic and asymmetrical one with four different blocks, and then a variable-length gene encoding mechanism of the GA is presented to search for the optimal network depth. Furthermore, an effective genetic operator is designed to adapt to the proposed variable-length gene encoding strategy. To verify the performance of the proposed algorithm, nine variants of AEs and VAEs are chosen as the peer competitors to perform the comparisons on MNIST, street view house numbers, and CIFAR-10 benchmark datasets. The experiments reveal the superiority of the proposed EvoVAE algorithm, which wins 21 times out of the 24 comparisons and outperforms the best competitors by 1.39\%, 14.21\%, and 13.03\% on the three benchmark datasets, respectively.},
  archive      = {J_TEVC},
  author       = {Xiangru Chen and Yanan Sun and Mengjie Zhang and Dezhong Peng},
  doi          = {10.1109/TEVC.2020.3047220},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {815-829},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolving deep convolutional variational autoencoders for image classification},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Guest editorial evolutionary computation meets deep
learning. <em>TEVC</em>, <em>25</em>(5), 810–814. (<a
href="https://doi.org/10.1109/TEVC.2021.3096336">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning is a timely research direction in machine learning, where breakthrough progress has been made in both academe and industries, bringing promising results in speech recognition, computer vision, industrial control and automation, etc. The motivation of deep learning is primarily to establish a model to simulate the neural connection structure of the human brain. While dealing with complex tasks, deep learning adopts a number of transformation stages to deliver the in-depth description and interpretation of the data. Deep learning achieves exceptional power and flexibility by learning to represent the task through a nested hierarchy of layers, with more abstract representations formed successively in terms of less abstract ones. One of the key issues of existing deep learning approaches is that the meaningful representations can be learned only when their hyperparameter settings are properly specified beforehand, and general parameters are learned during the training process. Until now, not much research has been dedicated to automatically set the hyperparameters, and accurately find the globally optimal general parameters. However, this problem can be formulated as optimization problems, including discrete optimization, constrained optimization, large-scale global optimization, and multiobjective optimization, by engaging mechanisms of evolutionary computation.},
  archive      = {J_TEVC},
  author       = {Weiping Ding and Witold Pedrycz and Gary G. Yen and Bing Xue},
  doi          = {10.1109/TEVC.2021.3096336},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {810-814},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Guest editorial evolutionary computation meets deep learning},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). IEEE transactions on evolutionary computation society
information. <em>TEVC</em>, <em>25</em>(4), C3. (<a
href="https://doi.org/10.1109/TEVC.2021.3085352">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Provides a listing of current committee members and society officers.},
  archive      = {J_TEVC},
  doi          = {10.1109/TEVC.2021.3085352},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {C3},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {IEEE transactions on evolutionary computation society information},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dual-surrogate-assisted cooperative particle swarm
optimization for expensive multimodal problems. <em>TEVC</em>,
<em>25</em>(4), 794–808. (<a
href="https://doi.org/10.1109/TEVC.2021.3064835">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various real-world applications can be classified as expensive multimodal optimization problems. When surrogate-assisted evolutionary algorithms (SAEAs) are employed to tackle these problems, they not only face a contradiction between the precision of surrogate models and the cost of individual evaluations but also have the difficulty that surrogate models and problem modalities are hard to match. To address this issue, this article studies a dual-surrogate-assisted cooperative particle swarm optimization algorithm to seek multiple optimal solutions. A dual-population cooperative particle swarm optimizer is first developed to simultaneously explore/exploit multiple modalities. Following that, a modal-guided dual-layer cooperative surrogate model, which contains one upper global surrogate model and a group of lower local surrogate models, is constructed with the purpose of reducing the individual evaluation cost. Moreover, a hybrid strategy based on clustering and peak-valley is proposed to detect new modalities. Compared with five existing SAEAs and seven multimodal evolutionary algorithms, the proposed algorithm can simultaneously obtain multiple highly competitive optimal solutions at a low computational cost according to the experimental results of testing both 11 benchmark instances and the building energy conservation problem.},
  archive      = {J_TEVC},
  author       = {Xinfang Ji and Yong Zhang and Dunwei Gong and Xiaoyan Sun},
  doi          = {10.1109/TEVC.2021.3064835},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {794-808},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Dual-surrogate-assisted cooperative particle swarm optimization for expensive multimodal problems},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Region encoding helps evolutionary computation evolve
faster: A new solution encoding scheme in particle swarm for large-scale
optimization. <em>TEVC</em>, <em>25</em>(4), 779–793. (<a
href="https://doi.org/10.1109/TEVC.2021.3065659">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last decade, many evolutionary computation (EC) algorithms with diversity enhancement have been proposed to solve large-scale optimization problems in big data era. Among them, the social learning particle swarm optimization (SLPSO) has shown good performance. However, as SLPSO uses different guidance information for different particles to maintain the diversity, it often results in slow convergence speed. Therefore, this article proposes a new region encoding scheme (RES) to extend the solution representation from a single point to a region, which can help EC algorithms evolve faster. The RES is generic for EC algorithms and is applied to SLPSO. Based on RES, a novel adaptive region search (ARS) is designed to on the one hand keep the diversity of SLPSO and on the other hand accelerate the convergence speed, forming the SLPSO with ARS (SLPSO-ARS). In SLPSO-ARS, each particle is encoded as a region so that some of the best (e.g., the top P) particles can carry out region search to search for better solutions near their current positions. The ARS strategy offers the particle a greater chance to discover the nearby optimal solutions and helps to accelerate the convergence speed of the whole population. Moreover, the region radius is adaptively controlled based on the search information. Comprehensive experiments on all the problems in both IEEE Congress on Evolutionary Computation 2010 (CEC 2010) and 2013 (CEC 2013) competitions are conducted to validate the effectiveness and efficiency of SLPSO-ARS and to investigate its important parameters and components. The experimental results show that SLPSO-ARS can achieve generally better performance than the compared algorithms.},
  archive      = {J_TEVC},
  author       = {Jun-Rong Jian and Zong-Gan Chen and Zhi-Hui Zhan and Jun Zhang},
  doi          = {10.1109/TEVC.2021.3065659},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {779-793},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Region encoding helps evolutionary computation evolve faster: A new solution encoding scheme in particle swarm for large-scale optimization},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multiple penalties and multiple local surrogates for
expensive constrained optimization. <em>TEVC</em>, <em>25</em>(4),
769–778. (<a href="https://doi.org/10.1109/TEVC.2021.3066606">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes an evolutionary algorithm using multiple penalties and multiple local surrogates (MPMLS) for expensive constrained optimization. In each generation, MPMLS defines and optimizes a number of subproblems. Each subproblem penalizes the constraints in the original problem using a different penalty coefficient and has its own search subregion. A local surrogate is built for optimizing each subproblem. Two major advantages of MPMLS are: 1) it can maintain good population diversity so that the search can approach the optimal solution of the original problem from different directions and 2) it only needs to build local surrogates so that the computational overhead of the model building can be reduced. Numerical experiments demonstrate that our proposed algorithm performs much better than some other state-of-the-art evolutionary algorithms.},
  archive      = {J_TEVC},
  author       = {Genghui Li and Qingfu Zhang},
  doi          = {10.1109/TEVC.2021.3066606},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {769-778},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Multiple penalties and multiple local surrogates for expensive constrained optimization},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Two-stage double niched evolution strategy for multimodal
multiobjective optimization. <em>TEVC</em>, <em>25</em>(4), 754–768. (<a
href="https://doi.org/10.1109/TEVC.2021.3064508">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, numerous efficient and effective multimodal multiobjective evolutionary algorithms (MMOEAs) have been developed to search for multiple equivalent sets of Pareto optimal solutions simultaneously. However, some of the MMOEAs prefer convergent individuals over diversified individuals to construct the mating pool, and the individuals with slightly better decision space distribution may be replaced by significantly better objective space distribution. Therefore, the diversity in the decision space may become deteriorated, in spite of the decision and objective diversities have been taken into account simultaneously in most MMOEAs. Because the Pareto optimal subsets may have various shapes and locations in the decision space, it is very difficult to drive the individuals converged to every Pareto subregion with a uniform density. Some of the Pareto subregions may be overly crowded, while others are rather sparsely distributed. Consequently, many existing MMOEAs obtain Pareto subregions with imbalanced density. In this article, we present a two-stage double niched evolution strategy, namely DN-MMOES, to search for the equivalent global Pareto optimal solutions which can address the above challenges effectively and efficiently. The proposed DN-MMOES solves the multimodal multiobjective optimization problem (MMOP) in two stages. The first stage adopts the niching strategy in the decision space, while the second stage adapts double niching strategy in both spaces. Moreover, an effective decision density self-adaptive strategy is designed for improving the imbalanced decision space density. The proposed algorithm is compared against eight state-of-the-art MMOEAs. The inverted generational distance union (IGDunion) performance indicator is proposed to fairly compare two competing MMOEAs as a whole. The experimental results show that DN-MMOES provides a better performance to search for the complete Pareto Subsets and Pareto Front on IDMP and CEC 2019 MMOPs test suite.},
  archive      = {J_TEVC},
  author       = {Kai Zhang and Chaonan Shen and Gary G. Yen and Zhiwei Xu and Juanjuan He},
  doi          = {10.1109/TEVC.2021.3064508},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {754-768},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Two-stage double niched evolution strategy for multimodal multiobjective optimization},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A dual-population-based evolutionary algorithm for
constrained multiobjective optimization. <em>TEVC</em>, <em>25</em>(4),
739–753. (<a href="https://doi.org/10.1109/TEVC.2021.3066301">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main challenge in constrained multiobjective optimization problems (CMOPs) is to appropriately balance convergence, diversity and feasibility. Their imbalance can easily cause the failure of a constrained multiobjective evolutionary algorithm (CMOEA) in converging to the Pareto-optimal front with diverse feasible solutions. To address this challenge, we propose a dual-population-based evolutionary algorithm, named c-DPEA, for CMOPs. c-DPEA is a cooperative coevolutionary algorithm which maintains two collaborative and complementary populations, termed Population1 and Population2. In c-DPEA, a novel self-adaptive penalty function, termed saPF, is designed to preserve competitive infeasible solutions in Population1. On the other hand, infeasible solutions in Population2 are handled using a feasibility-oriented approach. To maintain an appropriate balance between convergence and diversity in c-DPEA, a new adaptive fitness function, named bCAD, is developed. Extensive experiments on three popular test suites comprehensively validate the design components of c-DPEA. Comparison against six state-of-the-art CMOEAs demonstrates that c-DPEA is significantly superior or comparable to the contender algorithms on most of the test problems.},
  archive      = {J_TEVC},
  author       = {Mengjun Ming and Anupam Trivedi and Rui Wang and Dipti Srinivasan and Tao Zhang},
  doi          = {10.1109/TEVC.2021.3066301},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {739-753},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A dual-population-based evolutionary algorithm for constrained multiobjective optimization},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Large-scale evolutionary multiobjective optimization
assisted by directed sampling. <em>TEVC</em>, <em>25</em>(4), 724–738.
(<a href="https://doi.org/10.1109/TEVC.2021.3063606">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is particularly challenging for evolutionary algorithms to quickly converge to the Pareto front in large-scale multiobjective optimization. To tackle this problem, this article proposes a large-scale multiobjective evolutionary algorithm assisted by some selected individuals generated by directed sampling (DS). At each generation, a set of individuals closer to the ideal point is chosen for performing a DS in the decision space, and those nondominated ones of the sampled solutions are used to assist the reproduction to improve the convergence in evolutionary large-scale multiobjective optimization. In addition, elitist nondominated sorting is adopted complementarily for environmental selection with a reference vector-based method in order to maintain diversity of the population. Our experimental results show that the proposed algorithm is highly competitive on large-scale multiobjective optimization test problems with up to 5000 decision variables compared to five state-of-the-art multiobjective evolutionary algorithms.},
  archive      = {J_TEVC},
  author       = {Shufen Qin and Chaoli Sun and Yaochu Jin and Ying Tan and Jonathan Fieldsend},
  doi          = {10.1109/TEVC.2021.3063606},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {724-738},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Large-scale evolutionary multiobjective optimization assisted by directed sampling},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ensemble of dynamic resource allocation strategies for
decomposition-based multiobjective optimization. <em>TEVC</em>,
<em>25</em>(4), 710–723. (<a
href="https://doi.org/10.1109/TEVC.2021.3060899">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary algorithms via decomposition, namely, DEAs, decompose the original challenging problem and evolve a number of subproblems/subspaces concurrently in a cooperative fashion. Adaptive computational resource allocation (CRA) strategy is able to identify the efficiency of different subspaces and invest search effort on them accordingly in an online manner. A crucial issue for CRA is to measure the efficiency of subspaces. Unfortunately, existing approaches for efficiency measurement are either fitness improvement oriented or contribution oriented, which struggle to capture the potentials of subspaces accurately. To mitigate such drawback, we present an ensemble method for CRA, based on the recent fitness contribution rates (FCRs) and fitness improvement rates (FIRs) of subspaces simultaneously. In order to dynamically track the potential of each subregion, we adopt two memory matrices to record FIR and FCR for multiple subspaces over recent generations, respectively. Afterward, an aptitude vector indicating the potentials of subspaces is defined by exploiting FCR and FIR with memory and decaying scheme. On the basis of above strategies, an ensemble CRA (ECRA) scheme is designed, which is then embedded into an adaptive objective space partition-based DEA, termed ECRA-DEA, for solving the multi/many-objective optimization. Extensive experimental studies for ECRA-DEA on various types of challenging problems have been carried out and the results confirm that ECRA is effective. Besides, the competence of ECRA-DEA is empirically validated in comparison with state-of-the-art designs. The proposed ECRA paves a new way to leverage the capability of DEAs on handling complex problems.},
  archive      = {J_TEVC},
  author       = {Jiajun Zhou and Liang Gao and Xinyu Li},
  doi          = {10.1109/TEVC.2021.3060899},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {710-723},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Ensemble of dynamic resource allocation strategies for decomposition-based multiobjective optimization},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Analysis of evolutionary algorithms on fitness function with
time-linkage property. <em>TEVC</em>, <em>25</em>(4), 696–709. (<a
href="https://doi.org/10.1109/TEVC.2021.3061442">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-world applications, many optimization problems have the time-linkage property, that is, the objective function value relies on the current solution as well as the historical solutions. Although the rigorous theoretical analysis on evolutionary algorithms (EAs) has rapidly developed in recent two decades, it remains an open problem to theoretically understand the behaviors of EAs on time-linkage problems. This article takes the first step to rigorously analyze EAs for time-linkage functions. Based on the basic OneMax function, we propose a time-linkage function where the first bit value of the last time step is integrated but has a different preference from the current first bit. We prove that with probability 1-o(1), randomized local search and (1 + 1) EA cannot find the optimum, and with probability 1-o(1), (μ+1) EA is able to reach the optimum.},
  archive      = {J_TEVC},
  author       = {Weijie Zheng and Huanhuan Chen and Xin Yao},
  doi          = {10.1109/TEVC.2021.3061442},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {696-709},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Analysis of evolutionary algorithms on fitness function with time-linkage property},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the effect of the cooperation of indicator-based
multiobjective evolutionary algorithms. <em>TEVC</em>, <em>25</em>(4),
681–695. (<a href="https://doi.org/10.1109/TEVC.2021.3061545">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For almost 20 years, quality indicators (QIs) have promoted the design of new selection mechanisms of multiobjective evolutionary algorithms (MOEAs). Each indicator-based MOEA (IB-MOEA) has specific search preferences related to its baseline QI, producing Pareto front approximations with different properties. In consequence, an IB-MOEA based on a single QI has a limited scope of multiobjective optimization problems (MOPs) in which it is expected to have a good performance. This issue is emphasized when the associated Pareto front geometries are highly irregular. In order to overcome these issues, we propose here an island-based multiindicator algorithm (IMIA) that takes advantage of the search biases of multiple IB-MOEAs through a cooperative scheme. Our experimental results show that the cooperation of multiple IB-MOEAs allows IMIA to perform more robustly (considering several QIs) than the panmictic versions of its baseline IB-MOEAs as well as several state-of-the-art MOEAs. Additionally, IMIA shows a Pareto-front-shape invariance property, which makes it a remarkable optimizer when tackling MOPs with complex Pareto front geometries.},
  archive      = {J_TEVC},
  author       = {Jesús Guillermo Falcón-Cardona and Hisao Ishibuchi and Carlos A. Coello Coello and Michael Emmerich},
  doi          = {10.1109/TEVC.2021.3061545},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {681-695},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {On the effect of the cooperation of indicator-based multiobjective evolutionary algorithms},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning adaptive differential evolution algorithm from
optimization experiences by policy gradient. <em>TEVC</em>,
<em>25</em>(4), 666–680. (<a
href="https://doi.org/10.1109/TEVC.2021.3060811">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential evolution is one of the most prestigious population-based stochastic optimization algorithm for black-box problems. The performance of a differential evolution algorithm depends highly on its mutation and crossover strategy and associated control parameters. However, the determination process for the most suitable parameter setting is troublesome and time consuming. Adaptive control parameter methods that can adapt to problem landscape and optimization environment are more preferable than fixed parameter settings. This article proposes a novel adaptive parameter control approach based on learning from the optimization experiences over a set of problems. In the approach, the parameter control is modeled as a finite-horizon Markov decision process. A reinforcement learning algorithm, named policy gradient, is applied to learn an agent (i.e., parameter controller) that can provide the control parameters of a proposed differential evolution adaptively during the search procedure. The differential evolution algorithm based on the learned agent is compared against nine well-known evolutionary algorithms on the CEC&#39;13 and CEC&#39;17 test suites. Experimental results show that the proposed algorithm performs competitively against these compared algorithms on the test suites.},
  archive      = {J_TEVC},
  author       = {Jianyong Sun and Xin Liu and Thomas Bäck and Zongben Xu},
  doi          = {10.1109/TEVC.2021.3060811},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {666-680},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Learning adaptive differential evolution algorithm from optimization experiences by policy gradient},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Surrogate-assisted evolutionary multitask genetic
programming for dynamic flexible job shop scheduling. <em>TEVC</em>,
<em>25</em>(4), 651–665. (<a
href="https://doi.org/10.1109/TEVC.2021.3065707">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic flexible job shop scheduling (JSS) is an important combinatorial optimization problem with complex routing and sequencing decisions under dynamic environments. Genetic programming (GP), as a hyperheuristic approach, has been successfully applied to evolve scheduling heuristics for JSS. However, its training process is time consuming, and it faces the retraining problem once the characteristics of job shop scenarios vary. It is known that multitask learning is a promising paradigm for solving multiple tasks simultaneously by sharing knowledge among the tasks. To improve the training efficiency and effectiveness, this article proposes a novel surrogate-assisted evolutionary multitask algorithm via GP to share useful knowledge between different scheduling tasks. Specifically, we employ the phenotypic characterization for measuring the behaviors of scheduling rules and building a surrogate for each task accordingly. The built surrogates are used not only to improve the efficiency of solving each single task but also for knowledge transfer in multitask learning with a large number of promising individuals. The results show that the proposed algorithm can significantly improve the quality of scheduling heuristics for all scenarios. In addition, the proposed algorithm manages to solve multiple tasks collaboratively in terms of the evolved scheduling heuristics for different tasks in a multitask scenario.},
  archive      = {J_TEVC},
  author       = {Fangfang Zhang and Yi Mei and Su Nguyen and Mengjie Zhang and Kay Chen Tan},
  doi          = {10.1109/TEVC.2021.3065707},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {651-665},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Surrogate-assisted evolutionary multitask genetic programming for dynamic flexible job shop scheduling},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). A survey of evolutionary continuous dynamic optimization
over two decades—part b. <em>TEVC</em>, <em>25</em>(4), 630–650. (<a
href="https://doi.org/10.1109/TEVC.2021.3060012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents the second Part of a two-Part survey that reviews evolutionary dynamic optimization (EDO) for single-objective unconstrained continuous problems over the last two decades. While in the first part, we reviewed the components of dynamic optimization algorithms (DOAs); in this part, we present an in-depth review of the most commonly used benchmark problems, performance analysis methods, static optimization methods used in the framework of DOAs, and real-world applications. Compared to the previous works, this article provides a new taxonomy for the benchmark problems used in the field based on their baseline functions and dynamics. In addition, this survey classifies the commonly used performance indicators into fitness/error-based and efficiency-based ones. Different types of plots used in the literature for analyzing the performance and behavior of algorithms are also reviewed. Furthermore, the static optimization algorithms that are modified and utilized in the framework of DOAs as the optimization components are covered. We then comprehensively review some real-world dynamic problems that are optimized by EDO methods. Finally, some challenges and opportunities are pointed out for future directions.},
  archive      = {J_TEVC},
  author       = {Danial Yazdani and Ran Cheng and Donya Yazdani and Jürgen Branke and Yaochu Jin and Xin Yao},
  doi          = {10.1109/TEVC.2021.3060012},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {630-650},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A survey of evolutionary continuous dynamic optimization over two Decades—Part b},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). A survey of evolutionary continuous dynamic optimization
over two decades—part a. <em>TEVC</em>, <em>25</em>(4), 609–629. (<a
href="https://doi.org/10.1109/TEVC.2021.3060014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real-world optimization problems are dynamic. The field of dynamic optimization deals with such problems where the search space changes over time. In this two-part article, we present a comprehensive survey of the research in evolutionary dynamic optimization for single-objective unconstrained continuous problems over the last two decades. In Part A of this survey, we propose a new taxonomy for the components of dynamic optimization algorithms (DOAs), namely, convergence detection, change detection, explicit archiving, diversity control, and population division and management. In comparison to the existing taxonomies, the proposed taxonomy covers some additional important components, such as convergence detection and computational resource allocation. Moreover, we significantly expand and improve the classifications of diversity control and multipopulation methods, which are underrepresented in the existing taxonomies. We then provide detailed technical descriptions and analysis of different components according to the suggested taxonomy. Part B of this survey provides an in-depth analysis of the most commonly used benchmark problems, performance analysis methods, static optimization algorithms used as the optimization components in the DOAs, and dynamic real-world applications. Finally, several opportunities for future work are pointed out.},
  archive      = {J_TEVC},
  author       = {Danial Yazdani and Ran Cheng and Donya Yazdani and Jürgen Branke and Yaochu Jin and Xin Yao},
  doi          = {10.1109/TEVC.2021.3060014},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {609-629},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A survey of evolutionary continuous dynamic optimization over two Decades—Part a},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021d). IEEE transactions on evolutionary computation society
information. <em>TEVC</em>, <em>25</em>(3), C3. (<a
href="https://doi.org/10.1109/TEVC.2021.3079536">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Provides a listing of current committee members and society officers.},
  archive      = {J_TEVC},
  doi          = {10.1109/TEVC.2021.3079536},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {C3},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {IEEE transactions on evolutionary computation society information},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Few-shots parallel algorithm portfolio construction via
co-evolution. <em>TEVC</em>, <em>25</em>(3), 595–607. (<a
href="https://doi.org/10.1109/TEVC.2021.3059661">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generalization, i.e., the ability of solving problem instances that are not available during the system design and development phase, is a critical goal for intelligent systems. A typical way to achieve good generalization is to learn a model from vast data. In the context of heuristic search, such a paradigm could be implemented as configuring the parameters of a parallel algorithm portfolio (PAP) based on a set of “training” problem instances, which is often referred to as PAP construction. However, compared to the traditional machine learning, PAP construction often suffers from the lack of training instances, and the obtained PAPs may fail to generalize well. This article proposes a novel competitive co-evolution scheme, named co-evolution of parameterized search (CEPS), as a remedy to this challenge. By co-evolving a configuration population and an instance population, CEPS is capable of obtaining generalizable PAPs with few training instances. The advantage of CEPS in improving generalization is analytically shown in this article. Two concrete algorithms, namely, CEPS-TSP and CEPS-VRPSPDTW, are presented for the traveling salesman problem (TSP) and the vehicle routing problem with simultaneous pickup–delivery and time windows (VRPSPDTW), respectively. The experimental results show that CEPS has led to better generalization, and even managed to find new best-known solutions for some instances.},
  archive      = {J_TEVC},
  author       = {Ke Tang and Shengcai Liu and Peng Yang and Xin Yao},
  doi          = {10.1109/TEVC.2021.3059661},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {595-607},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Few-shots parallel algorithm portfolio construction via co-evolution},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multisource neighborhood immune detector adaptive model for
anomaly detection. <em>TEVC</em>, <em>25</em>(3), 582–594. (<a
href="https://doi.org/10.1109/TEVC.2021.3058687">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The artificial immune system (AIS) is one of the important branches of artificial intelligence technology, and it is widely used in many fields. The detector set is the core knowledge set, and the AIS application effects are mainly determined by the generation, evolution, and detection of the detectors. Presently, the problem space (shape-space) of AIS mainly applied real-valued representation. But the real-valued detectors have some problems that have not been solved well, such as slow convergence speed of generation, holes in the nonself region, detector overlapping redundancy, dimension curse, etc., which lead to the unsatisfactory detection effects. Moreover, artificial immune anomaly detection is a dynamic adaptive model, needs to be evolved adaptively with the detection environments. Without better adaptive modeling, these problems mentioned before will get worse. In view of this, this article proposes a multisource immune detector adaptive model in neighborhood shape-space and applies it to anomaly detection: based on random, chaotic map and DNA genetic algorithm (DNA-GA), multisource neighborhood negative selection algorithm (MSNNSA), multisource neighborhood immune detector generation algorithm (MS-NIDGA), and neighborhood immune anomaly detection algorithm (NIADA) are proposed, so that the generation and detection of immune detectors can be improved efficiently; introducing immune adaptive and feedback mechanism, multisource neighborhood immune detector adaptive model (MS-NIDAM) is built, so that the detectors can be adaptively evolved in a more targeted search domain, and keep better distribution to the nonself region in real time, so as to solve various problems existing in the real-valued shape-space under dynamic environment mentioned before and improve the overall detection performances. The experimental results show that MS-NIDAM can improve the detector generation/evolution efficiency, keep the up-to-date understanding of the changing environment, so as to obtain better overall detection performances and stability than other comparative methods.},
  archive      = {J_TEVC},
  author       = {Liang Xi and Rui-Dong Wang and Zhi-Yu Yao and Feng-Bin Zhang},
  doi          = {10.1109/TEVC.2021.3058687},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {582-594},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Multisource neighborhood immune detector adaptive model for anomaly detection},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learnable evolutionary search across heterogeneous problems
via kernelized autoencoding. <em>TEVC</em>, <em>25</em>(3), 567–581. (<a
href="https://doi.org/10.1109/TEVC.2021.3056514">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The design of the evolutionary algorithm with learning capability from past search experiences has attracted growing research interests in recent years. It has been demonstrated that the knowledge embedded in the past search experience can greatly speed up the evolutionary process if properly harnessed. Autoencoding evolutionary search (AEES) is a recently proposed search paradigm, which employs a single-layer denoising autoencoder to build the mapping between two problems by configuring the solutions of each problem as the input and output for the autoencoder, respectively. The learned mapping makes it possible to perform knowledge transfer across heterogeneous problem domains with diverse properties. It has shown a promising performance of learning and transferring the knowledge from past search experiences to facilitate the evolutionary search on a variety of optimization problems. However, despite the success enjoyed by AEES, the linear autoencoding model cannot capture the nonlinear relationship between the solution sets used in the mapping construction. Taking this cue, in this article, we devise a kernelized autoencoder to construct the mapping in a reproducing kernel Hilbert space (RKHS), where the nonlinearity among problem solutions can be captured easily. Importantly, the proposed kernelized autoencoding method also holds a closed-form solution which will not bring much computational burden in the evolutionary search. Furthermore, a kernelized autoencoding evolutionary-search (KAES) paradigm is proposed that adaptively selects the linear and kernelized autoencoding along the search process in pursuit of effective knowledge transfer across problem domains. To validate the efficacy of the proposed KAES, comprehensive empirical studies on both benchmark multiobjective optimization problems as well as real-world vehicle crashworthiness design problem are presented.},
  archive      = {J_TEVC},
  author       = {Lei Zhou and Liang Feng and Abhishek Gupta and Yew-Soon Ong},
  doi          = {10.1109/TEVC.2021.3056514},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {567-581},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Learnable evolutionary search across heterogeneous problems via kernelized autoencoding},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Correlation coefficient-based recombinative guidance for
genetic programming hyperheuristics in dynamic flexible job shop
scheduling. <em>TEVC</em>, <em>25</em>(3), 552–566. (<a
href="https://doi.org/10.1109/TEVC.2021.3056143">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic flexible job shop scheduling (JSS) is a challenging combinatorial optimization problem due to its complex environment. In this problem, machine assignment and operation sequencing decisions need to be made simultaneously under the dynamic environments. Genetic programming (GP), as a hyperheuristic approach, has been successfully used to evolve scheduling heuristics for dynamic flexible JSS. However, in traditional GP, recombination between parents may disrupt the beneficial building blocks by choosing the crossover points randomly. This article proposes a recombinative mechanism to provide guidance for GP to realize effective and adaptive recombination for parents to produce offspring. Specifically, we define a novel measure for the importance of each subtree of an individual, and the importance information is utilized to decide the crossover points. The proposed recombinative guidance mechanism attempts to improve the quality of offspring by preserving the promising building blocks of one parent and incorporating good building blocks from the other. The proposed algorithm is examined on six scenarios with different configurations. The results show that the proposed algorithm significantly outperforms the state-of-the-art algorithms on most tested scenarios, in terms of both final test performance and convergence speed. In addition, the rules obtained by the proposed algorithm have good interpretability.},
  archive      = {J_TEVC},
  author       = {Fangfang Zhang and Yi Mei and Su Nguyen and Mengjie Zhang},
  doi          = {10.1109/TEVC.2021.3056143},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {552-566},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Correlation coefficient-based recombinative guidance for genetic programming hyperheuristics in dynamic flexible job shop scheduling},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Enhanced constraint handling for reliability-constrained
multiobjective testing resource allocation. <em>TEVC</em>,
<em>25</em>(3), 537–551. (<a
href="https://doi.org/10.1109/TEVC.2021.3055538">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multiobjective testing resource allocation problem (MOTRAP) is how to efficiently allocate the finite testing time to various modules, with the aim of optimizing system reliability, testing cost, and testing time simultaneously. To deal with this problem, a common approach is to use multiobjective evolutionary algorithms (MOEAs) to seek a set of tradeoff solutions between the three objectives. However, such a tradeoff set may contain a substantial proportion of solutions with very low reliability level, which consume lots of computational resources but may be valueless to the software project manager. In this article, a MOTRAP model with a prespecified reliability is first proposed. Then, new lower bounds on the testing time invested in different modules are theoretically deduced from the necessary condition for the achievement of the given reliability, based on which an exact algorithm for determining the new lower bounds is presented. Moreover, several enhanced constraint-handling techniques (ECHTs) derived from the new bounds are successively developed to be combined with MOEAs to correct and reduce the constraint violation. Finally, the proposed ECHTs are evaluated in comparison with various state-of-the-art constraint-solving approaches. The comparative results demonstrate that the proposed ECHTs can work well with MOEAs, make the search focus on the feasible region of the prespecified reliability, and provide the software project manager with better and more diverse, satisfactory choices in test planning.},
  archive      = {J_TEVC},
  author       = {Zhaopin Su and Guofu Zhang and Feng Yue and Dezhi Zhan and Miqing Li and Bin Li and Xin Yao},
  doi          = {10.1109/TEVC.2021.3055538},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {537-551},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Enhanced constraint handling for reliability-constrained multiobjective testing resource allocation},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel training protocol for performance predictors of
evolutionary neural architecture search algorithms. <em>TEVC</em>,
<em>25</em>(3), 524–536. (<a
href="https://doi.org/10.1109/TEVC.2021.3055076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary neural architecture search (ENAS) can automatically design the architectures of deep neural networks (DNNs) using evolutionary computation algorithms. However, most ENAS algorithms require an intensive computational resource, which is not necessarily available to the users interested. Performance predictors are a type of regression models which can assist to accomplish the search, while without exerting much computational resource. Despite various performance predictors have been designed, they employ the same training protocol to build the regression models: 1) sampling a set of DNNs with performance as the training dataset; 2) training the model with the mean square error criterion; and 3) predicting the performance of DNNs newly generated during the ENAS. In this article, we point out that the three steps constituting the training protocol are not well thought-out through intuitive and illustrative examples. Furthermore, we propose a new training protocol to address these issues, consisting of designing a pairwise ranking indicator to construct the training target, proposing to use the logistic regression to fit the training samples, and developing a differential method to build the training instances. To verify the effectiveness of the proposed training protocol, four widely used regression models in the field of machine learning have been chosen to perform the comparisons on two benchmark datasets. The experimental results of all the comparisons demonstrate that the proposed training protocol can significantly improve the performance prediction accuracy against the traditional training protocols.},
  archive      = {J_TEVC},
  author       = {Yanan Sun and Xian Sun and Yuhan Fang and Gary G. Yen and Yuqiao Liu},
  doi          = {10.1109/TEVC.2021.3055076},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {524-536},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A novel training protocol for performance predictors of evolutionary neural architecture search algorithms},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evolutionary game analysis among three green-sensitive
parties in green supply chains. <em>TEVC</em>, <em>25</em>(3), 508–523.
(<a href="https://doi.org/10.1109/TEVC.2021.3052173">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A green supply chain, as one of the most critical low-carbon strategies, has been widely studied along with evolutionary game theory, for which governmental policies, such as a carbon tax, subsidies, or penalties, have been frequently applied; however, green sensitivity has been little explored. In this study, a general evolutionary game model composed of green-sensitive governments, enterprises, and consumers is built by considering the policy factors, and the evolutionary stable strategies of this model are solved. The solution results reveal that the green sensitivities significantly affect the evolutionary dynamics and stable strategies of the model. Green supply chains can evolve from low to advanced stages as the green sensitivities increase. At low development stages, governments must take the lead in enhancing their green sensitivity, resort to two key composite policy factor solutions, and encourage enterprises and consumers to increase their green sensitivities and drive them to adopt green strategies. As the green sensitivities of both enterprises and consumers have progressively increased to a certain high level, governments can adopt a nonsupervision strategy, reaching an advanced evolutionary stable strategy with the enterprises and consumers having complete autonomy. Therefore, green sensitivity has been proven to be a substitute for policy factors for green supply chain development. Moreover, the advanced strategy cannot be reached by any policy factor composition without green sensitivity. The findings above clarify the significance of green sensitivity, indicating that specific government policies based on the specific green sensitivities of the three parties can improve green supply chain management.},
  archive      = {J_TEVC},
  author       = {Qingqi Long and Xiaoying Tao and Ying Shi and Shuzhu Zhang},
  doi          = {10.1109/TEVC.2021.3052173},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {508-523},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolutionary game analysis among three green-sensitive parties in green supply chains},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A genetic programming approach for evolving variable
selectors in constraint programming. <em>TEVC</em>, <em>25</em>(3),
492–507. (<a href="https://doi.org/10.1109/TEVC.2021.3050465">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Operational researchers and decision modelers have aspired to optimization technologies with a self-adaptive mechanism to cope with new problem formulations. Self-adaptive mechanisms not only free users from low-level and complex development tasks to enhance optimization efficiency but also allow them to focus on addressing high-level real-world operational requirements. In recent years, there has been a growing interest in applying machine learning and artificial intelligence techniques to improve self-adaptive mechanisms. However, learning to optimize hard combinatorial optimization problems remains a challenging task. This article proposes a new genetic programming approach to evolve efficient variable selectors to enhance the search mechanism in constraint programming. Starting with a set of training instances for a specific combinatorial optimization problem, the proposed approach evaluates variable selectors and evolves them to be more efficient over a number of generations. The novelties of our proposed approach are threefold: 1) a new representation of variable selectors; 2) a new mechanism for fitness evaluations; and 3) a preselection technique. We examine performance of the proposed approach on different job-shop scheduling problems, and the results show that variable selectors can be evolved efficiently. In particular, there are substantial reductions in the computational effort required for the search component of the constraint solver as well as increased chances of finding the optimal solutions. Further analyses also confirm the efficacy of our approach in respect to scalability, generalization, and interpretability of the evolved variable selectors.},
  archive      = {J_TEVC},
  author       = {Su Nguyen and Dhananjay Thiruvady and Mengjie Zhang and Kay Chen Tan},
  doi          = {10.1109/TEVC.2021.3050465},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {492-507},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A genetic programming approach for evolving variable selectors in constraint programming},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SAFE: Scale-adaptive fitness evaluation method for expensive
optimization problems. <em>TEVC</em>, <em>25</em>(3), 478–491. (<a
href="https://doi.org/10.1109/TEVC.2021.3051608">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The key challenge of expensive optimization problems (EOP) is that evaluating the true fitness value of the solution is computationally expensive. A common method to deal with this issue is to seek for a less expensive surrogate model to replace the original expensive objective function. However, this method also brings in model approximation error. To efficiently solve the EOP, a novel scale-adaptive fitness evaluation (SAFE) method is proposed in this article to directly evaluate the true fitness value of the solution on the original objective function. To reduce the computational cost, the SAFE method uses a set of evaluation methods (EM) with different accuracy scales to cooperatively complete the fitness evaluation process. The basic idea is to adopt the low-accuracy scale EM to fast locate promising regions and utilize the high-accuracy scale EM to refine the solution accuracy. To this aim, two EM switch strategies are proposed in the SAFE method to adaptively control the multiple EMs according to different evolutionary stages and search requirements. Moreover, a neighbor best-based evaluation (NBE) strategy is also put forward to evaluate the solution according to its nearest high-quality evaluated solution, which can further reduce computational cost. Extensive experiments are carried out on the case study of crowdshipping scheduling problem in the smart city to verify the effectiveness and efficiency of the proposed SAFE method, and to investigate the effects of the two EM switch strategies and the NBE strategy. Experimental results show that the proposed SAFE method achieves better solution quality than some baseline and state-of-the-art algorithms, indicating an efficient method for solving EOP with a better balance between solution accuracy and computational cost.},
  archive      = {J_TEVC},
  author       = {Sheng-Hao Wu and Zhi-Hui Zhan and Jun Zhang},
  doi          = {10.1109/TEVC.2021.3051608},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {478-491},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {SAFE: Scale-adaptive fitness evaluation method for expensive optimization problems},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive multilevel prediction method for dynamic multimodal
optimization. <em>TEVC</em>, <em>25</em>(3), 463–477. (<a
href="https://doi.org/10.1109/TEVC.2021.3051172">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study develops an adaptive multilevel prediction (AMLP) method to detect and track multiple global optima over time. First, it formulates a multilevel prediction approach in which a higher level prediction improves the accuracy of the lower level prediction to reduce the prediction error, enabling it to capture more complex patterns in the changes. However, a higher level prediction is more sensitive to input errors and the randomness in the pattern of the change. To overcome this challenge, this study employs an adaptive mechanism which can determine the near-optimal prediction level at each time step. At the same time, AMLP calculates the strength of the diversity introduced after a change based on the estimated prediction error. A successful static multimodal optimizer is augmented with AMLP, for which AMLP determines the location and the mutation strength of the initialized subpopulations. An existing dynamic benchmark generator is improved so that it can generate dynamic test problems with more complex patterns in their changes. In particular, this dynamic benchmark generator allows for controlling the randomness of the pattern in the change to simulate dynamic problems with different degrees of predictability. A few controlled experiments are first performed to provide insight into different components of AMLP. Then, AMLP is compared with some of the most successful prediction methods when they are incorporated into the developed dynamic multimodal optimization method. Eleven dynamic cases with different change severity, change frequency, predictability, problem dimensionality, and the number of global minima are considered. The numerical results show the superiority of AMLP over other prediction methods.},
  archive      = {J_TEVC},
  author       = {Ali Ahrari and Saber Elsayed and Ruhul Sarker and Daryl Essam and Carlos A. Coello Coello},
  doi          = {10.1109/TEVC.2021.3051172},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {463-477},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Adaptive multilevel prediction method for dynamic multimodal optimization},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Paired offspring generation for constrained large-scale
multiobjective optimization. <em>TEVC</em>, <em>25</em>(3), 448–462. (<a
href="https://doi.org/10.1109/TEVC.2020.3047835">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained multiobjective optimization problems (CMOPs) widely exist in real-world applications, and they are challenging for conventional evolutionary algorithms (EAs) due to the existence of multiple constraints and objectives. When the number of objectives or decision variables is scaled up in CMOPs, the performance of EAs may degenerate dramatically and may fail to obtain any feasible solutions. To address this issue, we propose a paired offspring generation-based multiobjective EA for constrained large-scale optimization. The general idea is to emphasize the role of offspring generation in reproducing some promising feasible or useful infeasible offspring solutions. We first adopt a small set of reference vectors for constructing several subpopulations with a fixed number of neighborhood solutions. Then, a pairing strategy is adopted to determine some pairwise parent solutions for offspring generation. Consequently, the pairwise parent solutions, which could be infeasible, may guide the generation of well-converged solutions to cross the infeasible region(s) effectively. The proposed algorithm is evaluated on CMOPs with up to 1000 decision variables and ten objectives. Moreover, each component in the proposed algorithm is examined in terms of its effect on the overall algorithmic performance. Experimental results on a variety of existing and our tailored test problems demonstrate the effectiveness of the proposed algorithm in constrained large-scale multiobjective optimization.},
  archive      = {J_TEVC},
  author       = {Cheng He and Ran Cheng and Ye Tian and Xingyi Zhang and Kay Chen Tan and Yaochu Jin},
  doi          = {10.1109/TEVC.2020.3047835},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {448-462},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Paired offspring generation for constrained large-scale multiobjective optimization},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Preserving population diversity based on transformed
semantics in genetic programming for symbolic regression. <em>TEVC</em>,
<em>25</em>(3), 433–447. (<a
href="https://doi.org/10.1109/TEVC.2020.3046569">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Population diversity plays an important role in avoiding premature convergence in evolutionary techniques including genetic programming (GP). Obtaining an adequate level of diversity during the evolutionary process has became a concern of many previous researches in GP. This work proposes a new novelty metric for entropy-based diversity measure for GP. The new novelty metric is based on the transformed semantics of models in GP, where the semantics are the set of outputs of a model on the training data and principal component analysis is used for a transformation of the semantics. Based on the new novelty metric, a new diversity preserving framework, which incorporates a new fitness function and a new selection operator, is proposed to help GP achieve a good balance between the exploration and the exploitation, thus enhancing its learning and generalization performance. Compared with two stat-of-the-art diversity preserving methods, the new method can generalize better and reduce the overfitting trend more effectively in most cases. Further examinations on the properties of the search process confirm that the new framework notably enhances the evolvability and locality of GP.},
  archive      = {J_TEVC},
  author       = {Qi Chen and Bing Xue and Mengjie Zhang},
  doi          = {10.1109/TEVC.2020.3046569},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {433-447},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Preserving population diversity based on transformed semantics in genetic programming for symbolic regression},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A computationally efficient evolutionary algorithm for
multiobjective network robustness optimization. <em>TEVC</em>,
<em>25</em>(3), 419–432. (<a
href="https://doi.org/10.1109/TEVC.2020.3048174">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The robustness of complex networks is of great significance. Great achievements have been made in robustness optimization based on single measures, however, such networks may still be vulnerable to multiple attack scenarios. Therefore, recently, multiobjective robustness optimization of networks has received increasing attention. Nevertheless, several challenges remain to be addressed, including the different computational complexities in evaluating the objectives, insufficient diversity in the obtained networks, and high computational costs of the search process. In this article, we address the aforementioned challenges by developing a computationally efficient multiobjective optimization algorithm. Based on the unique features of complex networks, a new parallel fitness evaluation method guided by a network property parameter is designed and embedded in a reference vector-guided multiobjective evolutionary algorithm. In addition, a surrogate ensemble with heterogeneous inputs is constructed based on graph embedding information to efficiently estimate multiple robustness of networks. The proposed algorithm is validated on synthetic and real-world network data and our results show that the designed algorithm outperforms the state-of-the-art method with a marked improvement on the computational efficiency. Compared with other single-objective optimization methods, the proposed algorithm demonstrates a considerable exploitation ability.},
  archive      = {J_TEVC},
  author       = {Shuai Wang and Jing Liu and Yaochu Jin},
  doi          = {10.1109/TEVC.2020.3048174},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {419-432},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A computationally efficient evolutionary algorithm for multiobjective network robustness optimization},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multipopulation evolutionary algorithm for solving
large-scale multimodal multiobjective optimization problems.
<em>TEVC</em>, <em>25</em>(3), 405–418. (<a
href="https://doi.org/10.1109/TEVC.2020.3044711">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal multiobjective optimization problems (MMOPs) widely exist in real-world applications, which have multiple equivalent Pareto-optimal solutions that are similar in the objective space but totally different in the decision space. While some evolutionary algorithms (EAs) have been developed to find the equivalent Pareto-optimal solutions in recent years, they are ineffective to handle large-scale MMOPs having a large number of variables. This article thus proposes an EA for solving large-scale MMOPs with sparse Pareto-optimal solutions, i.e., most variables in the optimal solutions are 0. The proposed algorithm explores different regions of the decision space via multiple subpopulations and guides the search behavior of the subpopulations via adaptively updated guiding vectors. The guiding vector for each subpopulation not only provides efficient convergence in the huge search space but also differentiates its search direction from others to handle the multimodality. While most existing EAs solve MMOPs with 2-7 decision variables, the proposed algorithm is shown to be effective for benchmark MMOPs with up to 500 decision variables. Moreover, the proposed algorithm also produces a better result than state-of-the-art methods for the neural architecture search.},
  archive      = {J_TEVC},
  author       = {Ye Tian and Ruchen Liu and Xingyi Zhang and Haiping Ma and Kay Chen Tan and Yaochu Jin},
  doi          = {10.1109/TEVC.2020.3044711},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {405-418},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A multipopulation evolutionary algorithm for solving large-scale multimodal multiobjective optimization problems},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021e). IEEE transactions on evolutionary computation society
information. <em>TEVC</em>, <em>25</em>(2), C3. (<a
href="https://doi.org/10.1109/TEVC.2021.3066764">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Provides a listing of current committee members and society officers.},
  archive      = {J_TEVC},
  doi          = {10.1109/TEVC.2021.3066764},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {C3},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {IEEE transactions on evolutionary computation society information},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Introducing IEEE collabratec. <em>TEVC</em>,
<em>25</em>(2), 403. (<a
href="https://doi.org/10.1109/TEVC.2021.3066821">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advertisement, IEEE. IEEE Collabratec is a new, integrated online community where IEEE members, researchers, authors, and technology professionals with similar fields of interest can network and collaborate, as well as create and manage content. Featuring a suite of powerful online networking and collaboration tools, IEEE Collabratec allows you to connect according to geographic location, technical interests, or career pursuits. You can also create and share a professional identity that showcases key accomplishments and participate in groups focused around mutual interests, actively learning from and contributing to knowledgeable communities. All in one place! Learn about IEEE Collabratec at ieeecollabratec.org.},
  archive      = {J_TEVC},
  doi          = {10.1109/TEVC.2021.3066821},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {403},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Introducing IEEE collabratec},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). From prediction to prescription: Evolutionary optimization
of nonpharmaceutical interventions in the COVID-19 pandemic.
<em>TEVC</em>, <em>25</em>(2), 386–401. (<a
href="https://doi.org/10.1109/TEVC.2021.3063217">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several models have been developed to predict how the COVID-19 pandemic spreads, and how it could be contained with nonpharmaceutical interventions, such as social distancing restrictions and school and business closures. This article demonstrates how evolutionary AI can be used to facilitate the next step, i.e., determining most effective intervention strategies automatically. Through evolutionary surrogate-assisted prescription, it is possible to generate a large number of candidate strategies and evaluate them with predictive models. In principle, strategies can be customized for different countries and locales, and balance the need to contain the pandemic and the need to minimize their economic impact. Early experiments suggest that workplace and school restrictions are the most important and need to be designed carefully. They also demonstrate that results of lifting restrictions can be unreliable, and suggest creative ways in which restrictions can be implemented softly, e.g., by alternating them over time. As more data becomes available, the approach can be increasingly useful in dealing with COVID-19 as well as possible future pandemics.},
  archive      = {J_TEVC},
  author       = {Risto Miikkulainen and Olivier Francon and Elliot Meyerson and Xin Qiu and Darren Sargent and Elisa Canzani and Babak Hodjat},
  doi          = {10.1109/TEVC.2021.3063217},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {386-401},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {From prediction to prescription: Evolutionary optimization of nonpharmaceutical interventions in the COVID-19 pandemic},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient evolutionary search of attention convolutional
networks via sampled training and node inheritance. <em>TEVC</em>,
<em>25</em>(2), 371–385. (<a
href="https://doi.org/10.1109/TEVC.2020.3040272">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of deep neural networks is heavily dependent on its architecture and various neural architecture search strategies have been developed for automated network architecture design. Recently, evolutionary neural architecture search (EvoNAS) has received increasing attention due to the attractive global optimization capability of evolutionary algorithms. However, EvoNAS suffers from extremely high computational costs because a large number of performance evaluations are usually required in evolutionary optimization, and training deep neural networks is itself computationally very expensive. To address this issue, this article proposes a computationally efficient framework for the evolutionary search of convolutional networks based on a directed acyclic graph, in which parents are randomly sampled and trained on each mini-batch of training data. In addition, a node inheritance strategy is adopted so that the fitness of all offspring individuals can be evaluated without training them. Finally, we encode a channel attention mechanism in the search space to enhance the feature processing capability of the evolved neural networks. We evaluate the proposed algorithm on the widely used datasets, in comparison with 30 state-of-the-art peer algorithms. Our experimental results show that the proposed algorithm is not only computationally much more efficient but also highly competitive in learning performance.},
  archive      = {J_TEVC},
  author       = {Haoyu Zhang and Yaochu Jin and Ran Cheng and Kuangrong Hao},
  doi          = {10.1109/TEVC.2020.3040272},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {371-385},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Efficient evolutionary search of attention convolutional networks via sampled training and node inheritance},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fitness-based linkage learning in the real-valued gene-pool
optimal mixing evolutionary algorithm. <em>TEVC</em>, <em>25</em>(2),
358–370. (<a href="https://doi.org/10.1109/TEVC.2020.3039698">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recently introduced real-valued gene-pool optimal mixing evolutionary algorithm (RV-GOMEA) has been shown to be among the state of the art for solving gray-box optimization problems where partial evaluations can be leveraged. A core strength is its ability to effectively exploit the linkage structure of a problem, which often is unknown a priori and has to be learned online. Previously published work on RV-GOMEA, however, demonstrated excellent scalability when the linkage structure is prespecified appropriately. A mutual information-based metric to learn linkage structure online, as commonly adopted in EDA&#39;s and the original discrete version of the gene-pool optimal mixing evolutionary algorithm, did not lead to similarly excellent results, especially in a black-box setting. In this article, the strengths of RV-GOMEA are combined with a new fitness-based linkage learning approach that is inspired by differential grouping that reduces its computational overhead by an order of magnitude for problems with fewer interactions. The resulting new version of RV-GOMEA achieves scalability similar to when a predefined linkage model is used, outperforming also, for the first time, the EDA AMaLGaM upon which it is partially based in a black-box setting where partial evaluations cannot be leveraged.},
  archive      = {J_TEVC},
  author       = {Chantal Olieman and Anton Bouter and Peter A. N. Bosman},
  doi          = {10.1109/TEVC.2020.3039698},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {358-370},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Fitness-based linkage learning in the real-valued gene-pool optimal mixing evolutionary algorithm},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). QED: Using quality-environment-diversity to evolve resilient
robot swarms. <em>TEVC</em>, <em>25</em>(2), 346–357. (<a
href="https://doi.org/10.1109/TEVC.2020.3036578">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In quality-diversity algorithms, the behavioral diversity metric is a key design choice that determines the quality of the evolved archives. Although behavioral diversity is traditionally obtained by describing the observed resulting behavior of robot controllers evaluated in a single environment, it is often more easily induced by introducing environmental diversity, i.e., by manipulating the environments in which the controllers are evaluated. This article proposes quality-environment-diversity (QED), an algorithm that repeatedly generates a random environment according to a probability distribution over environmental features (e.g., number of obstacles, arena size and robot sensor and actuator characteristics), evaluates the controller in that environment, and then describes the controller in terms of the features of that environment, the environment descriptor. Our study compares QED to three baseline task-specific and generic behavioral descriptors, in 5 different robot swarm benchmark tasks. For each task, the quality of the evolved archives is assessed by their capability to provide high-performing compensatory behaviors following injection of 250 unique faults to the robots of the swarm. The evolved archives achieve a median 2- to 3-fold reduction in the impact of the faults on the performance of the swarm. A qualitative analysis of evolved archives is done by visualizing the relation between diversity of compensatory behaviors, here called useful behavioral diversity, and fault recovery metrics. The resulting signatures indicate that, due to the diversity of environments inducing useful behavioral diversity, archives evolved by QED provide robot swarm controllers that are capable of recovering from high-impact faults.},
  archive      = {J_TEVC},
  author       = {David M. Bossens and Danesh Tarapore},
  doi          = {10.1109/TEVC.2020.3036578},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {346-357},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {QED: Using quality-environment-diversity to evolve resilient robot swarms},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new many-objective evolutionary algorithm based on
determinantal point processes. <em>TEVC</em>, <em>25</em>(2), 334–345.
(<a href="https://doi.org/10.1109/TEVC.2020.3035825">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To handle different types of many-objective optimization problems (MaOPs), many-objective evolutionary algorithms (MaOEAs) need to simultaneously maintain convergence and population diversity in the high-dimensional objective space. In order to balance the relationship between diversity and convergence, we introduce a Kernel matrix and probability model called determinantal point processes (DPPs). Our MaOEA with DPPs (MaOEADPPs) is presented and compared with several state-of-the-art algorithms on various types of MaOPs with different numbers of objectives. The experimental results demonstrate that MaOEADPPs is competitive.},
  archive      = {J_TEVC},
  author       = {Peng Zhang and Jinlong Li and Tengfei Li and Huanhuan Chen},
  doi          = {10.1109/TEVC.2020.3035825},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {334-345},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A new many-objective evolutionary algorithm based on determinantal point processes},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MMES: Mixture model-based evolution strategy for large-scale
optimization. <em>TEVC</em>, <em>25</em>(2), 320–333. (<a
href="https://doi.org/10.1109/TEVC.2020.3034769">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work provides an efficient sampling method for the covariance matrix adaptation evolution strategy (CMA-ES) in large-scale settings. In contract to the Gaussian sampling in CMA-ES, the proposed method generates mutation vectors from a mixture model, which facilitates exploiting the rich variable correlations of the problem landscape within a limited time budget. We analyze the probability distribution of this mixture model and show that it approximates the Gaussian distribution of CMA-ES with a controllable accuracy. We use this sampling method, coupled with a novel method for mutation strength adaptation, to formulate the mixture model-based evolution strategy (MMES)-a CMA-ES variant for large-scale optimization. The numerical simulations show that, while significantly reducing the time complexity of CMA-ES, MMES preserves the rotational invariance, is scalable to high dimensional problems, and is competitive against the state-of-the-arts in performing global optimization.},
  archive      = {J_TEVC},
  author       = {Xiaoyu He and Zibin Zheng and Yuren Zhou},
  doi          = {10.1109/TEVC.2020.3034769},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {320-333},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {MMES: Mixture model-based evolution strategy for large-scale optimization},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Frequency fitness assignment: Making optimization algorithms
invariant under bijective transformations of the objective function
value. <em>TEVC</em>, <em>25</em>(2), 307–319. (<a
href="https://doi.org/10.1109/TEVC.2020.3032090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Under frequency fitness assignment (FFA), the fitness corresponding to an objective value is its encounter frequency in fitness assignment steps and is subject to minimization. FFA renders optimization processes invariant under bijective transformations of the objective function value. On TwoMax, Jump, and Trap functions of dimension s, the classical (1 + 1)-EA with standard mutation at rate 1/s can have expected runtimes exponential in s. In our experiments, a (1 + 1)-FEA, the same algorithm but using FFA, exhibits mean runtimes that seem to scale as s 2 ln s. Since Jump and Trap are bijective transformations of OneMax, it behaves identical on all three. On OneMax, LeadingOnes, and Plateau problems, it seems to be slower than the (1 + 1)-EA by a factor linear in s. The (1 + 1)-FEA performs much better than the (1 + 1)-EA on W-Model and MaxSat instances. We further verify the bijection invariance by applying the Md5 checksum computation as transformation to some of the above problems and yield the same behaviors. Finally, we show that FFA can improve the performance of a memetic algorithm for job shop scheduling.},
  archive      = {J_TEVC},
  author       = {Thomas Weise and Zhize Wu and Xinlu Li and Yan Chen},
  doi          = {10.1109/TEVC.2020.3032090},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {307-319},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Frequency fitness assignment: Making optimization algorithms invariant under bijective transformations of the objective function value},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Knee-based decision making and visualization in
many-objective optimization. <em>TEVC</em>, <em>25</em>(2), 292–306. (<a
href="https://doi.org/10.1109/TEVC.2020.3027620">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an essential component in multi- and many-objective optimization, decision-making process either selects a subset of solutions from the whole Pareto front or guides the search toward a small part of the Pareto front during the evolutionary process. In recent years, for many-objective optimization problems (MaOPs), a number of evolutionary algorithms have been developed to search for Pareto optimal solutions. However, there is a lack of research works focusing on designing decision-making approaches. In order to overcome this deficiency, we propose a novel knee-based decision-making method to search for several solutions of interest (SOIs) from a large number of solutions on the Pareto front, each of which contains the best convergence performance at least within its neighborhood and can be identified as a global or local knee solution. The optimization performance achieved by all SOIs approximates the performance of the whole Pareto front as much as possible. Furthermore, in order to relieve the difficulties in the decision-making process on MaOPs, a new visualization approach is developed based on this proposed decision-making approach. It provides information about the shape and location of the Pareto front, the possible bulge, as well as the convergence degree and distribution of solutions. The experimental results on several benchmark functions demonstrate the superiority of the proposed design in the selection of SOIs and visualization of high-dimensional objective space.},
  archive      = {J_TEVC},
  author       = {Zhenan He and Gary G. Yen and Jinliang Ding},
  doi          = {10.1109/TEVC.2020.3027620},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {292-306},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Knee-based decision making and visualization in many-objective optimization},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multiobjective evolutionary design of deep convolutional
neural networks for image classification. <em>TEVC</em>, <em>25</em>(2),
277–291. (<a href="https://doi.org/10.1109/TEVC.2020.3024708">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) are the backbones of deep learning paradigms for numerous vision tasks. Early advancements in CNN architectures are primarily driven by human expertise and by elaborate design processes. Recently, neural architecture search was proposed with the aim of automating the network design process and generating task-dependent architectures. While existing approaches have achieved competitive performance in image classification, they are not well suited to problems where the computational budget is limited for two reasons: 1) the obtained architectures are either solely optimized for classification performance, or only for one deployment scenario and 2) the search process requires vast computational resources in most approaches. To overcome these limitations, we propose an evolutionary algorithm for searching neural architectures under multiple objectives, such as classification performance and floating point operations (FLOPs). The proposed method addresses the first shortcoming by populating a set of architectures to approximate the entire Pareto frontier through genetic operations that recombine and modify architectural components progressively. Our approach improves computational efficiency by carefully down-scaling the architectures during the search as well as reinforcing the patterns commonly shared among past successful architectures through Bayesian model learning. The integration of these two main contributions allows an efficient design of architectures that are competitive and in most cases outperform both manually and automatically designed architectures on benchmark image classification datasets: CIFAR, ImageNet, and human chest X-ray. The flexibility provided from simultaneously obtaining multiple architecture choices for different compute requirements further differentiates our approach from other methods in the literature.},
  archive      = {J_TEVC},
  author       = {Zhichao Lu and Ian Whalen and Yashesh Dhebar and Kalyanmoy Deb and Erik D. Goodman and Wolfgang Banzhaf and Vishnu Naresh Boddeti},
  doi          = {10.1109/TEVC.2020.3024708},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {277-291},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Multiobjective evolutionary design of deep convolutional neural networks for image classification},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Regularized evolutionary multitask optimization: Learning to
intertask transfer in aligned subspace. <em>TEVC</em>, <em>25</em>(2),
262–276. (<a href="https://doi.org/10.1109/TEVC.2020.3023480">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a novel and computationally efficient explicit intertask information transfer strategy between optimization tasks by aligning the subspaces. In evolutionary multitasking, the tasks might have biases embedded in function landscapes and decision spaces, which often causes the threat of predominantly negative transfer. However, the complementary information among different tasks can give an enhanced performance of solving complicated problems when properly harnessed. In this article, we distill this insight by introducing an intertask knowledge transfer strategy implemented in the low-dimension subspaces via a learnable alignment matrix. Specifically, to unveil the significant features of the function landscapes, the task-specific low-dimension subspaces is established based on the distribution information of subpopulations possessed by tasks, respectively. Next, the alignment matrix between pairwise subspaces is learned by minimizing the discrepancies of the subspaces. Given the aligned subspaces by applying the alignment matrix to subspaces&#39; base vectors, the individuals from different tasks are then projected into aligned subspaces and reproduce therein. Moreover, since this method only considers the leading eigenvectors, it turns out to be intrinsically regularized and noise-insensitive. Comprehensive experiments are conducted on the synthetic and practical benchmark problems so as to assess the efficacy of the proposed method. According to the experimental results, the proposed method exhibits a superior performance compared with existing evolutionary multitask optimization algorithms.},
  archive      = {J_TEVC},
  author       = {Zedong Tang and Maoguo Gong and Yue Wu and Wenfeng Liu and Yu Xie},
  doi          = {10.1109/TEVC.2020.3023480},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {262-276},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Regularized evolutionary multitask optimization: Learning to intertask transfer in aligned subspace},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An evolutionary multiobjective framework for complex network
reconstruction using community structure. <em>TEVC</em>, <em>25</em>(2),
247–261. (<a href="https://doi.org/10.1109/TEVC.2020.3020423">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of inferring nonlinear and complex dynamical systems from available data is prominent in many fields, including engineering, biological, social, physical, and computer sciences. Many evolutionary algorithm (EA)-based network reconstruction methods have been proposed to address this problem, but they ignore several useful information of network structure, such as community structure, which widely exists in various complex networks. Inspired by the community structure, this article develops a community-based evolutionary multiobjective network reconstruction framework to promote the reconstruction performance of EA-based network reconstruction methods due to their good performance; we refer this framework as CEMO-NR. CEMO-NR is a generic framework and any population-based multiobjective metaheuristic algorithm can be employed as the base optimizer. CEMO-NR employs the community structure of networks to divide the original decision space into multiple small decision spaces, and then any multiobjective EA (MOEA) can be used to search for improved solutions in the reduced decision space. To verify the performance of CEMO-NR, this article also designs a test suite for complex network reconstruction problems. Three representative MOEAs are embedded into CEMO-NR and compared with their original versions, respectively. The experimental results have demonstrated the significant improvement benefiting from the proposed CEMO-NR in 30 multiobjective network reconstruction problems (MONRPs).},
  archive      = {J_TEVC},
  author       = {Kai Wu and Jing Liu and Xingxing Hao and Penghui Liu and Fang Shen},
  doi          = {10.1109/TEVC.2020.3020423},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {247-261},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {An evolutionary multiobjective framework for complex network reconstruction using community structure},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Realistic constrained multiobjective optimization benchmark
problems from design. <em>TEVC</em>, <em>25</em>(2), 234–246. (<a
href="https://doi.org/10.1109/TEVC.2020.3020046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiobjective optimization is increasingly used in engineering to design new systems and to identify design tradeoffs. Yet, design problems often have objective functions and constraints that are expensive and highly nonlinear. Combinations of these features lead to poor convergence and diversity loss with common algorithms that have not been specifically designed for constrained optimization. Constrained benchmark problems exist, but they do not necessarily represent the challenges of engineering problems. In this article, a framework to design electro-mechanical actuators, called multiobjective design of actuators (MODAct), is presented and 20 constrained multiobjective optimization test problems are derived from the framework with a specific focus on constraints. The full source code is made available to ease its use. The effects of the constraints are analyzed through their impact on the Pareto front as well as on the convergence performance. A constraint landscape analysis approach is followed and extended with three new metrics to characterize the search and objective spaces. The features of MODAct are compared to existing test suites to highlight the differences. In addition, a convergence analysis using NSGA-II, NSGA-III, and C-TAEA on MODAct and existing test suites suggests that the design problems are indeed difficult due to the constraints. In particular, the number of simultaneously violated constraints in newly generated solutions seems key in understanding the convergence challenges. Thus, MODAct offers an efficient framework to analyze and handle constraints in future optimization algorithm design.},
  archive      = {J_TEVC},
  author       = {Cyril Picard and Jürg Schiffmann},
  doi          = {10.1109/TEVC.2020.3020046},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {234-246},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Realistic constrained multiobjective optimization benchmark problems from design},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A classifier-assisted level-based learning swarm optimizer
for expensive optimization. <em>TEVC</em>, <em>25</em>(2), 219–233. (<a
href="https://doi.org/10.1109/TEVC.2020.3017865">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surrogate-assisted evolutionary algorithms (SAEAs) have become one popular method to solve complex and computationally expensive optimization problems. However, most existing SAEAs suffer from performance degradation with the dimensionality increasing. To solve this issue, this article proposes a classifier-assisted level-based learning swarm optimizer on the basis of the level-based learning swarm optimizer (LLSO) and the gradient boosting classifier (GBC) to improve the robustness and scalability of SAEAs. Particularly, the level-based learning strategy in LLSO has a tight correspondence with the classification characteristic by setting the number of levels in LLSO to be the same as the number of classes in GBC. Together, the classification results feedback the distribution of promising candidates to accelerate the evolution of the optimizer, while the evolved population helps to improve the accuracy of the classifier. To select informative and valuable candidates for real evaluations, we devise an ${L}1$ -exploitation strategy to extensively exploit promising areas. Then, the candidate selection is conducted between the predicted ${L}1$ offspring and the already real-evaluated ${L}1$ individuals based on their Euclidean distances. Extensive experiments on commonly used benchmark functions demonstrate that the proposed optimizer can achieve competitive or better performance with a very small training dataset compared with three state-of-the-art SAEAs.},
  archive      = {J_TEVC},
  author       = {Feng-Feng Wei and Wei-Neng Chen and Qiang Yang and Jeremiah Deng and Xiao-Nan Luo and Hu Jin and Jun Zhang},
  doi          = {10.1109/TEVC.2020.3017865},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {219-233},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A classifier-assisted level-based learning swarm optimizer for expensive optimization},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A duplication analysis-based evolutionary algorithm for
biobjective feature selection. <em>TEVC</em>, <em>25</em>(2), 205–218.
(<a href="https://doi.org/10.1109/TEVC.2020.3016049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is a complex optimization problem with important real-world applications. Normally, its main target is to reduce the dimensionality of the dataset and increase the effectiveness of the classification. Owing to the population-inspired characteristics, different evolutionary algorithms (EAs) have been proposed to solve feature selection problems over the past decades. However, the majority of them only consider single-objective optimization while many real-world problems have multiple objectives, which creates a genuine demand for designing more suitable and effective EAs to handle multiobjective feature selection. A multiobjective feature selection problem usually consists of two objectives: one is to minimize the number of selected features and the other is to minimize the error of classification. In this article, we propose a duplication analysis-based EA (DAEA) for biobjective feature selection in classification. In the proposed algorithm, we make improvements on the basic dominance-based EA framework in three aspects: first, the reproduction process is modified to improve the quality of offspring; second, a duplication analysis method is proposed to filter out the redundant solutions; and third, a diversity-based selection method is adopted to further select the reserved solutions. In the experiments, we have compared the proposed algorithm with five state-of-the-art multiobjective EAs (MOEAs) and tested them on 20 classification datasets, using two widely used performance metrics. According to the empirical results, DAEA performs the best on most datasets, indicating that DAEA not only gains outstanding optimization performance but also obtains good classification and generalization results.},
  archive      = {J_TEVC},
  author       = {Hang Xu and Bing Xue and Mengjie Zhang},
  doi          = {10.1109/TEVC.2020.3016049},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {205-218},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A duplication analysis-based evolutionary algorithm for biobjective feature selection},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021f). IEEE transactions on evolutionary computation society
information. <em>TEVC</em>, <em>25</em>(1), C3. (<a
href="https://doi.org/10.1109/TEVC.2021.3052590">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Provides a listing of current committee members and society officers.},
  archive      = {J_TEVC},
  doi          = {10.1109/TEVC.2021.3052590},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {C3},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {IEEE transactions on evolutionary computation society information},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). Introducing IEEE collabratec. <em>TEVC</em>,
<em>25</em>(1), 203. (<a
href="https://doi.org/10.1109/TEVC.2021.3052594">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advertisement, IEEE. IEEE Collabratec is a new, integrated online community where IEEE members, researchers, authors, and technology professionals with similar fields of interest can network and collaborate, as well as create and manage content. Featuring a suite of powerful online networking and collaboration tools, IEEE Collabratec allows you to connect according to geographic location, technical interests, or career pursuits. You can also create and share a professional identity that showcases key accomplishments and participate in groups focused around mutual interests, actively learning from and contributing to knowledgeable communities. All in one place! Learn about IEEE Collabratec at ieeecollabratec.org.},
  archive      = {J_TEVC},
  doi          = {10.1109/TEVC.2021.3052594},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {203},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Introducing IEEE collabratec},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Variable population memetic search: A case study on the
critical node problem. <em>TEVC</em>, <em>25</em>(1), 187–200. (<a
href="https://doi.org/10.1109/TEVC.2020.3011959">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Population-based memetic algorithms have been successfully applied to solve many difficult combinatorial problems. Often, a population of fixed size is used in such algorithms to record some best solutions sampled during the search. However, given the particular features of the problem instance under consideration, a population of variable size would be more suitable to ensure the best search performance possible. In this work, we propose a variable population memetic search (VPMS), where a strategic population sizing mechanism is used to dynamically adjust the population size during the search process. Our VPMS approach starts its search from a small population of only two solutions to focus on exploitation and then adapts the population size according to the search status to continuously influence the balancing between exploitation and exploration. We illustrate an application of the VPMS approach to solve the challenging critical node problem (CNP). We show that the VPMS algorithm integrating a variable population, an effective local optimization procedure, and a backbone-based crossover operator performs very well compared to state-of-the-art CNP algorithms. The algorithm is able to discover new upper bounds for 12 instances out of the 42 popular benchmark instances while matching 23 previous best-known upper bounds.},
  archive      = {J_TEVC},
  author       = {Yangming Zhou and Jin-Kao Hao and Zhang-Hua Fu and Zhe Wang and Xiangjing Lai},
  doi          = {10.1109/TEVC.2020.3011959},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {187-200},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Variable population memetic search: A case study on the critical node problem},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Constrained multiobjective optimization: Test problem
construction and performance evaluations. <em>TEVC</em>, <em>25</em>(1),
172–186. (<a href="https://doi.org/10.1109/TEVC.2020.3011829">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained multiobjective optimization abounds in practical applications and is gaining growing attention in the evolutionary computation community. Artificial test problems are critical to the progress in this research area. Nevertheless, many of them lack important characteristics, such as scalability and variable dependencies, which may be essential in benchmarking modern evolutionary algorithms. This article first proposes a new framework for constrained test problem construction. This framework splits a decision vector into position and distance variables and forces their optimal values to lie on a nonlinear hypersurface such that the interdependencies can be introduced among the position ones and among the distance ones individually. In this framework, two kinds of constraints are designed to introduce convergence-hardness and diversity-hardness, respectively. The first kind introduces infeasible barriers in approaching the optima, and at the same time, makes the position and distance variables interrelate with each other. The second kind restricts the feasible optimal regions such that different shapes of Pareto fronts can be obtained. Based on this framework, we construct 16 scalable and constrained test problems covering a variety of difficulties. Then, in the second part of this article, we evaluate the performance of some state of the art on the proposed test problems, showing that they are quite challenging and there is room for further enhancement of the existing algorithms. Finally, we discuss in detail the source of difficulties presented in these new problems.},
  archive      = {J_TEVC},
  author       = {Yuren Zhou and Yi Xiang and Xiaoyu He},
  doi          = {10.1109/TEVC.2020.3011829},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {172-186},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Constrained multiobjective optimization: Test problem construction and performance evaluations},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient recursive differential grouping for large-scale
continuous problems. <em>TEVC</em>, <em>25</em>(1), 159–171. (<a
href="https://doi.org/10.1109/TEVC.2020.3009390">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cooperative co-evolution (CC) is an efficient and practical evolutionary framework for solving large-scale optimization problems. The performance of CC is affected by the variable decomposition. An accurate variable decomposition can help to improve the performance of CC on solving an optimization problem. The variable grouping methods usually spend many computational resources obtaining an accurate variable decomposition. To reduce the computational cost on the decomposition, we propose an efficient recursive differential grouping (ERDG) method in this article. By exploiting the historical information on examining the interrelationship between the variables of an optimization problem, ERDG is able to avoid examining some interrelationship and spend much less computation than other recursive differential grouping methods. Our experimental results and analysis suggest that ERDG is a competitive method for decomposing large-scale continuous problems and improves the performance of CC for solving the large-scale optimization problems.},
  archive      = {J_TEVC},
  author       = {Ming Yang and Aimin Zhou and Changhe Li and Xin Yao},
  doi          = {10.1109/TEVC.2020.3009390},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {159-171},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {An efficient recursive differential grouping for large-scale continuous problems},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multiobjective evolutionary algorithm for finding knee
regions using two localized dominance relationships. <em>TEVC</em>,
<em>25</em>(1), 145–158. (<a
href="https://doi.org/10.1109/TEVC.2020.3008877">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In preference-based optimization, knee points are considered the naturally preferred tradeoff solutions, especially when the decision maker has little a priori knowledge about the problem to be solved. However, identifying all convex knee regions of a Pareto front remains extremely challenging, in particular in a high-dimensional objective space. This article presents a new evolutionary multiobjective algorithm for locating knee regions using two localized dominance relationships. In the environmental selection, the α-dominance is applied to each subpopulation partitioned by a set of predefined reference vectors, thereby guiding the search toward different potential knee regions while removing possible dominance resistant solutions. A knee-oriented-dominance measure making use of the extreme points is then proposed to detect knee solutions in convex knee regions and discard solutions in concave knee regions. Our experimental results demonstrate that the proposed algorithm outperforms the state-of-the-art knee identification algorithms on a majority of multiobjective optimization test problems having up to eight objectives and a hybrid electric vehicle controller design problem with seven objectives.},
  archive      = {J_TEVC},
  author       = {Guo Yu and Yaochu Jin and Markus Olhofer},
  doi          = {10.1109/TEVC.2020.3008877},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {145-158},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A multiobjective evolutionary algorithm for finding knee regions using two localized dominance relationships},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multimodal multiobjective evolutionary optimization with
dual clustering in decision and objective spaces. <em>TEVC</em>,
<em>25</em>(1), 130–144. (<a
href="https://doi.org/10.1109/TEVC.2020.3008822">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article suggests a multimodal multiobjective evolutionary algorithm with dual clustering in decision and objective spaces. One clustering is run in decision space to gather nearby solutions, which will classify solutions into multiple local clusters. Nondominated solutions within each local cluster are first selected to maintain local Pareto sets, and the remaining ones with good convergence in objective space are also selected, which will form a temporary population with more than ${N}$ solutions ( ${N}$ is the population size). After that, a second clustering is run in objective space for this temporary population to get ${N}$ final clusters with good diversity in objective space. Finally, a pruning process is repeatedly run on the above clusters until each cluster has only one solution, which removes the most crowded solution in decision space from the most crowded cluster in objective space each time. This way, the clustering in decision space can distinguish all Pareto sets and avoid the loss of local Pareto sets, while that in objective space can maintain diversity in objective space. When solving all the benchmark problems from the competition of multimodal multiobjective optimization in the IEEE Congress on Evolutionary Computation 2019, the experiments validate our advantages to maintain diversity in both objective and decision spaces.},
  archive      = {J_TEVC},
  author       = {Qiuzhen Lin and Wu Lin and Zexuan Zhu and Maoguo Gong and Jianqiang Li and Carlos A. Coello Coello},
  doi          = {10.1109/TEVC.2020.3008822},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {130-144},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Multimodal multiobjective evolutionary optimization with dual clustering in decision and objective spaces},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Knee point-based imbalanced transfer learning for dynamic
multiobjective optimization. <em>TEVC</em>, <em>25</em>(1), 117–129. (<a
href="https://doi.org/10.1109/TEVC.2020.3004027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic multiobjective optimization problems (DMOPs) are optimization problems with multiple conflicting optimization objectives, and these objectives change over time. Transfer learning-based approaches have been proven to be promising; however, a slow solving speed is one of the main obstacles preventing such methods from solving real-world problems. One of the reasons for the slow running speed is that low-quality individuals occupy a large amount of computing resources, and these individuals may lead to negative transfer. Combining high-quality individuals, such as knee points, with transfer learning is a feasible solution to this problem. However, the problem with this idea is that the number of high-quality individuals is often very small, so it is difficult to acquire substantial improvements using conventional transfer learning methods. In this article, we propose a knee point-based transfer learning method, called KT-DMOEA, for solving DMOPs. In the proposed method, a trend prediction model (TPM) is developed for producing the estimated knee points. Then, an imbalance transfer learning method is proposed to generate a high-quality initial population by using these estimated knee points. The advantage of this approach is that the seamless integration of a small number of high-quality individuals and the imbalance transfer learning technique can greatly improve the computational efficiency while maintaining the quality of the solution. The experimental results and performance comparisons with some chosen state-of-the-art algorithms demonstrate that the proposed design is capable of significantly improving the performance of dynamic optimization.},
  archive      = {J_TEVC},
  author       = {Min Jiang and Zhenzhong Wang and Haokai Hong and Gary G. Yen},
  doi          = {10.1109/TEVC.2020.3004027},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {117-129},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Knee point-based imbalanced transfer learning for dynamic multiobjective optimization},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A coevolutionary framework for constrained multiobjective
optimization problems. <em>TEVC</em>, <em>25</em>(1), 102–116. (<a
href="https://doi.org/10.1109/TEVC.2020.3004012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained multiobjective optimization problems (CMOPs) are challenging because of the difficulty in handling both multiple objectives and constraints. While some evolutionary algorithms have demonstrated high performance on most CMOPs, they exhibit bad convergence or diversity performance on CMOPs with small feasible regions. To remedy this issue, this article proposes a coevolutionary framework for constrained multiobjective optimization, which solves a complex CMOP assisted by a simple helper problem. The proposed framework evolves one population to solve the original CMOP and evolves another population to solve a helper problem derived from the original one. While the two populations are evolved by the same optimizer separately, the assistance in solving the original CMOP is achieved by sharing useful information between the two populations. In the experiments, the proposed framework is compared to several state-of-the-art algorithms tailored for CMOPs. High competitiveness of the proposed framework is demonstrated by applying it to 47 benchmark CMOPs and the vehicle routing problem with time windows.},
  archive      = {J_TEVC},
  author       = {Ye Tian and Tao Zhang and Jianhua Xiao and Xingyi Zhang and Yaochu Jin},
  doi          = {10.1109/TEVC.2020.3004012},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {102-116},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A coevolutionary framework for constrained multiobjective optimization problems},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Genetic programming with image-related operators and a
flexible program structure for feature learning in image classification.
<em>TEVC</em>, <em>25</em>(1), 87–101. (<a
href="https://doi.org/10.1109/TEVC.2020.3002229">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature extraction is essential for solving image classification by transforming low-level pixel values into high-level features. However, extracting effective features from images is challenging due to high variations across images in scale, rotation, illumination, and background. Existing methods often have a fixed model complexity and require domain expertise. Genetic programming (GP) with a flexible representation can find the best solution without the use of domain knowledge. This article proposes a new GP-based approach to automatically learning informative features for different image classification tasks. In the new approach, a number of image-related operators, including filters, pooling operators, and feature extraction methods, are employed as functions. A flexible program structure is developed to integrate different functions and terminals into a single tree/solution. The new approach can evolve solutions of variable depths to extract various numbers and types of features from the images. The new approach is examined on 12 different image classification tasks of varying difficulty and compared with a large number of effective algorithms. The results show that the new approach achieves better classification performance than most benchmark methods. The analysis of the evolved programs/solutions and the visualization of the learned features provide deep insights on the proposed approach.},
  archive      = {J_TEVC},
  author       = {Ying Bi and Bing Xue and Mengjie Zhang},
  doi          = {10.1109/TEVC.2020.3002229},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {87-101},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Genetic programming with image-related operators and a flexible program structure for feature learning in image classification},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Investigating the properties of indicators and an
evolutionary many-objective algorithm using promising regions.
<em>TEVC</em>, <em>25</em>(1), 75–86. (<a
href="https://doi.org/10.1109/TEVC.2020.2999100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates the properties of ratio and difference-based indicators under the Minkovsky distance and demonstrates that a ratio-based indicator with infinite norm is the best for solution evaluation among these indicators. Accordingly, a promising-region-based evolutionary many-objective algorithm with the ratio-based indicator is proposed. In our proposed algorithm, a promising region is identified in the objective space using the ratio-based indicator with infinite norm. Since the individuals outside the promising region are of poor quality, we can discard these solutions from the current population. To ensure the diversity of population, a strategy based on the parallel distance is introduced to select individuals in the promising region. In this strategy, all individuals in the promising region are projected vertically onto the normal plane so that crowded distances between them can be calculated. Afterward, two solutions with a smaller distance are selected from the candidate solutions each time, and the solution with the smaller indicator fitness value is removed from the current population. Empirical studies on various benchmark problems with 3-20 objectives show that the proposed algorithm performs competitively on all test problems. Compared with a number of other state-of-the-art evolutionary algorithms, the proposed algorithm is more robust on these problems with various Pareto fronts.},
  archive      = {J_TEVC},
  author       = {Jiawei Yuan and Hai-Lin Liu and Fangqing Gu and Qingfu Zhang and Zhaoshui He},
  doi          = {10.1109/TEVC.2020.2999100},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {75-86},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Investigating the properties of indicators and an evolutionary many-objective algorithm using promising regions},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning optimality theory for accuracy-based learning
classifier systems. <em>TEVC</em>, <em>25</em>(1), 61–74. (<a
href="https://doi.org/10.1109/TEVC.2020.2994314">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary computation has brought great progress to rule-based learning but this progress is often blind to the optimality of the system design. This article theoretically reveals an optimal learning scheme on the most popular evolutionary rule-based learning approach-the accuracy-based classifier system (or XCS). XCS seeks to form accurate, maximally general rules that together classify the state space of a given domain. Previously, setting up the system to perform well has been a “blackart” as no systematic approach to XCS parameter tuning existed. We derive a theoretical approach that mathematically guarantees that XCS identifies the accurate rules, which also returns a theoretically valid XCS parameter setting. Then, we demonstrate our theoretical setting derives the maximum correctness of rule-identification in the fewest iterations possible. We also experimentally show that our theoretical setting enables XCS to easily solve several challenging problems where it had previously struggled.},
  archive      = {J_TEVC},
  author       = {Masaya Nakata and Will N. Browne},
  doi          = {10.1109/TEVC.2020.2994314},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {61-74},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Learning optimality theory for accuracy-based learning classifier systems},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generating well-spaced points on a unit simplex for
evolutionary many-objective optimization. <em>TEVC</em>, <em>25</em>(1),
48–60. (<a href="https://doi.org/10.1109/TEVC.2020.2992387">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most evolutionary many-objective optimization (EMaO) algorithms start with a description of a number of the predefined set of reference points on a unit simplex. So far, most studies have used the Das and Dennis&#39;s structured approach for generating well-spaced reference points. Due to the highly structured nature of the procedure, this method cannot produce an arbitrary number of points, which is desired in an EMaO application. Although a layer-wise implementation has been suggested, EMO researchers always felt the need for a more generic approach. Motivated by earlier studies, we introduce a metric for defining well-spaced points on a unit simplex and propose a number of viable methods for generating such a set. We compare the proposed methods on a variety of performance metrics such as hypervolume (HV), deviation in triangularized simplices, distance of the closest point pair, and variance of the geometric means to nearest neighbors in up to 15-D spaces. We show that an iterative improvement based on Riesz s-energy is able to effectively find an arbitrary number of well-spaced points even in higher-dimensional spaces. Reference points created using the proposed Riesz s-energy method for a number of standard combinations of objectives and reference points as well as a source code written in Python are available publicly at https://www.egr.msu.edu/coinlab/blankjul/uniform.},
  archive      = {J_TEVC},
  author       = {Julian Blank and Kalyanmoy Deb and Yashesh Dhebar and Sunith Bandaru and Haitham Seada},
  doi          = {10.1109/TEVC.2020.2992387},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {48-60},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Generating well-spaced points on a unit simplex for evolutionary many-objective optimization},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A unified framework of graph-based evolutionary multitasking
hyper-heuristic. <em>TEVC</em>, <em>25</em>(1), 35–47. (<a
href="https://doi.org/10.1109/TEVC.2020.2991717">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent research, hyper-heuristics have attracted increasing attention in various fields. The most appealing feature of hyper-heuristics is that they aim to provide more generalized solutions to optimization problems by searching in a high-level space of heuristics instead of direct problem domains. Despite the promising findings in hyper-heuristics, the design of more general search methodologies still presents a key research. Evolutionary multitasking is a relatively new evolutionary paradigm which attempts to solve multiple optimization problems simultaneously. It exploits the underlying similarities among different optimization tasks by transferring information among them, thus accelerating the optimization of all tasks. Inherently, hyper-heuristics and evolutionary multitasking are similar in the following three ways: 1) they both operate on third-party search spaces; 2) high-level search methodologies are universal; and 3) they both conduct cross-domain optimization. To integrate their advantages effectively, i.e., the knowledge-transfer and cross-domain optimization of evolutionary multitasking and the search in the heuristic spaces of hyper-heuristics, in this article, a unified framework of evolutionary multitasking graph-based hyper-heuristic (EMHH) is proposed. To assess the generality and effectiveness of the EMHH, population-based graph-based hyper-heuristics integrated with evolutionary multitasking to solve exam timetabling and graph-coloring problems, separately and simultaneously, are studied. The experimental results demonstrate the effectiveness, efficiency, and increased the generality of the proposed unified framework compared with single-tasking hyper-heuristics.},
  archive      = {J_TEVC},
  author       = {Xingxing Hao and Rong Qu and Jing Liu},
  doi          = {10.1109/TEVC.2020.2991717},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {35-47},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A unified framework of graph-based evolutionary multitasking hyper-heuristic},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A grid-based inverted generational distance for
multi/many-objective optimization. <em>TEVC</em>, <em>25</em>(1), 21–34.
(<a href="https://doi.org/10.1109/TEVC.2020.2991040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assessing the performance of Pareto front (PF) approximations is a key issue in the field of evolutionary multi/many-objective optimization. Inverted generational distance (IGD) has been widely accepted as a performance indicator for evaluating the comprehensive quality for a PF approximation. However, IGD usually becomes infeasible when facing a real-world optimization problem as it needs to know the true PF a priori. In addition, the time complexity of IGD grows quadratically with the size of the solution/reference set. To address the aforementioned issues, a grid-based IGD (Grid-IGD) is proposed to estimate both convergence and diversity of PF approximations for multi/many-objective optimization. In Grid-IGD, a set of reference points is generated by estimating PFs of the problem in question, based on the representative nondominated solutions of all the approximations in a grid environment. To reduce the time complexity, Grid-IGD only considers the closest solution within the grid neighborhood in the approximation for every reference point. Grid-IGD also possesses other desirable properties, such as Pareto compliance, immunity to dominated/duplicate solutions, and no need of normalization. In the experimental studies, Grid-IGD is verified on both the artificial and real PF approximations obtained by five many-objective optimizers. Effects of the grid specification on the behavior of Grid-IGD are also discussed in detail theoretically and experimentally.},
  archive      = {J_TEVC},
  author       = {Xinye Cai and Yushun Xiao and Miqing Li and Han Hu and Hisao Ishibuchi and Xiaoping Li},
  doi          = {10.1109/TEVC.2020.2991040},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {21-34},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A grid-based inverted generational distance for Multi/Many-objective optimization},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on the hypervolume indicator in evolutionary
multiobjective optimization. <em>TEVC</em>, <em>25</em>(1), 1–20. (<a
href="https://doi.org/10.1109/TEVC.2020.3013290">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hypervolume is widely used as a performance indicator in the field of evolutionary multiobjective optimization (EMO). It is used not only for performance evaluation of EMO algorithms (EMOAs) but also in indicator-based EMOAs to guide the search. Since its initial proposal in the late 1990s, a wide variety of studies have been done on various topics, including hypervolume calculation, optimal μ-distribution, subset selection, hypervolume-based EMOAs, and extensions of the hypervolume indicator. However, currently there is no work to systematically survey the hypervolume indicator for these topics whereas it has been frequently used in the EMO field. This article aims to fill this gap and provide a comprehensive survey on the hypervolume indicator. We expect that this survey will help EMO researchers to understand the hypervolume indicator more deeply and thoroughly, and promote further utilization of the hypervolume indicator in the EMO field.},
  archive      = {J_TEVC},
  author       = {Ke Shang and Hisao Ishibuchi and Linjun He and Lie Meng Pang},
  doi          = {10.1109/TEVC.2020.3013290},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A survey on the hypervolume indicator in evolutionary multiobjective optimization},
  volume       = {25},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
