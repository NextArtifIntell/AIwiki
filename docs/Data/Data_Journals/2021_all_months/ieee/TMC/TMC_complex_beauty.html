<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TMC_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tmc---238">TMC - 238</h2>
<ul>
<li><details>
<summary>
(2021). STEP: A spatio-temporal fine-granular user traffic
prediction system for cellular networks. <em>TMC</em>, <em>20</em>(12),
3453–3466. (<a href="https://doi.org/10.1109/TMC.2020.3001225">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While traffic modeling and prediction are at the heart of providing high-quality telecommunication services in cellular networks and attract much attention, they have been approved as an extremely challenging task. Due to the diverse network demand of Internet-based apps, the cellular traffic from an individual user can have a wide dynamic range. Most existing methods, on the other hand, model traffic patterns as probabilistic distributions or stochastic processes and impose stringent assumptions over these models. Such assumptions may be beneficial at providing closed-form formula in evaluating prediction performances, but fall short for practice use. In this paper we propose STEP, a s patio- te mporal fine-granular user traffic p rediction mechanism for cellular networks. A deep graph convolution network, called GCGRN, is constructed. It is a novel combination of the graph convolution network (GCN) and gated recurrent units (GRU), which exploits graph neural network to learn an efficient spatio-temporal model from a user’s massive dataset for traffic prediction. The prototype of STEP has been implemented. Extensive experimental results demonstrate that our model outperforms the state-of-the-art time-series based approaches. Besides, STEP merely incurs mild energy consumption, communication overhead and system resource occupancy to mobile devices. Moreover, NS-3 based simulations validate the efficacy of STEP in reducing session dropping ratio in cellular networks.},
  archive      = {J_TMC},
  author       = {Lixing Yu and Ming Li and Wenqiang Jin and Yifan Guo and Qianlong Wang and Feng Yan and Pan Li},
  doi          = {10.1109/TMC.2020.3001225},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {3453-3466},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {STEP: A spatio-temporal fine-granular user traffic prediction system for cellular networks},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stable task assignment for mobile crowdsensing with budget
constraint. <em>TMC</em>, <em>20</em>(12), 3439–3452. (<a
href="https://doi.org/10.1109/TMC.2020.3000234">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In mobile crowdsensing, it is a challenge to assign tasks to appropriate smartphones. Existing task allocation mechanisms mainly aim at optimizing the global system performance, while ignoring the personal preferences of individual crowdsensing tasks and smartphone users. Nevertheless, in an open crowdsensing system, a task assignment is prone to be unstable if smartphone users or tasks have incentives to deviate from the global assignment, and seek for alternative choices to improve their own utilities. Besides that, during task competition, the rational smartphone users might choose to adjust their payments after the first few failures, which however, brings new challenges in achieving the stability. To address these issues, this paper constructs a distributed many-to-many matching model to capture the interaction between crowdsensing tasks and smartphone users, taking into account the budget constraints of tasks. Then, we design a stable matching algorithm to allocate the tasks to the users, and determine their payments. We prove that the proposed algorithm achieves several desirable properties including individual rationality, stability, and convergency. It is also proved that the proposed scheme achieves at least half of the optimal system efficiency when each smartphone provides homogeneous service quality. Finally, simulation results confirm the effectiveness of the proposed scheme.},
  archive      = {J_TMC},
  author       = {Chenxin Dai and Xiumin Wang and Kai Liu and Deyu Qi and Weiwei Lin and Pan Zhou},
  doi          = {10.1109/TMC.2020.3000234},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {3439-3452},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Stable task assignment for mobile crowdsensing with budget constraint},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Spatial and temporal contextual multi-armed bandit handovers
in ultra-dense mmWave cellular networks. <em>TMC</em>, <em>20</em>(12),
3423–3438. (<a href="https://doi.org/10.1109/TMC.2020.3000189">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although millimeter wave (mmWave) is a promising technology in 5G communication, its severe path attenuation and susceptibility to line-of-sight (LOS) blockage result in much more unpredictable outages than traditional technologies. This special propagation property raises a significant challenge to the mobility management in mmWave cellular networks. Since conventional handover policies purely rely on the measurement of signal strength, they would cause a large number of unnecessary handovers due to the frequent short-term LOS blockage by obstacles, imposing high signaling and energy overhead. In this paper, we propose two novel handover mechanisms to reduce unnecessary handovers by carefully deciding the next base station (BS) a user should handover to, so that the new user-BS connection after the handover can last as long as possible. Without prior knowledge of user’s mobility and environment, the proposed handover mechanisms exploit the empirical distribution of user’s post-handover trajectory and LOS blockage, learned online through a multi-armed bandit (MAB) framework. Depending on the contexts extracted from RSS information, two different MAB problems for handover are formulated, which focus on spatial and space-time contexts, respectively, The results of numerical simulations demonstrate that the proposed contextual handover mechanisms significantly outperform existing counterparts on reducing handovers in all simulated scenarios.},
  archive      = {J_TMC},
  author       = {Li Sun and Jing Hou and Tao Shu},
  doi          = {10.1109/TMC.2020.3000189},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {3423-3438},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Spatial and temporal contextual multi-armed bandit handovers in ultra-dense mmWave cellular networks},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Service provisioning framework for RAN slicing: User
admissibility, slice association and bandwidth allocation. <em>TMC</em>,
<em>20</em>(12), 3409–3422. (<a
href="https://doi.org/10.1109/TMC.2020.3000657">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network slicing (NS) has been identified as one of the most promising architectural technologies for future mobile network systems to meet the extremely diversified service requirements of users. In radio access networks (RAN) slicing, service provisioning for slice users becomes much more complicated than that in traditional mobile networks, as the constraints of both user physical association with base station (BS) and logical association with NS should be considered. In other words, the user-BS-NS three layer association relationship should be addressed in provisioning tailored service for diversified use cases with various quality of service (QoS) requirements. Therefore, service provisioning in RAN slicing becomes an essential yet challenging issue for 5G and beyond systems. In this paper, we propose a unified framework for service provisioning in RAN slicing with aim of maximizing resource utilization while guaranteeing QoS of users. The framework consists of two steps. The first step is to identify a set of slice users whose QoS can be satisfied simultaneously; while the second step performs joint slice association and bandwidth allocation with aim to minimize bandwidth consumption. Numerical results show that in typical scenarios, our proposed service provisioning framework can achieve significant performance gain in terms of the number of serving users and wireless bandwidth utilization compared with traditional schemes.},
  archive      = {J_TMC},
  author       = {Yao Sun and Shuang Qin and Gang Feng and Lei Zhang and Muhammad Ali Imran},
  doi          = {10.1109/TMC.2020.3000657},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {3409-3422},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Service provisioning framework for RAN slicing: User admissibility, slice association and bandwidth allocation},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). QoE based revenue maximizing dynamic resource allocation and
pricing for fog-enabled mission-critical IoT applications. <em>TMC</em>,
<em>20</em>(12), 3395–3408. (<a
href="https://doi.org/10.1109/TMC.2020.2999895">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fog computing is becoming a vital component for Internet of things (IoT) applications, acting as its computational engine. Mission-critical IoT applications are highly sensitive to latency, which depends on the physical location of the cloud server. Fog nodes of varying response rates are available to the cloud service provider (CSP) and it is faced with a challenge of forwarding the sequentially received IoT data to one of the fog nodes for processing. Since the arrival times and nature of requests is random, it is important to optimally classify the requests in real-time and allocate available virtual machine instances (VMIs) at the fog nodes to provide a high QoE to the users and consequently generate higher revenues for the CSP. In this paper, we use a pricing policy based on the QoE of the applications as a result of the allocation and obtain an optimal dynamic allocation rule based on the statistical information of the computational requests. The developed solution is statistically optimal, dynamic, and implementable in real-time as opposed to other static matching schemes in the literature. The performance of the proposed framework has been evaluated using simulations and the results show significant improvement as compared with benchmark schemes.},
  archive      = {J_TMC},
  author       = {Muhammad Junaid Farooq and Quanyan Zhu},
  doi          = {10.1109/TMC.2020.2999895},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {3395-3408},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {QoE based revenue maximizing dynamic resource allocation and pricing for fog-enabled mission-critical IoT applications},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-band time of arrival estimation for long term
evolution (LTE) signals. <em>TMC</em>, <em>20</em>(12), 3383–3394. (<a
href="https://doi.org/10.1109/TMC.2020.3000105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a method for estimating the time of arrival (ToA) of long term evolution (LTE) signals received on multiple separate transmission bands by the same base station (BS) mast. By exploiting the overall bandwidth occupied by the different signals and the correlation between the corresponding channel impulse responses, a higher precision is achieved with respect to the usually adopted single-band approach whenever the time-correlation among the bands is sufficiently high. The ToA estimation is carried out by generalizing the space-alternating generalized expectation-maximization (SAGE) algorithm to the multi-band context, proving that the availability of multiple bands provides a reduced standard deviation for the estimated ToA, with a limited increase of the computational cost. The main analyzed issue consists in the management of the asynchrony between transmitters belonging to distinct cellular operators, which is addressed by developing a suitable method to combine the contributions provided by the different bands. The method is validated by simulations in dual- and tri-band scenarios, and is further applied to real dual-band signals measured through a portable setup and experimentally acquired from an LTE BS mast covering multiple cells.},
  archive      = {J_TMC},
  author       = {Matteo Noschese and Fulvio Babich and Massimiliano Comisso and Chris Marshall},
  doi          = {10.1109/TMC.2020.3000105},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {3383-3394},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Multi-band time of arrival estimation for long term evolution (LTE) signals},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Machine learning at the edge: A data-driven architecture
with applications to 5G cellular networks. <em>TMC</em>,
<em>20</em>(12), 3367–3382. (<a
href="https://doi.org/10.1109/TMC.2020.2999852">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fifth generation of cellular networks (5G) will rely on edge cloud deployments to satisfy the ultra-low latency demand of future applications. In this paper, we argue that such deployments can also be used to enable advanced data-driven and Machine Learning (ML) applications in mobile networks. We propose an edge-controller-based architecture for cellular networks and evaluate its performance with real data from hundreds of base stations of a major U.S. operator. In this regard, we will provide insights on how to dynamically cluster and associate base stations and controllers, according to the global mobility patterns of the users. Then, we will describe how the controllers can be used to run ML algorithms to predict the number of users in each base station, and a use case in which these predictions are exploited by a higher-layer application to route vehicular traffic according to network Key Performance Indicators (KPIs). We show that the prediction accuracy improves when based on machine learning algorithms that rely on the controllers’ view and, consequently, on the spatial correlation introduced by the user mobility, with respect to when the prediction is based only on the local data of each single base station.},
  archive      = {J_TMC},
  author       = {Michele Polese and Rittwik Jana and Velin Kounev and Ke Zhang and Supratim Deb and Michele Zorzi},
  doi          = {10.1109/TMC.2020.2999852},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {3367-3382},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Machine learning at the edge: A data-driven architecture with applications to 5G cellular networks},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ITAM: Bilateral privacy-preserving task assignment for
mobile crowdsensing. <em>TMC</em>, <em>20</em>(12), 3351–3366. (<a
href="https://doi.org/10.1109/TMC.2020.2999923">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The minimum travel distance of task participants is one of the significant optimization objectives of privacy-preserving task assignment in mobile crowdsensing (MCS). However, when the travel distance is minimized, most of the previous schemes only focus on the task participant privacy and disregard the task requester privacy. Moreover, existing solutions usually only support the constraint of a single type, such as equality constraints or range constraints. In this paper, we propose a bilateral privacy-preserving Task Assignment mechanism for MCS (iTAM), which protects not only the task participants privacy but also the task requesters privacy and can minimize the travel distance. Furthermore, iTAM provides both equality and range constraints of task assignment by utilizing the Paillier cryptosystem. To accommodate the multiple relations between the task participants and the task, we propose the single/multiple task participants selection problems for a task requiring task participants to compete and cooperate. Experimental evaluations over synthetic and real-world data illustrate that iTAM is feasible and effective. Compared with the state-of-the-art, iTAM positively solves the optimal problem of travel distance. The complexities of iTAM are &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mathcal {O}(n)$&lt;/tex-math&gt;&lt;/inline-formula&gt; and &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mathcal {O}(n\log n)$&lt;/tex-math&gt;&lt;/inline-formula&gt; for a single and multiple task participants selection problems, respectively.},
  archive      = {J_TMC},
  author       = {Bowen Zhao and Shaohua Tang and Ximeng Liu and Xinglin Zhang and Wei-Neng Chen},
  doi          = {10.1109/TMC.2020.2999923},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {3351-3366},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {ITAM: Bilateral privacy-preserving task assignment for mobile crowdsensing},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hybrid OFDMA random access with resource unit sensing for
next-gen 802.11ax WLANs. <em>TMC</em>, <em>20</em>(12), 3338–3350. (<a
href="https://doi.org/10.1109/TMC.2020.3000503">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IEEE 802.11ax partitions a regular 20MHz channel into smaller sub-channels called resource units to support simultaneous multiuser operation using orthogonal frequency division multiple access (OFDMA). Uplink OFDMA random access (UORA) in IEEE 802.11ax allows stations to transmit via a scheduled random access mechanism. UORA is initiated via a trigger frame which aside from serving as a synchronization mechanism, also informs stations which resource units are allowed for random access. Using the trigger frame information, the stations engage in an OFDMA backoff process to win access to a resource unit. Similar to slotted ALOHA, the maximum normalized throughput of UORA is only 37 percent due to high probability of collisions at high loads. To reduce collisions, we equip UORA with carrier sensing capability resulting in a new uplink hybrid UORA (H-UORA) OFDMA access mechanism. Unlike other multi-carrier CSMA methods previously proposed in literature, H-UORA is an easily implementable modification to current 802.11ax WLANs. We show that H-UORA can achieve a normalized throughput of at least 80 percent (which increases further depending on the buffering capabilities of the access point) using various numerical analysis and simulations.},
  archive      = {J_TMC},
  author       = {Leonardo Lanante and Chittabrata Ghosh and Sumit Roy},
  doi          = {10.1109/TMC.2020.3000503},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {3338-3350},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Hybrid OFDMA random access with resource unit sensing for next-gen 802.11ax WLANs},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Device vs edge computing for mobile services: Delay-aware
decision making to minimize power consumption. <em>TMC</em>,
<em>20</em>(12), 3324–3337. (<a
href="https://doi.org/10.1109/TMC.2020.2999784">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A promising technique to provide mobile applications with high computation resources is to offload the processing task to the cloud. Utilizing the abundant processing capabilities of the clouds, mobile edge computing enables mobile devices with limited batteries to run resource hungry applications and to save power. However, it is not always true that edge computing consumes less power compared to device computing. It may take more power for the mobile device to transmit a file to the cloud than running the task itself. This paper investigates the power minimization problem for the mobile devices by data offloading in multi-cell multi-user OFDMA mobile edge computing networks. We consider the maximum acceptable delay as QoS metric to be satisfied in our network. We formulate the problem as a mixed integer nonlinear problem which is converted into a convex form using D.C. approximation. To solve the converted optimization problem, we have proposed centralized and distributed algorithms for joint power allocation and channel assignment together with decision-making. Simulation results illustrate that by utilizing the proposed algorithms, considerable power savings can be achieved, e.g., about 60 percent for large bit stream size compared to local computing baseline.},
  archive      = {J_TMC},
  author       = {Meysam Masoudi and Cicek Cavdar},
  doi          = {10.1109/TMC.2020.2999784},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {3324-3337},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Device vs edge computing for mobile services: Delay-aware decision making to minimize power consumption},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DEFT: Multipath TCP for high speed low latency
communications in 5G networks. <em>TMC</em>, <em>20</em>(12), 3311–3323.
(<a href="https://doi.org/10.1109/TMC.2020.3000041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multipath TCP (MPTCP) is a promising solution that can provide high end-to-end throughput in fifth generation (5G) mobile networks. Many next-generation applications will require high throughput and low latency simultaneously, but the current MPTCP congestion control algorithms cannot reliably satisfy this requirement. In this paper, a novel MPTCP congestion control scheme named delay-equalized FAST (DEFT) is proposed to achieve high throughput and low end-to-end (E2E) delay in 5G networks. First, in order to achieve high throughput, DEFT includes a novel window control algorithm that shows fast responsiveness when the state of the millimeter-wave (mmWave) link changes from line-of-sight (LOS) to non-LOS (NLOS) and vice versa. Second, in order to achieve low E2E delay, DEFT includes a delay-equalizing algorithm which minimizes additional reordering delay in the receive buffer. The performance of DEFT was evaluated based on ns-3 simulation and was compared with wVegas, Balia, and delay-adapted LIA. Simulation results show that DEFT can provide a significant goodput gain and application-level E2E delay reduction for the range of interest.},
  archive      = {J_TMC},
  author       = {Changsung Lee and Jaewook Jung and Jong-Moon Chung},
  doi          = {10.1109/TMC.2020.3000041},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {3311-3323},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {DEFT: Multipath TCP for high speed low latency communications in 5G networks},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). BaG: Behavior-aware group detection in crowded urban spaces
using WiFi probes. <em>TMC</em>, <em>20</em>(12), 3298–3310. (<a
href="https://doi.org/10.1109/TMC.2020.2999491">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Group detection is gaining popularity as it enables variousXzX applications ranging from marketing to urban planning. Existing methods use received signal strength indicator (RSSI) to detect co-located people as groups. However, this approach might have difficulties in crowded urban spaces since many strangers with similar mobility patterns could be identified as groups. Moreover, RSSI is vulnerable to many factors like the human body attenuation and thus is unreliable in crowded scenarios. In this work, we propose a behavior-aware group detection system (BaG). BaG fuses people’s mobility information and smartphone usage behaviors. We observe that people in a group tend to have similar phone usage patterns. Those patterns could be effectively captured by the proposed feature: number of bursts (NoB). Unlike RSSI, NoB is more resilient to environmental changes as it only cares about receiving packets or not. Besides, both mobility and usage patterns correspond to the same underlying grouping information. We propose a detection method based on collective matrix factorization to reveal the hidden associations by factorizing mobility information and usage patterns simultaneously. Experimental results indicate BaG outperforms baseline approaches by &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$3.97\% \sim 15.79\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; in F-score. The proposed system could also achieve robust and reliable performance in scenarios with different levels of crowdedness.},
  archive      = {J_TMC},
  author       = {Jiaxing Shen and Jiannong Cao and Xuefeng Liu},
  doi          = {10.1109/TMC.2020.2999491},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {3298-3310},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {BaG: Behavior-aware group detection in crowded urban spaces using WiFi probes},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AdaDeep: A usage-driven, automated deep model compression
framework for enabling ubiquitous intelligent mobiles. <em>TMC</em>,
<em>20</em>(12), 3282–3297. (<a
href="https://doi.org/10.1109/TMC.2020.2999956">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent breakthroughs in deep neural networks (DNNs) have fueled a tremendously growing demand for bringing DNN-powered intelligence into mobile platforms. While the potential of deploying DNNs on resource-constrained platforms has been demonstrated by DNN compression techniques, the current practice suffers from two limitations: 1) merely stand-alone compression schemes are investigated even though each compression technique only suit for certain types of DNN layers; and 2) mostly compression techniques are optimized for DNNs’ inference accuracy, without explicitly considering other application-driven system performance (e.g., latency and energy cost) and the varying resource availability across platforms (e.g., storage and processing capability). To this end, we propose AdaDeep, a usage-driven, automated DNN compression framework for systematically exploring the desired trade-off between performance and resource constraints, from a holistic system level. Specifically, in a layer-wise manner, AdaDeep automatically selects the most suitable combination of compression techniques and the corresponding compression hyperparameters for a given DNN. Thorough evaluations on six datasets and across twelve devices demonstrate that &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;${\sf AdaDeep}$&lt;/tex-math&gt;&lt;/inline-formula&gt; can achieve up to &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$18.6\times$&lt;/tex-math&gt;&lt;/inline-formula&gt; latency reduction, &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$9.8\times$&lt;/tex-math&gt;&lt;/inline-formula&gt; energy-efficiency improvement, and &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$37.3\times$&lt;/tex-math&gt;&lt;/inline-formula&gt; storage reduction in DNNs while incurring negligible accuracy loss. Furthermore, &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;${\sf AdaDeep}$&lt;/tex-math&gt;&lt;/inline-formula&gt; also uncovers multiple novel combinations of compression techniques.},
  archive      = {J_TMC},
  author       = {Sicong Liu and Junzhao Du and Kaiming Nan and Zimu Zhou and Hui Liu and Zhangyang Wang and Yingyan Lin},
  doi          = {10.1109/TMC.2020.2999956},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {3282-3297},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {AdaDeep: A usage-driven, automated deep model compression framework for enabling ubiquitous intelligent mobiles},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Low-complexity learning for dynamic spectrum access in
multi-user multi-channel networks. <em>TMC</em>, <em>20</em>(11),
3267–3281. (<a href="https://doi.org/10.1109/TMC.2020.2999075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In cognitive radio networks (CRNs), dynamic spectrum access allows (unlicensed) users to identify and access unused channels opportunistically, thus improves spectrum utilization. In this paper, we address the user-channel allocation problem in multi-user multi-channel CRNs without a prior knowledge of channel statistics. The result of channel access is stochastic with unknown distribution, and statistically different for each user. In deciding the channel for access, a user needs to either explore a channel to learn its statistics, or exploit the channel with the highest expected reward based on the information collected so far. Further, a channel should be accessed exclusively by one user at a time to avoid collision. Using multi-armed bandit framework, we develop two rate-optimal algorithms with low computational complexities of &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$O(N)$&lt;/tex-math&gt;&lt;/inline-formula&gt; and &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$O(NK)$&lt;/tex-math&gt;&lt;/inline-formula&gt; , respectively, where &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$N$&lt;/tex-math&gt;&lt;/inline-formula&gt; denotes the number of users and &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$K$&lt;/tex-math&gt;&lt;/inline-formula&gt; denotes the number of channels. Further, we extend the results and develop an algorithm that is amenable to implement in a distributed fashion.},
  archive      = {J_TMC},
  author       = {Sunjung Kang and Changhee Joo},
  doi          = {10.1109/TMC.2020.2999075},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {3267-3281},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Low-complexity learning for dynamic spectrum access in multi-user multi-channel networks},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust video broadcast for users with heterogeneous
resolution in mobile networks. <em>TMC</em>, <em>20</em>(11), 3251–3266.
(<a href="https://doi.org/10.1109/TMC.2020.2999195">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, robust video transmission system that can eliminate the cliff effect in digital video transmission has attracted great interest from both academia and industry. By linearizing the whole system, robust video transmission is intrinsically scalable to channel conditions in mobile networks. However, the heterogeneity of user devices in terms of viewing resolution has not been well studied for robust video broadcast systems. In this paper, we propose a spatial scalability enabled robust video broadcast (SSRVB) system, aiming at accommodating diverse users with both heterogeneous resolutions and heterogeneous channel conditions. In SSRVB, a novel spatial decomposition method based on linear projection is first designed for robust video transmission. Then the transmission distortion minimization problem with joint subcarrier matching and power allocation is formulated. A near-optimal low-complexity subcarrier matching algorithm based on auction theory and an optimal power allocation strategy are also proposed. Furthermore, an iterative algorithm is designed to solve the problem of joint resource allocation. Simulation results demonstrate that SSRVB can achieve an average of 3 dB gain when compared with the reference schemes (i.e., ECast, MCast, discrete wavelet transform (DWT) based scheme, and scalable video coding (SVC) scheme) in terms of average peak signal-to-noise ratio under heterogeneous scenarios.},
  archive      = {J_TMC},
  author       = {Yongqiang Gui and Hancheng Lu and Feng Wu and Chang Wen Chen},
  doi          = {10.1109/TMC.2020.2999195},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {3251-3266},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Robust video broadcast for users with heterogeneous resolution in mobile networks},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The paintbrush coverage problem. <em>TMC</em>,
<em>20</em>(11), 3239–3250. (<a
href="https://doi.org/10.1109/TMC.2020.2998406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous vehicles become more and more popular in our daily life. Mobile computing schemes to be installed on these vehicles have drawn a lot of recent research interest. In this paper, we address the important path-planning problem for autonomous vehicles. We introduce and formulate the novel paintbrush coverage problem . We present a theoretical study on the minimum trajectory length of a paintbrush to cover an arbitrary convex region, which is derived as a function of the area of the region and the size of the cover. Three commonly-used patrolling/scouting methods, namely boustrophedon, spiral, and sector, are manifested in details as the potential solutions to the paintbrush coverage problem. The theoretical minimum trajectory lengths any algorithm can achieve are also demonstrated as the benchmarks for different shapes of regions.},
  archive      = {J_TMC},
  author       = {Scott C.-H. Huang and Elaine Y.-N. Sun and Hsiao-Chun Wu and Costas Busch},
  doi          = {10.1109/TMC.2020.2998406},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {3239-3250},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {The paintbrush coverage problem},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). RF-pen: Practical real-time RFID tracking in the air.
<em>TMC</em>, <em>20</em>(11), 3227–3238. (<a
href="https://doi.org/10.1109/TMC.2020.2997080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless tracing technologies have seen great potentials in many applications, including drawing and writing, gesture-based commanding, and gaming. Many state-of-the-art systems have recently been proposed along this line. However, none of them can strike a balance among hardware complexity, time delay, and accuracy in real-world scenarios. In this paper, we propose RF-Pen, a practical and complete RFID tracking system that achieves centimeter-level real-time tracing with 4 antennas. To do so, RF-Pen mainly employs two key designs, namely selective hologram and hybrid voting. Our selective hologram places antennas in large separation, which not only expedites the tracking process by producing a handful of good-quality candidate points but also maximizes tracing resolution. Nevertheless, a big challenge is ambiguity. To address this, we introduce hybrid voting that effectively integrates RSSI and phase measurements to evaluate the likelihood of all candidate points. This way, a precise initial position and fine-resolution tracing beams are located. We implement RF-Pen using off-the-shelf readers and tags and compare it against state-of-the-art systems. Results show that with a single reader of 4 antennas, RF-pen achieves a median trajectory error of 2.15 cm and a median position error of 12.8 cm, which are &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$3.7\times$&lt;/tex-math&gt;&lt;/inline-formula&gt; and &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$4.1\times$&lt;/tex-math&gt;&lt;/inline-formula&gt; better than RF-IDraw, respectively.},
  archive      = {J_TMC},
  author       = {Haoyu Wang and Wei Gong},
  doi          = {10.1109/TMC.2020.2997080},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {3227-3238},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {RF-pen: Practical real-time RFID tracking in the air},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On heterogeneous sensing capability for distributed
rendezvous in cognitive radio networks. <em>TMC</em>, <em>20</em>(11),
3211–3226. (<a href="https://doi.org/10.1109/TMC.2020.2997077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cognitive radio networks (CRNs) have been proposed to solve the spectrum scarcity problem. One of their fundamental procedures is to construct a communication link on a common channel for the users, which is referred to as rendezvous . In reality, the capability to sense the spectrum may vary from user to user. We study distributed rendezvous for heterogeneous sensing capabilities in this paper. The licensed spectrum is divided into &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$n$&lt;/tex-math&gt;&lt;/inline-formula&gt; channels, &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$U = \lbrace 1,2,\ldots,n\rbrace$&lt;/tex-math&gt;&lt;/inline-formula&gt; . We denote the sensing capability of user &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$i$&lt;/tex-math&gt;&lt;/inline-formula&gt; as &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$C_i \subseteq U$&lt;/tex-math&gt;&lt;/inline-formula&gt; and the set of available channels (i.e., the channels not occupied by paying users) as &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$V_i \subseteq C_i$&lt;/tex-math&gt;&lt;/inline-formula&gt; . Due to hardware differences, the users may have different sensing capabilities: &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$C_i \ne C_j$&lt;/tex-math&gt;&lt;/inline-formula&gt; , and this is called heterogeneous sensing capability . In this paper, we propose efficient algorithms for two scenarios: the fully available scenario where &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$V_i = C_i$&lt;/tex-math&gt;&lt;/inline-formula&gt; and the partially available scenario where &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$V_i \subseteq C_i$&lt;/tex-math&gt;&lt;/inline-formula&gt; . Our idea is to utilize two ‘pointers’ to traverse the sensing capability set, which sets our algorithms apart from the extant rendezvous algorithms. Considering any two neighboring users &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$a, b$&lt;/tex-math&gt;&lt;/inline-formula&gt; , we propose the Traversing Pointer (TP) algorithm that guarantees rendezvous in &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$O(\max \lbrace |C_a|,|C_b|\rbrace \log \log n)$&lt;/tex-math&gt;&lt;/inline-formula&gt; time slots for the fully available scenario. This result is only &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$O(\log \log n)$&lt;/tex-math&gt;&lt;/inline-formula&gt; larger than the theoretical lower bound. Moreover, it removes an &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$O(\min \lbrace |C_a|,|C_b|\rbrace)$&lt;/tex-math&gt;&lt;/inline-formula&gt; factor when compared to the state-of-the-art result ( &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$O(|C_a||C_b|)$&lt;/tex-math&gt;&lt;/inline-formula&gt; in S.-H. Wu et al. For the partially available scenario, we propose the Moving Traversing Pointers (MTP) and Prime based Moving Traversing Pointers (P-MTP) algorithms that can guarantee rendezvous within &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$O((\max \lbrace |V_a|,|V_b|\rbrace)^2\log \log n)$&lt;/tex-math&gt;&lt;/inline-formula&gt; and &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$O(|V_a||V_b|\log \log n)$&lt;/tex-math&gt;&lt;/inline-formula&gt; time slots respectively, where the latter one combines the pointers and a common technique of plugging in a prime number. The proposed algorithms work more efficiently than the previous best result ( &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$O(|C_a||C_b|)$&lt;/tex-math&gt;&lt;/inline-formula&gt; in C.-C. Wu et al. under various circumstances. We also conduct extensive simulations and the results corroborate our analyses.},
  archive      = {J_TMC},
  author       = {Zhaoquan Gu and Yuexuan Wang and Tong Shen and Francis C.M. Lau},
  doi          = {10.1109/TMC.2020.2997077},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {3211-3226},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {On heterogeneous sensing capability for distributed rendezvous in cognitive radio networks},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). QoS-based budget constrained stable task assignment in
mobile crowdsensing. <em>TMC</em>, <em>20</em>(11), 3194–3210. (<a
href="https://doi.org/10.1109/TMC.2020.2997280">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the key problems in mobile crowdsensing (MCS) systems is the assignment of tasks to users. Most of the existing work aim to maximize a predefined system utility (e.g., quality of service or sensing), however, users (i.e., task requesters and performers/workers) may value different parameters and hence find an assignment unsatisfying if it is produced disregarding these parameters that define their preferences. While several studies utilize incentive mechanisms to motivate user participation in different ways, they do not take individual user preferences into account either. To address this issue, we leverage Stable Matching Theory which can help obtain a satisfying matching between two groups of entities based on their preferences. However, the existing approaches to find stable matchings do not work in MCS systems due to the many-to-one nature of task assignments and the budget constraints of task requesters. Thus, we first define two different stability conditions for user happiness in MCS systems. Then, we propose three efficient stable task assignment algorithms and discuss their stability guarantees in four different MCS scenarios. Finally, we evaluate the performance of the proposed algorithms through extensive simulations using a real dataset, and show that they outperform the state-of-the-art solutions.},
  archive      = {J_TMC},
  author       = {Fatih Yucel and Murat Yuksel and Eyuphan Bulut},
  doi          = {10.1109/TMC.2020.2997280},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {3194-3210},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {QoS-based budget constrained stable task assignment in mobile crowdsensing},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fog computing empowered data dissemination in software
defined heterogeneous VANETs. <em>TMC</em>, <em>20</em>(11), 3181–3193.
(<a href="https://doi.org/10.1109/TMC.2020.2997460">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper makes the first effort on proposing a fog computing empowered architecture together with a dedicated scheduling algorithm for data dissemination in software defined heterogeneous vehicular ad-hoc networks (VANETs). Specifically, the architecture supports both the logically centralized control via the cloud node in the core network and the distributed data dissemination via the fog nodes at the network edge. A problem called fog assisted cooperative service (FACS) is formulated, which takes network coding and vehicular caching into consideration, and aims at minimizing the overall service delay via the cooperation of vehicle-to-cloud (V2C), vehicle-to-fog (V2F) and vehicle-to-vehicle (V2V) communications. Further, we derive an equivalence problem of FACS and prove that FACS is NP-hard. On this basis, we propose a Clique Searching based Scheduling (CSS) algorithm at the SDN controller, which considers the heterogeneous communication interfaces and vehicle mobility in scheduling, and enables the collaborative data encoding and transmission among the cloud, fog nodes and vehicles. The complexity analysis demonstrates the feasibility of the proposed algorithm. Finally, we build the simulation model and give a comprehensive performance evaluation based on real vehicular trajectories extracted from different time and space. The simulation results conclusively demonstrate the superiority of the proposed solution.},
  archive      = {J_TMC},
  author       = {Kai Liu and Ke Xiao and Penglin Dai and Victor C.S. Lee and Songtao Guo and Jiannong Cao},
  doi          = {10.1109/TMC.2020.2997460},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {3181-3193},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Fog computing empowered data dissemination in software defined heterogeneous VANETs},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Charging task scheduling for directional wireless charger
networks. <em>TMC</em>, <em>20</em>(11), 3163–3180. (<a
href="https://doi.org/10.1109/TMC.2020.2997602">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the problem of c H arging t A sk S cheduling for direc T ional wireless charg E r networks (HASTE), i.e., given a set of rotatable directional wireless chargers on a 2D area and a series of offline (online) charging tasks, scheduling the orientations of all the chargers with time in a centralized offline (distributed online) fashion to maximize the overall charging utility for all the tasks. We prove that HASTE is NP-hard. Then, we prove that a relaxed version of HASTE falls within the realm of maximizing a submodular function subject to a partition matroid constraint, and propose a centralized offline algorithm that achieves &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$(1-\rho)(1-\frac{1}{e})$&lt;/tex-math&gt;&lt;/inline-formula&gt; approximation ratio to address HASTE where &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\rho$&lt;/tex-math&gt;&lt;/inline-formula&gt; is the switching delay of chargers. Further, we propose a distributed online algorithm and prove it achieves &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\frac{1}{2}(1-\rho)(1-\frac{1}{e})$&lt;/tex-math&gt;&lt;/inline-formula&gt; competitive ratio. We conduct simulations and field experiments on a testbed consisting of eight off-the-shelf power transmitters and 8 rechargeable sensor nodes. The results show that our distributed online algorithm achieves 92.97 percent of the optimal charging utility, and outperforms the comparison algorithms by up to 15.28 percent in terms of charging utility.},
  archive      = {J_TMC},
  author       = {Haipeng Dai and Ke Sun and Alex X. Liu and Lijun Zhang and Jiaqi Zheng and Guihai Chen},
  doi          = {10.1109/TMC.2020.2997602},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {3163-3180},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Charging task scheduling for directional wireless charger networks},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Continuous authentication through finger gesture interaction
for smart homes using WiFi. <em>TMC</em>, <em>20</em>(11), 3148–3162.
(<a href="https://doi.org/10.1109/TMC.2020.2994955">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of smart homes has advanced the concept of user authentication to not only protecting user privacy but also facilitating personalized services to users. Along this direction, we propose to integrate user authentication with human-computer interactions between users and smart household appliances through widely-deployed WiFi infrastructures, which is non-intrusive and device-free. In this paper, we propose &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$FingerPass$&lt;/tex-math&gt;&lt;/inline-formula&gt; which leverages channel state information (CSI) of surrounding WiFi signals to continuously authenticate users through finger gestures in smart homes. &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$FingerPass$&lt;/tex-math&gt;&lt;/inline-formula&gt; separates the user authentication process into two stages, login and interaction, to achieve high authentication accuracy and low response latency simultaneously. In the login stage, we develop a deep learning-based approach to extract behavioral characteristics of finger gestures for highly accurate user identification. For the interaction stage, to provide continuous authentication in real time for satisfactory user experience, we design a verification mechanism with lightweight classifiers to continuously authenticate the user’s identity during each interaction of finger gestures. Experiments in real environments show that &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$FingerPass$&lt;/tex-math&gt;&lt;/inline-formula&gt; can achieve the authentication accuracies of 90.6 percent under in-domain scenarios and 87.6 percent under cross-domain scenarios, as well as &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$186.6\;ms$&lt;/tex-math&gt;&lt;/inline-formula&gt; response time during interactions.},
  archive      = {J_TMC},
  author       = {Hao Kong and Li Lu and Jiadi Yu and Yingying Chen and Feilong Tang},
  doi          = {10.1109/TMC.2020.2994955},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {3148-3162},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Continuous authentication through finger gesture interaction for smart homes using WiFi},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The untold secrets of WiFi-calling services:
Vulnerabilities, attacks, and countermeasures. <em>TMC</em>,
<em>20</em>(11), 3131–3147. (<a
href="https://doi.org/10.1109/TMC.2020.2995509">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since 2016, all of four major U.S. operators have rolled out Wi-Fi calling services. They enable mobile users to place cellular calls over Wi-Fi networks based on the 3GPP IMS technology. Compared with conventional cellular voice solutions, the major difference lies in that their traffic traverses untrusted Wi-Fi networks and the Internet. This exposure to insecure networks can cause the Wi-Fi calling users to suffer from security threats. Its security mechanisms are similar to the VoLTE, because both of them are supported by the IMS. They include SIM-based security, 3GPP AKA, IPSec, etc. However, are they sufficient to secure Wi-Fi calling services? Unfortunately, our study yields a negative answer. We conduct the first security study on the operational Wi-Fi calling services in three major U.S. operators networks using commodity devices. We disclose that current Wi-Fi calling security is not bullet-proof and uncover three vulnerabilities. By exploiting the vulnerabilities, we devise two proof-of-concept attacks: telephony harassment or denial of voice service and user privacy leakage; both of them can bypass the existing security defenses. We have confirmed their feasibility using real-world experiments, as well as assessed their potential damages and proposed a solution to address all identified vulnerabilities.},
  archive      = {J_TMC},
  author       = {Tian Xie and Guan-Hua Tu and Bangjie Yin and Chi-Yu Li and Chunyi Peng and Mi Zhang and Hui Liu and Xiaoming Liu},
  doi          = {10.1109/TMC.2020.2995509},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {3131-3147},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {The untold secrets of WiFi-calling services: Vulnerabilities, attacks, and countermeasures},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Operation state scheduling towards optimal network utility
in RF-powered internet of things. <em>TMC</em>, <em>20</em>(11),
3117–3130. (<a href="https://doi.org/10.1109/TMC.2020.2995256">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RF power transfer is becoming a reliable solution to energy supplement of Internet of Things (IoT) in recent years, thanks to the emerging off-the-shelf wireless charging and sensing platforms. However, as a core component of IoT, sensor nodes mounted with these platforms can not work and harvest energy simultaneously, due to the low-manufacture-cost requirement. This leads to a new design challenge of optimally scheduling sensor nodes’ operation states: working or recharging, to achieve a desirable network utility. In our design, we first consider a single-hop special case of small-scale networks. We transform the operation state scheduling problem into a linear programming problem, and obtain an optimal analytical solution. Then a general case of large-scale multi-hop networks is investigated. The multi-hop operation state scheduling problem is proved to be NP-hard. We show that the spatiotemporal coupling caused by time-varying network topology makes the problem quite challenging. Based on Lyapunov optimization technique, we design a State Scheduling Algorithm (SSA) with a proved performance guarantee. Our algorithm decouples the primal problem by defining a dynamic energy threshold vector, which successfully schedules each sensor node to the desirable state according to its energy level. To verify our design, the SSA is implemented on a Powercast wireless charging and sensing testbed, achieving about 85 percent of the theoretical optimal with quite low time complexity. Furthermore, numerous simulation results demonstrate that the SSA outperforms the baseline algorithms and achieves good performance under different network settings.},
  archive      = {J_TMC},
  author       = {Songyuan Li and Shibo He and Kang Hu and Lingkun Fu and Shuo Chen and Jiming Chen},
  doi          = {10.1109/TMC.2020.2995256},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {3117-3130},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Operation state scheduling towards optimal network utility in RF-powered internet of things},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multi-trip task assignment for early target inspection in
squads of aerial drones. <em>TMC</em>, <em>20</em>(11), 3099–3116. (<a
href="https://doi.org/10.1109/TMC.2020.2994529">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fleets of cooperative drones are a powerful tool in monitoring critical scenarios requiring early anomaly discovery and intervention. Due to limited energy availability and application requirements, drones may visit target points in consecutive trips, with recharging and data offloading in between. To capture timeliness of intervention and prioritize early coverage, we propose the new notion of Weighted Progressive Coverage, which is based on the definition of time dependent weights. Weighted progressive coverage generalizes classic notions of coverage, as well as a new notion of accumulative coverage specifically designed to address trip scheduling. We show that weighted progressive coverage maximization is NP-hard and propose an efficient polynomial algorithm, called Greedy and Prune (GaP), with guaranteed approximation. By means of simulations we show that GaP performs close to the optimal solution and outperforms a previous approach in all the considered performance metrics, including coverage, average inspection delay, energy consumption, and computation time, in a wide range of application scenarios. Through prototype experiments we also confirm the theoretical and simulation analysis, and demonstrate the applicability of our algorithm in real scenarios.},
  archive      = {J_TMC},
  author       = {Novella Bartolini and Andrea Coletta and Gaia Maselli and Ala’ Khalifeh},
  doi          = {10.1109/TMC.2020.2994529},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {3099-3116},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A multi-trip task assignment for early target inspection in squads of aerial drones},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Uplink scheduling in multi-cell OFDMA networks: A
comprehensive study. <em>TMC</em>, <em>20</em>(10), 3081–3098. (<a
href="https://doi.org/10.1109/TMC.2020.2994354">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a comprehensive study of uplink scheduling in multi-cell OFDMA networks. We first focus on two scenarios for the homogeneous case, one without and one with a Cloud-RAN (C-RAN), and explore how to design efficient practical uplink schedulers for those scenarios. To compute the best achievable performance (BAP) under complete information, we study a centralized multi-cell scheduler. To this end, we formulate an MINLP problem and show how to solve it quasi-optimally. Then, we study the performance of an existing practical local benchmark scheduler (LBM) in terms of goodput and losses. We compare its performance to BAP and show that LBM only yields 44 percent of BAP. To reduce this performance gap, we propose two practical enhancements for LBM, one per scenario. The enhanced scheduler for the first scenario yields 51 percent of BAP (70 percent for the second). To reduce the gap further, we propose a new scheduler inspired by soft-frequency reuse (SFR). Its performance is 69 percent (resp. 83 percent) of BAP. It outperforms LBM by 56 percent for the scenario without C-RAN (84 percent with C-RAN). We finally extend our SFR-based scheduler to heterogeneous networks and show that it outperforms LBM by 53 percent for the scenario without C-RAN (96 percent with C-RAN).},
  archive      = {J_TMC},
  author       = {Yiğit Özcan and Catherine Rosenberg},
  doi          = {10.1109/TMC.2020.2994354},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {3081-3098},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Uplink scheduling in multi-cell OFDMA networks: A comprehensive study},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards automatic detection of nonfunctional sensitive
transmissions in mobile applications. <em>TMC</em>, <em>20</em>(10),
3066–3080. (<a href="https://doi.org/10.1109/TMC.2020.2992253">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While mobile apps often need to transmit sensitive information out to support various functionalities, they may also abuse the privilege by leaking the data to unauthorized third parties. This makes us question: Is the given transmission required to fulfill the app functionality? In this paper, we make the first attempt to automatically identify suspicious transmissions from app visual interfaces, including app names, descriptions, and user interfaces. We design and implement a novel framework called FlowIntent to detect nonfunctional transmissions at both software and network levels. During the exercising of the given apps, FlowIntent automatically detects privacy-sharing transmissions and determines their purposes by utilizing the fact that mobile users rely on visible app interface to perceive the functionality of the app at certain context. The characterizations of nonfunctional network traffic are then summarized to provide network level protection. FlowIntent not only reduces the false alarms caused by traditional taint analysis, but also captures the sensitive transmissions missed by widely-used taint analysis system TaintDroid. Evaluation using 2125 sharing flows collected from more than a thousand running instances shows that our approach achieves about 94 percent accuracy in detecting nonfunctional transmissions.},
  archive      = {J_TMC},
  author       = {Hao Fu and Pengfei Hu and Zizhan Zheng and Aveek K. Das and Parth H. Pathak and Tianbo Gu and Sencun Zhu and Prasant Mohapatra},
  doi          = {10.1109/TMC.2020.2992253},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {3066-3080},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Towards automatic detection of nonfunctional sensitive transmissions in mobile applications},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards a compressive-sensing-based lightweight encryption
scheme for the internet of things. <em>TMC</em>, <em>20</em>(10),
3049–3065. (<a href="https://doi.org/10.1109/TMC.2020.2992737">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Things (IoT) is flourishing and has penetrated deeply into people&#39;s daily life. With the seamless connection to the physical world, IoT provides tremendous opportunities to a wide range of applications. However, potential risks exist when the IoT system collects sensor data and uploads it to the Cloud. The leakage of private data can be severe with curious database administrator or malicious hackers who compromise the Cloud. In this work, we propose Kryptein, a compressive-sensing-based lightweight encryption scheme for Cloud-enabled IoT systems to secure the interaction between the IoT devices and the Cloud. Kryptein supports random compressed encryption, statistical computation over cipher, and accurate raw data decryption. According to our evaluation based on two real datasets, Kryptein provides strong protection to the data. It is 250 times faster than other state-of-the-art systems and incurs 120 times less energy consumption. The performance of Kryptein is also measured on off-the-shelf IoT devices, and the result shows Kryptein can run efficiently on IoT devices. After comparing with other state-of-the-art lightweight ciphers on IoT (Simon and Speck), IoT system with Kryptein is expected to have a much more longevity with about 35 percent extended lifetime. Further, experiments illustrated IoT data variance will not affect Kryptein&#39;s accuracy in a long term usage, and Krpytein is also able to support basic analytics tasks like machine learning (e.g., classification).},
  archive      = {J_TMC},
  author       = {Wanli Xue and Chengwen Luo and Yiran Shen and Rajib Rana and Guohao Lan and Sanjay Jha and Aruna Seneviratne and Wen Hu},
  doi          = {10.1109/TMC.2020.2992737},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {3049-3065},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Towards a compressive-sensing-based lightweight encryption scheme for the internet of things},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Toward an automated auction framework for wireless federated
learning services market. <em>TMC</em>, <em>20</em>(10), 3034–3048. (<a
href="https://doi.org/10.1109/TMC.2020.2994639">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In traditional machine learning, the central server first collects the data owners&#39; private data together and then trains the model. However, people&#39;s concerns about data privacy protection are dramatically increasing. The emerging paradigm of federated learning efficiently builds machine learning models while allowing the private data to be kept at local devices. The success of federated learning requires sufficient data owners to jointly utilize their data, computing and communication resources for model training. In this article, we propose an auction-based market model for incentivizing data owners to participate in federated learning. We design two auction mechanisms for the federated learning platform to maximize the social welfare of the federated learning services market. Specifically, we first design an approximate strategy-proof mechanism which guarantees the truthfulness, individual rationality, and computational efficiency. To improve the social welfare, we develop an automated strategy-proof mechanism based on deep reinforcement learning and graph neural networks. The communication traffic congestion and the unique characteristics of federated learning are particularly considered in the proposed model. Extensive experimental results demonstrate that our proposed auction mechanisms can efficiently maximize the social welfare and provide effective insights and strategies for the platform to organize the federated training.},
  archive      = {J_TMC},
  author       = {Yutao Jiao and Ping Wang and Dusit Niyato and Bin Lin and Dong In Kim},
  doi          = {10.1109/TMC.2020.2994639},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {3034-3048},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Toward an automated auction framework for wireless federated learning services market},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stochastic channel access in underwater networks with
statistical interference modeling. <em>TMC</em>, <em>20</em>(10),
3020–3033. (<a href="https://doi.org/10.1109/TMC.2020.2993026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing efficient medium access control protocols for underwater acoustic sensor networks (UW-ASNs) is a major challenge because of the spatial and temporal interference uncertainty caused by asynchronous transmissions and by the low propagation speed of sound. To address these challenges, in this article we propose a new approach for distributed underwater medium access based on lightweight and asynchronous distributed algorithms that optimize the access probability profile over a series of time slots based on a new statistical physical interference model. The latter is based on measuring the level of interference at multiple instants of time in each time slot in order to capture the effects of temporal uncertainty and of unaligned interference. At each measurement instant, the statistical properties of time-varying interference are represented by a Gamma probability distribution. The model is validated through extensive channel measurement experiments conducted with an underwater acoustic testbed in Lake LaSalle. Based on this model, we formulate the problem of queue-aware stochastic channel access. The objective is to maximize the sum throughput of a set of concurrent and mutually interfering source-destination pairs by letting the transmitters adjust their own transmission probability profiles, without collaborating with each other, over a series of time slots based on a statistical characterization of interference obtained through past observations. We propose an iterative distributed solution algorithm for this problem based on a best-response strategy. At each iteration, each node individually solves a non-convex optimization problem of logarithmic complexity. The performance of the proposed distributed algorithm is evaluated by comparing it with two alternative distributed schemes and with the global optimum obtained through a newly-developed centralized globally optimal solution algorithm. Results indicate that by jointly taking the queueing and multi-slot optimization into consideration considerable improvement in terms of sum-throughput can be achieved by the proposed distributed algorithm.},
  archive      = {J_TMC},
  author       = {Zhangyu Guan and Hovannes Kulhandjian and Tommaso Melodia},
  doi          = {10.1109/TMC.2020.2993026},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {3020-3033},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Stochastic channel access in underwater networks with statistical interference modeling},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Privacy preservation in location-based services: A novel
metric and attack model. <em>TMC</em>, <em>20</em>(10), 3006–3019. (<a
href="https://doi.org/10.1109/TMC.2020.2993599">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have seen rising needs for location-based services in our everyday life. Aside from the many advantages provided by these services, they have caused serious concerns regarding the location privacy of users. Adversaries can monitor the queried locations by users to infer sensitive information, such as home addresses and shopping habits. To address this issue, dummy-based algorithms have been developed to increase the anonymity of users, and thus, protecting their privacy. Unfortunately, the existing algorithms only assume a limited amount of side information known by adversaries, which may face more severe challenges in practice. In this paper, we develop an attack model termed as Viterbi attack, which represents a realistic privacy threat on user trajectories. Moreover, we propose a metric called transition entropy that enables the evaluation of dummy-based algorithms, followed by developing a robust algorithm that can defend users against the Viterbi attack while maintaining significantly high performance in terms of the traditional metrics. We compare and evaluate our proposed algorithm and metric on a publicly available dataset published by Microsoft, i.e., Geolife dataset.},
  archive      = {J_TMC},
  author       = {Sina Shaham and Ming Ding and Bo Liu and Shuping Dang and Zihuai Lin and Jun Li},
  doi          = {10.1109/TMC.2020.2993599},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {3006-3019},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Privacy preservation in location-based services: A novel metric and attack model},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-objective computation sharing in energy and delay
constrained mobile edge computing environments. <em>TMC</em>,
<em>20</em>(10), 2992–3005. (<a
href="https://doi.org/10.1109/TMC.2020.2994232">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a mobile edge computing (MEC) network, mobile devices, also called edge clients, offload their computations to multiple edge servers that provide additional computing resources. Since the edge servers are placed at the network edge, e.g., cell-phone towers, transmission delays between edge servers and edge clients are shorter compared to those of cloud computing. In addition, edge clients can offload their tasks to other nearby edge clients with available computing resources by exploiting the Fog Computing (FC) paradigm. A major challenge in MEC and FC networks is to assign the tasks from edge clients to edge servers, as well as to other edge clients, in such a way that their tasks are completed with minimum energy consumption and minimum processing delay. In this paper, we model task offloading in MEC as a constrained multi-objective optimization problem (CMOP) that minimizes both the energy consumption and task processing delay of the mobile devices. To solve the CMOP, we design an evolutionary algorithm that can efficiently find a representative sample of the best trade-offs between energy consumption and task processing delay, i.e., the Pareto-optimal front. Compared to existing approaches for task offloading in MEC, we see that our approach finds offloading decisions with lower energy consumption and task processing delay.},
  archive      = {J_TMC},
  author       = {Arash Bozorgchenani and Farshad Mashhadi and Daniele Tarchi and Sergio A. Salinas Monroy},
  doi          = {10.1109/TMC.2020.2994232},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {2992-3005},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Multi-objective computation sharing in energy and delay constrained mobile edge computing environments},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interference characterization in underlay cognitive networks
with intra-network and inter-network dependence. <em>TMC</em>,
<em>20</em>(10), 2977–2991. (<a
href="https://doi.org/10.1109/TMC.2020.2993408">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interference modeling in cognitive radio network is important to ensure adequate coverage in the network. A reliable interference model, however, depends on accurately characterizing the distribution of users. In this paper, the dependence between primary and secondary networks is examined in order to capture more system parameters related to system characterization. Hence, two cases are considered – primary user (PU) interference control and PU with secondary user (SU) interference control mechanisms. Under PU interference control, distributions of PUs follow the Matern hard core process while the distribution of SUs follow the Poisson hole process (PHP). However, under PU with SU interference control, the distribution of active SUs follow a modified PHP. Bound and approximate expressions were derived for coverage probability at both primary and secondary networks, while simple yet accurate expressions were obtained to depict the number of simultaneous active users supported for the two cases. The tight closeness between the bound and the approximate expressions shows the reliability of the presented theoretical analysis. Furthermore, the bipolar network model assumption was relaxed while the case of independence assumption among users was also considered. Numerical result showed close tightness when the bipolar network model assumption was relaxed while the independence assumption was shown to overestimate users’ coverage probability.},
  archive      = {J_TMC},
  author       = {Samuel D. Okegbile and Bodhaswar T. Maharaj and Attahiru S. Alfa},
  doi          = {10.1109/TMC.2020.2993408},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {2977-2991},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Interference characterization in underlay cognitive networks with intra-network and inter-network dependence},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fine-grained user profiling for personalized task matching
in mobile crowdsensing. <em>TMC</em>, <em>20</em>(10), 2961–2976. (<a
href="https://doi.org/10.1109/TMC.2020.2993963">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In mobile crowdsensing, finding the best match between tasks and users is crucial to ensure both the quality and effectiveness of a crowdsensing system. Existing works usually assume a centralized task assignment by the crowdsensing platform, without addressing the need of fine-grained personalized task matching. In this paper, we argue that it is essential to match tasks to users based on a careful characterization of both the users&#39; preference and reliability. To that end, we propose a personalized task recommender system for mobile crowdsensing, which recommends tasks to users based on a recommendation score that jointly takes each user&#39;s preference and reliability into consideration. We first present a hybrid preference metric to characterize users&#39; preference by exploiting their implicit feedback. Then, to profile users&#39; reliability levels, we formalize the problem as a semi-supervised learning model, and propose an efficient block coordinate descent algorithm to solve the problem. For some tasks that lack users&#39; historical information, we further propose a matrix factorization method to infer the users&#39; reliability levels on those tasks. We conduct extensive experiments to evaluate the performance of our system, and the evaluation results demonstrate that our system can achieve superior performance to the benchmarks in both user profiling and personalized task recommendation.},
  archive      = {J_TMC},
  author       = {Fan Wu and Shuo Yang and Zhenzhe Zheng and Shaojie Tang and Guihai Chen},
  doi          = {10.1109/TMC.2020.2993963},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {2961-2976},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Fine-grained user profiling for personalized task matching in mobile crowdsensing},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distributed device-to-device offloading system: Design and
performance optimization. <em>TMC</em>, <em>20</em>(10), 2949–2960. (<a
href="https://doi.org/10.1109/TMC.2020.2994138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In task offloading systems, it is imperative to guarantee that an offloaded task is completed within a pre-specified deadline. In this paper, we propose a distributed device-to-device (D2D) offloading system (DDOS) in which a task owner opportunistically broadcasts an offloading request that includes its mobility level and task completion deadline. After receiving the request, mobile devices in the vicinity of the task owner employ a constraint stochastic game to decide, in a distributed manner, whether to accept the request or not. We devise a best response dynamics-based algorithm (BRDA) to obtain a multi-policy constrained Nash equilibrium. Evaluation results demonstrate that DDOS can guarantee a high on-time task completion probability, as well as a low energy consumption.},
  archive      = {J_TMC},
  author       = {Haneul Ko and Sangheon Pack},
  doi          = {10.1109/TMC.2020.2994138},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {2949-2960},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Distributed device-to-device offloading system: Design and performance optimization},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distributed and adaptive reservation MAC protocol for
beaconing in vehicular networks. <em>TMC</em>, <em>20</em>(10),
2936–2948. (<a href="https://doi.org/10.1109/TMC.2020.2992045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In vehicular ad hoc networks (VANETs), beacon broadcasting plays a critical role in improving road safety and avoiding hazardous situations. How to ensure reliability and scalability of beacon broadcasting is a difficult and open problem, due to high mobility, dynamic network topology, hidden terminal, and varying density in both the time and location domains. In this paper, wireless resources are divided into basic resource units in the time and frequency domains, and a distributed and adaptive reservation based MAC protocol (DARP) is proposed to solve the above problem. For decentralized control in VANETs, each vehicle&#39;s channel access is coordinated with its neighbors to solve the hidden terminal problem. To ensure the reliability of beacon broadcasting, different kinds of preambles are applied in DARP to support distributed reservation, detect beacon collisions, and resolve collisions. Once a vehicle reserves a resource unit successfully, it will not release it until collision occurs due to topology change. The protocol performance in terms of access collision probability and access delay are analyzed. Based on the analysis, protocol parameters, including transmission power and time slots duration, can be adjusted to reduce collision probability and enhance reliability and scalability. Using NS-3 with vehicle traces generated by simulation of urban mobility (SUMO), simulation results show that the proposed DARP protocol can achieve the design goals of reliability and scalability, and it substantially outperforms the existing standard solutions.},
  archive      = {J_TMC},
  author       = {Hamed Mosavat-Jahromi and Yue Li and Yuanzhi Ni and Lin Cai},
  doi          = {10.1109/TMC.2020.2992045},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {2936-2948},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Distributed and adaptive reservation MAC protocol for beaconing in vehicular networks},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). BOOST: A user association and scheduling framework for
beamforming mmWave networks. <em>TMC</em>, <em>20</em>(10), 2924–2935.
(<a href="https://doi.org/10.1109/TMC.2020.2992623">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The millimeter wave (mmWave) band offers vast bandwidth and plays a key role for next generation wireless networks. However, the mmWave network raises a great challenge for user association and scheduling, due to the limited power budget and beamformers, diverse user traffic loads, user quality of service requirement, etc. In this paper, we propose a novel framework for user association and scheduling in multi-base station mmWave networks, termed the clustering Based dOwnlink UE assOciation, Scheduling, beamforming with power allocaTion (BOOST). The objective is to reduce the downlink network transmission time, subject to the base station power budget, number of beamformers, user traffic loads, and the quality of service requirement at users. We compare BOOST with three state-of-the-art user scheduling schemes. On average, BOOST reduces the transmission time by 37, 30, and 26 percent, and achieves a sum rate gain of 56, 43, and 34 percent, respectively.},
  archive      = {J_TMC},
  author       = {Prosanta Paul and Hongyi Wu and ChunSheng Xin},
  doi          = {10.1109/TMC.2020.2992623},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {2924-2935},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {BOOST: A user association and scheduling framework for beamforming mmWave networks},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A simple model of MTC flows applied to smart factories.
<em>TMC</em>, <em>20</em>(10), 2906–2923. (<a
href="https://doi.org/10.1109/TMC.2020.2993223">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we develop a simple, yet accurate, performance model to understand if and how evolutions of standard cellular network protocols can be exploited to allow large numbers of machine type devices to access transmission resources with short latency, and we apply our model to the performance analysis of smart factory radio access networks. The model results shed light on the problems resulting from the application of evolved standard access procedures and help understand how many devices can be served per base station with specified latency targets. In addition, considering the simultaneous presence of different traffic classes, we investigate the effectiveness of prioritised access, exploiting access class barring techniques. Our model shows that, even with the sub-millisecond time slots foreseen in LTE Advanced Pro and 5G, a base station can accommodate at most few thousand devices to guarantee access latency below 100 ms with high transmission success probability. Lower access latency, of the order of 10 ms, can be achieved only with base stations serving an unrealistically small numbers of devices. This calls for a rethinking of wireless access strategies to avoid excessive latency in ultra-dense cell deployments within smart factory’s infrastructures.},
  archive      = {J_TMC},
  author       = {Paolo Castagno and Vincenzo Mancuso and Matteo Sereno and Marco Ajmone Marsan},
  doi          = {10.1109/TMC.2020.2993223},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {2906-2923},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A simple model of MTC flows applied to smart factories},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Time-efficient target tags information collection in
large-scale RFID systems. <em>TMC</em>, <em>20</em>(9), 2891–2905. (<a
href="https://doi.org/10.1109/TMC.2020.2992256">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By integrating the micro-sensor on RFID tags to obtain the environment information, the sensor-augmented RFID system greatly supports the applications that are sensitive to environment. To quickly collect the information from all tags, many researchers dedicate on well arranging tag replying orders to avoid the signal collisions. Compared to from all tags, collecting information from a part of tags (i.e., target tags) is more challenging because the collecting process is interfered by useless replying from non-target tags. The existing works of target tag information collection are designed for single reader systems. However, they cannot work efficiently in more common multi-reader scenarios, where each reader lacks knowledge of tag distribution among all readers. In this paper, we propose time-efficient protocols to collect target tag information in multi-reader systems. The high efficiency of our protocol is enabled by two novel designs. First, we develop a technique that quickly detects and silences non-target tags without a priori knowledge of which tags are in the readers’ interrogation regions. Second, we design an allocation vector to efficiently arrange the replying order of only target tags. Different from previous bit-vector based approaches that make use of only singleton slots, our allocation vector approach also makes use of collision slots to speed up target tag information collection. We further propose an enhancement protocol which can reconcile the collision slots with higher probability and therefore collect information from more target tags simultaneously. The extensive simulation results demonstrate that our protocols significantly outperform the state-of-the-art protocols in terms of time-efficiency.},
  archive      = {J_TMC},
  author       = {Xuan Liu and Jiangjin Yin and Shigeng Zhang and Bin Xiao and Bo Ou},
  doi          = {10.1109/TMC.2020.2992256},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {2891-2905},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Time-efficient target tags information collection in large-scale RFID systems},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Practical privacy-preserving indoor localization based on
secure two-party computation. <em>TMC</em>, <em>20</em>(9), 2877–2890.
(<a href="https://doi.org/10.1109/TMC.2020.2990871">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a privacy-preserving indoor localization scheme based on received signal strength measurements, e.g., from WiFi access points. Our scheme preserves the privacy of both the client&#39;s location and the service provider&#39;s database by using secure two-party computation instantiated with known cryptographic primitives, namely, Paillier encryption and garbled circuits. We describe a number of optimizations that reduce the computation and communication overheads of the scheme and provide theoretical evaluations of these overheads. We also demonstrate the feasibility of the scheme by developing a proof-of-concept implementation for Android smartphones and commodity servers. This implementation allows us to validate the practical performance of our scheme and to show that it is feasible for practical use in certain types of indoor localization applications.},
  archive      = {J_TMC},
  author       = {Raine Nieminen and Kimmo Järvinen},
  doi          = {10.1109/TMC.2020.2990871},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {2877-2890},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Practical privacy-preserving indoor localization based on secure two-party computation},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Power-constrained quality optimization for mobile video
chatting with coding-transmission adaptation. <em>TMC</em>,
<em>20</em>(9), 2862–2876. (<a
href="https://doi.org/10.1109/TMC.2020.2990374">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile video chatting has emerged as an important Internet multimedia application that greatly enriches interpersonal communications. Mobile power efficiency is crucial to the service quality and time of video chatting on battery-limited smartphones. However, the power characteristics of the video coding and data communication are highly complex due to the time-varying network conditions and dynamic mobile energy features. This incurs crucial challenges to maintaining the low power dissipation of mobile chatting application while streaming satisfactory-quality videos. To address these challenges, this paper presents a joinT cOding-tranSmission Optimization (TOSO) protocol at application layer that performs machine learning based adaptation of the video bit rate and FEC (Forward Error Correction) coding parameters. By taking advantage of analytical and empirical models characterizing the quality-power relationship, TOSO is able to maximize video quality subject to a specified upper bound of power consumption in mobile chat application. This distinguishing feature prevents the video chat from draining battery too quickly. Moreover, it allows the smartphone operating system or the mobile user to define a desired video chat duration given the remaining battery, avoiding unpleasant conversation disruption due to battery depletion. Extensive experiments based on the Linphone platform and Exata network emulator show that TOSO outperforms baseline approaches by 29.3 percent in power conservation while achieving the same video quality level.},
  archive      = {J_TMC},
  author       = {Ji-Yan Wu and Kaishun Wu and Ming Wang},
  doi          = {10.1109/TMC.2020.2990374},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {2862-2876},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Power-constrained quality optimization for mobile video chatting with coding-transmission adaptation},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Non-uniform time-step deep q-network for carrier-sense
multiple access in heterogeneous wireless networks. <em>TMC</em>,
<em>20</em>(9), 2848–2861. (<a
href="https://doi.org/10.1109/TMC.2020.2990399">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a new class of carrier-sense multiple access (CSMA) protocols that employ deep reinforcement learning (DRL) techniques, referred to as carrier-sense deep-reinforcement learning multiple access (CS-DLMA). The goal of CS-DLMA is to enable efficient and equitable spectrum sharing among a group of co-located heterogeneous wireless networks. Existing CSMA protocols, such as the medium access control (MAC) protocol of WiFi, are designed for a homogeneous network in which all nodes adopt the same protocol. Such protocols suffer from severe performance degradation in a heterogeneous environment where there are nodes adopting other MAC protocols. CS-DLMA aims to circumvent this problem by making use of DRL. In particular, this paper adopts α-fairness as the general objective of CS-DLMA. With α-fairness, CS-DLMA can achieve a range of different objectives (e.g., maximizing sum throughput, achieving proportional fairness, or achieving max-min fairness) when coexisting with other MACs by changing the value of α. A salient feature of CS-DLMA is that it can achieve these objectives without knowing the coexisting MACs through a learning process based on DRL. The underpinning DRL technique in CS-DLMA is deep Q-network (DQN). However, the conventional DQN algorithms are not suitable for CS-DLMA due to their uniform time-step assumption. In CSMA protocols, time steps are non-uniform in that the time duration required for carrier sensing is smaller than the duration of data transmission. This paper introduces a non-uniform time-step formulation of DQN to address this issue. Our simulation results show that CS-DLMA can achieve the general α-fairness objective when coexisting with TDMA, ALOHA, and WiFi protocols by adjusting its own transmission strategy. Interestingly, we also find that CS-DLMA is more Pareto efficient than other CSMA protocols, e.g., p-persistent CSMA, when coexisting with WiFi. Although this paper focuses on the use of our non-uniform time-step DQN formulation in wireless networking, we believe this new DQN formulation can also find use in other domains.},
  archive      = {J_TMC},
  author       = {Yiding Yu and Soung Chang Liew and Taotao Wang},
  doi          = {10.1109/TMC.2020.2990399},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {2848-2861},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Non-uniform time-step deep Q-network for carrier-sense multiple access in heterogeneous wireless networks},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Leveraging UAVs for coverage in cell-free vehicular
networks: A deep reinforcement learning approach. <em>TMC</em>,
<em>20</em>(9), 2835–2847. (<a
href="https://doi.org/10.1109/TMC.2020.2991326">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The success in transitioning towards smart cities relies on the availability of information and communication technologies that meet the demands of this transformation. The terrestrial infrastructure presents itself as a preeminent component in this change. Unmanned aerial vehicles (UAVs) empowered with artificial intelligence (AI) are expected to become an integral component of future smart cities that provide seamless coverage for vehicles on highways with poor cellular infrastructure. Motivated by the above, in this paper, we introduce UAVs cell-free network for providing coverage to vehicles entering a highway that is not covered by other infrastructure. However, UAVs have limited energy resources and cannot serve the entire highway all the time. Furthermore, the deployed UAVs have insufficient knowledge about the environment (e.g., the vehicles&#39; instantaneous location). Therefore, it is challenging to control a swarm of UAVs to achieve efficient communication coverage. To address these challenges, we formulate the trajectories decisions making as a Markov decision process (MDP) where the system state space considers the vehicular network dynamics. Then, we leverage deep reinforcement learning (DRL) to propose an approach for learning the optimal trajectories of the deployed UAVs to efficiently maximize the vehicular coverage, where we adopt Actor-Critic algorithm to learn the vehicular environment and its dynamics to handle the complex continuous action space. Finally, simulations results are provided to verify our findings and demonstrate the effectiveness of the proposed design and show that during the mission time, the deployed UAVs adapt their velocities in order to cover the vehicles.},
  archive      = {J_TMC},
  author       = {Moataz Samir and Dariush Ebrahimi and Chadi Assi and Sanaa Sharafeddine and Ali Ghrayeb},
  doi          = {10.1109/TMC.2020.2991326},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {2835-2847},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Leveraging UAVs for coverage in cell-free vehicular networks: A deep reinforcement learning approach},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fly-navi: A novel indoor navigation system with on-the-fly
map generation. <em>TMC</em>, <em>20</em>(9), 2820–2834. (<a
href="https://doi.org/10.1109/TMC.2020.2990446">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing studies on indoor navigation often require such a pre-deployment as floor map, localization system and/or additional (customized) hardwares, or human motion traces, making them prohibitive when the situation deviates from these requirements (e.g., navigating a crowd of panicking people where no localization system or motion traces are available). The main observation inspiring our work without reliance on such pre-deployment is that when there are sufficient participants (e.g., a crowd of panicking people), the WiFi signatures collected by participants can serve as the fingerprints (referred to as location fingerprints) of their unknown locations. By computing relative positions of these location fingerprints we can connect them to form a global map. Such a map reflects the topology of the underlying walkable space and thus holds the potential of offering a navigation path for any intended users. Based on this observation, we design Fly-Navi, a crowdsourcing based indoor navigation system via on-the-fly map generation, and primarily designed for indoor environments with rectilinear and narrow corridors. Specifically, each participant uploads sensory data, and the server then generates a global map (on-the-fly map) through a series of operations such as local map generation, local map stitch and edge computation. On top of the global map, Fly-Navi computes a navigation path to the given destination and tracks the progress. We implement the prototype of Fly-Navi and our experiments show that Fly-Navi can quickly generate a correct global map with the 80-percentile of between-fingerprint distance error less than 3 meters, which is important for computing turning points of the map and hereon offering turn-by-turn instructions, and correctly navigate the intended users to their destinations.},
  archive      = {J_TMC},
  author       = {Hongbo Jiang and Wenping Liu and Guoyin Jiang and Yufu Jia and Xingjun Liu and Zhicheng Lui and Xiaofei Liao and Jing Xing and Daibo Liu},
  doi          = {10.1109/TMC.2020.2990446},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {2820-2834},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Fly-navi: A novel indoor navigation system with on-the-fly map generation},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Energy-aware tracking of mobile targets by bacterial
nanonetworks. <em>TMC</em>, <em>20</em>(9), 2808–2819. (<a
href="https://doi.org/10.1109/TMC.2020.2990134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The functioning of bacterial nanonetworks as a ”drug delivery system” requires the engineered bacteria to track the targets, such as harmful micro-organisms, pathogens, or chemical weapons, to release drug molecules effectively. The coordinated and intelligent movement of energy-constrained engineered bacteria is desired for successful tracking of mobile targets. In this work, first, we analyze the energy consumption by engineered bacteria for releasing molecules and propagating for the tracking process. Then we show that the events of the release of molecules by engineered bacteria and their propagation are interlinked in such a way that the strategy of releasing attractants upon detecting the target is coupled to the energy available with the engineered bacteria. Based on the finding, we propose an energy-aware algorithm, named as EnPoS, which probabilistically selects a group of engineered bacteria among the deployed bacterial population to release signaling molecules over a particular time period in order for engineered bacteria to track the mobile targets. The simulation results show better performance of the proposed algorithm as compared with the basic algorithm incorporating continuous releasing of signaling molecules, concerning the energy expenses, mean displacement over time, and distribution of the engineered bacteria around the targets.},
  archive      = {J_TMC},
  author       = {Nabiul Islam and Saswati Pal and Sasitharan Balasubramaniam and Sudip Misra},
  doi          = {10.1109/TMC.2020.2990134},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {2808-2819},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Energy-aware tracking of mobile targets by bacterial nanonetworks},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Energy optimization of wireless visual sensor networks with
the consideration of the desired target coverage. <em>TMC</em>,
<em>20</em>(9), 2795–2807. (<a
href="https://doi.org/10.1109/TMC.2020.2990596">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless visual sensor networks (WVSN) have recently seen dramatic growth with technology development. These networks consist of a number of smart visual sensors (VSes) that can collect visual information, i.e., images and video captured in a network area. Optimizing the energy consumption and coverage are important contradictory challenges in WVSNs since increase in coverage leads to increase in energy consumption. Therefore, optimization of energy consumption by maintaining image quality defined by user or operator located in sink [quality of experience (QoE)] to be used in target tracking applications is addressed in this paper. The target coverage as well as the quality of the received image of the target are considered as the desired QoE. The novel two-dimensional target coverage model is also presented mathematically. This model is described as a function of the VS inherent parameters, the target position and the visual sensor position. Based on a convex optimization framework, a heuristic approach for the VS selection and the focal length adjustment is suggested to solve the optimization problem while maintaining high image quality. Simulation results are presented to verify the capability and efficiency of the proposed method in comparison with the optimal method (Exhaustive search method).},
  archive      = {J_TMC},
  author       = {Reza Ghazalian and Ali Aghagolzadeh and Seyed Mehdi Hosseini Andargoli},
  doi          = {10.1109/TMC.2020.2990596},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {2795-2807},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Energy optimization of wireless visual sensor networks with the consideration of the desired target coverage},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Differentially private unknown worker recruitment for mobile
crowdsensing using multi-armed bandits. <em>TMC</em>, <em>20</em>(9),
2779–2794. (<a href="https://doi.org/10.1109/TMC.2020.2990221">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile crowdsensing is a new paradigm by which a platform can recruit mobile workers to perform some sensing tasks by using their smart mobile devices. In this paper, we focus on a privacy-preserving unknown worker recruitment issue. The platform needs to recruit some workers without knowing the qualities of them completing tasks. Meanwhile, these quality information also needs to be protected from disclosure. To tackle these challenges, we model the unknown worker recruitment as a Differentially Private Multi-Armed Bandit (DP-MAB) game by seeing each worker as an arm of DP-MAB and the task completion quality contributed by each worker as the reward of pulling arm. Then, recruiting workers is equivalent to designing a bandit policy of pulling DP-MAB arms. Under this model, we propose a Differentially Private ϵ-First-based arm-pulling (DPF) algorithm and a Differentially Private UCB-based arm-pulling (DPU) algorithm, which can achieve the nearly optimal expected accumulative rewards under a given budget. We also analyze the regrets of the DPF and DPU algorithms and prove that both of them are δ-differentially private on the task completion qualities (δ &gt; 0δ). Finally, we conduct extensive simulations to verify the significant performances of DPF and DPU based on both the real-trace and synthetic datasets.},
  archive      = {J_TMC},
  author       = {Hui Zhao and Mingjun Xiao and Jie Wu and Yun Xu and He Huang and Sheng Zhang},
  doi          = {10.1109/TMC.2020.2990221},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {2779-2794},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Differentially private unknown worker recruitment for mobile crowdsensing using multi-armed bandits},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Contract design in hierarchical game for sponsored content
service market. <em>TMC</em>, <em>20</em>(9), 2763–2778. (<a
href="https://doi.org/10.1109/TMC.2020.2991060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With a sponsored content scheme of mobile services, a content provider can encourage end users/subscribers to access its contents, e.g., with an advertisement, by paying part of the data price to the network operator. As a result, the content provider and end users are both actively engaged into the sponsored content ecosystem. As such, a key challenge is how to provide proper sponsorship given the content demand from the users and the service fee charged by the network operator. Furthermore, the information asymmetry between the content provider and users makes the sponsorship problem more challenging. In this paper, we propose a Stackelberg game-based framework to tackle this challenge. In the framework, the network operator, as the leader, determines the data price first, and the content provider as well as users, as the followers, make the decisions on sponsorship and content demand based on the data price, respectively. We model the interaction between the content provider and the users as a contract game in the presence of asymmetric information. In the contract game, the content provider designs a contract that contains its sponsorship strategies toward all types of users. We then derive the necessary and sufficient conditions of feasible contracts and obtain an optimal contract to maximize the profit of the content provider. Taking into account the optimal contract of contract game, we also investigate the optimal pricing of the network operator through backward induction. We prove that the Stackelberg equilibrium is unique under a mild condition and present the numerical results to illustrate some important properties of the equilibrium.},
  archive      = {J_TMC},
  author       = {Zehui Xiong and Jun Zhao and Yang Zhang and Dusit Niyato and Junshan Zhang},
  doi          = {10.1109/TMC.2020.2991060},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {2763-2778},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Contract design in hierarchical game for sponsored content service market},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Computation offloading in multi-access edge computing: A
multi-task learning approach. <em>TMC</em>, <em>20</em>(9), 2745–2762.
(<a href="https://doi.org/10.1109/TMC.2020.2990630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-access edge computing (MEC) has already shown great potential in enabling mobile devices to bear the computation-intensive applications by offloading some computing jobs to a nearby access point (AP) integrated with a MEC server (MES). However, due to the varying network conditions and limited computational resources of the MES, the offloading decisions taken by a mobile device and the computational resources allocated by the MES can be formulated as a mixed-integer nonlinear programming (MINLP) problem, which may not be optimized with the lowest cost. In this paper, we propose a novel offloading framework for the multi-server MEC network where each AP is equipped with an MES assisting mobile users (MUs) in executing computation-intensive jobs via offloading. Specifically, we formulate the offloading decision problem as a multiclass classification problem and formulate the MES computational resource allocation problem as a regression problem. Then a multi-task learning based feedforward neural network (MTFNN) model is designed and trained to jointly optimize the offloading decision and computational resource allocation. Numerical results show that the proposed MTFNN outperforms the conventional optimization method in terms of inference accuracy and computational complexity.},
  archive      = {J_TMC},
  author       = {Bo Yang and Xuelin Cao and Joshua Bassey and Xiangfang Li and Lijun Qian},
  doi          = {10.1109/TMC.2020.2990630},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {2745-2762},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Computation offloading in multi-access edge computing: A multi-task learning approach},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A truthful and near-optimal mechanism for colocation
emergency demand response. <em>TMC</em>, <em>20</em>(9), 2728–2744. (<a
href="https://doi.org/10.1109/TMC.2020.2990425">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Demand response (DR) has been widely adopted as a strategic plan of the electricity market in maintaining power grid reliability, sustainability, and stability. In a typical emergency DR (EDR) that arises in colocation data centers, participating tenants can reduce their power consumption when the supply of electricity is a shortage and be rewarded with financial compensation. In this paper, we study a mechanism design problem of motivating tenants for colocation EDR (MEDR). To solve the MEDR problem, we present a truthful Fully Polynomial-Time Approximation Scheme (FPTAS) which is theoretically proved deterministic, truthful and near-optimal, and can be approximated within 1 + ϵ for any given ϵ &gt; 0, while the running time is in the polynomial of the number of tenants n and ε. To speed up the calculation of the payments, we further study the Vickrey-Clarke-Groves (VCG) based mechanism. Moreover, we build a MEDR auction system (MEDRAS) and implement all mechanism algorithms for a colocation data center. Comprehensive and detailed experiments have been implemented to validate the efficiency of our proposed mechanisms.},
  archive      = {J_TMC},
  author       = {Jianhai Chen and Deshi Ye and Zhenguang Liu and Shouling Ji and Qinming He and Yang Xiang},
  doi          = {10.1109/TMC.2020.2990425},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {2728-2744},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A truthful and near-optimal mechanism for colocation emergency demand response},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A fuzzy logic-based on-demand charging algorithm for
wireless rechargeable sensor networks with multiple chargers.
<em>TMC</em>, <em>20</em>(9), 2715–2727. (<a
href="https://doi.org/10.1109/TMC.2020.2990419">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile chargers have greatly promoted the wireless rechargeable sensor networks (WRSNs). While most recent works have focused on recharging the WRSNs in an on-demand fashion, little attention has been paid on joint consideration of multiple mobile chargers (MCs) and multi-node energy transfer for determining the charging schedule of energy-hungry nodes. Moreover, most of the schemes leave out the contemplation of multiple network attributes while making scheduling decisions and even they overlook the issue of ill-timed charging response to the nodes with uneven energy consumption rates. In this paper, we address the aforesaid issues together and propose a novel scheduling scheme for on-demand charging in WRSNs. We first present an efficient network partitioning method for distributing the MCs so as to evenly balance their workload. We next adopt the fuzzy logic which blends various network attributes for determining the charging schedule of the MCs. We also formulate an expression to determine the charging threshold for the nodes that vary depending on their energy consumption rate. Extensive simulations are conducted to demonstrate the effectiveness and competitiveness of our scheme. The comparison results reveal that the proposed scheme improves charging performance compared to the state-of-the-art schemes with respect to various performance metrics.},
  archive      = {J_TMC},
  author       = {Abhinav Tomar and Lalatendu Muduli and Prasanta K. Jana},
  doi          = {10.1109/TMC.2020.2990419},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {2715-2727},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A fuzzy logic-based on-demand charging algorithm for wireless rechargeable sensor networks with multiple chargers},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards fine-grained access control in enterprise-scale
internet-of-things. <em>TMC</em>, <em>20</em>(8), 2701–2714. (<a
href="https://doi.org/10.1109/TMC.2020.2984700">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scalable, fine-grained access control for Internet-of-Things is needed in enterprise environments, where tens of thousands of users need to access smart objects which have a similar or larger order of magnitude. Existing solutions offer all-or-nothing access, or require all access to go through a cloud backend, greatly impeding access granularity, robustness and scale. In this paper, we propose Heracles, an IoT access control system which achieves robust, fine-grained access control and responsive execution at enterprise scale. Heracles adopts a capability-based approach using secure, unforgeable tokens that describe the authorizations of users, to either individuals or collections of objects in single or bulk operations. It has a 3-tier architecture to provide centralized policy and distributed execution desired in enterprise environments. Extensive analysis and performance evaluation on a testbed prove that Heracles achieves fine-grained access control and responsive execution at enterprise scale. Compared with systems using access control list, Heracles eliminates or reduces by 10x-100x the updating overhead under frequent changes of subject memberships and policies. Besides, Heracles achieves responsive execution: it takes 0.57 second to access 18 objects which are scattered 1-9 hops away, and execution on a 1-hop or 2-hop object needs only 0.07 or 0.13 second respectively.},
  archive      = {J_TMC},
  author       = {Qian Zhou and Mohammed Elbadry and Fan Ye and Yuanyuan Yang},
  doi          = {10.1109/TMC.2020.2984700},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {2701-2714},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Towards fine-grained access control in enterprise-scale internet-of-things},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Statistical performance modeling of solar and wind-powered
UAV communications. <em>TMC</em>, <em>20</em>(8), 2686–2700. (<a
href="https://doi.org/10.1109/TMC.2020.2983955">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop novel statistical models of the harvested energy from renewable energy sources considering harvest-store-consume (HSC) architecture. We consider three renewable energy harvesting scenarios, i.e., (i) harvesting from the solar power, (ii) harvesting from the wind power, and (iii) hybrid solar and wind power. In this context, we first derive the closed-form expressions for the density functions and moments of the harvested power solar and wind power. Then, we calculate the probability of energy outage at UAVs and signal-to-noise ratio (SNR) outage at ground cellular users. The energy outage occurs when the UAV is unable to support the flight consumption and transmission consumption from its battery power and the harvested power. Due to the intricate distribution of the hybrid solar and wind power, we derive novel closed-form expressions for the moment generating function (MGF) of the harvested solar power and wind power. Then, we apply Gil-Pelaez inversion to evaluate the energy outage at the UAV and SNR outage at the ground users. In addition, we formulate the SNR outage minimization problem and obtain closed-form solutions for the transmit power and flight time of the UAV. Furthermore, we demonstrate the application of moments in computing novel metrics such as the probability of charging the UAV battery within the flight time, average UAV battery charging time, probability of energy outage at UAVs, and the probability of eventual energy outage (i.e., the probability of energy outage in a finite duration of time) at UAVs. Numerical results validate the analytical expressions and reveal interesting insights related to the optimal flight time and transmit power of the UAV as a function of the harvested energy.},
  archive      = {J_TMC},
  author       = {Silvia Sekander and Hina Tabassum and Ekram Hossain},
  doi          = {10.1109/TMC.2020.2983955},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {2686-2700},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Statistical performance modeling of solar and wind-powered UAV communications},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Real-time detection for drowsy driving via acoustic sensing
on smartphones. <em>TMC</em>, <em>20</em>(8), 2671–2685. (<a
href="https://doi.org/10.1109/TMC.2020.2984278">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drowsy driving is one of the biggest threats to driving safety, which has drawn much public attention in recent years. Thus, a simple but robust system that can remind drivers of drowsiness levels with off-the-shelf devices (e.g., smartphones) is very necessary. With this motivation, we explore the feasibility of using acoustic sensors on smartphones to detect drowsy driving. Through analyzing real driving data to study characteristics of drowsy driving, we find some unique patterns of Doppler shift caused by three typical drowsy behaviours (i.e., nodding, yawning and operating steering wheel), among which operating steering wheels is also related to drowsiness levels. Then, a real-time Drowsy Driving Detection system named D 3 -Guard is proposed based on the acoustic sensing abilities of smartphones. We adopt several effective feature extraction methods, and carefully design a high-accuracy detector based on LSTM networks for the early detection of drowsy driving. Besides, measures to distinguish drowsiness levels are also introduced in the system by analyzing the data of operating steering wheel. Through extensive experiments with five drivers in real driving environments, D 3 -Guard detects drowsy driving actions with an average accuracy of 93.31%, as well as classifies drowsiness levels with an average accuracy of 86%.},
  archive      = {J_TMC},
  author       = {Yadong Xie and Fan Li and Yue Wu and Song Yang and Yu Wang},
  doi          = {10.1109/TMC.2020.2984278},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {2671-2685},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Real-time detection for drowsy driving via acoustic sensing on smartphones},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). RAMOS: A resource-aware multi-objective system for edge
computing. <em>TMC</em>, <em>20</em>(8), 2654–2670. (<a
href="https://doi.org/10.1109/TMC.2020.2984134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile and IoT devices are becoming increasingly capable computing platforms that are often underutilized. In this paper, we propose RAMOS, a system that leverages the idle compute cycles in a group of heterogeneous mobile and IoT devices that can be clustered to form an edge FemtoCloud. At the heart of this system, we formulate a multi-objective, resource-aware task assignment and scheduling problem. The scheduler runs in two main modes; latency-minimization and energy-efficiency. Under the latency-minimization mode, it strives to maximize the computational throughput of the constructed FemtoCloud while maintaining the energy consumption below an operator specified threshold. Under the energy-efficient mode, it minimizes the total energy consumed in the FemtoCloud while meeting defined tasks deadlines. Due to the NP-Completeness of this scheduling problem, we design a set of heuristics to solve it. We implement a prototype of our system and use it to evaluate its performance and efficiency. Our results demonstrate the system&#39;s ability to meet different scheduling objectives while adhering to pre-specified time and energy constraints. Compared to other schedulers, RAMOS achieves 10 to 40 percent completion time improvement under latency minimization mode and up to 30 percent more energy-efficiency under the energy-efficient mode.},
  archive      = {J_TMC},
  author       = {Hend Gedawy and Karim Habak and Khaled A. Harras and Mounir Hamdi},
  doi          = {10.1109/TMC.2020.2984134},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {2654-2670},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {RAMOS: A resource-aware multi-objective system for edge computing},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Profit-oriented task allocation for mobile crowdsensing with
worker dynamics: Cooperative offline solution and predictive online
solution. <em>TMC</em>, <em>20</em>(8), 2637–2653. (<a
href="https://doi.org/10.1109/TMC.2020.2983688">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile crowdsensing (MCS) is a new paradigm of data collection with large-scale sensing. A group of mobile users are recruited as workers to move around in a specific region and carry out sensing tasks. A challenging problem of MCS is task allocation, especially when the MCS platform needs to assign tasks to selected workers among a large user pool and consider mixed spatial and temporal features, including locations and time windows of tasks, and trajectories and arrival time of workers. In this paper, we take into account these features and study the task allocation problem that assigns tasks to workers over time and guarantees the tasks are accomplished before their deadlines. We consider an offline scenario where the MCS platform is informed of all the information of tasks and workers in advance, and an online scenario where the platform does not know the information of workers before they enter the system. For the offline scenario, we provide a cooperative ant colony algorithm with swarm intelligence to approximate the optimal solution in large-scale cases. For the online scenario with incomplete information, we propose several online algorithms, among which the predictive online algorithm exploits historical records of workers and performs the best. Finally, we conduct simulations and evaluate the differences among the online solutions and offline solutions. The results show that the proposed online solutions can approach the offline optimal solution in small-scale cases, and its approximation obtained by the cooperative offline solution in large-scale cases.},
  archive      = {J_TMC},
  author       = {Xi Tao and Wei Song},
  doi          = {10.1109/TMC.2020.2983688},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {2637-2653},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Profit-oriented task allocation for mobile crowdsensing with worker dynamics: Cooperative offline solution and predictive online solution},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Lifecycle-aware online video caching. <em>TMC</em>,
<em>20</em>(8), 2624–2636. (<a
href="https://doi.org/10.1109/TMC.2020.2984364">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current explosion of video traffic compels service providers to deploy caches at edge networks. Nowadays, most caching systems store data with a high programming voltage corresponding to the largest possible ‘expiry date’, typically on the order of years, which maximizes the cache damage. However, popular videos rarely exhibit lifecycles longer than a couple of months. Consequently, the programming voltage can instead be adapted to fit the lifecycle and mitigate the cache damage accordingly. In this paper, we propose LiA-cache, a Lifecycle-Aware caching policy for online videos. LiA-cache finds both near-optimal caching retention times and cache eviction policies by optimizing traffic delivery cost and cache damage cost conjointly. We first investigate temporal patterns of video access from a real-world dataset covering 10 million online videos collected by one of the largest mobile network operators in the world. We next cluster the videos based on their access lifecycles and integrate the clustering into a general model of the caching system. Specifically, LiA-cache analyzes videos and caches them depending on their cluster label. Compared to other popular policies in real-world scenarios, LiA-cache can reduce cache damage up to 90 perce, while keeping a cache hit ratio close to a policy purely relying on video popularity.},
  archive      = {J_TMC},
  author       = {Tong Li and Tristan Braud and Yong Li and Pan Hui},
  doi          = {10.1109/TMC.2020.2984364},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {2624-2636},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Lifecycle-aware online video caching},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). LeaD: Large-scale edge cache deployment based on
spatio-temporal WiFi traffic statistics. <em>TMC</em>, <em>20</em>(8),
2607–2623. (<a href="https://doi.org/10.1109/TMC.2020.2984261">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Widespread and large-scale WiFi systems have been deployed in many corporate locations, while the backhual capacity becomes the bottleneck in providing high-rate data services to a tremendous number of WiFi users. Mobile edge caching is a promising solution to relieve backhaul pressure and deliver quality services by proactively pushing contents to access points (APs). However, how to deploy cache in large-scale WiFi system is not well studied yet quite challenging since numerous APs can have heterogeneous traffic characteristics, and future traffic conditions are unknown ahead. In this paper, given the cache storage budget, we explore the cache deployment in a large-scale WiFi system, which contains 8,000 APs and serves more than 40,000 active users, to maximize the long-term caching gain. Specifically, we first collect two-month user association records and conduct intensive spatio-temporal analytics on WiFi traffic consumption, gaining two major observations. First, per AP traffic consumption varies in a rather wide range and the proportion of AP distributes evenly within the range, indicating that the cache size should be heterogeneously allocated in accordance to the underlying traffic demands. Second, compared to a single AP, the traffic consumption of a group of APs (clustered by physical locations) is more stable, which means that the short-term traffic statistics can be used to infer the future long-term traffic conditions. We then propose our cache deployment strategy, named LeaD (i.e., Large-scale WiFi Edge cAche Deployment), in which we first cluster large-scale APs into well-sized edge nodes, then conduct the stationary testing on edge level traffic consumption and sample sufficient traffic statistics in order to precisely characterize long-term traffic conditions, and finally devise the TEG (Traffic-wEighted Greedy) algorithm to solve the long-term caching gain maximization problem. Extensive trace-driven experiments are carried out, and the results demonstrate that LeaD is able to achieve the near-optimal caching performance and can outperform other benchmark strategies significantly.},
  archive      = {J_TMC},
  author       = {Feng Lyu and Ju Ren and Nan Cheng and Peng Yang and Minglu Li and Yaoxue Zhang and Xuemin Sherman Shen},
  doi          = {10.1109/TMC.2020.2984261},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {2607-2623},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {LeaD: Large-scale edge cache deployment based on spatio-temporal WiFi traffic statistics},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). How can IoT services pose new security threats in
operational cellular networks? <em>TMC</em>, <em>20</em>(8), 2592–2606.
(<a href="https://doi.org/10.1109/TMC.2020.2984192">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Carriers are rolling out Internet of Things (IoT) services including various IoT devices and use scenarios. Compared with conventional non-IoT devices such as smartphones and tablets, IoT devices have limited network capabilities (e.g., low rates) and specific use scenarios (e.g., inside vehicles only). These specialized use scenarios lead to carries often offering cheaper device access fees for IoT devices. However, the aforementioned disparity of service charging between IoT and non-IoT devices may lead to security issues. In this work, we conduct the first empirical security study on cellular IoT service charging over two major US carriers and make three major contributions. First, we discover four security vulnerabilities and analyze their root causes, which help us identify two significant security threats, IoT masquerading and IoT use scenario abuse. Second, we devise three proof-of-concept attacks and assess their real-world impact. We determine that they can be exploited to allow adversaries to pay 43.75-80.00 percent less for cellular data services. Third, we analyze the challenges in addressing these vulnerabilities and develop an anti-abuse solution to mitigate attack incentives. The solution is standard-compliant and can be used immediately in practice. Our prototype and evaluation confirm its effectiveness.},
  archive      = {J_TMC},
  author       = {Tian Xie and Guan-Hua Tu and Chi-Yu Li and Chunyi Peng},
  doi          = {10.1109/TMC.2020.2984192},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {2592-2606},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {How can IoT services pose new security threats in operational cellular networks?},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploiting multi-dimensional task diversity in distributed
auctions for mobile crowdsensing. <em>TMC</em>, <em>20</em>(8),
2576–2591. (<a href="https://doi.org/10.1109/TMC.2020.2987881">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To promote development of Mobile Crowdsensing Systems (MCSs), numerous auction schemes have been proposed to motivate mobile users&#39; participation. But, task diversity of MCSs has not been fully explored by most existing works. To further exploit task diversity and improve performance of MCSs, in this paper, we investigate the joint problem of sensing task assignment and schedule with considering multi-dimensional task diversity, including partial fulfillment, bilaterally-multi-schedule, attribute diversity, and price diversity. First, task owner-centric auction model is formulated and two distributed auction schemes (CPAS and TPAS) are proposed such that each task owner can locally process auction procedure. Then, mobile user-centric auction model is established and two distributed auction schemes (VPAS and DPAS) are developed to facilitate local auction implementation. These four auction schemes differ in their approaches to determine winners and compute payments. We further rigorously prove that all the four auction schemes (CPAS, TPAS, VPAS, and DPAS) are computationally-efficient, individually-rational, and incentive-compatible and that both CPAS and TPAS are budget-feasible. Finally, we comprehensively evaluate the effectiveness of CPAS, TPAS, VPAS, and DPAS via comparing with the state-of-the-art in real-data experiments.},
  archive      = {J_TMC},
  author       = {Zhipeng Cai and Zhuojun Duan and Wei Li},
  doi          = {10.1109/TMC.2020.2987881},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {2576-2591},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Exploiting multi-dimensional task diversity in distributed auctions for mobile crowdsensing},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DynamicSLAM: Leveraging human anchors for ubiquitous
low-overhead indoor localization. <em>TMC</em>, <em>20</em>(8),
2563–2575. (<a href="https://doi.org/10.1109/TMC.2020.2984320">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present DynamicSLAM: an indoor localization technique that eliminates the need for the daunting calibration step. DynamicSLAM is a novel Simultaneous Localization And Mapping (SLAM) framework that iteratively acquires the feature map of the environment while simultaneously localizing users relative to this map. Specifically, we employ the phone inertial sensors to keep track of the user&#39;s path. To compensate for the error accumulation due to the low-cost inertial sensors, DynamicSLAM leverages unique points in the environment (anchors) as observations to reduce the estimated location error. DynamicSLAM introduces the novel concept of mobile human anchors that are based on the encounters with other users in the environment, significantly increasing the number and ubiquity of anchors and boosting localization accuracy. We present different encounter models and show how they are incorporated in a unified probabilistic framework to reduce the ambiguity in the user location. Furthermore, we present a theoretical proof for system convergence and the human anchors ability to reset the accumulated error. Evaluation of DynamicSLAM using different Android phones shows that it can provide a localization accuracy with a median of 1.1m. This accuracy outperforms the state-of-the-art techniques by 55 percent, highlighting DynamicSLAM promise for ubiquitous indoor localization.},
  archive      = {J_TMC},
  author       = {Ahmed Shokry and Moustafa Elhamshary and Moustafa Youssef},
  doi          = {10.1109/TMC.2020.2984320},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {2563-2575},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {DynamicSLAM: Leveraging human anchors for ubiquitous low-overhead indoor localization},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distributed online learning of cooperative caching in edge
cloud. <em>TMC</em>, <em>20</em>(8), 2550–2562. (<a
href="https://doi.org/10.1109/TMC.2020.2983924">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cooperative caching can unify storage across edge clouds and provide efficient delivery of popular contents under effective content placement. However, the placement and delivery are non-trivial in cooperative caching due to the decentralized property of edge clouds, as well as the temporal and spatial correlation of the placement. We propose a new distributed online learning approach to jointly optimize content placement and delivery without the a-priori knowledge on file popularity and link availability. Content placement and delivery can be asymptotically optimized in real-time by running distributed online learning at individual edge servers by exploiting stochastic gradient descent (SGD). The proposed approach can allow operations at different timescales by integrating mini-batch learning for farsighted content placement. The optimality loss, stemming from the different timescales, can asymptotically reduce, as the SGD stepsize declines. Simulations confirm that the proposed approach outperforms existing techniques in terms of cache hit ratio and cost effectiveness. Insights are shed on the optimal placement of popular contents.},
  archive      = {J_TMC},
  author       = {Xinchen Lyu and Chenshan Ren and Wei Ni and Hui Tian and Ren Ping Liu and Xiaofeng Tao},
  doi          = {10.1109/TMC.2020.2983924},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {2550-2562},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Distributed online learning of cooperative caching in edge cloud},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An approximation algorithm for bounded task assignment
problem in spatial crowdsourcing. <em>TMC</em>, <em>20</em>(8),
2536–2549. (<a href="https://doi.org/10.1109/TMC.2020.2984380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatial crowdsourcing, a human-centric compelling paradigm in performing spatial tasks, has drawn rising attention. Task assignment is of paramount importance in spatial crowdsourcing. Existing studies often use heuristics of various kinds to solve task assignment problems. These schemes usually only apply some specific cases, once the environment changes, the efficiency of the algorithms is significantly reduced. In this paper, we first introduce a taxonomy of task assignment in spatial crowdsourcing. Next, we design an approximation algorithm and get an efficient solution for the important problem, namely, Bounded and Heterogeneous Task Assignment (BHTA), such that the sum of the rewards of workers is maximized subject to multiple constraints. We prove that the BHTA problem is NP-hard. Subsequently, we propose a constant-ratio approximation algorithm based on partition and shifting method to achieve the assignment solution. To meet with the workers&#39; dynamism, we further devise a greedy algorithm and provide theoretical guarantee. Experiments on synthetic and real datasets demonstrate the efficiency of our strategy over previous methods. So far as we know, this paper is the first attempt to give a constant-ratio approximation for such task assignment problems in spatial crowdsourcing.},
  archive      = {J_TMC},
  author       = {Shahzad Sarwar Bhatti and Jiahao Fan and Kangrui Wang and Xiaofeng Gao and Fan Wu and Guihai Chen},
  doi          = {10.1109/TMC.2020.2984380},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {2536-2549},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {An approximation algorithm for bounded task assignment problem in spatial crowdsourcing},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive predictive power management for mobile LTE devices.
<em>TMC</em>, <em>20</em>(8), 2518–2535. (<a
href="https://doi.org/10.1109/TMC.2020.2988651">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reducing the energy consumption of mobile phones is a crucial design goal for cellular modem solutions for LTE and 5G NR standards. Most dynamic power management techniques targeting mobile devices proposed so far, however, are purely reactive in powering down and up system components. Promising approaches extend this, by predicting information from the cell and the communication protocol to take decisions proactively. In this paper, we present a complete proactive power management approach for the modem based on on-line grant prediction. In this context, we define proactive policies that allow a mobile device to go to sleep states more often compared to reactive power management systems, e.g., in time slots of predicted transmission inactivity in a cell. Furthermore, we propose and compare two algorithmic solutions to this proactive grant prediction problem, one a feed-forward neural network and one a SARSA-λ reinforcement agent. As the implementation of these machine learning techniques also creates additional energy and resource costs, both approaches are carefully designed, optimized, and evaluated not only in terms of prediction accuracy, but also in terms of overall energy savings. Notably, our predictor implementations are able to achieve up to 17 percent in overall energy savings on real-world traces.},
  archive      = {J_TMC},
  author       = {Peter Brand and Joachim Falk and Jonathan Ah Sue and Johannes Brendel and Ralph Hasholzner and Jürgen Teich},
  doi          = {10.1109/TMC.2020.2988651},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {2518-2535},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Adaptive predictive power management for mobile LTE devices},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). UniLoc: A unified mobile localization framework exploiting
scheme diversity. <em>TMC</em>, <em>20</em>(7), 2505–2517. (<a
href="https://doi.org/10.1109/TMC.2020.2979857">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current localization schemes on mobile devices are experiencing great diversity that is mainly shown in two aspects: the large number of available localization schemes and their diverse performance. This paper presents UniLoc, a unified framework that gains improved performance from multiple localization schemes by exploiting their diversity. UniLoc predicts the localization error of each scheme online based on an error model and real-time context. It further combines the results of all available schemes based on the error prediction results and an ensemble learning algorithm. The combined result is more accurate than any individual schemes. With the flexible design of error modeling and ensemble learning, UniLoc can easily integrate a new localization scheme. The energy consumption of UniLoc is low, since its computation, including both error prediction and ensemble learning, only involves simple linear calculation. Our experience with extensive experiments tells that such easy aggregation incurs little overhead in integrating and training a localization scheme, but gains substantially from the scheme diversity. UniLoc outperforms individual localization schemes by 1.6× in a variety of environments, including &gt; 89% new places where we did not train the error models.},
  archive      = {J_TMC},
  author       = {Wan Du and Panrong Tong and Mo Li},
  doi          = {10.1109/TMC.2020.2979857},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {2505-2517},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {UniLoc: A unified mobile localization framework exploiting scheme diversity},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SmartSO: Chinese character and stroke order recognition with
smartwatch. <em>TMC</em>, <em>20</em>(7), 2490–2504. (<a
href="https://doi.org/10.1109/TMC.2020.2980842">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Following the correct stroke order while writing Chinese characters composed of strokes plays an important role in handwriting efficiency and quality, especially for early education. Most existing systems use image processing techniques for character and stroke order recognition, which is sensitive to lighting conditions. In this paper, we present the design, implementation and evaluation of SmartSO, which utilizes the inertial sensors of an off-the-shelf smartwatch for Chinese character and stroke order recognition. SmartSo first identifies the Chinese character written by the user, based on which SmartSo decides whether the stroke order is written correctly to help improve users&#39; writing behavior. The biggest challenge for stroke order recognition is that some Chinese characters have repeated strokes (strokes of the same type), e.g., with two same horizontal strokes, and it is challenging to differentiate the writing order of such strokes given only the detected stroke composition (number and type of strokes). To mitigate this problem, we further analyze the hand movement between two adjacent strokes (referred to as direction motion) and propose a novel algorithm to recognize stroke order based on direction motion information. Finally, we build a fully functional prototype of SmartSO, and extensive experiments confirm its effectiveness and robustness.},
  archive      = {J_TMC},
  author       = {Jian Zhang and Hongliang Bi and Yanjiao Chen and Qian Zhang and Zhaoyuan Fu and Yunzhe Li and Zeyu Li},
  doi          = {10.1109/TMC.2020.2980842},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {2490-2504},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {SmartSO: Chinese character and stroke order recognition with smartwatch},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Scalable &amp; resilient vehicle-centric certificate
revocation list distribution in vehicular communication systems.
<em>TMC</em>, <em>20</em>(7), 2473–2489. (<a
href="https://doi.org/10.1109/TMC.2020.2981887">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In spite of progress in securing vehicular communication (VC) systems, there is no consensus on how to distribute certificate revocation lists (CRLs). The main challenges lie exactly in (i) crafting an efficient and timely distribution of CRLs for numerous anonymous credentials, pseudonyms, (ii) maintaining strong privacy for vehicles prior to revocation events, even with honest-but-curious system entities, (iii) and catering to computation and communication constraints of on-board units with intermittent connectivity to the infrastructure. Relying on peers to distribute the CRLs is a double-edged sword: abusive peers could “pollute” the process, thus degrading the timely CRLs distribution. In this paper, we propose a vehicle-centric solution that addresses all these challenges and thus closes a gap in the literature. Our scheme radically reduces CRL distribution overhead: each vehicle receives CRLs corresponding only to its region of operation and its actual trip duration. Moreover, a “fingerprint” of CRL `pieces&#39; is attached to a subset of (verifiable) pseudonyms for fast CRL `piece&#39; validation (while mitigating resource depletion attacks abusing the CRL distribution). Our experimental evaluation shows that our scheme is efficient, scalable, dependable, and practical: with no more than 25 KB/s of traffic load, the latest CRL can be delivered to 95 percent of the vehicles in a region (15×15 KM) within 15s, i.e., more than 40 times faster than the state-of-the-art. Overall, our scheme is a comprehensive solution that complements standards and can catalyze the deployment of secure and privacy-protecting VC systems.},
  archive      = {J_TMC},
  author       = {Mohammad Khodaei and Panos Papadimitratos},
  doi          = {10.1109/TMC.2020.2981887},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {2473-2489},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Scalable &amp; resilient vehicle-centric certificate revocation list distribution in vehicular communication systems},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Predictability and prediction of human mobility based on
application-collected location data. <em>TMC</em>, <em>20</em>(7),
2457–2472. (<a href="https://doi.org/10.1109/TMC.2020.2981441">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the modern information society, analysis of human mobility becomes increasingly essential in various areas such as city planning and resource management. With users’ historical trajectories, the inherent patterns of their movements can be extracted and utilized to accurately predict the future movements. Plenty of previous work adopted traditional Markov model, which suffers when the trajectory becomes sparse or it shows distinct mobility patterns in different time of day. In this paper, based on an app-collected dataset of 100,000 individuals’ actively uploaded location information, we comprehensively analyze the mobility and predictability of each user. To approach the theoretical predictability and overcome the shortcomings of traditional Markov model, we propose a time-variant Markov model based on Gibbs sampling for mobility prediction. Specifically, we model human mobility as several interconnected Markov chains, each chain corresponds to a movement pattern of a period of time. Then, we adopt Gibbs sampling method to simultaneously recover the missing part of trajectories and train the Markov chains, in order to solve the unevenly distribution and the high missing rate. Results show that our prediction algorithm can achieve 11.2 percent higher prediction accuracy than the benchmark method, especially on sparse trajectories. In addition, we discover a high correlation between prediction accuracy and predictability, with correlation coefficient reaching 0.81. Finally, we investigate various factors including spatial and temporal resolution, orders of Markov models, and radius of gyration, in order to further explore the predictability under different circumstances.},
  archive      = {J_TMC},
  author       = {Huandong Wang and Sihan Zeng and Yong Li and Depeng Jin},
  doi          = {10.1109/TMC.2020.2981441},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {2457-2472},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Predictability and prediction of human mobility based on application-collected location data},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Outage in motorway multi-lane VANETs with hardcore headway
distance using synthetic traces. <em>TMC</em>, <em>20</em>(7),
2445–2456. (<a href="https://doi.org/10.1109/TMC.2020.2980232">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we analyze synthetic mobility traces generated for three-lane unidirectional motorway traffic to find that the locations of vehicles along a lane are better modeled by a hardcore point process instead of the widely-accepted Poisson point process (PPP). In order to capture the repulsion between successive vehicles while maintaining a level of analytical tractability, we make a simple extension to PPP: We model the inter-vehicle distance along a lane equal to the sum of a constant hardcore distance and an exponentially distributed random variable. We calculate the J-function and the Ripley’s K-function for this hardcore point process. We fit its parameters to the available traces, and we illustrate that the higher the average speed along a lane, the more prominent the hardcore component becomes. In addition, we consider a transmitter-receiver link on the same lane, and we generate simple formulae for the moments of interference under reduced Palm measure for that lane, and without conditioning for other lanes. We illustrate that under Rayleigh fading a shifted-gamma approximation for the distribution of interference per lane provides a very good fit to the simulated outage probability using the synthetic traces, while the fit using the PPP is poor.},
  archive      = {J_TMC},
  author       = {Konstantinos Koufos and Carl P. Dettmann},
  doi          = {10.1109/TMC.2020.2980232},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {2445-2456},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Outage in motorway multi-lane VANETs with hardcore headway distance using synthetic traces},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-area throughput and energy optimization of UAV-aided
cellular networks powered by solar panels and grid. <em>TMC</em>,
<em>20</em>(7), 2427–2444. (<a
href="https://doi.org/10.1109/TMC.2020.2980834">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Small cells (SCs) mounted on top of Unmanned Aerial Vehicles (UAVs) can be used to boost the radio capacity in hotspot zones. However, UAV-SCs are subject to tight battery constraints, resulting in frequent recharges operated at the ground sites. To meet the UAV-SCs energy demanded to the ground sites, the operator leverages a set of Solar Panels (SPs) and grid connection. In this work, we demonstrate that both i) the level of throughput provided to a set of areas and ii) the amount of energy that is exchanged with the grid by the ground sites play a critical role in such UAV-aided cellular network. We then formulate the J-MATE model to jointly optimize the energy and throughput through revenue and cost components. In addition, we design the BBSR algorithm, which is able to retrieve a solution even for large problem instances. We evaluate J-MATE and BBSR over a realistic scenario composed of dozens of areas and multiple ground sites, showing that: i) both J-MATE and BBSR outperform previous approaches targeting either the throughput maximization or the energy minimization, and ii) the computation time and the memory occupation of BBSR are reduced up to five orders of magnitude compared to J-MATE .},
  archive      = {J_TMC},
  author       = {Luca Chiaraviglio and Fabio D’Andreagiovanni and William Liu and Jairo A. Gutierrez and Nicola Blefari-Melazzi and Kim-Kwang Raymond Choo and Mohamed-Slim Alouini},
  doi          = {10.1109/TMC.2020.2980834},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {2427-2444},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Multi-area throughput and energy optimization of UAV-aided cellular networks powered by solar panels and grid},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Low-latency data aggregation scheduling for cognitive radio
networks with non-predetermined structure. <em>TMC</em>, <em>20</em>(7),
2412–2426. (<a href="https://doi.org/10.1109/TMC.2020.2979710">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data aggregation is a fundamental yet popular operation in wireless networks where the sink needs to obtain the combined information of the whole network. However, the problem of minimum latency aggregation scheduling (MLAS) is not well studied in cognitive radio networks. Few studies have addressed this issue and most previous aggregation methods all assume that a fixed-structure based aggregation tree is constructed in advance, which may result in the selection of a node with limited spectrum opportunities as the parent by many nodes and by extension results in a large latency. Thus, the MLAS problem in cognitive radio networks (MLAS-CR) without the above limitation is investigated in this paper. First, the MLAS-CR problem with primary social behaviors where the activity of primary users can be predicted is studied. To make full use of the limited spectrum opportunities, we integrate the construction of the aggregation tree, and the computation of a conflict-free schedule simultaneously, without any predetermined structures. Second, the MLAS-CR problem without the above assumption is also investigated. To reduce the latency, a two-way aggregation scheduling method is proposed to adaptively choose the parent with only current channel information. To further reduce the latency, we also introduce a new data aggregation mode for CRN, i.e., Data Aggregation Scheduling in The Dark, to utilize the spectrum opportunities of scheduled nodes. Finally, the theoretical analysis and simulation results verify that the proposed algorithms have high performance in terms of latency.},
  archive      = {J_TMC},
  author       = {Quan Chen and Zhipeng Cai and Lianglun Cheng and Hong Gao},
  doi          = {10.1109/TMC.2020.2979710},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {2412-2426},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Low-latency data aggregation scheduling for cognitive radio networks with non-predetermined structure},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Joint modeling of TDD and decoupled uplink/downlink access
in 5G HetNets with multiple small cells deployment. <em>TMC</em>,
<em>20</em>(7), 2395–2411. (<a
href="https://doi.org/10.1109/TMC.2020.2979447">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to highly variant traffic in downlink (DL) and uplink (UL) in heterogeneous networks (HetNets), dynamic time-division duplexing (TDD) is proposed to dynamically allocate UL and DL resources. Under the same circumstances, downlink and uplink decoupled access (DUDA) is introduced to balance between UL and DL transmissions and to further improve the system performance. Rather than belonging to a specific cell, a mobile user can receive the downlink traffic from one base station (BS) and send uplink traffic through another BS. In this article, we analytically investigate a joint TDD and DUDA statistical model with multiple small cells deployment. This model is based on a geometric probability approach. Taking all possible TDD subframes combinations between the macro and small cells, coupled and decoupled cell associations strategies are investigated in details. We derive analytical expressions for the capacity and the interference, considering a network of one macro cell and multiple small cells. We build on the derived capacity expressions to measure the decoupling gain and thus, identify the location of the interferer small cell where the decoupled mode maintains a higher gain in both DL and UL. Monte-Carlo simulations results are presented to validate the accuracy of the statistical model.},
  archive      = {J_TMC},
  author       = {Bachir Lahad and Marc Ibrahim and Samer Lahoud and Kinda Khawam and Steven Martin},
  doi          = {10.1109/TMC.2020.2979447},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {2395-2411},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Joint modeling of TDD and decoupled Uplink/Downlink access in 5G HetNets with multiple small cells deployment},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generalized lottery trees: Budget-balanced incentive tree
mechanisms for crowdsourcing. <em>TMC</em>, <em>20</em>(7), 2379–2394.
(<a href="https://doi.org/10.1109/TMC.2020.2979459">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incentive mechanism design has aroused extensive attention for crowdsourcing applications in recent years. Most research assumes that participants are already in the system and aware of the existence of crowdsourcing tasks. Whereas in real-life scenarios without this assumption, it is more effective to leverage incentive tree mechanisms that incentivize both users&#39; direct contributions and solicitations to other users. Although such mechanisms have been investigated, we are the first to propose budget-balanced incentive tree mechanisms, called generalized lottrees, which require the total payout to be equal to the announced budget, while guaranteeing several desirable properties including continuing contribution incentive, continuing solicitation incentive, value proportional to contribution, unprofitable solicitor bypassing, and unprofitable Sybil attack. Moreover, three types of generalized lottree mechanisms, 1-Pachira, K-Pachira and Sharing-Pachira, are presented for supporting diversified requirements. A solid theoretical guideline on the mechanism selection is provided based on the Cumulative Prospect Theory. Both extensive simulations and realistic experiments with 82 users are conducted to confirm our theoretical analysis.},
  archive      = {J_TMC},
  author       = {Dong Zhao and Huadong Ma and Xinna Ji},
  doi          = {10.1109/TMC.2020.2979459},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {2379-2394},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Generalized lottery trees: Budget-balanced incentive tree mechanisms for crowdsourcing},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fine-grained frequency reuse in centralized small cell
networks. <em>TMC</em>, <em>20</em>(7), 2367–2378. (<a
href="https://doi.org/10.1109/TMC.2020.2981032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interference management for Small Cell (SC) networks has drawn great attention from both academia and industry due to its importance in Long-Term Evolution (LTE) and emerging 5G networks. Although various approaches have been proposed in the literature, many of them face practical limitations such as showing gains only in specific scenarios, relying on ideal fronthaul, or becoming computationally intractable as the network size increases. In this paper, a novel framework is proposed for interference management in centralized SC networks by jointly utilizing graph theory and optimization theory. It extends the classic center-edge frequency reuse schemes into a more fine-grained scale, thus capturing the complex interference relationships in SC networks. The cell-level resource partition can be semi-statically updated according to the traffic dynamics while existing Medium Access Control (MAC) schedulers can be used for subframe-level resource allocation, not requiring fiber fronthaul. LTE system-level simulation results show that the proposed scheme can significantly improve both cell edge and mean user throughput with practical complexity.},
  archive      = {J_TMC},
  author       = {Tao Guo and Alberto Suárez},
  doi          = {10.1109/TMC.2020.2981032},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {2367-2378},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Fine-grained frequency reuse in centralized small cell networks},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploiting interference fingerprints for predictable
wireless concurrency. <em>TMC</em>, <em>20</em>(7), 2354–2366. (<a
href="https://doi.org/10.1109/TMC.2020.2978205">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Operating in unlicensed ISM bands, ZigBee devices often yield poor performance due to the interference from ever increasing wireless devices in the 2.4 GHz band. Our empirical results show that, a specific interference is likely to have different influence on different outbound links of a ZigBee sender, which indicates the chance of concurrent transmissions. Based on this insight, we propose Smoggy-Link, a practical protocol to exploit the potential concurrency for adaptive ZigBee transmissions under harsh interference. Smoggy-Link maintains an accurate link model to quantify and trace the relationship between interference and link qualities of the sender&#39;s outbound links. With such a link model, Smoggy-Link can translate low-cost interference information to the fine-grained spatiotemporal link state. The link information is further utilized for adaptive link selection and intelligent transmission schedule. We implement and evaluate a prototype of our approach with TinyOS and TelosB motes. The evaluation results show that Smoggy-Link has consistent improvements in both throughput and packet reception ratio under interference from various interferers.},
  archive      = {J_TMC},
  author       = {Meng Jin and Yuan He and Xiaolong Zheng and Dingyi Fang and Dan Xu and Tianzhang Xing and Xiaojiang Chen},
  doi          = {10.1109/TMC.2020.2978205},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {2354-2366},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Exploiting interference fingerprints for predictable wireless concurrency},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). EPASS360: QoE-aware 360-degree video streaming over mobile
devices. <em>TMC</em>, <em>20</em>(7), 2338–2353. (<a
href="https://doi.org/10.1109/TMC.2020.2978187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The 360-degree video streaming system delivers a monocular panoramic video surrounding the user, and the user can change the viewing direction of mobile devices to see different parts of the video through the “viewport”. Due to the limited network bandwidth, playbacks of high-resolution 360-degree videos often suffer from rebuffering, while too much bandwidth is wasted in delivering those out-of-viewport parts that the user never watches. In this article, we present an Ensemble Prediction and Allocation based Streaming System, named as EPASS360, for delivering high Quality of Experience (QoE) 360-degree videos. The prediction model takes advantages of ensemble learning, providing high accuracy on the prediction of viewports. The allocation model divides a video into tiles, and allocates high resolution to tiles where a user&#39;s viewpoint may appear in the future by solving the QoE-aware optimization problem. Trace-driven emulation on real-world datasets shows that EPASS360 enhances the QoE in various scenarios compared to state-of-the-art streaming approaches. Experiments on the head-mounted device and the hand-held device over real-world Internet confirm the high user experience of EPASS360.},
  archive      = {J_TMC},
  author       = {Yuanxing Zhang and Yushuo Guan and Kaigui Bian and Yunxin Liu and Hu Tuo and Lingyang Song and Xiaoming Li},
  doi          = {10.1109/TMC.2020.2978187},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {2338-2353},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {EPASS360: QoE-aware 360-degree video streaming over mobile devices},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Channel condition based dynamic beacon interval for faster
formation of 6TiSCH network. <em>TMC</em>, <em>20</em>(7), 2326–2337.
(<a href="https://doi.org/10.1109/TMC.2020.2980828">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial applications of Internet of Things (IoT) demand high reliability, deterministic latency, and high scalability with energy efficiency to the communication and networking protocols. 6TiSCH is a time slotted channel hopping (TSCH) medium access control (MAC) protocol running under the IPv6 enabled higher layer protocols for industrial IoT (IIoT). In this paper, we theoretically analyze the network formation protocol in 6TiSCH network. Analysis reveals that the performance of the 6TiSCH network degrades when a pledge (new node) joins as it increases channel congestion by allowing to transmit beacon message. On the other hand, beacon transmission is essential to expand or reorganize the present network topology. To overcome this performance tradeoff, a channel condition based dynamic beacon interval (C2DBI) scheme is proposed in which beacon transmission interval varies with channel congestion status during network formation. Channel congestion status is estimated by each joined node in distributed manner, and subsequently changes its beacon generation interval to best fit with present condition. Finally the performance of C2DBI is compared with the minimal configuration standard and few other benchmark protocols. Analytical, simulation and real testbed results show that the proposed scheme outperforms the state of the art protocols in terms of joining time and energy consumption during network formation.},
  archive      = {J_TMC},
  author       = {Alakesh Kalita and Manas Khatua},
  doi          = {10.1109/TMC.2020.2980828},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {2326-2337},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Channel condition based dynamic beacon interval for faster formation of 6TiSCH network},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unobtrusive stress assessment using smartphones.
<em>TMC</em>, <em>20</em>(6), 2313–2325. (<a
href="https://doi.org/10.1109/TMC.2020.2974834">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stress assessment is a complex issue and numerous studies have examined factors that influence stress in working environments. Research studies have shown that monitoring individuals&#39; behaviour parameters during daily life can also help assess stress levels. In this study, we examine assessment of work-related stress using features derived from sensors in smartphones. In particular, we use information from physical activity levels, location, social-interactions, social-activity, and application usage during working days. Our study included 30 employees chosen from two different private companies, monitored over a period of 8 weeks in real work environments. The findings suggest that information from phone sensors shows important correlation with employees perceived stress level. Second, we used machine learning methods to classify perceived stress levels based on the analysis of information provided by smartphones. We used decision trees obtaining 67.57 percent accuracy and 71.73 percent after applying a semi-supervised method. Our results show that stress levels can be monitored in unobtrusive manner, through analysis of smartphone data.},
  archive      = {J_TMC},
  author       = {Alban Maxhuni and Pablo Hernandez-Leal and Eduardo F. Morales and L. Enrique Sucar and Venet Osmani and Oscar Mayora},
  doi          = {10.1109/TMC.2020.2974834},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {2313-2325},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Unobtrusive stress assessment using smartphones},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PROTECT: Efficient password-based threshold single-sign-on
authentication for mobile users against perpetual leakage. <em>TMC</em>,
<em>20</em>(6), 2297–2312. (<a
href="https://doi.org/10.1109/TMC.2020.2975792">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Password-based single-sign-on authentication has been widely applied in mobile environments. It enables an identity server to issue authentication tokens to mobile users holding correct passwords. With an authentication token, one can request mobile services from related service providers without multiple registrations. However, if an adversary compromises the identity server, he can retrieve users&#39; passwords by performing dictionary guessing attacks (DGA) and can overissue authentication tokens to break the security. In this paper, we propose a password-based threshold single-sign-on authentication scheme dubbed PROTECT that thwarts adversaries who can compromise identity server(s), where multiple identity servers are introduced to authenticate mobile users and issue authentication tokens in a threshold way. PROTECT supports key renewal that periodically updates the secret on each identity server to resist perpetual leakage of the secret. Furthermore, PROTECT is secure against off-line DGA: a credential used to authenticate a user is computed from the password and a server-side key. PROTECT is also resistant to online DGA and password testing attacks in an efficient way. We conduct a comprehensive performance evaluation of PROTECT, which demonstrates the high efficiency on the user side in terms of computation and communication and proves that it can be easily deployed on mobile devices.},
  archive      = {J_TMC},
  author       = {Yuan Zhang and Chunxiang Xu and Hongwei Li and Kan Yang and Nan Cheng and Xuemin Shen},
  doi          = {10.1109/TMC.2020.2975792},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {2297-2312},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {PROTECT: Efficient password-based threshold single-sign-on authentication for mobile users against perpetual leakage},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Power saving and secure text input for commodity smart
watches. <em>TMC</em>, <em>20</em>(6), 2281–2296. (<a
href="https://doi.org/10.1109/TMC.2020.2976007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart wristband has become a dominant device in the wearable ecosystem, providing versatile functions such as fitness tracking, mobile payment, and transport ticketing. However, the small form-factor, low-profile hardware interfaces and computational resources limit their capabilities in security checking. Many wristband devices have recently witnessed alarming vulnerabilities, e.g., personal data leakage and payment fraud, due to the lack of authentication and access control. To fill this gap, we propose a secure text pin input system, namely Taprint, which extends a virtual number pad on the back of a user&#39;s hand. Taprint builds on the key observation that the hand “landmarks”, especially finger knuckles, bear unique vibration characteristics when being tapped by the user herself. It thus uses the tapping vibrometry as biometrics to authenticate the user, while distinguishing the tapping locations. Taprint reuses the inertial measurement unit in the wristband, “overclocks” its sampling rate with the cubic spline interpolation to extrapolate fine-grained features, and further refines the features to enhance the uniqueness and reliability. Extensive experiments on 128 users demonstrate that Taprint achieves a high accuracy (96 percent) of keystrokes recognition. It can authenticate users, even through a single-tap, at extremely low error rate (2.2 percent), and under various practical usage disturbances.},
  archive      = {J_TMC},
  author       = {Kaishun Wu and Yandao Huang and Wenqiang Chen and Lin Chen and Xinyu Zhang and Lu Wang and Rukhsana Ruby},
  doi          = {10.1109/TMC.2020.2976007},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {2281-2296},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Power saving and secure text input for commodity smart watches},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimizing information freshness in wireless networks: A
stochastic geometry approach. <em>TMC</em>, <em>20</em>(6), 2269–2280.
(<a href="https://doi.org/10.1109/TMC.2020.2977010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimization of information freshness in wireless networks has usually been performed based on queueing analysis that captures only the temporal traffic dynamics associated with the transmitters and receivers. However, the effect of interference, which is mainly dominated by the interferers&#39; geographic locations, is not well understood. In this paper, we leverage a spatiotemporal model, which allows one to characterize the age of information (AoI) from a joint queueing-geometry perspective, for the design of a decentralized scheduling policy that exploits local observation to make transmission decisions that minimize the AoI. To quantify the performance, we also derive accurate and tractable expressions for the peak AoI. Numerical results reveal that: i) the packet arrival rate directly affects the service process due to queueing interactions, ii) the proposed scheme can adapt to traffic variations and largely reduce the peak AoI, and iii) the proposed scheme scales well as the network grows in size. This is done by adaptively adjusting the radio access probability at each transmitter to the change of the ambient environment.},
  archive      = {J_TMC},
  author       = {Howard H. Yang and Ahmed Arafa and Tony Q. S. Quek and H. Vincent Poor},
  doi          = {10.1109/TMC.2020.2977010},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {2269-2280},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Optimizing information freshness in wireless networks: A stochastic geometry approach},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the capacity of fractal D2D social networks with
hierarchical communications. <em>TMC</em>, <em>20</em>(6), 2254–2268.
(<a href="https://doi.org/10.1109/TMC.2020.2975783">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The maximum capacity of fractal D2D (device-to-device) social networks with both direct and hierarchical communications is studied in this paper. Specifically, the fractal networks are characterized by the direct social connection and the self-similarity. First, for a fractal D2D social network with direct social communications, it is proved that the maximum capacity is &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$ \Theta (\frac{1}{\sqrt{n\,\log n}})$&lt;/tex-math&gt; &lt;/inline-formula&gt; if a user communicates with one of his/her direct contacts randomly, where &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$ n$&lt;/tex-math&gt; &lt;/inline-formula&gt; denotes the total number of users in the network, and it can reach up to &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$ \Theta (\frac{1}{\log n})$&lt;/tex-math&gt; &lt;/inline-formula&gt; if any pair of social contacts with distance &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$ d$&lt;/tex-math&gt; &lt;/inline-formula&gt; communicate according to the probability in proportion to &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$ d^{-\beta }$&lt;/tex-math&gt; &lt;/inline-formula&gt; . Second, since users might get in touch with others without direct social connections through the inter-connected multiple users, the fractal D2D social network with these hierarchical communications is studied as well, and the related capacity is further derived. Our results show that this capacity is mainly affected by the correlation exponent &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\epsilon$&lt;/tex-math&gt; &lt;/inline-formula&gt; of the fractal structure. The capacity is reduced in proportional to &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$ \frac{1}{{\log n}}$&lt;/tex-math&gt; &lt;/inline-formula&gt; if &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$ 2&amp;lt;\epsilon &amp;lt;3$&lt;/tex-math&gt; &lt;/inline-formula&gt; , while the reduction coefficient is &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$ \frac{1}{n}$&lt;/tex-math&gt; &lt;/inline-formula&gt; if &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$ \epsilon &amp;gt;3$&lt;/tex-math&gt; &lt;/inline-formula&gt; .},
  archive      = {J_TMC},
  author       = {Ying Chen and Rongpeng Li and Zhifeng Zhao and Honggang Zhang},
  doi          = {10.1109/TMC.2020.2975783},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {2254-2268},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {On the capacity of fractal D2D social networks with hierarchical communications},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). NOMA-based scalable video multicast in mobile networks with
statistical channels. <em>TMC</em>, <em>20</em>(6), 2238–2253. (<a
href="https://doi.org/10.1109/TMC.2020.2977639">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To cope with rapid growth of video services, we propose a non-orthogonal multiple access (NOMA) based scalable video multicast (NOMA-SVM) framework for mobile networks, by exploiting NOMA&#39;s specific potential in scalable video multicast transmission. We consider statistical channels, instead of channels with perfect estimation, in the proposed NOMA-SVM framework in order to capture the realistic channel behaviors. As quality of experience (QoE) is a better metric than throughput for video transmission, QoE-driven power allocation is performed among multiple video layers in the proposed NOMA-SVM framework, in which users can decode video with quality proportional to their channel conditions. Specifically, we formulate the power allocation problem with the goal to maximize the average QoE over all users while guaranteeing the basic services of these users. To solve such a non-convex discrete problem, an optimal algorithm is developed based on the hidden monotonicity of the problem. A suboptimal algorithm is also proposed with much lower complexity in order to meet the practical needs. Simulation results show that the proposed algorithms outperform existing orthogonal multiple access (OMA) and NOMA based algorithms under various multicast scenarios in terms of QoE.},
  archive      = {J_TMC},
  author       = {Ming Zhang and Hancheng Lu and Feng Wu and Chang Wen Chen},
  doi          = {10.1109/TMC.2020.2977639},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {2238-2253},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {NOMA-based scalable video multicast in mobile networks with statistical channels},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-adversarial in-car activity recognition using RFIDs.
<em>TMC</em>, <em>20</em>(6), 2224–2237. (<a
href="https://doi.org/10.1109/TMC.2020.2977902">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In-car human activity recognition opens a new opportunity toward intelligent driving behavior detection and touchless human-car interaction. Among the many sensing technologies (e.g., using cameras and wearable sensors), radio frequency identification (RFID) exhibits unique advantages given its low cost, easy deployment, and less privacy concerns. Existing RFID-based solutions for activity recognition are mostly confined to working in stable indoor spaces. The inside space of a car however is much more compact and complex, not to mention the fast-changing driving conditions. All these introduce non-negligible noises that pollute the activity-related information, and the existence of various car models in the market further complicates the problem. In this article, we for the first time closely examine the distinct factors that affect the RFID-based in-car activity recognition. We present RF-CAR, a novel RFID-based tag-free solution that well adapts to different in-car environments. RF-CAR smartly filters the domain-specific features in RF signals and retains activity-related features to the maximum extent. It then integrates a deep learning architecture and an advanced multi-adversarial domain adaptation network for training and prediction. With only one-time pre-training, RF-CAR can adapt to new data domains such as new driving conditions, car models, and human subjects for robust activity recognition. We also demonstrate that it is readily deployable in cars with commercial off-the-shelf (COTS) RFID devices. Our extensive experiments suggest that RF-CAR achieves an overall recognition accuracy of around 95 percent, which significantly outperforms the state-of-the-art solutions.},
  archive      = {J_TMC},
  author       = {Fangxin Wang and Jiangchuan Liu and Wei Gong},
  doi          = {10.1109/TMC.2020.2977902},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {2224-2237},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Multi-adversarial in-car activity recognition using RFIDs},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interference management and duplex mode selection in in-band
full duplex D2D communications: A stochastic geometry approach.
<em>TMC</em>, <em>20</em>(6), 2212–2223. (<a
href="https://doi.org/10.1109/TMC.2020.2977899">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we present a new approach for managing the interference on cellular users through optimum mode selection between half-duplex (HD) and in-band full-duplex (IBFD) in such a way that device-to-device (D2D) throughput is maximized, while the quality of service (QoS) of the cellular users is guaranteed in terms of delay. To present a comprehensive view and analyse of the proposed approach in a large network, we use Poisson point process that enables us to model a large network with random parameters in such a way that is highly compatible with reality. Also, to model the cellular users&#39; delay, we use the queuing theory and Markov processes. Unlike other related works, the mode selection between HD and IBFD is considered as a decision variable and its optimal value is obtained. The results show that in comparison with the related works, our proposed approach leads to improvements in the D2D throughput, while through proper interference management, the impact on the cellular users&#39; throughput is negligible. Moreover, the QoS of the cellular users is guaranteed by keeping the delay below a certain threshold.},
  archive      = {J_TMC},
  author       = {Simin Badri and Mehdi Rasti},
  doi          = {10.1109/TMC.2020.2977899},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {2212-2223},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Interference management and duplex mode selection in in-band full duplex D2D communications: A stochastic geometry approach},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). High-throughput visual MIMO systems for screen-camera
communications. <em>TMC</em>, <em>20</em>(6), 2200–2211. (<a
href="https://doi.org/10.1109/TMC.2020.2977042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Screen-camera communications, using a liquid crystal display (LCD) screen and camera image sensors, have been attractive variants of visible light communications (VLC) since any external light-emitting modules and photo detectors are required for recent mobile devices, which are usually equipped with display and camera. A major issue in screen-camera communications is a performance loss in transmission rate due to nonlinear channel impairments with ambient noise. To improve transmission rates, we investigate the impact of nonlinear channel equalization, nonbinary channel coding, probabilistic shaping, and nonlinear precoding for high-order modulation schemes. Experimental evaluations using an LCD screen and camera demonstrate that our proposed scheme achieves 3.8-3.3 times higher transmission rates compared to existing schemes for a communication distance of 60-160 cm.},
  archive      = {J_TMC},
  author       = {Takuya Fujihashi and Toshiaki Koike-Akino and Philip V. Orlik and Takashi Watanabe},
  doi          = {10.1109/TMC.2020.2977042},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {2200-2211},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {High-throughput visual MIMO systems for screen-camera communications},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). GaitWay: Monitoring and recognizing gait speed through the
walls. <em>TMC</em>, <em>20</em>(6), 2186–2199. (<a
href="https://doi.org/10.1109/TMC.2020.2975158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interests in monitoring and recognizing gait have surged significantly over the past decades. Traditional approaches rely on camera array, floor sensors (e.g., pressure mats), or wearables (e.g., accelerometers), none of which are suitable for continuous and ubiquitous everyday use. In this article, we present GaitWay, the first system that monitors and recognizes an individual&#39;s gait through the walls via wireless radios. GaitWay passively and unobtrusively monitors an individual&#39;s gait speed by a single pair of commodity WiFi transceivers, without requiring the user to wear any device or walk on a restricted walkway. On this basis, GaitWay automatically identifies stable walking periods, extracts physically plausible and environmentally irrelevant speed features, and accordingly recognizes a subject&#39;s gait. Built upon a distinct rich-scattering multipath model, GaitWay can capture one&#39;s gait speed when one is $&gt;$ &gt;10 meters away behind the walls. We conduct experiments in a typical indoor space and perform eight sessions of data collection with 11 subjects across six months, resulting in $&gt;$ &gt;5,000 gait instances. The results show that GaitWay achieves a median 0.12 m/s and 90%tile 0.35 m/s error in speed estimation, with a mean error of 3.36 cm in stride lengths. Further, it achieves a verification rate of 90.4% and a recognition rate of 81.2% for five users and 69.8% for 11 users, confirming its comfort and accuracy for continuous and ubiquitous use.},
  archive      = {J_TMC},
  author       = {Chenshu Wu and Feng Zhang and Yuqian Hu and K. J. Ray Liu},
  doi          = {10.1109/TMC.2020.2975158},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {2186-2199},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {GaitWay: Monitoring and recognizing gait speed through the walls},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distributed time-sensitive task selection in mobile
crowdsensing. <em>TMC</em>, <em>20</em>(6), 2172–2185. (<a
href="https://doi.org/10.1109/TMC.2020.2975569">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rich set of embedded sensors installed in smartphones, we are witnessing the emergence of many innovative commercial mobile crowdsensing applications, which combine the power of mobile technology with crowdsourcing to effectively collect time-sensitive and location-dependent information. Motivated by these real-world applications, we consider the distributed task selection problem for heterogeneous users with different initial locations, destinations, costs, speeds, and reputation levels. We design a Bayesian asynchronous task selection (BATS) algorithm to help the users plan their task selections based on the incomplete information of the task popularity statistics. We prove its convergence and characterize the computation time for the users’ updates. As a performance benchmark, we consider the ideal case that the service provider centrally allocates the tasks to the users for social surplus maximization. We show that it is an NP-hard problem and propose a greedy centralized algorithm with a lower complexity as the benchmark performance. Simulation results suggest that the BATS scheme achieves the highest Jain&#39;s fairness index and coverage, while yielding a user payoff similar to that with the greedy centralized benchmark. Finally, we evaluate the schemes based on some real-world movement time and distance data from Google Maps.},
  archive      = {J_TMC},
  author       = {Man Hon Cheung and Fen Hou and Jianwei Huang and Richard Southwell},
  doi          = {10.1109/TMC.2020.2975569},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {2172-2185},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Distributed time-sensitive task selection in mobile crowdsensing},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). BuildSenSys: Reusing building sensing data for traffic
prediction with cross-domain learning. <em>TMC</em>, <em>20</em>(6),
2154–2171. (<a href="https://doi.org/10.1109/TMC.2020.2976936">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of smart cities, smart buildings are generating a massive amount of building sensing data by the equipped sensors. Indeed, building sensing data provides a promising way to enrich a series of data-demanding and cost-expensive urban mobile applications. In this paper, as a preliminary exploration, we study how to reuse building sensing data to predict traffic volume on nearby roads. Compared with existing studies, reusing building sensing data has considerable merits of cost-efficiency and high-reliability. Nevertheless, it is non-trivial to achieve accurate prediction on such cross-domain data with two major challenges. First, relationships between building sensing data and traffic data are not unknown as prior, and the spatio-temporal complexities impose more difficulties to uncover the underlying reasons behind the above relationships. Second, it is even more daunting to accurately predict traffic volume with dynamic building-traffic correlations, which are cross-domain, non-linear, and time-varying. To address the above challenges, we design and implement BuildSenSys, a first-of-its-kind system for nearby traffic volume prediction by reusing building sensing data. Our work consists of two parts, i.e., Correlation Analysis and Cross-domain Learning. First, we conduct a comprehensive building-traffic analysis based on multi-source datasets, disclosing how and why building sensing data is correlated with nearby traffic volume. Second, we propose a novel recurrent neural network for traffic volume prediction based on cross-domain learning with two attention mechanisms. Specifically, a cross-domain attention mechanism captures the building-traffic correlations and adaptively extracts the most relevant building sensing data at each predicting step. Then, a temporal attention mechanism is employed to model the temporal dependencies of data across historical time intervals. The extensive experimental studies demonstrate that BuildSenSys outperforms all baseline methods with up to 65.3 percent accuracy improvement (e.g., 2.2 percent MAPE) in predicting nearby traffic volume. We believe that this work can open a new gate of reusing building sensing data for urban traffic sensing, thus establishing connections between smart buildings and intelligent transportation.},
  archive      = {J_TMC},
  author       = {Xiaochen Fan and Chaocan Xiang and Chao Chen and Panlong Yang and Liangyi Gong and Xudong Song and Priyadarsi Nanda and Xiangjian He},
  doi          = {10.1109/TMC.2020.2976936},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {2154-2171},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {BuildSenSys: Reusing building sensing data for traffic prediction with cross-domain learning},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A usable and robust continuous authentication framework
using wearables. <em>TMC</em>, <em>20</em>(6), 2140–2153. (<a
href="https://doi.org/10.1109/TMC.2020.2974941">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One-time login process in conventional authentication systems does not guarantee that the identified user is the actual user throughout the session. However, it is necessary to re-verify the user identity periodically throughout a login session, which is lacking in existing one-time login systems. Continuous authentication, which re-verifies the user identity without breaking the continuity of the session, can address this issue. However, existing methods for Continuous Authentication are either not reliable or not usable. In this paper, we introduce a usable and reliable Wearable-Assisted Continuous Authentication (WACA), which relies on the sensor-based keystroke dynamics and the authentication data is acquired through the built-in sensors of a wearable (e.g., smartwatch) while the user is typing. The acquired data is periodically and transparently compared with the registered profile of the initially logged-in user with one-way classifiers. With this, WACA continuously ensures that the current user is the user who logged-in initially. We implemented the WACA framework and evaluated its performance extensively on real devices with real users. The empirical evaluation of WACA reveals that WACA is feasible, and its error rate is as low as 1 percent with 30 seconds of processing time and 2-3 percent for 20 seconds. The computational overhead is minimal. Furthermore, WACA is capable of identifying insider threats with very high accuracy (99.2 percent) and also robust against powerful adversaries such as imitation and statistical attackers. We believe that this work has practical and far-reaching implications for the future of the usable authentication field.},
  archive      = {J_TMC},
  author       = {Abbas Acar and Hidayet Aksu and A. Selcuk Uluagac and Kemal Akkaya},
  doi          = {10.1109/TMC.2020.2974941},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {2140-2153},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A usable and robust continuous authentication framework using wearables},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A personalized preference learning framework for caching in
mobile networks. <em>TMC</em>, <em>20</em>(6), 2124–2139. (<a
href="https://doi.org/10.1109/TMC.2020.2975786">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper comprehensively studies a content-centric mobile network based on a preference learning framework, where each mobile user is equipped with a finite-size cache. We consider a practical scenario where each user requests a content file according to its own preferences, which is motivated by the existence of heterogeneity in file preferences among different users. Under our model, we consider a single-hop-based device-to-device (D2D) content delivery protocol and characterize the average hit ratio for the following two file preference cases: the personalized file preferences and the common file preferences. By assuming that the model parameters such as user activity levels, user file preferences, and file popularity are unknown and thus need to be inferred, we present a collaborative filtering (CF) -based approach to learn these parameters. Then, we reformulate the hit ratio maximization problems into a submodular function maximization and propose two computationally efficient algorithms including a greedy approach to efficiently solve the cache allocation problems. We analyze the computational complexity of each algorithm. Moreover, we analyze the corresponding level of the approximation that our greedy algorithm can achieve compared to the optimal solution. Using a real-world dataset, we demonstrate that the proposed framework employing the personalized file preferences brings substantial gains over its counterpart for various system parameters.},
  archive      = {J_TMC},
  author       = {Adeel Malik and Joongheon Kim and Kwang Soon Kim and Won-Yong Shin},
  doi          = {10.1109/TMC.2020.2975786},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {2124-2139},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A personalized preference learning framework for caching in mobile networks},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A framework to maximize the capacity of 5G systems for
ultra-reliable low-latency communications. <em>TMC</em>, <em>20</em>(6),
2111–2123. (<a href="https://doi.org/10.1109/TMC.2020.2976055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Providing Ultra-Reliable Low-Latency Communications (URLLC) is one of the key challenges for 5G systems, which requires the redesign of both radio access technologies and the architectures. While 3GPP and the research community focus mainly on radio low layer functionality and architectural changes that enable URLLC, this article proposes a novel cross-layer framework that extends the already standardized 5G solutions to support a very massive number of users/flows in the system. The framework consists of a scheduler, a congestion avoidance algorithm, and a new traffic management algorithm, which together achieve the maximum capacity of 5G systems for URLLC, i.e., they maximize the load at which the reliability and latency requirements are satisfied for at least 99 percent of the users. Extensive performance evaluation results demonstrate that the proposed framework achieves the network capacity very close to the upper bound.},
  archive      = {J_TMC},
  author       = {Evgeny Khorov and Artem Krasilov and Ilya Selnitskiy and Ian F. Akyildiz},
  doi          = {10.1109/TMC.2020.2976055},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {2111-2123},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A framework to maximize the capacity of 5G systems for ultra-reliable low-latency communications},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Transfer learning-based outdoor position recovery with
cellular data. <em>TMC</em>, <em>20</em>(5), 2094–2110. (<a
href="https://doi.org/10.1109/TMC.2020.2968899">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Telecommunication (Telco) outdoor position recovery aims to localize outdoor mobile devices by leveraging measurement report (MR) data. Unfortunately, Telco position recovery requires sufficient amount of MR samples across different areas and suffers from high data collection cost. For an area with scarce MR samples, it is hard to achieve good accuracy. In this paper, by leveraging the recently developed transfer learning techniques, we design a novel Telco position recovery framework, called TLoc, to transfer good models in the carefully selected source domains (those fine-grained small subareas) to a target one which originally suffers from poor localization accuracy. Specifically, TLoc introduces three dedicated components: 1) a new coordinate space to divide an area of interest into smaller domains, 2) a similarity measurement to select best source domains, and 3) an adaptation of an existing transfer learning approach. To the best of our knowledge, TLoc is the first framework that demonstrates the efficacy of applying transfer learning in the Telco outdoor position recovery. To exemplify, on the 2G GSM and 4G LTE MR datasets in Shanghai, TLoc outperforms a non-transfer approach by 27.58 and 26.12 percent less median errors, and further leads to 47.77 and 49.22 percent less median errors than a recent fingerprinting approach NBL.},
  archive      = {J_TMC},
  author       = {Yige Zhang and Aaron Yi Ding and Jörg Ott and Mingxuan Yuan and Jia Zeng and Kun Zhang and Weixiong Rao},
  doi          = {10.1109/TMC.2020.2968899},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {2094-2110},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Transfer learning-based outdoor position recovery with cellular data},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards personalized task-oriented worker recruitment in
mobile crowdsensing. <em>TMC</em>, <em>20</em>(5), 2080–2093. (<a
href="https://doi.org/10.1109/TMC.2020.2973990">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Worker recruitment in mobile crowdsensing systems aims to recruit the most suitable users to perform tasks with high quality and in real-time. Many worker recruitment or task matching mechanisms have been proposed, especially for crowdsourcing platforms, where content information of tasks from the implicit feedback of workers&#39; attendance is extensively exploited to help workers find preferred tasks efficiently. Different from traditional crowdsourcing systems, tasks in mobile crowdsensing systems are usually time-sensitive and location-dependent which also play a crucial role in worker recruitment. However, these context information have not been effectively explored for user recruitment in mobile crowdsensing systems. In this paper, we propose a novel personalized task-oriented worker recruitment mechanism for mobile crowdsensing systems based on a careful characterization of workers&#39; preference. In particular, we fully exploit the content information (e.g., task category, task description) together with the context information (e.g., task time, task location) from the implicit feedback of workers&#39; attendance to accurately model workers&#39; preference on tasks. Moreover, we regard the task-worker fitness prediction as a binary classification problem and utilize the Logit model to integrate the heterogeneous factors into a single framework to predict the matching probability of each task-worker pair. Finally, the workers with the highest matching probability are recruited proactively for each new task. Extensive experiments on real-world datasets demonstrate that the proposed mechanism achieves better performance than the benchmarks.},
  archive      = {J_TMC},
  author       = {Zhibo Wang and Jing Zhao and Jiahui Hu and Tianqing Zhu and Qian Wang and Ju Ren and Chao Li},
  doi          = {10.1109/TMC.2020.2973990},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {2080-2093},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Towards personalized task-oriented worker recruitment in mobile crowdsensing},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SST: Software sonic thermometer on acoustic-enabled IoT
devices. <em>TMC</em>, <em>20</em>(5), 2067–2079. (<a
href="https://doi.org/10.1109/TMC.2020.2970902">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temperature is an important data source for weather forecasting, agriculture irrigation, anomaly detection, etc. While temperature measurement can be achieved via low-cost yet standalone hardware with reasonable accuracy, integrating thermal sensing into ubiquitous computing devices is highly non-trivial due to the design requirement for specific heat isolation and proper device layout. In this paper, we present the first integrated thermometer using commercial-off-the-shelf acoustic-enabled devices. Our software sonic thermometer (SST) utilizes on-board dual microphones on commodity mobile devices to estimate sound speed, which has a known relation with temperature. To precisely measure temperature via sound speed, we propose a chirp mixing approach to circumvent low sampling rates on commodity hardware and design a pipeline of signal processing blocks to handle channel distortions. SST, for the first time, empowers ubiquitous computing devices with thermal sensing capability. It is portable and cost-effective, making it competitive with current thermometers using dedicated hardware. SST is potential to facilitate many interesting applications such as large-scale distributed thermal sensing, yielding high temporal/spatial resolutions with unimaginable low costs. We implement SST on a commodity platform and results show that SST achieves a median accuracy of &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;${0.5^\circ \mathrm{C}}$&lt;/tex-math&gt;&lt;/inline-formula&gt; even at varying humidity levels.},
  archive      = {J_TMC},
  author       = {Chao Cai and Henglin Pu and Menglan Hu and Rong Zheng and Jun Luo},
  doi          = {10.1109/TMC.2020.2970902},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {2067-2079},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {SST: Software sonic thermometer on acoustic-enabled IoT devices},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SocialRecruiter: Dynamic incentive mechanism for mobile
crowdsourcing worker recruitment with social networks. <em>TMC</em>,
<em>20</em>(5), 2055–2066. (<a
href="https://doi.org/10.1109/TMC.2020.2973958">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Worker recruitment is an important problem in mobile crowdsourcing (MCS), which aims to find sufficient and suitable participants to perform tasks. However, existing worker recruitment approaches mainly focus on how to select the most suitable workers for tasks from a large worker pool, while the recruitment problem under insufficient workers (e.g., a new MCS system) has not been well addressed. In this paper, we focus on the insufficient participation problem of MCS systems with limited number of workers, and propose to leverage social network to recruit workers for task completion as well as expanding the worker pool. To this end, we propose a dynamic incentive mechanism, called SocialRecruiter, to encourage workers on the MCS platform to propagate tasks through social networks, so that inviting friends to join in the MCS platform to further propagate and complete tasks. Motivated by the SIR epidemic model, we propose a novel task-specific epidemic model to characterize the status change of users for task propagation and completion through social networks. In order to encourage task completion and propagation, the propagating reward and completing reward are provided according to workers’ actions. In particular, in order to maximize the task completion within the financial budget, the propagating and completing rewards are dynamically updated at each cycle according to real-time worker recruitment progress. The extensive experimental results on two real-world datasets demonstrate that SocialRecruiter outperforms the state-of-the-art approaches in terms of worker recruitment and task completion.},
  archive      = {J_TMC},
  author       = {Zhibo Wang and Yuting Huang and Xinkai Wang and Ju Ren and Qian Wang and Libing Wu},
  doi          = {10.1109/TMC.2020.2973958},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {2055-2066},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {SocialRecruiter: Dynamic incentive mechanism for mobile crowdsourcing worker recruitment with social networks},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Secure information fusion using local posterior for
distributed cyber-physical systems. <em>TMC</em>, <em>20</em>(5),
2041–2054. (<a href="https://doi.org/10.1109/TMC.2020.2969352">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern distributed cyber-physical systems (CPS), information fusion often plays a key role in automate and self-adaptive decision making process. However, given the heterogeneous and distributed nature of modern CPSs, it is a great challenge to operate CPSs with the compromised data integrity and unreliable communication links. In this paper, we study the distributed state estimation problem under the false data injection attack (FDIA) with probabilistic communication networks. We propose an integrated ”detection + fusion” solution, which is based on the Kullback-Leibler divergences (KLD) between local posteriors and therefore does not require the exchange of raw sensor data. For the FDIA detection step, the KLDs are used to cluster nodes in the probability space and to partition the space into secure and insecure subspaces. By approximating the distribution of the KLDs with a general &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\chi ^2$&lt;/tex-math&gt;&lt;/inline-formula&gt; distribution and calculating its tail probability, we provide an analysis of the detection error rate. For the information fusion step, we discuss the potential risk of double counting the shared prior information in the KLD-based consensus formulation method. We show that if the local posteriors are updated from the shared prior, the increased number of neighbouring nodes will lead to the diminished information gain. To overcome this problem, we propose a near-optimal distributed information fusion solution with properly weighted prior and data likelihood. Finally, we present simulation results for the integrated solution. We discuss the impact of network connectivity on the empirical detection error rate and the accuracy of state estimation.},
  archive      = {J_TMC},
  author       = {Xiuming Liu and Edith C.-H. Ngai and Jiangchuan Liu},
  doi          = {10.1109/TMC.2020.2969352},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {2041-2054},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Secure information fusion using local posterior for distributed cyber-physical systems},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust computation offloading and resource scheduling in
cloudlet-based mobile cloud computing. <em>TMC</em>, <em>20</em>(5),
2025–2040. (<a href="https://doi.org/10.1109/TMC.2020.2973993">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile cloud computing (MCC) as an emerging computing paradigm enables mobile devices to offload their computation tasks to nearby resource-rich cloudlets so as to augment computation capability and reduce energy consumption of mobile devices. However, due to the mobility of mobile devices and the admission of cloudlets, the connection between mobile devices and cloudlets may be unstable, which will affect offloading decision, even cause offloading failure. To address such an issue, in this paper, we propose a robust computation offloading strategy with failure recovery (RoFFR) in an intermittently connected cloudlet system aiming to reduce energy consumption and shorten application completion time. We first provide an optimal cloudlet selection policy when multiple cloudlets are available near mobile devices. Furthermore, we formulate the RoFFR problem as two optimization problems, i.e., local execution cost minimization problem and offloading execution cost minimization problem while satisfying the task-dependency requirement and application completion deadline constraint. By solving both optimization problems, we present a distributed RoFFR algorithm for CPU clock frequency configuration in local execution and transmission power allocation and data rate control in cloudlet execution. Experimental results in a real testbed show that our distributed RoFFR algorithm outperforms several baseline policies and existing offloading schemes in terms of application completion cost and offloading data rate.},
  archive      = {J_TMC},
  author       = {Menggang Chen and Songtao Guo and Kai Liu and Xiaofeng Liao and Bin Xiao},
  doi          = {10.1109/TMC.2020.2973993},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {2025-2040},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Robust computation offloading and resource scheduling in cloudlet-based mobile cloud computing},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Revitalizing ultrasonic positioning systems for
ultrasound-incapable smart devices. <em>TMC</em>, <em>20</em>(5),
2007–2024. (<a href="https://doi.org/10.1109/TMC.2020.2973159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An ultrasonic positioning system (UPS) has demonstrated its high accuracy for years. However, few of the developed solutions have been deployed in practice to satisfy the localization demand of today’s smart devices, which lack ultrasonic sensors and were considered as being “deaf” to ultrasound. A recent finding demonstrates that ultrasound may be audible to the smart devices under certain conditions due to their microphone’s nonlinearity. Inspired by this insight, this work revisits the ultrasonic positioning technique and builds a practical UPS, called UPS+, for ultrasound-incapable smart devices. The core concept is to deploy two types of indoor beacon devices, which will advertise ultrasonic beacons at two different ultrasonic frequencies respectively. Their superimposed beacons are downconverted to a low-frequency by exploiting the nonlinearity effect at the receiver’s microphone. This underlying property functions as an implicit ultrasonic downconverter without inflicting harm to the hearing system of humans. We demonstrate UPS+, a fully functional UPS prototype, with centimeter-level localization accuracy using custom-made beacon hardware and well-designed algorithms.},
  archive      = {J_TMC},
  author       = {Zhenlin An and Qiongzheng Lin and Lei Yang and Yi Guo},
  doi          = {10.1109/TMC.2020.2973159},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {2007-2024},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Revitalizing ultrasonic positioning systems for ultrasound-incapable smart devices},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Resilient routing for wireless sensor networks on high genus
surfaces. <em>TMC</em>, <em>20</em>(5), 1993–2006. (<a
href="https://doi.org/10.1109/TMC.2020.2974195">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers a fundamental problem of designing routing scheme resilient to node or link failures for wireless sensor networks deployed on a surface of a complex-connected three-dimensional (3D) setting. Instead of heuristically detouring around the failed path, we borrow homotopy, an important topological concept, to effectively create and evaluate the diversity of alternative paths. We propose a tessellation-free and GPS-free method to compute paths with different homotopy types on surface networks. A source node greedily forwards a packet to its destination based on the computed nodes’ virtual planar coordinates. When the current path fails, the source node can flexibly choose another greedy path from a different homotopy type to deliver the packet. The proposed algorithms are distributed and scalable to both the size and genus number of a surface network. We evaluate the performance of the proposed routing scheme under three different failure models. Simulation results show that our method achieves the best performance under geographically correlated failure models compared with other resilient routing schemes. We also compare our routing scheme with existing state-of-the-art ones specifically designed for surface networks when a network is failure free. Our method achieves the lowest stretch factor.},
  archive      = {J_TMC},
  author       = {Buri Ban and Hongyi Wu and Miao Jin},
  doi          = {10.1109/TMC.2020.2974195},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1993-2006},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Resilient routing for wireless sensor networks on high genus surfaces},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Pushing the data rate of practical VLC via combinatorial
light emission. <em>TMC</em>, <em>20</em>(5), 1979–1992. (<a
href="https://doi.org/10.1109/TMC.2020.2971204">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visible light communication (VLC) systems relying on commercial-off-the-shelf (COTS) devices have gathered momentum recently, due to the pervasive adoption of LED lighting and mobile devices. However, the achievable throughput by such practical systems is still several orders below those claimed by controlled experiments with specialized devices. In this paper, we engineer CoLight aiming to boost the data rate of the VLC system purely built upon COTS devices. CoLight adopts COTS LEDs as its transmitter, but it innovates in its simple yet delicate driver circuit wiring an array of LED chips in a combinatorial manner. Consequently, modulated signals can directly drive the on-off procedures of individual chip groups, so that the spatially synthesized light emissions exhibit a varying luminance following exactly the modulation symbols. To obtain a readily usable receiver, CoLight interfaces a COTS PD with a smartphone through the audio jack, and it also has an alternative MCU-driven circuit to emulate a future integration into the phone. The evaluations on CoLight are both promising and informative: they demonstrate a throughput up to 80 kbps at a distance of 2 m, while suggesting various potentials to further enhance the performance.},
  archive      = {J_TMC},
  author       = {Yanbing Yang and Jun Luo and Chen Chen and Zequn Chen and Wen-De Zhong and Liangyin Chen},
  doi          = {10.1109/TMC.2020.2971204},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1979-1992},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Pushing the data rate of practical VLC via combinatorial light emission},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Protecting your shopping preference with differential
privacy. <em>TMC</em>, <em>20</em>(5), 1965–1978. (<a
href="https://doi.org/10.1109/TMC.2020.2972001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online banks may disclose consumers’ shopping preferences due to various attacks. With differential privacy, each consumer can disturb his consumption amount locally before sending it to online banks. However, directly applying differential privacy in online banks will incur problems in reality because existing differential privacy schemes do not consider handling the noise boundary problem. In this paper, we propose an Optimized Differential prIvate Online tRansaction scheme (O-DIOR) for online banks to set boundaries of consumption amounts with added noises. We then revise O-DIOR to design a RO-DIOR scheme to select different boundaries while satisfying the differential privacy definition. Moreover, we provide in-depth theoretical analysis to prove that our schemes are capable to satisfy the differential privacy constraint. Finally, to evaluate the effectiveness, we have implemented our schemes in mobile payment experiments. Experimental results illustrate that the relevance between the consumption amount and online bank amount is reduced significantly, and the privacy losses are less than 0.5 in terms of mutual information.},
  archive      = {J_TMC},
  author       = {Jiaping Lin and Jianwei Niu and Xuefeng Liu and Mohsen Guizani},
  doi          = {10.1109/TMC.2020.2972001},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1965-1978},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Protecting your shopping preference with differential privacy},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Privacy-preserving media sharing with scalable access
control and secure deduplication in mobile cloud computing.
<em>TMC</em>, <em>20</em>(5), 1951–1964. (<a
href="https://doi.org/10.1109/TMC.2020.2970705">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Benefiting from cloud computing and mobile devices, a huge number of media contents, such as videos are shared in mobile networks. Although scalable video coding can be utilized to provide flexible adaptation, the cloud poses a serious threat to media privacy. In this paper, we propose a privacy-preserving multi-dimensional media sharing scheme named SMACD in mobile cloud computing. First, each media layer is encrypted with an access policy based on attribute-based encryption, which guarantees media confidentiality as well as fine-grained access control. Then, we present a multi-level access policy construction with secret sharing scheme. It ensures that the mobile consumers who obtain a media layer at a higher access level must satisfy the access trees of its child layers at the lower access level, which is compatible with the characteristics of multi-dimensional media and also reduces the complexity of access policies. Moreover, we introduce decentralized key servers to achieve both intra-server and inter-server deduplication by associating different access policies into the same encrypted media. Finally, we conduct experimental evaluation on mobile device and cloud platform with real-world datasets. The results indicate that SMACD protects media privacy against cloud media center and unauthorized parties, while incurring less computational and storage cost.},
  archive      = {J_TMC},
  author       = {Qinlong Huang and Zhicheng Zhang and Yixian Yang},
  doi          = {10.1109/TMC.2020.2970705},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1951-1964},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Privacy-preserving media sharing with scalable access control and secure deduplication in mobile cloud computing},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Performance analysis of indoor mmWave networks with
ceiling-mounted access points. <em>TMC</em>, <em>20</em>(5), 1940–1950.
(<a href="https://doi.org/10.1109/TMC.2020.2972282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of the Enhanced Mobile Broadband use case in 5G networks is to deliver high capacity access to densely populated areas, like city centres, transportation hubs or convention centres. Millimetre-wave communications are the go-to technology to realise that objective, yet due to weak outdoor-to-indoor penetration, outdoor deployments will not suffice and dedicated indoor deployments will be necessary. In this article, we study dense deployments of millimetre-wave access points mounted on the ceiling, with directional antennas pointing downwards to illuminate selected spots on the ground. In this setup, the signal propagation is primarily limited by human body blockages. Therefore, we develop a body blockage model and derive an expression for the probability of blockage. Using the developed expressions and our simulation framework, we assess the impact of densification and body blockage on the achievable performance. We find that both coverage and area spectral efficiency curves exhibit non-trivial behaviour with respect to the access point density and that there is an optimal beamwidth-density configuration that only maximises either coverage or area spectral efficiency. Such optimal configuration changes depending on the body blockage probability, leading to a necessity for network designers to carefully consider their intended application and scenario.},
  archive      = {J_TMC},
  author       = {Fadhil Firyaguna and Jacek Kibilda and Carlo Galiotto and Nicola Marchetti},
  doi          = {10.1109/TMC.2020.2972282},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1940-1950},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Performance analysis of indoor mmWave networks with ceiling-mounted access points},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PACE: Privacy-preserving and quality-aware incentive
mechanism for mobile crowdsensing. <em>TMC</em>, <em>20</em>(5),
1924–1939. (<a href="https://doi.org/10.1109/TMC.2020.2973980">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Providing appropriate monetary rewards is an efficient way for mobile crowdsensing to motivate the participation of task participants. However, a monetary incentive mechanism is generally challenging to prevent malicious task participants and a dishonest task requester. Moreover, prior quality-aware incentive schemes are usually failed to preserve the privacy of task participants. Meanwhile, most existing privacy-preserving incentive schemes ignore the data quality of task participants. To tackle these issues, we propose a privacy-preserving and data quality-aware incentive scheme, called PACE. In particular, data quality consists of the reliability and deviation of data. Specifically, we first propose a zero-knowledge model of data reliability estimation that can protect data privacy while assessing data reliability. Then, we quantify the data quality based on the deviation between reliable data and the ground truth. Finally, we distribute monetary rewards to task participants according to their data quality. To demonstrate the effectiveness and efficiency of PACE, we evaluate it in a real-world dataset. The evaluation and analysis results show that PACE can prevent malicious behaviors of task participants and a task requester, and achieves both privacy-preserving and data quality measurement of task participants.},
  archive      = {J_TMC},
  author       = {Bowen Zhao and Shaohua Tang and Ximeng Liu and Xinglin Zhang},
  doi          = {10.1109/TMC.2020.2973980},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1924-1939},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {PACE: Privacy-preserving and quality-aware incentive mechanism for mobile crowdsensing},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal application deployment in resource constrained
distributed edges. <em>TMC</em>, <em>20</em>(5), 1907–1923. (<a
href="https://doi.org/10.1109/TMC.2020.2970698">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dramatically increasing of mobile applications make it convenient for users to complete complex tasks on their mobile devices. However, the latency brought by unstable wireless networks and the computation failures caused by constrained resources limit the development of mobile computing. A popular approach to solve this problem is to establish a mobile service provisioning system based on a mobile edge computing (MEC) paradigm. In the MEC paradigm, plenty of machines are placed at the edge of the network so that the performance of applications can be optimized by using the involved microservice instances deployed on them. In this paper, we explore the deployment problem of microserivce-based applications in the MEC environment and propose an approach to help to optimize the cost of application deployment with the constraints of resources and the requirement of performance. We conduct a series of experiments to evaluate the performance of our approach. The result shows that our approach can improve the average response time of mobile services.},
  archive      = {J_TMC},
  author       = {Shuiguang Deng and Zhengzhe Xiang and Javid Taheri and Mohammad Ali Khoshkholghi and Jianwei Yin and Albert Y. Zomaya and Schahram Dustdar},
  doi          = {10.1109/TMC.2020.2970698},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1907-1923},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Optimal application deployment in resource constrained distributed edges},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). NFV-enabled IoT service provisioning in mobile edge clouds.
<em>TMC</em>, <em>20</em>(5), 1892–1906. (<a
href="https://doi.org/10.1109/TMC.2020.2972530">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional Internet of Things (IoT) applications involve data capture from various sensors in environments, and the captured data then is processed in remote clouds. However, some critical IoT applications (e.g., autonomous vehicles) require a much lower response latency and more secure guarantees than those offered by remote clouds today. Mobile edge clouds (MEC) supported by the network function virtualization (NFV) technique have been envisioned as an ideal platform for supporting such IoT applications. Specifically, MECs enable to handle IoT applications in edge networks to shorten network latency, and NFV enables agile and low-cost network functions to run in low-cost commodity servers as virtual machines (VMs). One fundamental problem for the provisioning of IoT applications in an NFV-enabled MEC is where to place virtualized network functions (VNFs) for IoT applications in the MEC, such that the operational cost of provisioning IoT applications is minimized. In this paper, we first address this fundamental problem, by considering a special case of the IoT application placement problem, where the IoT application and VNFs of each service request are consolidated into a single location (gateway or cloudlet), for which we propose an exact solution and an approximation algorithm with a provable approximation ratio. We then develop a heuristic algorithm that controls the resource violation ratios of edge clouds in the network. For the IoT application placement problem for IoT applications where their VNFs can be placed to multiple locations, we propose an efficient heuristic that jointly places the IoT application and its VNFs. We finally study the performance of the proposed algorithms by simulations and implementations in a real test-bed, Experimental results show that the performance of the proposed algorithms outperform their counterparts by at least 10 percent.},
  archive      = {J_TMC},
  author       = {Zichuan Xu and Wanli Gong and Qiufen Xia and Weifa Liang and Omer F. Rana and Guowei Wu},
  doi          = {10.1109/TMC.2020.2972530},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1892-1906},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {NFV-enabled IoT service provisioning in mobile edge clouds},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multimodal named data discovery with interest broadcast
suppression for vehicular CPS. <em>TMC</em>, <em>20</em>(5), 1877–1891.
(<a href="https://doi.org/10.1109/TMC.2020.2971479">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyber-physical system (CPS) provides a well-organized integration between communication , computation , and control (3C) technologies. CPS has been widely used in the vehicular networks and it requires to discover multimodal data from the physical system to make appropriate decisions and actions, for example, congestion warnings, applying brakes, adjusting speed limits, etc. Information discovery and availability at individual network elements is one of the fundamental foundations of CPS. In this paper, we proposed two multimodal network information discovery schemes for vehicular CPS using the Named Data Networking (NDN). One of the proposed schemes simply modifies the pull-based NDN communication mechanism to discover multimodal multi-hop data from the network and the other scheme uses the Interest broadcast suppression (IBS) mechanism. The proposed Interest broadcast suppression scheme adapts the holding time technique to defer the Interest forwarding and its computation involves the hop-count, distance, and other network parameters. Simulation results show that the proposed schemes discover about 172 and 162 percent more multimodal information from approximately 283 and 210 percent more network area by suppressing approximately 50 percent of the Interest broadcast storm in highway and the urban traffic scenarios, respectively.},
  archive      = {J_TMC},
  author       = {Safdar Hussain Bouk and Syed Hassan Ahmed and Yongsoon Eun and Kyung-Joon Park},
  doi          = {10.1109/TMC.2020.2971479},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1877-1891},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Multimodal named data discovery with interest broadcast suppression for vehicular CPS},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Motion-fi&lt;inline-formula&gt;&lt;tex-math
notation=“LaTeX”&gt;<span
class="math inline"><sup>+</sup></span>&lt;/tex-math&gt;&lt;mml:math
xmlns:mml=“http://www.w3.org/1998/math/MathML”&gt;&lt;mml:msup&gt;&lt;mml:mspace
width=“4pt”/&gt;&lt;mml:mo&gt;+&lt;/mml:mo&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;&lt;inline-graphic
xlink:href=“xiao-ieq1-2971996.gif”
xmlns:xlink=“http://www.w3.org/1999/xlink”/&gt;&lt;/inline-formula&gt;:
Recognizing and counting repetitive motions with wireless
backscattering. <em>TMC</em>, <em>20</em>(5), 1862–1876. (<a
href="https://doi.org/10.1109/TMC.2020.2971996">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driven by a wide range of real-world applications, several ground-breaking RF-based motion-recognition systems were proposed to detect and/or recognize macro/micro human movements. These systems often suffer from various interferences caused by multiple-users moving simultaneously, resulting in extremely low recognition accuracy. Even if the repetitive motions are fairly well detectable through the wireless signals in theory, in reality they get blended into various other system noises during the motion. Moreover, irregular motion patterns among users will lead to expensive computation cost for motion recognition. To tackle these challenges, we propose a novel wireless sensing system, called Motion-Fi&lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\ ^+$&lt;/tex-math&gt;&lt;mml:math&gt;&lt;mml:msup&gt;&lt;mml:mspace width=&quot;4pt&quot;/&gt;&lt;mml:mo&gt;+&lt;/mml:mo&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href=&quot;xiao-ieq2-2971996.gif&quot;/&gt;&lt;/inline-formula&gt; , which marries battery-free wireless backscattering and device-free sensing in one clean sheet. Motion-Fi&lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\ ^+$&lt;/tex-math&gt;&lt;mml:math&gt;&lt;mml:msup&gt;&lt;mml:mspace width=&quot;4pt&quot;/&gt;&lt;mml:mo&gt;+&lt;/mml:mo&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href=&quot;xiao-ieq3-2971996.gif&quot;/&gt;&lt;/inline-formula&gt; is an accurate, interference tolerable motion-recognition system, which counts repetitive motions without using scenario-dependent templates or profiles and enables multi-user performing certain motions simultaneously because of the relatively short transmission range of backscattered signals and dedicated signal separation method. We implement a backscattering wireless platform to validate our design in various scenarios for over 6 months when different persons, distances and orientations are incorporated. In our experiments, the periodicity in motions could be recognized without any learning or training process, and the accuracy of counting such motions can be achieved within 5 percent count error. With little efforts in learning the patterns, our method could achieve 95.2 percent motion-recognition accuracy for a variety of 7 typical motions. Moreover, by leveraging the periodicity of motions, the recognition accuracy could be further improved to nearly 100 percent with only three repetitions. Our experiments also show that the motions of multiple persons separating by around &lt;inline-formula xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:xlink=&quot;http://www.w3.org/1999/xlink&quot;&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$ 2$&lt;/tex-math&gt;&lt;inline-graphic xlink:href=&quot;xiao-ieq4-2971996.gif&quot;/&gt;&lt;/inline-formula&gt; meters cause little accuracy reduction in the counting process.},
  archive      = {J_TMC},
  author       = {Ning Xiao and Panlong Yang and Yubo Yan and Hao Zhou and Xiang-Yang Li and Haohua Du},
  doi          = {10.1109/TMC.2020.2971996},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1862-1876},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Motion-fi&lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$^+$&lt;/tex-math&gt;&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mml:msup&gt;&lt;mml:mspace width=&quot;4pt&quot;/&gt;&lt;mml:mo&gt;+&lt;/mml:mo&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href=&quot;xiao-ieq1-2971996.gif&quot; xmlns:xlink=&quot;http://www.w3.org/1999/xlink&quot;/&gt;&lt;/inline-formula&gt;: recognizing and counting repetitive motions with wireless backscattering},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Minimizing the maximum charging delay of multiple mobile
chargers under the multi-node energy charging scheme. <em>TMC</em>,
<em>20</em>(5), 1846–1861. (<a
href="https://doi.org/10.1109/TMC.2020.2973979">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless energy charging has emerged as a very promising technology for prolonging sensor lifetime in wireless rechargeable sensor networks (WRSNs). Existing studies focused mainly on the one-to-one charging scheme that a single sensor can be charged by a mobile charger at each time, this charging scheme however suffers from poor charging scalability and inefficiency. Recently, another charging scheme, the multi-node charging scheme that allows multiple sensors to be charged simultaneously by a mobile charger, becomes dominant, which can mitigate charging scalability and improve charging efficiency. However, most previous studies on this multi-node energy charging scheme focused on the use of a single mobile charger to charge multiple sensors simultaneously. For large scale WRSNs, it is insufficient to deploy only a single mobile charger to charge many lifetime-critical sensors, and consequently sensor expiration durations will increase dramatically. To charge many lifetime-critical sensors in large scale WRSNs as early as possible, it is inevitable to adopt multiple mobile chargers for sensor charging that can not only speed up sensor charging but also reduce expiration times of sensors. This however poses great challenges to fairly schedule the multiple mobile chargers such that the longest charging delay among sensors is minimized. One important constraint is that no sensor can be charged by more than one mobile charger at any time due to the fact that the sensor cannot receive any energy from either of the chargers or the overcharging will damage the recharging battery of the sensor. Thus, finding a closed charge tour for each of the multiple chargers such that the longest charging delay is minimized is crucial. In this paper we address the challenge by formulating a novel longest charging delay minimization problem. We first show that the problem is NP-hard. We then devise the very first approximation algorithm with a provable approximation ratio for the problem. We finally evaluate the performance of the proposed algorithms through experimental simulations. Experimental results demonstrate that the proposed algorithm is promising, and outperforms existing algorithms in various settings.},
  archive      = {J_TMC},
  author       = {Wenzheng Xu and Weifa Liang and Xiaohua Jia and Haibin Kan and Yinlong Xu and Xinming Zhang},
  doi          = {10.1109/TMC.2020.2973979},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1846-1861},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Minimizing the maximum charging delay of multiple mobile chargers under the multi-node energy charging scheme},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Implementing the abstract MAC layer in dynamic networks.
<em>TMC</em>, <em>20</em>(5), 1832–1845. (<a
href="https://doi.org/10.1109/TMC.2020.2971599">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamicity is one of the most challenging, yet, key aspects of wireless networks. It can come in many guises, such as churn (node insertion/deletion) and node mobility. Although the study of dynamic networks has been popular in distributed computing domain, previous works considered only partial factors causing dynamicity. In this work, we propose a dynamic model that is comprehensive to include crucial dynamic factors on nodes and links. Our model defines dynamicity in terms of localized topological changes in the vicinity of each node, rather than a global view of the whole network. Obviously, a localized dynamic model suits distributed algorithm studies better than a global one. The proposed dynamic model makes use of the more realistic SINR model to describe wireless interference, instead of the oversimplified graph-based models adopted by most existing research. Under the proposed dynamic model, we develop an efficient distributed algorithm accomplishing local broadcast services in the abstract MAC layer that was first presented by Kuhn et al. [24] . Our solution paves the way for many new fast algorithms to solve high-level problems in dynamic networks, such as consensus, single-message broadcast, and multiple-message broadcast. Extensive simulation studies indicate that our algorithm exhibits good performance in realistic environments with dynamic network behaviors.},
  archive      = {J_TMC},
  author       = {Dongxiao Yu and Yifei Zou and Jiguo Yu and Yong Zhang and Feng Li and Xiuzhen Cheng and Falko Dressler and Francis C.M. Lau},
  doi          = {10.1109/TMC.2020.2971599},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1832-1845},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Implementing the abstract MAC layer in dynamic networks},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient tag grouping via collision reconciliation and data
compression. <em>TMC</em>, <em>20</em>(5), 1817–1831. (<a
href="https://doi.org/10.1109/TMC.2020.2972386">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In RFID systems, tag grouping is to inform each tag in the interrogator&#39;s RF field which group it belongs to by assigning them a group ID. With this information, the reader can write the same data into a group of tags in one transmission by taking their shared group ID as the destination address, which plays a vital role in improving inventory efficiency. Existing work proposes some efficient protocols but suffers from two defects: slot waste and data redundancy. To address these problems, we in this paper propose a two-phase grouping scheme that improves the grouping efficiency via slot reuse as well as data compression. For slot waste, we try to reconcile collision slots and turn some of them into useful again by re-assigning a new slot to collision tags, which increases the number of useful slots and reduces slot waste. For data redundancy, we encode group IDs with lossless coding algorithms and reduce the data redundancy caused by repetitive transmission of group IDs. Two coding methods, Huffman coding and arithmetic coding , are adopted to shorten the length of the bit vector comprised by group IDs. Theoretical analyses and extensive simulations show that our best protocol improves the time efficiency by 51.9 percent compared with the state-of-the-art.},
  archive      = {J_TMC},
  author       = {Xia Wang and Jia Liu and Yanyan Wang and Xingyu Chen and Lijun Chen},
  doi          = {10.1109/TMC.2020.2972386},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1817-1831},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Efficient tag grouping via collision reconciliation and data compression},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Economic analysis of unmanned aerial vehicle (UAV) provided
mobile services. <em>TMC</em>, <em>20</em>(5), 1804–1816. (<a
href="https://doi.org/10.1109/TMC.2020.2973088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to its agility and mobility, the unmanned aerial vehicle (UAV) is a promising technology to provide high-quality mobile services (e.g., fast Internet access, edge computing, and local caching) to ground users. The Internet service providers (ISPs) directly or commission the third-party UAV firms to provide UAV-provided services (UPS) to improve and make up for the shortage of their current mobile services for additional profit. Yet the UAV has limited energy storage and needs to fly to serve users locally, requiring an optimal energy allocation for balancing both hovering time and service capacity. For profit-maximizing purpose, when hovering in a hotspot, how the UAV should dynamically price its capacity-limited UPS according to randomly arriving users with private service valuations is another question. This paper first introduce a threshold-based assignment policy to show how the UAV decides to serve the users or not under complete information that a user’s service valuation can be observed when he arrives. Following this benchmark, we analyze the UAV’s optimal pricing under incomplete information about the users’ random arrival and private service valuations. It is proved that the UAV should ask for a higher price if the leftover hovering time is longer or its service capacity is smaller, and its expected profit approaches to that under complete user information if the hovering time is sufficiently large. Then, based on the optimal pricing, the energy allocation to hovering time and service capacity in a hotspot is optimized. We show that as the hotspot’s user occurrence rate increases, a shorter hovering time or a larger service capacity should be allocated. Finally, when a UAV faces multiple hotspot candidates with different user occurrence rates and flying distances, we prove that it is optimal to deploy the UAV to serve a single hotspot, by taking the optimal pricing and energy allocation of each hotspot into consideration. With multiple UAVs, however, this result can be reversed with UAVs’ forking deployment to different hotspots, especially when hotspots are more symmetric or the UAV number is large. Perhaps surprisingly, more UAVs may be deployed to the second-best hotspot rather than the first-best one.},
  archive      = {J_TMC},
  author       = {Xuehe Wang and Lingjie Duan},
  doi          = {10.1109/TMC.2020.2973088},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1804-1816},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Economic analysis of unmanned aerial vehicle (UAV) provided mobile services},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). EchoWrite: An acoustic-based finger input system without
training. <em>TMC</em>, <em>20</em>(5), 1789–1803. (<a
href="https://doi.org/10.1109/TMC.2020.2973094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, wearable devices have become increasingly popular in our lives because of their neat features and stylish appearance. However, their tiny sizes bring about new challenges to human-device interaction such as texts input. Although some novel methods have been put forward, they possess different defects and are not applicable to deal with the problem. As a result, we propose an acoustic-based texts-entry system, i.e., EchoWrite, by which texts can be entered with a finger writing in the air without wearing any additional device. More importantly, different from many previous works, EchoWrite runs in a training-free style which reduces the training overhead and improves system scalability. We implement EchoWrite with commercial devices and conduct comprehensive experiments to evaluate its texts-entry performance. Experimental results show that EchoWrite enables users to enter texts at a speed of 7.5 WPM without practice, and 16.6 WPM after about 30-minute practice. This speed is better than touch screen-based method on smartwatches, and comparable with previous related works. Moreover, EchoWrite provides favorable user experience of entering texts.},
  archive      = {J_TMC},
  author       = {Kaishun Wu and Qiang Yang and Baojie Yuan and Yongpan Zou and Rukhsana Ruby and Mo Li},
  doi          = {10.1109/TMC.2020.2973094},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1789-1803},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {EchoWrite: An acoustic-based finger input system without training},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Data-driven c-RAN optimization exploiting traffic and
mobility dynamics of mobile users. <em>TMC</em>, <em>20</em>(5),
1773–1788. (<a href="https://doi.org/10.1109/TMC.2020.2971470">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The surging traffic volumes and dynamic user mobility patterns pose great challenges for cellular network operators to reduce operational costs and ensure service quality. Cloud-radio access network (C-RAN) aims to address these issues by handling traffic and mobility in a centralized manner, separating baseband units (BBUs) from base stations (RRHs) and sharing BBUs in a pool. The key problem in C-RAN optimization is to dynamically allocate BBUs and map them to RRHs under cost and quality constraints, since real-world traffic and mobility are difficult to predict, and there are enormous numbers of candidate RRH-BBU mapping schemes. In this work, we propose a data-driven framework for C-RAN optimization. First, we propose a deep-learning-based Multivariate long short term memory (MuLSTM) model to capture the spatiotemporal patterns of traffic and mobility for accurate prediction. Second, we formulate RRH-BBU mapping with cost and quality objectives as a set partitioning problem, and propose a resource-constrained label-propagation (RCLP) algorithm to solve it. We show that the greedy RCLP algorithm is monotone suboptimal with worst-case approximation guarantee to optimal. Evaluations with real-world datasets from Ivory Coast and Senegal show that our framework achieves a BBU utilization above 85.2 percent, with over 82.3 percent of mobility events handled with high quality, outperforming the traditional and the state-of-the-art baselines.},
  archive      = {J_TMC},
  author       = {Longbiao Chen and Thi-Mai-Trang Nguyen and Dingqi Yang and Michele Nogueira and Cheng Wang and Daqing Zhang},
  doi          = {10.1109/TMC.2020.2971470},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1773-1788},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Data-driven C-RAN optimization exploiting traffic and mobility dynamics of mobile users},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). CoSafe: Securing mobile devices through mutual mobility
consistency verification. <em>TMC</em>, <em>20</em>(5), 1761–1772. (<a
href="https://doi.org/10.1109/TMC.2020.2974222">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As mobile devices play increasingly important roles in our daily lives, it is of great significance to protect personal mobile devices from being lost. Noticing the trend that one person normally carries more than one mobile device, we propose an innovative scheme, called CoSafe , to detect device loss by verifying the motion consistency between a pair of devices. The rationale is that the vibrations perceived on devices carried by the same person should be tightly coupled whereas a lost device would show distinct mobility characteristics from others. Specifically, CoSafe compares the mobility consistency between a pair of devices on three levels, where coarse features (i.e., the mobility state and motion periodicity) are first compared to give fast response and more complex comparison on subtle feature (i.e., the relative phase) is conducted only when needed. In this way, CoSafe can instantly respond and introduce very low computation and communication costs. We implement CoSafe on a Commercial-Off-The-Shelf Android smartphone and a smartwatch, and conduct both trace-driven simulations and real-world experiments to evaluate the performance of CoSafe. The results show that CoSafe achieves a mean false negative ratio and false positive ratio of 1.46 and 3.12 percent, respectively, even under sophisticated stealing attacks.},
  archive      = {J_TMC},
  author       = {Shan Chang and Hang Chen and Hongzi Zhu and Xinggang Hu and Di Cao},
  doi          = {10.1109/TMC.2020.2974222},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1761-1772},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {CoSafe: Securing mobile devices through mutual mobility consistency verification},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A fault-tolerant early classification approach for human
activities using multivariate time series. <em>TMC</em>, <em>20</em>(5),
1747–1760. (<a href="https://doi.org/10.1109/TMC.2020.2973616">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Activity classification has been an interesting area of research for many years, to better understand human behavior. Recent advancements in embedded computing systems allowed the emergence of several state-of-art solutions for human activity classification using sensors of a smartphone. The sensors generate temporal sequences of observations for human activity, which is called as Multivariate Time Series (MTS). Current state-of-art solutions for human activity classification suffer from two major limitations: first, the length of testing MTS should be equal to the training MTS and second, the MTS should not have any faulty time series. In real-time applications, it is desirable to classify a human activity using an incomplete MTS as early as possible. In this work, we propose a fault-tolerant early classification of MTS (FECM) approach to address these limitations. FECM builds a set of classification models using MTS training dataset. The approach employs Gaussian Process classifier to estimate minimum required length of time series, which is used to predict a class label of new MTS. Further, FECM uses an Auto Regressive Integrated Moving Average model to identify faulty time series in the new MTS. Finally, we conduct an experiment to evaluate the performance of FECM using accuracy and earliness metrics.},
  archive      = {J_TMC},
  author       = {Ashish Gupta and Hari Prabhat Gupta and Bhaskar Biswas and Tanima Dutta},
  doi          = {10.1109/TMC.2020.2973616},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1747-1760},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A fault-tolerant early classification approach for human activities using multivariate time series},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Corrections to “HMO: Ordering RFID tags with static devices
in mobile environments.” <em>TMC</em>, <em>20</em>(4), 1746. (<a
href="https://doi.org/10.1109/TMC.2021.3050539">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Presents corrections to the acknowledgement section for the above named article.},
  archive      = {J_TMC},
  author       = {Ge Wang and Chen Qian and Longfei Shangguan and Han Ding and Jinsong Han and Kaiyan Cui and Wei Xi and Jizhong Zhao},
  doi          = {10.1109/TMC.2021.3050539},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1746},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Corrections to “HMO: Ordering RFID tags with static devices in mobile environments”},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). WiTrace: Centimeter-level passive gesture tracking using
OFDM signals. <em>TMC</em>, <em>20</em>(4), 1730–1745. (<a
href="https://doi.org/10.1109/TMC.2019.2961885">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gesture tracking is a basic Human-Computer Interaction mechanism to control devices, such as IoT and VR/AR devices. However, prior OFDM signal based systems focus on gesture recognition and provide results with insufficient accuracy, and thus, cannot be applied for high-precision gesture tracking. In this paper, we propose a CSI based device-free gesture tracking system, called WiTrace, which leverages the CSI values extracted from OFDM signals to enable accurate gesture tracking. For 1D tracking, WiTrace derives the phase of the signals reflected by the hand from the composite signals, and measures the phase changes to obtain the movement distance. For 2D tracking, WiTrace proposes the first CSI based scheme to accurately estimate the initial position, and adopts the Kalman Filter based on continuous Wiener process acceleration model to further filter out tracking noise. Our results show that WiTrace achieves an average accuracy of 6.23 cm for initial position estimation and achieves cm-level accuracy with average tracking errors of 1.46 cm and 2.09 cm for 1D tracking and 2D tracking, respectively.},
  archive      = {J_TMC},
  author       = {Lei Wang and Ke Sun and Haipeng Dai and Wei Wang and Kang Huang and Alex X. Liu and Xiaoyu Wang and Qing Gu},
  doi          = {10.1109/TMC.2019.2961885},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1730-1745},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {WiTrace: Centimeter-level passive gesture tracking using OFDM signals},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Video stabilization for camera shoot in mobile devices via
inertial-visual state tracking. <em>TMC</em>, <em>20</em>(4), 1714–1729.
(<a href="https://doi.org/10.1109/TMC.2019.2961313">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the sudden movement during the camera shoot, the videos retrieved from the hand-held mobile devices often suffer from undesired frame jitters, leading to the loss of video quality. In this paper, we present a video stabilization solution in mobile devices via inertial-visual state tracking. Specifically, during the video shoot, we use the gyroscope to estimate the rotation of camera, and use the structure-from-motion among the image frames to estimate the translation of camera. We build a camera projection model by considering the rotation and translation of the camera, and the camera motion model to depict the relationship between the inertial-visual state and the camera&#39;s 3D motion. By fusing the inertial measurement (IMU)-based method and the computer vision (CV)-based method, our solution is robust to the fast movement and violent jitters, moreover, it greatly reduces the computation overhead in video stabilization. In comparison to the IMU-based solution, our solution can estimate the translation in a more accurate manner, since we use the feature point pairs in adjacent image frames, rather than the error-prone accelerometers, to estimate the translation. In comparison to the CV-based solution, our solution can estimate the translation with less number of feature point pairs, since the number of undetermined degrees of freedom in the 3D motion directly reduces from 6 to 3. We implemented a prototype system on smart glasses and smart phones, and evaluated the performance under real scenarios, i.e., the human subjects used mobile devices to shoot videos while they were walking, climbing or riding. The experiment results show that our solution achieves 32 percent better performance than the state-of-art solutions in regard to video stabilization. Moreover, the average processing time latency is 32.6ms, which is lower than the conventional inter-frame time interval, i.e., 33ms, and thus meets the real-time requirement for online processing.},
  archive      = {J_TMC},
  author       = {Fei Han and Lei Xie and Yafeng Yin and Hao Zhang and Guihai Chen and Sanglu Lu},
  doi          = {10.1109/TMC.2019.2961313},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1714-1729},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Video stabilization for camera shoot in mobile devices via inertial-visual state tracking},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ultra-dense networks: A holistic analysis of multi-piece
path loss, antenna heights, finite users and BS idle modes.
<em>TMC</em>, <em>20</em>(4), 1702–1713. (<a
href="https://doi.org/10.1109/TMC.2019.2960223">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We discover a new capacity scaling law in ultra-dense networks under practical system assumptions, such as a general multi-piece path loss model, a non-zero base station to user equipment antenna height difference, and a finite user equipment density. The intuition and implication of this new capacity scaling law are completely different from those found in the year 2011. That law indicated that the increase of the interference power caused by a denser network would be exactly compensated by the increase of the signal power due to the reduced distance between transmitters and receivers, and thus, network capacity should grow linearly with network densification. However, we find that both the signal and interference powers become bounded in practical ultra-dense networks, which leads to a constant capacity scaling law. Moreover, our new discovery on the constant capacity scaling law indicates three network optimization problems respectively for base station deployment, user equipment scheduling and base station coordination. These three optimization problems are justified and solved in this paper, shedding new light on the deployment and optimization of ultra-dense networks.},
  archive      = {J_TMC},
  author       = {Ming Ding and David López-Pérez and Youjia Chen and Guoqiang Mao and Zihuai Lin and Albert Y. Zomaya},
  doi          = {10.1109/TMC.2019.2960223},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1702-1713},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Ultra-dense networks: A holistic analysis of multi-piece path loss, antenna heights, finite users and BS idle modes},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards low-cost sign language gesture recognition
leveraging wearables. <em>TMC</em>, <em>20</em>(4), 1685–1701. (<a
href="https://doi.org/10.1109/TMC.2019.2962760">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Different from traditional gestures, sign language gestures involve a lot of finger-level gestures without wrist or arm movements. They are hard to detect using existing motion sensors-based approaches. We introduce the first low-cost sign language gesture recognition system that can differentiate fine-grained finger movements using the Photoplethysmography (PPG) and motion sensors in commodity wearables. By leveraging the motion artifacts in PPG, our system can accurately recognize sign language gestures when there are large body movements, which cannot be handled by the traditional motion sensor-based approaches. We further explore the feasibility of using both PPG and motion sensors in wearables to improve the sign language gesture recognition accuracy when there are limited body movements. We develop a gradient boost tree (GBT) model and deep neural network-based model (i.e., ResNet) for classification. The transfer learning technique is applied to ResNet-based model to reduce the training effort. We develop a prototype using low-cost PPG and motions sensors and conduct extensive experiments and collect over 7000 gestures from 10 adults in the static and body-motion scenarios. Results demonstrate that our system can differentiate nine finger-level gestures from the American Sign Language with an average recognition accuracy over 98 percent.},
  archive      = {J_TMC},
  author       = {Tianming Zhao and Jian Liu and Yan Wang and Hongbo Liu and Yingying Chen},
  doi          = {10.1109/TMC.2019.2962760},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1685-1701},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Towards low-cost sign language gesture recognition leveraging wearables},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The design of dynamic probabilistic caching with
time-varying content popularity. <em>TMC</em>, <em>20</em>(4),
1672–1684. (<a href="https://doi.org/10.1109/TMC.2020.2967038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we design dynamic probabilistic caching for the scenario when the instantaneous content popularity may vary with time while it is possible to predict the average content popularity over a time window. Based on the average content popularity, optimal content caching probabilities can be found, e.g., from solving optimization problems, and existing results in the literature can implement the optimal caching probabilities via static content placement. The objective of this work is to design dynamic probabilistic caching that: i) converge (in distribution) to the optimal content caching probabilities under time-invariant content popularity, and ii) adapt to the time-varying instantaneous content popularity under time-varying content popularity. Achieving the above objective requires a novel design of dynamic content replacement because static caching cannot adapt to varying content popularity while classic dynamic replacement policies, such as LRU, cannot converge to target caching probabilities (as they do not exploit any content popularity information). We model the design of dynamic probabilistic replacement policy as the problem of finding the state transition probability matrix of a Markov chain and propose a method to generate and refine the transition probability matrix. Extensive numerical results are provided to validate the effectiveness of the proposed design.},
  archive      = {J_TMC},
  author       = {Jie Gao and Shan Zhang and Lian Zhao and Xuemin Shen},
  doi          = {10.1109/TMC.2020.2967038},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1672-1684},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {The design of dynamic probabilistic caching with time-varying content popularity},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stealing your android patterns via acoustic signals.
<em>TMC</em>, <em>20</em>(4), 1656–1671. (<a
href="https://doi.org/10.1109/TMC.2019.2960778">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pattern lock is an essential authentication method on mobile devices. Recent works on cracking pattern locks either require additional network facilities (e.g., WiFi hotspots) or suffer from strict constraints (e.g., physical closeness to the victim and good lighting). Being too susceptible to environment settings, these attacks are less effective in practice and cannot scale to a large number of users. To address these concerns, in this paper, we propose PatternListener+, a practical attack on pattern locks using the speakers and microphones on mobile devices. The speaker plays inaudible acoustic signals, which are reflected by the fingertip when the victim is drawing the pattern, and then recorded by the microphone. The recorded acoustic signals contain rich information of the fingertip motion that can be leveraged to infer the pattern. We carefully design a series of algorithms to eliminate the dynamic and static interferences, segment acoustic signals into fragments corresponding to all pattern lines, and recover each line composed of the pattern according to the signals. Finally, we recover the candidate pattern by mapping all line candidates into grid patterns with a tree structure. We implement a PatternListener+ prototype using off-the-shelf smartphones, and extensive experiments confirm the effectiveness and robustness of PatternListener+. The attack success rate is over 90 percent on 120 patterns in five attempts.},
  archive      = {J_TMC},
  author       = {Man Zhou and Qian Wang and Jingxiao Yang and Qi Li and Peipei Jiang and Yanjiao Chen and Zhibo Wang},
  doi          = {10.1109/TMC.2019.2960778},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1656-1671},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Stealing your android patterns via acoustic signals},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Spatio-temporal correlation of interference in MANET under
spatially correlated shadowing environment. <em>TMC</em>,
<em>20</em>(4), 1642–1655. (<a
href="https://doi.org/10.1109/TMC.2019.2959990">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Correlation of interference affects spatio-temporal aspects of various wireless mobile systems, such as retransmission, multiple antennas and cooperative relaying. In this paper, we study the spatial and temporal correlation of interference in mobile ad-hoc networks under a correlated shadowing environment. By modeling the node locations as a Poisson point process with an i.i.d. mobility model and considering Gudmundson (1991)&#39;s spatially correlated shadowing model, we theoretically analyze the relationship between the correlation distance of log-normal shadowing and the spatial and temporal correlation coefficients of interference. Since the exact expressions of the correlation coefficients are intractable, we obtain their simple asymptotic expressions as the variance of log-normal shadowing increases. We found in our numerical examples that the asymptotic expansions can be used as tight approximate formulas and useful for modeling general wireless systems under spatially correlated shadowing.},
  archive      = {J_TMC},
  author       = {Tatsuaki Kimura and Hiroshi Saito},
  doi          = {10.1109/TMC.2019.2959990},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1642-1655},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Spatio-temporal correlation of interference in MANET under spatially correlated shadowing environment},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Slow beam steering and NOMA for indoor multi-user visible
light communications. <em>TMC</em>, <em>20</em>(4), 1627–1641. (<a
href="https://doi.org/10.1109/TMC.2019.2960495">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visible light communication (VLC) is an emerging technology that enables broadband data rates using the visible spectrum. In this paper, considering slow beam steering where VLC beam directions are assumed to be fixed during a transmission frame, we find the steering angles that simultaneously serve multiple users within the frame duration and maximize the data rates. This is achieved by solving a non-convex optimization problem using a grid-based search and majorization-minimization (MM) procedure. Subsequently, we consider multiple steerable beams with a larger number of users in the network and propose an algorithm to cluster users and serve each cluster with a separate beam. We optimize the transmit power of each beam to maximize the data rates. Finally, we propose a non-orthogonal multiple access (NOMA) scheme for the beam steering and user clustering scenario, to further increase the data rates of the users. The simulation results show that the proposed beam steering method can efficiently serve a high number of users, and with power optimization, a sum rate gain up to thirteen times is possible. The simulation results for NOMA suggests an additional 10 Mbps sum rate gain for each NOMA user pair.},
  archive      = {J_TMC},
  author       = {Yusuf Said Eroglu and Chethan Kumar Anjinappa and İsmail Guvenc and Nezih Pala},
  doi          = {10.1109/TMC.2019.2960495},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1627-1641},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Slow beam steering and NOMA for indoor multi-user visible light communications},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). RFID harmonic for vibration sensing. <em>TMC</em>,
<em>20</em>(4), 1614–1626. (<a
href="https://doi.org/10.1109/TMC.2019.2963152">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional vibration sensing systems, equipped with specific sensors (e.g., accelerometer) and communication modules, are either expensive or cumbersome to deploy. Recently research community revisits this classic topic by taking advantage of off-the-shelf RFIDs. However, limited by low reading rate and long wavelength, current RFID based solutions can only sense low-frequency (e.g., below 100 Hz) mechanical vibrations with larger amplitude (e.g., &gt;5 mm). To address the issue, this work presents TagSound, an RFID-based vibration sensing system that explores a tag&#39;s harmonic backscattering to recover high-frequency and tiny mechanical vibrations accurately. The key innovations are in two aspects: harmonics based sensingand a newrecovery scheme. We implement TagSound with USRP platforms. Our comprehensive evaluation shows (i) TagSound can achieve a mean error of 0.37 Hz when detecting vibrations at frequencies below 100 Hz, and a mean error of 4.2 Hz even when the vibration frequency is up to 2500 Hz. (ii) TagSound can achieve a Hz-level frequency estimation even when the vibration amplitude is only 2 mm.},
  archive      = {J_TMC},
  author       = {Ping Li and Zhenlin An and Lei Yang and Panlong Yang and QiongZheng Lin},
  doi          = {10.1109/TMC.2019.2963152},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1614-1626},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {RFID harmonic for vibration sensing},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Relay node placement in wireless sensor networks: From
theory to practice. <em>TMC</em>, <em>20</em>(4), 1602–1613. (<a
href="https://doi.org/10.1109/TMC.2019.2962674">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasingly wide utilization of Wireless Sensor Networks (WSNs) in industrial applications outstands the significance of the Delay Constrained Relay Node Placement (DCRNP) problem. Existing algorithms to the DCRNP problem are designed based on the ideal geometric disk wireless channel model, and no real-world deployments are performed to verify the effectiveness of these algorithms. However, the unreliable and unpredictable wireless links in WSNs may lead these algorithms to fail in practice. Therefore, we first conduct extensive real-world deployments under the guidance of existing algorithms to evaluate their performance and to gain some insights for designing practical deployment algorithms. The results exhibit that the WSNs built by existing algorithms have a favorable performance in end-to-end delay but a poor performance in reliability, which is mainly due to the lack of methods ensuring high-quality links. To this end, we first devise a Set-Covering-based Algorithm (SCA) which figures out the DCRNP problem while ensuring the quality of each link better than a given threshold. As our experiments also show that the fault-tolerant topology can significantly improve network reliability, we then design a k-Set-Covering-based Algorithm (kSCA) to build fault-tolerant WSNs based on the methodology of SCA. Furthermore, the elaborate analysis proves that both SCA and kSCA are polynomial-time algorithms, and their approximation ratios are both O(ln n), where n is the number of sensor nodes. Finally, extensive experiments are performed under the guidance of SCA and kSCA to demonstrate the effectiveness of these two algorithms.},
  archive      = {J_TMC},
  author       = {Wei Liang and Chaofan Ma and Meng Zheng and Longxiang Luo},
  doi          = {10.1109/TMC.2019.2962674},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1602-1613},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Relay node placement in wireless sensor networks: From theory to practice},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). RED: RFID-based eccentricity detection for high-speed
rotating machinery. <em>TMC</em>, <em>20</em>(4), 1590–1601. (<a
href="https://doi.org/10.1109/TMC.2019.2962770">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Eccentricity detection is a crucial issue for high-speed rotating machinery, which concerns the stability and safety of the machinery. Conventional techniques in industry for eccentricity detection are mainly based on measuring certain physical indicators, which are costly and hard to deploy. In this paper, we propose RED, a non-intrusive, low-cost, and real-time RFID-based eccentricity detection approach. Differing from the existing RFID-based sensing approaches, RED utilizes the temporal and phase distributions of tag readings as effective features for eccentricity detection. RED includes a Markov chain based model called RUM, which only needs a few sample readings from the tag to make a highly accurate and precise judgement. The design of RED further addresses practical issues, such as parameterizing the RUM model, making it robust to dynamic and noisy environments, and considering how the doppler shift may affect our system. We implement RED with COTS RFID reader and tags, and evaluate its performance across various scenarios. The overall accuracy is 93.6 percent and the detection latency is 0.68 seconds in average.},
  archive      = {J_TMC},
  author       = {Yuan He and Yilun Zheng and Meng Jin and Songzhen Yang and Xiaolong Zheng and Yunhao Liu},
  doi          = {10.1109/TMC.2019.2962770},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1590-1601},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {RED: RFID-based eccentricity detection for high-speed rotating machinery},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PicSys: Energy-efficient fast image search on distributed
mobile networks. <em>TMC</em>, <em>20</em>(4), 1574–1589. (<a
href="https://doi.org/10.1109/TMC.2019.2963150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile devices collect a large amount of visual data that are useful for many applications. Searching for an object of interest over a network of mobile devices can aid human analysts in a variety of situations. However, processing the information on these devices is a challenge owing to the high computational complexity of the state-of-the-art computer vision algorithms that primarily rely on Convolutional Neural Networks (CNNs). Thus, this paper builds PicSys, a system that enables answering visual search queries on a mobile network. The objective of the system is to minimize the maximum completion time over all devices while taking into account the energy consumption of mobile devices as well. First, PicSys carefully divides the computation into multiple filtering stages, such that only a small percentage of images need to run the entire CNN pipeline. Splitting such CNN computation into multiple stages requires understanding the intermediate CNN features and systematically trading off accuracy for the computation speed. Second, PicSys determines where to run each of the stages of the multi-stage pipeline to fully utilize the available resources. Finally, through extensive experimentation, system implementation, and simulation, we show that PicSys performance is close to optimal and significantly outperforms other standard algorithms.},
  archive      = {J_TMC},
  author       = {Noor Felemban and Fidan Mehmeti and Hana Khamfroush and Zongqing Lu and Swati Rallapalli and Kevin Chan and Thomas La Porta},
  doi          = {10.1109/TMC.2019.2963150},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1574-1589},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {PicSys: Energy-efficient fast image search on distributed mobile networks},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Performance modeling of softwarized network services based
on queuing theory with experimental validation. <em>TMC</em>,
<em>20</em>(4), 1558–1573. (<a
href="https://doi.org/10.1109/TMC.2019.2962488">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network Functions Virtualization facilitates the automation of the scaling of softwarized network services (SNSs). However, the realization of such a scenario requires a way to determine the needed amount of resources so that the SNSs performance requisites are met for a given workload. This problem is known as resource dimensioning, and it can be efficiently tackled by performance modeling. In this vein, this paper describes an analytical model based on an open queuing network of G/G/m queues to evaluate the response time of SNSs. We validate our model experimentally for a virtualized Mobility Management Entity (vMME) with a three-tiered architecture running on a testbed that resembles a typical data center virtualization environment. We detail the description of our experimental setup and procedures. We solve our resulting queueing network by using the Queueing Networks Analyzer (QNA), Jackson&#39;s networks, and Mean Value Analysis methodologies, and compare them in terms of estimation error. Results show that, for medium and high workloads, the QNA method achieves less than half of error compared to the standard techniques. For low workloads, the three methods produce an error lower than 10 percent. Finally, we show the usefulness of the model for performing the dynamic resource provisioning of the vMME experimentally.},
  archive      = {J_TMC},
  author       = {Jonathan Prados-Garzon and Pablo Ameigeiras and Juan J. Ramos-Munoz and Jorge Navarro-Ortiz and Pilar Andres-Maldonado and Juan M. Lopez-Soler},
  doi          = {10.1109/TMC.2019.2962488},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1558-1573},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Performance modeling of softwarized network services based on queuing theory with experimental validation},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Performance and pitfalls of 60 GHz WLANs based on
consumer-grade hardware. <em>TMC</em>, <em>20</em>(4), 1543–1557. (<a
href="https://doi.org/10.1109/TMC.2020.2967386">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless networks operating in the 60 GHz band have the potential to provide very high throughput but face a number of challenges (e.g., high attenuation, beam training, and coping with mobility) which are widely accepted but often not well understood in practice. Understanding these challenges, and especially their actual impact on consumer-grade hardware is fundamental to fully exploit the high physical layer rates in the 60 GHz band. To this end, we perform an extensive measurement campaign using two commercial off-the-shelf 60 GHz routers in real-world environments. Our results allow us to revisit a range of issues and provide much deeper insights into the reasons for specific performance compared to prior work on performance characterization. Further, our study goes beyond basic link characterization and explores for the first time practical considerations such as coverage and access point deployment. While some of our observations are expected, we also obtain highly surprising insights that challenge the prevailing wisdom in the community. We derive the shortcomings of current commercial 60 GHz devices, and the fundamental problems that remain open on the way to fast and efficient 60 GHz networking.},
  archive      = {J_TMC},
  author       = {Swetank Kumar Saha and Shivang Aggarwal and Hany Assasa and Adrian Loch and Naveen Muralidhar Prakash and Roshan Shyamsunder and Daniel Steinmetzer and Dimitrios Koutsonikolas and Joerg Widmer and Matthias Hollick},
  doi          = {10.1109/TMC.2020.2967386},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1543-1557},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Performance and pitfalls of 60 GHz WLANs based on consumer-grade hardware},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Pedestrian flow estimation through passive WiFi sensing.
<em>TMC</em>, <em>20</em>(4), 1529–1542. (<a
href="https://doi.org/10.1109/TMC.2019.2959610">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In public places, even if pedestrians do not have their mobile devices connected with any WiFi access point (AP), WiFi probe requests will be broadcast, so that WiFi sniffers can be employed to crowdsource these WiFi probe packets for use. This paper tackles the problem of exploiting the passive WiFi sensing approach for pedestrian flow analysis. To be specific, a passive WiFi sensing model is first established based on a probabilistic analysis of interactions between WiFi sniffers and the moving pedestrian flow, capturing the main factors affecting pedestrian flow characteristics. On that basis, a sequential filtering algorithm is proposed based on the Rao-Blackwellized particle filter (RBPF) to produce simultaneous and efficient estimates of the pedestrian flow speed and pedestrian number utilizing the real-time sniffing results. In order to validate this study, an experimental pedestrian surveillance system using WiFi sniffers is deployed at the transfer channel of a metro station in Guangzhou, China. Extensive experiments are conducted to verify the passive sensing model, and confirm the effectiveness and advantages of the proposed algorithm. The pedestrian flow estimation not only helps to improve the safety and facility management and customer services, but also paves the way for introducing other novel applications.},
  archive      = {J_TMC},
  author       = {Baoqi Huang and Guoqiang Mao and Yong Qin and Yun Wei},
  doi          = {10.1109/TMC.2019.2959610},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1529-1542},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Pedestrian flow estimation through passive WiFi sensing},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Novel wake-up scheme for energy-efficient low-latency mobile
devices in 5G networks. <em>TMC</em>, <em>20</em>(4), 1511–1528. (<a
href="https://doi.org/10.1109/TMC.2020.2964218">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improved mobile device battery lifetime and latency minimization are critical requirements for enhancing the mobile broadband services and user experience. Long-term evolution (LTE) networks have adopted discontinuous reception (DRX) as the baseline solution for prolonged battery lifetime. However, in every DRX cycle, the mobile device baseband processing unit monitors and decodes the control signaling, and thus, all instances without any actual data allocation leads to unnecessary energy consumption. This fact together with the long start-up and power-down times can prevent adopting frequent wake-up instants, which, in turn, leads to considerable latency. In this work, a novel wake-up scheme is described and studied, to tackle the trade-off between latency and battery lifetime in future 5G networks, seeking thus to facilitate an always-available experience, rather than always-on. Analytical and simulation-based results show that the proposed scheme is a promising approach to control the user plane latency and energy consumption, when the device is operating in the power saving mode. The aim of this article is to describe the overall wake-up system operating principle and the associated signaling methods, receiver processing solutions and essential implementation aspects. Additionally, the advantages compared to DRX-based systems are shown and demonstrated, through the analysis of the system energy-efficiency and latency characteristics, with special emphasis on future 5G-grade mobile devices.},
  archive      = {J_TMC},
  author       = {Soheil Rostami and Kari Heiska and Oleksandr Puchko and Kari Leppanen and Mikko Valkama},
  doi          = {10.1109/TMC.2020.2964218},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1511-1528},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Novel wake-up scheme for energy-efficient low-latency mobile devices in 5G networks},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-task allocation under time constraints in mobile
crowdsensing. <em>TMC</em>, <em>20</em>(4), 1494–1510. (<a
href="https://doi.org/10.1109/TMC.2019.2962457">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile crowdsensing (MCS) is a popular paradigm to collect sensed data for numerous sensing applications. With the increment of tasks and workers in MCS, it has become indispensable to design efficient task allocation schemes to achieve high performance for MCS applications. Many existing works on task allocation focus on single-task allocation, which is inefficient in many MCS scenarios where workers are able to undertake multiple tasks. On the other hand, many tasks are time-limited, while the available time of workers is also limited. Therefore, time validity is essential for both tasks and workers. To accommodate these challenges, this paper proposes a multi-task allocation problem with time constraints, which investigates the impact of time constraints to multi-task allocation and aims to maximize the utility of the MCS platform. We first prove that this problem is NP-complete. Then two evolutionary algorithms are designed to solve this problem. Finally, we conduct the experiments based on synthetic and real-world datasets under different experiment settings. The results verify that the proposed algorithms achieve more competitive and stable performance compared with baseline algorithms.},
  archive      = {J_TMC},
  author       = {Xin Li and Xinglin Zhang},
  doi          = {10.1109/TMC.2019.2962457},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1494-1510},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Multi-task allocation under time constraints in mobile crowdsensing},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Load management, power and admission control in downlink
cellular OFDMA networks. <em>TMC</em>, <em>20</em>(4), 1477–1493. (<a
href="https://doi.org/10.1109/TMC.2019.2962126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a resource management framework for load-coupled downlink cellular OFDMA networks considering the load factor of an individual base station (BS) per resource block (RB), i.e., the number of adjacent sub-carriers (SCs), as the variable of interest in the resource management problem. The load factor of a BS per RB, which corresponds to the fraction of active SCs in the BS per RB, is an indicator of the level of resource consumption, and it affects the interference caused to that RB reused in other BSs, and thereby, results in a load-coupled OFDMA system. We first propose two distributed schemes to minimize: (i) the total load factor of the BSs (which would in turn increase the number of supportable users in the system), and (ii) the total downlink transmit power level of the BSs. Then, we derive the necessary and sufficient conditions for checking the feasibility of given target-rate requirements (also referred to as demand vector ) for users. Accordingly, an iterative and distributed scheme is proposed to check the feasibility of a given demand vector. Next, for a priority-based load-coupled network, we propose a priority-based gradual removal algorithm to support the maximal number of low-priority users while satisfying the demands of the high-priority users. To evaluate the performance of our proposed schemes for resource management and admission control in load-coupled OFDMA networks, the theoretical investigations are complemented with Monte Carlo simulations.},
  archive      = {J_TMC},
  author       = {Fahime Khoramnejad and Mehdi Rasti and Hossein Pedram and Ekram Hossain and Shahrokh Valaee},
  doi          = {10.1109/TMC.2019.2962126},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1477-1493},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Load management, power and admission control in downlink cellular OFDMA networks},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Kollector: Detecting fraudulent activities on mobile devices
using deep learning. <em>TMC</em>, <em>20</em>(4), 1465–1476. (<a
href="https://doi.org/10.1109/TMC.2020.2964226">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth in smartphone usage, preventing leakage of personal information and privacy has become a challenging task. One major consequence of such leakage is impersonation. This type of illegal usage is nearly impossible to prevent as existing preventive mechanisms (e.g., passcode and fingerprinting), are not capable of continuously monitoring usage and determining whether the user is authorized. Once unauthorized users can defeat the initial protection mechanisms, they would have full access to the devices including using stored passwords to access high-value websites. We present Kollector , a new framework to detect impersonation based on a multi-view bagging deep learning approach to capture sequential tapping information on the smart-phone&#39;s keyboard. We construct a sequential-tapping biometrics model to continuously authenticate the user while typing. We empirically evaluated our system using real-world phone usage sessions from 26 users over eight weeks. We then compared our model against commonly used shallow machine techniques and find that our system performs better than other approaches and can achieve an 8.42 percent equal error rate, a 94.24 percent accuracy and a 94.41 percent H-mean using only the accelerometer and only five keyboard taps. We also experiment with using only three keyboard taps and find that the system still yields high accuracy while giving additional opportunities to make more decisions that can result in more accurate final decisions.},
  archive      = {J_TMC},
  author       = {Lichao Sun and Bokai Cao and Ji Wang and Witawas Srisa-an and Philip S. Yu and Alex D. Leow and Stephen Checkoway},
  doi          = {10.1109/TMC.2020.2964226},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1465-1476},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Kollector: Detecting fraudulent activities on mobile devices using deep learning},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Joint scheduling and incentive mechanism for spatio-temporal
vehicular crowd sensing. <em>TMC</em>, <em>20</em>(4), 1449–1464. (<a
href="https://doi.org/10.1109/TMC.2019.2960328">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have witnessed the rising popularity of urban vehicular crowd sensing (UVCS) systems that leverage drivers’ mobile devices equipped with on-board sensors for various urban sensing tasks. Because of the importance of ensuring satisfactory spatio-temporal sensing coverage in such UVCS systems, most existing work has focus on designing efficient scheduling mechanisms to maximize the task completion rate under drivers’ traveling constraints. Different from prior work, we propose Hector, a joint trajectory scheduling and incentive mechanism for spatio-temporal UVCS systems, which concentrates on capturing the interactive effects between scheduling and incentive mechanisms. Technically, we first reduce the dimensions of the original scheduling problem by mapping it into an augmented set cover problem with spatio-temporal constraints. Then, based on reverse combinatorial auctions, we design Hector, whose incentive mechanism with the presence of uncertain future trajectory information makes scheduling and compensation decisions in real-time. Specifically, Hector is truthful , individual rational and computationally efficient . Furthermore, the social cost yielded by Hector is close-to-optimal, and the approximation ratio is &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$H_m$&lt;/tex-math&gt;&lt;/inline-formula&gt; . The advantageous properties of Hector are verified by both rigorous theoretical analysis and extensive simulations based on the real world datasets in the Chinese city Shenzhen which consists of 726,000 taxi trajectories.},
  archive      = {J_TMC},
  author       = {Guiyun Fan and Haiming Jin and Qihong Liu and Wei Qin and Xiaoying Gan and Huan Long and Luoyi Fu and Xinbing Wang},
  doi          = {10.1109/TMC.2019.2960328},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1449-1464},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Joint scheduling and incentive mechanism for spatio-temporal vehicular crowd sensing},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). IoT and HIP’s opportunistic mode. <em>TMC</em>,
<em>20</em>(4), 1434–1448. (<a
href="https://doi.org/10.1109/TMC.2020.2967044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Key sharing has always been a complex issue. It became even more challenging for the Internet of Things (IoT), where a trusted third party for global management rarely exists. With authentication and confidentiality lacking, things resort to a leap of faith (LoF) paradigm where it is assumed that no attacker is present during the initial configuration. In this paper we focus on the Host Identity Protocol (HIP), specifically designed to provide mobility and multihoming capabilities. Although HIP is normally based on many strict security mechanisms (e.g., DNSSEC), it also provides a better than nothing opportunistic mode, based on the LoF paradigm, which is to be used when other more trusted mechanisms are not available. In this paper, we analyze different MiTM attacks which might occur under this opportunistic mode. Taking advantage of HIP&#39;s multihoming capabilities, we propose two key spraying techniques which strengthen the opportunistic mode&#39;s security. The first technique spreads the four key-exchange messages among different networks, while the second spreads fractions of one of those messages. Evaluation of these techniques is provided, demonstrating the major benefit of our proposal.},
  archive      = {J_TMC},
  author       = {Adel Fuchs and Ariel Stulman and Andrei Gurtov},
  doi          = {10.1109/TMC.2020.2967044},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1434-1448},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {IoT and HIP&#39;s opportunistic mode},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). GazMon: Eye gazing enabled driving behavior monitoring and
prediction. <em>TMC</em>, <em>20</em>(4), 1420–1433. (<a
href="https://doi.org/10.1109/TMC.2019.2962764">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automobiles have become one of the necessities of modern life, but also introduced numerous traffic accidents that threaten drivers and other road users. Most state-of-the-art safety systems are passively triggered, reacting to dangerous road conditions or driving maneuvers only after they happen and are observed, which greatly limits the last chances for collision avoidances. Timely tracking and predicting the driving maneuvers calls for a more direct interface beyond the traditional steering wheel/brake/gas pedal. In this paper, we argue that a driver&#39;s eyes are the interface, as it is the first and the essential window that gathers external information during driving. Our experiments suggest that a driver&#39;s gaze patterns appear prior to and correlate with the driving maneuvers for driving maneuver prediction. We accordingly present GazMon, an active driving maneuver monitoring and prediction framework for driving assistance applications. GazMon extracts the gaze information through a front-camera and analyzes the facial features, including facial landmarks, head pose, and iris centers, through a carefully constructed deep learning architecture. Both our on-road experiments and driving simulator based evaluations demonstrate the superiority of our GazMon on predicting driving maneuvers as well as other distracted behaviors. It is readily deployable using RGB cameras and allows reuse of existing smartphones towards more safely driving.},
  archive      = {J_TMC},
  author       = {Xiaoyi Fan and Feng Wang and Danyang Song and Yuhe Lu and Jiangchuan Liu},
  doi          = {10.1109/TMC.2019.2962764},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1420-1433},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {GazMon: Eye gazing enabled driving behavior monitoring and prediction},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fair configuration scheme for random access in NB-IoT with
multiple coverage enhancement levels. <em>TMC</em>, <em>20</em>(4),
1408–1419. (<a href="https://doi.org/10.1109/TMC.2019.2962422">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Narrowband Internet of Things (NB-IoT) is a new technology developed to support low-power wide area networks (LPWAN) services. To extend its coverage and decrease its transmission power, devices in one NB-IoT cell are divided into several coverage enhancement (CE) levels with different random access configuration. This potentially results in unfair access, especially when massive number of devices in different CE levels simultaneously accessing the network. This work presents an effective strategy to configure the random access in NB-IoT to yield fair performance across CE levels. An analytical model is used to estimate the performance of each CE level and overall system performance in term of normalized throughput and average access delay. Simulation is incorporated to verify the accuracy of the model. Different practical assumptions of fair system are explored and examined in the experiment. The result shows that the analytical model is accurate under various loads. Additionally, the proposed search strategy is proven to be able to obtain the configuration which yield acceptable throughput fairly for all CE levels.},
  archive      = {J_TMC},
  author       = {Ruki Harwahyu and Ray-Guang Cheng and Da-Hao Liu and Riri Fitri Sari},
  doi          = {10.1109/TMC.2019.2962422},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1408-1419},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Fair configuration scheme for random access in NB-IoT with multiple coverage enhancement levels},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Enhancing dynamic-viewport mobile applications with screen
scrolling. <em>TMC</em>, <em>20</em>(4), 1393–1407. (<a
href="https://doi.org/10.1109/TMC.2019.2959524">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pervasive penetration of mobile smart devices has significantly enriched Internet applications and undoubtedly reshaped the way that users access Internet services. Different from traditional desktop applications, mobile Internet applications require users to input via touch screens and view outputs on the displays with considerably limited size. The significant conflict between the limited-size of touch screens and the richness of online media contents widely exists in dynamic-viewport mobile applications, a class of mobile Internet applications that download contents beyond the user&#39;s viewing region (referred to as viewport). As dynamic-viewport mobile applications usually use HTTP for content downloading, to improve their quality of experience (QoE) and cost efficiency, in this paper, we present a Mobile-Friendly HTTP middleware (MF-HTTP), which can interpret user touch screen inputs and optimize the HTTP downloading of media objects for such applications. We first demystify screen scrolling in mobile operating systems and precisely break down the viewport moving process. We identify the key influential factors for media object downloading and develop an optimal download scheme. Towards building a practical middleware, we further discuss and address the implementation issues in detail. We implement a MF-HTTP prototype based on Android platforms and evaluate the performance of MF-HTTP by conducting concrete case studies on two representative dynamic-viewport mobile applications, namely, web browsing and 360-degree video streaming.},
  archive      = {J_TMC},
  author       = {Lei Zhang and Feng Wang and Jiangchuan Liu},
  doi          = {10.1109/TMC.2019.2959524},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1393-1407},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Enhancing dynamic-viewport mobile applications with screen scrolling},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Edge-enabled V2X service placement for intelligent
transportation systems. <em>TMC</em>, <em>20</em>(4), 1380–1392. (<a
href="https://doi.org/10.1109/TMC.2020.2965929">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle-to-everything (V2X) communication and services have been garnering significant interest from different stakeholders as part of future intelligent transportation systems (ITSs). This is due to the many benefits they offer. However, many of these services have stringent performance requirements, particularly in terms of the delay/latency. Multi-access/mobile edge computing (MEC) has been proposed as a potential solution for such services by bringing them closer to vehicles. Yet, this introduces a new set of challenges such as where to place these V2X services, especially given the limit computation resources available at edge nodes. To that end, this work formulates the problem of optimal V2X service placement (OVSP) in a hybrid core/edge environment as a binary integer linear programming problem. To the best of our knowledge, no previous work considered the V2X service placement problem while taking into consideration the computational resource availability at the nodes. Moreover, a low-complexity greedy-based heuristic algorithm named “Greedy V2X Service Placement Algorithm” (G-VSPA) was developed to solve this problem. Simulation results show that the OVSP model successfully guarantees and maintains the QoS requirements of all the different V2X services. Additionally, it is observed that the proposed G-VSPA algorithm achieves close to optimal performance while having lower complexity.},
  archive      = {J_TMC},
  author       = {Abdallah Moubayed and Abdallah Shami and Parisa Heidari and Adel Larabi and Richard Brunner},
  doi          = {10.1109/TMC.2020.2965929},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1380-1392},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Edge-enabled V2X service placement for intelligent transportation systems},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic model for network selection in next generation
HetNets with memory-affecting rational users. <em>TMC</em>,
<em>20</em>(4), 1365–1379. (<a
href="https://doi.org/10.1109/TMC.2020.2965450">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, due to the staggering growth of wireless data traffic, heterogeneous networks have drawn tremendous attention due to the capabilities of enhancing the capacity/coverage and reducing energy consumption for the next generation wireless networks. In this paper, we study a long-run user-centric network selection problem in the 5G heterogeneous network, where the network selection strategies of the users can be investigated dynamically. Unlike the conventional studies on the long-run model, we incorporate the memory effect and consider the fact that the decision-making of the users is affected by their memory, i.e., their past service experience. Namely, the users select the network based on not only their instantaneous achievable service experience but also their past service experience within their memory. Specifically, we model and study the interaction among the users in the framework of fractional evolutionary game based on the classical evolutionary game theory and the concept of the power-law memory. We analytically prove that the equilibrium of the fractional evolutionary game exists, is unique and uniformly stable. We also numerically demonstrate the stability of the fractional evolutionary equilibrium. Extensive simulations have been conducted to evaluate the performance of the fractional evolutionary game. The numerical results have revealed some insightful findings. For example, the user in the fractional evolutionary game with positive memory effect can achieve a higher cumulative utility compared with the user in the fractional evolutionary game with negative memory effect. Moreover, the fractional evolutionary game with positive memory effect can reduce the loss in the user&#39;s cumulative utility caused by the small-scale fading.},
  archive      = {J_TMC},
  author       = {Shaohan Feng and Dusit Niyato and Xiao Lu and Ping Wang and Dong In Kim},
  doi          = {10.1109/TMC.2020.2965450},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1365-1379},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Dynamic model for network selection in next generation HetNets with memory-affecting rational users},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep neural network based inertial odometry using low-cost
inertial measurement units. <em>TMC</em>, <em>20</em>(4), 1351–1364. (<a
href="https://doi.org/10.1109/TMC.2019.2960780">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inertial measurement units (IMUs) have emerged as an essential component in many of today&#39;s indoor navigation solutions due to their low cost and ease of use. However, despite many attempts for reducing the error growth of navigation systems based on commercial-grade inertial sensors, there is still no satisfactory solution that produces navigation estimates with long-time stability in widely differing conditions. This paper proposes to break the cycle of continuous integration used in traditional inertial algorithms, formulate it as an optimization problem, and explore the use of deep recurrent neural networks for estimating the displacement of a user over a specified time window. By training the deep neural network using inertial measurements and ground truth displacement data, it is possible to learn both motion characteristics and systematic error drift. As opposed to established context-aided inertial solutions, the proposed method is not dependent on either fixed sensor positions or periodic motion patterns. It can reconstruct accurate trajectories directly from raw inertial measurements, and predict the corresponding uncertainty to show model confidence. Extensive experimental evaluations demonstrate that the neural network produces position estimates with high accuracy for several different attachments, users, sensors, and motion types. As a particular demonstration of its flexibility, our deep inertial solutions can estimate trajectories for non-periodic motion, such as the shopping trolley tracking. Further more, it works in highly dynamic conditions, such as running, remaining extremely challenging for current techniques.},
  archive      = {J_TMC},
  author       = {Changhao Chen and Chris Xiaoxuan Lu and Johan Wahlström and Andrew Markham and Niki Trigoni},
  doi          = {10.1109/TMC.2019.2960780},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1351-1364},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Deep neural network based inertial odometry using low-cost inertial measurement units},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Coding for distributed fog computing in internet of mobile
things. <em>TMC</em>, <em>20</em>(4), 1337–1350. (<a
href="https://doi.org/10.1109/TMC.2019.2963668">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Mobile Things (IoMTs) refers to the interconnection of mobile devices, for example, mobile phones, vehicles, robots, etc. For mobile data, strong extra processing resources are normally required due to the limited physical resources of the mobile devices in IoMTs. Due to latency or bandwidth limitations, it may be infeasible to transfer a large amounts of mobile data to remote server for processing. Thus, distributed computing is one of the potential solutions to overcome these limitations. We consider the device mobility in IoMTs. Two situations of the movement position of the mobile devices, i.e., unpredictable and predictable, are considered. In addition, three possible relative positions between the two server sets which respectively correspond to the positions of a mobile device for computation tasks offloading and for output results receiving, i.e., within the same server sets, with two different server sets and with two adjacent server sets, are studied. Coded schemes with high flexibility and low complexity are proposed based on Fountain codes to reduce the total processing time and latency of the distributed fog computing process in IoMTs for the above different situations. The latency related performance, i.e., the computation, the communication and the transmission loads, is analyzed. We also compare of the Fountain code-based and the uncoded schemes and numerical results demonstrate that shorter total processing time and lower latency can be achieved by the Fountain code-based schemes.},
  archive      = {J_TMC},
  author       = {Jing Yue and Ming Xiao},
  doi          = {10.1109/TMC.2019.2963668},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1337-1350},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Coding for distributed fog computing in internet of mobile things},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Characterizing delay and control traffic of the cellular MME
with IoT support. <em>TMC</em>, <em>20</em>(4), 1325–1336. (<a
href="https://doi.org/10.1109/TMC.2020.2964677">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the main use cases for advanced cellular networks is represented by massive Internet-of-things (MIoT), i.e., an enormous number of IoT devices that transmit data toward the cellular network infrastructure. To make cellular MIoT a reality, data transfer and control procedures specifically designed for the support of IoT are needed. For this reason, 3GPP has introduced the Control Plane Cellular IoT optimization, which foresees a simplified bearer instantiation, with the Mobility Management Entity (MME) handling both control and data traffic. The performance of the MME has therefore become critical, and properly scaling its computational capability can determine the ability of the whole network to tackle MIoT effectively. In particular, considering virtualized networks and the need for an efficient allocation of computing resources, it is paramount to characterize the MME performance as the MIoT traffic load changes. We address this need by presenting compact, closed-form expressions linking the number of IoT sources with the rate at which bearers are requested, and such a rate with the delay incurred by the IoT data. We show that our analysis, supported by testbed experiments and verified through large-scale simulations, represents a valuable tool to make effective scaling decisions in virtualized cellular core networks.},
  archive      = {J_TMC},
  author       = {Christian Vitale and Carla Fabiana Chiasserini and Francesco Malandrino and Senay Semu Tadesse},
  doi          = {10.1109/TMC.2020.2964677},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1325-1336},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Characterizing delay and control traffic of the cellular MME with IoT support},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Autonomous UAV trajectory for localizing ground objects: A
reinforcement learning approach. <em>TMC</em>, <em>20</em>(4),
1312–1324. (<a href="https://doi.org/10.1109/TMC.2020.2966989">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Disaster management, search and rescue missions, and health monitoring are examples of critical applications that require object localization with high precision and sometimes in a timely manner. In the absence of the global positioning system (GPS), the radio received signal strength index (RSSI) can be used for localization purposes due to its simplicity and cost-effectiveness. However, due to the low accuracy of RSSI, unmanned aerial vehicles (UAVs) or drones may be used as an efficient solution for improved localization accuracy due to their agility and higher probability of line-of-sight (LoS). Hence, in this context, we propose a novel framework based on reinforcement learning (RL) to enable a UAV (agent) to autonomously find its trajectory that results in improving the localization accuracy of multiple objects in shortest time and path length, fewer signal-strength measurements (waypoints), and/or lower UAV energy consumption. In particular, we first control the agent through initial scan trajectory on the whole region to 1) know the number of nodes and estimate their initial locations, and 2) train the agent online during operation. Then, the agent forms its trajectory by using RL to choose the next waypoints in order to minimize the average location errors of all objects. Our framework includes detailed UAV to ground channel characteristics with an empirical path loss and log-normal shadowing model, and also with an elaborate energy consumption model. We investigate and compare the localization precision of our approach with existing methods from the literature by varying the UAV&#39;s trajectory length, energy, number of waypoints, and time. Furthermore, we study the impact of the UAV&#39;s velocity, altitude, hovering time, communication range, number of maximum RSSI measurements, and number of objects. The results show the superiority of our method over the state-of-art and demonstrates its fast reduction of the localization error.},
  archive      = {J_TMC},
  author       = {Dariush Ebrahimi and Sanaa Sharafeddine and Pin-Han Ho and Chadi Assi},
  doi          = {10.1109/TMC.2020.2966989},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1312-1324},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Autonomous UAV trajectory for localizing ground objects: A reinforcement learning approach},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An application placement technique for concurrent IoT
applications in edge and fog computing environments. <em>TMC</em>,
<em>20</em>(4), 1298–1311. (<a
href="https://doi.org/10.1109/TMC.2020.2967041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fog/Edge computing emerges as a novel computing paradigm that harnesses resources in the proximity of the Internet of Things (IoT) devices so that, alongside with the cloud servers, provide services in a timely manner. However, due to the ever-increasing growth of IoT devices with resource-hungry applications, fog/edge servers with limited resources cannot efficiently satisfy the requirements of the IoT applications. Therefore, the application placement in the fog/edge computing environment, in which several distributed fog/edge servers and centralized cloud servers are available, is a challenging issue. In this article, we propose a weighted cost model to minimize the execution time and energy consumption of IoT applications, in a computing environment with multiple IoT devices, multiple fog/edge servers and cloud servers. Besides, a new application placement technique based on the Memetic Algorithm is proposed to make batch application placement decision for concurrent IoT applications. Due to the heterogeneity of IoT applications, we also propose a lightweight pre-scheduling algorithm to maximize the number of parallel tasks for the concurrent execution. The performance results demonstrate that our technique significantly improves the weighted cost of IoT applications up to 65 percent in comparison to its counterparts.},
  archive      = {J_TMC},
  author       = {Mohammad Goudarzi and Huaming Wu and Marimuthu Palaniswami and Rajkumar Buyya},
  doi          = {10.1109/TMC.2020.2967041},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1298-1311},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {An application placement technique for concurrent IoT applications in edge and fog computing environments},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AdSherlock: Efficient and deployable click fraud detection
for mobile applications. <em>TMC</em>, <em>20</em>(4), 1285–1297. (<a
href="https://doi.org/10.1109/TMC.2020.2966991">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile advertising plays a vital role in the mobile app ecosystem. A major threat to the sustainability of this ecosystem is click fraud, i.e., ad clicks performed by malicious code or automatic bot problems. Existing click fraud detection approaches focus on analyzing the ad requests at the server side. However, such approaches may suffer from high false negatives since the detection can be easily circumvented, e.g., when the clicks are behind proxies or globally distributed. In this paper, we present AdSherlock, an efficient and deployable click fraud detection approach at the client side (inside the application) for mobile apps. AdSherlock splits the computation-intensive operations of click request identification into an offline procedure and an online procedure. In the offline procedure, AdSherlock generates both exact patterns and probabilistic patterns based on URL (Uniform Resource Locator) tokenization. These patterns are used in the online procedure for click request identification and further used for click fraud detection together with an ad request tree model. We implement a prototype of AdSherlock and evaluate its performance using real apps. The online detector is injected into the app executable archive through binary instrumentation. Results show that AdSherlock achieves higher click fraud detection accuracy compared with state of the art, with negligible runtime overhead.},
  archive      = {J_TMC},
  author       = {Chenhong Cao and Yi Gao and Yang Luo and Mingyuan Xia and Wei Dong and Chun Chen and Xue Liu},
  doi          = {10.1109/TMC.2020.2966991},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1285-1297},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {AdSherlock: Efficient and deployable click fraud detection for mobile applications},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Accurate localization of tagged objects using mobile
RFID-augmented robots. <em>TMC</em>, <em>20</em>(4), 1273–1284. (<a
href="https://doi.org/10.1109/TMC.2019.2962129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the problem of tag localization using RFID-augmented robots, which is practically important for promising warehousing applications, e.g., automatic item fetching and misplacement detection. Existing RFID localization systems suffer from one or more of following limitations: requiring specialized devices; only 2D localization is enabled; having blind zone for mobile localization; low scalability. In this paper, we use Commercial Off-The-Shelf (COTS) robot and RFID devices to implement a Mobile RF-robot Localization (MRL) system. Specifically, when the RFID-augmented robot moves along the straight aisle in a warehouse, the reader keeps reading the target tag via two vertically deployed antennas ( Z1 and Z2) and returns the tag phase data with timestamps to the server. We take three points in the phase profile of antenna Z1 and leverage the spatial and temporal changes inherent in this phase triad to construct an equation set. By solving it, we achieve the location of target tag relative to the trajectory of antenna Z1. Based on different phase triads, we can have candidate locations of the target tag with different accuracy. Then, we propose theoretical analysis to quantify the deviation of each localization result. A fine-grained localization result can be achieved by assigning larger weights to the localization results with smaller deviations. Similarly, we can also calculate the relative location of target tag with respect to the trajectory of antenna Z2. Leveraging the geometric relationships among target tag and antenna trajectories, we eventually calculate the location of target tag in 3D space. We perform various experiments to evaluate the performance of the MRL system and results show that the proposed MRL system can achieve high accuracy in both 2D and 3D localization.},
  archive      = {J_TMC},
  author       = {Xiulong Liu and Jiuwu Zhang and Shan Jiang and Yanni Yang and Keqiu Li and Jiannong Cao and Jiangchuan Liu},
  doi          = {10.1109/TMC.2019.2962129},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1273-1284},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Accurate localization of tagged objects using mobile RFID-augmented robots},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A near-optimal protocol for the grouping problem in RFID
systems. <em>TMC</em>, <em>20</em>(4), 1257–1272. (<a
href="https://doi.org/10.1109/TMC.2019.2962125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radio frequency identification (RFID) has been widely used in many fields such as object tracking and inventory management. For RFID systems, grouping is a fundamental issue which can support efficient multicast transmissions, dynamic tag management, and accurate aggregate queries. Existing grouping protocols have drawbacks of unknown theoretical communication time, high computational cost on the server end and inability to deal with unexpected tags which are those tags whose IDs have not been collected by readers. In this paper, we would like to address the above limitations and consider a more general grouping problem that allows an arbitrary number of unexpected tags to present. Our objective is to design a protocol that guarantees the reader to efficiently and correctly notify each known tag of its group-ID, while the probability that an unexpected tag is mistakenly notified of any group-ID is smaller than a pre-determined value. In this paper, we first obtain a lower bound on the communication time for solving this generalized grouping problem. Then, we propose a near-optimal protocol, called OPT-G, and prove that its communication time approximately equals the lower bound. Finally, we report extensive simulation results that demonstrate OPT-G&#39;s near-optimal performance and its superiority over existing baseline schemes.},
  archive      = {J_TMC},
  author       = {Xiujun Wang and Zhi Liu and Yan Gao and Xiao Zheng and Zhe Dang and Xiaojun Shen},
  doi          = {10.1109/TMC.2019.2962125},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1257-1272},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A near-optimal protocol for the grouping problem in RFID systems},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). WiFi based multi-user gesture recognition. <em>TMC</em>,
<em>20</em>(3), 1242–1256. (<a
href="https://doi.org/10.1109/TMC.2019.2954891">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {WiFi based gesture recognition has received significant attention over the past few years. However, the key limitation of prior WiFi based gesture recognition systems is that they cannot recognize the gestures of multiple users performing them simultaneously. In this article, we address this limitation and propose WiMU, a Wi Fi based M ulti- U ser gesture recognition system. The key idea behind WiMU is that when it detects that some users have performed some gestures simultaneously, it first automatically determines the number of simultaneously performed gestures ( &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$N_a$&lt;/tex-math&gt;&lt;/inline-formula&gt; ) and then, using the training samples collected from a single user, generates virtual samples for various plausible combinations of &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$N_a$&lt;/tex-math&gt;&lt;/inline-formula&gt; gestures. The key property of these virtual samples is that the virtual samples for any given combination of gestures are identical to the real samples that would result from real users performing that combination of gestures. WiMU compares the detected sample against these virtual samples and recognizes the simultaneously performed gestures. We implemented and extensively evaluated WiMU using commodity WiFi devices. Our results show that WiMU recognizes 2, 3, 4, 5, 6, 7, and 8 simultaneously performed gestures with accuracies of 95.6, 94.9, 93.9, 92.7, 91.6, 91.0, and 90.1 percent, respectively.},
  archive      = {J_TMC},
  author       = {Raghav H. Venkatnarayan and Shakir Mahmood and Muhammad Shahzad},
  doi          = {10.1109/TMC.2019.2954891},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1242-1256},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {WiFi based multi-user gesture recognition},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Strategic learning approach for deploying UAV-provided
wireless services. <em>TMC</em>, <em>20</em>(3), 1230–1241. (<a
href="https://doi.org/10.1109/TMC.2019.2953726">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicle (UAV) have emerged as a promising technique to rapidly provide wireless services to a group of mobile users simultaneously. The article aims to address a challenging issue that each user is selfish and may misreport his location or preference for changing the optimal UAV location to be close to himself. Using algorithmic game theory, we study how to determine the final location of a UAV in the 3D space, by ensuring all selfish users’ truthfulness in reporting their locations for learning purpose. To minimize the social service cost in this UAV placement game, we design strategyproof mechanisms with the approximation ratios, when comparing to the social optimum. We also study the obnoxious UAV placement game to maximally keep their social utility, where each incumbent user may misreport his location to keep the UAV away from him. Moreover, we present the dual-preference UAV placement game by considering the coexistence of the two groups of users above, where users can misreport both their locations and preference types (favorable or obnoxious) towards the UAV. Finally, we extend the three games above to include multiple UAVs and design strategyproof mechanisms with provable approximation ratios.},
  archive      = {J_TMC},
  author       = {Xinping Xu and Lingjie Duan and Minming Li},
  doi          = {10.1109/TMC.2019.2953726},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1230-1241},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Strategic learning approach for deploying UAV-provided wireless services},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Software-defined cooperative data sharing in edge computing
assisted 5G-VANET. <em>TMC</em>, <em>20</em>(3), 1212–1229. (<a
href="https://doi.org/10.1109/TMC.2019.2953163">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is widely recognized that connected vehicles have the potential to further improve the road safety, transportation intelligence and enhance the in-vehicle entertainment. By leveraging the 5G enabled Vehicular Ad hoc NETworks (VANET) technology, which is referred to as 5G-VANET, a flexible software-defined communication can be achieved with ultra-high reliability, low latency, and high capacity. Many enabling applications in 5G-VANET rely on sharing mobile data among vehicles, which is still a challenging issue due to the extremely large data volume and the prohibitive cost of transmitting such data using 5G cellular networks. This article focuses on efficient cooperative data sharing in edge computing assisted 5G-VANET. First, to enable efficient cooperation between cellular communication and Dedicated Short-Range Communication (DSRC), we first propose a software-defined cooperative data sharing architecture in 5G-VANET. The cellular link allows the communications between OpenFlow enabled vehicles and the Controller to collect contextual information, while the DSRC serves as the data plane, enabling cooperative data sharing among adjacent vehicles. Second, we propose a graph theory based algorithm to efficiently solve the data sharing problem, which is formulated as a maximum weighted independent set problem on the constructed conflict graph. Specifically, considering the continuous data sharing, we propose a balanced greedy algorithm, which can make the content distribution more balanced. Furthermore, due to the fixed amount of computing resources allocated to this software-defined cooperative data sharing service, we propose an integer linear programming based decomposition algorithm to make full use of the computing resources. Extensive simulations in NS3 and SUMO demonstrate the superiority and scalability of the proposed software-defined architecture and cooperative data sharing algorithms.},
  archive      = {J_TMC},
  author       = {Guiyang Luo and Haibo Zhou and Nan Cheng and Quan Yuan and Jinglin Li and Fangchun Yang and Xuemin Shen},
  doi          = {10.1109/TMC.2019.2953163},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1212-1229},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Software-defined cooperative data sharing in edge computing assisted 5G-VANET},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SatProbe: Low-energy and fast indoor/outdoor detection via
satellite existence sensing. <em>TMC</em>, <em>20</em>(3), 1198–1211.
(<a href="https://doi.org/10.1109/TMC.2019.2954873">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Indoor-outdoor (IO) detection provides very useful hints for a mobile device to perform context-aware services. To that end, GPS presents a viable solution by relating a device&#39;s IO status with its positioning performance, which depends on the device&#39;s exposure to the open sky. This approach, however, is prohibitively expensive in terms of energy consumption and response time. Recent work has thus been focused on exploiting low-energy sensors such as light, cellular, and magnetic sensors to infer the IO status indirectly, at the cost of reduced adaptability or manual labeling effort. In this article, we propose a new method to address these problems. Our method, called SatProbe, reverts to the GPS approach for its directness and robustness, but avoids its drawback by extracting only the number of visible satellites from the raw GPS data, instead of going through extensive computation to obtain a final position. This metric provides a clear indicator of the IO status, yet can be obtained with great efficiency. Experiments on 79 raw GPS traces with 2595 detection points across a variety of environments show that SatProbe produces a 14.2 percent improvement in detection accuracy, with a 98.8 percent reduction in both energy use and detection time, in comparison with the standard GPS method.},
  archive      = {J_TMC},
  author       = {Kongyang Chen and Guang Tan},
  doi          = {10.1109/TMC.2019.2954873},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1198-1211},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {SatProbe: Low-energy and fast Indoor/Outdoor detection via satellite existence sensing},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal scheduling for unmanned aerial vehicle networks with
flow-level dynamics. <em>TMC</em>, <em>20</em>(3), 1186–1197. (<a
href="https://doi.org/10.1109/TMC.2019.2952848">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicle (UAV) Networks have recently attracted great attention as being able to provide convenient and fast wireless connections. One central question is how to allocate a limited number of UAVs to provide wireless services across a large number of regions, where each region has dynamic arriving flows and flows depart from the system once they receive the desired amount of service (referred to as the flow-level dynamic model). In this article, we propose a MaxWeight-type scheduling algorithm taking into account sharp flow-level dynamics that efficiently redirect UAVs across a large number of regions. However, in our considered model, each flow experiences an independent fading channel and will immediately leave the system once it completes its service, which makes its evolution quite different from the traditional queueing model for wireless networks. This poses significant challenges in our performance analysis. Nevertheless, we incorporate sharp flow-dynamic into the Lyapunov-drift analysis framework, and successfully establish both throughput and heavy-traffic optimality of the proposed algorithm. Extensive simulations are performed to validate the effectiveness of our proposed algorithm.},
  archive      = {J_TMC},
  author       = {Xiangqi Kong and Ning Lu and Bin Li},
  doi          = {10.1109/TMC.2019.2952848},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1186-1197},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Optimal scheduling for unmanned aerial vehicle networks with flow-level dynamics},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Minimizing the age of information in wireless networks with
stochastic arrivals. <em>TMC</em>, <em>20</em>(3), 1173–1185. (<a
href="https://doi.org/10.1109/TMC.2019.2959774">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a wireless network with a base station serving multiple traffic streams to different destinations. Packets from each stream arrive to the base station according to a stochastic process and are enqueued in a separate (per stream) queue. The queueing discipline controls which packet within each queue is available for transmission. The base station decides, at every time t, which stream to serve to the corresponding destination. The goal of scheduling decisions is to keep the information at the destinations fresh. Information freshness is captured by the Age of Information (AoI) metric. In this paper, we derive a lower bound on the AoI performance achievable by any given network operating under any queueing discipline. Then, we consider three common queueing disciplines and develop both an Optimal Stationary Randomized policy and a Max-Weight policy under each discipline. Our approach allows us to evaluate the combined impact of the stochastic arrivals, queueing discipline and scheduling policy on AoI. We evaluate the AoI performance both analytically and using simulations. Numerical results show that the performance of the Max-Weight policy is close to the analytical lower bound.},
  archive      = {J_TMC},
  author       = {Igor Kadota and Eytan Modiano},
  doi          = {10.1109/TMC.2019.2959774},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1173-1185},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Minimizing the age of information in wireless networks with stochastic arrivals},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Messages classification and dynamic batch verification
scheme for VANETs. <em>TMC</em>, <em>20</em>(3), 1156–1172. (<a
href="https://doi.org/10.1109/TMC.2019.2952105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Under a high-density traffic environment in a vehicular ad hoc network (VANET), many safety messages will not be verified in time and then get dropped. To touch such an issue appropriately, we aim at improving the efficiency of message verification and the number of verified safety messages. In our proposed scheme, messages are properly classified and prioritized first so that more important basic safety messages can be verified earlier. To improve batch verification, a dynamic batch verification scheme with an adjustable batch size is designed accordingly. The batch size is halved when failures of batch verification occur consecutively over a certain threshold to improve the efficiency of batch verification. On the contrary, the batch size is doubled when successes of batch verification occur consecutively over a certain threshold to increase the messages in a batch to be verified. For a failure of batch verification, a divide-and-conquer approach is utilized to find the illegitimate message(s). Via analysis, the superiority of our design over some closely related schemes in terms of verification delay and number of verified basic safety messages etc. is successfully demonstrated. By simulation, performance of our design and some closely related schemes is further investigated in realistic scenarios.},
  archive      = {J_TMC},
  author       = {Huei-Wen Ferng and Jia-Ying Chen and Amin Lotfolahi and Ying-Tsu Tseng and Si-Yuan Zhang},
  doi          = {10.1109/TMC.2019.2952105},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1156-1172},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Messages classification and dynamic batch verification scheme for VANETs},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MAdLens: Investigating into android in-app ad practice at
API granularity. <em>TMC</em>, <em>20</em>(3), 1138–1155. (<a
href="https://doi.org/10.1109/TMC.2019.2953609">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In-app advertising has served as the major revenue source for millions of app developers in the mobile Internet ecosystem. Ad networks play an important role in app monetization by providing third-party libraries for developers to choose and embed into their apps. Various ad mediations help developers manage all of the ad libraries used in apps to show the best available ad among received ads from different ad network servers. However, developers lack guidelines on how to choose from hundreds of ad networks or ad mediations and various ad features to maximize their revenues without hurting the user experience of their apps. Our work aims to provide app developers guidelines on the selection of ad networks, ad mediations, and ad placement by observing current common practices. To this end, we investigate 838 unique APIs from 207 ad networks which are extracted from 277,616 Android apps, develop a methodology of ad type classification based on UI interaction and behavior, and perform a large scale measurement study of in-app ads with static analysis techniques at the API granularity. We found that developers have more choices about ad networks than several years before. Most developers are conservative about ad placement and about 77 percent of the apps contain at most one ad library. Besides, the likeliness of an app containing ads depends on the app category to which it belongs. Furthermore, we propose a terminology and classify mobile ads into five ad types: Embedded, Popup, Notification, Offerwall, and Floating. Also, our research shows that it is a better solution for developers to integrate ad libraries with ad mediation feature in their apps because it may avoid bad ratings and improve user experience. And in our findings, more than 95 percent of embedded, popup, notification, and offer ads locate in the zero activity (main activity), the first activity and the second activity of Android apps. More interestingly, developers tend to put high aggressive ads on activities which need deeper user interaction. Our research is the first to reveal the preference of both developers and users for ad networks, ad mediation feature and ad types.},
  archive      = {J_TMC},
  author       = {Ling Jin and Boyuan He and Guangyao Weng and Haitao Xu and Yan Chen and Guanyu Guo},
  doi          = {10.1109/TMC.2019.2953609},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1138-1155},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {MAdLens: Investigating into android in-app ad practice at API granularity},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Localization of acoustically tagged marine animals in
under-ranked conditions. <em>TMC</em>, <em>20</em>(3), 1126–1137. (<a
href="https://doi.org/10.1109/TMC.2019.2959765">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A key technology in the movement tracking of marine animals is localization using acoustic transmitters. These are attached to marine animals and are detected by an array of receivers. Then, offline localization is performed by multilateration. However, due to the transmitter&#39;s low power and environmental conditions, emissions may be detected by only a limited number of receivers, causing localization ambiguities to arise. This work proposes a solution for such localization ambiguities. The proposed method assumes that the position of acoustically-tagged marine animals follows a hidden Markov model, such that localization ambiguities can probabilistically be resolved using a Forward-Backward algorithm. Our method is able to extrapolate the positions in a data series, as long as one sample in that series is picked up by three receivers, or if the identity of the receivers changes during tracking. Performance analysis shows that the localization accuracy of our method approaches the Cramér-Rao lower bound. Furthermore, to demonstrate the suitability of our method in a real sea environment, we have established a testbed that operated for three months, demonstrating localization of 20 acoustically-tagged sandbar sharks. Compared to the available solutions, roughly 20 times more location estimates were made; thereby, significantly increasing the impact of the test-site.},
  archive      = {J_TMC},
  author       = {Talmon Alexandri and Ziv Zemah Shamir and Eyal Bigal and Aviad Scheinin and Dan Tchernov and Roee Diamant},
  doi          = {10.1109/TMC.2019.2959765},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1126-1137},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Localization of acoustically tagged marine animals in under-ranked conditions},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). LEDGE: Leveraging edge computing for resilient access
management of mobile IoT. <em>TMC</em>, <em>20</em>(3), 1110–1125. (<a
href="https://doi.org/10.1109/TMC.2019.2954872">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the blooming of Internet of Things (IoT), heterogeneous IoT mobile devices emerge to connect the network infrastructure. Traditional mobile access system faces several challenges arising from these IoT devices: 1) centralized controllers are distant from the end devices, 2) inefficient access control of heterogeneous IoT devices, and 3) insufficient authentication and monitoring for IoT devices. In order to tackle the challenges from IoT devices on mobile access control and scalable access monitoring, we present LEDGE, an agile and secured software-defined edge computing system for resilient access management of mobile IoT. In a nutshell, our LEDGE is a synergy of an efficient location authentication method to secure communication between each IoT mobile device and access point (AP) pair, an optimal AP assignment scheme to satisfy IoT flow requests, a Personal AP protocol for scalable access, and a deep learning model for anomaly detection. We prototype our system, and realistic testbed experiments demonstrate that LEDGE could achieve promising results in mobile IoT.},
  archive      = {J_TMC},
  author       = {Di Wu and Xin Huang and Xiaofeng Xie and Xiang Nie and Lichun Bao and Zhijin Qin},
  doi          = {10.1109/TMC.2019.2954872},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1110-1125},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {LEDGE: Leveraging edge computing for resilient access management of mobile IoT},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning-based mobile edge computing resource management to
support public blockchain networks. <em>TMC</em>, <em>20</em>(3),
1092–1109. (<a href="https://doi.org/10.1109/TMC.2019.2959772">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a public blockchain realized in the mobile edge computing (MEC) network, where the blockchain miners compete against each other to solve the proof-of-work puzzle and win a mining reward. Due to limited computing capabilities of their mobile terminals, miners offload computations to the MEC servers. The MEC servers are maintained by the service provider (SP) that sells its computing resources to the miners. The SP aims at maximizing its long-term profit subject to miners’ budget constraints. The miners decide on their hash rates, i.e., computing powers, simultaneously and independently, to maximize their payoffs without revealing their decisions to other miners. As such, the interactions between the SP and miners are modeled as a stochastic Stackelberg game under private information, where the SP assigns the price per unit hash rate, and miners select their actions, i.e., hash rate decisions, without observing actions of other miners. We develop a hierarchical learning framework for this game based on fully- and partially-observable Markov decision models of the decision processes of the SP and miners. We show that the proposed learning algorithms converge to stable states in which miners’ actions are the best responses to the optimal price assigned by the SP.},
  archive      = {J_TMC},
  author       = {Alia Asheralieva and Dusit Niyato},
  doi          = {10.1109/TMC.2019.2959772},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1092-1109},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Learning-based mobile edge computing resource management to support public blockchain networks},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Joint resource allocation for device-to-device communication
assisted fog computing. <em>TMC</em>, <em>20</em>(3), 1076–1091. (<a
href="https://doi.org/10.1109/TMC.2019.2952354">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, joint resource management for device-to-device (D2D) communication assisted multi-tier fog computing is studied. In the considered system model, each subscribed mobile end user can choose to offload its computation task to either an edge server deployed at the base station via the cellular connection or one nearby third-party fog node via the direct D2D connection. After receiving offloading requests from all end users, the network operator determines the optimal management of the fog computing system, including both computation and communication resource allocations, according to its service agreements with end users, energy cost of edge-server processing and total expense in renting third-party fog nodes. With the objective of maximizing the network management profit, a joint multi-dimensional resource optimization problem, integrating link scheduling, channel assignment and power control, is formulated. An optimal solution algorithm is proposed based on the idea of branch-and-price for addressing this complicated mixed integer nonlinear programming problem. To facilitate the practical implementation in large-scale systems, a suboptimal greedy algorithm with significantly reduced computational complexity is also developed. Simulation results examine the efficiency of the proposed D2D-assisted fog computing framework, and demonstrate the superiority of the proposed resource allocation algorithm over the counterparts.},
  archive      = {J_TMC},
  author       = {Changyan Yi and Shiwei Huang and Jun Cai},
  doi          = {10.1109/TMC.2019.2952354},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1076-1091},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Joint resource allocation for device-to-device communication assisted fog computing},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interaction-oriented service entity placement in edge
computing. <em>TMC</em>, <em>20</em>(3), 1064–1075. (<a
href="https://doi.org/10.1109/TMC.2019.2952097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed Interactive Applications (DIAs) such as virtual reality and multiplayer online game usually require fast processing of tremendous data and timely exchange of delay-sensitive action data and metadata. This makes traditional mobile-based or cloud-based solutions no longer effective. Thanks to edge computing, DIA Service Providers (DSPs) can rent resources from Edge Infrastructure Providers (EIPs) to place service entities that store user states and run computation-intensive tasks. One fundamental problem for a DSP is to decide where to place service entities to achieve low-delay pairwise interactions between DIA users, under the constraint that the total placement cost is no more than a specified budget threshold. In this article, we formally model the service entity placement problem and prove that it is NP-complete by a polynomial reduction from the set cover problem. We present GPA, an efficient algorithm for service entity placement, and theoretically analyze its performance. We evaluated GPA with both real-world data trace-driven simulations, and observed that GPA performs close to the optimal algorithm and generally outperforms the baseline algorithm. We also output a curve showing the trade-off between the weighted average interaction delay and the budget threshold, so that a DSP can choose the right balance.},
  archive      = {J_TMC},
  author       = {Yu Liang and Jidong Ge and Sheng Zhang and Jie Wu and Lingwei Pan and Tengfei Zhang and Bin Luo},
  doi          = {10.1109/TMC.2019.2952097},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1064-1075},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Interaction-oriented service entity placement in edge computing},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). How much benefit can dynamic frequency scaling bring to
WiFi? <em>TMC</em>, <em>20</em>(3), 1046–1063. (<a
href="https://doi.org/10.1109/TMC.2019.2958323">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic frequency scaling (DFS) is a state-of-the-art power-saving technique. Various DFS-based WiFi schemes have been proposed for power saving. These schemes demonstrated the power-saving feasibility of DFS via hardware implementation or simulation. This paper is the first that proposes a general theoretical framework to evaluate the performance of these schemes, where we use Queuing theory to analyze the system throughput and use Semi-Markov theory to quantify the power consumption. In addition, we adopt the energy efficiency (i.e., the throughput per energy cost) to compare the gains of these schemes. This efficiency measure can be used to make a trade-off between system throughput and power consumption and therefore help us choose appropriate parameter settings. Extensive simulations verify that our theoretical model is very accurate and our theoretical results well match with universal software radio peripheral (USRP) experiment results. Our study shows that DFS can greatly improve the energy efficiency of WiFi networks even under low SNR conditions; for example, when SNR = 9.7 dB (i.e., the basic requirement for decoding packets in WiFi), the improvement is around 25 percent for 802.11b at rate 11 Mb/s and 16 percent for 802.11 ac at rate 1300 Mb/s. Our study also shows that DFS can be well integrated with other commonly used power-saving mechanisms to improve energy efficiency further.},
  archive      = {J_TMC},
  author       = {Zhimin Wang and Qinglin Zhao and Li Feng and Fangxin Xu},
  doi          = {10.1109/TMC.2019.2958323},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1046-1063},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {How much benefit can dynamic frequency scaling bring to WiFi?},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). FastGraph enhanced: High accuracy automatic indoor
navigation and mapping. <em>TMC</em>, <em>20</em>(3), 1027–1045. (<a
href="https://doi.org/10.1109/TMC.2019.2955653">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {FastGraph is a novel positioning approach recently proposed to address the challenges of positioning in large spaces. Wi-Fi-based indoor positioning solutions often require complex and time-consuming deployments. Fingerprinting, as one of most used approaches, relies on a radio map, usually created by manual site survey, a process unpractical even for small spaces. Moreover, the site survey has to be repeated frequently due to the changes in the radio environment. Wi-Fi-based solutions are also frequently discarded for applications such as indoor vehicle navigation due to limited accuracy. This article introduces FastGraph Enhanced, a new version of FastGraph, able to provide high accuracy positioning, opening new fields of application, such as navigation for autonomous vehicles. In FastGraph Enhanced, the 3D Force-Directed Graph-Based method, used to model the radio environment, is extended with new algorithms, allowing to improve, among other aspects, the positioning performance. The core advantages of FastGraph are maintained, not requiring previous calibration or knowledge about the space. The proposed solution was evaluated in real world, with very significative improvements in positioning accuracy when compared with the basic version of FastGraph (from around 5m to 0.5m), and with state-of-the-art solutions.},
  archive      = {J_TMC},
  author       = {Cristiano Pendão and Adriano Moreira},
  doi          = {10.1109/TMC.2019.2955653},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1027-1045},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {FastGraph enhanced: High accuracy automatic indoor navigation and mapping},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fast admission control and power optimization with adaptive
rates for communication fairness in wireless networks. <em>TMC</em>,
<em>20</em>(3), 1017–1026. (<a
href="https://doi.org/10.1109/TMC.2019.2954126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Along with the exponentially increasing quantity of intelligent terminals connected to the Internet, the spectrum competition among users becomes more and more severe in wireless networks. The network have not the ability to satisfy all communication requirements due to the significantly increasing users and demanded rates. Energy-aware admission control has been proved to be an efficient way to tackle the infeasibility caused by the severe spectrum competition among users. However, the traditional admission control is limited by gradually removing chosen users, and pays less attention to the fairness. In this article, we elaborate the concept of the fairness in a max-min optimization problem with respect to the transmission rates, by leveraging the model of bit error rates with Q-function for general fading communications. Then, we make use of the max-min rate fairness to smartly determine the subset of users to be admitted in wireless networks. Meanwhile, the overall energy consumption is minimized and the network fairness is guaranteed. In particular, the algorithms can tackle more than one user at each iteration. Numerical evaluations show the effectiveness of the algorithms.},
  archive      = {J_TMC},
  author       = {Xiangping Bryce Zhai and Xin Liu and Chunsheng Zhu and Kun Zhu and Bing Chen},
  doi          = {10.1109/TMC.2019.2954126},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1017-1026},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Fast admission control and power optimization with adaptive rates for communication fairness in wireless networks},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Expertise-aware truth analysis and task allocation in mobile
crowdsourcing. <em>TMC</em>, <em>20</em>(3), 1001–1016. (<a
href="https://doi.org/10.1109/TMC.2019.2955688">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In mobile crowdsourcing, the accuracy of the collected data is usually hard to ensure. Researchers have proposed techniques to identify truth from noisy data by inferring and utilizing the reliability of mobile users, and allocate tasks to users with higher reliability. However, they neglect the fact that a user may only have expertise on some problems (in some domains), but not others, and hence causing two problems: low estimation accuracy in truth analysis and ineffective task allocation. To address these problems, we propose Expertise-aware Truth Analysis and Task Allocation (ETA 2 ), which can effectively infer user expertise, and then estimate truth and allocate tasks based on the inferred expertise. ETA 2 relies on a novel semantic analysis method to identify the expertise, and an expertise-aware truth analysis method to find the truth. For expertise-aware task allocation in ETA 2 , we formalize and solve two problems based on the optimization objectives: max-qualitytask allocation which maximizes the probability fortasks to be allocated to users with high expertise and min-costtask allocation which minimizes the cost of task allocation while ensuring high-quality data are collected. Experimental results based on two real-world datasets and one synthetic dataset demonstrate that ETA 2 significantly outperforms existing solutions.},
  archive      = {J_TMC},
  author       = {Xiaomei Zhang and Yibo Wu and Lifu Huang and Heng Ji and Guohong Cao},
  doi          = {10.1109/TMC.2019.2955688},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1001-1016},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Expertise-aware truth analysis and task allocation in mobile crowdsourcing},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Energy-efficient resource allocation for ultra-dense
licensed and unlicensed dual-access small cell networks. <em>TMC</em>,
<em>20</em>(3), 983–1000. (<a
href="https://doi.org/10.1109/TMC.2019.2953845">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, an energy-efficient self-organized framework for sub-channel allocation and power allocation is presented for ultra-dense small cell networks, which can operate in both licensed and unlicensed bands. In order to protect legacy WiFi devices (operating in unlicensed bands), we consider the Long-Term Evolution (LTE) operation in unlicensed bands based on Carrier Sense Adaptive Transmission (CSAT), in which ’ON’ and ’OFF’ duty cycle approach is utilized. On the other hand, there are severe interference management problems among small cells (operating in licensed and unlicensed bands) and between macro cells and small cells (operating in licensed bands) due to co-channel and ultra-dense deployment of small cells. This article proposes a self-organized optimization framework for the allocation of sub-channels and power levels by exploiting a non-cooperative game with the objective to maximize the energy efficiency of dual-access small cells without creating harmful impact on coexisting network entities including macro cell users, small cell users, and legacy WiFi devices. Simulation results show that the proposed scheme outperforms (6 and 11 percent) and (8 and 18 percent) the round-robin and the spectrum-efficient schemes, respectively, for two different small cell scenarios. In addition, it is shown that for less channel state information (CSI) estimation errors &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\varsigma = 0.02$&lt;/tex-math&gt;&lt;/inline-formula&gt; , the maximum performance degradation of the proposed scheme is reasonably small (5.5 percent) as compared to the perfect CSI.},
  archive      = {J_TMC},
  author       = {Adnan Shahid and Vasilis Maglogiannis and Irfan Ahmed and Kwang Soon Kim and Eli De Poorter and Ingrid Moerman},
  doi          = {10.1109/TMC.2019.2953845},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {983-1000},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Energy-efficient resource allocation for ultra-dense licensed and unlicensed dual-access small cell networks},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Energy efficient collaborative beamforming for reducing
sidelobe in wireless sensor networks. <em>TMC</em>, <em>20</em>(3),
965–982. (<a href="https://doi.org/10.1109/TMC.2019.2955948">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative beamforming (CB) in wireless sensor networks (WSNs) based on a virtual node antenna array (VNAA) can increase the transmission distance and enhance the energy efficiency of sensor nodes. However, a VNAA cannot be pre-designed like the conventional antenna arrays due to the randomly deployed sensor nodes, thereby causing a high sidelobe level (SLL) which increases the interferences. In this article, we formulate a hybrid discrete and continuous optimization problem (HDCOP) for reducing the maximum SLL. HDCOP requires to solve both the discrete and the continuous problems simultaneously, and we propose both centralized and consensus-based distributed CB strategies for solving HDCOP. For the centralized strategy, we convert HDCOP into two sub-optimization problems, and propose a discrete cuckoo search (CS) algorithm for the node location selection optimization and a continuous CS algorithm to optimize the excitation current weights of the selected nodes. For the distributed strategy, we propose a parallel distributed CS algorithm to solve the discrete and continuous parts of HDCOP simultaneously. Moreover, we propose two operating mechanisms based on these two algorithms. Simulation results verify the effectiveness of the proposed strategies for reducing the maximum SLL of CB in WSNs. Moreover, the proposed CB strategies have better performance in terms of the energy efficiency compared with other approaches such as the cross-entropy optimization-based method.},
  archive      = {J_TMC},
  author       = {Geng Sun and Yanheng Liu and Zhaoyu Chen and Aimin Wang and Ying Zhang and Daxin Tian and Victor C.M. Leung},
  doi          = {10.1109/TMC.2019.2955948},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {965-982},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Energy efficient collaborative beamforming for reducing sidelobe in wireless sensor networks},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Enabling 3D ambient light positioning with mobile phones and
battery-free chips. <em>TMC</em>, <em>20</em>(3), 952–964. (<a
href="https://doi.org/10.1109/TMC.2019.2956128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visible Light Positioning (VLP) has attracted much research effort recently. Most existing VLP approaches require special designed light or receiver, collecting light information or strict user operation (e.g., horizontally holding the mobile phone). This incurs a high deployment, maintenance and usage cost. We present RainbowLight, a low-cost ambient light 3D localization approach that is easy to deploy in today&#39;s buildings. Our key finding is that light through a chip of polarizer and birefringence material produces specific interference and light spectrum at different directions to the chip. We derive a model to characterize the relation for direction, light interference, and spectrum. Exploiting the model, RainbowLight calculates the direction to a chip after taking a photo containing the chip. With multiple chips, RainbowLight designs a direction intersection based method to derive the location. We implement RainbowLight and extensively evaluate its performance in various environments. The evaluation results show that RainbowLight achieves an average localization error of 3.3 cm in 2D and 9.6 cm in 3D for light on, and an error of 7.4 cm in 2D and 20.5 cm in 3D for light off scenario in the daytime.},
  archive      = {J_TMC},
  author       = {Lingkun Li and Pengjin Xie and Jiliang Wang},
  doi          = {10.1109/TMC.2019.2956128},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {952-964},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Enabling 3D ambient light positioning with mobile phones and battery-free chips},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Delay-aware microservice coordination in mobile edge
computing: A reinforcement learning approach. <em>TMC</em>,
<em>20</em>(3), 939–951. (<a
href="https://doi.org/10.1109/TMC.2019.2957804">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an emerging service architecture, microservice enables decomposition of a monolithic web service into a set of independent lightweight services which can be executed independently. With mobile edge computing, microservices can be further deployed in edge clouds dynamically, launched quickly, and migrated across edge clouds easily, providing better services for users in proximity. However, the user mobility can result in frequent switch of nearby edge clouds, which increases the service delay when users move away from their serving edge clouds. To address this issue, this article investigates microservice coordination among edge clouds to enable seamless and real-time responses to service requests from mobile users. The objective of this work is to devise the optimal microservice coordination scheme which can reduce the overall service delay with low costs. To this end, we first propose a dynamic programming-based offline microservice coordination algorithm, that can achieve the globally optimal performance. However, the offline algorithm heavily relies on the availability of the prior information such as computation request arrivals, time-varying channel conditions and edge cloud&#39;s computation capabilities required, which is hard to be obtained. Therefore, we reformulate the microservice coordination problem using Markov decision process framework and then propose a reinforcement learning-based online microservice coordination algorithm to learn the optimal strategy. Theoretical analysis proves that the offline algorithm can find the optimal solution while the online algorithm can achieve near-optimal performance. Furthermore, based on two real-world datasets, i.e., the Telecom&#39;s base station dataset and Taxi Track dataset from Shanghai, experiments are conducted. The experimental results demonstrate that the proposed online algorithm outperforms existing algorithms in terms of service delay and migration costs, and the achieved performance is close to the optimal performance obtained by the offline algorithm.},
  archive      = {J_TMC},
  author       = {Shangguang Wang and Yan Guo and Ning Zhang and Peng Yang and Ao Zhou and Xuemin Shen},
  doi          = {10.1109/TMC.2019.2957804},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {939-951},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Delay-aware microservice coordination in mobile edge computing: A reinforcement learning approach},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cost-efficient mobile crowdsensing with spatial-temporal
awareness. <em>TMC</em>, <em>20</em>(3), 928–938. (<a
href="https://doi.org/10.1109/TMC.2019.2953911">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A cost-efficient deal that can achieve high sensing quality with a low reward is the permanent goal of the requestor in mobile crowdsensing, which heavily depends on the quantity and quality of the workers. However, the spatial diversity and temporal dynamics lead to heterogeneous worker supplies, making it hard for the requestor to utilize a homogeneous pricing strategy to realize a cost-efficient deal from a systematic point of view. Therefore, a cost-efficient deal calls for a cost-efficient pricing strategy, boosting the whole sensing quality with less operation (computation) cost. However, the state-of-the-art studies ignore the dual cost-efficient demands of large-scale sensing tasks. Hence, we propose a combinatorial pinning zero-determinant (ZD) strategy, which empowers the requestor to utilize a single strategy within its feasible range to minimize the total expected utilities of the workers throughout all sensing regions for each time interval, without being affected by the strategies of the workers. Through turning the worker-customized strategy to an interval-customized one, the proposed combinatorial pinning ZD strategy reduces the number of pricing strategies required by the requestor from O(n 3 ) to O(n). Besides, it extends the application scenarios of the classical ZD strategy from two-player simultaneous-move games to multiple-heterogeneous-player sequential-move ones, where a leader can determine the linear relationship of the players&#39; expected utilities. Such an extension enriches the theoretical hierarchy of ZD strategies, broadening their application scope. Extensive simulations based on real-world data verify the effectiveness and efficiency of the proposed scheme.},
  archive      = {J_TMC},
  author       = {Qin Hu and Shengling Wang and Xiuzhen Cheng and Junshan Zhang and Weifeng Lv},
  doi          = {10.1109/TMC.2019.2953911},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {928-938},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Cost-efficient mobile crowdsensing with spatial-temporal awareness},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Connectivity-constrained placement of wireless chargers.
<em>TMC</em>, <em>20</em>(3), 909–927. (<a
href="https://doi.org/10.1109/TMC.2019.2954306">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we first study the problem of Connected wIReless Charger pLacEment (CIRCLE). That is, given a fixed number of directional wireless chargers and candidate positions, determining the placement position and orientation angle for each charger under connectivity constraint for wireless chargers such that the overall charging utility is maximized. To address CIRCLE problem, we first consider a relaxed version of CIRCLE (CIRCLE-R for short). We prove that CIRCLE-R falls into the realm of maximizing a submodular set function subject to a connectivity constraint, and propose an algorithm whose approximation ratio is at least 1.5 times better than that of the state-of-the-art algorithm. Next, we reduce the solution space for CIRCLE from infinite to finite, and propose an algorithm with a constant approximation ratio to address CIRCLE. Besides, we consider a variant of CIRCLE, CIRCLE-NB, and propose an approximation algorithm to address it. We conduct both simulation experiments and field experiments to verify our theoretical findings. The results show that our algorithm can outperform comparison algorithms by 83.35 percent.},
  archive      = {J_TMC},
  author       = {Nan Yu and Haipeng Dai and Guihai Chen and Alex X. Liu and Bingchuan Tian and Tian He},
  doi          = {10.1109/TMC.2019.2954306},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {909-927},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Connectivity-constrained placement of wireless chargers},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Computer vision-assisted 3D object localization via COTS
RFID devices and a monocular camera. <em>TMC</em>, <em>20</em>(3),
893–908. (<a href="https://doi.org/10.1109/TMC.2019.2954830">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In most RFID localization systems, acquiring a reader antenna&#39;s position at each sampling time is challenging, especially for those antenna-carrying robot or drone systems with unpredictable trajectories. In this article, we present RF-MVO that fuses RFID and computer vision for stationary RFID localization in 3D space by attaching a light-weight 2D monocular camera to two reader antennas in parallel. First, the existing monocular visual odometry only recovers a camera/antenna trajectory in the camera view from 2D images. By combining it with RF phase, we design a model to estimate a scale factor for real-world trajectory transformation, along with spatial directions of an RFID tag relative to a virtual antenna array due to the mobility of each antenna. Then we propose a novel RFID localization algorithm that does not require exhaustively searching all possible positions within the pre-specified region. Second, to speed up the searching process and improve localization accuracy, we propose a coarse-to-fine optimization algorithm. Third, we introduce the concept of horizontal dilution of precision (HDOP) to measure the confidence level of localization results. Our experiments demonstrate the effectiveness of proposed algorithms and show RF-MVO can achieve 6.23 cm localization error.},
  archive      = {J_TMC},
  author       = {Zhongqin Wang and Min Xu and Ning Ye and Fu Xiao and Ruchuan Wang and Haiping Huang},
  doi          = {10.1109/TMC.2019.2954830},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {893-908},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Computer vision-assisted 3D object localization via COTS RFID devices and a monocular camera},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Collaboratively replicating encoded content on RSUs to
enhance video services for vehicles. <em>TMC</em>, <em>20</em>(3),
877–892. (<a href="https://doi.org/10.1109/TMC.2019.2960022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of smart cities, Internet services will be pervasively accessible for moving vehicles. It is envisioned that the video content demand of vehicles will explode in the near future. However, the strategy to efficiently distribute video content in large-scale vehicular networks is still absent due to challenges arising from the huge video population, heavy bandwidth consumption, heterogeneous user devices, and vehicles’ mobility. In this work, we propose to collaboratively replicate video content on Roadside Units (RSUs) to enhance video distribution services based on the fact that the contact period between moving vehicles and a single RSU is not long enough to complete video downloading. In our design, a video file is split into multiple chunks. Each RSU replicates a small number of original chunks and chunks encoded by network coding. Replicating encoded chunks can reduce redundancy of chunks on different RSUs so that RSUs can complement each other better, whereas original chunks can be transrated to chunks with lower bitrates flexibly to fit in users’ devices. Therefore, we replicate both original and encoded chunks on RSUs to take advantages of both sides. Stochastic models are employed to analyze chunk download processes and a convex optimization problem is formulated to determine the optimal partition of space allocated to each kind of chunks. Furthermore, we extend our strategy to support video streaming services and empirically prove that the influence caused by limitations of network coding is moderate. In the end, we conduct extensive simulations which not only validate the accuracy of our models but also demonstrate that our strategy can effectively boost video distribution services.},
  archive      = {J_TMC},
  author       = {Yipeng Zhou and Jiawen Chen and Guoqiao Ye and Di Wu and Jessie Hui Wang and Min Chen},
  doi          = {10.1109/TMC.2019.2960022},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {877-892},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Collaboratively replicating encoded content on RSUs to enhance video services for vehicles},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ChromaCode: A fully imperceptible screen-camera
communication system. <em>TMC</em>, <em>20</em>(3), 861–876. (<a
href="https://doi.org/10.1109/TMC.2019.2956493">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hidden screen-camera communication techniques emerge as a new paradigm that embeds data imperceptibly into regular videos while remaining unobtrusive to human viewers. Three key goals on imperceptible, high rate, and reliable communication are desirable but conflicting, and existing solutions usually made a trade-off among them. In this paper, we present the design and implementation of CHROMACODE, a screen-camera communication system that achieves all three goals simultaneously. In our design, we consider for the first time color space for perceptually uniform lightness modifications. On this basis, we design an outcome-based adaptive embedding scheme, which adapts to both pixel lightness and regional texture. Last, we propose a concatenated code scheme for robust coding and devise multiple techniques to overcome various screen-camera channel errors. Our prototype and experiments demonstrate that CHROMACODE achieves remarkable raw throughputs of &gt;700 kbps, data goodputs of 120 kbps with BER of 0.05, and with fully imperceptible flicker for viewing proved by user study, which significantly outperforms previous works.},
  archive      = {J_TMC},
  author       = {Kai Zhang and Yi Zhao and Chenshu Wu and Chaofan Yang and Kehong Huang and Chunyi Peng and Yunhao Liu and Zheng Yang},
  doi          = {10.1109/TMC.2019.2956493},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {861-876},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {ChromaCode: A fully imperceptible screen-camera communication system},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). BuSAR: Bluetooth slot availability randomization for better
coexistence with dense wi-fi networks. <em>TMC</em>, <em>20</em>(3),
846–860. (<a href="https://doi.org/10.1109/TMC.2019.2955080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The last decade has witnessed the ever-increasing deployment of Wi-Fi networks and the explosion of Bluetooth-based applications. As a result, the coexistence of Bluetooth piconets with highly-dense Wi-Fi networks is a common phenomenon currently. Unlike Wi-Fi that conducts carrier sensing before channel access, Bluetooth adopts frequency hopping based on a predefined hop sequence, which inevitably incurs considerable cross-technology interference to Wi-Fi. While the Adaptive Frequency Hopping technique is standardized for interference reduction, it does not perform well in current practice where densely-deployed Wi-Fi networks commonly cover the whole 2.4 GHz unlicensed spectrum. In this context, this article presents BuSAR, a novel approach to account for the coexistence problem between Bluetooth piconets and dense Wi-Fi networks. BuSAR embodies the first work to aim at mitigating the cross-technology interference between Bluetooth and highly-dense Wi-Fi networks in a distributed manner. At the heart of BuSAR lies a subtle technique called Bluetooth slot availability randomization, which exploits the redundancy of erroneous Bluetooth packets for better Bluetooth/Wi-Fi coexistence. With BuSAR adopted, multiple Bluetooth piconets are guaranteed to operate independently and only a lightweight algorithm is needed to be implemented at each Bluetooth device. Both theoretical analysis and experimental results validate the feasibility and superiority of BuSAR.},
  archive      = {J_TMC},
  author       = {Chenglong Shao and Heejun Roh and Wonjun Lee},
  doi          = {10.1109/TMC.2019.2955080},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {846-860},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {BuSAR: Bluetooth slot availability randomization for better coexistence with dense wi-fi networks},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Backbone-assisted wireless local area network. <em>TMC</em>,
<em>20</em>(3), 830–845. (<a
href="https://doi.org/10.1109/TMC.2019.2953895">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a cross-layer design of backbone-assisted wireless local area network (WLAN) for dense WLAN deployment. The popularity of 802.11-based WLANs leads to dense WLAN deployment in geographically limited space, including dense access points (AP) and dense users. With dense APs, an AP could overhear packets destined for other APs. Backbone-assisted WLAN is a new system architecture where cooperative APs share the overheard packets through a backbone network, thereby reducing packet retransmission and improving system throughput. Conventional WLAN, such as Wi-Fi, uses Stop-and-Wait ARQ. This article argues that Stop-and-Wait does not work well with backbone-assisted WLAN because of large backbone delays. We first show that with a variant of Selective Repeat ARQ tailored for backbone-assisted WLAN, a single-user backbone-assisted WLAN system can achieve substantial throughput improvement over that with Stop-and-Wait ARQ. Then, we put forth a new system architecture targeted for dense users, referred to as network-coded backbone-assisted WLAN, in which multiple users are allowed to transmit simultaneously. A distinguishing feature of this system is the joint use of physical-layer network-coding (PNC) decoding and multiuser decoding (MUD) in multipacket reception. This article is the first attempt to design an ARQ for multiuser backbone-assisted WLAN. Our overall system design solves a PNC sequence obfuscation problem and addresses long packet latency in Selective Repeat ARQ. Experiments on our software-defined radio prototype indicate that network-coded Ethernet-backbone-assisted WLAN can achieve high system throughput and low packet latency. Specifically, the system throughput can outperform an MUD-only multiuser WLAN and a single-user WLAN by 60 and 100 percent, respectively. Overall, we believe that network-coded backbone-assisted WLAN is a viable solution for boosting throughput and reducing latency in dense WLAN environments.},
  archive      = {J_TMC},
  author       = {Haoyuan Pan and Soung Chang Liew},
  doi          = {10.1109/TMC.2019.2953895},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {830-845},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Backbone-assisted wireless local area network},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ARPAP: A novel antenna-radiation-pattern-aware power-based
positioning in RF system. <em>TMC</em>, <em>20</em>(3), 816–829. (<a
href="https://doi.org/10.1109/TMC.2019.2959983">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional power-based localization methods suffer from low accuracy in the practical application environment. The main challenges are the antenna directivity and fading effect. Conventional methods assume omnidirectional antenna directivity such that the solution is the intersections of multiple circle-shape contours. This strong assumption results in significant localization error in practical non-isotropic antenna applications. In this article, a novel antenna radiation-pattern-aware power-based positioning (ARPAP) scheme is proposed. It reduces the antenna directivity effect by including the antenna pattern into the localization system model. It reduces the bias error that introduced by power measurement through estimating the line-of-sight (LoS) component in received signal strength (RSS). Moreover, the error mode for the proposed ARPAP system, along with the theoretical limit, Cramer-Rao Bound (CRB), and bias of the proposed positioning system are derived. The Pearson correlation coefficient between the proposed error model and simulation result shows a high similarity score. The proposed positioning scheme and analytic error model are instantiated for the cellular network. Both analytical model and simulation results demonstrate the superiority of the proposed method over traditional methods.},
  archive      = {J_TMC},
  author       = {Lei Wang and Li Feng and Maciej J. Zawodniok},
  doi          = {10.1109/TMC.2019.2959983},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {816-829},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {ARPAP: A novel antenna-radiation-pattern-aware power-based positioning in RF system},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Anonymization and de-anonymization of mobility trajectories:
Dissecting the gaps between theory and practice. <em>TMC</em>,
<em>20</em>(3), 796–815. (<a
href="https://doi.org/10.1109/TMC.2019.2952774">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human mobility trajectories are increasingly collected by ISPs to assist academic research and commercial applications. Meanwhile, there is a growing concern that individual trajectories can be de-anonymized when the data is shared, using information from external sources (e.g., online social networks). To understand this risk, prior works either estimate the theoretical privacy bound or simulate de-anonymization attacks on synthetically created datasets. However, it is not clear how well the theoretical estimations are preserved in practice. In this article, we collected a large-scale ground-truth trajectory dataset from 2,161,500 users of a cellular network, and two matched external trajectory datasets from a large social network (56,683 users) and a check-in/review service (45,790 users) on the same user population. The two sets of large ground-truth data provide a rare opportunity to extensively evaluate a variety of de-anonymization algorithms (nine in total). We find that their performance in the real-world dataset is far from the theoretical bound. Further analysis shows that most algorithms have under-estimated the impact of spatio-temporal mismatches between the data from different sources, and the high sparsity of user generated data also contributes to the under-performance. Based on these insights, we propose four new algorithms that are specially designed to tolerate spatial or temporal mismatches (or both) and model location contexts and time contexts. Extensive evaluations show that our algorithms achieve more than 17 percent performance gain over the best existing algorithms, confirming our insights. Further, we propose two new location-privacy preserving mechanisms utilizing the spatio-temporal mismatches to better protect users’ privacy against the de-anonymization attack. Evaluation results show that our proposed mechanisms can reduce the performance of de-anonymization attacks by over 8.0 percent, demonstrating the effectiveness of our insights.},
  archive      = {J_TMC},
  author       = {Huandong Wang and Yong Li and Chen Gao and Gang Wang and Xiaoming Tao and Depeng Jin},
  doi          = {10.1109/TMC.2019.2952774},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {796-815},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Anonymization and de-anonymization of mobility trajectories: Dissecting the gaps between theory and practice},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel bayesian filter for RSS-based device-free
localization and tracking. <em>TMC</em>, <em>20</em>(3), 780–795. (<a
href="https://doi.org/10.1109/TMC.2019.2953474">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Received signal strength based device-free localization applications utilize a model that relates the measurements to position of the wireless sensors and person, and the underlying inverse problem is solved either using an imaging method or a nonlinear Bayesian filter. In this paper, it is shown that the Bayesian filters nearly reach the posterior Cramer-Rao bound and they are superior with respect to imaging approaches in terms of localization accuracy because the measurements are directly related to position of the person. However, Bayesian filters are known to suffer from divergence issues and in this paper, the problem is addressed by introducing a novel Bayesian filter. The developed filter augments the measurement model of a Bayesian filter with position estimates from an imaging approach. This bounds the filter&#39;s measurement residuals by the position errors of the imaging approach and as an outcome, the developed filter has robustness of an imaging method and tracking accuracy of a Bayesian filter. The filter is demonstrated to achieve a localization error of 0.11 m in a 75 m 2 open indoor deployment and an error of 0.29 m in a 82 m 2 apartment experiment, decreasing the localization error by 30-48 percent with respect to a state-of-the-art imaging method.},
  archive      = {J_TMC},
  author       = {Ossi Kaltiokallio and Roland Hostettler and Neal Patwari},
  doi          = {10.1109/TMC.2019.2953474},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {780-795},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A novel bayesian filter for RSS-based device-free localization and tracking},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SWIM: Speed-aware WiFi-based passive indoor localization for
mobile ship environment. <em>TMC</em>, <em>20</em>(2), 765–779. (<a
href="https://doi.org/10.1109/TMC.2019.2947667">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and pervasive device-free indoor localization with meter-level resolution is critical for large cruise and passenger ships due to safety-critical rescue and evacuation requirements when accidents occur. However, existing localization techniques would severely suffer on ships because of their unique mobility characteristics. In this paper, we take the first attempt to build a ubiquitous passive localization system using WiFi fingerprints for the mobile ship environment. By conducting extensive experiments and measurements during several cruise trips, we identified a major influence factor on the fingerprints in the mobile environment: varying the ship speeds may significantly change the patterns of fingerprints at runtime. Since it may be too expensive to identify the fingerprints associated with different speeds, we propose an efficient localization method, namely SWIM, which calibrates the fingerprints from only a single-speed scenario to multiple-speed scenarios using a signal reconstruction analysis. SWIM is designed to learn the predictive fingerprint variation introduced by environmental speed changes and reconstruct the original fingerprints to adapt to the runtime speed scenarios. We have implemented and extensively evaluated SWIM on actual cruise ships. Experimental results demonstrate that SWIM improves localization accuracy from 63.2 to 82.9 percent, while reducing the overall system deployment cost by 87 percent.},
  archive      = {J_TMC},
  author       = {Mozi Chen and Kezhong Liu and Jie Ma and Yu Gu and Zheng Dong and Cong Liu},
  doi          = {10.1109/TMC.2019.2947667},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {765-779},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {SWIM: Speed-aware WiFi-based passive indoor localization for mobile ship environment},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Vernier: Accurate and fast acoustic motion tracking using
mobile devices. <em>TMC</em>, <em>20</em>(2), 754–764. (<a
href="https://doi.org/10.1109/TMC.2019.2945955">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Acoustic motion tracking has been viewed as a promising user interaction technique in many scenarios such as Virtual Reality (VR), Smart Appliance, video gaming, etc. Existing acoustic motion tracking approaches, however, suffer from long window of accumulated signal and time-consuming signal processing. They are inherently difficult to achieve both high accuracy and low delay. In this paper, we present Vernier, an efficient and accurate acoustic tracking method based on commodity mobile devices. We design a new approach to efficiently and accurately derive phase change and thus moving distance. Vernier significantly reduces the tracking delay/overhead by removing the complicated frequency analysis and long window of signal accumulation, while keeping a high tracking accuracy. We implement Vernier on Android, and evaluate its performance with COTS mobile devices including Samsung Galaxy S7 and Sony L50t. Experimental results show that Vernier outperforms previous approaches with a tracking error less than 4 mm. The tracking speed achieves 3× improvement to the previous phase based approaches and 10× to Doppler Effect based approaches. Vernier is also validated in applications like controlling and drawing, and we believe it is generally applicable in many real applications.},
  archive      = {J_TMC},
  author       = {Yunhao Liu and Jiliang Wang and Yunting Zhang and Linsong Cheng and Weiyi Wang and Zhao Wang and Weimin Xu and Zhenjiang Li},
  doi          = {10.1109/TMC.2019.2945955},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {754-764},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Vernier: Accurate and fast acoustic motion tracking using mobile devices},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Simultaneous material identification and target imaging with
commodity RFID devices. <em>TMC</em>, <em>20</em>(2), 739–753. (<a
href="https://doi.org/10.1109/TMC.2019.2946072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Material identification and target imaging play an important role in many applications. This paper introduces TagScan, a system that can identify the material type and image the horizontal cut of a target simultaneously with cheap commodity Radio-Frequency IDentification (RFID) devices. The key intuition is that different materials and/or target sizes cause different amounts of phase and RSS (Received Signal Strength) changes, when radio frequency (RF) signal penetrates through the target. Multiple challenges need to be addressed before we can turn the idea into a functional system, including (i) indoor environments exhibit rich multipath which breaks the linear relationship between the phase change and the propagation distance inside a target; (ii) without knowing either material type or target size, trying to obtain these two information simultaneously is challenging; and (iii) stitching pieces of the propagation distances inside a target for an image estimate is non-trivial. We propose solutions to all the challenges and evaluate the system&#39;s performance in three different environments. TagScan is able to achieve higher than 94 percent material identification accuracies for 10 liquids and differentiates even very similar objects such as Coke and Pepsi. TagScan can accurately estimate the horizontal cut images of more than one target behind a wall.},
  archive      = {J_TMC},
  author       = {Ju Wang and Jie Xiong and Xiaojiang Chen and Hongbo Jiang and Rajesh Krishna Balan and Dingyi Fang},
  doi          = {10.1109/TMC.2019.2946072},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {739-753},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Simultaneous material identification and target imaging with commodity RFID devices},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). RF-3DScan: RFID-based 3D reconstruction on tagged packages.
<em>TMC</em>, <em>20</em>(2), 722–738. (<a
href="https://doi.org/10.1109/TMC.2019.2943853">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, the logistic industry has introduced 3D reconstruction to monitor the package placement in the warehouse. Previous 3D reconstruction solutions mainly utilize computer vision or sensor-based methods, which are restricted to the line-of-sight or the battery life. Therefore, we propose a passive RFID-based solution, called RF-3DScan, to perform 3D reconstruction on tagged packages, including the package orientation and the package stacking. The basic idea is that a moving antenna can obtain RF-signals from the tags attached on packages with the 1D linear mobile scanning. Through extracting phase differences to build angle profiles for each tag, RF-3DScan derives their relative positions, further determines the package orientation and the coarse-grained package stacking. By simply performing the 2D scanning, RF-3DScan can provide the fine-grained package stacking determination. We implement a prototype system of RF-3DScan and evaluate its performance in real settings. Our experiment results show that RF-3DScan can achieve about 92.5 percent identification accuracy of the bottom face, and an average error about 4.08° of thethe rotation angle. For the package stacking, 1D scanning can achieve the comparable performance in comparison with 2D scanning.},
  archive      = {J_TMC},
  author       = {Yanling Bu and Lei Xie and Yinyin Gong and Jia Liu and Bingbing He and Jiannong Cao and Baoliu Ye and Sanglu Lu},
  doi          = {10.1109/TMC.2019.2943853},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {722-738},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {RF-3DScan: RFID-based 3D reconstruction on tagged packages},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Radio resource sharing and edge caching with latency
constraint for local 5G operator: Geometric programming meets
stackelberg game. <em>TMC</em>, <em>20</em>(2), 707–721. (<a
href="https://doi.org/10.1109/TMC.2019.2948630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapidly increasing demand in indoor small cell networks has given rise to the concept of local 5G operator (OP) for local service delivery. In this regard, we develop a novel game-theoretic framework with geometric programming to model and analyze cache-enabled small cell base stations (SBSs) with infrastructure sharing for local 5G OP networks. In such a network, the local 5G OP provides wireless network in indoor area and rent out the infrastructure which are RAN and cache storage to multiple mobile network operators (MNOs) while guarantee the quality-of-experience (QoE) at the users (UEs) of MNOs. We formulate a Stackelberg game model where the local 5G OP is the leader and the MNOs are the followers. The local 5G OP aims to maximize its profit by optimizing its infrastructure rental fee, and the MNOs aim to minimize their renting cost of infrastructure by minimizing the cache intensity subject to latency constraint at each UE. Here, the cache intensity is defined as the product of the number of SBSs per unit area and the number of popular files stored in each SBS. The optimization problems of the local 5G OP and the MNOs are transformed into geometric programming. Accordingly, the subgame perfect equilibrium of Stackelberg game is obtained through the succesive geometric programming (SGP) method. Since the MNOs share their rented infrastructure, for cost sharing, we apply the concept of Shapley value to divide the cost among the MNOs. We show that the cost sharing problem can be mapped into a simplified “airport runway cost sharing problem”, in which the Shapley value can be computed efficiently. Finally, we present an extensive performance evaluation that reveals interesting insights into designing resource sharing with edge caching in local 5G OP networks.},
  archive      = {J_TMC},
  author       = {Tachporn Sanguanpuak and Dusit Niyato and Nandana Rajatheva and Matti Latva-Aho},
  doi          = {10.1109/TMC.2019.2948630},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {707-721},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Radio resource sharing and edge caching with latency constraint for local 5G operator: Geometric programming meets stackelberg game},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Portfolio optimization in traffic offloading: Concept,
model, and algorithms. <em>TMC</em>, <em>20</em>(2), 691–706. (<a
href="https://doi.org/10.1109/TMC.2019.2946811">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to explosive growth of mobile data over the overburdened cellular network, opportunistic offloading is proposed to transmit the traffic originally transmitted through infrastructure network to delay-tolerant device-to-device networks at the edge of mobile networks. Existing offloading schemes mainly focus on selecting a subset of mobile nodes to work as offloadees, who first download the contents through the infrastructure, and then transmit them to subscriber nodes. However, when there is large amount of contents to be offloaded, and if all contents are disseminated through only one fixed set of offloadees every time, it may result in the risk of extreme cases that only extremely few nodes received the content, even if the expectation is large. This is like putting all of your eggs in one basket. To deal with this problem, we introduce an economic concept, conditional value at risk (CVaR) to measure the risk in offloadee set selection. CVaR is a widely used risk assessment measure for investments, which provides a unified and comprehensive risk evaluation framework for complex investment portfolio. We propose an algorithm to compute a portfolio over multiple offloadee sets with a guarantee on CVaR. Moreover, we prove the feasibility of our methodology from the mathematical point of view. Extensive evaluations with real-world traces show that our proposed offloading scheme can obtain a portfolio with significantly better CVaR, i.e., 91.53 percent performance gain at most, compared with the state-of-the-art solutions.},
  archive      = {J_TMC},
  author       = {Dianlei Xu and Yong Li and Tong Xia and Jianbo Li and Pan Hui},
  doi          = {10.1109/TMC.2019.2946811},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {691-706},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Portfolio optimization in traffic offloading: Concept, model, and algorithms},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal multicasting strategies in underwater acoustic
networks. <em>TMC</em>, <em>20</em>(2), 678–690. (<a
href="https://doi.org/10.1109/TMC.2019.2944158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in underwater networking exploit the large propagation delays in underwater channels to schedule transmissions which increase the performance of underwater acoustic sensor networks (UASNs). The underwater channel is broadcast in nature so it supports broadcast and multicast transmissions. In this paper, we discuss novel scheduling strategies, based on TDMA (Time Division Multiple Access), for UASNs where packets may be bound for multiple destinations. The main contributions are to establish an upper bound on the throughput of multicast networks, in which each packet has the same number of intended destinations, by exploiting large propagation delays, and explore network topologies that can achieve this bound. As an example, we study the throughput of unicast and multicast ring networks, including the properties of optimal, valid, perfect and fair transmission schedules. Further, several algorithms to find fair and optimal schedules for unicast and multicast ring networks are presented. Finally, we perform extensive simulations for uniform ring networks, as well as more general ring networks, in both noiseless and noisy underwater channels. Simulation results verify that the proposed algorithms can effectively determine the optimal schedules for ring networks, which achieve the maximum possible throughput and asymptotically approach the upper bound on the throughput of multicasting UASNs.},
  archive      = {J_TMC},
  author       = {Linbo Zhang and Tong Liu and Mehul Motani},
  doi          = {10.1109/TMC.2019.2944158},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {678-690},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Optimal multicasting strategies in underwater acoustic networks},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal ADMM-based spectrum and power allocation for
heterogeneous small-cell networks with hybrid energy supplies.
<em>TMC</em>, <em>20</em>(2), 662–677. (<a
href="https://doi.org/10.1109/TMC.2019.2948014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Powering cellular networks with hybrid energy supplies is not only environment-friendly but can also reduce the on-grid energy consumption, thus being emerging as a promising solution for green networking. Intelligent management of spectrum and power can increase the network utility in cellular networks with hybrid energy supplies, usually at the cost of higher energy consumption. Unlike prior studies on either the network utility maximization or on-grid energy cost minimization, this paper studies the joint spectrum and power allocation problem that maximizes the system revenue in a heterogeneous small-cell network with hybrid energy supplies. Specifically, the system revenue is considered as the difference between the network utility and on-grid energy cost. By developing the convexity of the optimization problem through transformation and reparameterization, we propose a joint spectrum and power allocation algorithm based on the primal-dual arguments to obtain the optimal solution by iteratively solving the primal and dual sub-problems of the convex optimization problem. To solve the primal sub-problem, we further propose the Lagrangian maximization based on the alternating direction method of multipliers (ADMM), and derive the optimal solution in the closed-form expression at each iteration. It is shown that the proposed joint spectrum and power allocation algorithm approaches the global optimality at the rate of &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$1/n$&lt;/tex-math&gt;&lt;/inline-formula&gt; with &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$n$&lt;/tex-math&gt;&lt;/inline-formula&gt; being the number of iterations. Also, the proposed ADMM-based Lagrangian maximization algorithm approaches the primal optimal solution with the time complexity of &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$O(1/\epsilon _r)$&lt;/tex-math&gt;&lt;/inline-formula&gt; iterations with &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\epsilon _r$&lt;/tex-math&gt;&lt;/inline-formula&gt; being the termination parameter. Simulation results show that in comparison with the power control with equal frequency allocation algorithm and frequency allocation with equal power allocation algorithms the proposed algorithm increases the system revenue by over 20 and 60 percent without consuming more on-grid energy when the proportional fairness utility and the weighted sum rate utility are considered with the approximate system parameter settings, respectively. Meanwhile, in comparison with the full frequency reuse case, the proposed algorithm increases the system revenue by 20 percent at least in terms of the weighted sum rate utility, although it achieves the similar system revenue when considering the proportional fairness utility. Simulation results also show that our proposed algorithm can perform well under the realistic fast fading channel conditions.},
  archive      = {J_TMC},
  author       = {Li Ping Qian and Yuan Wu and Bo Ji and Xuemin Sherman Shen},
  doi          = {10.1109/TMC.2019.2948014},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {662-677},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Optimal ADMM-based spectrum and power allocation for heterogeneous small-cell networks with hybrid energy supplies},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the data quality in privacy-preserving mobile
crowdsensing systems with untruthful reporting. <em>TMC</em>,
<em>20</em>(2), 647–661. (<a
href="https://doi.org/10.1109/TMC.2019.2943468">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of mobile smart devices with ever improving sensing capacities means that human-centric Mobile Crowdsensing Systems (MCSs) can economically provide a large scale and flexible sensing solution. The use of personal mobile devices is a sensitive issue, therefore it is mandatory for practical MCSs to preserve private information (the user&#39;s true identity, precise location, etc.) while collecting the required sensing data. However, well intentioned privacy protection techniques also conceal autonomous, or even malicious, behaviors of device owners (termed as self-interested), where the objectivity and accuracy of crowdsensing data can therefore be severely threatened. The issue of data quality due to untruthful reporting in privacy-preserving MCSs has been yet to produce solutions. Bringing together game theory, algorithmic mechanism design, and truth discovery, we develop a mechanism to guarantee and enhance the quality of crowdsensing data without jeopardizing the privacy of MCS participants. Together with solid theoretical justifications, we evaluate the performance of our proposal with extensive real-world MCS trace-driven simulations. Experimental results demonstrate the effectiveness of our mechanism on both enhancing the quality of the crowdsensing data and eliminating the motivation of MCS participants, even when their privacy is well protected, to report untruthfully.},
  archive      = {J_TMC},
  author       = {Cong Zhao and Shusen Yang and Julie A. McCann},
  doi          = {10.1109/TMC.2019.2943468},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {647-661},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {On the data quality in privacy-preserving mobile crowdsensing systems with untruthful reporting},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). OmniTrack: Orientation-aware RFID tracking with
centimeter-level accuracy. <em>TMC</em>, <em>20</em>(2), 634–646. (<a
href="https://doi.org/10.1109/TMC.2019.2949412">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RFID tracking attracts a lot of research efforts in recent years. Most of the existing approaches, however, adopt an orientation-oblivious model. When tracking a target whose orientation changes, those approaches suffer from serious accuracy degradation. In order to achieve target tracking with pervasive applicability in various scenarios, in this article, we propose OmniTrack, an orientation-aware RFID tracking approach. Our study presents a generic model that discribes the linear relationship between the tag orientation and the phase change of the backscattered signals. Based on this finding, we propose an orientation-aware phase model to explicitly quantify the respective impact of the read-tag distance and the tag&#39;s orientation. OmniTrack addresses practical challenges in tracking the location and orientation of a mobile tag. Our experimental results demonstrate that OmniTrack achieves centimeter-level location accuracy and has significant advantages in tracking targets with varing orientations, compared to the state-of-the-art approaches.},
  archive      = {J_TMC},
  author       = {Chengkun Jiang and Yuan He and Xiaolong Zheng and Yunhao Liu},
  doi          = {10.1109/TMC.2019.2949412},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {634-646},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {OmniTrack: Orientation-aware RFID tracking with centimeter-level accuracy},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). No more than what i post: Preventing linkage attacks on
check-in services. <em>TMC</em>, <em>20</em>(2), 620–633. (<a
href="https://doi.org/10.1109/TMC.2019.2947416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the flourishing of location based social networks, posting check-ins has become a common practice to document one&#39;s daily life. Users usually do not consider check-in records as violations of their privacy. However, through analyzing two real-world check-in datasets, our study shows that check-in records are vulnerable to linkage attacks. Specifically, adversary is able to uniquely re-identify over 52~66 percent users in other anonymous mobility datasets and 60~80 percent users have more than 60 percent probability leaking unreported mobility records. In addition, we further demonstrate that the privacy sensitivity of check-in records can be more accurately measured by including the information of additional mobility data compared with only looking at check-ins. Based on this observation, we design a partition-and-group framework to integrate the information of check-ins and additional mobility data to attain a novel privacy criterion-k τ,l -anonymity. It ensures adversaries with arbitrary background knowledge cannot use check-ins to re-identify users in other anonymous datasets or learning unreported mobility records. The proposed framework achieves favorable performance against state-of-art baseline in terms of improving check-in utility by 24~57 percent while providing stronger privacy guarantee at the same time. We believe this study will open a new angle in attaining both privacy-preserving and useful check-in services.services.},
  archive      = {J_TMC},
  author       = {Fengli Xu and Yong Li and Zhen Tu and Shuhao Chang and Hongjia Huang},
  doi          = {10.1109/TMC.2019.2947416},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {620-633},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {No more than what i post: Preventing linkage attacks on check-in services},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Maximizing fairness for resource allocation in heterogeneous
5G networks. <em>TMC</em>, <em>20</em>(2), 603–619. (<a
href="https://doi.org/10.1109/TMC.2019.2948877">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we first formulate the joint resource allocation, interference minimization, user-level, and cell-level fairness for maximum resource reuse in 5G heterogeneous small cell networks as an NP-hard problem. We then propose three algorithms - centralized, distributed, and randomized distributed algorithms - to efficiently solve the formulated resource allocation problem while minimizing interference, maximizing fairness, and resource reuse. Through extensive real data analysis and network simulations, we show that our proposed solutions outperform state-of-the-art schemes, namely interfering model (INT) and distributed random access (DRA), for both low and high-density 5G networks.},
  archive      = {J_TMC},
  author       = {Ajay Pratap and Rajiv Misra and Sajal K. Das},
  doi          = {10.1109/TMC.2019.2948877},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {603-619},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Maximizing fairness for resource allocation in heterogeneous 5G networks},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). &lt;Inline-formula&gt;&lt;tex-math notation=“LaTeX”&gt;<span
class="math inline"><em>M</em><sup>3</sup></span>&lt;/tex-math&gt;&lt;mml:math
xmlns:mml=“http://www.w3.org/1998/math/MathML”&gt;&lt;mml:msup&gt;&lt;mml:mi&gt;m&lt;/mml:mi&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;&lt;inline-graphic
xlink:href=“xu-ieq1-2950315.gif”
xmlns:xlink=“http://www.w3.org/1999/xlink”/&gt;&lt;/inline-formula&gt;:
Multipath assisted wi-fi localization with a single access point.
<em>TMC</em>, <em>20</em>(2), 588–602. (<a
href="https://doi.org/10.1109/TMC.2019.2950315">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Owing to the ubiquitous penetration of Wi-Fi in our daily lives, Wi-Fi indoor localization has attracted intensive attentions in the last decade or so. Despite some significant progresses, the high accuracy of existing systems is still achieved at the cost of dense access point (AP) deployment. The more practical single AP localization is largely left as an open problem because the hardware-induced time delay “contaminates” the measurement of signal propagation time in the air. In this article, we design and implement M 3 to tackle this challenge with commodity Wi-Fi cards. M 3 exploits a multipath-assisted approach that turns the harmful multipath from foe to friend to enable single AP localization: a device can be pinpointed through the combination of azimuths and the relative time of flight (ToF) of Line-of-Sight (LoS) signal and reflection signals, eliminating the need for multiple APs along with their absolute ToF measurements. M 3 further utilizes frequency hopping to combine multiple channels to form a virtually wider-spectrum channel for higher ToF resolution. As a prominent feature of M 3 , the channels do not need to be adjacent. Comprehensive experiments demonstrate that M 3 outperforms the state-of-the-art systems and achieves a median localization accuracy of 71 cm in three environments with a single AP.},
  archive      = {J_TMC},
  author       = {Zhe Chen and Guorong Zhu and Sulei Wang and Yuedong Xu and Jie Xiong and Jin Zhao and Jun Luo and Xin Wang},
  doi          = {10.1109/TMC.2019.2950315},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {588-602},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {&lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$M^3$&lt;/tex-math&gt;&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mml:msup&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href=&quot;xu-ieq1-2950315.gif&quot; xmlns:xlink=&quot;http://www.w3.org/1999/xlink&quot;/&gt;&lt;/inline-formula&gt;: multipath assisted wi-fi localization with a single access point},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Low-overhead wireless uplink scheduling for large-scale
internet-of-things. <em>TMC</em>, <em>20</em>(2), 577–587. (<a
href="https://doi.org/10.1109/TMC.2019.2949291">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth of Internet-of-Things (IoT) applications in recent years, there is a strong need for wireless uplink scheduling algorithms that determine when and which subset of a large number of users should transmit to the central controller. Different from the downlink case, the central controller in the uplink scenario typically has very limited information about the users. On the other hand, periodically collecting all such information from a large number of users typically incurs a prohibitively high communication overhead. This motivates us to investigate the development of an efficient and low-overhead uplink scheduling algorithm that is suitable for large-scale IoT applications. Specifically, we first characterize a capacity outer bound subject to the sampling constraint where only a small subset of users are allowed to use control channels for system state reporting at each time. Next, we relax the sampling constraint and propose a joint sampling and transmission algorithm, which utilizes full knowledge of channel state distributions and instantaneous queue lengths to achieve the capacity outer bound. The insights obtained from this capacity-achieving algorithm allow us to develop a low-overhead scheduling algorithm that can strictly satisfy the sampling constraint with asymptotically diminishing throughput loss.},
  archive      = {J_TMC},
  author       = {Bin Li and Jia Liu and Bo Ji},
  doi          = {10.1109/TMC.2019.2949291},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {577-587},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Low-overhead wireless uplink scheduling for large-scale internet-of-things},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). JointDNN: An efficient training and inference engine for
intelligent mobile cloud computing services. <em>TMC</em>,
<em>20</em>(2), 565–576. (<a
href="https://doi.org/10.1109/TMC.2019.2947893">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models are being deployed in many mobile intelligent applications. End-side services, such as intelligent personal assistants, autonomous cars, and smart home services often employ either simple local models on the mobile or complex remote models on the cloud. However, recent studies have shown that partitioning the DNN computations between the mobile and cloud can increase the latency and energy efficiencies. In this paper, we propose an efficient, adaptive, and practical engine, JointDNN, for collaborative computation between a mobile device and cloud for DNNs in both inference and training phase. JointDNN not only provides an energy and performance efficient method of querying DNNs for the mobile side but also benefits the cloud server by reducing the amount of its workload and communications compared to the cloud-only approach. Given the DNN architecture, we investigate the efficiency of processing some layers on the mobile device and some layers on the cloud server. We provide optimization formulations at layer granularity for forward- and backward-propagations in DNNs, which can adapt to mobile battery limitations and cloud server load constraints and quality of service. JointDNN achieves up to 18 and 32 times reductions on the latency and mobile energy consumption of querying DNNs compared to the status-quo approaches, respectively.},
  archive      = {J_TMC},
  author       = {Amir Erfan Eshratifar and Mohammad Saeed Abrishami and Massoud Pedram},
  doi          = {10.1109/TMC.2019.2947893},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {565-576},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {JointDNN: An efficient training and inference engine for intelligent mobile cloud computing services},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). IoTorch: Reliable LED-to-camera communication against
inter-frame gaps and frame drops. <em>TMC</em>, <em>20</em>(2), 550–564.
(<a href="https://doi.org/10.1109/TMC.2019.2943148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {LED-to-camera communication for smartphones promises to enable low-cost, small-size, and intuitive data access to Internet-of-things (IoT) devices. However, for fast and reliable communication under the rolling shutter effect, the packet losses caused by inter-frame gaps and frame drops must be dealt with. In this paper, we introduce LED-to-camera communication between a commercial smartphone and an IoT device with LED flashlight, where the user can intuitively acquire the desired data transmitted from the IoT device to the smartphone. Specifically, we present IoTorch, a fast and reliable LED-to-camera communication that efficiently prevents the packet losses. IoTorch consists of two core mechanisms: 1) a minimum-repetition one-way reliable transmission focusing on the periodicity of inter-frame gaps and 2) an acknowledgement mechanism to overcome frame drops by using a smartphone&#39;s built-in flash focusing on its delay characteristics. Additionally, we propose an optimization method to increase the throughput up to 2.92 kbps (i.e., 2.43 times faster than that of the state-of-the-art method that overcomes the inter-frame gaps). Furthermore, we realize a remote wake-up function by using the smartphone&#39;s flash as the data transmission trigger. To demonstrate the benefit of IoTorch, we present a sensor data viewer using Arduino and a smartphone console system on TelosB.},
  archive      = {J_TMC},
  author       = {Yuki Hokazono and Aoi Koizuka and Guibing Zhu and Makoto Suzuki and Yoshiaki Narusue and Hiroyuki Morikawa},
  doi          = {10.1109/TMC.2019.2943148},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {550-564},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {IoTorch: Reliable LED-to-camera communication against inter-frame gaps and frame drops},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Integrating fronthaul and backhaul networks: Transport
challenges and feasibility results. <em>TMC</em>, <em>20</em>(2),
533–549. (<a href="https://doi.org/10.1109/TMC.2019.2948641">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In addition to CPRI, new functional splits have been defined in 5G creating diverse fronthaul transport bandwidth and latency requirements. These fronthaul requirements shall be fulfilled simultaneously together with the backhaul requirements by an integrated fronthaul and backhaul transport solution. In this paper, we analyze the technical challenges to achieve an integrated transport solution in 5G and propose specific solutions to address these challenges. These solutions have been implemented and verified with pre-commercial equipment. Our results confirm that an integrated fronthaul and backhaul transport dubbed Crosshaul can meet all the requirements of 5G fronthaul and backhaul in a cost-efficient manner.},
  archive      = {J_TMC},
  author       = {Sergio Gonzalez-Diaz and Andres Garcia-Saavedra and Antonio de la Oliva and Xavier Costa-Perez and Robert Gazda and Alain Mourad and Thomas Deiss and Josep Mangues-Bafalluy and Paola Iovanna and Stefano Stracca and Phillip Leithead},
  doi          = {10.1109/TMC.2019.2948641},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {533-549},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Integrating fronthaul and backhaul networks: Transport challenges and feasibility results},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Incentivizing crowdsensing-based noise monitoring with
differentially-private locations. <em>TMC</em>, <em>20</em>(2), 519–532.
(<a href="https://doi.org/10.1109/TMC.2019.2946800">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile crowd sensing is a technique where a crowd sensing server outsources sensing tasks to the crowd for mobile data collection. In mobile crowd sensing, some tasks require location information to achieve their objectives, such as road monitoring, indoor floor plan reconstruction, and smart transportation. This required information incurs severe concerns on location privacy leakage and threatens workers’ properties as well as public safety. In some cases, even sensing data itself can be used as auxiliary information resulting in location privacy breaches. Many existing works apply differential privacy mechanisms for location privacy preservation to tackle this problem, but they cannot efficiently fulfill privacy goals because each worker only considers his own privacy. As a consequence, the accumulated privacy budget will lower down the composed privacy level of all the workers’ locations. In addition, deploying differential privacy is costly for workers and it will degrade the quality of data required in crowd sensing tasks. How to balance the cost and provide accurate aggregated data while fulfilling privacy objectives becomes a challenging issue. In this paper, we propose a group-differentially-private game-theoretical solution, which addresses these limitations in a privacy-preserving and efficient way. Our scheme enables the indistinguishability of workers’ locations and sensing data without the help of a trusted entity while meeting the accuracy demands of crowd sensing tasks. The effectiveness and efficiency of our scheme are thoroughly evaluated based on real-world datasets.},
  archive      = {J_TMC},
  author       = {Pei Huang and Xiaonan Zhang and Linke Guo and Ming Li},
  doi          = {10.1109/TMC.2019.2946800},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {519-532},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Incentivizing crowdsensing-based noise monitoring with differentially-private locations},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fully distributed packet scheduling framework for handling
disturbances in lossy real-time wireless networks. <em>TMC</em>,
<em>20</em>(2), 502–518. (<a
href="https://doi.org/10.1109/TMC.2019.2950913">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Along with the rapid growth of Industrial Internet-of-Things (IIoT) applications and their penetration into many industry sectors, real-time wireless networks (RTWNs) have been playing a more critical role in providing real-time, reliable, and secure communication services for such applications. A key challenge in RTWN management is how to ensure real-time Quality of Services (QoS) especially in the presence of unexpected disturbances and lossy wireless links. Most prior work takes centralized approaches for handling disturbances, which are slow and subject to single-point failure, and do not scale. To overcome these drawbacks, this article presents a fully distributed packet scheduling framework called FD-PaS . FD-PaS aims to provide guaranteed fast response to unexpected disturbances while achieving minimum performance degradation for meeting the timing and reliability requirements of all critical tasks. To combat the scalability challenge, FD-PaS incorporates several key advances in both algorithm design and data link layer protocol design to enable individual nodes to make on-line decisions locally without any centralized control. Our extensive simulation and testbed results have validated the correctness of the FD-PaS design and demonstrated its effectiveness in providing fast response for handling disturbances while ensuring the designated QoS requirements.},
  archive      = {J_TMC},
  author       = {Tianyu Zhang and Tao Gong and Song Han and Qingxu Deng and Xiaobo Sharon Hu},
  doi          = {10.1109/TMC.2019.2950913},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {502-518},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Fully distributed packet scheduling framework for handling disturbances in lossy real-time wireless networks},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). EzNavi: An easy-to-operate indoor navigation system based on
pedestrian dead reckoning and crowdsourced user trajectories.
<em>TMC</em>, <em>20</em>(2), 488–501. (<a
href="https://doi.org/10.1109/TMC.2019.2946821">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, researchers have paid attention to designing indoor navigation services for smartphone users. Conventional indoor navigation systems highly rely on well-known indoor information and prior training phase for localization, and thus it is time- and labor-consuming to bootstrap indoor navigation services. Without too much prior configurations, the proposed indoor navigation system, called ezNavi , utilizes trajectory information (reported by users) to generate indoor pathway and point of interests (POIs). The proposed system consists of a front-end mobile application (APP) and a back-end server. The mobile APP infers users’ walking trajectories according to sensory values from smartphones. The back-end server processes crowdsourced trajectories with the help of deployed Bluetooth low energy beacon devices, and then produces pathways of the indoor environment. After obtaining more trajectories, the ezNavi can further refine the derived pathways to provide more efficient guidance services for users. Our experiment and prototyping results reveal that the ezNavi can effectively derive users’ walking trajectories, produces indoor pathways, and indicates directions for users.},
  archive      = {J_TMC},
  author       = {Meng-Shiuan Pan and Kuan-Ying Li},
  doi          = {10.1109/TMC.2019.2946821},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {488-501},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {EzNavi: An easy-to-operate indoor navigation system based on pedestrian dead reckoning and crowdsourced user trajectories},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Energy-efficient resource allocation in c-RANs with
capacity-limited fronthaul. <em>TMC</em>, <em>20</em>(2), 473–487. (<a
href="https://doi.org/10.1109/TMC.2019.2942597">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud Radio Access Network (C-RAN) is a key architecture for 5G cellular wireless network that aims at improving spectral and energy efficiency of the network by uniting traditional RAN with cloud computing. In this paper, a novel resource allocation scheme that optimizes the network energy efficiency of a C-RAN is designed. First, an energy consumption model that characterizes the computation energy of the BaseBand Unit (BBU) is introduced based on empirical results collected from a programmable C-RAN testbed. Then, an optimization problem is formulated to maximize the energy efficiency of the network, subject to practical constraints including Quality of Service (QoS) requirement, radio remote head transmit power, and fronthaul capacity limits. The formulated Network Energy Efficiency Maximization (NEEM) problem jointly considers the tradeoff among the network accumulated data rate, BBU power consumption, fronthaul cost, and beamforming design. To deal with the non-convexity and mixed-integer nature of the problem, we utilize successive convex approximation methods to transform the original problem into the equivalent Weighted Sum-Rate (WSR) maximization problem. We then propose a provably-convergent iterative method to solve the resulting WSR problem. Extensive simulation results coupled with real-time experiments on a small-scale C-RAN testbed show the effectiveness of our proposed resource allocation scheme and its advantages over existing approaches.},
  archive      = {J_TMC},
  author       = {Ayman Younis and Tuyen X. Tran and Dario Pompili},
  doi          = {10.1109/TMC.2019.2942597},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {473-487},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Energy-efficient resource allocation in C-RANs with capacity-limited fronthaul},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic service entity placement for latency sensitive
applications in transportation systems. <em>TMC</em>, <em>20</em>(2),
460–472. (<a href="https://doi.org/10.1109/TMC.2019.2947465">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of applications on end devices, such as cell phones and tablets, more and more passengers would like to have entertainment on these end devices when they are cruising on vehicles. Due to the limited computation ability of the end devices, some of these applications have back-end components on the edge clouds, which are realized by Service Entities (SEs). In this work, we propose a system named DSEP to Dynamically determine the SEPlacement, such that the maximum latency experienced by the passengers can be minimized. To this end, we first train two sequential neural networks to predict the position of each individual vehicle, and propose an efficient algorithm based on optimization relaxation and Lagrange decomposition to determine the SE placement. Through extensive real-data driven simulations, we find that with the two sequential neural networks proposed in this paper, there are less than 1 percent errors on estimating where the passengers will access the edge cloud system. When the computation resources in the edge cloud are limited, DSEP can reduce the response latency by up to 43 percent compared with the nearest placement scheme. Even averaging the performance improvement over all simulation settings, DSEP can reduce the response latency by 16 percent.},
  archive      = {J_TMC},
  author       = {Yangming Zhao and Xin Liu and Lai Tu and Chen Tian and Chunming Qiao},
  doi          = {10.1109/TMC.2019.2947465},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {460-472},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Dynamic service entity placement for latency sensitive applications in transportation systems},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Delay-aware virtual network function placement and routing
in edge clouds. <em>TMC</em>, <em>20</em>(2), 445–459. (<a
href="https://doi.org/10.1109/TMC.2019.2942306">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile Edge Computing (MEC) offers a way to shorten the cloud servicing delay by building the small-scale cloud infrastructures at the network edge, which are in close proximity to the end users. Moreover, Network Function Virtualization (NFV) has been an emerging technology that transforms from traditional dedicated hardware implementations to software instances running in a virtualized environment. In NFV, the requested service is implemented by a sequence of Virtual Network Functions (VNF) that can run on generic servers by leveraging the virtualization technology. Service Function Chaining (SFC) is defined as a chain-ordered set of placed VNFs that handles the traffic of the delivery and control of a specific application. NFV therefore allows to allocate network resources in a more scalable and elastic manner, offer a more efficient and agile management and operation mechanism for network functions and hence can largely reduce the overall costs in MEC. In this paper, we study the problem of how to place VNFs on edge and public clouds and route the traffic among adjacent VNF pairs, such that the maximum link load ratio is minimized and each user&#39;s requested delay is satisfied. We consider this problem for both totally ordered SFCs and partially ordered SFCs. We prove that this problem is NP-hard, even for the special case when only one VNF is requested. We subsequently propose an efficient randomized rounding approximation algorithm to solve this problem. Extensive simulation results show that the proposed approximation algorithm can achieve close-to-optimal performance in terms of acceptance ratio and maximum link load ratio.},
  archive      = {J_TMC},
  author       = {Song Yang and Fan Li and Stojan Trajanovski and Xu Chen and Yu Wang and Xiaoming Fu},
  doi          = {10.1109/TMC.2019.2942306},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {445-459},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Delay-aware virtual network function placement and routing in edge clouds},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DeepWiFi: Cognitive WiFi with deep learning. <em>TMC</em>,
<em>20</em>(2), 429–444. (<a
href="https://doi.org/10.1109/TMC.2019.2949815">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present the DeepWiFi protocol, which hardens the baseline WiFi (IEEE 802.11ac) with deep learning and sustains high throughput by mitigating out-of-network interference. DeepWiFi is interoperable with baseline WiFi and builds upon the existing WiFi&#39;s PHY transceiver chain without changing the MAC frame format. Users run DeepWiFi for: i) RF front end processing; ii) spectrum sensing and signal classification; iii) signal authentication; iv) channel selection and access; v) power control; vi) modulation and coding scheme (MCS) adaptation; and vii) routing. DeepWiFi mitigates the effects of probabilistic, sensing-based, and adaptive jammers. RF front end processing applies a deep learning-based autoencoder to extract spectrum-representative features. Then a deep neural network is trained to classify waveforms reliably as idle, WiFi, or jammer. Utilizing channel labels, users effectively access idle or jammed channels, while avoiding interference with legitimate WiFi transmissions (authenticated by machine learning-based RF fingerprinting) resulting in higher throughput. Users optimize their transmit power for low probability of intercept/detection and their MCS to maximize link rates used by backpressure algorithm for routing. Supported by embedded platform implementation, DeepWiFi provides major throughput gains compared to baseline WiFi and another jamming-resistant protocol, especially when channels are likely to be jammed and the signal-to-interference-plus-noise-ratio is low.},
  archive      = {J_TMC},
  author       = {Kemal Davaslioglu and Sohraab Soltani and Tugba Erpek and Yalin E. Sagduyu},
  doi          = {10.1109/TMC.2019.2949815},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {429-444},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {DeepWiFi: Cognitive WiFi with deep learning},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cyclic three-sided matching game inspired wireless network
virtualization. <em>TMC</em>, <em>20</em>(2), 416–428. (<a
href="https://doi.org/10.1109/TMC.2019.2947522">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless network virtualization is basically the abstraction, isolation, and sharing of wireless resources among different entities. Consequently, virtualization provides great flexibility and higher network efficiency, and enables easier migration to new technologies in wireless networks. Traditionally, a wireless network virtualization controller manages the virtual resources (including radio resources and infrastructure resources) known as slices which are available to the Service Providers (SPs). The SPs then allocate their purchased resources to serve their subscribed mobile users. Such a centralized allocation decouples the Quality-of-Service (QoS) management by the SPs from the virtual resource management by the controller. In this paper, we propose a matching based wireless network virtualization resource allocation mechanism: a distributed three-sided (3D) matching between radio resources, physical infrastructure and mobile users. The Restricted Three-sided Matching with Size and Cyclic preference model (R-TMSC) is implemented to obtain a stable solution. Simulation results show that our proposed spectrum-oriented and user-oriented algorithms outperform the traditional resource allocation schemes. The spectrum-oriented algorithm enhances the user throughput and the system performance, within a lesser run time. Furthermore, for an increasing number of users, the proposed algorithms serve more users than traditional methods.},
  archive      = {J_TMC},
  author       = {Neetu Raveendran and Yunan Gu and Chunxiao Jiang and Nguyen H. Tran and Miao Pan and Lingyang Song and Zhu Han},
  doi          = {10.1109/TMC.2019.2947522},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {416-428},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Cyclic three-sided matching game inspired wireless network virtualization},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cost-fair task allocation in mobile crowd sensing with
probabilistic users. <em>TMC</em>, <em>20</em>(2), 403–415. (<a
href="https://doi.org/10.1109/TMC.2019.2950921">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile crowd sensing (MCS) is a new paradigm for urban-scale monitoring. This article concentrates on the Cost-Fair Task Allocation (CFA) problem for the MCS scenario where the collaboration of multiple probabilistic mobilephone users is needed to yield more reliable observation. CFA aims to allocate sensing tasks to users so that the sensing costs undertaken by all users are as balancing as possible, while the requirement of the requester for data reliability can be satisfied. CFA is greatly important to MCS campaigns in terms of reliability and sustainability. We design two algorithms to solve the CFA problem in the offline and online cases, respectively. Specifically, we propose a novel penalty-based model to reformulate the offline CFA problem, and based on this model, we design an offline algorithm, which can yield a computation-efficient &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\varepsilon$&lt;/tex-math&gt;&lt;/inline-formula&gt; -solution with any small &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\varepsilon &amp;gt;0$&lt;/tex-math&gt;&lt;/inline-formula&gt; . For the online case, we design a polynomial-time approximation algorithm, which struggles to allocate each of the sequentially arriving tasks to users as fairly as possible, and can achieve an upper-bounded competitiveness relative to the optimal CFA solution. Finally, we conduct extensive numeric analyses to validate the performance of our algorithms under diverse experimental setups.},
  archive      = {J_TMC},
  author       = {Guodong Sun and Yanan Wang and Xingjian Ding and Rong Hu},
  doi          = {10.1109/TMC.2019.2950921},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {403-415},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Cost-fair task allocation in mobile crowd sensing with probabilistic users},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cooperative caching in vehicular content centric network
based on social attributes and mobility. <em>TMC</em>, <em>20</em>(2),
391–402. (<a href="https://doi.org/10.1109/TMC.2019.2944829">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Communications in vehicular ad-hoc network (VANET) are subject to performance degradation as results of channel fading and intermittent network connectivity. The emerging Vehicular Content Centric Network (VCCN) is promising in supporting the needs of contents and alleviating the communication problems in VANET. Specifically, to improve the cache hit ratio and reduce the access delay of content retrieval, it helps to choose the appropriate vehicles to cache the frequently accessed data items. In this paper, we propose a Cooperative Caching scheme based on Social Attributes and Mobility Prediction (CCSAMP) for VCCN. CCSAMP is based on the observation that vehicles move around and are liable to contact each other according to drivers&#39; common interests or social similarities. A caching node sharing more social attributes with the content requester is more likely to be interested in the same contents and distribute the contents to others with similar interests. Furthermore, a caching node that frequently meets other nodes is a better candidate to keep cache copies. To increase the network performance, CCSAMP also exploits the regularity of vehicle moving behaviors to predict the chance for a vehicle to reach hot zones based on Hidden Markov Model (HMM). We evaluate CCSAMP through the ONE simulator to demonstrate its higher cache hit ratio and lower content access delay compared to other state-of-the-art schemes.},
  archive      = {J_TMC},
  author       = {Lin Yao and Yuqi Wang and Xin Wang and Guowei WU},
  doi          = {10.1109/TMC.2019.2944829},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {391-402},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Cooperative caching in vehicular content centric network based on social attributes and mobility},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Collaborative service placement for edge computing in dense
small cell networks. <em>TMC</em>, <em>20</em>(2), 377–390. (<a
href="https://doi.org/10.1109/TMC.2019.2945956">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile Edge Computing (MEC) pushes computing functionalities away from the centralized cloud to the proximity of data sources, thereby reducing service provision latency and saving backhaul network bandwidth. Although computation offloading for MEC systems has been extensively studied in the literature, service placement is an equally, if not more, important design topic of MEC, yet receives much less attention. Service placement refers to configuring the service platform and storing the related libraries/databases at the edge server, e.g., MEC-enabled Base Station (BS), which enables corresponding computation tasks to be executed. Due to the limited computing resource, the edge server can host only a small number of services and hence which services to host has to be judiciously decided to maximize the system performance. In this paper, we investigate collaborative service placement in MEC-enabled dense small cell networks. An efficient decentralized algorithm, called CSP (Collaborative Service Placement), is proposed where a network of small cell BSs optimize service placement decisions collaboratively to address a number of challenges in MEC systems, including service heterogeneity, spatial demand coupling, and decentralized coordination. CSP is developed based on parallel Gibbs sampling by exploiting the graph coloring on the small cell network. The algorithm significantly improves the time efficiency compared to conventional Gibbs sampling, yet guarantees provable convergence and optimality. CSP is further extended to work with selfish BSs, where BSs are allowed to choose “to cooperate” or “not to cooperate.” We employ coalitional game to investigate the strategic behaviors of selfish BSs and design a coalition formation scheme to form stable BS coalitions using merge-and-split rules. Simulations results show that CSP can effectively reduce edge system operational cost for both cooperative and selfish BSs.},
  archive      = {J_TMC},
  author       = {Lixing Chen and Cong Shen and Pan Zhou and Jie Xu},
  doi          = {10.1109/TMC.2019.2945956},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {377-390},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Collaborative service placement for edge computing in dense small cell networks},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Becoming smarter at characterizing potholes and speed bumps
from smartphone data — introducing a second-generation inference
problem. <em>TMC</em>, <em>20</em>(2), 366–376. (<a
href="https://doi.org/10.1109/TMC.2019.2947443">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Much has been said regarding the automatic identification of roadway obstacles by analyzing data collected from inertial sensors either fixed to the vehicle or embedded into the drivers&#39; smartphones. Literature is vast in models to, given a record of sensor readings, determine if the sample corresponds to a pothole or speed bump, even with scores beyond 90% in performance. Acknowledging this advance, this article considers the next-generation version of this problem. Specifically, we investigate questions such as: what physical properties of roadway obstacles could be inferred from the same sensor readings? or, what are the best schemes to model this profile problem? To approach these questions we built the first obstacle-detailed data set that is composed of accelerometer and gyroscope readings of 163 potholes and 101 speed bumps. This data set is the first of its kind, since it specifies ground truth labels that correspond to potholes&#39; depths and also, functional status (OK - Not OK) for speed bumps. We approach this fine-grained characterization using three different learning schemes, as a Regression, Classification and Learning to Rank tasks. Results are encouraging, reporting a RMSE for pothole&#39;s depth prediction of up to 1.68 cm and classification performance of 0.89 in AUC score. In summary, after more than 10 years of analysis, struggles and achievements, it is time for the community to become smarter and start profiling roads with real detail.},
  archive      = {J_TMC},
  author       = {M. Ricardo Carlos and Luis C. González and Johan Wahlström and Raymundo Cornejo and Fernando Martínez},
  doi          = {10.1109/TMC.2019.2947443},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {366-376},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Becoming smarter at characterizing potholes and speed bumps from smartphone data — introducing a second-generation inference problem},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Augur: Modeling the resource requirements of ConvNets on
mobile devices. <em>TMC</em>, <em>20</em>(2), 352–365. (<a
href="https://doi.org/10.1109/TMC.2019.2946538">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional Neural Networks (ConvNets/CNNs) have revolutionized the research in computer vision, due to their ability to capture complex patterns, resulting in high inference accuracies. However, the increasingly complex nature of these neural networks means that they are particularly suited for server computers with powerful GPUs. We envision that deep learning applications will be eventually widely deployed on mobile devices, e.g., smartphones, self-driving cars, and drones. Therefore, in this paper, we aim to understand the resource requirements of CNNs on mobile devices in terms of compute time, memory, and power. First, by deploying several popular CNNs on different mobile CPUs and GPUs, we measure and analyze the performance and resource usage for the CNNs on a layerwise granularity. Our findings point out the potential ways of optimizing the CNN pipelines on mobile devices. Second, we model resource requirements of core computations of CNNs. Finally, based on the measurement and modeling, we build and evaluate our modeling tool, Augur, which takes a CNN configuration (descriptor) as the input and estimates the compute time, memory, and power requirements of the CNN, to give insights about whether and how efficiently a CNN can be run on a given mobile platform.},
  archive      = {J_TMC},
  author       = {Zongqing Lu and Swati Rallapalli and Kevin Chan and Shiliang Pu and Thomas La Porta},
  doi          = {10.1109/TMC.2019.2946538},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {352-365},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Augur: Modeling the resource requirements of ConvNets on mobile devices},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An indirect eavesdropping attack of keystrokes on touch
screen through acoustic sensing. <em>TMC</em>, <em>20</em>(2), 337–351.
(<a href="https://doi.org/10.1109/TMC.2019.2947468">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper demonstrates the feasibility of a side-channel attack to infer keystrokes on touch screen leveraging an off-the-shelf smartphone. Although there exist some studies on keystroke eavesdropping attacks on touch screen, they are mainly direct eavesdropping attacks, i.e., require the device of victims compromised to provide side-channel information for the adversary, which are hardly launched in practical scenarios. In this work, we show the practicability of an indirect eavesdropping attack, KeyListener, which infers keystrokes on QWERTY keyboards of touch screen leveraging audio devices on a smartphone. We investigate the attenuation of acoustic signals, and find that a user&#39;s keystroke fingers can be localized through the attenuation of acoustic signals received by the microphones in the smartphone. We then utilize the attenuation of acoustic signals to localize each keystroke, and further analyze errors induced by ambient noises. To improve the accuracy of keystroke localization, KeyListener further tracks finger movements during inputs through phase change and Doppler effect to reduce errors of acoustic signal attenuation-based keystroke localization. In addition, a binary tree-based search approach is employed to infer keystrokes in a context-aware manner. The proposed keystroke eavesdropping attack is robust to various environments without the assistance of additional infrastructures. Extensive experiments demonstrate that the accuracy of keystroke inference in top-5 candidates can approach 90 percent with a top-5 error rate of around 6 percent, which is a strong indication of the possible user privacy leakage of inputs on QWERTY keyboard.},
  archive      = {J_TMC},
  author       = {Jiadi Yu and Li Lu and Yingying Chen and Yanmin Zhu and Linghe Kong},
  doi          = {10.1109/TMC.2019.2947468},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {337-351},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {An indirect eavesdropping attack of keystrokes on touch screen through acoustic sensing},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An adaptive sensor fusion framework for pedestrian indoor
navigation in dynamic environments. <em>TMC</em>, <em>20</em>(2),
320–336. (<a href="https://doi.org/10.1109/TMC.2019.2946809">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Indoor navigation is a representative application of an indoor positioning system that uses a variety of equipment, including smartphones with various sensors. Many indoor navigation systems utilize Wi-Fi signals, as well as a variety of inertial sensors, such as a 3D accelerometer, digital compass, gyroscope, and barometer, to improve the accuracy of user location tracking. The inertial sensors are vulnerable to changes in the surrounding environments and sensitive to users behavior, but little research has been conducted on sensor fusion under these conditions. In this paper, we propose a dynamic sensor fusion framework (DSFF) that provides accurate user tracking results by dynamically calibrating inertial sensor readings in a sensor fusion process. The proposed method continually learns the errors and biases of each sensor due to the changes in user behavior patterns and surrounding environments. The learned patterns are then dynamically applied to the user tracking process to yield accurate results. The results of experiments conducted in both a single-story and a multi-story building confirm that DSFF provides accurate tracking results. The scalability of the DSFF will enable it to provide more accurate tracking results with various sensors, both existing and under development.},
  archive      = {J_TMC},
  author       = {Gunwoo Lee and Suk-Hoon Jung and Dongsoo Han},
  doi          = {10.1109/TMC.2019.2946809},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {320-336},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {An adaptive sensor fusion framework for pedestrian indoor navigation in dynamic environments},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adversarial deep learning for over-the-air spectrum
poisoning attacks. <em>TMC</em>, <em>20</em>(2), 306–319. (<a
href="https://doi.org/10.1109/TMC.2019.2950398">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An adversarial deep learning approach is presented to launch over-the-air spectrum poisoning attacks. A transmitter applies deep learning on its spectrum sensing results to predict idle time slots for data transmission. In the meantime, an adversary learns the transmitter&#39;s behavior (exploratory attack) by building another deep neural network to predict when transmissions will succeed. The adversary falsifies (poisons) the transmitter&#39;s spectrum sensing data over the air by transmitting during the short spectrum sensing period of the transmitter. Depending on whether the transmitter uses the sensing results as test data to make transmit decisions or as training data to retrain its deep neural network, either it is fooled into making incorrect decisions (evasion attack) or the transmitter&#39;s algorithm is retrained incorrectly for future decisions (causative attack). Both attacks are energy efficient and hard to detect (stealth) compared to jamming the long data transmission period, and substantially reduce the throughput. A dynamic defense is designed for the transmitter that deliberately makes a small number of incorrect transmissions (selected by the confidence score on channel classification) to manipulate the adversary&#39;s training data. This defense effectively fools the adversary (if any) and helps the transmitter sustain its throughput with or without an adversary present.},
  archive      = {J_TMC},
  author       = {Yalin E. Sagduyu and Yi Shi and Tugba Erpek},
  doi          = {10.1109/TMC.2019.2950398},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {306-319},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Adversarial deep learning for over-the-air spectrum poisoning attacks},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A cloud-guided feature extraction approach for image
retrieval in mobile edge computing. <em>TMC</em>, <em>20</em>(2),
292–305. (<a href="https://doi.org/10.1109/TMC.2019.2944371">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile Edge Computing (MEC) can facilitate various important image retrieval applications for mobile users by offloading partial computation tasks from resource-limited mobile devices to edge servers. However, existing related works suffer from two major limitations. (i) High network bandwidth cost: they need to extract numerous features from the image and upload these feature data to the cloud server. (ii) Lowretrieval accuracy: they separate the feature extraction processes from the image data set in the cloud server, thus unable to provide effective features for accurate image retrieval. In this paper, we propose a cloud-guided feature extraction approach for mobile image retrieval. In the proposed approach, the cloud server first leverages the relationships among labeled images in the data set to learn a projection matrix P. Then, it uses the matrix P to extract discriminative features from the image data set and form a low-dimensional feature data set. Following that, the cloud server sends the matrix P to the edge server and uses it to multiply the image χ. The result PTχ, i.e., image features, is uploaded to the cloud server to find the label of the image with the most similar multiplying result. The label is regarded as the retrieval result and returned to the mobile user. In the cloud-guided feature extraction approach, the matrix P can extract a small number of effective image features, which not only reduces network traffic but also improves retrieval accuracy. We have implemented a prototype system to validate the proposed approach and evaluate its performance by conducting extensive experiments using a real MEC environment and data set. The experimental results show that the proposed approach reduces the network traffic by nearly 93 percent and improves the retrieval accuracy by nearly 6.9 percent compared with the state-of-the-art image retrieval approaches in MEC.},
  archive      = {J_TMC},
  author       = {Shangguang Wang and Chuntao Ding and Ning Zhang and Xiulong Liu and Ao Zhou and Jiannong Cao and Xuemin Shen},
  doi          = {10.1109/TMC.2019.2944371},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {292-305},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A cloud-guided feature extraction approach for image retrieval in mobile edge computing},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Wireless power transfer with information asymmetry: A public
goods perspective. <em>TMC</em>, <em>20</em>(1), 276–291. (<a
href="https://doi.org/10.1109/TMC.2019.2941205">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless power transfer (WPT) technology enables a cost-effective and sustainable energy supply in wireless networks. However, the broadcast nature of wireless signals makes them non-excludable public goods , which leads to potential free-riders among energy receivers. In this study, we formulate the wireless power provision problem as a public goods provision problem, aiming to maximize the social welfare of a system of an energy transmitter (ET) and all the energy users (EUs), while considering their heterogeneous valuations, private information, and self-interested behaviors. We propose a two-phase all-or-none scheme involving a low-complexity Power And Taxation (PAT) mechanism, which ensures voluntary participation, truthfulness, budget balance, and social optimality at every Nash equilibrium (NE). We propose a distributed PAT (D-PAT) algorithm to reach an NE, and prove its convergence by connecting the structure of NEs and that of the optimal solution to a related optimization problem. We further extend the analysis to a multi-channel system, which brings a further challenge of non-strictly concave agents’ payoffs. We propose a Multi-Channel PAT (M-PAT) mechanism and a distributed M-PAT (D-MPAT) algorithm to address the challenge. Simulation results show that, our design is most beneficial when there are more EUs and more homogeneous channel gains.},
  archive      = {J_TMC},
  author       = {Meng Zhang and Jianwei Huang and Rui Zhang},
  doi          = {10.1109/TMC.2019.2941205},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {276-291},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Wireless power transfer with information asymmetry: A public goods perspective},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Wireless-assisted key establishment leveraging channel
manipulation. <em>TMC</em>, <em>20</em>(1), 263–275. (<a
href="https://doi.org/10.1109/TMC.2019.2939529">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless communication is easily eavesdropped due to the broadcast nature of the wireless medium. This has spurred extensive research into secret key establishment using physical layer characteristics of wireless channels. In all these schemes, the secret keys directly originate from the physical features of the real wireless channel, which is highly dependent on the communication environment nearby. Also, previous schemes require performing information reconciliation, which increases both the costs and the risk of key leakage. In this paper, we exhibit a novel wireless key establishment method allowing the transmitter to specify arbitrary content as the key and cause the receiver to obtain the same key leveraging a channel manipulation technique. We furthermore enable the transmitter to apply error-correction code to the key, so that the receiver can automatically correct any mismatched bits without sending key-related information back to the transmitter over the public channel. Experimental results demonstrate that our key establishment method reaches a success rate as high as 91.0 percent for establishing a 168-bit key between the transmitter and the receiver, and meanwhile the chance that the eavesdropper can infer the key in meter-order range of the receiver is subdued into the range of 0~0.10 percent.},
  archive      = {J_TMC},
  author       = {Song Fang and Ian Markwood and Yao Liu},
  doi          = {10.1109/TMC.2019.2939529},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {263-275},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Wireless-assisted key establishment leveraging channel manipulation},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Tracking and behavior augmented activity recognition for
multiple inhabitants. <em>TMC</em>, <em>20</em>(1), 247–262. (<a
href="https://doi.org/10.1109/TMC.2019.2936382">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop CACE (Constraints And Correlations mining Engine), a framework that significantly improves the recognition accuracy of complex daily activities in multi-inhabitant smarthomes. CACE views the implicit relationships between the activities of multiple people as an asset, and exploits such constraints and correlations in a hierarchical fashion, taking advantage of both personspecific sensor data (generated by wearable devices) and person-independent ambient sensor data (generated by ambient sensors). To effectively utilize such couplings, CACE first uses a multi-target particle filtering approach over ambient sensors captured movement data, to identify the number of distinct users and infer individual-specific movement trajectories. We then utilize a Hierarchical Dynamic Bayesian Network (HDBN)-based model for activity recognition. This model utilizes the inter-and-intra individual correlations and constraints, at both micro-activity and macro-activity levels, to recognize individual activities accurately. These constraints are learnt automatically using data-mining techniques, and help to dramatically reduce the computational complexity of HDBN-based inferencing. Empirical studies using a real-world testbed of five multi-inhabitant smarthomes shows that CACE is able to achieve an activity recognition accuracy of 95%, with a 16-fold reduction in computational overhead compared to traditional hybrid classification approaches.},
  archive      = {J_TMC},
  author       = {Mohammad Arif Ul Alam and Nirmalya Roy and Archan Misra},
  doi          = {10.1109/TMC.2019.2936382},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {247-262},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Tracking and behavior augmented activity recognition for multiple inhabitants},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Throughput-optimal broadcast in wireless networks with
point-to-multipoint transmissions. <em>TMC</em>, <em>20</em>(1),
232–246. (<a href="https://doi.org/10.1109/TMC.2019.2940025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of efficient packet dissemination in wireless networks with point-to-multipoint wireless broadcast channels. We propose a dynamic policy, which achieves the broadcast capacity of the network. This policy is obtained by first transforming the original multi-hop network into a precedence-relaxed virtual single-hop network and then finding an optimal broadcasting policy for the relaxed network. The resulting policy is shown to be throughput-optimal for the original wireless network using a sample-path argument. We also prove the NP-completeness of the finite-horizon broadcasting problem, which is in contrast with the polynomial-time solvability of the problem with point-to-point channels. Illustrative simulation results demonstrate the efficacy of the proposed broadcast policy in achieving the full broadcast capacity with low delay.},
  archive      = {J_TMC},
  author       = {Abhishek Sinha and Eytan Modiano},
  doi          = {10.1109/TMC.2019.2940025},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {232-246},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Throughput-optimal broadcast in wireless networks with point-to-multipoint transmissions},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SMARS: Sleep monitoring via ambient radio signals.
<em>TMC</em>, <em>20</em>(1), 217–231. (<a
href="https://doi.org/10.1109/TMC.2019.2939791">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present the model, design, and implementation of SMARS, the first practical Sleep Monitoring system that exploits Ambient Radio Signals to recognize sleep stages and assess sleep quality. This will enable a future smart home that monitors daily sleep in a ubiquitous, non-invasive and contactless manner, without instrumenting the subject&#39;s body or the bed. The key enabler underlying SMARS is a statistical model that accounts for all reflecting and scattering multipaths, allowing highly accurate and instantaneous breathing estimation with best-ever performance achieved on commodity devices. On this basis, SMARS then recognizes different sleep stages, including wake, rapid eye movement (REM), and non-REM (NREM), which was previously only possible with dedicated hardware. We implement a real-time system on commercial WiFi chipsets and deploy it in 6 homes, resulting in 32 nights of data in total. Our results demonstrate that SMARS yields a median absolute error of 0.47 breaths per minute (BPM) and a 95 percent-tile error of only 2.92 BPM for breathing estimation, and detects breathing robustly even when a person is 10 meters away from the link, or behind a wall. SMARS achieves a sleep staging accuracy of 88 percent, outperforming the prevalent unobtrusive commodity solutions using bed sensor or UWB radar. The performance is also validated upon a public sleep dataset of 20 patients. By achieving promising results with merely a single commodity RF link, we believe that SMARS will set the stage for a practical in-home sleep monitoring solution.},
  archive      = {J_TMC},
  author       = {Feng Zhang and Chenshu Wu and Beibei Wang and Min Wu and Daniel Bugos and Hangfang Zhang and K. J. Ray Liu},
  doi          = {10.1109/TMC.2019.2939791},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {217-231},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {SMARS: Sleep monitoring via ambient radio signals},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Networking support for bidirectional cross-technology
communication. <em>TMC</em>, <em>20</em>(1), 204–216. (<a
href="https://doi.org/10.1109/TMC.2019.2938524">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research on physical layer cross technology communication (PHY-CTC) brings a timely answer for escalated wireless coexistence and open spectrum movement. PHY-CTC achieves direct communication among heterogeneous wireless technologies (e.g.,WiFi, Bluetooth, and ZigBee) in physical layer and thus brings communication support for coexistence service such as spectrum management and IoT device control. To put PHY-CTC into service, however, there still exists a gap due to its transmission failure and asymmetric link (i.e., one-way PHY-CTC) issues. In this paper, we propose NetCTC – the first networking support design for PHY-CTC to establish feedbacks (e.g., ACKs) and thus meet the upper layer networking requirements in heterogeneous unicast, multicast and broadcast. The core design of NetCTC is a real-time interaction mechanism which achieves reliable, transmission efficient and concurrent interactive communication among heterogeneous devices. We implement and evaluate NetCTC on commodity devices and the USRP-N210 platform. Our extensive evaluation demonstrates that NetCTC achieves reliable bidirectional cross technology communication under a full range of wireless configurations including stationary, mobile and duty-cycled settings.},
  archive      = {J_TMC},
  author       = {Shuai Wang and Zhimeng Yin and Shuai Wang and Zhijun Li and Yongrui Chen and Song Min Kim and Tian He},
  doi          = {10.1109/TMC.2019.2938524},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {204-216},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Networking support for bidirectional cross-technology communication},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MobileCopy: Improving data availability and file search
efficiency in delay tolerant networks against correlated node failure.
<em>TMC</em>, <em>20</em>(1), 188–203. (<a
href="https://doi.org/10.1109/TMC.2019.2939792">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {So far, there is no file replication method that tries to reduce data loss in correlated node failures, which however are common in Disruption Tolerant Networks (DTNs). In this paper, we propose a distributed file replication method (called MobileCopy) in DTNs, which aims to achieve low probability of totally losing a file at the expense of having a high number of impacted files in an individual large-scale correlated node failure. MobileCopy is designed for community-based file sharing systems. It has two main components: i) data loss resistant and popularity aware file replication, and ii) distributed hash table (DHT)-based file replica indexing. MobileCopy considers file popularity to determine the number of replicas of a file in each community. Through limiting the possible combination of candidate replica holders, MobileCopy greatly reduces the probability of node failures that will lead to data loss, i.e., losing all replicas of a file. Moreover, MobileCopy enables nodes to efficiently store and fetch the placement information of file replicas through competition based file replication and considering node mobility throughput among communities. Extensive trace-driven experiments demonstrate the effectiveness of MobileCopy against correlated node failures compared with previous methods.},
  archive      = {J_TMC},
  author       = {Li Yan and Haiying Shen and Kang Chen and Guoxin Liu},
  doi          = {10.1109/TMC.2019.2939792},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {188-203},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {MobileCopy: Improving data availability and file search efficiency in delay tolerant networks against correlated node failure},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving the performance of online bitrate adaptation with
multi-step prediction over cellular networks. <em>TMC</em>,
<em>20</em>(1), 174–187. (<a
href="https://doi.org/10.1109/TMC.2019.2939124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video streaming over mobile is flourishing, and most commercial players use adaptive bitrate (ABR) streaming to deliver video in varying network conditions. Using network capacity and buffer occupancy as system states, ABR algorithms adjust bitrate based on the instantaneous system states, which is able to adapt to network changes in real-time and ensure high quality of experience (QoE). However, they are incapable of providing good QoE over mobile. Due to the high dynamic characteristics of cellular network, the system states change rapidly over time. The instantaneous state-based adaptation can induce significant video quality fluctuation which greatly degrades QoE. In this paper, we propose an online ABR algorithm called MSPC to provide good QoE in cellular network. To balance the conflict between rapid adaptation and smooth bitrate, MSPC utilizes the multi-step prediction of future system states to select bitrates instead of the instantaneous current states. At the same time, it controls the buffer occupancy to eliminate the impact of prediction error on performance. We implement MSPC on a reference video player with performance evaluated based on realistic cellular traces. Experimental results show that MSPC reduces the bitrate change of existing online algorithms by 62.4 percent on average while maintaining high bitrates and achieving zero rebuffering over 97.83 percent of all tested sessions.},
  archive      = {J_TMC},
  author       = {Bo Wang and Fengyuan Ren and Jiahai Yang and Chao Zhou},
  doi          = {10.1109/TMC.2019.2939124},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {174-187},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Improving the performance of online bitrate adaptation with multi-step prediction over cellular networks},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Heterogeneous V2V communications in multi-link and multi-RAT
vehicular networks. <em>TMC</em>, <em>20</em>(1), 162–173. (<a
href="https://doi.org/10.1109/TMC.2019.2939803">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Connected and automated vehicles will enable advanced traffic safety and efficiency applications thanks to the dynamic exchange of information between vehicles, and between vehicles and infrastructure nodes. Connected vehicles can utilize IEEE 802.11p for vehicle-to-vehicle (V2V) and vehicle-to-infrastructure (V2I) communications. However, a widespread deployment of connected vehicles and the introduction of connected automated driving applications will notably increase the bandwidth and scalability requirements of vehicular networks. This paper proposes to address these challenges through the adoption of heterogeneous V2V communications in multi-link and multi-RAT vehicular networks. In particular, the paper proposes the first distributed (and decentralized) context-aware heterogeneous V2V communications algorithm that is technology and application agnostic, and that allows each vehicle to autonomously and dynamically select its communications technology taking into account its application requirements and the communication context conditions. This study demonstrates the potential of heterogeneous V2V communications, and the capability of the proposed algorithm to satisfy the vehicles&#39; application requirements while approaching the estimated upper bound network capacity.},
  archive      = {J_TMC},
  author       = {Miguel Sepulcre and Javier Gozalvez},
  doi          = {10.1109/TMC.2019.2939803},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {162-173},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Heterogeneous V2V communications in multi-link and multi-RAT vehicular networks},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distributed deep learning optimized system over the cloud
and smart phone devices. <em>TMC</em>, <em>20</em>(1), 147–161. (<a
href="https://doi.org/10.1109/TMC.2019.2941492">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has been becoming a promising focus in data mining research. With deep learning techniques, researchers can discover deep properties and features of events from quantitative mobile sensor data. However, many data sources are geographically separated and have strict privacy, security, and regulatory constraints. Upon releasing the privacy-sensitive data, these data sources generally no longer physically possess their data and cannot interfere with the way their personal data being used. Therefore, it is necessary to explore distributed data mining architecture which is able to conduct consensus learning based on needs. Accordingly, we propose a distributed deep learning optimized system which contains a cloud server and multiple smartphone devices with computation capabilities and each device is served as a personal mobile data hub for enabling mobile computing while preserving data privacy. The proposed system keeps the private data locally in smartphones, shares trained parameters, and builds a global consensus model. The feasibility and usability of the proposed system are evaluated by three experiments and related discussion. The experimental results show that the proposed distributed deep learning system can reconstruct the behavior of centralized training. We also measure the cumulative network traffic in different scenarios and show that the partial parameter sharing strategy does not only preserve the performance of the trained model but also can reduce network traffic. User data privacy is protected on two levels. First, local private training data do not need to be shared with other people and the user has full control of their personal training data all the time. Second, only a small fraction of trained gradients of the local model are selected for sharing, which further reduces the risk of information leaking.},
  archive      = {J_TMC},
  author       = {Haotian Jiang and James Starkman and Yu-Ju Lee and Huan Chen and Xiaoye Qian and Ming-Chun Huang},
  doi          = {10.1109/TMC.2019.2941492},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {147-161},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Distributed deep learning optimized system over the cloud and smart phone devices},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distributed and energy-efficient mobile crowdsensing with
charging stations by deep reinforcement learning. <em>TMC</em>,
<em>20</em>(1), 130–146. (<a
href="https://doi.org/10.1109/TMC.2019.2938509">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile crowdsensing (MCS) represents a new sensing paradigm that utilizes the smart mobile devices to collect and share data. Traditional MCS systems mainly leverages the people carried smartphones and other wearable devices which are constrained by the limited sensing capability and battery power. With the popularity of unmanned vehicles like unmanned aerial vehicles (UAVs) and driverless cars, they can provide much more reliable, accurate and cost-efficient sensing services due to to their equipped more powerful sensors. In this paper, we propose a distributed control framework for energy-efficient and DIstributed VEhicle navigation with chaRging sTations, called “e-Divert”. It is a distributed multi-agent deep reinforcement learning (DRL) solution, which uses a convolutional neural network (CNN) to extract useful spatial features as the input to the actor-critic network to produce a real-time action. Also, e-Divert incorporates a distributed prioritized experience replay for better exploration and exploitation, and a long short-term memory (LSTM) enabled N-step temporal sequence modeling module. The solution fully explores the spatiotemporal nature of the considered scenario for better vehicle cooperation and competition between themselves and charging stations, to maximize the energy efficiency, data collection ratio, geographic fairness, and minimize the energy consumption simultaneously. Through extensive simulations, we find an appropriate set of hyperparameters that achieve the best performance, i.e., 5 actors in Ape-X architecture, priority exponent 0.5, and LSTM sequence length 3. Finally, we compare with four baselines including one state-of-the-art approach MADDPG. Results show that our proposed e-Divert significantly improves the energy efficiency, as compared to MADDPG, by 3.62 and 2.36 times on average when varying different numbers of vehicles and charging stations, respectively.},
  archive      = {J_TMC},
  author       = {Chi Harold Liu and Zipeng Dai and Yinuo Zhao and Jon Crowcroft and Dapeng Wu and Kin K. Leung},
  doi          = {10.1109/TMC.2019.2938509},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {130-146},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Distributed and energy-efficient mobile crowdsensing with charging stations by deep reinforcement learning},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Compressed beam alignment with out-of-band assistance in
millimeter wave cellular networks. <em>TMC</em>, <em>20</em>(1),
117–129. (<a href="https://doi.org/10.1109/TMC.2019.2941474">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network transmission over millimeter-wave (mmW) bands has a big potential to provide orders of higher bandwidth. However, beamforming is generally needed to compensate for the high path loss. As mmW antennas have a potentially large number of candidate beamforming directions, to achieve high network throughput, the finding of a high gain direction between a base station and each mobile in the mmW network may involve a large overhead if training signals are directly sent along all possible directions or according to a large volume of codebook. Taking advantage of the block sparse characteristics of the mmW channel and coexistence of legacy antennas, we propose a comprehensive design for more efficient beam direction finding. Different from existing compressive-sensing-based schemes which just take a random subset of directions to measure, taking advantage of the path clustering feature of the mmW channel, we develop a self-adaptive block sparse algorithm which can benefit from preliminary channel estimation during each iteration of the problem solving to significantly improve the overall channel estimation accuracy thus the beam alignment gain. We also explore two methods to exploit co-located legacy antennas to provide further guidance for transmission direction finding. Simulation results indicate that our proposed beam alignment scheme outperforms the baseline and peer schemes in terms of the beamforming gain and training cost. By taking advantage of the block sparse properties of mmW channel, our proposed design is able to achieve the transmission throughput comparable with the exhaustive direction search at much lower overhead.},
  archive      = {J_TMC},
  author       = {Jie Zhao and Xin Wang and Harish Viswanathan and Arjuna Madanayake and Guangxue Yue},
  doi          = {10.1109/TMC.2019.2941474},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {117-129},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Compressed beam alignment with out-of-band assistance in millimeter wave cellular networks},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). CollabLoc: Privacy-preserving multi-modal collaborative
mobile phone localization. <em>TMC</em>, <em>20</em>(1), 104–116. (<a
href="https://doi.org/10.1109/TMC.2019.2937775">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile location-based services are important context-aware services that are more and more used for enforcing security policies, for supporting indoor room navigation, and for providing personalized assistance. However, a major problem still remains unaddressed-the lack of solutions that work across buildings while not using additional infrastructure and also accounting for privacy and reliability needs. A privacy-preserving, multi-modal, cross-building, collaborative localization platform is proposed based on Wi-Fi Received Signal Strength Indicator (RSSI) (existing infrastructure), Cellular RSSI, sound, light, and geo-magnetic levels, that enables sub-room level localization. The solution is fully based on mobile phones and existing Wi-Fi infrastructure, and has privacy inherently built into it via cryptographically-secured onion routing and perturbation/randomization techniques. It also exploits the idea of weighted collaboration to increase the reliability as well as to limit the effect of noisy devices (due to sensor noise/privacy). The solution has been analyzed in terms of latency overhead due to onion-routing, request load on phones, privacy-accuracy tradeoffs, optimum parameters, granularity, different classification algorithms using real location data collected at multiple indoor and outdoor locations via an Android application. The additional features other than Wi-Fi RSSI values are shown to increase the accuracy to a maximum of 15 percent, while considering Geo-magnetic field is shown to enhance the granularity from 2.5 m to ≈1 m, a 60 percent improvement.},
  archive      = {J_TMC},
  author       = {Vidyasagar Sadhu and Saman Zonouz and Vincent Sritapan and Dario Pompili},
  doi          = {10.1109/TMC.2019.2937775},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {104-116},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {CollabLoc: Privacy-preserving multi-modal collaborative mobile phone localization},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Analysis of drone assisted network coded cooperation for
next generation wireless network. <em>TMC</em>, <em>20</em>(1), 93–103.
(<a href="https://doi.org/10.1109/TMC.2019.2939308">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, use of drone as a relay node in Network Coded Cooperation (NCC) for upcoming wireless networks is proposed to achieve additional diversity as well as improve throughput. Unlike static relay cases, in drone assisted scenarios, better performance can be achieved simply by changing the position of relay. In order to quantify the network performance in drone assisted NCC, analytical closed form expression of outage probability has been calculated using two approaches namely, Analytical and Semi-analytical. Using a generalized system model, Probability Density Function (PDF) of Signal to Noise Ratio (SNR) of the path from source to destination via drone (relay) is derived. Closed form expression for outage probability in absence of direct link is also investigated. By analyzing Analog Network Coding (ANC) noise, statistical parameters of variance of ANC-noise have been obtained. Analytical findings have been verified through extensive simulations using MATLAB. Effects of drone height on system performance is also investigated through simulations. Framework presented here can be useful while analysing networks having resource constraint devices. PDF of SNR of relay path can be utilized for performing diversity calculations. Two outage expressions derived may be useful in determining system parameters for achieving any particular Quality of Service (QoS) in next generation wireless networks. Valuable insights obtained through the analysis of optimum height of drone are conducive while deploying the nodes in deterministic fashion for NCC.},
  archive      = {J_TMC},
  author       = {Pankaj Kumar and Prabhleen Singh and Sam Darshi and Samar Shailendra},
  doi          = {10.1109/TMC.2019.2939308},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {93-103},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Analysis of drone assisted network coded cooperation for next generation wireless network},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An inter-data encoding technique that exploits synchronized
data for network applications. <em>TMC</em>, <em>20</em>(1), 76–92. (<a
href="https://doi.org/10.1109/TMC.2019.2940578">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a variety of network applications, there exists a significant amount of shared data between two end hosts. Examples include data synchronization services that replicate data from one node to another. Given that shared data may have a high correlation with new data to transmit, we question how such shared data can be best utilized to improve the efficiency of data transmission. To answer this, we develop an inter-data encoding technique, SyncCoding, that effectively replaces bit sequences of the data to be transmitted with the pointers to their matching bit sequences in the shared data so called references. By doing so, SyncCoding can reduce data traffic, speed up data transmission, and save energy consumption for transmission. Our evaluations of SyncCoding implemented in Linux show that it outperforms existing popular encoding techniques, Brotli, LZMA, Deflate, and Deduplication. The gains of SyncCoding over those techniques in the perspective of data size after compression in a cloud storage scenario are about 12.5, 20.8, 30.1, and 66.1 percent, and are about 78.4, 80.3, 84.3, and 94.3 percent in a web browsing scenario, respectively.},
  archive      = {J_TMC},
  author       = {Wooseung Nam and Joohyun Lee and Ness B. Shroff and Kyunghan Lee},
  doi          = {10.1109/TMC.2019.2940578},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {76-92},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {An inter-data encoding technique that exploits synchronized data for network applications},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An incentive-aware job offloading control framework for
multi-access edge computing. <em>TMC</em>, <em>20</em>(1), 63–75. (<a
href="https://doi.org/10.1109/TMC.2019.2941934">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers a scenario in which an access point (AP) is equipped with a server of finite computing power, and serves multiple resource-hungry users by charging users a price. This price helps to regulate users&#39; behavior in offloading jobs to the AP. However, existing works on pricing are based on abstract concave utility functions, giving no dependence on physical layer parameters. To that end, we first introduce a novel utility function, which measures the cost reduction by offloading as compared with executing jobs locally. Based on this utility function we then formulate two offloading games, with one maximizing individuals interest and the other maximizing the overall systems interest. We analyze the structural property of the games and admit in closed-form the Nash Equilibrium and the Social Equilibrium for the homogeneous user case, respectively. The proposed expressions are functions of user parameters such as the weights of time and energy, the distance from the AP, thus constituting an advancement over prior economic works that have considered only abstract functions. Finally, we propose an optimal price-based scheme, with which we prove that the interactive decision-making process with self-interested users converges to a Nash Equilibrium point equal to the Social Equilibrium point.},
  archive      = {J_TMC},
  author       = {Lingxiang Li and Tony Q.S. Quek and Ju Ren and Howard H. Yang and Zhi Chen and Yaoxue Zhang},
  doi          = {10.1109/TMC.2019.2941934},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {63-75},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {An incentive-aware job offloading control framework for multi-access edge computing},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A utility model for photo selection in mobile crowdsensing.
<em>TMC</em>, <em>20</em>(1), 48–62. (<a
href="https://doi.org/10.1109/TMC.2019.2941927">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing mobile photo crowdsensing approaches focus on the participant-to-server photo pre-selection, i.e., reducing the photo redundancy from participants to a server. The server may still receive plenty of photos for a target area. Yet, another important problem is to select a proper photo subset of an area from the server to a requester. This is a challenging problem because the selected subset with a small size should attain both coverage on the PoIs - Points of Interest (i.e., photo coverage of the area) and quality on the views (i.e., view quality). In this paper, we propose a novel and generic server-to-requester photo selection approach even when there are neither photo shooting direction information nor reference photos. A utility model is designed to measure photo merits of coverage and quality by exploiting photos&#39; spatial distribution and visual representativeness. We present two photo selection schemes, basic and PoI number-aware, to maximize the photo selection utility with multiple levels of granularity. Experimental results on real-world datasets show that our basic scheme outperforms the baselines by an average of 33% and 18.7% on photo coverage and view quality, respectively. Our PoI number-aware scheme can yield an additionally 44.8 percent improvement on the photo coverage performance.},
  archive      = {J_TMC},
  author       = {Tongqing Zhou and Bin Xiao and Zhiping Cai and Ming Xu},
  doi          = {10.1109/TMC.2019.2941927},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {48-62},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A utility model for photo selection in mobile crowdsensing},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A reassessment on friendly jamming efficiency. <em>TMC</em>,
<em>20</em>(1), 32–47. (<a
href="https://doi.org/10.1109/TMC.2019.2940941">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid and continuous growth of various types of wireless devices in IoT, securing the communications among heterogeneous devices becomes an emerging issue. A physical layer security scheme, called “friendly jamming”, has drawn great attention recently owing to its ability to protect the confidentiality of the communication as well as to enable message authentication and access control for those already employed, unencrypted, weakly encrypted, or resource constrained devices. We notice that in a large number of cases in which friendly jamming are preferable, the transmitting signals to be protected have varying spectrum utilization at symbol level. In this paper, we rebuild secrecy capacity models and re-evaluate the jamming efficiency by taking this micro time scale non-stationary characteristic into consideration. Our reassessments reveal that jamming efficiency is greatly overestimated in the existing literature. The second part of our work further proposes a waveform design on jamming signal as a means to enhance the jamming efficiency. The basic idea is to consider both time and frequency domain structure of the transmitting signal when designing the jamming signal, making both time and frequency bandwidth largely match to each other. We discuss the implementation details for jamming common QAM and PSK modulated signals. Both simulations and proof-of-concept experiments validate the theoretical correctness of our reassessment and practical effectiveness of our method.},
  archive      = {J_TMC},
  author       = {Rong Jin and Kai Zeng and Kai Zhang},
  doi          = {10.1109/TMC.2019.2940941},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {32-47},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A reassessment on friendly jamming efficiency},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel mobile edge network architecture with joint
caching-delivering and horizontal cooperation. <em>TMC</em>,
<em>20</em>(1), 19–31. (<a
href="https://doi.org/10.1109/TMC.2019.2938510">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile edge caching/computing (MEC) has been emerging as a promising paradigm to provide ultra-high rate, ultra-reliable, and/or low-latency communications in future wireless networks. In this paper, we introduce a novel MEC network architecture that leverages the optimal joint caching-delivering with horizontal cooperation among mobile edge nodes (MENs). To that end, we first formulate the content-access delay minimization problem by jointly optimizing the content caching and delivering decisions under various network constraints (e.g., network topology, storage capacity and users’ demands at each MEN). However, the strongly mutual dependency between the decisions makes the problem a nested dual optimization that is proved to be NP-hard. To deal with it, we propose a novel transformation method to transform the nested dual problem to an equivalent mixed-integer nonlinear programming (MINLP) optimization problem. Then, we design a centralized solution using an improved branch-and-bound algorithm with the interior-point method to find the joint caching and delivering policy which is within 1 percent of the optimal solution. Since the centralized solution requires the full network topology and information from all MENs, to make our solution scalable, we develop a distributed algorithm which allows each MEN to make its own decisions based on its local observations. Extensive simulations demonstrate that the proposed solutions can reduce the total average delay for the whole network up to 40 percent compared with other current caching policies. Furthermore, the proposed solutions also increase the cache hit ratio for the network up to 4 times, thereby dramatically reducing the traffic load on the backhaul network.},
  archive      = {J_TMC},
  author       = {Yuris Mulya Saputra and Dinh Thai Hoang and Diep N. Nguyen and Eryk Dutkiewicz},
  doi          = {10.1109/TMC.2019.2938510},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {19-31},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A novel mobile edge network architecture with joint caching-delivering and horizontal cooperation},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A link-layer synchronization and medium access control
protocol for terahertz-band communication networks. <em>TMC</em>,
<em>20</em>(1), 2–18. (<a
href="https://doi.org/10.1109/TMC.2019.2940441">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a link-layer synchronization and medium access control (MAC) protocol for very-high-speed wireless communication networks in the Terahertz (THz) band is presented. The protocol relies on a receiver-initiated handshake to guarantee synchronization between transmitter and receiver. Two scenarios are considered, namely, a macroscale scenario, where nodes utilize rotating directional antennas to periodically sweep the space while overcoming the distance problem at THz frequencies, and a nanoscale scenario, where nano-devices require energy harvesting systems to operate. Both scenarios are implemented on a centralized and an ad-hoc network architecture. A carrier-based physical layer is considered for the macro-scenario, whereas the physical layer for the nano-scenario is based on a femtosecond-long pulse-based modulation scheme with packet interleaving. The performance of the proposed MAC protocol is analytically investigated in terms of delay, throughput and probability of successful packet delivery, and compared to that of an adapted Carrier Sense Multiple Access with Collision Avoidance (CSMA/CA) with and without handshake. The results are validated by means of extensive simulations with ns-3, in which all the necessary THz elements have been implemented. The results show that the proposed protocol can maximize the successful packet delivery probability without compromising the achievable throughput in THz-band communication networks.},
  archive      = {J_TMC},
  author       = {Qing Xia and Zahed Hossain and Michael Medley and Josep Miquel Jornet},
  doi          = {10.1109/TMC.2019.2940441},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {2-18},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A link-layer synchronization and medium access control protocol for terahertz-band communication networks},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A message from the editor-in-chief. <em>TMC</em>,
<em>20</em>(1), 1. (<a
href="https://doi.org/10.1109/TMC.2020.3035951">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Presents the introductory editorial for this issue of the publication.},
  archive      = {J_TMC},
  author       = {Qian Zhang},
  doi          = {10.1109/TMC.2020.3035951},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {1},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A message from the editor-in-chief},
  volume       = {20},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
